{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9012179600183294, "cur_kl_coeff": 0.2, "cur_lr": 0.0010000000000000005, "total_loss": 7.993553760316637, "policy_loss": -0.008550286512063058, "vf_loss": 7.998858353700587, "vf_explained_var": 0.021807681158106162, "kl": 0.016228428122698334, "entropy": 1.5934406296286003, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2447327791067657, "cur_kl_coeff": 0.2, "cur_lr": 0.0010000000000000005, "total_loss": 5.824562709545963, "policy_loss": -0.015014972186046185, "vf_loss": 5.836051817041225, "vf_explained_var": 0.0038711574657884222, "kl": 0.017629352552617647, "entropy": 1.5920560142350575, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 150.79999999999967, "episode_reward_min": -193.00000000000122, "episode_reward_mean": -15.616666666666914, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -388.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.0, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": -75.08611111111118, "predator_policy": 67.27777777777777}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.599999999999998, -133.40000000000066, 111.19999999999968, -13.99999999999996, -167.00000000000074, 127.29999999999973, -13.899999999999679, -183.3000000000005, 96.30000000000005, -29.20000000000084, -193.00000000000122, -62.59999999999993, 150.79999999999967, 134.99999999999974, -74.19999999999989, -8.200000000000113, 56.500000000000455, -96.00000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999772, 5.300000000000038, -333.40000000000015, -48.999999999999844, 22.700000000000063, 42.50000000000011, 25.40000000000006, -93.40000000000018, -70.60000000000053, -300.3999999999994, 80.00000000000001, -15.700000000000049, -5.199999999999777, -147.69999999999993, -381.20000000000005, -192.10000000000034, 160.9999999999999, -264.7, -0.7000000000004079, -158.50000000000065, -152.20000000000059, -149.80000000000052, 112.69999999999956, -388.30000000000007, -110.2000000000004, 182.0, 70.40000000000005, 17.600000000000083, -268.90000000000026, 46.70000000000024, -42.4, -71.80000000000058, 2.000000000000073, 42.50000000000025, -85.89999999999986, -216.1000000000001], "policy_predator_policy_reward": [10.0, 17.0, 140.0, 109.0, 17.0, 29.0, 9.0, 45.0, 97.0, 107.0, 36.0, 27.0, 58.0, 81.0, 127.0, 263.0, 145.0, 55.0, 85.0, 45.0, 104.0, 5.0, 210.0, 3.0, 71.0, 8.0, 20.0, 27.0, 44.0, 104.0, 54.0, 52.0, 0.0, 12.0, 104.0, 102.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9941128132444373, "mean_inference_ms": 2.615219638032129, "mean_action_processing_ms": 0.3830819479303555, "mean_env_wait_ms": 0.31257402603034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010430150561862521, "StateBufferConnector_ms": 0.00467167960272895, "ViewRequirementAgentConnector_ms": 0.19935501946343315}, "num_episodes": 18, "episode_return_max": 150.79999999999967, "episode_return_min": -193.00000000000122, "episode_return_mean": -15.616666666666914, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.00315554869496, "num_env_steps_trained_throughput_per_sec": 320.00315554869496, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 12499.885, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12499.832, "sample_time_ms": 2055.989, "learn_time_ms": 10422.49, "learn_throughput": 383.785, "synch_weights_time_ms": 16.22}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "f0d88_00000", "date": "2024-08-14_10-46-30", "timestamp": 1723646790, "time_this_iter_s": 12.547019004821777, "time_total_s": 12.547019004821777, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac05f700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12.547019004821777, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 40.261111111111106, "ram_util_percent": 83.68333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9366909377158634, "cur_kl_coeff": 0.2, "cur_lr": 0.0010000000000000005, "total_loss": 8.8067875115329, "policy_loss": -0.02082799678328373, "vf_loss": 8.82280205999102, "vf_explained_var": 0.05012175191647161, "kl": 0.02406728610392979, "entropy": 1.5653477711021584, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6517437425870745, "cur_kl_coeff": 0.2, "cur_lr": 0.0010000000000000005, "total_loss": 5.4667638750934096, "policy_loss": -0.02338770849220011, "vf_loss": 5.48557659822797, "vf_explained_var": 0.004410808269308989, "kl": 0.022875011675129366, "entropy": 1.5705676699441578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 258.89999999999986, "episode_reward_min": -266.39999999999884, "episode_reward_mean": 8.049999999999812, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -388.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.19999999999993, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": -65.35000000000005, "predator_policy": 69.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.599999999999998, -133.40000000000066, 111.19999999999968, -13.99999999999996, -167.00000000000074, 127.29999999999973, -13.899999999999679, -183.3000000000005, 96.30000000000005, -29.20000000000084, -193.00000000000122, -62.59999999999993, 150.79999999999967, 134.99999999999974, -74.19999999999989, -8.200000000000113, 56.500000000000455, -96.00000000000028, 83.79999999999984, 118.39999999999975, 258.89999999999986, 95.19999999999992, 79.70000000000007, 173.59999999999962, 87.29999999999964, 73.5999999999999, 15.100000000000039, 136.2999999999997, 10.599999999999948, 69.60000000000002, -97.6, -215.00000000000057, 80.30000000000014, -266.39999999999884, 76.799999999999, -209.30000000000038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999772, 5.300000000000038, -333.40000000000015, -48.999999999999844, 22.700000000000063, 42.50000000000011, 25.40000000000006, -93.40000000000018, -70.60000000000053, -300.3999999999994, 80.00000000000001, -15.700000000000049, -5.199999999999777, -147.69999999999993, -381.20000000000005, -192.10000000000034, 160.9999999999999, -264.7, -0.7000000000004079, -158.50000000000065, -152.20000000000059, -149.80000000000052, 112.69999999999956, -388.30000000000007, -110.2000000000004, 182.0, 70.40000000000005, 17.600000000000083, -268.90000000000026, 46.70000000000024, -42.4, -71.80000000000058, 2.000000000000073, 42.50000000000025, -85.89999999999986, -216.1000000000001, -373.5999999999997, 187.39999999999992, -17.200000000000003, 56.600000000000065, 179.3, 32.60000000000006, -81.40000000000009, 38.60000000000002, 11.900000000000002, -5.1999999999999265, 24.50000000000021, 121.1, 18.500000000000114, -38.200000000000074, -98.8000000000001, 67.40000000000012, -49.30000000000001, -91.60000000000005, 189.19999999999993, -319.89999999999924, 68.60000000000015, -169.00000000000048, -193.30000000000007, 74.89999999999966, -47.5, -341.10000000000025, -271.00000000000006, -115.00000000000037, 109.69999999999999, -120.40000000000035, -222.70000000000005, -225.7000000000003, 24.50000000000012, -15.700000000000017, -259.5999999999994, -150.69999999999993], "policy_predator_policy_reward": [10.0, 17.0, 140.0, 109.0, 17.0, 29.0, 9.0, 45.0, 97.0, 107.0, 36.0, 27.0, 58.0, 81.0, 127.0, 263.0, 145.0, 55.0, 85.0, 45.0, 104.0, 5.0, 210.0, 3.0, 71.0, 8.0, 20.0, 27.0, 44.0, 104.0, 54.0, 52.0, 0.0, 12.0, 104.0, 102.0, 126.0, 144.0, 38.0, 41.0, 5.0, 42.0, 78.0, 60.0, 46.0, 27.0, 13.0, 15.0, 36.0, 71.0, 93.0, 12.0, 79.0, 77.0, 82.0, 185.0, 55.0, 56.0, 83.0, 105.0, 223.0, 68.0, 29.0, 142.0, 4.0, 87.0, 32.0, 150.0, 28.0, 40.0, 39.0, 162.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9194879634717716, "mean_inference_ms": 2.400272129125089, "mean_action_processing_ms": 0.35408455555153046, "mean_env_wait_ms": 0.2943446035176461, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009217527177598741, "StateBufferConnector_ms": 0.0040272871653238935, "ViewRequirementAgentConnector_ms": 0.16250047418806288}, "num_episodes": 18, "episode_return_max": 258.89999999999986, "episode_return_min": -266.39999999999884, "episode_return_mean": 8.049999999999812, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.02216198968983, "num_env_steps_trained_throughput_per_sec": 360.02216198968983, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 11805.16, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11805.103, "sample_time_ms": 1714.536, "learn_time_ms": 10065.957, "learn_throughput": 397.379, "synch_weights_time_ms": 19.822}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "f0d88_00000", "date": "2024-08-14_10-46-44", "timestamp": 1723646804, "time_this_iter_s": 11.166929960250854, "time_total_s": 23.713948965072632, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac053f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 23.713948965072632, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 32.870000000000005, "ram_util_percent": 83.43500000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5973149097785746, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.0010000000000000005, "total_loss": 7.7432690910561375, "policy_loss": -0.01905609586463364, "vf_loss": 7.7543723749736, "vf_explained_var": 0.13917809516664537, "kl": 0.026509398464840298, "entropy": 1.5513790405616559, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.075623131334466, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.0010000000000000005, "total_loss": 4.060278237685956, "policy_loss": -0.022542586685380055, "vf_loss": 4.076250008678941, "vf_explained_var": 0.040498238549661385, "kl": 0.021902694046222013, "entropy": 1.5563588720780832, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 270.5, "episode_reward_min": -266.39999999999884, "episode_reward_mean": 37.24999999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -388.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.19999999999993, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": -44.51388888888894, "predator_policy": 63.138888888888886}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.599999999999998, -133.40000000000066, 111.19999999999968, -13.99999999999996, -167.00000000000074, 127.29999999999973, -13.899999999999679, -183.3000000000005, 96.30000000000005, -29.20000000000084, -193.00000000000122, -62.59999999999993, 150.79999999999967, 134.99999999999974, -74.19999999999989, -8.200000000000113, 56.500000000000455, -96.00000000000028, 83.79999999999984, 118.39999999999975, 258.89999999999986, 95.19999999999992, 79.70000000000007, 173.59999999999962, 87.29999999999964, 73.5999999999999, 15.100000000000039, 136.2999999999997, 10.599999999999948, 69.60000000000002, -97.6, -215.00000000000057, 80.30000000000014, -266.39999999999884, 76.799999999999, -209.30000000000038, 32.99999999999978, 270.5, -65.3000000000001, 59.00000000000008, 9.100000000000001, 226.79999999999998, -50.79999999999984, 260.39999999999964, 31.300000000000097, 197.09999999999985, 143.99999999999966, 110.89999999999921, 127.59999999999971, 270.5, 180.49999999999983, -20.39999999999958, -98.29999999999987, 35.80000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999772, 5.300000000000038, -333.40000000000015, -48.999999999999844, 22.700000000000063, 42.50000000000011, 25.40000000000006, -93.40000000000018, -70.60000000000053, -300.3999999999994, 80.00000000000001, -15.700000000000049, -5.199999999999777, -147.69999999999993, -381.20000000000005, -192.10000000000034, 160.9999999999999, -264.7, -0.7000000000004079, -158.50000000000065, -152.20000000000059, -149.80000000000052, 112.69999999999956, -388.30000000000007, -110.2000000000004, 182.0, 70.40000000000005, 17.600000000000083, -268.90000000000026, 46.70000000000024, -42.4, -71.80000000000058, 2.000000000000073, 42.50000000000025, -85.89999999999986, -216.1000000000001, -373.5999999999997, 187.39999999999992, -17.200000000000003, 56.600000000000065, 179.3, 32.60000000000006, -81.40000000000009, 38.60000000000002, 11.900000000000002, -5.1999999999999265, 24.50000000000021, 121.1, 18.500000000000114, -38.200000000000074, -98.8000000000001, 67.40000000000012, -49.30000000000001, -91.60000000000005, 189.19999999999993, -319.89999999999924, 68.60000000000015, -169.00000000000048, -193.30000000000007, 74.89999999999966, -47.5, -341.10000000000025, -271.00000000000006, -115.00000000000037, 109.69999999999999, -120.40000000000035, -222.70000000000005, -225.7000000000003, 24.50000000000012, -15.700000000000017, -259.5999999999994, -150.69999999999993, -32.500000000000256, -101.50000000000009, 16.69999999999999, 186.79999999999998, -61.89999999999979, -156.40000000000015, 57.50000000000003, -101.50000000000003, -221.50000000000045, 86.5999999999998, 167.89999999999995, -30.099999999999937, -33.09999999999988, -156.69999999999987, 62.60000000000001, 138.79999999999967, -38.19999999999978, -20.50000000000002, 62.90000000000002, 72.19999999999999, 5.299999999999965, 100.7, 62.900000000000084, 20.000000000000014, 140.59999999999974, -121.00000000000037, 60.19999999999999, 137.3, 73.10000000000001, 25.40000000000002, 6.199999999999968, -94.6000000000007, -267.70000000000016, -34.60000000000001, -175.00000000000006, 60.8], "policy_predator_policy_reward": [10.0, 17.0, 140.0, 109.0, 17.0, 29.0, 9.0, 45.0, 97.0, 107.0, 36.0, 27.0, 58.0, 81.0, 127.0, 263.0, 145.0, 55.0, 85.0, 45.0, 104.0, 5.0, 210.0, 3.0, 71.0, 8.0, 20.0, 27.0, 44.0, 104.0, 54.0, 52.0, 0.0, 12.0, 104.0, 102.0, 126.0, 144.0, 38.0, 41.0, 5.0, 42.0, 78.0, 60.0, 46.0, 27.0, 13.0, 15.0, 36.0, 71.0, 93.0, 12.0, 79.0, 77.0, 82.0, 185.0, 55.0, 56.0, 83.0, 105.0, 223.0, 68.0, 29.0, 142.0, 4.0, 87.0, 32.0, 150.0, 28.0, 40.0, 39.0, 162.0, 107.0, 60.0, 26.0, 41.0, 107.0, 46.0, 4.0, 99.0, 27.0, 117.0, 45.0, 44.0, 53.0, 86.0, 25.0, 34.0, 58.0, 32.0, 37.0, 25.0, 11.0, 27.0, 28.0, 0.0, 80.0, 28.0, 38.0, 35.0, 17.0, 65.0, 61.0, 7.0, 134.0, 70.0, 138.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8789952699991546, "mean_inference_ms": 2.2978798539806697, "mean_action_processing_ms": 0.33987157172061866, "mean_env_wait_ms": 0.28420712955668204, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010569228066338433, "StateBufferConnector_ms": 0.003906532570167824, "ViewRequirementAgentConnector_ms": 0.15465396421926994}, "num_episodes": 18, "episode_return_max": 270.5, "episode_return_min": -266.39999999999884, "episode_return_mean": 37.24999999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.49541301263395, "num_env_steps_trained_throughput_per_sec": 320.49541301263395, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 12030.335, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12030.282, "sample_time_ms": 1623.351, "learn_time_ms": 10382.773, "learn_throughput": 385.254, "synch_weights_time_ms": 19.772}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "f0d88_00000", "date": "2024-08-14_10-46-56", "timestamp": 1723646816, "time_this_iter_s": 12.607851028442383, "time_total_s": 36.321799993515015, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac05f9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 36.321799993515015, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 49.76666666666667, "ram_util_percent": 83.41111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3065967776157237, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 0.0010000000000000005, "total_loss": 6.880969674246652, "policy_loss": -0.01742852840069977, "vf_loss": 6.88887835331064, "vf_explained_var": 0.11641851332452562, "kl": 0.021155221698331096, "entropy": 1.5202935421908343, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.848255964971724, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 0.0010000000000000005, "total_loss": 3.7483536886790443, "policy_loss": -0.030161994919747546, "vf_loss": 3.7692797673442375, "vf_explained_var": 0.10387197158954761, "kl": 0.020524255189273224, "entropy": 1.5525170210808044, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 270.5, "episode_reward_min": -266.39999999999884, "episode_reward_mean": 48.399999999999785, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -388.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.19999999999993, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": -34.668055555555625, "predator_policy": 58.86805555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.599999999999998, -133.40000000000066, 111.19999999999968, -13.99999999999996, -167.00000000000074, 127.29999999999973, -13.899999999999679, -183.3000000000005, 96.30000000000005, -29.20000000000084, -193.00000000000122, -62.59999999999993, 150.79999999999967, 134.99999999999974, -74.19999999999989, -8.200000000000113, 56.500000000000455, -96.00000000000028, 83.79999999999984, 118.39999999999975, 258.89999999999986, 95.19999999999992, 79.70000000000007, 173.59999999999962, 87.29999999999964, 73.5999999999999, 15.100000000000039, 136.2999999999997, 10.599999999999948, 69.60000000000002, -97.6, -215.00000000000057, 80.30000000000014, -266.39999999999884, 76.799999999999, -209.30000000000038, 32.99999999999978, 270.5, -65.3000000000001, 59.00000000000008, 9.100000000000001, 226.79999999999998, -50.79999999999984, 260.39999999999964, 31.300000000000097, 197.09999999999985, 143.99999999999966, 110.89999999999921, 127.59999999999971, 270.5, 180.49999999999983, -20.39999999999958, -98.29999999999987, 35.80000000000001, -70.79999999999984, 94.19999999999959, 193.9999999999992, 172.4999999999994, 170.00000000000006, 38.300000000000004, 175.99999999999955, -85.1, 159.09999999999965, -18.90000000000051, 157.99999999999957, 171.19999999999945, -10.099999999999685, -53.500000000001044, -104.20000000000073, 170.09999999999926, 116.19999999999982, 196.2999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999772, 5.300000000000038, -333.40000000000015, -48.999999999999844, 22.700000000000063, 42.50000000000011, 25.40000000000006, -93.40000000000018, -70.60000000000053, -300.3999999999994, 80.00000000000001, -15.700000000000049, -5.199999999999777, -147.69999999999993, -381.20000000000005, -192.10000000000034, 160.9999999999999, -264.7, -0.7000000000004079, -158.50000000000065, -152.20000000000059, -149.80000000000052, 112.69999999999956, -388.30000000000007, -110.2000000000004, 182.0, 70.40000000000005, 17.600000000000083, -268.90000000000026, 46.70000000000024, -42.4, -71.80000000000058, 2.000000000000073, 42.50000000000025, -85.89999999999986, -216.1000000000001, -373.5999999999997, 187.39999999999992, -17.200000000000003, 56.600000000000065, 179.3, 32.60000000000006, -81.40000000000009, 38.60000000000002, 11.900000000000002, -5.1999999999999265, 24.50000000000021, 121.1, 18.500000000000114, -38.200000000000074, -98.8000000000001, 67.40000000000012, -49.30000000000001, -91.60000000000005, 189.19999999999993, -319.89999999999924, 68.60000000000015, -169.00000000000048, -193.30000000000007, 74.89999999999966, -47.5, -341.10000000000025, -271.00000000000006, -115.00000000000037, 109.69999999999999, -120.40000000000035, -222.70000000000005, -225.7000000000003, 24.50000000000012, -15.700000000000017, -259.5999999999994, -150.69999999999993, -32.500000000000256, -101.50000000000009, 16.69999999999999, 186.79999999999998, -61.89999999999979, -156.40000000000015, 57.50000000000003, -101.50000000000003, -221.50000000000045, 86.5999999999998, 167.89999999999995, -30.099999999999937, -33.09999999999988, -156.69999999999987, 62.60000000000001, 138.79999999999967, -38.19999999999978, -20.50000000000002, 62.90000000000002, 72.19999999999999, 5.299999999999965, 100.7, 62.900000000000084, 20.000000000000014, 140.59999999999974, -121.00000000000037, 60.19999999999999, 137.3, 73.10000000000001, 25.40000000000002, 6.199999999999968, -94.6000000000007, -267.70000000000016, -34.60000000000001, -175.00000000000006, 60.8, 21.800000000000047, -234.60000000000002, -31.0, 27.20000000000015, 54.200000000000195, 102.80000000000001, 51.80000000000001, 49.70000000000019, 22.39999999999978, 68.6, -1.9000000000000834, -50.79999999999994, 71.3000000000001, 64.70000000000002, -126.09999999999997, -130.0, 40.7, 13.399999999999979, -80.80000000000078, -63.10000000000002, 20.000000000000014, 101.0, 23.900000000000098, 101.30000000000001, -14.500000000000483, -97.59999999999994, -59.80000000000062, -78.70000000000087, -183.40000000000015, -125.80000000000058, -8.799999999999985, 122.89999999999986, 125.00000000000001, -122.80000000000075, 90.8, 51.500000000000234], "policy_predator_policy_reward": [10.0, 17.0, 140.0, 109.0, 17.0, 29.0, 9.0, 45.0, 97.0, 107.0, 36.0, 27.0, 58.0, 81.0, 127.0, 263.0, 145.0, 55.0, 85.0, 45.0, 104.0, 5.0, 210.0, 3.0, 71.0, 8.0, 20.0, 27.0, 44.0, 104.0, 54.0, 52.0, 0.0, 12.0, 104.0, 102.0, 126.0, 144.0, 38.0, 41.0, 5.0, 42.0, 78.0, 60.0, 46.0, 27.0, 13.0, 15.0, 36.0, 71.0, 93.0, 12.0, 79.0, 77.0, 82.0, 185.0, 55.0, 56.0, 83.0, 105.0, 223.0, 68.0, 29.0, 142.0, 4.0, 87.0, 32.0, 150.0, 28.0, 40.0, 39.0, 162.0, 107.0, 60.0, 26.0, 41.0, 107.0, 46.0, 4.0, 99.0, 27.0, 117.0, 45.0, 44.0, 53.0, 86.0, 25.0, 34.0, 58.0, 32.0, 37.0, 25.0, 11.0, 27.0, 28.0, 0.0, 80.0, 28.0, 38.0, 35.0, 17.0, 65.0, 61.0, 7.0, 134.0, 70.0, 138.0, 12.0, 142.0, 0.0, 65.0, 33.0, 17.0, 20.0, 47.0, 24.0, 36.0, 43.0, 68.0, 23.0, 15.0, 25.0, 42.0, 129.0, 37.0, 68.0, 28.0, 97.0, 25.0, 12.0, 30.0, 16.0, 46.0, 56.0, 39.0, 46.0, 62.0, 143.0, 42.0, 14.0, 62.0, 52.0, 25.0, 29.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9198706467460656, "mean_inference_ms": 2.425435529212565, "mean_action_processing_ms": 0.35144153471176337, "mean_env_wait_ms": 0.3036099145705393, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013888213369581435, "StateBufferConnector_ms": 0.004015862941741943, "ViewRequirementAgentConnector_ms": 0.2111532621913486}, "num_episodes": 18, "episode_return_max": 270.5, "episode_return_min": -266.39999999999884, "episode_return_mean": 48.399999999999785, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 213.81982705579853, "num_env_steps_trained_throughput_per_sec": 213.81982705579853, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 13699.588, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13699.538, "sample_time_ms": 2182.748, "learn_time_ms": 11493.761, "learn_throughput": 348.015, "synch_weights_time_ms": 19.101}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "f0d88_00000", "date": "2024-08-14_10-47-15", "timestamp": 1723646835, "time_this_iter_s": 18.742547035217285, "time_total_s": 55.0643470287323, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad48dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 55.0643470287323, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 82.20000000000002, "ram_util_percent": 83.81153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2459997018178304, "cur_kl_coeff": 0.675, "cur_lr": 0.0010000000000000005, "total_loss": 8.236981076285952, "policy_loss": -0.02002752543372846, "vf_loss": 8.244079237387925, "vf_explained_var": 0.15169395971550512, "kl": 0.019154620908423806, "entropy": 1.4768850628030363, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9888434368151207, "cur_kl_coeff": 0.675, "cur_lr": 0.0010000000000000005, "total_loss": 4.107298983089508, "policy_loss": -0.02956843452168402, "vf_loss": 4.123977624802363, "vf_explained_var": 0.1339706044663828, "kl": 0.019095970515692604, "entropy": 1.5400850123198575, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 310.9999999999998, "episode_reward_min": -266.39999999999884, "episode_reward_mean": 64.2656565656564, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -388.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.19999999999993, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": -24.038888888888952, "predator_policy": 56.17171717171717}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.599999999999998, -133.40000000000066, 111.19999999999968, -13.99999999999996, -167.00000000000074, 127.29999999999973, -13.899999999999679, -183.3000000000005, 96.30000000000005, -29.20000000000084, -193.00000000000122, -62.59999999999993, 150.79999999999967, 134.99999999999974, -74.19999999999989, -8.200000000000113, 56.500000000000455, -96.00000000000028, 83.79999999999984, 118.39999999999975, 258.89999999999986, 95.19999999999992, 79.70000000000007, 173.59999999999962, 87.29999999999964, 73.5999999999999, 15.100000000000039, 136.2999999999997, 10.599999999999948, 69.60000000000002, -97.6, -215.00000000000057, 80.30000000000014, -266.39999999999884, 76.799999999999, -209.30000000000038, 32.99999999999978, 270.5, -65.3000000000001, 59.00000000000008, 9.100000000000001, 226.79999999999998, -50.79999999999984, 260.39999999999964, 31.300000000000097, 197.09999999999985, 143.99999999999966, 110.89999999999921, 127.59999999999971, 270.5, 180.49999999999983, -20.39999999999958, -98.29999999999987, 35.80000000000001, -70.79999999999984, 94.19999999999959, 193.9999999999992, 172.4999999999994, 170.00000000000006, 38.300000000000004, 175.99999999999955, -85.1, 159.09999999999965, -18.90000000000051, 157.99999999999957, 171.19999999999945, -10.099999999999685, -53.500000000001044, -104.20000000000073, 170.09999999999926, 116.19999999999982, 196.2999999999994, 31.500000000000142, 161.2, -33.29999999999961, -8.999999999999932, 106.69999999999999, 89.50000000000004, 23.300000000000093, 170.4000000000001, 148.0, 27.40000000000002, -4.3000000000002405, 117.19999999999976, 223.89999999999995, 173.29999999999978, 21.89999999999994, -94.30000000000004, 198.2, 109.39999999999999, 59.30000000000008, 163.2999999999994, 71.00000000000004, 175.59999999999934, 240.20000000000002, -32.0, 167.6999999999995, 310.9999999999998, 260.40000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999772, 5.300000000000038, -333.40000000000015, -48.999999999999844, 22.700000000000063, 42.50000000000011, 25.40000000000006, -93.40000000000018, -70.60000000000053, -300.3999999999994, 80.00000000000001, -15.700000000000049, -5.199999999999777, -147.69999999999993, -381.20000000000005, -192.10000000000034, 160.9999999999999, -264.7, -0.7000000000004079, -158.50000000000065, -152.20000000000059, -149.80000000000052, 112.69999999999956, -388.30000000000007, -110.2000000000004, 182.0, 70.40000000000005, 17.600000000000083, -268.90000000000026, 46.70000000000024, -42.4, -71.80000000000058, 2.000000000000073, 42.50000000000025, -85.89999999999986, -216.1000000000001, -373.5999999999997, 187.39999999999992, -17.200000000000003, 56.600000000000065, 179.3, 32.60000000000006, -81.40000000000009, 38.60000000000002, 11.900000000000002, -5.1999999999999265, 24.50000000000021, 121.1, 18.500000000000114, -38.200000000000074, -98.8000000000001, 67.40000000000012, -49.30000000000001, -91.60000000000005, 189.19999999999993, -319.89999999999924, 68.60000000000015, -169.00000000000048, -193.30000000000007, 74.89999999999966, -47.5, -341.10000000000025, -271.00000000000006, -115.00000000000037, 109.69999999999999, -120.40000000000035, -222.70000000000005, -225.7000000000003, 24.50000000000012, -15.700000000000017, -259.5999999999994, -150.69999999999993, -32.500000000000256, -101.50000000000009, 16.69999999999999, 186.79999999999998, -61.89999999999979, -156.40000000000015, 57.50000000000003, -101.50000000000003, -221.50000000000045, 86.5999999999998, 167.89999999999995, -30.099999999999937, -33.09999999999988, -156.69999999999987, 62.60000000000001, 138.79999999999967, -38.19999999999978, -20.50000000000002, 62.90000000000002, 72.19999999999999, 5.299999999999965, 100.7, 62.900000000000084, 20.000000000000014, 140.59999999999974, -121.00000000000037, 60.19999999999999, 137.3, 73.10000000000001, 25.40000000000002, 6.199999999999968, -94.6000000000007, -267.70000000000016, -34.60000000000001, -175.00000000000006, 60.8, 21.800000000000047, -234.60000000000002, -31.0, 27.20000000000015, 54.200000000000195, 102.80000000000001, 51.80000000000001, 49.70000000000019, 22.39999999999978, 68.6, -1.9000000000000834, -50.79999999999994, 71.3000000000001, 64.70000000000002, -126.09999999999997, -130.0, 40.7, 13.399999999999979, -80.80000000000078, -63.10000000000002, 20.000000000000014, 101.0, 23.900000000000098, 101.30000000000001, -14.500000000000483, -97.59999999999994, -59.80000000000062, -78.70000000000087, -183.40000000000015, -125.80000000000058, -8.799999999999985, 122.89999999999986, 125.00000000000001, -122.80000000000075, 90.8, 51.500000000000234, 53.0, -158.50000000000028, 71.6, -33.400000000000006, 9.499999999999964, -143.8000000000002, -166.90000000000055, -18.09999999999998, -13.0, 31.699999999999996, -68.5, 59.00000000000006, -51.09999999999983, -4.599999999999978, 48.5, 41.9000000000001, 41.0, 23.0, 17.599999999999994, -134.20000000000016, -152.2000000000006, 29.900000000000077, 57.20000000000004, 20.000000000000014, 119.29999999999993, 26.599999999999966, -78.69999999999999, 127.99999999999979, -55.300000000000004, -89.80000000000013, -101.80000000000075, -173.50000000000026, 119.0, 12.199999999999994, 62.599999999999994, -77.19999999999999, -130.90000000000015, 63.20000000000003, 141.2, -19.899999999999743, 8.299999999999997, -46.3, 131.59999999999994, 20.000000000000014, 110.9, 68.3, -130.0, -37.0, 156.5, -59.80000000000062, 145.99999999999997, 136.99999999999994, 171.5, 50.900000000000055], "policy_predator_policy_reward": [10.0, 17.0, 140.0, 109.0, 17.0, 29.0, 9.0, 45.0, 97.0, 107.0, 36.0, 27.0, 58.0, 81.0, 127.0, 263.0, 145.0, 55.0, 85.0, 45.0, 104.0, 5.0, 210.0, 3.0, 71.0, 8.0, 20.0, 27.0, 44.0, 104.0, 54.0, 52.0, 0.0, 12.0, 104.0, 102.0, 126.0, 144.0, 38.0, 41.0, 5.0, 42.0, 78.0, 60.0, 46.0, 27.0, 13.0, 15.0, 36.0, 71.0, 93.0, 12.0, 79.0, 77.0, 82.0, 185.0, 55.0, 56.0, 83.0, 105.0, 223.0, 68.0, 29.0, 142.0, 4.0, 87.0, 32.0, 150.0, 28.0, 40.0, 39.0, 162.0, 107.0, 60.0, 26.0, 41.0, 107.0, 46.0, 4.0, 99.0, 27.0, 117.0, 45.0, 44.0, 53.0, 86.0, 25.0, 34.0, 58.0, 32.0, 37.0, 25.0, 11.0, 27.0, 28.0, 0.0, 80.0, 28.0, 38.0, 35.0, 17.0, 65.0, 61.0, 7.0, 134.0, 70.0, 138.0, 12.0, 142.0, 0.0, 65.0, 33.0, 17.0, 20.0, 47.0, 24.0, 36.0, 43.0, 68.0, 23.0, 15.0, 25.0, 42.0, 129.0, 37.0, 68.0, 28.0, 97.0, 25.0, 12.0, 30.0, 16.0, 46.0, 56.0, 39.0, 46.0, 62.0, 143.0, 42.0, 14.0, 62.0, 52.0, 25.0, 29.0, 121.0, 16.0, 47.0, 76.0, 25.0, 76.0, 99.0, 77.0, 20.0, 68.0, 82.0, 17.0, 33.0, 46.0, 61.0, 19.0, 27.0, 57.0, 83.0, 61.0, 32.0, 86.0, 17.0, 23.0, 57.0, 21.0, 36.0, 88.0, 98.0, 69.0, 46.0, 135.0, 4.0, 63.0, 92.0, 32.0, 21.0, 106.0, 12.0, 30.0, 91.0, 18.0, 8.0, 16.0, 44.0, 17.0, 25.0, 110.0, 35.0, 36.0, 13.0, 15.0, 1.0, 37.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.943135872696991, "mean_inference_ms": 2.4976701152348313, "mean_action_processing_ms": 0.3597971564204642, "mean_env_wait_ms": 0.31541786200633914, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014524267177389126, "StateBufferConnector_ms": 0.00404878096147017, "ViewRequirementAgentConnector_ms": 0.19344898185344658}, "num_episodes": 27, "episode_return_max": 310.9999999999998, "episode_return_min": -266.39999999999884, "episode_return_mean": 64.2656565656564, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.8938462612676, "num_env_steps_trained_throughput_per_sec": 319.8938462612676, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 13460.502, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13460.452, "sample_time_ms": 2104.246, "learn_time_ms": 11335.197, "learn_throughput": 352.883, "synch_weights_time_ms": 17.71}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "f0d88_00000", "date": "2024-08-14_10-47-28", "timestamp": 1723646848, "time_this_iter_s": 12.550042152404785, "time_total_s": 67.61438918113708, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac096160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 67.61438918113708, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 49.75555555555556, "ram_util_percent": 83.61111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.012134970338256, "cur_kl_coeff": 0.675, "cur_lr": 0.0010000000000000005, "total_loss": 9.178387489016094, "policy_loss": -0.0128493586264393, "vf_loss": 9.179262600752411, "vf_explained_var": -0.008112715097962233, "kl": 0.0177396607129114, "entropy": 1.459194890594987, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0888886816917904, "cur_kl_coeff": 0.675, "cur_lr": 0.0010000000000000005, "total_loss": 5.274026749373744, "policy_loss": -0.030935579322515026, "vf_loss": 5.2898612630430355, "vf_explained_var": 0.13325184700350282, "kl": 0.022371926222256172, "entropy": 1.5216722138975032, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 325.7999999999999, "episode_reward_min": -315.5, "episode_reward_mean": 65.50999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.5999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.19999999999993, "predator_policy": 223.0}, "policy_reward_mean": {"prey_policy": -25.65000000000005, "predator_policy": 58.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-96.00000000000028, 83.79999999999984, 118.39999999999975, 258.89999999999986, 95.19999999999992, 79.70000000000007, 173.59999999999962, 87.29999999999964, 73.5999999999999, 15.100000000000039, 136.2999999999997, 10.599999999999948, 69.60000000000002, -97.6, -215.00000000000057, 80.30000000000014, -266.39999999999884, 76.799999999999, -209.30000000000038, 32.99999999999978, 270.5, -65.3000000000001, 59.00000000000008, 9.100000000000001, 226.79999999999998, -50.79999999999984, 260.39999999999964, 31.300000000000097, 197.09999999999985, 143.99999999999966, 110.89999999999921, 127.59999999999971, 270.5, 180.49999999999983, -20.39999999999958, -98.29999999999987, 35.80000000000001, -70.79999999999984, 94.19999999999959, 193.9999999999992, 172.4999999999994, 170.00000000000006, 38.300000000000004, 175.99999999999955, -85.1, 159.09999999999965, -18.90000000000051, 157.99999999999957, 171.19999999999945, -10.099999999999685, -53.500000000001044, -104.20000000000073, 170.09999999999926, 116.19999999999982, 196.2999999999994, 31.500000000000142, 161.2, -33.29999999999961, -8.999999999999932, 106.69999999999999, 89.50000000000004, 23.300000000000093, 170.4000000000001, 148.0, 27.40000000000002, -4.3000000000002405, 117.19999999999976, 223.89999999999995, 173.29999999999978, 21.89999999999994, -94.30000000000004, 198.2, 109.39999999999999, 59.30000000000008, 163.2999999999994, 71.00000000000004, 175.59999999999934, 240.20000000000002, -32.0, 167.6999999999995, 310.9999999999998, 260.40000000000003, 306.0999999999998, -315.5, 325.7999999999999, -120.80000000000004, -90.70000000000002, 33.10000000000006, -257.30000000000007, 246.60000000000002, 64.69999999999999, 125.3000000000001, 167.0, -257.8, -208.20000000000016, -211.49999999999997, 289.69999999999993, 49.300000000000004, -69.09999999999997, -73.10000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-85.89999999999986, -216.1000000000001, -373.5999999999997, 187.39999999999992, -17.200000000000003, 56.600000000000065, 179.3, 32.60000000000006, -81.40000000000009, 38.60000000000002, 11.900000000000002, -5.1999999999999265, 24.50000000000021, 121.1, 18.500000000000114, -38.200000000000074, -98.8000000000001, 67.40000000000012, -49.30000000000001, -91.60000000000005, 189.19999999999993, -319.89999999999924, 68.60000000000015, -169.00000000000048, -193.30000000000007, 74.89999999999966, -47.5, -341.10000000000025, -271.00000000000006, -115.00000000000037, 109.69999999999999, -120.40000000000035, -222.70000000000005, -225.7000000000003, 24.50000000000012, -15.700000000000017, -259.5999999999994, -150.69999999999993, -32.500000000000256, -101.50000000000009, 16.69999999999999, 186.79999999999998, -61.89999999999979, -156.40000000000015, 57.50000000000003, -101.50000000000003, -221.50000000000045, 86.5999999999998, 167.89999999999995, -30.099999999999937, -33.09999999999988, -156.69999999999987, 62.60000000000001, 138.79999999999967, -38.19999999999978, -20.50000000000002, 62.90000000000002, 72.19999999999999, 5.299999999999965, 100.7, 62.900000000000084, 20.000000000000014, 140.59999999999974, -121.00000000000037, 60.19999999999999, 137.3, 73.10000000000001, 25.40000000000002, 6.199999999999968, -94.6000000000007, -267.70000000000016, -34.60000000000001, -175.00000000000006, 60.8, 21.800000000000047, -234.60000000000002, -31.0, 27.20000000000015, 54.200000000000195, 102.80000000000001, 51.80000000000001, 49.70000000000019, 22.39999999999978, 68.6, -1.9000000000000834, -50.79999999999994, 71.3000000000001, 64.70000000000002, -126.09999999999997, -130.0, 40.7, 13.399999999999979, -80.80000000000078, -63.10000000000002, 20.000000000000014, 101.0, 23.900000000000098, 101.30000000000001, -14.500000000000483, -97.59999999999994, -59.80000000000062, -78.70000000000087, -183.40000000000015, -125.80000000000058, -8.799999999999985, 122.89999999999986, 125.00000000000001, -122.80000000000075, 90.8, 51.500000000000234, 53.0, -158.50000000000028, 71.6, -33.400000000000006, 9.499999999999964, -143.8000000000002, -166.90000000000055, -18.09999999999998, -13.0, 31.699999999999996, -68.5, 59.00000000000006, -51.09999999999983, -4.599999999999978, 48.5, 41.9000000000001, 41.0, 23.0, 17.599999999999994, -134.20000000000016, -152.2000000000006, 29.900000000000077, 57.20000000000004, 20.000000000000014, 119.29999999999993, 26.599999999999966, -78.69999999999999, 127.99999999999979, -55.300000000000004, -89.80000000000013, -101.80000000000075, -173.50000000000026, 119.0, 12.199999999999994, 62.599999999999994, -77.19999999999999, -130.90000000000015, 63.20000000000003, 141.2, -19.899999999999743, 8.299999999999997, -46.3, 131.59999999999994, 20.000000000000014, 110.9, 68.3, -130.0, -37.0, 156.5, -59.80000000000062, 145.99999999999997, 136.99999999999994, 171.5, 50.900000000000055, 145.1, 134.00000000000006, -346.9, -154.6, 114.80000000000001, 146.0, -154.60000000000014, -89.20000000000003, -304.0, -69.70000000000002, 53.00000000000001, -124.90000000000063, -246.40000000000003, -283.9, 98.00000000000003, 83.59999999999998, -253.0, 70.7, -5.499999999999808, 27.80000000000001, -19.0, 83.0, -173.8, -307.0, -312.70000000000005, -125.50000000000011, -156.39999999999998, -216.09999999999997, 123.2, 129.5, -40.0, -54.7, -126.10000000000005, -184.00000000000006, -87.99999999999997, -144.10000000000005], "policy_predator_policy_reward": [104.0, 102.0, 126.0, 144.0, 38.0, 41.0, 5.0, 42.0, 78.0, 60.0, 46.0, 27.0, 13.0, 15.0, 36.0, 71.0, 93.0, 12.0, 79.0, 77.0, 82.0, 185.0, 55.0, 56.0, 83.0, 105.0, 223.0, 68.0, 29.0, 142.0, 4.0, 87.0, 32.0, 150.0, 28.0, 40.0, 39.0, 162.0, 107.0, 60.0, 26.0, 41.0, 107.0, 46.0, 4.0, 99.0, 27.0, 117.0, 45.0, 44.0, 53.0, 86.0, 25.0, 34.0, 58.0, 32.0, 37.0, 25.0, 11.0, 27.0, 28.0, 0.0, 80.0, 28.0, 38.0, 35.0, 17.0, 65.0, 61.0, 7.0, 134.0, 70.0, 138.0, 12.0, 142.0, 0.0, 65.0, 33.0, 17.0, 20.0, 47.0, 24.0, 36.0, 43.0, 68.0, 23.0, 15.0, 25.0, 42.0, 129.0, 37.0, 68.0, 28.0, 97.0, 25.0, 12.0, 30.0, 16.0, 46.0, 56.0, 39.0, 46.0, 62.0, 143.0, 42.0, 14.0, 62.0, 52.0, 25.0, 29.0, 121.0, 16.0, 47.0, 76.0, 25.0, 76.0, 99.0, 77.0, 20.0, 68.0, 82.0, 17.0, 33.0, 46.0, 61.0, 19.0, 27.0, 57.0, 83.0, 61.0, 32.0, 86.0, 17.0, 23.0, 57.0, 21.0, 36.0, 88.0, 98.0, 69.0, 46.0, 135.0, 4.0, 63.0, 92.0, 32.0, 21.0, 106.0, 12.0, 30.0, 91.0, 18.0, 8.0, 16.0, 44.0, 17.0, 25.0, 110.0, 35.0, 36.0, 13.0, 15.0, 1.0, 37.0, 22.0, 5.0, 182.0, 4.0, 35.0, 30.0, 89.0, 34.0, 123.0, 160.0, 36.0, 69.0, 154.0, 119.0, 36.0, 29.0, 148.0, 99.0, 49.0, 54.0, 78.0, 25.0, 79.0, 144.0, 45.0, 185.0, 22.0, 139.0, 30.0, 7.0, 61.0, 83.0, 121.0, 120.0, 30.0, 129.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9340812249013299, "mean_inference_ms": 2.4772217828941843, "mean_action_processing_ms": 0.3556115826578662, "mean_env_wait_ms": 0.3178873683332462, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013186335563659668, "StateBufferConnector_ms": 0.0037250518798828125, "ViewRequirementAgentConnector_ms": 0.17178380489349365}, "num_episodes": 18, "episode_return_max": 325.7999999999999, "episode_return_min": -315.5, "episode_return_mean": 65.50999999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 337.3097927088422, "num_env_steps_trained_throughput_per_sec": 337.3097927088422, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 13193.508, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13193.46, "sample_time_ms": 1958.022, "learn_time_ms": 11215.857, "learn_throughput": 356.638, "synch_weights_time_ms": 16.653}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "f0d88_00000", "date": "2024-08-14_10-47-40", "timestamp": 1723646860, "time_this_iter_s": 11.897626876831055, "time_total_s": 79.51201605796814, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad49f790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 79.51201605796814, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 46.076470588235296, "ram_util_percent": 83.50588235294119}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9989892140582757, "cur_kl_coeff": 0.675, "cur_lr": 0.0010000000000000005, "total_loss": 8.90640177171697, "policy_loss": -0.01182970278699286, "vf_loss": 8.904984557691705, "vf_explained_var": -0.09857478968050114, "kl": 0.01962503616773871, "entropy": 1.468841251809761, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3513233775815006, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 6.885235907791784, "policy_loss": -0.02559811392794092, "vf_loss": 6.887526195263736, "vf_explained_var": 0.18425051178881732, "kl": 0.02302006768695483, "entropy": 1.505024991401289, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 325.7999999999999, "episode_reward_min": -339.8, "episode_reward_mean": 47.40599999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -388.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.79999999999998, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -38.41700000000005, "predator_policy": 62.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-209.30000000000038, 32.99999999999978, 270.5, -65.3000000000001, 59.00000000000008, 9.100000000000001, 226.79999999999998, -50.79999999999984, 260.39999999999964, 31.300000000000097, 197.09999999999985, 143.99999999999966, 110.89999999999921, 127.59999999999971, 270.5, 180.49999999999983, -20.39999999999958, -98.29999999999987, 35.80000000000001, -70.79999999999984, 94.19999999999959, 193.9999999999992, 172.4999999999994, 170.00000000000006, 38.300000000000004, 175.99999999999955, -85.1, 159.09999999999965, -18.90000000000051, 157.99999999999957, 171.19999999999945, -10.099999999999685, -53.500000000001044, -104.20000000000073, 170.09999999999926, 116.19999999999982, 196.2999999999994, 31.500000000000142, 161.2, -33.29999999999961, -8.999999999999932, 106.69999999999999, 89.50000000000004, 23.300000000000093, 170.4000000000001, 148.0, 27.40000000000002, -4.3000000000002405, 117.19999999999976, 223.89999999999995, 173.29999999999978, 21.89999999999994, -94.30000000000004, 198.2, 109.39999999999999, 59.30000000000008, 163.2999999999994, 71.00000000000004, 175.59999999999934, 240.20000000000002, -32.0, 167.6999999999995, 310.9999999999998, 260.40000000000003, 306.0999999999998, -315.5, 325.7999999999999, -120.80000000000004, -90.70000000000002, 33.10000000000006, -257.30000000000007, 246.60000000000002, 64.69999999999999, 125.3000000000001, 167.0, -257.8, -208.20000000000016, -211.49999999999997, 289.69999999999993, 49.300000000000004, -69.09999999999997, -73.10000000000002, -249.70000000000002, -339.8, 0.60000000000004, -47.3, -95.50000000000001, -129.10000000000005, 51.79999999999984, -39.099999999999866, 88.29999999999993, -161.39999999999998, -284.99999999999994, 169.99999999999932, -134.1000000000001, -253.39999999999998, 153.39999999999947, -46.599999999999795, 240.79999999999927, -50.1000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-259.5999999999994, -150.69999999999993, -32.500000000000256, -101.50000000000009, 16.69999999999999, 186.79999999999998, -61.89999999999979, -156.40000000000015, 57.50000000000003, -101.50000000000003, -221.50000000000045, 86.5999999999998, 167.89999999999995, -30.099999999999937, -33.09999999999988, -156.69999999999987, 62.60000000000001, 138.79999999999967, -38.19999999999978, -20.50000000000002, 62.90000000000002, 72.19999999999999, 5.299999999999965, 100.7, 62.900000000000084, 20.000000000000014, 140.59999999999974, -121.00000000000037, 60.19999999999999, 137.3, 73.10000000000001, 25.40000000000002, 6.199999999999968, -94.6000000000007, -267.70000000000016, -34.60000000000001, -175.00000000000006, 60.8, 21.800000000000047, -234.60000000000002, -31.0, 27.20000000000015, 54.200000000000195, 102.80000000000001, 51.80000000000001, 49.70000000000019, 22.39999999999978, 68.6, -1.9000000000000834, -50.79999999999994, 71.3000000000001, 64.70000000000002, -126.09999999999997, -130.0, 40.7, 13.399999999999979, -80.80000000000078, -63.10000000000002, 20.000000000000014, 101.0, 23.900000000000098, 101.30000000000001, -14.500000000000483, -97.59999999999994, -59.80000000000062, -78.70000000000087, -183.40000000000015, -125.80000000000058, -8.799999999999985, 122.89999999999986, 125.00000000000001, -122.80000000000075, 90.8, 51.500000000000234, 53.0, -158.50000000000028, 71.6, -33.400000000000006, 9.499999999999964, -143.8000000000002, -166.90000000000055, -18.09999999999998, -13.0, 31.699999999999996, -68.5, 59.00000000000006, -51.09999999999983, -4.599999999999978, 48.5, 41.9000000000001, 41.0, 23.0, 17.599999999999994, -134.20000000000016, -152.2000000000006, 29.900000000000077, 57.20000000000004, 20.000000000000014, 119.29999999999993, 26.599999999999966, -78.69999999999999, 127.99999999999979, -55.300000000000004, -89.80000000000013, -101.80000000000075, -173.50000000000026, 119.0, 12.199999999999994, 62.599999999999994, -77.19999999999999, -130.90000000000015, 63.20000000000003, 141.2, -19.899999999999743, 8.299999999999997, -46.3, 131.59999999999994, 20.000000000000014, 110.9, 68.3, -130.0, -37.0, 156.5, -59.80000000000062, 145.99999999999997, 136.99999999999994, 171.5, 50.900000000000055, 145.1, 134.00000000000006, -346.9, -154.6, 114.80000000000001, 146.0, -154.60000000000014, -89.20000000000003, -304.0, -69.70000000000002, 53.00000000000001, -124.90000000000063, -246.40000000000003, -283.9, 98.00000000000003, 83.59999999999998, -253.0, 70.7, -5.499999999999808, 27.80000000000001, -19.0, 83.0, -173.8, -307.0, -312.70000000000005, -125.50000000000011, -156.39999999999998, -216.09999999999997, 123.2, 129.5, -40.0, -54.7, -126.10000000000005, -184.00000000000006, -87.99999999999997, -144.10000000000005, -376.0, -249.70000000000002, -307.9, -310.9, -113.20000000000002, 0.8000000000000398, 14.0, -241.3, -96.70000000000002, -263.8, -244.0, -138.10000000000005, 52.10000000000011, -109.3, -388.0, 11.899999999999967, -77.49999999999986, 93.79999999999997, -72.39999999999999, -259.0, -184.29999999999995, -279.69999999999993, 20.000000000000014, 122.0, -84.4, -234.7000000000002, -268.0, -168.40000000000003, -45.09999999999976, 153.49999999999997, 20.000000000000014, -346.6, 86.59999999999928, 105.19999999999999, -157.9, -110.19999999999999], "policy_predator_policy_reward": [39.0, 162.0, 107.0, 60.0, 26.0, 41.0, 107.0, 46.0, 4.0, 99.0, 27.0, 117.0, 45.0, 44.0, 53.0, 86.0, 25.0, 34.0, 58.0, 32.0, 37.0, 25.0, 11.0, 27.0, 28.0, 0.0, 80.0, 28.0, 38.0, 35.0, 17.0, 65.0, 61.0, 7.0, 134.0, 70.0, 138.0, 12.0, 142.0, 0.0, 65.0, 33.0, 17.0, 20.0, 47.0, 24.0, 36.0, 43.0, 68.0, 23.0, 15.0, 25.0, 42.0, 129.0, 37.0, 68.0, 28.0, 97.0, 25.0, 12.0, 30.0, 16.0, 46.0, 56.0, 39.0, 46.0, 62.0, 143.0, 42.0, 14.0, 62.0, 52.0, 25.0, 29.0, 121.0, 16.0, 47.0, 76.0, 25.0, 76.0, 99.0, 77.0, 20.0, 68.0, 82.0, 17.0, 33.0, 46.0, 61.0, 19.0, 27.0, 57.0, 83.0, 61.0, 32.0, 86.0, 17.0, 23.0, 57.0, 21.0, 36.0, 88.0, 98.0, 69.0, 46.0, 135.0, 4.0, 63.0, 92.0, 32.0, 21.0, 106.0, 12.0, 30.0, 91.0, 18.0, 8.0, 16.0, 44.0, 17.0, 25.0, 110.0, 35.0, 36.0, 13.0, 15.0, 1.0, 37.0, 22.0, 5.0, 182.0, 4.0, 35.0, 30.0, 89.0, 34.0, 123.0, 160.0, 36.0, 69.0, 154.0, 119.0, 36.0, 29.0, 148.0, 99.0, 49.0, 54.0, 78.0, 25.0, 79.0, 144.0, 45.0, 185.0, 22.0, 139.0, 30.0, 7.0, 61.0, 83.0, 121.0, 120.0, 30.0, 129.0, 192.0, 184.0, 145.0, 134.0, 113.0, 0.0, 30.0, 150.0, 114.0, 151.0, 104.0, 149.0, 103.0, 6.0, 167.0, 170.0, 57.0, 15.0, 160.0, 10.0, 9.0, 170.0, 21.0, 7.0, 136.0, 49.0, 170.0, 13.0, 3.0, 42.0, 150.0, 130.0, 28.0, 21.0, 108.0, 110.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9413946721140275, "mean_inference_ms": 2.5059672918034868, "mean_action_processing_ms": 0.3578898264954266, "mean_env_wait_ms": 0.3234201470635709, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014166831970214844, "StateBufferConnector_ms": 0.0036640167236328125, "ViewRequirementAgentConnector_ms": 0.1652306318283081}, "num_episodes": 18, "episode_return_max": 325.7999999999999, "episode_return_min": -339.8, "episode_return_mean": 47.40599999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 335.2326475029636, "num_env_steps_trained_throughput_per_sec": 335.2326475029636, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 13013.296, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13013.247, "sample_time_ms": 1860.034, "learn_time_ms": 11133.841, "learn_throughput": 359.265, "synch_weights_time_ms": 16.277}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "f0d88_00000", "date": "2024-08-14_10-47-52", "timestamp": 1723646872, "time_this_iter_s": 11.97835087776184, "time_total_s": 91.49036693572998, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad48dc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 91.49036693572998, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 46.25882352941177, "ram_util_percent": 83.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9934412158040142, "cur_kl_coeff": 0.675, "cur_lr": 0.0010000000000000005, "total_loss": 8.677343839816945, "policy_loss": -0.013629451328050837, "vf_loss": 8.677505146258722, "vf_explained_var": -0.10163949094121419, "kl": 0.019952786449874273, "entropy": 1.4476837153787967, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0992831882345615, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.384625585495479, "policy_loss": -0.026404836567158186, "vf_loss": 7.38210213121283, "vf_explained_var": 0.29996037152078414, "kl": 0.01904744311277655, "entropy": 1.4707539038683373, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 325.7999999999999, "episode_reward_min": -393.79999999999995, "episode_reward_mean": 20.502999999999883, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 171.5, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -60.04850000000004, "predator_policy": 70.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.80000000000001, -70.79999999999984, 94.19999999999959, 193.9999999999992, 172.4999999999994, 170.00000000000006, 38.300000000000004, 175.99999999999955, -85.1, 159.09999999999965, -18.90000000000051, 157.99999999999957, 171.19999999999945, -10.099999999999685, -53.500000000001044, -104.20000000000073, 170.09999999999926, 116.19999999999982, 196.2999999999994, 31.500000000000142, 161.2, -33.29999999999961, -8.999999999999932, 106.69999999999999, 89.50000000000004, 23.300000000000093, 170.4000000000001, 148.0, 27.40000000000002, -4.3000000000002405, 117.19999999999976, 223.89999999999995, 173.29999999999978, 21.89999999999994, -94.30000000000004, 198.2, 109.39999999999999, 59.30000000000008, 163.2999999999994, 71.00000000000004, 175.59999999999934, 240.20000000000002, -32.0, 167.6999999999995, 310.9999999999998, 260.40000000000003, 306.0999999999998, -315.5, 325.7999999999999, -120.80000000000004, -90.70000000000002, 33.10000000000006, -257.30000000000007, 246.60000000000002, 64.69999999999999, 125.3000000000001, 167.0, -257.8, -208.20000000000016, -211.49999999999997, 289.69999999999993, 49.300000000000004, -69.09999999999997, -73.10000000000002, -249.70000000000002, -339.8, 0.60000000000004, -47.3, -95.50000000000001, -129.10000000000005, 51.79999999999984, -39.099999999999866, 88.29999999999993, -161.39999999999998, -284.99999999999994, 169.99999999999932, -134.1000000000001, -253.39999999999998, 153.39999999999947, -46.599999999999795, 240.79999999999927, -50.1000000000001, -73.40000000000003, 90.49999999999997, -130.1000000000005, 209.00000000000006, -156.70000000000002, -164.3, 67.19999999999993, 33.600000000000065, -97.1, -13.399999999999892, -134.0000000000007, 234.40000000000006, -67.6, -393.79999999999995, -74.7000000000001, -90.5, -94.19999999999999, -358.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.00000000000006, 60.8, 21.800000000000047, -234.60000000000002, -31.0, 27.20000000000015, 54.200000000000195, 102.80000000000001, 51.80000000000001, 49.70000000000019, 22.39999999999978, 68.6, -1.9000000000000834, -50.79999999999994, 71.3000000000001, 64.70000000000002, -126.09999999999997, -130.0, 40.7, 13.399999999999979, -80.80000000000078, -63.10000000000002, 20.000000000000014, 101.0, 23.900000000000098, 101.30000000000001, -14.500000000000483, -97.59999999999994, -59.80000000000062, -78.70000000000087, -183.40000000000015, -125.80000000000058, -8.799999999999985, 122.89999999999986, 125.00000000000001, -122.80000000000075, 90.8, 51.500000000000234, 53.0, -158.50000000000028, 71.6, -33.400000000000006, 9.499999999999964, -143.8000000000002, -166.90000000000055, -18.09999999999998, -13.0, 31.699999999999996, -68.5, 59.00000000000006, -51.09999999999983, -4.599999999999978, 48.5, 41.9000000000001, 41.0, 23.0, 17.599999999999994, -134.20000000000016, -152.2000000000006, 29.900000000000077, 57.20000000000004, 20.000000000000014, 119.29999999999993, 26.599999999999966, -78.69999999999999, 127.99999999999979, -55.300000000000004, -89.80000000000013, -101.80000000000075, -173.50000000000026, 119.0, 12.199999999999994, 62.599999999999994, -77.19999999999999, -130.90000000000015, 63.20000000000003, 141.2, -19.899999999999743, 8.299999999999997, -46.3, 131.59999999999994, 20.000000000000014, 110.9, 68.3, -130.0, -37.0, 156.5, -59.80000000000062, 145.99999999999997, 136.99999999999994, 171.5, 50.900000000000055, 145.1, 134.00000000000006, -346.9, -154.6, 114.80000000000001, 146.0, -154.60000000000014, -89.20000000000003, -304.0, -69.70000000000002, 53.00000000000001, -124.90000000000063, -246.40000000000003, -283.9, 98.00000000000003, 83.59999999999998, -253.0, 70.7, -5.499999999999808, 27.80000000000001, -19.0, 83.0, -173.8, -307.0, -312.70000000000005, -125.50000000000011, -156.39999999999998, -216.09999999999997, 123.2, 129.5, -40.0, -54.7, -126.10000000000005, -184.00000000000006, -87.99999999999997, -144.10000000000005, -376.0, -249.70000000000002, -307.9, -310.9, -113.20000000000002, 0.8000000000000398, 14.0, -241.3, -96.70000000000002, -263.8, -244.0, -138.10000000000005, 52.10000000000011, -109.3, -388.0, 11.899999999999967, -77.49999999999986, 93.79999999999997, -72.39999999999999, -259.0, -184.29999999999995, -279.69999999999993, 20.000000000000014, 122.0, -84.4, -234.7000000000002, -268.0, -168.40000000000003, -45.09999999999976, 153.49999999999997, 20.000000000000014, -346.6, 86.59999999999928, 105.19999999999999, -157.9, -110.19999999999999, -236.50000000000003, -70.9, -10.599999999999994, 4.099999999999994, -139.0000000000005, -270.1, 150.5, -23.5, -175.6, -189.10000000000002, -244.30000000000004, -223.0, -109.89999999999989, 28.099999999999994, -103.0, 14.600000000000115, -110.8, -223.30000000000004, -24.09999999999981, -142.3, -64.30000000000072, -216.7, 121.70000000000002, 67.7000000000001, -96.69999999999999, -127.9, -317.79999999999995, -385.0, -316.6, -24.099999999999888, -64.6, -169.9, -186.4000000000001, -164.80000000000007, -397.0, -283.6], "policy_predator_policy_reward": [138.0, 12.0, 142.0, 0.0, 65.0, 33.0, 17.0, 20.0, 47.0, 24.0, 36.0, 43.0, 68.0, 23.0, 15.0, 25.0, 42.0, 129.0, 37.0, 68.0, 28.0, 97.0, 25.0, 12.0, 30.0, 16.0, 46.0, 56.0, 39.0, 46.0, 62.0, 143.0, 42.0, 14.0, 62.0, 52.0, 25.0, 29.0, 121.0, 16.0, 47.0, 76.0, 25.0, 76.0, 99.0, 77.0, 20.0, 68.0, 82.0, 17.0, 33.0, 46.0, 61.0, 19.0, 27.0, 57.0, 83.0, 61.0, 32.0, 86.0, 17.0, 23.0, 57.0, 21.0, 36.0, 88.0, 98.0, 69.0, 46.0, 135.0, 4.0, 63.0, 92.0, 32.0, 21.0, 106.0, 12.0, 30.0, 91.0, 18.0, 8.0, 16.0, 44.0, 17.0, 25.0, 110.0, 35.0, 36.0, 13.0, 15.0, 1.0, 37.0, 22.0, 5.0, 182.0, 4.0, 35.0, 30.0, 89.0, 34.0, 123.0, 160.0, 36.0, 69.0, 154.0, 119.0, 36.0, 29.0, 148.0, 99.0, 49.0, 54.0, 78.0, 25.0, 79.0, 144.0, 45.0, 185.0, 22.0, 139.0, 30.0, 7.0, 61.0, 83.0, 121.0, 120.0, 30.0, 129.0, 192.0, 184.0, 145.0, 134.0, 113.0, 0.0, 30.0, 150.0, 114.0, 151.0, 104.0, 149.0, 103.0, 6.0, 167.0, 170.0, 57.0, 15.0, 160.0, 10.0, 9.0, 170.0, 21.0, 7.0, 136.0, 49.0, 170.0, 13.0, 3.0, 42.0, 150.0, 130.0, 28.0, 21.0, 108.0, 110.0, 109.0, 125.0, 9.0, 88.0, 163.0, 116.0, 31.0, 51.0, 145.0, 63.0, 174.0, 129.0, 78.0, 71.0, 21.0, 101.0, 120.0, 117.0, 122.0, 31.0, 142.0, 5.0, 24.0, 21.0, 147.0, 10.0, 114.0, 195.0, 140.0, 126.0, 137.0, 7.0, 159.0, 98.0, 145.0, 177.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9512959035593067, "mean_inference_ms": 2.534352235216898, "mean_action_processing_ms": 0.3609133222279061, "mean_env_wait_ms": 0.32880345264454663, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014737844467163086, "StateBufferConnector_ms": 0.003523707389831543, "ViewRequirementAgentConnector_ms": 0.15621888637542725}, "num_episodes": 18, "episode_return_max": 325.7999999999999, "episode_return_min": -393.79999999999995, "episode_return_mean": 20.502999999999883, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.7781200122903, "num_env_steps_trained_throughput_per_sec": 334.7781200122903, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 12880.161, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12880.113, "sample_time_ms": 1777.922, "learn_time_ms": 11083.378, "learn_throughput": 360.901, "synch_weights_time_ms": 15.837}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "f0d88_00000", "date": "2024-08-14_10-48-04", "timestamp": 1723646884, "time_this_iter_s": 11.994500875473022, "time_total_s": 103.484867811203, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0a9280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 103.484867811203, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 45.0, "ram_util_percent": 83.44117647058823}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7760491885520793, "cur_kl_coeff": 0.675, "cur_lr": 0.0010000000000000005, "total_loss": 7.14554476157698, "policy_loss": -0.0181459529017389, "vf_loss": 7.149534794640919, "vf_explained_var": -0.07482906125840687, "kl": 0.020971752861776854, "entropy": 1.4474526376951309, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5304411552570483, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 8.564341152281989, "policy_loss": -0.025549335613299813, "vf_loss": 8.561363003998206, "vf_explained_var": 0.056927933484788924, "kl": 0.018783515093544555, "entropy": 1.4248213809634012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 325.7999999999999, "episode_reward_min": -393.79999999999995, "episode_reward_mean": -15.229000000000074, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 171.5, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -91.61950000000004, "predator_policy": 84.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.999999999999932, 106.69999999999999, 89.50000000000004, 23.300000000000093, 170.4000000000001, 148.0, 27.40000000000002, -4.3000000000002405, 117.19999999999976, 223.89999999999995, 173.29999999999978, 21.89999999999994, -94.30000000000004, 198.2, 109.39999999999999, 59.30000000000008, 163.2999999999994, 71.00000000000004, 175.59999999999934, 240.20000000000002, -32.0, 167.6999999999995, 310.9999999999998, 260.40000000000003, 306.0999999999998, -315.5, 325.7999999999999, -120.80000000000004, -90.70000000000002, 33.10000000000006, -257.30000000000007, 246.60000000000002, 64.69999999999999, 125.3000000000001, 167.0, -257.8, -208.20000000000016, -211.49999999999997, 289.69999999999993, 49.300000000000004, -69.09999999999997, -73.10000000000002, -249.70000000000002, -339.8, 0.60000000000004, -47.3, -95.50000000000001, -129.10000000000005, 51.79999999999984, -39.099999999999866, 88.29999999999993, -161.39999999999998, -284.99999999999994, 169.99999999999932, -134.1000000000001, -253.39999999999998, 153.39999999999947, -46.599999999999795, 240.79999999999927, -50.1000000000001, -73.40000000000003, 90.49999999999997, -130.1000000000005, 209.00000000000006, -156.70000000000002, -164.3, 67.19999999999993, 33.600000000000065, -97.1, -13.399999999999892, -134.0000000000007, 234.40000000000006, -67.6, -393.79999999999995, -74.7000000000001, -90.5, -94.19999999999999, -358.6, -136.0, -145.70000000000002, 17.99999999999996, -292.7000000000001, -291.5, -96.10000000000088, -263.1, -202.6, 271.0000000000003, 220.69999999999928, 51.20000000000018, 6.200000000000023, -39.899999999999785, 33.500000000000206, 132.59999999999968, -152.5, -146.89999999999986, 6.700000000000291, -239.80000000000004, -219.70000000000007, -134.30000000000084, -283.80000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-166.90000000000055, -18.09999999999998, -13.0, 31.699999999999996, -68.5, 59.00000000000006, -51.09999999999983, -4.599999999999978, 48.5, 41.9000000000001, 41.0, 23.0, 17.599999999999994, -134.20000000000016, -152.2000000000006, 29.900000000000077, 57.20000000000004, 20.000000000000014, 119.29999999999993, 26.599999999999966, -78.69999999999999, 127.99999999999979, -55.300000000000004, -89.80000000000013, -101.80000000000075, -173.50000000000026, 119.0, 12.199999999999994, 62.599999999999994, -77.19999999999999, -130.90000000000015, 63.20000000000003, 141.2, -19.899999999999743, 8.299999999999997, -46.3, 131.59999999999994, 20.000000000000014, 110.9, 68.3, -130.0, -37.0, 156.5, -59.80000000000062, 145.99999999999997, 136.99999999999994, 171.5, 50.900000000000055, 145.1, 134.00000000000006, -346.9, -154.6, 114.80000000000001, 146.0, -154.60000000000014, -89.20000000000003, -304.0, -69.70000000000002, 53.00000000000001, -124.90000000000063, -246.40000000000003, -283.9, 98.00000000000003, 83.59999999999998, -253.0, 70.7, -5.499999999999808, 27.80000000000001, -19.0, 83.0, -173.8, -307.0, -312.70000000000005, -125.50000000000011, -156.39999999999998, -216.09999999999997, 123.2, 129.5, -40.0, -54.7, -126.10000000000005, -184.00000000000006, -87.99999999999997, -144.10000000000005, -376.0, -249.70000000000002, -307.9, -310.9, -113.20000000000002, 0.8000000000000398, 14.0, -241.3, -96.70000000000002, -263.8, -244.0, -138.10000000000005, 52.10000000000011, -109.3, -388.0, 11.899999999999967, -77.49999999999986, 93.79999999999997, -72.39999999999999, -259.0, -184.29999999999995, -279.69999999999993, 20.000000000000014, 122.0, -84.4, -234.7000000000002, -268.0, -168.40000000000003, -45.09999999999976, 153.49999999999997, 20.000000000000014, -346.6, 86.59999999999928, 105.19999999999999, -157.9, -110.19999999999999, -236.50000000000003, -70.9, -10.599999999999994, 4.099999999999994, -139.0000000000005, -270.1, 150.5, -23.5, -175.6, -189.10000000000002, -244.30000000000004, -223.0, -109.89999999999989, 28.099999999999994, -103.0, 14.600000000000115, -110.8, -223.30000000000004, -24.09999999999981, -142.3, -64.30000000000072, -216.7, 121.70000000000002, 67.7000000000001, -96.69999999999999, -127.9, -317.79999999999995, -385.0, -316.6, -24.099999999999888, -64.6, -169.9, -186.4000000000001, -164.80000000000007, -397.0, -283.6, -118.60000000000038, -210.4, -367.0, -126.70000000000002, -21.999999999999744, 20.000000000000014, -320.80000000000007, -253.89999999999998, -182.5, -316.0, -74.50000000000087, -334.6, -304.0, -225.1, -400.0, -166.6, 85.99999999999994, 146.0, 95.59999999999934, 70.10000000000002, -147.69999999999996, 17.899999999999988, -11.499999999999819, -202.30000000000024, 5.299999999999965, -362.2, -32.49999999999975, 20.000000000000014, -39.09999999999988, 103.69999999999962, -391.0, -89.50000000000003, -341.2, -66.69999999999999, -61.90000000000035, -30.39999999999975, -281.80000000000007, -328.0, -252.99999999999986, -240.7, -91.30000000000084, -337.0, -329.80000000000007, -319.0], "policy_predator_policy_reward": [99.0, 77.0, 20.0, 68.0, 82.0, 17.0, 33.0, 46.0, 61.0, 19.0, 27.0, 57.0, 83.0, 61.0, 32.0, 86.0, 17.0, 23.0, 57.0, 21.0, 36.0, 88.0, 98.0, 69.0, 46.0, 135.0, 4.0, 63.0, 92.0, 32.0, 21.0, 106.0, 12.0, 30.0, 91.0, 18.0, 8.0, 16.0, 44.0, 17.0, 25.0, 110.0, 35.0, 36.0, 13.0, 15.0, 1.0, 37.0, 22.0, 5.0, 182.0, 4.0, 35.0, 30.0, 89.0, 34.0, 123.0, 160.0, 36.0, 69.0, 154.0, 119.0, 36.0, 29.0, 148.0, 99.0, 49.0, 54.0, 78.0, 25.0, 79.0, 144.0, 45.0, 185.0, 22.0, 139.0, 30.0, 7.0, 61.0, 83.0, 121.0, 120.0, 30.0, 129.0, 192.0, 184.0, 145.0, 134.0, 113.0, 0.0, 30.0, 150.0, 114.0, 151.0, 104.0, 149.0, 103.0, 6.0, 167.0, 170.0, 57.0, 15.0, 160.0, 10.0, 9.0, 170.0, 21.0, 7.0, 136.0, 49.0, 170.0, 13.0, 3.0, 42.0, 150.0, 130.0, 28.0, 21.0, 108.0, 110.0, 109.0, 125.0, 9.0, 88.0, 163.0, 116.0, 31.0, 51.0, 145.0, 63.0, 174.0, 129.0, 78.0, 71.0, 21.0, 101.0, 120.0, 117.0, 122.0, 31.0, 142.0, 5.0, 24.0, 21.0, 147.0, 10.0, 114.0, 195.0, 140.0, 126.0, 137.0, 7.0, 159.0, 98.0, 145.0, 177.0, 137.0, 56.0, 191.0, 157.0, 0.0, 20.0, 166.0, 116.0, 15.0, 192.0, 180.0, 133.0, 107.0, 159.0, 164.0, 200.0, 14.0, 25.0, 36.0, 19.0, 85.0, 96.0, 107.0, 113.0, 172.0, 145.0, 25.0, 21.0, 21.0, 47.0, 191.0, 137.0, 135.0, 126.0, 73.0, 26.0, 181.0, 189.0, 157.0, 117.0, 158.0, 136.0, 183.0, 182.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9077897985030761, "mean_inference_ms": 2.404236510697408, "mean_action_processing_ms": 0.3459129902390002, "mean_env_wait_ms": 0.31280715510931845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011035442352294922, "StateBufferConnector_ms": 0.0033522844314575195, "ViewRequirementAgentConnector_ms": 0.1064763069152832}, "num_episodes": 22, "episode_return_max": 325.7999999999999, "episode_return_min": -393.79999999999995, "episode_return_mean": -15.229000000000074, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 328.9153727345233, "num_env_steps_trained_throughput_per_sec": 328.9153727345233, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 12800.275, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12800.227, "sample_time_ms": 1714.312, "learn_time_ms": 11067.274, "learn_throughput": 361.426, "synch_weights_time_ms": 15.82}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "f0d88_00000", "date": "2024-08-14_10-48-16", "timestamp": 1723646896, "time_this_iter_s": 12.1905198097229, "time_total_s": 115.6753876209259, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3abfe1d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 115.6753876209259, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 44.85, "ram_util_percent": 83.61666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9973219306696028, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 8.010814940740191, "policy_loss": -0.01727795973432462, "vf_loss": 8.010380516355, "vf_explained_var": 0.004500723232037176, "kl": 0.01749369833631153, "entropy": 1.4480099406822649, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4913245224763476, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 8.391787886745716, "policy_loss": -0.023963643855750363, "vf_loss": 8.388480929722862, "vf_explained_var": 0.20106076203956805, "kl": 0.017955945094456128, "entropy": 1.4078028506702847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 325.7999999999999, "episode_reward_min": -408.7, "episode_reward_mean": -64.21500000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 171.5, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -130.00750000000002, "predator_policy": 97.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [260.40000000000003, 306.0999999999998, -315.5, 325.7999999999999, -120.80000000000004, -90.70000000000002, 33.10000000000006, -257.30000000000007, 246.60000000000002, 64.69999999999999, 125.3000000000001, 167.0, -257.8, -208.20000000000016, -211.49999999999997, 289.69999999999993, 49.300000000000004, -69.09999999999997, -73.10000000000002, -249.70000000000002, -339.8, 0.60000000000004, -47.3, -95.50000000000001, -129.10000000000005, 51.79999999999984, -39.099999999999866, 88.29999999999993, -161.39999999999998, -284.99999999999994, 169.99999999999932, -134.1000000000001, -253.39999999999998, 153.39999999999947, -46.599999999999795, 240.79999999999927, -50.1000000000001, -73.40000000000003, 90.49999999999997, -130.1000000000005, 209.00000000000006, -156.70000000000002, -164.3, 67.19999999999993, 33.600000000000065, -97.1, -13.399999999999892, -134.0000000000007, 234.40000000000006, -67.6, -393.79999999999995, -74.7000000000001, -90.5, -94.19999999999999, -358.6, -136.0, -145.70000000000002, 17.99999999999996, -292.7000000000001, -291.5, -96.10000000000088, -263.1, -202.6, 271.0000000000003, 220.69999999999928, 51.20000000000018, 6.200000000000023, -39.899999999999785, 33.500000000000206, 132.59999999999968, -152.5, -146.89999999999986, 6.700000000000291, -239.80000000000004, -219.70000000000007, -134.30000000000084, -283.80000000000007, -282.9999999999991, 43.20000000000024, 8.99999999999995, -7.299999999999649, 74.59999999999991, -222.30000000000032, -38.49999999999994, 99.29999999999995, -408.7, -84.00000000000013, -355.0, -230.80000000000004, 170.49999999999994, -366.39999999999986, -306.2, -285.0999999999995, 55.00000000000017, 5.100000000000053, -182.7000000000001, -300.3999999999994, 42.40000000000005, 26.200000000000237, 104.19999999999936], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [171.5, 50.900000000000055, 145.1, 134.00000000000006, -346.9, -154.6, 114.80000000000001, 146.0, -154.60000000000014, -89.20000000000003, -304.0, -69.70000000000002, 53.00000000000001, -124.90000000000063, -246.40000000000003, -283.9, 98.00000000000003, 83.59999999999998, -253.0, 70.7, -5.499999999999808, 27.80000000000001, -19.0, 83.0, -173.8, -307.0, -312.70000000000005, -125.50000000000011, -156.39999999999998, -216.09999999999997, 123.2, 129.5, -40.0, -54.7, -126.10000000000005, -184.00000000000006, -87.99999999999997, -144.10000000000005, -376.0, -249.70000000000002, -307.9, -310.9, -113.20000000000002, 0.8000000000000398, 14.0, -241.3, -96.70000000000002, -263.8, -244.0, -138.10000000000005, 52.10000000000011, -109.3, -388.0, 11.899999999999967, -77.49999999999986, 93.79999999999997, -72.39999999999999, -259.0, -184.29999999999995, -279.69999999999993, 20.000000000000014, 122.0, -84.4, -234.7000000000002, -268.0, -168.40000000000003, -45.09999999999976, 153.49999999999997, 20.000000000000014, -346.6, 86.59999999999928, 105.19999999999999, -157.9, -110.19999999999999, -236.50000000000003, -70.9, -10.599999999999994, 4.099999999999994, -139.0000000000005, -270.1, 150.5, -23.5, -175.6, -189.10000000000002, -244.30000000000004, -223.0, -109.89999999999989, 28.099999999999994, -103.0, 14.600000000000115, -110.8, -223.30000000000004, -24.09999999999981, -142.3, -64.30000000000072, -216.7, 121.70000000000002, 67.7000000000001, -96.69999999999999, -127.9, -317.79999999999995, -385.0, -316.6, -24.099999999999888, -64.6, -169.9, -186.4000000000001, -164.80000000000007, -397.0, -283.6, -118.60000000000038, -210.4, -367.0, -126.70000000000002, -21.999999999999744, 20.000000000000014, -320.80000000000007, -253.89999999999998, -182.5, -316.0, -74.50000000000087, -334.6, -304.0, -225.1, -400.0, -166.6, 85.99999999999994, 146.0, 95.59999999999934, 70.10000000000002, -147.69999999999996, 17.899999999999988, -11.499999999999819, -202.30000000000024, 5.299999999999965, -362.2, -32.49999999999975, 20.000000000000014, -39.09999999999988, 103.69999999999962, -391.0, -89.50000000000003, -341.2, -66.69999999999999, -61.90000000000035, -30.39999999999975, -281.80000000000007, -328.0, -252.99999999999986, -240.7, -91.30000000000084, -337.0, -329.80000000000007, -319.0, -292.3, -297.69999999999914, -225.7, 17.899999999999988, -150.69999999999993, -76.29999999999998, -28.29999999999975, -21.999999999999744, -51.39999999999988, 32.0, -297.10000000000014, -281.2, -21.39999999999987, -162.1, 17.300000000000004, -88.0, -328.0, -279.7, -70.30000000000003, -141.7, -331.0, -313.0, -224.80000000000004, -313.0, 56.0, 45.49999999999996, -373.0, -309.39999999999986, -341.2, -325.0, -233.20000000000013, -316.9, 35.29999999999998, 13.699999999999964, -175.9, 20.000000000000014, -280.0, -261.7000000000001, -385.9, -287.49999999999943, -79.60000000000065, 20.000000000000014, -240.7, -3.099999999999958, -169.0, 54.20000000000017], "policy_predator_policy_reward": [1.0, 37.0, 22.0, 5.0, 182.0, 4.0, 35.0, 30.0, 89.0, 34.0, 123.0, 160.0, 36.0, 69.0, 154.0, 119.0, 36.0, 29.0, 148.0, 99.0, 49.0, 54.0, 78.0, 25.0, 79.0, 144.0, 45.0, 185.0, 22.0, 139.0, 30.0, 7.0, 61.0, 83.0, 121.0, 120.0, 30.0, 129.0, 192.0, 184.0, 145.0, 134.0, 113.0, 0.0, 30.0, 150.0, 114.0, 151.0, 104.0, 149.0, 103.0, 6.0, 167.0, 170.0, 57.0, 15.0, 160.0, 10.0, 9.0, 170.0, 21.0, 7.0, 136.0, 49.0, 170.0, 13.0, 3.0, 42.0, 150.0, 130.0, 28.0, 21.0, 108.0, 110.0, 109.0, 125.0, 9.0, 88.0, 163.0, 116.0, 31.0, 51.0, 145.0, 63.0, 174.0, 129.0, 78.0, 71.0, 21.0, 101.0, 120.0, 117.0, 122.0, 31.0, 142.0, 5.0, 24.0, 21.0, 147.0, 10.0, 114.0, 195.0, 140.0, 126.0, 137.0, 7.0, 159.0, 98.0, 145.0, 177.0, 137.0, 56.0, 191.0, 157.0, 0.0, 20.0, 166.0, 116.0, 15.0, 192.0, 180.0, 133.0, 107.0, 159.0, 164.0, 200.0, 14.0, 25.0, 36.0, 19.0, 85.0, 96.0, 107.0, 113.0, 172.0, 145.0, 25.0, 21.0, 21.0, 47.0, 191.0, 137.0, 135.0, 126.0, 73.0, 26.0, 181.0, 189.0, 157.0, 117.0, 158.0, 136.0, 183.0, 182.0, 190.0, 117.0, 132.0, 119.0, 92.0, 144.0, 17.0, 26.0, 48.0, 46.0, 192.0, 164.0, 134.0, 11.0, 92.0, 78.0, 6.0, 193.0, 15.0, 113.0, 96.0, 193.0, 171.0, 136.0, 14.0, 55.0, 194.0, 122.0, 175.0, 185.0, 85.0, 180.0, 3.0, 3.0, 67.0, 94.0, 172.0, 187.0, 198.0, 175.0, 57.0, 45.0, 146.0, 124.0, 111.0, 108.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8604046554959964, "mean_inference_ms": 2.272120046490041, "mean_action_processing_ms": 0.3297985869644196, "mean_env_wait_ms": 0.2964278178221613, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008226871490478516, "StateBufferConnector_ms": 0.003274679183959961, "ViewRequirementAgentConnector_ms": 0.10129213333129883}, "num_episodes": 23, "episode_return_max": 325.7999999999999, "episode_return_min": -408.7, "episode_return_mean": -64.21500000000006, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.19834285810583, "num_env_steps_trained_throughput_per_sec": 334.19834285810583, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 12717.143, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12717.094, "sample_time_ms": 1664.58, "learn_time_ms": 11034.349, "learn_throughput": 362.504, "synch_weights_time_ms": 15.492}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "f0d88_00000", "date": "2024-08-14_10-48-28", "timestamp": 1723646908, "time_this_iter_s": 11.99936294555664, "time_total_s": 127.67475056648254, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e2310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 127.67475056648254, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 43.95882352941177, "ram_util_percent": 83.33529411764707}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.113772649361343, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 8.07811505176403, "policy_loss": -0.020984117798359386, "vf_loss": 8.08227956509464, "vf_explained_var": 0.007589129733030127, "kl": 0.016611971716093195, "entropy": 1.4349611115203333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6435378188178653, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 8.536325237738392, "policy_loss": -0.019454027420382887, "vf_loss": 8.526308717677201, "vf_explained_var": 0.17876192110556144, "kl": 0.019404466477432405, "entropy": 1.4112544152471753, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 271.0000000000003, "episode_reward_min": -434.2, "episode_reward_mean": -92.17300000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 153.49999999999997, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -152.2615, "predator_policy": 106.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-73.10000000000002, -249.70000000000002, -339.8, 0.60000000000004, -47.3, -95.50000000000001, -129.10000000000005, 51.79999999999984, -39.099999999999866, 88.29999999999993, -161.39999999999998, -284.99999999999994, 169.99999999999932, -134.1000000000001, -253.39999999999998, 153.39999999999947, -46.599999999999795, 240.79999999999927, -50.1000000000001, -73.40000000000003, 90.49999999999997, -130.1000000000005, 209.00000000000006, -156.70000000000002, -164.3, 67.19999999999993, 33.600000000000065, -97.1, -13.399999999999892, -134.0000000000007, 234.40000000000006, -67.6, -393.79999999999995, -74.7000000000001, -90.5, -94.19999999999999, -358.6, -136.0, -145.70000000000002, 17.99999999999996, -292.7000000000001, -291.5, -96.10000000000088, -263.1, -202.6, 271.0000000000003, 220.69999999999928, 51.20000000000018, 6.200000000000023, -39.899999999999785, 33.500000000000206, 132.59999999999968, -152.5, -146.89999999999986, 6.700000000000291, -239.80000000000004, -219.70000000000007, -134.30000000000084, -283.80000000000007, -282.9999999999991, 43.20000000000024, 8.99999999999995, -7.299999999999649, 74.59999999999991, -222.30000000000032, -38.49999999999994, 99.29999999999995, -408.7, -84.00000000000013, -355.0, -230.80000000000004, 170.49999999999994, -366.39999999999986, -306.2, -285.0999999999995, 55.00000000000017, 5.100000000000053, -182.7000000000001, -300.3999999999994, 42.40000000000005, 26.200000000000237, 104.19999999999936, -434.2, 121.19999999999929, 39.00000000000026, 141.09999999999997, -51.59999999999987, -375.29999999999984, -144.0000000000006, -1.3999999999999315, -48.799999999999926, -109.80000000000001, -433.8999999999994, -22.29999999999974, -196.90000000000023, -294.20000000000005, -162.10000000000022, -274.59999999999945, 29.50000000000003, -240.39999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-87.99999999999997, -144.10000000000005, -376.0, -249.70000000000002, -307.9, -310.9, -113.20000000000002, 0.8000000000000398, 14.0, -241.3, -96.70000000000002, -263.8, -244.0, -138.10000000000005, 52.10000000000011, -109.3, -388.0, 11.899999999999967, -77.49999999999986, 93.79999999999997, -72.39999999999999, -259.0, -184.29999999999995, -279.69999999999993, 20.000000000000014, 122.0, -84.4, -234.7000000000002, -268.0, -168.40000000000003, -45.09999999999976, 153.49999999999997, 20.000000000000014, -346.6, 86.59999999999928, 105.19999999999999, -157.9, -110.19999999999999, -236.50000000000003, -70.9, -10.599999999999994, 4.099999999999994, -139.0000000000005, -270.1, 150.5, -23.5, -175.6, -189.10000000000002, -244.30000000000004, -223.0, -109.89999999999989, 28.099999999999994, -103.0, 14.600000000000115, -110.8, -223.30000000000004, -24.09999999999981, -142.3, -64.30000000000072, -216.7, 121.70000000000002, 67.7000000000001, -96.69999999999999, -127.9, -317.79999999999995, -385.0, -316.6, -24.099999999999888, -64.6, -169.9, -186.4000000000001, -164.80000000000007, -397.0, -283.6, -118.60000000000038, -210.4, -367.0, -126.70000000000002, -21.999999999999744, 20.000000000000014, -320.80000000000007, -253.89999999999998, -182.5, -316.0, -74.50000000000087, -334.6, -304.0, -225.1, -400.0, -166.6, 85.99999999999994, 146.0, 95.59999999999934, 70.10000000000002, -147.69999999999996, 17.899999999999988, -11.499999999999819, -202.30000000000024, 5.299999999999965, -362.2, -32.49999999999975, 20.000000000000014, -39.09999999999988, 103.69999999999962, -391.0, -89.50000000000003, -341.2, -66.69999999999999, -61.90000000000035, -30.39999999999975, -281.80000000000007, -328.0, -252.99999999999986, -240.7, -91.30000000000084, -337.0, -329.80000000000007, -319.0, -292.3, -297.69999999999914, -225.7, 17.899999999999988, -150.69999999999993, -76.29999999999998, -28.29999999999975, -21.999999999999744, -51.39999999999988, 32.0, -297.10000000000014, -281.2, -21.39999999999987, -162.1, 17.300000000000004, -88.0, -328.0, -279.7, -70.30000000000003, -141.7, -331.0, -313.0, -224.80000000000004, -313.0, 56.0, 45.49999999999996, -373.0, -309.39999999999986, -341.2, -325.0, -233.20000000000013, -316.9, 35.29999999999998, 13.699999999999964, -175.9, 20.000000000000014, -280.0, -261.7000000000001, -385.9, -287.49999999999943, -79.60000000000065, 20.000000000000014, -240.7, -3.099999999999958, -169.0, 54.20000000000017, -391.6, -355.6000000000001, 20.000000000000014, 72.19999999999976, -55.30000000000001, -15.699999999999747, -22.30000000000001, 49.39999999999998, -195.7, -163.9000000000005, -331.0, -274.29999999999984, -312.99999999999994, -160.00000000000057, 31.70000000000022, -126.10000000000068, -42.99999999999992, -263.8, -122.4999999999999, -313.3, -353.7999999999997, -294.0999999999997, 3.1999999999999704, -326.5, -202.00000000000026, -166.9, -355.9, -208.29999999999998, -169.6000000000002, -299.4999999999999, -284.19999999999936, -312.4000000000001, -43.00000000000007, -263.5, -219.4, -298.0], "policy_predator_policy_reward": [30.0, 129.0, 192.0, 184.0, 145.0, 134.0, 113.0, 0.0, 30.0, 150.0, 114.0, 151.0, 104.0, 149.0, 103.0, 6.0, 167.0, 170.0, 57.0, 15.0, 160.0, 10.0, 9.0, 170.0, 21.0, 7.0, 136.0, 49.0, 170.0, 13.0, 3.0, 42.0, 150.0, 130.0, 28.0, 21.0, 108.0, 110.0, 109.0, 125.0, 9.0, 88.0, 163.0, 116.0, 31.0, 51.0, 145.0, 63.0, 174.0, 129.0, 78.0, 71.0, 21.0, 101.0, 120.0, 117.0, 122.0, 31.0, 142.0, 5.0, 24.0, 21.0, 147.0, 10.0, 114.0, 195.0, 140.0, 126.0, 137.0, 7.0, 159.0, 98.0, 145.0, 177.0, 137.0, 56.0, 191.0, 157.0, 0.0, 20.0, 166.0, 116.0, 15.0, 192.0, 180.0, 133.0, 107.0, 159.0, 164.0, 200.0, 14.0, 25.0, 36.0, 19.0, 85.0, 96.0, 107.0, 113.0, 172.0, 145.0, 25.0, 21.0, 21.0, 47.0, 191.0, 137.0, 135.0, 126.0, 73.0, 26.0, 181.0, 189.0, 157.0, 117.0, 158.0, 136.0, 183.0, 182.0, 190.0, 117.0, 132.0, 119.0, 92.0, 144.0, 17.0, 26.0, 48.0, 46.0, 192.0, 164.0, 134.0, 11.0, 92.0, 78.0, 6.0, 193.0, 15.0, 113.0, 96.0, 193.0, 171.0, 136.0, 14.0, 55.0, 194.0, 122.0, 175.0, 185.0, 85.0, 180.0, 3.0, 3.0, 67.0, 94.0, 172.0, 187.0, 198.0, 175.0, 57.0, 45.0, 146.0, 124.0, 111.0, 108.0, 113.0, 200.0, 16.0, 13.0, 74.0, 36.0, 36.0, 78.0, 133.0, 175.0, 39.0, 191.0, 176.0, 153.0, 33.0, 60.0, 117.0, 141.0, 167.0, 159.0, 24.0, 190.0, 139.0, 162.0, 170.0, 2.0, 159.0, 111.0, 174.0, 133.0, 186.0, 136.0, 170.0, 166.0, 184.0, 93.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.831056934638865, "mean_inference_ms": 2.1896425907471517, "mean_action_processing_ms": 0.3197853781475694, "mean_env_wait_ms": 0.2860269095742681, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008210301399230957, "StateBufferConnector_ms": 0.003279566764831543, "ViewRequirementAgentConnector_ms": 0.10106396675109863}, "num_episodes": 18, "episode_return_max": 271.0000000000003, "episode_return_min": -434.2, "episode_return_mean": -92.17300000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.9936217290979, "num_env_steps_trained_throughput_per_sec": 336.9936217290979, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 12654.121, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12654.074, "sample_time_ms": 1575.58, "learn_time_ms": 11061.14, "learn_throughput": 361.626, "synch_weights_time_ms": 15.076}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "f0d88_00000", "date": "2024-08-14_10-48-40", "timestamp": 1723646920, "time_this_iter_s": 11.894727945327759, "time_total_s": 139.5694785118103, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0bc9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 139.5694785118103, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 44.152941176470584, "ram_util_percent": 83.34705882352942}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0792183162358704, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 7.687465004946189, "policy_loss": -0.023982288648261043, "vf_loss": 7.693296374971904, "vf_explained_var": 0.07710224232345662, "kl": 0.017926842078018968, "entropy": 1.4464146089301537, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.31434498123391, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 8.828100626809256, "policy_loss": -0.02576835335801459, "vf_loss": 8.828287167523904, "vf_explained_var": 0.11531389412425813, "kl": 0.0168440024128351, "entropy": 1.3817297172294092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 271.0000000000003, "episode_reward_min": -434.2, "episode_reward_mean": -92.69700000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.5, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -160.5235, "predator_policy": 114.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.1000000000001, -73.40000000000003, 90.49999999999997, -130.1000000000005, 209.00000000000006, -156.70000000000002, -164.3, 67.19999999999993, 33.600000000000065, -97.1, -13.399999999999892, -134.0000000000007, 234.40000000000006, -67.6, -393.79999999999995, -74.7000000000001, -90.5, -94.19999999999999, -358.6, -136.0, -145.70000000000002, 17.99999999999996, -292.7000000000001, -291.5, -96.10000000000088, -263.1, -202.6, 271.0000000000003, 220.69999999999928, 51.20000000000018, 6.200000000000023, -39.899999999999785, 33.500000000000206, 132.59999999999968, -152.5, -146.89999999999986, 6.700000000000291, -239.80000000000004, -219.70000000000007, -134.30000000000084, -283.80000000000007, -282.9999999999991, 43.20000000000024, 8.99999999999995, -7.299999999999649, 74.59999999999991, -222.30000000000032, -38.49999999999994, 99.29999999999995, -408.7, -84.00000000000013, -355.0, -230.80000000000004, 170.49999999999994, -366.39999999999986, -306.2, -285.0999999999995, 55.00000000000017, 5.100000000000053, -182.7000000000001, -300.3999999999994, 42.40000000000005, 26.200000000000237, 104.19999999999936, -434.2, 121.19999999999929, 39.00000000000026, 141.09999999999997, -51.59999999999987, -375.29999999999984, -144.0000000000006, -1.3999999999999315, -48.799999999999926, -109.80000000000001, -433.8999999999994, -22.29999999999974, -196.90000000000023, -294.20000000000005, -162.10000000000022, -274.59999999999945, 29.50000000000003, -240.39999999999998, -64.10000000000002, 138.5, -3.4999999999999645, -247.60000000000025, -35.19999999999962, -26.29999999999974, -307.1, -171.0, -23.3999999999999, 67.79999999999998, -105.10000000000056, -193.50000000000009, 14.600000000000044, -189.90000000000018, 40.899999999999956, -20.99999999999976, -38.49999999999996, -37.19999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-157.9, -110.19999999999999, -236.50000000000003, -70.9, -10.599999999999994, 4.099999999999994, -139.0000000000005, -270.1, 150.5, -23.5, -175.6, -189.10000000000002, -244.30000000000004, -223.0, -109.89999999999989, 28.099999999999994, -103.0, 14.600000000000115, -110.8, -223.30000000000004, -24.09999999999981, -142.3, -64.30000000000072, -216.7, 121.70000000000002, 67.7000000000001, -96.69999999999999, -127.9, -317.79999999999995, -385.0, -316.6, -24.099999999999888, -64.6, -169.9, -186.4000000000001, -164.80000000000007, -397.0, -283.6, -118.60000000000038, -210.4, -367.0, -126.70000000000002, -21.999999999999744, 20.000000000000014, -320.80000000000007, -253.89999999999998, -182.5, -316.0, -74.50000000000087, -334.6, -304.0, -225.1, -400.0, -166.6, 85.99999999999994, 146.0, 95.59999999999934, 70.10000000000002, -147.69999999999996, 17.899999999999988, -11.499999999999819, -202.30000000000024, 5.299999999999965, -362.2, -32.49999999999975, 20.000000000000014, -39.09999999999988, 103.69999999999962, -391.0, -89.50000000000003, -341.2, -66.69999999999999, -61.90000000000035, -30.39999999999975, -281.80000000000007, -328.0, -252.99999999999986, -240.7, -91.30000000000084, -337.0, -329.80000000000007, -319.0, -292.3, -297.69999999999914, -225.7, 17.899999999999988, -150.69999999999993, -76.29999999999998, -28.29999999999975, -21.999999999999744, -51.39999999999988, 32.0, -297.10000000000014, -281.2, -21.39999999999987, -162.1, 17.300000000000004, -88.0, -328.0, -279.7, -70.30000000000003, -141.7, -331.0, -313.0, -224.80000000000004, -313.0, 56.0, 45.49999999999996, -373.0, -309.39999999999986, -341.2, -325.0, -233.20000000000013, -316.9, 35.29999999999998, 13.699999999999964, -175.9, 20.000000000000014, -280.0, -261.7000000000001, -385.9, -287.49999999999943, -79.60000000000065, 20.000000000000014, -240.7, -3.099999999999958, -169.0, 54.20000000000017, -391.6, -355.6000000000001, 20.000000000000014, 72.19999999999976, -55.30000000000001, -15.699999999999747, -22.30000000000001, 49.39999999999998, -195.7, -163.9000000000005, -331.0, -274.29999999999984, -312.99999999999994, -160.00000000000057, 31.70000000000022, -126.10000000000068, -42.99999999999992, -263.8, -122.4999999999999, -313.3, -353.7999999999997, -294.0999999999997, 3.1999999999999704, -326.5, -202.00000000000026, -166.9, -355.9, -208.29999999999998, -169.6000000000002, -299.4999999999999, -284.19999999999936, -312.4000000000001, -43.00000000000007, -263.5, -219.4, -298.0, -356.2000000000001, -19.899999999999743, 45.8, -19.300000000000004, 20.000000000000014, -269.5, -361.0, -262.599999999999, -213.4000000000005, -17.79999999999974, -349.0, 13.699999999999966, -258.1, -391.0, -298.0, -253.0, -252.39999999999998, 20.000000000000014, 115.70000000000005, -364.9, -335.2, -22.899999999999757, -190.60000000000008, -307.9, -144.70000000000002, 8.299999999999997, -298.0, -235.90000000000018, -109.89999999999989, 66.79999999999997, 20.000000000000014, -391.0, -24.09999999999996, -303.4, -29.199999999999967, -295.0], "policy_predator_policy_reward": [108.0, 110.0, 109.0, 125.0, 9.0, 88.0, 163.0, 116.0, 31.0, 51.0, 145.0, 63.0, 174.0, 129.0, 78.0, 71.0, 21.0, 101.0, 120.0, 117.0, 122.0, 31.0, 142.0, 5.0, 24.0, 21.0, 147.0, 10.0, 114.0, 195.0, 140.0, 126.0, 137.0, 7.0, 159.0, 98.0, 145.0, 177.0, 137.0, 56.0, 191.0, 157.0, 0.0, 20.0, 166.0, 116.0, 15.0, 192.0, 180.0, 133.0, 107.0, 159.0, 164.0, 200.0, 14.0, 25.0, 36.0, 19.0, 85.0, 96.0, 107.0, 113.0, 172.0, 145.0, 25.0, 21.0, 21.0, 47.0, 191.0, 137.0, 135.0, 126.0, 73.0, 26.0, 181.0, 189.0, 157.0, 117.0, 158.0, 136.0, 183.0, 182.0, 190.0, 117.0, 132.0, 119.0, 92.0, 144.0, 17.0, 26.0, 48.0, 46.0, 192.0, 164.0, 134.0, 11.0, 92.0, 78.0, 6.0, 193.0, 15.0, 113.0, 96.0, 193.0, 171.0, 136.0, 14.0, 55.0, 194.0, 122.0, 175.0, 185.0, 85.0, 180.0, 3.0, 3.0, 67.0, 94.0, 172.0, 187.0, 198.0, 175.0, 57.0, 45.0, 146.0, 124.0, 111.0, 108.0, 113.0, 200.0, 16.0, 13.0, 74.0, 36.0, 36.0, 78.0, 133.0, 175.0, 39.0, 191.0, 176.0, 153.0, 33.0, 60.0, 117.0, 141.0, 167.0, 159.0, 24.0, 190.0, 139.0, 162.0, 170.0, 2.0, 159.0, 111.0, 174.0, 133.0, 186.0, 136.0, 170.0, 166.0, 184.0, 93.0, 150.0, 162.0, 88.0, 24.0, 141.0, 105.0, 184.0, 192.0, 86.0, 110.0, 165.0, 144.0, 199.0, 143.0, 191.0, 189.0, 125.0, 84.0, 153.0, 164.0, 160.0, 93.0, 186.0, 119.0, 147.0, 4.0, 181.0, 163.0, 12.0, 72.0, 193.0, 157.0, 144.0, 145.0, 130.0, 157.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8080847011112181, "mean_inference_ms": 2.1243697989447328, "mean_action_processing_ms": 0.3119246798832037, "mean_env_wait_ms": 0.2777508747017676, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006494402885437012, "StateBufferConnector_ms": 0.003327488899230957, "ViewRequirementAgentConnector_ms": 0.1056293249130249}, "num_episodes": 18, "episode_return_max": 271.0000000000003, "episode_return_min": -434.2, "episode_return_mean": -92.69700000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 328.7342288418886, "num_env_steps_trained_throughput_per_sec": 328.7342288418886, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 12759.867, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12759.82, "sample_time_ms": 1569.111, "learn_time_ms": 11174.583, "learn_throughput": 357.955, "synch_weights_time_ms": 14.106}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "f0d88_00000", "date": "2024-08-14_10-48-52", "timestamp": 1723646932, "time_this_iter_s": 12.215268850326538, "time_total_s": 151.78474736213684, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0bcc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 151.78474736213684, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 48.05294117647059, "ram_util_percent": 83.39999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1486113837471716, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 5.884807115130954, "policy_loss": -0.026412827505301387, "vf_loss": 5.892588606587163, "vf_explained_var": 0.11177744155838376, "kl": 0.018401319190892728, "entropy": 1.425186505708745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1517540022178934, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 8.240371845891236, "policy_loss": -0.013956401164510421, "vf_loss": 8.225470464696329, "vf_explained_var": 0.08320537922243593, "kl": 0.019001008231560083, "entropy": 1.366363601457505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 271.0000000000003, "episode_reward_min": -434.2, "episode_reward_mean": -88.49099999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 146.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -157.53549999999998, "predator_policy": 113.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-358.6, -136.0, -145.70000000000002, 17.99999999999996, -292.7000000000001, -291.5, -96.10000000000088, -263.1, -202.6, 271.0000000000003, 220.69999999999928, 51.20000000000018, 6.200000000000023, -39.899999999999785, 33.500000000000206, 132.59999999999968, -152.5, -146.89999999999986, 6.700000000000291, -239.80000000000004, -219.70000000000007, -134.30000000000084, -283.80000000000007, -282.9999999999991, 43.20000000000024, 8.99999999999995, -7.299999999999649, 74.59999999999991, -222.30000000000032, -38.49999999999994, 99.29999999999995, -408.7, -84.00000000000013, -355.0, -230.80000000000004, 170.49999999999994, -366.39999999999986, -306.2, -285.0999999999995, 55.00000000000017, 5.100000000000053, -182.7000000000001, -300.3999999999994, 42.40000000000005, 26.200000000000237, 104.19999999999936, -434.2, 121.19999999999929, 39.00000000000026, 141.09999999999997, -51.59999999999987, -375.29999999999984, -144.0000000000006, -1.3999999999999315, -48.799999999999926, -109.80000000000001, -433.8999999999994, -22.29999999999974, -196.90000000000023, -294.20000000000005, -162.10000000000022, -274.59999999999945, 29.50000000000003, -240.39999999999998, -64.10000000000002, 138.5, -3.4999999999999645, -247.60000000000025, -35.19999999999962, -26.29999999999974, -307.1, -171.0, -23.3999999999999, 67.79999999999998, -105.10000000000056, -193.50000000000009, 14.600000000000044, -189.90000000000018, 40.899999999999956, -20.99999999999976, -38.49999999999996, -37.19999999999998, -16.099999999999795, 31.600000000000094, 89.00000000000001, -79.10000000000056, -260.8, 5.700000000000372, -32.19999999999982, 10.200000000000001, -77.0000000000002, 26.600000000000247, -330.3999999999985, 2.600000000000194, -58.20000000000013, 59.80000000000033, -17.9999999999998, 92.89999999999937, 110.49999999999962, -41.699999999999825], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-397.0, -283.6, -118.60000000000038, -210.4, -367.0, -126.70000000000002, -21.999999999999744, 20.000000000000014, -320.80000000000007, -253.89999999999998, -182.5, -316.0, -74.50000000000087, -334.6, -304.0, -225.1, -400.0, -166.6, 85.99999999999994, 146.0, 95.59999999999934, 70.10000000000002, -147.69999999999996, 17.899999999999988, -11.499999999999819, -202.30000000000024, 5.299999999999965, -362.2, -32.49999999999975, 20.000000000000014, -39.09999999999988, 103.69999999999962, -391.0, -89.50000000000003, -341.2, -66.69999999999999, -61.90000000000035, -30.39999999999975, -281.80000000000007, -328.0, -252.99999999999986, -240.7, -91.30000000000084, -337.0, -329.80000000000007, -319.0, -292.3, -297.69999999999914, -225.7, 17.899999999999988, -150.69999999999993, -76.29999999999998, -28.29999999999975, -21.999999999999744, -51.39999999999988, 32.0, -297.10000000000014, -281.2, -21.39999999999987, -162.1, 17.300000000000004, -88.0, -328.0, -279.7, -70.30000000000003, -141.7, -331.0, -313.0, -224.80000000000004, -313.0, 56.0, 45.49999999999996, -373.0, -309.39999999999986, -341.2, -325.0, -233.20000000000013, -316.9, 35.29999999999998, 13.699999999999964, -175.9, 20.000000000000014, -280.0, -261.7000000000001, -385.9, -287.49999999999943, -79.60000000000065, 20.000000000000014, -240.7, -3.099999999999958, -169.0, 54.20000000000017, -391.6, -355.6000000000001, 20.000000000000014, 72.19999999999976, -55.30000000000001, -15.699999999999747, -22.30000000000001, 49.39999999999998, -195.7, -163.9000000000005, -331.0, -274.29999999999984, -312.99999999999994, -160.00000000000057, 31.70000000000022, -126.10000000000068, -42.99999999999992, -263.8, -122.4999999999999, -313.3, -353.7999999999997, -294.0999999999997, 3.1999999999999704, -326.5, -202.00000000000026, -166.9, -355.9, -208.29999999999998, -169.6000000000002, -299.4999999999999, -284.19999999999936, -312.4000000000001, -43.00000000000007, -263.5, -219.4, -298.0, -356.2000000000001, -19.899999999999743, 45.8, -19.300000000000004, 20.000000000000014, -269.5, -361.0, -262.599999999999, -213.4000000000005, -17.79999999999974, -349.0, 13.699999999999966, -258.1, -391.0, -298.0, -253.0, -252.39999999999998, 20.000000000000014, 115.70000000000005, -364.9, -335.2, -22.899999999999757, -190.60000000000008, -307.9, -144.70000000000002, 8.299999999999997, -298.0, -235.90000000000018, -109.89999999999989, 66.79999999999997, 20.000000000000014, -391.0, -24.09999999999996, -303.4, -29.199999999999967, -295.0, -340.0, 17.899999999999988, 20.000000000000014, -117.39999999999992, 82.10000000000004, -45.09999999999982, -170.5000000000003, -109.60000000000025, -263.8, -370.0, -70.30000000000086, 19.99999999999997, -233.2000000000001, 20.000000000000014, -347.8, 20.000000000000014, -307.9, 17.899999999999988, -44.19999999999998, -26.199999999999747, -324.3999999999994, -315.9999999999991, -26.199999999999747, -5.199999999999958, -312.99999999999994, -32.19999999999997, -19.899999999999743, 55.700000000000124, -343.0, 20.000000000000014, 12.499999999999966, -22.59999999999993, 15.799999999999946, 55.70000000000005, 20.000000000000014, -243.7], "policy_predator_policy_reward": [145.0, 177.0, 137.0, 56.0, 191.0, 157.0, 0.0, 20.0, 166.0, 116.0, 15.0, 192.0, 180.0, 133.0, 107.0, 159.0, 164.0, 200.0, 14.0, 25.0, 36.0, 19.0, 85.0, 96.0, 107.0, 113.0, 172.0, 145.0, 25.0, 21.0, 21.0, 47.0, 191.0, 137.0, 135.0, 126.0, 73.0, 26.0, 181.0, 189.0, 157.0, 117.0, 158.0, 136.0, 183.0, 182.0, 190.0, 117.0, 132.0, 119.0, 92.0, 144.0, 17.0, 26.0, 48.0, 46.0, 192.0, 164.0, 134.0, 11.0, 92.0, 78.0, 6.0, 193.0, 15.0, 113.0, 96.0, 193.0, 171.0, 136.0, 14.0, 55.0, 194.0, 122.0, 175.0, 185.0, 85.0, 180.0, 3.0, 3.0, 67.0, 94.0, 172.0, 187.0, 198.0, 175.0, 57.0, 45.0, 146.0, 124.0, 111.0, 108.0, 113.0, 200.0, 16.0, 13.0, 74.0, 36.0, 36.0, 78.0, 133.0, 175.0, 39.0, 191.0, 176.0, 153.0, 33.0, 60.0, 117.0, 141.0, 167.0, 159.0, 24.0, 190.0, 139.0, 162.0, 170.0, 2.0, 159.0, 111.0, 174.0, 133.0, 186.0, 136.0, 170.0, 166.0, 184.0, 93.0, 150.0, 162.0, 88.0, 24.0, 141.0, 105.0, 184.0, 192.0, 86.0, 110.0, 165.0, 144.0, 199.0, 143.0, 191.0, 189.0, 125.0, 84.0, 153.0, 164.0, 160.0, 93.0, 186.0, 119.0, 147.0, 4.0, 181.0, 163.0, 12.0, 72.0, 193.0, 157.0, 144.0, 145.0, 130.0, 157.0, 140.0, 166.0, 66.0, 63.0, 31.0, 21.0, 71.0, 130.0, 193.0, 180.0, 47.0, 9.0, 107.0, 74.0, 175.0, 163.0, 98.0, 115.0, 44.0, 53.0, 148.0, 162.0, 1.0, 33.0, 130.0, 157.0, 18.0, 6.0, 132.0, 173.0, 54.0, 49.0, 29.0, 10.0, 50.0, 132.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.789385275657878, "mean_inference_ms": 2.0720280054568407, "mean_action_processing_ms": 0.30551111517766605, "mean_env_wait_ms": 0.27104544461417474, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004106044769287109, "StateBufferConnector_ms": 0.003321409225463867, "ViewRequirementAgentConnector_ms": 0.1034623384475708}, "num_episodes": 18, "episode_return_max": 271.0000000000003, "episode_return_min": -434.2, "episode_return_mean": -88.49099999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.34284094186665, "num_env_steps_trained_throughput_per_sec": 340.34284094186665, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 12687.084, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12687.038, "sample_time_ms": 1542.826, "learn_time_ms": 11129.102, "learn_throughput": 359.418, "synch_weights_time_ms": 13.334}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "f0d88_00000", "date": "2024-08-14_10-49-04", "timestamp": 1723646944, "time_this_iter_s": 11.796231031417847, "time_total_s": 163.5809783935547, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e2ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 163.5809783935547, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 44.1764705882353, "ram_util_percent": 83.32941176470588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.305124725488128, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 5.862828869289822, "policy_loss": -0.026536030834294344, "vf_loss": 5.870421658117304, "vf_explained_var": 0.0299306452589691, "kl": 0.01870937241561532, "entropy": 1.4245492322735054, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.207907892408825, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 8.310384456695072, "policy_loss": -0.015416236862382561, "vf_loss": 8.302412678451134, "vf_explained_var": -0.0364209686952924, "kl": 0.015399520149786782, "entropy": 1.3703451766538872, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 340.00000000000045, "episode_reward_min": -434.2, "episode_reward_mean": -54.39899999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.6, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -131.4745, "predator_policy": 104.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [74.59999999999991, -222.30000000000032, -38.49999999999994, 99.29999999999995, -408.7, -84.00000000000013, -355.0, -230.80000000000004, 170.49999999999994, -366.39999999999986, -306.2, -285.0999999999995, 55.00000000000017, 5.100000000000053, -182.7000000000001, -300.3999999999994, 42.40000000000005, 26.200000000000237, 104.19999999999936, -434.2, 121.19999999999929, 39.00000000000026, 141.09999999999997, -51.59999999999987, -375.29999999999984, -144.0000000000006, -1.3999999999999315, -48.799999999999926, -109.80000000000001, -433.8999999999994, -22.29999999999974, -196.90000000000023, -294.20000000000005, -162.10000000000022, -274.59999999999945, 29.50000000000003, -240.39999999999998, -64.10000000000002, 138.5, -3.4999999999999645, -247.60000000000025, -35.19999999999962, -26.29999999999974, -307.1, -171.0, -23.3999999999999, 67.79999999999998, -105.10000000000056, -193.50000000000009, 14.600000000000044, -189.90000000000018, 40.899999999999956, -20.99999999999976, -38.49999999999996, -37.19999999999998, -16.099999999999795, 31.600000000000094, 89.00000000000001, -79.10000000000056, -260.8, 5.700000000000372, -32.19999999999982, 10.200000000000001, -77.0000000000002, 26.600000000000247, -330.3999999999985, 2.600000000000194, -58.20000000000013, 59.80000000000033, -17.9999999999998, 92.89999999999937, 110.49999999999962, -41.699999999999825, -28.599999999999667, -10.899999999999977, 25.4, 8.199999999999948, 101.40000000000006, 159.6999999999996, 128.7, 40.40000000000008, 86.09999999999931, 340.00000000000045, 35.2000000000001, 118.49999999999935, -93.70000000000027, 62.40000000000007, 164.39999999999958, -6.5999999999999215, -95.49999999999986, 61.4000000000001, -162.70000000000005, 53.40000000000011, 25.700000000000074, -19.99999999999976, -76.1000000000005, 17.599999999999994, 10.899999999999975, 22.600000000000193, -60.10000000000061], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-51.39999999999988, 32.0, -297.10000000000014, -281.2, -21.39999999999987, -162.1, 17.300000000000004, -88.0, -328.0, -279.7, -70.30000000000003, -141.7, -331.0, -313.0, -224.80000000000004, -313.0, 56.0, 45.49999999999996, -373.0, -309.39999999999986, -341.2, -325.0, -233.20000000000013, -316.9, 35.29999999999998, 13.699999999999964, -175.9, 20.000000000000014, -280.0, -261.7000000000001, -385.9, -287.49999999999943, -79.60000000000065, 20.000000000000014, -240.7, -3.099999999999958, -169.0, 54.20000000000017, -391.6, -355.6000000000001, 20.000000000000014, 72.19999999999976, -55.30000000000001, -15.699999999999747, -22.30000000000001, 49.39999999999998, -195.7, -163.9000000000005, -331.0, -274.29999999999984, -312.99999999999994, -160.00000000000057, 31.70000000000022, -126.10000000000068, -42.99999999999992, -263.8, -122.4999999999999, -313.3, -353.7999999999997, -294.0999999999997, 3.1999999999999704, -326.5, -202.00000000000026, -166.9, -355.9, -208.29999999999998, -169.6000000000002, -299.4999999999999, -284.19999999999936, -312.4000000000001, -43.00000000000007, -263.5, -219.4, -298.0, -356.2000000000001, -19.899999999999743, 45.8, -19.300000000000004, 20.000000000000014, -269.5, -361.0, -262.599999999999, -213.4000000000005, -17.79999999999974, -349.0, 13.699999999999966, -258.1, -391.0, -298.0, -253.0, -252.39999999999998, 20.000000000000014, 115.70000000000005, -364.9, -335.2, -22.899999999999757, -190.60000000000008, -307.9, -144.70000000000002, 8.299999999999997, -298.0, -235.90000000000018, -109.89999999999989, 66.79999999999997, 20.000000000000014, -391.0, -24.09999999999996, -303.4, -29.199999999999967, -295.0, -340.0, 17.899999999999988, 20.000000000000014, -117.39999999999992, 82.10000000000004, -45.09999999999982, -170.5000000000003, -109.60000000000025, -263.8, -370.0, -70.30000000000086, 19.99999999999997, -233.2000000000001, 20.000000000000014, -347.8, 20.000000000000014, -307.9, 17.899999999999988, -44.19999999999998, -26.199999999999747, -324.3999999999994, -315.9999999999991, -26.199999999999747, -5.199999999999958, -312.99999999999994, -32.19999999999997, -19.899999999999743, 55.700000000000124, -343.0, 20.000000000000014, 12.499999999999966, -22.59999999999993, 15.799999999999946, 55.70000000000005, 20.000000000000014, -243.7, -28.29999999999977, -214.30000000000038, 20.000000000000014, -190.9, -268.5999999999999, 20.000000000000014, 20.000000000000014, -146.8000000000005, -95.2, 26.60000000000007, -49.299999999999805, 155.00000000000003, 85.69999999999999, -109.0, 16.69999999999999, -157.3, -13.000000000000046, -16.899999999999928, 173.8999999999999, 103.1, -98.7999999999999, 20.000000000000014, 20.000000000000014, 69.50000000000009, -382.9, -26.800000000000153, -64.60000000000005, 20.000000000000014, 93.80000000000001, -18.39999999999999, -180.70000000000024, -40.89999999999998, -29.500000000000014, -373.0, 20.000000000000014, -34.59999999999988, -245.5, -260.1999999999998, 3.1999999999999615, 36.19999999999996, -5.199999999999962, 17.899999999999988, 20.000000000000014, -316.0, -146.20000000000016, -127.90000000000035, -89.20000000000084, 12.799999999999974, -7.299999999999891, -161.8, -66.10000000000065, -25.300000000000026, -195.10000000000014, -127.00000000000074], "policy_predator_policy_reward": [48.0, 46.0, 192.0, 164.0, 134.0, 11.0, 92.0, 78.0, 6.0, 193.0, 15.0, 113.0, 96.0, 193.0, 171.0, 136.0, 14.0, 55.0, 194.0, 122.0, 175.0, 185.0, 85.0, 180.0, 3.0, 3.0, 67.0, 94.0, 172.0, 187.0, 198.0, 175.0, 57.0, 45.0, 146.0, 124.0, 111.0, 108.0, 113.0, 200.0, 16.0, 13.0, 74.0, 36.0, 36.0, 78.0, 133.0, 175.0, 39.0, 191.0, 176.0, 153.0, 33.0, 60.0, 117.0, 141.0, 167.0, 159.0, 24.0, 190.0, 139.0, 162.0, 170.0, 2.0, 159.0, 111.0, 174.0, 133.0, 186.0, 136.0, 170.0, 166.0, 184.0, 93.0, 150.0, 162.0, 88.0, 24.0, 141.0, 105.0, 184.0, 192.0, 86.0, 110.0, 165.0, 144.0, 199.0, 143.0, 191.0, 189.0, 125.0, 84.0, 153.0, 164.0, 160.0, 93.0, 186.0, 119.0, 147.0, 4.0, 181.0, 163.0, 12.0, 72.0, 193.0, 157.0, 144.0, 145.0, 130.0, 157.0, 140.0, 166.0, 66.0, 63.0, 31.0, 21.0, 71.0, 130.0, 193.0, 180.0, 47.0, 9.0, 107.0, 74.0, 175.0, 163.0, 98.0, 115.0, 44.0, 53.0, 148.0, 162.0, 1.0, 33.0, 130.0, 157.0, 18.0, 6.0, 132.0, 173.0, 54.0, 49.0, 29.0, 10.0, 50.0, 132.0, 104.0, 110.0, 31.0, 129.0, 142.0, 132.0, 81.0, 54.0, 92.0, 78.0, 22.0, 32.0, 99.0, 53.0, 94.0, 87.0, 72.0, 44.0, 31.0, 32.0, 55.0, 59.0, 12.0, 17.0, 134.0, 182.0, 37.0, 70.0, 32.0, 57.0, 108.0, 107.0, 191.0, 116.0, 50.0, 26.0, 180.0, 163.0, 3.0, 11.0, 1.0, 12.0, 127.0, 149.0, 72.0, 126.0, 52.0, 42.0, 76.0, 104.0, 72.0, 42.0, 137.0, 125.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7684404362553171, "mean_inference_ms": 2.008205493601039, "mean_action_processing_ms": 0.29768869282703403, "mean_env_wait_ms": 0.2641390445731488, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00397801399230957, "StateBufferConnector_ms": 0.0032341480255126953, "ViewRequirementAgentConnector_ms": 0.10380542278289795}, "num_episodes": 27, "episode_return_max": 340.00000000000045, "episode_return_min": -434.2, "episode_return_mean": -54.39899999999999, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 331.107682343362, "num_env_steps_trained_throughput_per_sec": 331.107682343362, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 12024.417, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12024.368, "sample_time_ms": 1277.226, "learn_time_ms": 10732.09, "learn_throughput": 372.714, "synch_weights_time_ms": 13.137}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "f0d88_00000", "date": "2024-08-14_10-49-16", "timestamp": 1723646956, "time_this_iter_s": 12.13311219215393, "time_total_s": 175.71409058570862, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e2e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 175.71409058570862, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 45.976470588235294, "ram_util_percent": 83.58823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0343293552360837, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 4.664295810114139, "policy_loss": -0.03886889139283941, "vf_loss": 4.6876860781321446, "vf_explained_var": -0.005129589731731112, "kl": 0.015287536123192964, "entropy": 1.4328472316580474, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.737586529040463, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.517677574309092, "policy_loss": -0.017842496698475863, "vf_loss": 7.509703375044323, "vf_explained_var": -0.09453726899686944, "kl": 0.01699864622546583, "entropy": 1.375456142236316, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 340.00000000000045, "episode_reward_min": -434.2, "episode_reward_mean": -17.422000000000043, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -99.001, "predator_policy": 90.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [104.19999999999936, -434.2, 121.19999999999929, 39.00000000000026, 141.09999999999997, -51.59999999999987, -375.29999999999984, -144.0000000000006, -1.3999999999999315, -48.799999999999926, -109.80000000000001, -433.8999999999994, -22.29999999999974, -196.90000000000023, -294.20000000000005, -162.10000000000022, -274.59999999999945, 29.50000000000003, -240.39999999999998, -64.10000000000002, 138.5, -3.4999999999999645, -247.60000000000025, -35.19999999999962, -26.29999999999974, -307.1, -171.0, -23.3999999999999, 67.79999999999998, -105.10000000000056, -193.50000000000009, 14.600000000000044, -189.90000000000018, 40.899999999999956, -20.99999999999976, -38.49999999999996, -37.19999999999998, -16.099999999999795, 31.600000000000094, 89.00000000000001, -79.10000000000056, -260.8, 5.700000000000372, -32.19999999999982, 10.200000000000001, -77.0000000000002, 26.600000000000247, -330.3999999999985, 2.600000000000194, -58.20000000000013, 59.80000000000033, -17.9999999999998, 92.89999999999937, 110.49999999999962, -41.699999999999825, -28.599999999999667, -10.899999999999977, 25.4, 8.199999999999948, 101.40000000000006, 159.6999999999996, 128.7, 40.40000000000008, 86.09999999999931, 340.00000000000045, 35.2000000000001, 118.49999999999935, -93.70000000000027, 62.40000000000007, 164.39999999999958, -6.5999999999999215, -95.49999999999986, 61.4000000000001, -162.70000000000005, 53.40000000000011, 25.700000000000074, -19.99999999999976, -76.1000000000005, 17.599999999999994, 10.899999999999975, 22.600000000000193, -60.10000000000061, 180.49999999999952, -12.799999999999851, -11.600000000000295, -55.09999999999965, 88.99999999999909, 33.300000000000196, 259.29999999999956, 73.09999999999972, 123.7999999999987, 41.30000000000026, 99.29999999999987, 80.90000000000019, 119.49999999999945, 32.2000000000002, 92.9999999999994, 69.69999999999976, 50.60000000000049, 124.69999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-169.0, 54.20000000000017, -391.6, -355.6000000000001, 20.000000000000014, 72.19999999999976, -55.30000000000001, -15.699999999999747, -22.30000000000001, 49.39999999999998, -195.7, -163.9000000000005, -331.0, -274.29999999999984, -312.99999999999994, -160.00000000000057, 31.70000000000022, -126.10000000000068, -42.99999999999992, -263.8, -122.4999999999999, -313.3, -353.7999999999997, -294.0999999999997, 3.1999999999999704, -326.5, -202.00000000000026, -166.9, -355.9, -208.29999999999998, -169.6000000000002, -299.4999999999999, -284.19999999999936, -312.4000000000001, -43.00000000000007, -263.5, -219.4, -298.0, -356.2000000000001, -19.899999999999743, 45.8, -19.300000000000004, 20.000000000000014, -269.5, -361.0, -262.599999999999, -213.4000000000005, -17.79999999999974, -349.0, 13.699999999999966, -258.1, -391.0, -298.0, -253.0, -252.39999999999998, 20.000000000000014, 115.70000000000005, -364.9, -335.2, -22.899999999999757, -190.60000000000008, -307.9, -144.70000000000002, 8.299999999999997, -298.0, -235.90000000000018, -109.89999999999989, 66.79999999999997, 20.000000000000014, -391.0, -24.09999999999996, -303.4, -29.199999999999967, -295.0, -340.0, 17.899999999999988, 20.000000000000014, -117.39999999999992, 82.10000000000004, -45.09999999999982, -170.5000000000003, -109.60000000000025, -263.8, -370.0, -70.30000000000086, 19.99999999999997, -233.2000000000001, 20.000000000000014, -347.8, 20.000000000000014, -307.9, 17.899999999999988, -44.19999999999998, -26.199999999999747, -324.3999999999994, -315.9999999999991, -26.199999999999747, -5.199999999999958, -312.99999999999994, -32.19999999999997, -19.899999999999743, 55.700000000000124, -343.0, 20.000000000000014, 12.499999999999966, -22.59999999999993, 15.799999999999946, 55.70000000000005, 20.000000000000014, -243.7, -28.29999999999977, -214.30000000000038, 20.000000000000014, -190.9, -268.5999999999999, 20.000000000000014, 20.000000000000014, -146.8000000000005, -95.2, 26.60000000000007, -49.299999999999805, 155.00000000000003, 85.69999999999999, -109.0, 16.69999999999999, -157.3, -13.000000000000046, -16.899999999999928, 173.8999999999999, 103.1, -98.7999999999999, 20.000000000000014, 20.000000000000014, 69.50000000000009, -382.9, -26.800000000000153, -64.60000000000005, 20.000000000000014, 93.80000000000001, -18.39999999999999, -180.70000000000024, -40.89999999999998, -29.500000000000014, -373.0, 20.000000000000014, -34.59999999999988, -245.5, -260.1999999999998, 3.1999999999999615, 36.19999999999996, -5.199999999999962, 17.899999999999988, 20.000000000000014, -316.0, -146.20000000000016, -127.90000000000035, -89.20000000000084, 12.799999999999974, -7.299999999999891, -161.8, -66.10000000000065, -25.300000000000026, -195.10000000000014, -127.00000000000074, 13.700000000000014, 57.8000000000001, -12.39999999999995, -189.4000000000002, -157.60000000000008, -9.999999999999815, -9.3999999999999, -243.7000000000001, 7.399999999999965, 20.600000000000062, 11.599999999999964, 13.699999999999964, 123.79999999999978, 120.49999999999994, 20.000000000000014, 52.10000000000018, 91.09999999999985, 22.700000000000056, -58.30000000000003, 11.599999999999964, 52.400000000000006, -3.099999999999958, -8.199999999999797, 52.1000000000001, 7.399999999999965, 85.10000000000008, 20.000000000000014, 3.1999999999999695, 46.400000000000134, 11.599999999999966, 35.000000000000206, -103.30000000000027, 13.699999999999973, 26.900000000000144, 82.09999999999997, 11.599999999999971], "policy_predator_policy_reward": [111.0, 108.0, 113.0, 200.0, 16.0, 13.0, 74.0, 36.0, 36.0, 78.0, 133.0, 175.0, 39.0, 191.0, 176.0, 153.0, 33.0, 60.0, 117.0, 141.0, 167.0, 159.0, 24.0, 190.0, 139.0, 162.0, 170.0, 2.0, 159.0, 111.0, 174.0, 133.0, 186.0, 136.0, 170.0, 166.0, 184.0, 93.0, 150.0, 162.0, 88.0, 24.0, 141.0, 105.0, 184.0, 192.0, 86.0, 110.0, 165.0, 144.0, 199.0, 143.0, 191.0, 189.0, 125.0, 84.0, 153.0, 164.0, 160.0, 93.0, 186.0, 119.0, 147.0, 4.0, 181.0, 163.0, 12.0, 72.0, 193.0, 157.0, 144.0, 145.0, 130.0, 157.0, 140.0, 166.0, 66.0, 63.0, 31.0, 21.0, 71.0, 130.0, 193.0, 180.0, 47.0, 9.0, 107.0, 74.0, 175.0, 163.0, 98.0, 115.0, 44.0, 53.0, 148.0, 162.0, 1.0, 33.0, 130.0, 157.0, 18.0, 6.0, 132.0, 173.0, 54.0, 49.0, 29.0, 10.0, 50.0, 132.0, 104.0, 110.0, 31.0, 129.0, 142.0, 132.0, 81.0, 54.0, 92.0, 78.0, 22.0, 32.0, 99.0, 53.0, 94.0, 87.0, 72.0, 44.0, 31.0, 32.0, 55.0, 59.0, 12.0, 17.0, 134.0, 182.0, 37.0, 70.0, 32.0, 57.0, 108.0, 107.0, 191.0, 116.0, 50.0, 26.0, 180.0, 163.0, 3.0, 11.0, 1.0, 12.0, 127.0, 149.0, 72.0, 126.0, 52.0, 42.0, 76.0, 104.0, 72.0, 42.0, 137.0, 125.0, 41.0, 68.0, 118.0, 71.0, 34.0, 122.0, 98.0, 100.0, 29.0, 32.0, 4.0, 4.0, 5.0, 10.0, 0.0, 1.0, 6.0, 4.0, 17.0, 71.0, 13.0, 37.0, 27.0, 10.0, 13.0, 14.0, 3.0, 6.0, 22.0, 13.0, 84.0, 54.0, 3.0, 7.0, 15.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7551510768374127, "mean_inference_ms": 1.9763049358064202, "mean_action_processing_ms": 0.2944880555217085, "mean_env_wait_ms": 0.2595067552812382, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0034933090209960938, "StateBufferConnector_ms": 0.003011941909790039, "ViewRequirementAgentConnector_ms": 0.09284031391143799}, "num_episodes": 18, "episode_return_max": 340.00000000000045, "episode_return_min": -434.2, "episode_return_mean": -17.422000000000043, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.02360405733606, "num_env_steps_trained_throughput_per_sec": 334.02360405733606, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 11971.522, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11971.473, "sample_time_ms": 1232.115, "learn_time_ms": 10724.137, "learn_throughput": 372.99, "synch_weights_time_ms": 13.154}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "f0d88_00000", "date": "2024-08-14_10-49-28", "timestamp": 1723646968, "time_this_iter_s": 12.015034914016724, "time_total_s": 187.72912549972534, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad49f790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 187.72912549972534, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 45.21764705882353, "ram_util_percent": 83.5529411764706}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.191369634172904, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 4.408906693559475, "policy_loss": -0.02848847173622479, "vf_loss": 4.419397704815738, "vf_explained_var": -0.027808503120664567, "kl": 0.017775275299075043, "entropy": 1.4372744625838345, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.128091718784716, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.9031258123892325, "policy_loss": -0.018141002953914857, "vf_loss": 6.897176008628159, "vf_explained_var": -0.0674491162968691, "kl": 0.015862249741158144, "entropy": 1.383304737169276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 340.00000000000045, "episode_reward_min": -330.3999999999985, "episode_reward_mean": 14.610999999999944, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -67.36449999999999, "predator_policy": 74.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-240.39999999999998, -64.10000000000002, 138.5, -3.4999999999999645, -247.60000000000025, -35.19999999999962, -26.29999999999974, -307.1, -171.0, -23.3999999999999, 67.79999999999998, -105.10000000000056, -193.50000000000009, 14.600000000000044, -189.90000000000018, 40.899999999999956, -20.99999999999976, -38.49999999999996, -37.19999999999998, -16.099999999999795, 31.600000000000094, 89.00000000000001, -79.10000000000056, -260.8, 5.700000000000372, -32.19999999999982, 10.200000000000001, -77.0000000000002, 26.600000000000247, -330.3999999999985, 2.600000000000194, -58.20000000000013, 59.80000000000033, -17.9999999999998, 92.89999999999937, 110.49999999999962, -41.699999999999825, -28.599999999999667, -10.899999999999977, 25.4, 8.199999999999948, 101.40000000000006, 159.6999999999996, 128.7, 40.40000000000008, 86.09999999999931, 340.00000000000045, 35.2000000000001, 118.49999999999935, -93.70000000000027, 62.40000000000007, 164.39999999999958, -6.5999999999999215, -95.49999999999986, 61.4000000000001, -162.70000000000005, 53.40000000000011, 25.700000000000074, -19.99999999999976, -76.1000000000005, 17.599999999999994, 10.899999999999975, 22.600000000000193, -60.10000000000061, 180.49999999999952, -12.799999999999851, -11.600000000000295, -55.09999999999965, 88.99999999999909, 33.300000000000196, 259.29999999999956, 73.09999999999972, 123.7999999999987, 41.30000000000026, 99.29999999999987, 80.90000000000019, 119.49999999999945, 32.2000000000002, 92.9999999999994, 69.69999999999976, 50.60000000000049, 124.69999999999935, 13.70000000000004, 69.50000000000004, 19.099999999999955, -5.099999999999714, 35.600000000000236, 68.79999999999995, 128.29999999999964, -9.000000000000137, 117.19999999999983, -14.799999999999986, 70.90000000000018, 127.39999999999965, 84.39999999999915, -32.49999999999954, 86.20000000000005, 105.69999999999982, 121.79999999999978, 101.99999999999959], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-219.4, -298.0, -356.2000000000001, -19.899999999999743, 45.8, -19.300000000000004, 20.000000000000014, -269.5, -361.0, -262.599999999999, -213.4000000000005, -17.79999999999974, -349.0, 13.699999999999966, -258.1, -391.0, -298.0, -253.0, -252.39999999999998, 20.000000000000014, 115.70000000000005, -364.9, -335.2, -22.899999999999757, -190.60000000000008, -307.9, -144.70000000000002, 8.299999999999997, -298.0, -235.90000000000018, -109.89999999999989, 66.79999999999997, 20.000000000000014, -391.0, -24.09999999999996, -303.4, -29.199999999999967, -295.0, -340.0, 17.899999999999988, 20.000000000000014, -117.39999999999992, 82.10000000000004, -45.09999999999982, -170.5000000000003, -109.60000000000025, -263.8, -370.0, -70.30000000000086, 19.99999999999997, -233.2000000000001, 20.000000000000014, -347.8, 20.000000000000014, -307.9, 17.899999999999988, -44.19999999999998, -26.199999999999747, -324.3999999999994, -315.9999999999991, -26.199999999999747, -5.199999999999958, -312.99999999999994, -32.19999999999997, -19.899999999999743, 55.700000000000124, -343.0, 20.000000000000014, 12.499999999999966, -22.59999999999993, 15.799999999999946, 55.70000000000005, 20.000000000000014, -243.7, -28.29999999999977, -214.30000000000038, 20.000000000000014, -190.9, -268.5999999999999, 20.000000000000014, 20.000000000000014, -146.8000000000005, -95.2, 26.60000000000007, -49.299999999999805, 155.00000000000003, 85.69999999999999, -109.0, 16.69999999999999, -157.3, -13.000000000000046, -16.899999999999928, 173.8999999999999, 103.1, -98.7999999999999, 20.000000000000014, 20.000000000000014, 69.50000000000009, -382.9, -26.800000000000153, -64.60000000000005, 20.000000000000014, 93.80000000000001, -18.39999999999999, -180.70000000000024, -40.89999999999998, -29.500000000000014, -373.0, 20.000000000000014, -34.59999999999988, -245.5, -260.1999999999998, 3.1999999999999615, 36.19999999999996, -5.199999999999962, 17.899999999999988, 20.000000000000014, -316.0, -146.20000000000016, -127.90000000000035, -89.20000000000084, 12.799999999999974, -7.299999999999891, -161.8, -66.10000000000065, -25.300000000000026, -195.10000000000014, -127.00000000000074, 13.700000000000014, 57.8000000000001, -12.39999999999995, -189.4000000000002, -157.60000000000008, -9.999999999999815, -9.3999999999999, -243.7000000000001, 7.399999999999965, 20.600000000000062, 11.599999999999964, 13.699999999999964, 123.79999999999978, 120.49999999999994, 20.000000000000014, 52.10000000000018, 91.09999999999985, 22.700000000000056, -58.30000000000003, 11.599999999999964, 52.400000000000006, -3.099999999999958, -8.199999999999797, 52.1000000000001, 7.399999999999965, 85.10000000000008, 20.000000000000014, 3.1999999999999695, 46.400000000000134, 11.599999999999966, 35.000000000000206, -103.30000000000027, 13.699999999999973, 26.900000000000144, 82.09999999999997, 11.599999999999971, -7.299999999999891, -0.9999999999999846, 70.39999999999975, -19.899999999999743, -9.400000000000027, 9.499999999999964, -15.6999999999998, -30.39999999999975, -17.79999999999974, 19.400000000000023, 57.8000000000002, -138.99999999999997, 51.5, 15.799999999999963, -64.30000000000052, -51.70000000000008, -9.399999999999961, 71.6, -130.29999999999995, -2.4999999999999716, 52.09999999999996, 15.799999999999955, 34.40000000000001, 20.000000000000014, 28.700000000000117, 13.699999999999964, -70.30000000000089, -47.19999999999976, 13.699999999999964, 69.49999999999997, -114.70000000000019, 76.40000000000006, 55.70000000000003, 28.1, -38.799999999999756, 27.80000000000004], "policy_predator_policy_reward": [184.0, 93.0, 150.0, 162.0, 88.0, 24.0, 141.0, 105.0, 184.0, 192.0, 86.0, 110.0, 165.0, 144.0, 199.0, 143.0, 191.0, 189.0, 125.0, 84.0, 153.0, 164.0, 160.0, 93.0, 186.0, 119.0, 147.0, 4.0, 181.0, 163.0, 12.0, 72.0, 193.0, 157.0, 144.0, 145.0, 130.0, 157.0, 140.0, 166.0, 66.0, 63.0, 31.0, 21.0, 71.0, 130.0, 193.0, 180.0, 47.0, 9.0, 107.0, 74.0, 175.0, 163.0, 98.0, 115.0, 44.0, 53.0, 148.0, 162.0, 1.0, 33.0, 130.0, 157.0, 18.0, 6.0, 132.0, 173.0, 54.0, 49.0, 29.0, 10.0, 50.0, 132.0, 104.0, 110.0, 31.0, 129.0, 142.0, 132.0, 81.0, 54.0, 92.0, 78.0, 22.0, 32.0, 99.0, 53.0, 94.0, 87.0, 72.0, 44.0, 31.0, 32.0, 55.0, 59.0, 12.0, 17.0, 134.0, 182.0, 37.0, 70.0, 32.0, 57.0, 108.0, 107.0, 191.0, 116.0, 50.0, 26.0, 180.0, 163.0, 3.0, 11.0, 1.0, 12.0, 127.0, 149.0, 72.0, 126.0, 52.0, 42.0, 76.0, 104.0, 72.0, 42.0, 137.0, 125.0, 41.0, 68.0, 118.0, 71.0, 34.0, 122.0, 98.0, 100.0, 29.0, 32.0, 4.0, 4.0, 5.0, 10.0, 0.0, 1.0, 6.0, 4.0, 17.0, 71.0, 13.0, 37.0, 27.0, 10.0, 13.0, 14.0, 3.0, 6.0, 22.0, 13.0, 84.0, 54.0, 3.0, 7.0, 15.0, 16.0, 9.0, 13.0, 0.0, 19.0, 14.0, 5.0, 38.0, 3.0, 16.0, 18.0, 61.0, 89.0, 30.0, 31.0, 93.0, 14.0, 32.0, 23.0, 34.0, 84.0, 0.0, 3.0, 50.0, 23.0, 21.0, 21.0, 41.0, 44.0, 3.0, 0.0, 83.0, 61.0, 16.0, 22.0, 59.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7446178796821176, "mean_inference_ms": 1.9479649061051685, "mean_action_processing_ms": 0.2913197888218428, "mean_env_wait_ms": 0.25596793744373025, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035157203674316406, "StateBufferConnector_ms": 0.002956867218017578, "ViewRequirementAgentConnector_ms": 0.0959930419921875}, "num_episodes": 18, "episode_return_max": 340.00000000000045, "episode_return_min": -330.3999999999985, "episode_return_mean": 14.610999999999944, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.3236077232125, "num_env_steps_trained_throughput_per_sec": 342.3236077232125, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 11954.153, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11954.105, "sample_time_ms": 1233.164, "learn_time_ms": 10705.576, "learn_throughput": 373.637, "synch_weights_time_ms": 13.272}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "f0d88_00000", "date": "2024-08-14_10-49-40", "timestamp": 1723646980, "time_this_iter_s": 11.730191230773926, "time_total_s": 199.45931673049927, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac05f550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 199.45931673049927, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 43.80588235294118, "ram_util_percent": 83.56470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5285731577999377, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 4.653637944075165, "policy_loss": -0.03186442086771229, "vf_loss": 4.668243023453567, "vf_explained_var": 0.04733790916109842, "kl": 0.017046248037951347, "entropy": 1.4396417193311863, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.376043662759993, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.323228552984813, "policy_loss": -0.023547362736253828, "vf_loss": 5.327134635839513, "vf_explained_var": -0.03389461138261058, "kl": 0.012932533802922523, "entropy": 1.3846732577318868, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 340.00000000000045, "episode_reward_min": -330.3999999999985, "episode_reward_mean": 38.266999999999946, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -382.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -37.496500000000026, "predator_policy": 56.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-37.19999999999998, -16.099999999999795, 31.600000000000094, 89.00000000000001, -79.10000000000056, -260.8, 5.700000000000372, -32.19999999999982, 10.200000000000001, -77.0000000000002, 26.600000000000247, -330.3999999999985, 2.600000000000194, -58.20000000000013, 59.80000000000033, -17.9999999999998, 92.89999999999937, 110.49999999999962, -41.699999999999825, -28.599999999999667, -10.899999999999977, 25.4, 8.199999999999948, 101.40000000000006, 159.6999999999996, 128.7, 40.40000000000008, 86.09999999999931, 340.00000000000045, 35.2000000000001, 118.49999999999935, -93.70000000000027, 62.40000000000007, 164.39999999999958, -6.5999999999999215, -95.49999999999986, 61.4000000000001, -162.70000000000005, 53.40000000000011, 25.700000000000074, -19.99999999999976, -76.1000000000005, 17.599999999999994, 10.899999999999975, 22.600000000000193, -60.10000000000061, 180.49999999999952, -12.799999999999851, -11.600000000000295, -55.09999999999965, 88.99999999999909, 33.300000000000196, 259.29999999999956, 73.09999999999972, 123.7999999999987, 41.30000000000026, 99.29999999999987, 80.90000000000019, 119.49999999999945, 32.2000000000002, 92.9999999999994, 69.69999999999976, 50.60000000000049, 124.69999999999935, 13.70000000000004, 69.50000000000004, 19.099999999999955, -5.099999999999714, 35.600000000000236, 68.79999999999995, 128.29999999999964, -9.000000000000137, 117.19999999999983, -14.799999999999986, 70.90000000000018, 127.39999999999965, 84.39999999999915, -32.49999999999954, 86.20000000000005, 105.69999999999982, 121.79999999999978, 101.99999999999959, 22.200000000000127, 34.90000000000028, 1.9999999999999847, 35.900000000000254, 40.800000000000146, 30.600000000000186, 30.100000000000144, 36.50000000000023, 46.80000000000011, 124.39999999999951, 52.40000000000009, 87.29999999999905, 155.7999999999993, 6.800000000000081, 21.099999999999994, 30.20000000000023, 56.400000000000325, 146.59999999999945], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.199999999999967, -295.0, -340.0, 17.899999999999988, 20.000000000000014, -117.39999999999992, 82.10000000000004, -45.09999999999982, -170.5000000000003, -109.60000000000025, -263.8, -370.0, -70.30000000000086, 19.99999999999997, -233.2000000000001, 20.000000000000014, -347.8, 20.000000000000014, -307.9, 17.899999999999988, -44.19999999999998, -26.199999999999747, -324.3999999999994, -315.9999999999991, -26.199999999999747, -5.199999999999958, -312.99999999999994, -32.19999999999997, -19.899999999999743, 55.700000000000124, -343.0, 20.000000000000014, 12.499999999999966, -22.59999999999993, 15.799999999999946, 55.70000000000005, 20.000000000000014, -243.7, -28.29999999999977, -214.30000000000038, 20.000000000000014, -190.9, -268.5999999999999, 20.000000000000014, 20.000000000000014, -146.8000000000005, -95.2, 26.60000000000007, -49.299999999999805, 155.00000000000003, 85.69999999999999, -109.0, 16.69999999999999, -157.3, -13.000000000000046, -16.899999999999928, 173.8999999999999, 103.1, -98.7999999999999, 20.000000000000014, 20.000000000000014, 69.50000000000009, -382.9, -26.800000000000153, -64.60000000000005, 20.000000000000014, 93.80000000000001, -18.39999999999999, -180.70000000000024, -40.89999999999998, -29.500000000000014, -373.0, 20.000000000000014, -34.59999999999988, -245.5, -260.1999999999998, 3.1999999999999615, 36.19999999999996, -5.199999999999962, 17.899999999999988, 20.000000000000014, -316.0, -146.20000000000016, -127.90000000000035, -89.20000000000084, 12.799999999999974, -7.299999999999891, -161.8, -66.10000000000065, -25.300000000000026, -195.10000000000014, -127.00000000000074, 13.700000000000014, 57.8000000000001, -12.39999999999995, -189.4000000000002, -157.60000000000008, -9.999999999999815, -9.3999999999999, -243.7000000000001, 7.399999999999965, 20.600000000000062, 11.599999999999964, 13.699999999999964, 123.79999999999978, 120.49999999999994, 20.000000000000014, 52.10000000000018, 91.09999999999985, 22.700000000000056, -58.30000000000003, 11.599999999999964, 52.400000000000006, -3.099999999999958, -8.199999999999797, 52.1000000000001, 7.399999999999965, 85.10000000000008, 20.000000000000014, 3.1999999999999695, 46.400000000000134, 11.599999999999966, 35.000000000000206, -103.30000000000027, 13.699999999999973, 26.900000000000144, 82.09999999999997, 11.599999999999971, -7.299999999999891, -0.9999999999999846, 70.39999999999975, -19.899999999999743, -9.400000000000027, 9.499999999999964, -15.6999999999998, -30.39999999999975, -17.79999999999974, 19.400000000000023, 57.8000000000002, -138.99999999999997, 51.5, 15.799999999999963, -64.30000000000052, -51.70000000000008, -9.399999999999961, 71.6, -130.29999999999995, -2.4999999999999716, 52.09999999999996, 15.799999999999955, 34.40000000000001, 20.000000000000014, 28.700000000000117, 13.699999999999964, -70.30000000000089, -47.19999999999976, 13.699999999999964, 69.49999999999997, -114.70000000000019, 76.40000000000006, 55.70000000000003, 28.1, -38.799999999999756, 27.80000000000004, -82.30000000000067, 9.499999999999964, -20.799999999999812, 13.69999999999999, -106.0000000000008, -55.0, 20.00000000000003, -60.10000000000051, -42.09999999999996, -3.099999999999958, -53.5, -46.9000000000006, 9.499999999999964, 11.599999999999964, -5.1999999999999265, -76.3000000000001, 3.199999999999969, 14.600000000000186, 20.000000000000014, 55.40000000000005, 94.70000000000002, -187.30000000000047, -80.80000000000076, 91.0999999999995, 129.19999999999987, 11.599999999999964, -64.00000000000026, -17.199999999999953, -14.799999999999764, 17.899999999999988, 15.799999999999963, 7.399999999999981, 15.799999999999963, 14.600000000000032, 96.49999999999997, -19.89999999999978], "policy_predator_policy_reward": [130.0, 157.0, 140.0, 166.0, 66.0, 63.0, 31.0, 21.0, 71.0, 130.0, 193.0, 180.0, 47.0, 9.0, 107.0, 74.0, 175.0, 163.0, 98.0, 115.0, 44.0, 53.0, 148.0, 162.0, 1.0, 33.0, 130.0, 157.0, 18.0, 6.0, 132.0, 173.0, 54.0, 49.0, 29.0, 10.0, 50.0, 132.0, 104.0, 110.0, 31.0, 129.0, 142.0, 132.0, 81.0, 54.0, 92.0, 78.0, 22.0, 32.0, 99.0, 53.0, 94.0, 87.0, 72.0, 44.0, 31.0, 32.0, 55.0, 59.0, 12.0, 17.0, 134.0, 182.0, 37.0, 70.0, 32.0, 57.0, 108.0, 107.0, 191.0, 116.0, 50.0, 26.0, 180.0, 163.0, 3.0, 11.0, 1.0, 12.0, 127.0, 149.0, 72.0, 126.0, 52.0, 42.0, 76.0, 104.0, 72.0, 42.0, 137.0, 125.0, 41.0, 68.0, 118.0, 71.0, 34.0, 122.0, 98.0, 100.0, 29.0, 32.0, 4.0, 4.0, 5.0, 10.0, 0.0, 1.0, 6.0, 4.0, 17.0, 71.0, 13.0, 37.0, 27.0, 10.0, 13.0, 14.0, 3.0, 6.0, 22.0, 13.0, 84.0, 54.0, 3.0, 7.0, 15.0, 16.0, 9.0, 13.0, 0.0, 19.0, 14.0, 5.0, 38.0, 3.0, 16.0, 18.0, 61.0, 89.0, 30.0, 31.0, 93.0, 14.0, 32.0, 23.0, 34.0, 84.0, 0.0, 3.0, 50.0, 23.0, 21.0, 21.0, 41.0, 44.0, 3.0, 0.0, 83.0, 61.0, 16.0, 22.0, 59.0, 54.0, 42.0, 53.0, 27.0, 15.0, 97.0, 66.0, 29.0, 47.0, 28.0, 58.0, 104.0, 27.0, 5.0, 4.0, 84.0, 34.0, 8.0, 21.0, 14.0, 35.0, 66.0, 79.0, 38.0, 39.0, 9.0, 6.0, 49.0, 39.0, 17.0, 1.0, 0.0, 7.0, 26.0, 0.0, 34.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7369494754886916, "mean_inference_ms": 1.929233003289166, "mean_action_processing_ms": 0.28969822052776356, "mean_env_wait_ms": 0.25346383704139297, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0034781694412231445, "StateBufferConnector_ms": 0.0029076337814331055, "ViewRequirementAgentConnector_ms": 0.0950242280960083}, "num_episodes": 18, "episode_return_max": 340.00000000000045, "episode_return_min": -330.3999999999985, "episode_return_mean": 38.266999999999946, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.4438592366904, "num_env_steps_trained_throughput_per_sec": 334.4438592366904, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 11956.968, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11956.92, "sample_time_ms": 1276.573, "learn_time_ms": 10664.941, "learn_throughput": 375.061, "synch_weights_time_ms": 13.563}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "f0d88_00000", "date": "2024-08-14_10-49-52", "timestamp": 1723646992, "time_this_iter_s": 11.994972944259644, "time_total_s": 211.4542896747589, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3abfe1e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 211.4542896747589, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 45.852941176470594, "ram_util_percent": 83.49411764705881}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2065282885359707, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 4.693496206828526, "policy_loss": -0.017000890812077733, "vf_loss": 4.6941761198497955, "vf_explained_var": 0.29172064611520715, "kl": 0.016119492080463923, "entropy": 1.4081741148201876, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.593139511630649, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.1483668502676423, "policy_loss": -0.021899457283505293, "vf_loss": 3.152136174459306, "vf_explained_var": -0.004638772193716947, "kl": 0.011937536586501896, "entropy": 1.3874621523751154, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 340.00000000000045, "episode_reward_min": -162.70000000000005, "episode_reward_mean": 63.61599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -382.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": -8.542000000000035, "predator_policy": 40.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.199999999999948, 101.40000000000006, 159.6999999999996, 128.7, 40.40000000000008, 86.09999999999931, 340.00000000000045, 35.2000000000001, 118.49999999999935, -93.70000000000027, 62.40000000000007, 164.39999999999958, -6.5999999999999215, -95.49999999999986, 61.4000000000001, -162.70000000000005, 53.40000000000011, 25.700000000000074, -19.99999999999976, -76.1000000000005, 17.599999999999994, 10.899999999999975, 22.600000000000193, -60.10000000000061, 180.49999999999952, -12.799999999999851, -11.600000000000295, -55.09999999999965, 88.99999999999909, 33.300000000000196, 259.29999999999956, 73.09999999999972, 123.7999999999987, 41.30000000000026, 99.29999999999987, 80.90000000000019, 119.49999999999945, 32.2000000000002, 92.9999999999994, 69.69999999999976, 50.60000000000049, 124.69999999999935, 13.70000000000004, 69.50000000000004, 19.099999999999955, -5.099999999999714, 35.600000000000236, 68.79999999999995, 128.29999999999964, -9.000000000000137, 117.19999999999983, -14.799999999999986, 70.90000000000018, 127.39999999999965, 84.39999999999915, -32.49999999999954, 86.20000000000005, 105.69999999999982, 121.79999999999978, 101.99999999999959, 22.200000000000127, 34.90000000000028, 1.9999999999999847, 35.900000000000254, 40.800000000000146, 30.600000000000186, 30.100000000000144, 36.50000000000023, 46.80000000000011, 124.39999999999951, 52.40000000000009, 87.29999999999905, 155.7999999999993, 6.800000000000081, 21.099999999999994, 30.20000000000023, 56.400000000000325, 146.59999999999945, 133.8999999999998, 169.79999999999941, 188.39999999999975, 9.400000000000098, 17.999999999999957, 131.99999999999915, 58.400000000000055, 31.000000000000185, 109.79999999999976, 126.49999999999957, 158.09999999999943, 203.89999999999972, 26.800000000000093, 62.500000000000114, 73.2, 123.19999999999959, 0.5000000000001183, 248.9999999999997, 14.299999999999914, 33.900000000000226, 28.000000000000107, 48.40000000000044], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -146.8000000000005, -95.2, 26.60000000000007, -49.299999999999805, 155.00000000000003, 85.69999999999999, -109.0, 16.69999999999999, -157.3, -13.000000000000046, -16.899999999999928, 173.8999999999999, 103.1, -98.7999999999999, 20.000000000000014, 20.000000000000014, 69.50000000000009, -382.9, -26.800000000000153, -64.60000000000005, 20.000000000000014, 93.80000000000001, -18.39999999999999, -180.70000000000024, -40.89999999999998, -29.500000000000014, -373.0, 20.000000000000014, -34.59999999999988, -245.5, -260.1999999999998, 3.1999999999999615, 36.19999999999996, -5.199999999999962, 17.899999999999988, 20.000000000000014, -316.0, -146.20000000000016, -127.90000000000035, -89.20000000000084, 12.799999999999974, -7.299999999999891, -161.8, -66.10000000000065, -25.300000000000026, -195.10000000000014, -127.00000000000074, 13.700000000000014, 57.8000000000001, -12.39999999999995, -189.4000000000002, -157.60000000000008, -9.999999999999815, -9.3999999999999, -243.7000000000001, 7.399999999999965, 20.600000000000062, 11.599999999999964, 13.699999999999964, 123.79999999999978, 120.49999999999994, 20.000000000000014, 52.10000000000018, 91.09999999999985, 22.700000000000056, -58.30000000000003, 11.599999999999964, 52.400000000000006, -3.099999999999958, -8.199999999999797, 52.1000000000001, 7.399999999999965, 85.10000000000008, 20.000000000000014, 3.1999999999999695, 46.400000000000134, 11.599999999999966, 35.000000000000206, -103.30000000000027, 13.699999999999973, 26.900000000000144, 82.09999999999997, 11.599999999999971, -7.299999999999891, -0.9999999999999846, 70.39999999999975, -19.899999999999743, -9.400000000000027, 9.499999999999964, -15.6999999999998, -30.39999999999975, -17.79999999999974, 19.400000000000023, 57.8000000000002, -138.99999999999997, 51.5, 15.799999999999963, -64.30000000000052, -51.70000000000008, -9.399999999999961, 71.6, -130.29999999999995, -2.4999999999999716, 52.09999999999996, 15.799999999999955, 34.40000000000001, 20.000000000000014, 28.700000000000117, 13.699999999999964, -70.30000000000089, -47.19999999999976, 13.699999999999964, 69.49999999999997, -114.70000000000019, 76.40000000000006, 55.70000000000003, 28.1, -38.799999999999756, 27.80000000000004, -82.30000000000067, 9.499999999999964, -20.799999999999812, 13.69999999999999, -106.0000000000008, -55.0, 20.00000000000003, -60.10000000000051, -42.09999999999996, -3.099999999999958, -53.5, -46.9000000000006, 9.499999999999964, 11.599999999999964, -5.1999999999999265, -76.3000000000001, 3.199999999999969, 14.600000000000186, 20.000000000000014, 55.40000000000005, 94.70000000000002, -187.30000000000047, -80.80000000000076, 91.0999999999995, 129.19999999999987, 11.599999999999964, -64.00000000000026, -17.199999999999953, -14.799999999999764, 17.899999999999988, 15.799999999999963, 7.399999999999981, 15.799999999999963, 14.600000000000032, 96.49999999999997, -19.89999999999978, 15.499999999999993, -106.6000000000002, -15.699999999999747, 168.49999999999991, 142.69999999999996, -1.3000000000001446, -0.9999999999999992, -34.59999999999975, -3.1000000000000525, 1.0999999999999865, 118.6999999999997, 5.299999999999979, 9.499999999999964, 20.900000000000063, 5.299999999999974, 16.699999999999974, 20.000000000000014, 54.800000000000075, 84.50000000000003, 20.000000000000014, 15.799999999999963, 116.29999999999998, 96.49999999999984, 49.40000000000003, 20.000000000000014, -5.199999999999934, 26.300000000000114, -68.8, 5.299999999999965, 17.9000000000001, 69.20000000000005, 20.000000000000014, -41.19999999999979, -7.299999999999891, 158.59999999999982, 31.400000000000027, -51.399999999999906, 25.700000000000106, 20.000000000000014, 5.899999999999983, 11.599999999999964, 7.399999999999965, 20.000000000000014, 25.4000000000001], "policy_predator_policy_reward": [81.0, 54.0, 92.0, 78.0, 22.0, 32.0, 99.0, 53.0, 94.0, 87.0, 72.0, 44.0, 31.0, 32.0, 55.0, 59.0, 12.0, 17.0, 134.0, 182.0, 37.0, 70.0, 32.0, 57.0, 108.0, 107.0, 191.0, 116.0, 50.0, 26.0, 180.0, 163.0, 3.0, 11.0, 1.0, 12.0, 127.0, 149.0, 72.0, 126.0, 52.0, 42.0, 76.0, 104.0, 72.0, 42.0, 137.0, 125.0, 41.0, 68.0, 118.0, 71.0, 34.0, 122.0, 98.0, 100.0, 29.0, 32.0, 4.0, 4.0, 5.0, 10.0, 0.0, 1.0, 6.0, 4.0, 17.0, 71.0, 13.0, 37.0, 27.0, 10.0, 13.0, 14.0, 3.0, 6.0, 22.0, 13.0, 84.0, 54.0, 3.0, 7.0, 15.0, 16.0, 9.0, 13.0, 0.0, 19.0, 14.0, 5.0, 38.0, 3.0, 16.0, 18.0, 61.0, 89.0, 30.0, 31.0, 93.0, 14.0, 32.0, 23.0, 34.0, 84.0, 0.0, 3.0, 50.0, 23.0, 21.0, 21.0, 41.0, 44.0, 3.0, 0.0, 83.0, 61.0, 16.0, 22.0, 59.0, 54.0, 42.0, 53.0, 27.0, 15.0, 97.0, 66.0, 29.0, 47.0, 28.0, 58.0, 104.0, 27.0, 5.0, 4.0, 84.0, 34.0, 8.0, 21.0, 14.0, 35.0, 66.0, 79.0, 38.0, 39.0, 9.0, 6.0, 49.0, 39.0, 17.0, 1.0, 0.0, 7.0, 26.0, 0.0, 34.0, 36.0, 114.0, 111.0, 17.0, 0.0, 39.0, 8.0, 22.0, 23.0, 5.0, 15.0, 7.0, 1.0, 24.0, 4.0, 6.0, 3.0, 30.0, 5.0, 4.0, 18.0, 8.0, 18.0, 9.0, 49.0, 12.0, 0.0, 48.0, 57.0, 17.0, 33.0, 22.0, 12.0, 17.0, 32.0, 12.0, 47.0, 34.0, 6.0, 8.0, 0.0, 6.0, 3.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7347877733765779, "mean_inference_ms": 1.9251308130564226, "mean_action_processing_ms": 0.2902695076875956, "mean_env_wait_ms": 0.25240486938773243, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00411379337310791, "StateBufferConnector_ms": 0.006955504417419434, "ViewRequirementAgentConnector_ms": 0.10518646240234375}, "num_episodes": 22, "episode_return_max": 340.00000000000045, "episode_return_min": -162.70000000000005, "episode_return_mean": 63.61599999999989, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.2328451168791, "num_env_steps_trained_throughput_per_sec": 326.2328451168791, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 11988.265, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11988.217, "sample_time_ms": 1365.696, "learn_time_ms": 10606.303, "learn_throughput": 377.134, "synch_weights_time_ms": 14.506}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "f0d88_00000", "date": "2024-08-14_10-50-04", "timestamp": 1723647004, "time_this_iter_s": 12.37612795829773, "time_total_s": 223.83041763305664, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4bcaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 223.83041763305664, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 43.235294117647065, "ram_util_percent": 83.11764705882354}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7830194571030833, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 3.9419991801024743, "policy_loss": -0.027870238761210607, "vf_loss": 3.9539442337379254, "vf_explained_var": 0.3873848092303705, "kl": 0.01572858566982966, "entropy": 1.4271683509387667, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2055101689207492, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.7360059336379723, "policy_loss": -0.02807709194803561, "vf_loss": 1.7472581955806288, "vf_explained_var": 0.07353938887358974, "kl": 0.011078078901952178, "entropy": 1.3559436542647225, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 259.29999999999956, "episode_reward_min": -61.10000000000121, "episode_reward_mean": 71.43399999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -243.7000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.49999999999991, "predator_policy": 137.0}, "policy_reward_mean": {"prey_policy": 8.19199999999997, "predator_policy": 27.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-60.10000000000061, 180.49999999999952, -12.799999999999851, -11.600000000000295, -55.09999999999965, 88.99999999999909, 33.300000000000196, 259.29999999999956, 73.09999999999972, 123.7999999999987, 41.30000000000026, 99.29999999999987, 80.90000000000019, 119.49999999999945, 32.2000000000002, 92.9999999999994, 69.69999999999976, 50.60000000000049, 124.69999999999935, 13.70000000000004, 69.50000000000004, 19.099999999999955, -5.099999999999714, 35.600000000000236, 68.79999999999995, 128.29999999999964, -9.000000000000137, 117.19999999999983, -14.799999999999986, 70.90000000000018, 127.39999999999965, 84.39999999999915, -32.49999999999954, 86.20000000000005, 105.69999999999982, 121.79999999999978, 101.99999999999959, 22.200000000000127, 34.90000000000028, 1.9999999999999847, 35.900000000000254, 40.800000000000146, 30.600000000000186, 30.100000000000144, 36.50000000000023, 46.80000000000011, 124.39999999999951, 52.40000000000009, 87.29999999999905, 155.7999999999993, 6.800000000000081, 21.099999999999994, 30.20000000000023, 56.400000000000325, 146.59999999999945, 133.8999999999998, 169.79999999999941, 188.39999999999975, 9.400000000000098, 17.999999999999957, 131.99999999999915, 58.400000000000055, 31.000000000000185, 109.79999999999976, 126.49999999999957, 158.09999999999943, 203.89999999999972, 26.800000000000093, 62.500000000000114, 73.2, 123.19999999999959, 0.5000000000001183, 248.9999999999997, 14.299999999999914, 33.900000000000226, 28.000000000000107, 48.40000000000044, 139.89999999999947, 126.79999999999954, 17.799999999999983, 3.9000000000002024, 1.5000000000003753, 46.3000000000004, 30.100000000000165, 102.59999999999972, -61.10000000000121, 69.50000000000006, 31.0000000000002, 201.79999999999976, 109.39999999999954, 29.500000000000174, 32.30000000000019, 153.9999999999994, 129.29999999999947, 113.09999999999974, 37.700000000000266, 72.30000000000011, 159.89999999999904, 50.7000000000004, 165.4999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-195.10000000000014, -127.00000000000074, 13.700000000000014, 57.8000000000001, -12.39999999999995, -189.4000000000002, -157.60000000000008, -9.999999999999815, -9.3999999999999, -243.7000000000001, 7.399999999999965, 20.600000000000062, 11.599999999999964, 13.699999999999964, 123.79999999999978, 120.49999999999994, 20.000000000000014, 52.10000000000018, 91.09999999999985, 22.700000000000056, -58.30000000000003, 11.599999999999964, 52.400000000000006, -3.099999999999958, -8.199999999999797, 52.1000000000001, 7.399999999999965, 85.10000000000008, 20.000000000000014, 3.1999999999999695, 46.400000000000134, 11.599999999999966, 35.000000000000206, -103.30000000000027, 13.699999999999973, 26.900000000000144, 82.09999999999997, 11.599999999999971, -7.299999999999891, -0.9999999999999846, 70.39999999999975, -19.899999999999743, -9.400000000000027, 9.499999999999964, -15.6999999999998, -30.39999999999975, -17.79999999999974, 19.400000000000023, 57.8000000000002, -138.99999999999997, 51.5, 15.799999999999963, -64.30000000000052, -51.70000000000008, -9.399999999999961, 71.6, -130.29999999999995, -2.4999999999999716, 52.09999999999996, 15.799999999999955, 34.40000000000001, 20.000000000000014, 28.700000000000117, 13.699999999999964, -70.30000000000089, -47.19999999999976, 13.699999999999964, 69.49999999999997, -114.70000000000019, 76.40000000000006, 55.70000000000003, 28.1, -38.799999999999756, 27.80000000000004, -82.30000000000067, 9.499999999999964, -20.799999999999812, 13.69999999999999, -106.0000000000008, -55.0, 20.00000000000003, -60.10000000000051, -42.09999999999996, -3.099999999999958, -53.5, -46.9000000000006, 9.499999999999964, 11.599999999999964, -5.1999999999999265, -76.3000000000001, 3.199999999999969, 14.600000000000186, 20.000000000000014, 55.40000000000005, 94.70000000000002, -187.30000000000047, -80.80000000000076, 91.0999999999995, 129.19999999999987, 11.599999999999964, -64.00000000000026, -17.199999999999953, -14.799999999999764, 17.899999999999988, 15.799999999999963, 7.399999999999981, 15.799999999999963, 14.600000000000032, 96.49999999999997, -19.89999999999978, 15.499999999999993, -106.6000000000002, -15.699999999999747, 168.49999999999991, 142.69999999999996, -1.3000000000001446, -0.9999999999999992, -34.59999999999975, -3.1000000000000525, 1.0999999999999865, 118.6999999999997, 5.299999999999979, 9.499999999999964, 20.900000000000063, 5.299999999999974, 16.699999999999974, 20.000000000000014, 54.800000000000075, 84.50000000000003, 20.000000000000014, 15.799999999999963, 116.29999999999998, 96.49999999999984, 49.40000000000003, 20.000000000000014, -5.199999999999934, 26.300000000000114, -68.8, 5.299999999999965, 17.9000000000001, 69.20000000000005, 20.000000000000014, -41.19999999999979, -7.299999999999891, 158.59999999999982, 31.400000000000027, -51.399999999999906, 25.700000000000106, 20.000000000000014, 5.899999999999983, 11.599999999999964, 7.399999999999965, 20.000000000000014, 25.4000000000001, 108.79999999999993, 1.0999999999999723, 79.09999999999985, 19.699999999999978, -11.499999999999925, 5.299999999999965, -21.999999999999744, -3.099999999999958, -29.19999999999979, -28.299999999999763, 20.000000000000014, 26.300000000000114, 1.0999999999999603, 20.000000000000014, 20.000000000000014, 29.599999999999916, -70.3000000000008, -110.80000000000064, -50.49999999999984, 28.99999999999997, 15.799999999999981, 6.1999999999999655, 89.89999999999995, 74.9, -17.79999999999975, 96.19999999999999, 17.599999999999977, -3.099999999999958, 20.000000000000014, 5.2999999999999705, -30.39999999999975, 160.39999999999986, -64.00000000000088, 143.29999999999987, 73.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, -34.60000000000013, 18.199999999999996, 91.70000000000005, 21.800000000000043, 23.900000000000055, 17.899999999999988, 140.6], "policy_predator_policy_reward": [137.0, 125.0, 41.0, 68.0, 118.0, 71.0, 34.0, 122.0, 98.0, 100.0, 29.0, 32.0, 4.0, 4.0, 5.0, 10.0, 0.0, 1.0, 6.0, 4.0, 17.0, 71.0, 13.0, 37.0, 27.0, 10.0, 13.0, 14.0, 3.0, 6.0, 22.0, 13.0, 84.0, 54.0, 3.0, 7.0, 15.0, 16.0, 9.0, 13.0, 0.0, 19.0, 14.0, 5.0, 38.0, 3.0, 16.0, 18.0, 61.0, 89.0, 30.0, 31.0, 93.0, 14.0, 32.0, 23.0, 34.0, 84.0, 0.0, 3.0, 50.0, 23.0, 21.0, 21.0, 41.0, 44.0, 3.0, 0.0, 83.0, 61.0, 16.0, 22.0, 59.0, 54.0, 42.0, 53.0, 27.0, 15.0, 97.0, 66.0, 29.0, 47.0, 28.0, 58.0, 104.0, 27.0, 5.0, 4.0, 84.0, 34.0, 8.0, 21.0, 14.0, 35.0, 66.0, 79.0, 38.0, 39.0, 9.0, 6.0, 49.0, 39.0, 17.0, 1.0, 0.0, 7.0, 26.0, 0.0, 34.0, 36.0, 114.0, 111.0, 17.0, 0.0, 39.0, 8.0, 22.0, 23.0, 5.0, 15.0, 7.0, 1.0, 24.0, 4.0, 6.0, 3.0, 30.0, 5.0, 4.0, 18.0, 8.0, 18.0, 9.0, 49.0, 12.0, 0.0, 48.0, 57.0, 17.0, 33.0, 22.0, 12.0, 17.0, 32.0, 12.0, 47.0, 34.0, 6.0, 8.0, 0.0, 6.0, 3.0, 3.0, 0.0, 16.0, 14.0, 24.0, 4.0, 15.0, 9.0, 14.0, 15.0, 18.0, 41.0, 0.0, 0.0, 1.0, 8.0, 10.0, 43.0, 64.0, 56.0, 45.0, 46.0, 0.0, 9.0, 15.0, 22.0, 4.0, 27.0, 4.0, 11.0, 7.0, 0.0, 24.0, 0.0, 40.0, 10.0, 9.0, 11.0, 3.0, 1.0, 21.0, 68.0, 29.0, 21.0, 5.0, 0.0, 6.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7374692781800576, "mean_inference_ms": 1.9359479579419199, "mean_action_processing_ms": 0.2935121561721786, "mean_env_wait_ms": 0.25416839314363715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004962921142578125, "StateBufferConnector_ms": 0.007264375686645508, "ViewRequirementAgentConnector_ms": 0.13691508769989014}, "num_episodes": 23, "episode_return_max": 259.29999999999956, "episode_return_min": -61.10000000000121, "episode_return_mean": 71.43399999999987, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.40801854777743, "num_env_steps_trained_throughput_per_sec": 319.40801854777743, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 12024.463, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12024.417, "sample_time_ms": 1444.692, "learn_time_ms": 10561.531, "learn_throughput": 378.733, "synch_weights_time_ms": 16.533}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "f0d88_00000", "date": "2024-08-14_10-50-17", "timestamp": 1723647017, "time_this_iter_s": 12.610482215881348, "time_total_s": 236.440899848938, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac05f8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 236.440899848938, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 44.50555555555556, "ram_util_percent": 83.37777777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4431302031196616, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 5.654994977718939, "policy_loss": -0.026077195568251665, "vf_loss": 5.661216738615087, "vf_explained_var": 0.3155147596011086, "kl": 0.01961031948105613, "entropy": 1.386643609924922, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.358737714139242, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.35571277942607, "policy_loss": -0.028195672920318667, "vf_loss": 2.368368197496606, "vf_explained_var": 0.049147601417763524, "kl": 0.01023226587537127, "entropy": 1.3367778495506004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 248.9999999999997, "episode_reward_min": -61.10000000000121, "episode_reward_mean": 78.39099999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -200.49999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 13.185499999999966, "predator_policy": 26.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [124.69999999999935, 13.70000000000004, 69.50000000000004, 19.099999999999955, -5.099999999999714, 35.600000000000236, 68.79999999999995, 128.29999999999964, -9.000000000000137, 117.19999999999983, -14.799999999999986, 70.90000000000018, 127.39999999999965, 84.39999999999915, -32.49999999999954, 86.20000000000005, 105.69999999999982, 121.79999999999978, 101.99999999999959, 22.200000000000127, 34.90000000000028, 1.9999999999999847, 35.900000000000254, 40.800000000000146, 30.600000000000186, 30.100000000000144, 36.50000000000023, 46.80000000000011, 124.39999999999951, 52.40000000000009, 87.29999999999905, 155.7999999999993, 6.800000000000081, 21.099999999999994, 30.20000000000023, 56.400000000000325, 146.59999999999945, 133.8999999999998, 169.79999999999941, 188.39999999999975, 9.400000000000098, 17.999999999999957, 131.99999999999915, 58.400000000000055, 31.000000000000185, 109.79999999999976, 126.49999999999957, 158.09999999999943, 203.89999999999972, 26.800000000000093, 62.500000000000114, 73.2, 123.19999999999959, 0.5000000000001183, 248.9999999999997, 14.299999999999914, 33.900000000000226, 28.000000000000107, 48.40000000000044, 139.89999999999947, 126.79999999999954, 17.799999999999983, 3.9000000000002024, 1.5000000000003753, 46.3000000000004, 30.100000000000165, 102.59999999999972, -61.10000000000121, 69.50000000000006, 31.0000000000002, 201.79999999999976, 109.39999999999954, 29.500000000000174, 32.30000000000019, 153.9999999999994, 129.29999999999947, 113.09999999999974, 37.700000000000266, 72.30000000000011, 159.89999999999904, 50.7000000000004, 165.4999999999994, 192.39999999999912, 79.49999999999996, 11.199999999999987, 5.600000000000109, 25.60000000000009, 117.29999999999971, 104.69999999999979, 236.4999999999996, 118.29999999999967, 1.200000000000179, 21.400000000000006, 183.5999999999993, 78.50000000000009, 176.7999999999996, 116.2999999999998, 230.6999999999997, 112.09999999999977, 89.89999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [82.09999999999997, 11.599999999999971, -7.299999999999891, -0.9999999999999846, 70.39999999999975, -19.899999999999743, -9.400000000000027, 9.499999999999964, -15.6999999999998, -30.39999999999975, -17.79999999999974, 19.400000000000023, 57.8000000000002, -138.99999999999997, 51.5, 15.799999999999963, -64.30000000000052, -51.70000000000008, -9.399999999999961, 71.6, -130.29999999999995, -2.4999999999999716, 52.09999999999996, 15.799999999999955, 34.40000000000001, 20.000000000000014, 28.700000000000117, 13.699999999999964, -70.30000000000089, -47.19999999999976, 13.699999999999964, 69.49999999999997, -114.70000000000019, 76.40000000000006, 55.70000000000003, 28.1, -38.799999999999756, 27.80000000000004, -82.30000000000067, 9.499999999999964, -20.799999999999812, 13.69999999999999, -106.0000000000008, -55.0, 20.00000000000003, -60.10000000000051, -42.09999999999996, -3.099999999999958, -53.5, -46.9000000000006, 9.499999999999964, 11.599999999999964, -5.1999999999999265, -76.3000000000001, 3.199999999999969, 14.600000000000186, 20.000000000000014, 55.40000000000005, 94.70000000000002, -187.30000000000047, -80.80000000000076, 91.0999999999995, 129.19999999999987, 11.599999999999964, -64.00000000000026, -17.199999999999953, -14.799999999999764, 17.899999999999988, 15.799999999999963, 7.399999999999981, 15.799999999999963, 14.600000000000032, 96.49999999999997, -19.89999999999978, 15.499999999999993, -106.6000000000002, -15.699999999999747, 168.49999999999991, 142.69999999999996, -1.3000000000001446, -0.9999999999999992, -34.59999999999975, -3.1000000000000525, 1.0999999999999865, 118.6999999999997, 5.299999999999979, 9.499999999999964, 20.900000000000063, 5.299999999999974, 16.699999999999974, 20.000000000000014, 54.800000000000075, 84.50000000000003, 20.000000000000014, 15.799999999999963, 116.29999999999998, 96.49999999999984, 49.40000000000003, 20.000000000000014, -5.199999999999934, 26.300000000000114, -68.8, 5.299999999999965, 17.9000000000001, 69.20000000000005, 20.000000000000014, -41.19999999999979, -7.299999999999891, 158.59999999999982, 31.400000000000027, -51.399999999999906, 25.700000000000106, 20.000000000000014, 5.899999999999983, 11.599999999999964, 7.399999999999965, 20.000000000000014, 25.4000000000001, 108.79999999999993, 1.0999999999999723, 79.09999999999985, 19.699999999999978, -11.499999999999925, 5.299999999999965, -21.999999999999744, -3.099999999999958, -29.19999999999979, -28.299999999999763, 20.000000000000014, 26.300000000000114, 1.0999999999999603, 20.000000000000014, 20.000000000000014, 29.599999999999916, -70.3000000000008, -110.80000000000064, -50.49999999999984, 28.99999999999997, 15.799999999999981, 6.1999999999999655, 89.89999999999995, 74.9, -17.79999999999975, 96.19999999999999, 17.599999999999977, -3.099999999999958, 20.000000000000014, 5.2999999999999705, -30.39999999999975, 160.39999999999986, -64.00000000000088, 143.29999999999987, 73.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, -34.60000000000013, 18.199999999999996, 91.70000000000005, 21.800000000000043, 23.900000000000055, 17.899999999999988, 140.6, 173.8999999999999, 9.499999999999964, 13.700000000000069, 15.799999999999963, 11.599999999999964, -30.399999999999757, -13.59999999999979, -86.80000000000015, -1.0000000000000275, -0.40000000000004365, 7.399999999999965, 77.90000000000003, 111.19999999999982, -200.49999999999994, 80.00000000000001, 117.49999999999994, -11.499999999999883, 87.79999999999997, 20.000000000000014, -80.80000000000086, 1.0999999999999865, 5.299999999999965, 131.8999999999998, 49.69999999999997, -150.40000000000003, 17.899999999999988, 15.800000000000024, 77.00000000000003, 136.0999999999999, -98.80000000000078, 98.89999999999985, 105.79999999999995, 88.40000000000002, -7.299999999999891, -13.599999999999783, 42.50000000000003], "policy_predator_policy_reward": [15.0, 16.0, 9.0, 13.0, 0.0, 19.0, 14.0, 5.0, 38.0, 3.0, 16.0, 18.0, 61.0, 89.0, 30.0, 31.0, 93.0, 14.0, 32.0, 23.0, 34.0, 84.0, 0.0, 3.0, 50.0, 23.0, 21.0, 21.0, 41.0, 44.0, 3.0, 0.0, 83.0, 61.0, 16.0, 22.0, 59.0, 54.0, 42.0, 53.0, 27.0, 15.0, 97.0, 66.0, 29.0, 47.0, 28.0, 58.0, 104.0, 27.0, 5.0, 4.0, 84.0, 34.0, 8.0, 21.0, 14.0, 35.0, 66.0, 79.0, 38.0, 39.0, 9.0, 6.0, 49.0, 39.0, 17.0, 1.0, 0.0, 7.0, 26.0, 0.0, 34.0, 36.0, 114.0, 111.0, 17.0, 0.0, 39.0, 8.0, 22.0, 23.0, 5.0, 15.0, 7.0, 1.0, 24.0, 4.0, 6.0, 3.0, 30.0, 5.0, 4.0, 18.0, 8.0, 18.0, 9.0, 49.0, 12.0, 0.0, 48.0, 57.0, 17.0, 33.0, 22.0, 12.0, 17.0, 32.0, 12.0, 47.0, 34.0, 6.0, 8.0, 0.0, 6.0, 3.0, 3.0, 0.0, 16.0, 14.0, 24.0, 4.0, 15.0, 9.0, 14.0, 15.0, 18.0, 41.0, 0.0, 0.0, 1.0, 8.0, 10.0, 43.0, 64.0, 56.0, 45.0, 46.0, 0.0, 9.0, 15.0, 22.0, 4.0, 27.0, 4.0, 11.0, 7.0, 0.0, 24.0, 0.0, 40.0, 10.0, 9.0, 11.0, 3.0, 1.0, 21.0, 68.0, 29.0, 21.0, 5.0, 0.0, 6.0, 1.0, 5.0, 4.0, 11.0, 39.0, 2.0, 28.0, 33.0, 73.0, 13.0, 14.0, 26.0, 6.0, 118.0, 76.0, 22.0, 17.0, 23.0, 19.0, 48.0, 14.0, 6.0, 9.0, 2.0, 0.0, 109.0, 102.0, 52.0, 32.0, 29.0, 50.0, 20.0, 6.0, 2.0, 29.0, 16.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7419558421455511, "mean_inference_ms": 1.9485311867851838, "mean_action_processing_ms": 0.29647846560246516, "mean_env_wait_ms": 0.2557746858442099, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004982352256774902, "StateBufferConnector_ms": 0.007289767265319824, "ViewRequirementAgentConnector_ms": 0.1429121494293213}, "num_episodes": 18, "episode_return_max": 248.9999999999997, "episode_return_min": -61.10000000000121, "episode_return_mean": 78.39099999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.0039064584876, "num_env_steps_trained_throughput_per_sec": 333.0039064584876, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 12028.756, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12028.709, "sample_time_ms": 1495.396, "learn_time_ms": 10513.705, "learn_throughput": 380.456, "synch_weights_time_ms": 17.786}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "f0d88_00000", "date": "2024-08-14_10-50-29", "timestamp": 1723647029, "time_this_iter_s": 12.05282473564148, "time_total_s": 248.49372458457947, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac05fee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 248.49372458457947, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 47.30555555555556, "ram_util_percent": 83.48888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.378206978336213, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 5.5649492604391915, "policy_loss": -0.025691295849903432, "vf_loss": 5.575615831153103, "vf_explained_var": 0.5128771682895681, "kl": 0.014839237578929031, "entropy": 1.3810770879977594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4432428908726527, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.0045031352017921, "policy_loss": -0.024910840671755887, "vf_loss": 1.014161214390129, "vf_explained_var": 0.0726168331645784, "kl": 0.010042970066772088, "entropy": 1.3469850010972806, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 293.5999999999999, "episode_reward_min": -61.10000000000121, "episode_reward_mean": 91.46799999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -200.49999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 21.43399999999995, "predator_policy": 24.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [101.99999999999959, 22.200000000000127, 34.90000000000028, 1.9999999999999847, 35.900000000000254, 40.800000000000146, 30.600000000000186, 30.100000000000144, 36.50000000000023, 46.80000000000011, 124.39999999999951, 52.40000000000009, 87.29999999999905, 155.7999999999993, 6.800000000000081, 21.099999999999994, 30.20000000000023, 56.400000000000325, 146.59999999999945, 133.8999999999998, 169.79999999999941, 188.39999999999975, 9.400000000000098, 17.999999999999957, 131.99999999999915, 58.400000000000055, 31.000000000000185, 109.79999999999976, 126.49999999999957, 158.09999999999943, 203.89999999999972, 26.800000000000093, 62.500000000000114, 73.2, 123.19999999999959, 0.5000000000001183, 248.9999999999997, 14.299999999999914, 33.900000000000226, 28.000000000000107, 48.40000000000044, 139.89999999999947, 126.79999999999954, 17.799999999999983, 3.9000000000002024, 1.5000000000003753, 46.3000000000004, 30.100000000000165, 102.59999999999972, -61.10000000000121, 69.50000000000006, 31.0000000000002, 201.79999999999976, 109.39999999999954, 29.500000000000174, 32.30000000000019, 153.9999999999994, 129.29999999999947, 113.09999999999974, 37.700000000000266, 72.30000000000011, 159.89999999999904, 50.7000000000004, 165.4999999999994, 192.39999999999912, 79.49999999999996, 11.199999999999987, 5.600000000000109, 25.60000000000009, 117.29999999999971, 104.69999999999979, 236.4999999999996, 118.29999999999967, 1.200000000000179, 21.400000000000006, 183.5999999999993, 78.50000000000009, 176.7999999999996, 116.2999999999998, 230.6999999999997, 112.09999999999977, 89.89999999999992, 104.99999999999977, 144.49999999999932, 130.89999999999958, 293.5999999999999, 126.49999999999957, 91.39999999999944, 78.59999999999978, 105.1999999999995, 160.1999999999996, 164.89999999999927, 191.19999999999985, 160.79999999999941, 165.89999999999975, 144.89999999999984, 40.0000000000003, 76.9999999999997, 140.19999999999928, 98.79999999999927], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-38.799999999999756, 27.80000000000004, -82.30000000000067, 9.499999999999964, -20.799999999999812, 13.69999999999999, -106.0000000000008, -55.0, 20.00000000000003, -60.10000000000051, -42.09999999999996, -3.099999999999958, -53.5, -46.9000000000006, 9.499999999999964, 11.599999999999964, -5.1999999999999265, -76.3000000000001, 3.199999999999969, 14.600000000000186, 20.000000000000014, 55.40000000000005, 94.70000000000002, -187.30000000000047, -80.80000000000076, 91.0999999999995, 129.19999999999987, 11.599999999999964, -64.00000000000026, -17.199999999999953, -14.799999999999764, 17.899999999999988, 15.799999999999963, 7.399999999999981, 15.799999999999963, 14.600000000000032, 96.49999999999997, -19.89999999999978, 15.499999999999993, -106.6000000000002, -15.699999999999747, 168.49999999999991, 142.69999999999996, -1.3000000000001446, -0.9999999999999992, -34.59999999999975, -3.1000000000000525, 1.0999999999999865, 118.6999999999997, 5.299999999999979, 9.499999999999964, 20.900000000000063, 5.299999999999974, 16.699999999999974, 20.000000000000014, 54.800000000000075, 84.50000000000003, 20.000000000000014, 15.799999999999963, 116.29999999999998, 96.49999999999984, 49.40000000000003, 20.000000000000014, -5.199999999999934, 26.300000000000114, -68.8, 5.299999999999965, 17.9000000000001, 69.20000000000005, 20.000000000000014, -41.19999999999979, -7.299999999999891, 158.59999999999982, 31.400000000000027, -51.399999999999906, 25.700000000000106, 20.000000000000014, 5.899999999999983, 11.599999999999964, 7.399999999999965, 20.000000000000014, 25.4000000000001, 108.79999999999993, 1.0999999999999723, 79.09999999999985, 19.699999999999978, -11.499999999999925, 5.299999999999965, -21.999999999999744, -3.099999999999958, -29.19999999999979, -28.299999999999763, 20.000000000000014, 26.300000000000114, 1.0999999999999603, 20.000000000000014, 20.000000000000014, 29.599999999999916, -70.3000000000008, -110.80000000000064, -50.49999999999984, 28.99999999999997, 15.799999999999981, 6.1999999999999655, 89.89999999999995, 74.9, -17.79999999999975, 96.19999999999999, 17.599999999999977, -3.099999999999958, 20.000000000000014, 5.2999999999999705, -30.39999999999975, 160.39999999999986, -64.00000000000088, 143.29999999999987, 73.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, -34.60000000000013, 18.199999999999996, 91.70000000000005, 21.800000000000043, 23.900000000000055, 17.899999999999988, 140.6, 173.8999999999999, 9.499999999999964, 13.700000000000069, 15.799999999999963, 11.599999999999964, -30.399999999999757, -13.59999999999979, -86.80000000000015, -1.0000000000000275, -0.40000000000004365, 7.399999999999965, 77.90000000000003, 111.19999999999982, -200.49999999999994, 80.00000000000001, 117.49999999999994, -11.499999999999883, 87.79999999999997, 20.000000000000014, -80.80000000000086, 1.0999999999999865, 5.299999999999965, 131.8999999999998, 49.69999999999997, -150.40000000000003, 17.899999999999988, 15.800000000000024, 77.00000000000003, 136.0999999999999, -98.80000000000078, 98.89999999999985, 105.79999999999995, 88.40000000000002, -7.299999999999891, -13.599999999999783, 42.50000000000003, -17.79999999999974, 87.80000000000001, -68.20000000000087, 148.69999999999973, 13.699999999999964, 99.20000000000003, 129.19999999999982, 154.39999999999986, 97.09999999999997, 7.399999999999965, 1.0999999999999865, 68.29999999999983, -3.1000000000001613, -1.3000000000000913, 59.0000000000001, 3.199999999999971, 61.69999999999999, 48.50000000000002, 146.89999999999975, 7.99999999999997, 134.29999999999976, -75.10000000000016, 129.79999999999995, 20.000000000000014, 104.89999999999998, 23.000000000000036, 97.69999999999993, -26.80000000000009, 20.000000000000014, 20.000000000000014, -7.600000000000001, 41.600000000000094, 110.29999999999984, 17.899999999999988, 20.000000000000014, 42.8000000000001], "policy_predator_policy_reward": [59.0, 54.0, 42.0, 53.0, 27.0, 15.0, 97.0, 66.0, 29.0, 47.0, 28.0, 58.0, 104.0, 27.0, 5.0, 4.0, 84.0, 34.0, 8.0, 21.0, 14.0, 35.0, 66.0, 79.0, 38.0, 39.0, 9.0, 6.0, 49.0, 39.0, 17.0, 1.0, 0.0, 7.0, 26.0, 0.0, 34.0, 36.0, 114.0, 111.0, 17.0, 0.0, 39.0, 8.0, 22.0, 23.0, 5.0, 15.0, 7.0, 1.0, 24.0, 4.0, 6.0, 3.0, 30.0, 5.0, 4.0, 18.0, 8.0, 18.0, 9.0, 49.0, 12.0, 0.0, 48.0, 57.0, 17.0, 33.0, 22.0, 12.0, 17.0, 32.0, 12.0, 47.0, 34.0, 6.0, 8.0, 0.0, 6.0, 3.0, 3.0, 0.0, 16.0, 14.0, 24.0, 4.0, 15.0, 9.0, 14.0, 15.0, 18.0, 41.0, 0.0, 0.0, 1.0, 8.0, 10.0, 43.0, 64.0, 56.0, 45.0, 46.0, 0.0, 9.0, 15.0, 22.0, 4.0, 27.0, 4.0, 11.0, 7.0, 0.0, 24.0, 0.0, 40.0, 10.0, 9.0, 11.0, 3.0, 1.0, 21.0, 68.0, 29.0, 21.0, 5.0, 0.0, 6.0, 1.0, 5.0, 4.0, 11.0, 39.0, 2.0, 28.0, 33.0, 73.0, 13.0, 14.0, 26.0, 6.0, 118.0, 76.0, 22.0, 17.0, 23.0, 19.0, 48.0, 14.0, 6.0, 9.0, 2.0, 0.0, 109.0, 102.0, 52.0, 32.0, 29.0, 50.0, 20.0, 6.0, 2.0, 29.0, 16.0, 45.0, 29.0, 6.0, 42.0, 22.0, 0.0, 18.0, 8.0, 2.0, 8.0, 14.0, 13.0, 9.0, 21.0, 62.0, 21.0, 22.0, 36.0, 14.0, 0.0, 10.0, 50.0, 82.0, 6.0, 5.0, 8.0, 30.0, 11.0, 63.0, 0.0, 0.0, 38.0, 5.0, 0.0, 12.0, 28.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7482484400775425, "mean_inference_ms": 1.9650759192213945, "mean_action_processing_ms": 0.29985213809774847, "mean_env_wait_ms": 0.25777310700200096, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005008101463317871, "StateBufferConnector_ms": 0.007288336753845215, "ViewRequirementAgentConnector_ms": 0.1410454511642456}, "num_episodes": 18, "episode_return_max": 293.5999999999999, "episode_return_min": -61.10000000000121, "episode_return_mean": 91.46799999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.08904301795735, "num_env_steps_trained_throughput_per_sec": 341.08904301795735, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 12014.505, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12014.456, "sample_time_ms": 1530.377, "learn_time_ms": 10462.656, "learn_throughput": 382.312, "synch_weights_time_ms": 19.043}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "f0d88_00000", "date": "2024-08-14_10-50-41", "timestamp": 1723647041, "time_this_iter_s": 11.80375075340271, "time_total_s": 260.2974753379822, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e2550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 260.2974753379822, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 40.825, "ram_util_percent": 83.475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.264556868082632, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 4.846318029348182, "policy_loss": -0.04428851934588421, "vf_loss": 4.873333805452579, "vf_explained_var": 0.30319845203369383, "kl": 0.01705948596757783, "entropy": 1.3844600417626598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.820757028097829, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.534642453389193, "policy_loss": -0.029462142378737333, "vf_loss": 1.550468755746014, "vf_explained_var": -0.003727153432432306, "kl": 0.008978328643858674, "entropy": 1.2971744891196961, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 293.5999999999999, "episode_reward_min": -61.10000000000121, "episode_reward_mean": 101.46199999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -200.49999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 29.575999999999958, "predator_policy": 21.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [146.59999999999945, 133.8999999999998, 169.79999999999941, 188.39999999999975, 9.400000000000098, 17.999999999999957, 131.99999999999915, 58.400000000000055, 31.000000000000185, 109.79999999999976, 126.49999999999957, 158.09999999999943, 203.89999999999972, 26.800000000000093, 62.500000000000114, 73.2, 123.19999999999959, 0.5000000000001183, 248.9999999999997, 14.299999999999914, 33.900000000000226, 28.000000000000107, 48.40000000000044, 139.89999999999947, 126.79999999999954, 17.799999999999983, 3.9000000000002024, 1.5000000000003753, 46.3000000000004, 30.100000000000165, 102.59999999999972, -61.10000000000121, 69.50000000000006, 31.0000000000002, 201.79999999999976, 109.39999999999954, 29.500000000000174, 32.30000000000019, 153.9999999999994, 129.29999999999947, 113.09999999999974, 37.700000000000266, 72.30000000000011, 159.89999999999904, 50.7000000000004, 165.4999999999994, 192.39999999999912, 79.49999999999996, 11.199999999999987, 5.600000000000109, 25.60000000000009, 117.29999999999971, 104.69999999999979, 236.4999999999996, 118.29999999999967, 1.200000000000179, 21.400000000000006, 183.5999999999993, 78.50000000000009, 176.7999999999996, 116.2999999999998, 230.6999999999997, 112.09999999999977, 89.89999999999992, 104.99999999999977, 144.49999999999932, 130.89999999999958, 293.5999999999999, 126.49999999999957, 91.39999999999944, 78.59999999999978, 105.1999999999995, 160.1999999999996, 164.89999999999927, 191.19999999999985, 160.79999999999941, 165.89999999999975, 144.89999999999984, 40.0000000000003, 76.9999999999997, 140.19999999999928, 98.79999999999927, 161.4999999999991, 222.49999999999946, 33.2000000000002, 121.69999999999956, 110.99999999999906, 35.600000000000236, 33.30000000000022, 34.200000000000216, 162.69999999999956, 166.49999999999997, 149.59999999999948, 231.7999999999992, 38.80000000000028, 128.09999999999934, 22.900000000000027, 123.29999999999973, 163.6999999999994, -24.800000000000473], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [96.49999999999997, -19.89999999999978, 15.499999999999993, -106.6000000000002, -15.699999999999747, 168.49999999999991, 142.69999999999996, -1.3000000000001446, -0.9999999999999992, -34.59999999999975, -3.1000000000000525, 1.0999999999999865, 118.6999999999997, 5.299999999999979, 9.499999999999964, 20.900000000000063, 5.299999999999974, 16.699999999999974, 20.000000000000014, 54.800000000000075, 84.50000000000003, 20.000000000000014, 15.799999999999963, 116.29999999999998, 96.49999999999984, 49.40000000000003, 20.000000000000014, -5.199999999999934, 26.300000000000114, -68.8, 5.299999999999965, 17.9000000000001, 69.20000000000005, 20.000000000000014, -41.19999999999979, -7.299999999999891, 158.59999999999982, 31.400000000000027, -51.399999999999906, 25.700000000000106, 20.000000000000014, 5.899999999999983, 11.599999999999964, 7.399999999999965, 20.000000000000014, 25.4000000000001, 108.79999999999993, 1.0999999999999723, 79.09999999999985, 19.699999999999978, -11.499999999999925, 5.299999999999965, -21.999999999999744, -3.099999999999958, -29.19999999999979, -28.299999999999763, 20.000000000000014, 26.300000000000114, 1.0999999999999603, 20.000000000000014, 20.000000000000014, 29.599999999999916, -70.3000000000008, -110.80000000000064, -50.49999999999984, 28.99999999999997, 15.799999999999981, 6.1999999999999655, 89.89999999999995, 74.9, -17.79999999999975, 96.19999999999999, 17.599999999999977, -3.099999999999958, 20.000000000000014, 5.2999999999999705, -30.39999999999975, 160.39999999999986, -64.00000000000088, 143.29999999999987, 73.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, -34.60000000000013, 18.199999999999996, 91.70000000000005, 21.800000000000043, 23.900000000000055, 17.899999999999988, 140.6, 173.8999999999999, 9.499999999999964, 13.700000000000069, 15.799999999999963, 11.599999999999964, -30.399999999999757, -13.59999999999979, -86.80000000000015, -1.0000000000000275, -0.40000000000004365, 7.399999999999965, 77.90000000000003, 111.19999999999982, -200.49999999999994, 80.00000000000001, 117.49999999999994, -11.499999999999883, 87.79999999999997, 20.000000000000014, -80.80000000000086, 1.0999999999999865, 5.299999999999965, 131.8999999999998, 49.69999999999997, -150.40000000000003, 17.899999999999988, 15.800000000000024, 77.00000000000003, 136.0999999999999, -98.80000000000078, 98.89999999999985, 105.79999999999995, 88.40000000000002, -7.299999999999891, -13.599999999999783, 42.50000000000003, -17.79999999999974, 87.80000000000001, -68.20000000000087, 148.69999999999973, 13.699999999999964, 99.20000000000003, 129.19999999999982, 154.39999999999986, 97.09999999999997, 7.399999999999965, 1.0999999999999865, 68.29999999999983, -3.1000000000001613, -1.3000000000000913, 59.0000000000001, 3.199999999999971, 61.69999999999999, 48.50000000000002, 146.89999999999975, 7.99999999999997, 134.29999999999976, -75.10000000000016, 129.79999999999995, 20.000000000000014, 104.89999999999998, 23.000000000000036, 97.69999999999993, -26.80000000000009, 20.000000000000014, 20.000000000000014, -7.600000000000001, 41.600000000000094, 110.29999999999984, 17.899999999999988, 20.000000000000014, 42.8000000000001, 7.399999999999965, 145.09999999999974, 63.199999999999996, 149.29999999999984, 20.000000000000014, 3.1999999999999615, -7.299999999999891, 100.99999999999989, 15.799999999999963, 93.19999999999963, 20.000000000000014, 11.599999999999964, 11.599999999999968, 13.699999999999946, 3.1999999999999615, 20.000000000000014, 126.49999999999973, -98.80000000000024, 5.600000000000179, 131.9, 1.0999999999999865, 126.49999999999993, 117.19999999999989, 101.59999999999945, 15.799999999999963, 20.000000000000014, -187.90000000000057, 130.9999999999998, 20.000000000000014, -24.099999999999746, 5.299999999999965, 106.99999999999999, 131.89999999999998, 15.799999999999963, -179.80000000000013, 20.000000000000014], "policy_predator_policy_reward": [34.0, 36.0, 114.0, 111.0, 17.0, 0.0, 39.0, 8.0, 22.0, 23.0, 5.0, 15.0, 7.0, 1.0, 24.0, 4.0, 6.0, 3.0, 30.0, 5.0, 4.0, 18.0, 8.0, 18.0, 9.0, 49.0, 12.0, 0.0, 48.0, 57.0, 17.0, 33.0, 22.0, 12.0, 17.0, 32.0, 12.0, 47.0, 34.0, 6.0, 8.0, 0.0, 6.0, 3.0, 3.0, 0.0, 16.0, 14.0, 24.0, 4.0, 15.0, 9.0, 14.0, 15.0, 18.0, 41.0, 0.0, 0.0, 1.0, 8.0, 10.0, 43.0, 64.0, 56.0, 45.0, 46.0, 0.0, 9.0, 15.0, 22.0, 4.0, 27.0, 4.0, 11.0, 7.0, 0.0, 24.0, 0.0, 40.0, 10.0, 9.0, 11.0, 3.0, 1.0, 21.0, 68.0, 29.0, 21.0, 5.0, 0.0, 6.0, 1.0, 5.0, 4.0, 11.0, 39.0, 2.0, 28.0, 33.0, 73.0, 13.0, 14.0, 26.0, 6.0, 118.0, 76.0, 22.0, 17.0, 23.0, 19.0, 48.0, 14.0, 6.0, 9.0, 2.0, 0.0, 109.0, 102.0, 52.0, 32.0, 29.0, 50.0, 20.0, 6.0, 2.0, 29.0, 16.0, 45.0, 29.0, 6.0, 42.0, 22.0, 0.0, 18.0, 8.0, 2.0, 8.0, 14.0, 13.0, 9.0, 21.0, 62.0, 21.0, 22.0, 36.0, 14.0, 0.0, 10.0, 50.0, 82.0, 6.0, 5.0, 8.0, 30.0, 11.0, 63.0, 0.0, 0.0, 38.0, 5.0, 0.0, 12.0, 28.0, 8.0, 6.0, 3.0, 4.0, 6.0, 2.0, 8.0, 15.0, 13.0, 0.0, 2.0, 4.0, 0.0, 4.0, 4.0, 3.0, 8.0, 52.0, 83.0, 27.0, 2.0, 13.0, 9.0, 10.0, 3.0, 2.0, 1.0, 96.0, 89.0, 21.0, 6.0, 7.0, 4.0, 8.0, 8.0, 23.0, 112.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.753522767812303, "mean_inference_ms": 1.9793882873312632, "mean_action_processing_ms": 0.3023839401568514, "mean_env_wait_ms": 0.25965072547016166, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004977822303771973, "StateBufferConnector_ms": 0.007276773452758789, "ViewRequirementAgentConnector_ms": 0.14072704315185547}, "num_episodes": 18, "episode_return_max": 293.5999999999999, "episode_return_min": -61.10000000000121, "episode_return_mean": 101.46199999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.38239404770906, "num_env_steps_trained_throughput_per_sec": 338.38239404770906, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 11979.811, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11979.762, "sample_time_ms": 1552.214, "learn_time_ms": 10405.752, "learn_throughput": 384.403, "synch_weights_time_ms": 19.515}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "f0d88_00000", "date": "2024-08-14_10-50-53", "timestamp": 1723647053, "time_this_iter_s": 11.928956985473633, "time_total_s": 272.2264323234558, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e2310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 272.2264323234558, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 45.147058823529406, "ram_util_percent": 83.27058823529411}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.546229965188516, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.0010000000000000005, "total_loss": 5.3970806008293515, "policy_loss": -0.026576064108678746, "vf_loss": 5.401931268197519, "vf_explained_var": 0.5621267099859854, "kl": 0.021457195561697735, "entropy": 1.3669171253840129, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9139272761092614, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.3874538859046956, "policy_loss": -0.02761107178358115, "vf_loss": 1.3988942764896564, "vf_explained_var": 0.12649755004852536, "kl": 0.01064735887458863, "entropy": 1.2995274994108412, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 293.5999999999999, "episode_reward_min": -61.10000000000121, "episode_reward_mean": 110.50299999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.59999999999945, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 33.15649999999995, "predator_policy": 22.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.5000000000003753, 46.3000000000004, 30.100000000000165, 102.59999999999972, -61.10000000000121, 69.50000000000006, 31.0000000000002, 201.79999999999976, 109.39999999999954, 29.500000000000174, 32.30000000000019, 153.9999999999994, 129.29999999999947, 113.09999999999974, 37.700000000000266, 72.30000000000011, 159.89999999999904, 50.7000000000004, 165.4999999999994, 192.39999999999912, 79.49999999999996, 11.199999999999987, 5.600000000000109, 25.60000000000009, 117.29999999999971, 104.69999999999979, 236.4999999999996, 118.29999999999967, 1.200000000000179, 21.400000000000006, 183.5999999999993, 78.50000000000009, 176.7999999999996, 116.2999999999998, 230.6999999999997, 112.09999999999977, 89.89999999999992, 104.99999999999977, 144.49999999999932, 130.89999999999958, 293.5999999999999, 126.49999999999957, 91.39999999999944, 78.59999999999978, 105.1999999999995, 160.1999999999996, 164.89999999999927, 191.19999999999985, 160.79999999999941, 165.89999999999975, 144.89999999999984, 40.0000000000003, 76.9999999999997, 140.19999999999928, 98.79999999999927, 161.4999999999991, 222.49999999999946, 33.2000000000002, 121.69999999999956, 110.99999999999906, 35.600000000000236, 33.30000000000022, 34.200000000000216, 162.69999999999956, 166.49999999999997, 149.59999999999948, 231.7999999999992, 38.80000000000028, 128.09999999999934, 22.900000000000027, 123.29999999999973, 163.6999999999994, -24.800000000000473, 151.49999999999926, 221.899999999999, 24.799999999999642, 110.29999999999953, 168.09999999999937, 124.79999999999961, 16.899999999999995, 162.79999999999927, 145.49999999999935, 21.200000000000113, 235.29999999999987, 238.59999999999968, -53.20000000000027, 45.80000000000023, 139.4999999999997, 118.19999999999949, 19.099999999999977, 285.6999999999997, 216.79999999999913, 94.0, 93.7999999999997, 152.0999999999998, 105.79999999999981, 98.09999999999988, 126.0999999999998, 155.8999999999994, 118.69999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.19999999999979, -28.299999999999763, 20.000000000000014, 26.300000000000114, 1.0999999999999603, 20.000000000000014, 20.000000000000014, 29.599999999999916, -70.3000000000008, -110.80000000000064, -50.49999999999984, 28.99999999999997, 15.799999999999981, 6.1999999999999655, 89.89999999999995, 74.9, -17.79999999999975, 96.19999999999999, 17.599999999999977, -3.099999999999958, 20.000000000000014, 5.2999999999999705, -30.39999999999975, 160.39999999999986, -64.00000000000088, 143.29999999999987, 73.1, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, -34.60000000000013, 18.199999999999996, 91.70000000000005, 21.800000000000043, 23.900000000000055, 17.899999999999988, 140.6, 173.8999999999999, 9.499999999999964, 13.700000000000069, 15.799999999999963, 11.599999999999964, -30.399999999999757, -13.59999999999979, -86.80000000000015, -1.0000000000000275, -0.40000000000004365, 7.399999999999965, 77.90000000000003, 111.19999999999982, -200.49999999999994, 80.00000000000001, 117.49999999999994, -11.499999999999883, 87.79999999999997, 20.000000000000014, -80.80000000000086, 1.0999999999999865, 5.299999999999965, 131.8999999999998, 49.69999999999997, -150.40000000000003, 17.899999999999988, 15.800000000000024, 77.00000000000003, 136.0999999999999, -98.80000000000078, 98.89999999999985, 105.79999999999995, 88.40000000000002, -7.299999999999891, -13.599999999999783, 42.50000000000003, -17.79999999999974, 87.80000000000001, -68.20000000000087, 148.69999999999973, 13.699999999999964, 99.20000000000003, 129.19999999999982, 154.39999999999986, 97.09999999999997, 7.399999999999965, 1.0999999999999865, 68.29999999999983, -3.1000000000001613, -1.3000000000000913, 59.0000000000001, 3.199999999999971, 61.69999999999999, 48.50000000000002, 146.89999999999975, 7.99999999999997, 134.29999999999976, -75.10000000000016, 129.79999999999995, 20.000000000000014, 104.89999999999998, 23.000000000000036, 97.69999999999993, -26.80000000000009, 20.000000000000014, 20.000000000000014, -7.600000000000001, 41.600000000000094, 110.29999999999984, 17.899999999999988, 20.000000000000014, 42.8000000000001, 7.399999999999965, 145.09999999999974, 63.199999999999996, 149.29999999999984, 20.000000000000014, 3.1999999999999615, -7.299999999999891, 100.99999999999989, 15.799999999999963, 93.19999999999963, 20.000000000000014, 11.599999999999964, 11.599999999999968, 13.699999999999946, 3.1999999999999615, 20.000000000000014, 126.49999999999973, -98.80000000000024, 5.600000000000179, 131.9, 1.0999999999999865, 126.49999999999993, 117.19999999999989, 101.59999999999945, 15.799999999999963, 20.000000000000014, -187.90000000000057, 130.9999999999998, 20.000000000000014, -24.099999999999746, 5.299999999999965, 106.99999999999999, 131.89999999999998, 15.799999999999963, -179.80000000000013, 20.000000000000014, 121.69999999999993, 15.799999999999963, 155.2999999999999, 59.60000000000019, 7.399999999999886, -58.60000000000025, 1.0999999999999865, 87.19999999999986, 5.299999999999965, 147.7999999999999, 86.60000000000002, 3.1999999999999615, 5.299999999999965, -9.399999999999855, 5.299999999999965, 150.49999999999986, 146.59999999999985, -24.099999999999746, -10.899999999999906, -7.8999999999998884, 127.10000000000002, 75.20000000000009, 89.30000000000003, 116.29999999999983, -25.60000000000001, -319.59999999999945, -30.39999999999977, 18.199999999999918, 108.50000000000003, 20.000000000000014, -0.9999999999999846, 105.19999999999987, 20.000000000000014, -19.899999999999743, 149.59999999999968, 127.0999999999998, 98.89999999999989, 92.89999999999984, 43.399999999999906, 5.599999999999971, 15.799999999999963, 14.0, 155.89999999999986, -167.8000000000002, -26.199999999999747, 109.99999999999997, 130.69999999999996, -160.60000000000065, -3.099999999999958, 90.20000000000002, 125.89999999999992, 20.000000000000014, -40.89999999999976, 107.59999999999988], "policy_predator_policy_reward": [18.0, 41.0, 0.0, 0.0, 1.0, 8.0, 10.0, 43.0, 64.0, 56.0, 45.0, 46.0, 0.0, 9.0, 15.0, 22.0, 4.0, 27.0, 4.0, 11.0, 7.0, 0.0, 24.0, 0.0, 40.0, 10.0, 9.0, 11.0, 3.0, 1.0, 21.0, 68.0, 29.0, 21.0, 5.0, 0.0, 6.0, 1.0, 5.0, 4.0, 11.0, 39.0, 2.0, 28.0, 33.0, 73.0, 13.0, 14.0, 26.0, 6.0, 118.0, 76.0, 22.0, 17.0, 23.0, 19.0, 48.0, 14.0, 6.0, 9.0, 2.0, 0.0, 109.0, 102.0, 52.0, 32.0, 29.0, 50.0, 20.0, 6.0, 2.0, 29.0, 16.0, 45.0, 29.0, 6.0, 42.0, 22.0, 0.0, 18.0, 8.0, 2.0, 8.0, 14.0, 13.0, 9.0, 21.0, 62.0, 21.0, 22.0, 36.0, 14.0, 0.0, 10.0, 50.0, 82.0, 6.0, 5.0, 8.0, 30.0, 11.0, 63.0, 0.0, 0.0, 38.0, 5.0, 0.0, 12.0, 28.0, 8.0, 6.0, 3.0, 4.0, 6.0, 2.0, 8.0, 15.0, 13.0, 0.0, 2.0, 4.0, 0.0, 4.0, 4.0, 3.0, 8.0, 52.0, 83.0, 27.0, 2.0, 13.0, 9.0, 10.0, 3.0, 2.0, 1.0, 96.0, 89.0, 21.0, 6.0, 7.0, 4.0, 8.0, 8.0, 23.0, 112.0, 12.0, 2.0, 1.0, 6.0, 2.0, 74.0, 3.0, 19.0, 2.0, 13.0, 34.0, 1.0, 7.0, 14.0, 7.0, 0.0, 2.0, 21.0, 9.0, 31.0, 14.0, 19.0, 27.0, 6.0, 161.0, 131.0, 10.0, 48.0, 1.0, 10.0, 4.0, 10.0, 19.0, 0.0, 0.0, 9.0, 11.0, 14.0, 36.0, 9.0, 26.0, 38.0, 80.0, 84.0, 22.0, 0.0, 61.0, 67.0, 19.0, 20.0, 0.0, 10.0, 35.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7570601271545246, "mean_inference_ms": 1.9852573032375125, "mean_action_processing_ms": 0.3033773257224506, "mean_env_wait_ms": 0.26090450360426337, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005057811737060547, "StateBufferConnector_ms": 0.0035060644149780273, "ViewRequirementAgentConnector_ms": 0.1375523805618286}, "num_episodes": 27, "episode_return_max": 293.5999999999999, "episode_return_min": -61.10000000000121, "episode_return_mean": 110.50299999999972, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.2320240091157, "num_env_steps_trained_throughput_per_sec": 343.2320240091157, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 11969.918, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11969.868, "sample_time_ms": 1577.039, "learn_time_ms": 10367.282, "learn_throughput": 385.829, "synch_weights_time_ms": 23.303}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "f0d88_00000", "date": "2024-08-14_10-51-05", "timestamp": 1723647065, "time_this_iter_s": 11.70500922203064, "time_total_s": 283.93144154548645, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4e5550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 283.93144154548645, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 44.88235294117647, "ram_util_percent": 83.32352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7160606453343044, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.83211134400948, "policy_loss": -0.02130026064293272, "vf_loss": 5.828577435205853, "vf_explained_var": 0.623039562361581, "kl": 0.016351721676643567, "entropy": 1.362716269682324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4628112780984748, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.663244715632585, "policy_loss": -0.023228518945958326, "vf_loss": 1.670203846913797, "vf_explained_var": 0.19549250599568482, "kl": 0.010712356287086748, "entropy": 1.2717546661064107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 305.20000000000005, "episode_reward_min": -53.20000000000027, "episode_reward_mean": 125.77899999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.59999999999945, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.8999999999999, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 40.71949999999995, "predator_policy": 22.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [165.4999999999994, 192.39999999999912, 79.49999999999996, 11.199999999999987, 5.600000000000109, 25.60000000000009, 117.29999999999971, 104.69999999999979, 236.4999999999996, 118.29999999999967, 1.200000000000179, 21.400000000000006, 183.5999999999993, 78.50000000000009, 176.7999999999996, 116.2999999999998, 230.6999999999997, 112.09999999999977, 89.89999999999992, 104.99999999999977, 144.49999999999932, 130.89999999999958, 293.5999999999999, 126.49999999999957, 91.39999999999944, 78.59999999999978, 105.1999999999995, 160.1999999999996, 164.89999999999927, 191.19999999999985, 160.79999999999941, 165.89999999999975, 144.89999999999984, 40.0000000000003, 76.9999999999997, 140.19999999999928, 98.79999999999927, 161.4999999999991, 222.49999999999946, 33.2000000000002, 121.69999999999956, 110.99999999999906, 35.600000000000236, 33.30000000000022, 34.200000000000216, 162.69999999999956, 166.49999999999997, 149.59999999999948, 231.7999999999992, 38.80000000000028, 128.09999999999934, 22.900000000000027, 123.29999999999973, 163.6999999999994, -24.800000000000473, 151.49999999999926, 221.899999999999, 24.799999999999642, 110.29999999999953, 168.09999999999937, 124.79999999999961, 16.899999999999995, 162.79999999999927, 145.49999999999935, 21.200000000000113, 235.29999999999987, 238.59999999999968, -53.20000000000027, 45.80000000000023, 139.4999999999997, 118.19999999999949, 19.099999999999977, 285.6999999999997, 216.79999999999913, 94.0, 93.7999999999997, 152.0999999999998, 105.79999999999981, 98.09999999999988, 126.0999999999998, 155.8999999999994, 118.69999999999956, 231.49999999999943, 34.50000000000022, 93.89999999999992, 26.800000000000086, 37.10000000000026, 78.19999999999999, 267.59999999999985, 296.19999999999993, 126.39999999999966, -36.30000000000014, 274.6999999999998, 305.20000000000005, 121.99999999999952, 238.49999999999994, 302.59999999999985, 157.49999999999946, 14.700000000000001, 266.39999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, 140.6, 173.8999999999999, 9.499999999999964, 13.700000000000069, 15.799999999999963, 11.599999999999964, -30.399999999999757, -13.59999999999979, -86.80000000000015, -1.0000000000000275, -0.40000000000004365, 7.399999999999965, 77.90000000000003, 111.19999999999982, -200.49999999999994, 80.00000000000001, 117.49999999999994, -11.499999999999883, 87.79999999999997, 20.000000000000014, -80.80000000000086, 1.0999999999999865, 5.299999999999965, 131.8999999999998, 49.69999999999997, -150.40000000000003, 17.899999999999988, 15.800000000000024, 77.00000000000003, 136.0999999999999, -98.80000000000078, 98.89999999999985, 105.79999999999995, 88.40000000000002, -7.299999999999891, -13.599999999999783, 42.50000000000003, -17.79999999999974, 87.80000000000001, -68.20000000000087, 148.69999999999973, 13.699999999999964, 99.20000000000003, 129.19999999999982, 154.39999999999986, 97.09999999999997, 7.399999999999965, 1.0999999999999865, 68.29999999999983, -3.1000000000001613, -1.3000000000000913, 59.0000000000001, 3.199999999999971, 61.69999999999999, 48.50000000000002, 146.89999999999975, 7.99999999999997, 134.29999999999976, -75.10000000000016, 129.79999999999995, 20.000000000000014, 104.89999999999998, 23.000000000000036, 97.69999999999993, -26.80000000000009, 20.000000000000014, 20.000000000000014, -7.600000000000001, 41.600000000000094, 110.29999999999984, 17.899999999999988, 20.000000000000014, 42.8000000000001, 7.399999999999965, 145.09999999999974, 63.199999999999996, 149.29999999999984, 20.000000000000014, 3.1999999999999615, -7.299999999999891, 100.99999999999989, 15.799999999999963, 93.19999999999963, 20.000000000000014, 11.599999999999964, 11.599999999999968, 13.699999999999946, 3.1999999999999615, 20.000000000000014, 126.49999999999973, -98.80000000000024, 5.600000000000179, 131.9, 1.0999999999999865, 126.49999999999993, 117.19999999999989, 101.59999999999945, 15.799999999999963, 20.000000000000014, -187.90000000000057, 130.9999999999998, 20.000000000000014, -24.099999999999746, 5.299999999999965, 106.99999999999999, 131.89999999999998, 15.799999999999963, -179.80000000000013, 20.000000000000014, 121.69999999999993, 15.799999999999963, 155.2999999999999, 59.60000000000019, 7.399999999999886, -58.60000000000025, 1.0999999999999865, 87.19999999999986, 5.299999999999965, 147.7999999999999, 86.60000000000002, 3.1999999999999615, 5.299999999999965, -9.399999999999855, 5.299999999999965, 150.49999999999986, 146.59999999999985, -24.099999999999746, -10.899999999999906, -7.8999999999998884, 127.10000000000002, 75.20000000000009, 89.30000000000003, 116.29999999999983, -25.60000000000001, -319.59999999999945, -30.39999999999977, 18.199999999999918, 108.50000000000003, 20.000000000000014, -0.9999999999999846, 105.19999999999987, 20.000000000000014, -19.899999999999743, 149.59999999999968, 127.0999999999998, 98.89999999999989, 92.89999999999984, 43.399999999999906, 5.599999999999971, 15.799999999999963, 14.0, 155.89999999999986, -167.8000000000002, -26.199999999999747, 109.99999999999997, 130.69999999999996, -160.60000000000065, -3.099999999999958, 90.20000000000002, 125.89999999999992, 20.000000000000014, -40.89999999999976, 107.59999999999988, 86.59999999999977, 128.9, 20.000000000000014, 9.499999999999964, 117.79999999999994, -82.90000000000046, 9.499999999999964, 5.299999999999965, 5.299999999999965, 15.799999999999962, -131.2000000000004, 133.39999999999992, 117.19999999999999, 109.39999999999998, 121.69999999999997, 150.49999999999991, -0.9999999999999881, 64.40000000000005, -93.10000000000008, -134.20000000000022, 126.1999999999999, 120.49999999999996, 144.49999999999986, 145.69999999999987, -7.299999999999891, 92.29999999999988, 107.29999999999998, 102.19999999999996, 136.09999999999982, 156.49999999999991, -3.099999999999979, 140.59999999999994, -24.099999999999746, 15.799999999999963, 113.89999999999995, 129.49999999999983], "policy_predator_policy_reward": [6.0, 1.0, 5.0, 4.0, 11.0, 39.0, 2.0, 28.0, 33.0, 73.0, 13.0, 14.0, 26.0, 6.0, 118.0, 76.0, 22.0, 17.0, 23.0, 19.0, 48.0, 14.0, 6.0, 9.0, 2.0, 0.0, 109.0, 102.0, 52.0, 32.0, 29.0, 50.0, 20.0, 6.0, 2.0, 29.0, 16.0, 45.0, 29.0, 6.0, 42.0, 22.0, 0.0, 18.0, 8.0, 2.0, 8.0, 14.0, 13.0, 9.0, 21.0, 62.0, 21.0, 22.0, 36.0, 14.0, 0.0, 10.0, 50.0, 82.0, 6.0, 5.0, 8.0, 30.0, 11.0, 63.0, 0.0, 0.0, 38.0, 5.0, 0.0, 12.0, 28.0, 8.0, 6.0, 3.0, 4.0, 6.0, 2.0, 8.0, 15.0, 13.0, 0.0, 2.0, 4.0, 0.0, 4.0, 4.0, 3.0, 8.0, 52.0, 83.0, 27.0, 2.0, 13.0, 9.0, 10.0, 3.0, 2.0, 1.0, 96.0, 89.0, 21.0, 6.0, 7.0, 4.0, 8.0, 8.0, 23.0, 112.0, 12.0, 2.0, 1.0, 6.0, 2.0, 74.0, 3.0, 19.0, 2.0, 13.0, 34.0, 1.0, 7.0, 14.0, 7.0, 0.0, 2.0, 21.0, 9.0, 31.0, 14.0, 19.0, 27.0, 6.0, 161.0, 131.0, 10.0, 48.0, 1.0, 10.0, 4.0, 10.0, 19.0, 0.0, 0.0, 9.0, 11.0, 14.0, 36.0, 9.0, 26.0, 38.0, 80.0, 84.0, 22.0, 0.0, 61.0, 67.0, 19.0, 20.0, 0.0, 10.0, 35.0, 17.0, 16.0, 0.0, 5.0, 0.0, 49.0, 10.0, 7.0, 5.0, 9.0, 7.0, 4.0, 72.0, 14.0, 27.0, 18.0, 6.0, 33.0, 30.0, 122.0, 69.0, 12.0, 16.0, 8.0, 7.0, 12.0, 25.0, 29.0, 0.0, 5.0, 5.0, 11.0, 9.0, 21.0, 2.0, 19.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7559883889863542, "mean_inference_ms": 1.9854288374964677, "mean_action_processing_ms": 0.30368044699745267, "mean_env_wait_ms": 0.26011857383669396, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005156874656677246, "StateBufferConnector_ms": 0.003956198692321777, "ViewRequirementAgentConnector_ms": 0.11438906192779541}, "num_episodes": 18, "episode_return_max": 305.20000000000005, "episode_return_min": -53.20000000000027, "episode_return_mean": 125.77899999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.45605799805895, "num_env_steps_trained_throughput_per_sec": 341.45605799805895, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 11933.305, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11933.257, "sample_time_ms": 1600.364, "learn_time_ms": 10305.867, "learn_throughput": 388.128, "synch_weights_time_ms": 23.909}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "f0d88_00000", "date": "2024-08-14_10-51-17", "timestamp": 1723647077, "time_this_iter_s": 11.803352117538452, "time_total_s": 295.7347936630249, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4e5ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 295.7347936630249, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 44.92941176470589, "ram_util_percent": 83.3}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7415973504699727, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.9853356146938586, "policy_loss": -0.023035113984304998, "vf_loss": 5.986261713441718, "vf_explained_var": 0.6184438798162673, "kl": 0.014557383961238894, "entropy": 1.3435545166333516, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.602164033228758, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.5471791277486813, "policy_loss": -0.023072770160312454, "vf_loss": 2.5539050312269302, "vf_explained_var": 0.1127998618537156, "kl": 0.010763371219158815, "entropy": 1.321940005267108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 313.5999999999999, "episode_reward_min": -53.20000000000027, "episode_reward_mean": 138.6659999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.59999999999945, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 158.89999999999992, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 48.71299999999996, "predator_policy": 20.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.89999999999992, 104.99999999999977, 144.49999999999932, 130.89999999999958, 293.5999999999999, 126.49999999999957, 91.39999999999944, 78.59999999999978, 105.1999999999995, 160.1999999999996, 164.89999999999927, 191.19999999999985, 160.79999999999941, 165.89999999999975, 144.89999999999984, 40.0000000000003, 76.9999999999997, 140.19999999999928, 98.79999999999927, 161.4999999999991, 222.49999999999946, 33.2000000000002, 121.69999999999956, 110.99999999999906, 35.600000000000236, 33.30000000000022, 34.200000000000216, 162.69999999999956, 166.49999999999997, 149.59999999999948, 231.7999999999992, 38.80000000000028, 128.09999999999934, 22.900000000000027, 123.29999999999973, 163.6999999999994, -24.800000000000473, 151.49999999999926, 221.899999999999, 24.799999999999642, 110.29999999999953, 168.09999999999937, 124.79999999999961, 16.899999999999995, 162.79999999999927, 145.49999999999935, 21.200000000000113, 235.29999999999987, 238.59999999999968, -53.20000000000027, 45.80000000000023, 139.4999999999997, 118.19999999999949, 19.099999999999977, 285.6999999999997, 216.79999999999913, 94.0, 93.7999999999997, 152.0999999999998, 105.79999999999981, 98.09999999999988, 126.0999999999998, 155.8999999999994, 118.69999999999956, 231.49999999999943, 34.50000000000022, 93.89999999999992, 26.800000000000086, 37.10000000000026, 78.19999999999999, 267.59999999999985, 296.19999999999993, 126.39999999999966, -36.30000000000014, 274.6999999999998, 305.20000000000005, 121.99999999999952, 238.49999999999994, 302.59999999999985, 157.49999999999946, 14.700000000000001, 266.39999999999986, 132.39999999999966, 178.5999999999992, 235.69999999999982, 148.3999999999994, 166.79999999999984, 217.39999999999986, 240.29999999999984, 133.49999999999963, 110.99999999999955, 313.5999999999999, 231.09999999999962, 155.39999999999995, 289.1, 166.79999999999976, 153.89999999999955, 182.89999999999918, 100.09999999999994, 108.8999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-13.599999999999783, 42.50000000000003, -17.79999999999974, 87.80000000000001, -68.20000000000087, 148.69999999999973, 13.699999999999964, 99.20000000000003, 129.19999999999982, 154.39999999999986, 97.09999999999997, 7.399999999999965, 1.0999999999999865, 68.29999999999983, -3.1000000000001613, -1.3000000000000913, 59.0000000000001, 3.199999999999971, 61.69999999999999, 48.50000000000002, 146.89999999999975, 7.99999999999997, 134.29999999999976, -75.10000000000016, 129.79999999999995, 20.000000000000014, 104.89999999999998, 23.000000000000036, 97.69999999999993, -26.80000000000009, 20.000000000000014, 20.000000000000014, -7.600000000000001, 41.600000000000094, 110.29999999999984, 17.899999999999988, 20.000000000000014, 42.8000000000001, 7.399999999999965, 145.09999999999974, 63.199999999999996, 149.29999999999984, 20.000000000000014, 3.1999999999999615, -7.299999999999891, 100.99999999999989, 15.799999999999963, 93.19999999999963, 20.000000000000014, 11.599999999999964, 11.599999999999968, 13.699999999999946, 3.1999999999999615, 20.000000000000014, 126.49999999999973, -98.80000000000024, 5.600000000000179, 131.9, 1.0999999999999865, 126.49999999999993, 117.19999999999989, 101.59999999999945, 15.799999999999963, 20.000000000000014, -187.90000000000057, 130.9999999999998, 20.000000000000014, -24.099999999999746, 5.299999999999965, 106.99999999999999, 131.89999999999998, 15.799999999999963, -179.80000000000013, 20.000000000000014, 121.69999999999993, 15.799999999999963, 155.2999999999999, 59.60000000000019, 7.399999999999886, -58.60000000000025, 1.0999999999999865, 87.19999999999986, 5.299999999999965, 147.7999999999999, 86.60000000000002, 3.1999999999999615, 5.299999999999965, -9.399999999999855, 5.299999999999965, 150.49999999999986, 146.59999999999985, -24.099999999999746, -10.899999999999906, -7.8999999999998884, 127.10000000000002, 75.20000000000009, 89.30000000000003, 116.29999999999983, -25.60000000000001, -319.59999999999945, -30.39999999999977, 18.199999999999918, 108.50000000000003, 20.000000000000014, -0.9999999999999846, 105.19999999999987, 20.000000000000014, -19.899999999999743, 149.59999999999968, 127.0999999999998, 98.89999999999989, 92.89999999999984, 43.399999999999906, 5.599999999999971, 15.799999999999963, 14.0, 155.89999999999986, -167.8000000000002, -26.199999999999747, 109.99999999999997, 130.69999999999996, -160.60000000000065, -3.099999999999958, 90.20000000000002, 125.89999999999992, 20.000000000000014, -40.89999999999976, 107.59999999999988, 86.59999999999977, 128.9, 20.000000000000014, 9.499999999999964, 117.79999999999994, -82.90000000000046, 9.499999999999964, 5.299999999999965, 5.299999999999965, 15.799999999999962, -131.2000000000004, 133.39999999999992, 117.19999999999999, 109.39999999999998, 121.69999999999997, 150.49999999999991, -0.9999999999999881, 64.40000000000005, -93.10000000000008, -134.20000000000022, 126.1999999999999, 120.49999999999996, 144.49999999999986, 145.69999999999987, -7.299999999999891, 92.29999999999988, 107.29999999999998, 102.19999999999996, 136.09999999999982, 156.49999999999991, -3.099999999999979, 140.59999999999994, -24.099999999999746, 15.799999999999963, 113.89999999999995, 129.49999999999983, 20.000000000000014, 106.39999999999996, 14.599999999999973, 148.99999999999974, 48.80000000000004, 128.89999999999995, 158.89999999999992, -53.49999999999995, -66.39999999999998, 138.19999999999985, 157.39999999999984, 29.00000000000009, 70.69999999999993, 119.59999999999992, 124.39999999999996, -40.89999999999976, 93.19999999999993, -5.1999999999999265, 150.19999999999987, 154.39999999999992, 19.99999999999993, 127.09999999999978, 56.60000000000003, 39.80000000000005, 149.5999999999999, 93.49999999999997, 77.90000000000003, 38.900000000000034, -0.9999999999999881, 128.89999999999998, 149.89999999999986, 20.000000000000014, 15.799999999999963, 38.299999999999976, -13.599999999999783, 90.49999999999997], "policy_predator_policy_reward": [16.0, 45.0, 29.0, 6.0, 42.0, 22.0, 0.0, 18.0, 8.0, 2.0, 8.0, 14.0, 13.0, 9.0, 21.0, 62.0, 21.0, 22.0, 36.0, 14.0, 0.0, 10.0, 50.0, 82.0, 6.0, 5.0, 8.0, 30.0, 11.0, 63.0, 0.0, 0.0, 38.0, 5.0, 0.0, 12.0, 28.0, 8.0, 6.0, 3.0, 4.0, 6.0, 2.0, 8.0, 15.0, 13.0, 0.0, 2.0, 4.0, 0.0, 4.0, 4.0, 3.0, 8.0, 52.0, 83.0, 27.0, 2.0, 13.0, 9.0, 10.0, 3.0, 2.0, 1.0, 96.0, 89.0, 21.0, 6.0, 7.0, 4.0, 8.0, 8.0, 23.0, 112.0, 12.0, 2.0, 1.0, 6.0, 2.0, 74.0, 3.0, 19.0, 2.0, 13.0, 34.0, 1.0, 7.0, 14.0, 7.0, 0.0, 2.0, 21.0, 9.0, 31.0, 14.0, 19.0, 27.0, 6.0, 161.0, 131.0, 10.0, 48.0, 1.0, 10.0, 4.0, 10.0, 19.0, 0.0, 0.0, 9.0, 11.0, 14.0, 36.0, 9.0, 26.0, 38.0, 80.0, 84.0, 22.0, 0.0, 61.0, 67.0, 19.0, 20.0, 0.0, 10.0, 35.0, 17.0, 16.0, 0.0, 5.0, 0.0, 49.0, 10.0, 7.0, 5.0, 9.0, 7.0, 4.0, 72.0, 14.0, 27.0, 18.0, 6.0, 33.0, 30.0, 122.0, 69.0, 12.0, 16.0, 8.0, 7.0, 12.0, 25.0, 29.0, 0.0, 5.0, 5.0, 11.0, 9.0, 21.0, 2.0, 19.0, 4.0, 0.0, 6.0, 6.0, 9.0, 4.0, 54.0, 34.0, 9.0, 51.0, 44.0, 6.0, 25.0, 14.0, 36.0, 29.0, 21.0, 0.0, 23.0, 9.0, 0.0, 36.0, 48.0, 20.0, 39.0, 30.0, 16.0, 31.0, 19.0, 18.0, 8.0, 6.0, 7.0, 10.0, 36.0, 17.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7545869969068612, "mean_inference_ms": 1.982485725986802, "mean_action_processing_ms": 0.30336243424048576, "mean_env_wait_ms": 0.25944468530091136, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007453203201293945, "StateBufferConnector_ms": 0.003973245620727539, "ViewRequirementAgentConnector_ms": 0.10646486282348633}, "num_episodes": 18, "episode_return_max": 313.5999999999999, "episode_return_min": -53.20000000000027, "episode_return_mean": 138.6659999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 335.94243193839293, "num_env_steps_trained_throughput_per_sec": 335.94243193839293, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 11926.466, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11926.417, "sample_time_ms": 1620.535, "learn_time_ms": 10277.139, "learn_throughput": 389.213, "synch_weights_time_ms": 24.402}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "f0d88_00000", "date": "2024-08-14_10-51-29", "timestamp": 1723647089, "time_this_iter_s": 11.998143911361694, "time_total_s": 307.7329375743866, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0bcd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 307.7329375743866, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 45.411764705882355, "ram_util_percent": 83.48823529411766}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0149679774329776, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.0075420840076665, "policy_loss": -0.023147973254761565, "vf_loss": 5.005844380111291, "vf_explained_var": 0.7673283944054256, "kl": 0.016359294269580285, "entropy": 1.3223045537080715, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.402040089059759, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.76599558188171, "policy_loss": -0.028857318977899258, "vf_loss": 1.7796079725500138, "vf_explained_var": 0.05377621486704186, "kl": 0.01003781429966471, "entropy": 1.2856793223865448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 313.5999999999999, "episode_reward_min": -53.20000000000027, "episode_reward_mean": 138.76099999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.59999999999945, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 163.99999999999983, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 48.060499999999955, "predator_policy": 21.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [98.79999999999927, 161.4999999999991, 222.49999999999946, 33.2000000000002, 121.69999999999956, 110.99999999999906, 35.600000000000236, 33.30000000000022, 34.200000000000216, 162.69999999999956, 166.49999999999997, 149.59999999999948, 231.7999999999992, 38.80000000000028, 128.09999999999934, 22.900000000000027, 123.29999999999973, 163.6999999999994, -24.800000000000473, 151.49999999999926, 221.899999999999, 24.799999999999642, 110.29999999999953, 168.09999999999937, 124.79999999999961, 16.899999999999995, 162.79999999999927, 145.49999999999935, 21.200000000000113, 235.29999999999987, 238.59999999999968, -53.20000000000027, 45.80000000000023, 139.4999999999997, 118.19999999999949, 19.099999999999977, 285.6999999999997, 216.79999999999913, 94.0, 93.7999999999997, 152.0999999999998, 105.79999999999981, 98.09999999999988, 126.0999999999998, 155.8999999999994, 118.69999999999956, 231.49999999999943, 34.50000000000022, 93.89999999999992, 26.800000000000086, 37.10000000000026, 78.19999999999999, 267.59999999999985, 296.19999999999993, 126.39999999999966, -36.30000000000014, 274.6999999999998, 305.20000000000005, 121.99999999999952, 238.49999999999994, 302.59999999999985, 157.49999999999946, 14.700000000000001, 266.39999999999986, 132.39999999999966, 178.5999999999992, 235.69999999999982, 148.3999999999994, 166.79999999999984, 217.39999999999986, 240.29999999999984, 133.49999999999963, 110.99999999999955, 313.5999999999999, 231.09999999999962, 155.39999999999995, 289.1, 166.79999999999976, 153.89999999999955, 182.89999999999918, 100.09999999999994, 108.8999999999998, 119.79999999999976, 131.9999999999996, 6.200000000000113, 121.49999999999967, 136.49999999999963, 309.1000000000001, 255.49999999999991, 279.6999999999999, 104.09999999999975, 187.99999999999966, 34.50000000000006, -3.199999999999702, 20.69999999999998, 87.69999999999968, 165.5999999999993, 112.80000000000013, 167.0999999999998, 182.59999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 42.8000000000001, 7.399999999999965, 145.09999999999974, 63.199999999999996, 149.29999999999984, 20.000000000000014, 3.1999999999999615, -7.299999999999891, 100.99999999999989, 15.799999999999963, 93.19999999999963, 20.000000000000014, 11.599999999999964, 11.599999999999968, 13.699999999999946, 3.1999999999999615, 20.000000000000014, 126.49999999999973, -98.80000000000024, 5.600000000000179, 131.9, 1.0999999999999865, 126.49999999999993, 117.19999999999989, 101.59999999999945, 15.799999999999963, 20.000000000000014, -187.90000000000057, 130.9999999999998, 20.000000000000014, -24.099999999999746, 5.299999999999965, 106.99999999999999, 131.89999999999998, 15.799999999999963, -179.80000000000013, 20.000000000000014, 121.69999999999993, 15.799999999999963, 155.2999999999999, 59.60000000000019, 7.399999999999886, -58.60000000000025, 1.0999999999999865, 87.19999999999986, 5.299999999999965, 147.7999999999999, 86.60000000000002, 3.1999999999999615, 5.299999999999965, -9.399999999999855, 5.299999999999965, 150.49999999999986, 146.59999999999985, -24.099999999999746, -10.899999999999906, -7.8999999999998884, 127.10000000000002, 75.20000000000009, 89.30000000000003, 116.29999999999983, -25.60000000000001, -319.59999999999945, -30.39999999999977, 18.199999999999918, 108.50000000000003, 20.000000000000014, -0.9999999999999846, 105.19999999999987, 20.000000000000014, -19.899999999999743, 149.59999999999968, 127.0999999999998, 98.89999999999989, 92.89999999999984, 43.399999999999906, 5.599999999999971, 15.799999999999963, 14.0, 155.89999999999986, -167.8000000000002, -26.199999999999747, 109.99999999999997, 130.69999999999996, -160.60000000000065, -3.099999999999958, 90.20000000000002, 125.89999999999992, 20.000000000000014, -40.89999999999976, 107.59999999999988, 86.59999999999977, 128.9, 20.000000000000014, 9.499999999999964, 117.79999999999994, -82.90000000000046, 9.499999999999964, 5.299999999999965, 5.299999999999965, 15.799999999999962, -131.2000000000004, 133.39999999999992, 117.19999999999999, 109.39999999999998, 121.69999999999997, 150.49999999999991, -0.9999999999999881, 64.40000000000005, -93.10000000000008, -134.20000000000022, 126.1999999999999, 120.49999999999996, 144.49999999999986, 145.69999999999987, -7.299999999999891, 92.29999999999988, 107.29999999999998, 102.19999999999996, 136.09999999999982, 156.49999999999991, -3.099999999999979, 140.59999999999994, -24.099999999999746, 15.799999999999963, 113.89999999999995, 129.49999999999983, 20.000000000000014, 106.39999999999996, 14.599999999999973, 148.99999999999974, 48.80000000000004, 128.89999999999995, 158.89999999999992, -53.49999999999995, -66.39999999999998, 138.19999999999985, 157.39999999999984, 29.00000000000009, 70.69999999999993, 119.59999999999992, 124.39999999999996, -40.89999999999976, 93.19999999999993, -5.1999999999999265, 150.19999999999987, 154.39999999999992, 19.99999999999993, 127.09999999999978, 56.60000000000003, 39.80000000000005, 149.5999999999999, 93.49999999999997, 77.90000000000003, 38.900000000000034, -0.9999999999999881, 128.89999999999998, 149.89999999999986, 20.000000000000014, 15.799999999999963, 38.299999999999976, -13.599999999999783, 90.49999999999997, 5.299999999999965, 90.50000000000007, -9.399999999999855, 109.39999999999995, -59.80000000000062, 20.000000000000014, 3.1999999999999633, 89.30000000000007, 20.000000000000014, 30.49999999999996, 163.99999999999983, 136.09999999999997, 122.29999999999993, 90.20000000000002, 112.99999999999994, 142.7, 31.399999999999963, 13.699999999999964, 4.39999999999999, 113.59999999999994, 112.69999999999996, -173.20000000000056, -19.899999999999743, -7.299999999999894, 13.699999999999964, -21.999999999999744, 7.399999999999965, 26.300000000000026, 121.99999999999994, 11.599999999999964, 70.39999999999999, -64.60000000000011, -33.100000000000065, 123.19999999999996, 47.299999999999976, 107.2999999999999], "policy_predator_policy_reward": [28.0, 8.0, 6.0, 3.0, 4.0, 6.0, 2.0, 8.0, 15.0, 13.0, 0.0, 2.0, 4.0, 0.0, 4.0, 4.0, 3.0, 8.0, 52.0, 83.0, 27.0, 2.0, 13.0, 9.0, 10.0, 3.0, 2.0, 1.0, 96.0, 89.0, 21.0, 6.0, 7.0, 4.0, 8.0, 8.0, 23.0, 112.0, 12.0, 2.0, 1.0, 6.0, 2.0, 74.0, 3.0, 19.0, 2.0, 13.0, 34.0, 1.0, 7.0, 14.0, 7.0, 0.0, 2.0, 21.0, 9.0, 31.0, 14.0, 19.0, 27.0, 6.0, 161.0, 131.0, 10.0, 48.0, 1.0, 10.0, 4.0, 10.0, 19.0, 0.0, 0.0, 9.0, 11.0, 14.0, 36.0, 9.0, 26.0, 38.0, 80.0, 84.0, 22.0, 0.0, 61.0, 67.0, 19.0, 20.0, 0.0, 10.0, 35.0, 17.0, 16.0, 0.0, 5.0, 0.0, 49.0, 10.0, 7.0, 5.0, 9.0, 7.0, 4.0, 72.0, 14.0, 27.0, 18.0, 6.0, 33.0, 30.0, 122.0, 69.0, 12.0, 16.0, 8.0, 7.0, 12.0, 25.0, 29.0, 0.0, 5.0, 5.0, 11.0, 9.0, 21.0, 2.0, 19.0, 4.0, 0.0, 6.0, 6.0, 9.0, 4.0, 54.0, 34.0, 9.0, 51.0, 44.0, 6.0, 25.0, 14.0, 36.0, 29.0, 21.0, 0.0, 23.0, 9.0, 0.0, 36.0, 48.0, 20.0, 39.0, 30.0, 16.0, 31.0, 19.0, 18.0, 8.0, 6.0, 7.0, 10.0, 36.0, 17.0, 15.0, 7.0, 17.0, 25.0, 7.0, 38.0, 8.0, 15.0, 14.0, 52.0, 34.0, 4.0, 5.0, 19.0, 24.0, 18.0, 6.0, 47.0, 12.0, 34.0, 36.0, 3.0, 92.0, 5.0, 19.0, 9.0, 20.0, 20.0, 34.0, 11.0, 21.0, 67.0, 40.0, 40.0, 37.0, 15.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7527048913310488, "mean_inference_ms": 1.98044244613765, "mean_action_processing_ms": 0.3032807882070064, "mean_env_wait_ms": 0.25912194061547494, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010883450508117676, "StateBufferConnector_ms": 0.0040100812911987305, "ViewRequirementAgentConnector_ms": 0.11064207553863525}, "num_episodes": 18, "episode_return_max": 313.5999999999999, "episode_return_min": -53.20000000000027, "episode_return_mean": 138.76099999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.6619641068818, "num_env_steps_trained_throughput_per_sec": 342.6619641068818, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 11925.313, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11925.26, "sample_time_ms": 1654.216, "learn_time_ms": 10241.396, "learn_throughput": 390.572, "synch_weights_time_ms": 25.235}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "f0d88_00000", "date": "2024-08-14_10-51-40", "timestamp": 1723647100, "time_this_iter_s": 11.774003982543945, "time_total_s": 319.50694155693054, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac096820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 319.50694155693054, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 45.629411764705885, "ram_util_percent": 83.45294117647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1352689163394705, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.66544959330685, "policy_loss": -0.013799589978550714, "vf_loss": 5.65373740877424, "vf_explained_var": 0.6003906053210062, "kl": 0.016797877226696872, "entropy": 1.3150328026246771, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.360887469879534, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.0307203969627463, "policy_loss": -0.029001267564793428, "vf_loss": 2.0413164448170433, "vf_explained_var": 0.18461284129707903, "kl": 0.012118666188448923, "entropy": 1.2004865652038939, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 321.2000000000001, "episode_reward_min": -53.20000000000027, "episode_reward_mean": 160.90099999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.59999999999945, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 171.79999999999998, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 58.800499999999964, "predator_policy": 21.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [110.29999999999953, 168.09999999999937, 124.79999999999961, 16.899999999999995, 162.79999999999927, 145.49999999999935, 21.200000000000113, 235.29999999999987, 238.59999999999968, -53.20000000000027, 45.80000000000023, 139.4999999999997, 118.19999999999949, 19.099999999999977, 285.6999999999997, 216.79999999999913, 94.0, 93.7999999999997, 152.0999999999998, 105.79999999999981, 98.09999999999988, 126.0999999999998, 155.8999999999994, 118.69999999999956, 231.49999999999943, 34.50000000000022, 93.89999999999992, 26.800000000000086, 37.10000000000026, 78.19999999999999, 267.59999999999985, 296.19999999999993, 126.39999999999966, -36.30000000000014, 274.6999999999998, 305.20000000000005, 121.99999999999952, 238.49999999999994, 302.59999999999985, 157.49999999999946, 14.700000000000001, 266.39999999999986, 132.39999999999966, 178.5999999999992, 235.69999999999982, 148.3999999999994, 166.79999999999984, 217.39999999999986, 240.29999999999984, 133.49999999999963, 110.99999999999955, 313.5999999999999, 231.09999999999962, 155.39999999999995, 289.1, 166.79999999999976, 153.89999999999955, 182.89999999999918, 100.09999999999994, 108.8999999999998, 119.79999999999976, 131.9999999999996, 6.200000000000113, 121.49999999999967, 136.49999999999963, 309.1000000000001, 255.49999999999991, 279.6999999999999, 104.09999999999975, 187.99999999999966, 34.50000000000006, -3.199999999999702, 20.69999999999998, 87.69999999999968, 165.5999999999993, 112.80000000000013, 167.0999999999998, 182.59999999999985, 319.90000000000043, 321.2000000000001, 119.79999999999976, 158.09999999999926, 310.3000000000002, 248.9999999999998, 113.79999999999944, 246.99999999999966, 179.5999999999992, 308.0999999999999, 297.3999999999999, 147.79999999999959, 305.90000000000015, 126.3999999999997, 11.000000000000092, 119.19999999999929, 114.6999999999995, 279.39999999999986, 303.79999999999984, 30.40000000000006, 264.8999999999998, 298.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, 87.19999999999986, 5.299999999999965, 147.7999999999999, 86.60000000000002, 3.1999999999999615, 5.299999999999965, -9.399999999999855, 5.299999999999965, 150.49999999999986, 146.59999999999985, -24.099999999999746, -10.899999999999906, -7.8999999999998884, 127.10000000000002, 75.20000000000009, 89.30000000000003, 116.29999999999983, -25.60000000000001, -319.59999999999945, -30.39999999999977, 18.199999999999918, 108.50000000000003, 20.000000000000014, -0.9999999999999846, 105.19999999999987, 20.000000000000014, -19.899999999999743, 149.59999999999968, 127.0999999999998, 98.89999999999989, 92.89999999999984, 43.399999999999906, 5.599999999999971, 15.799999999999963, 14.0, 155.89999999999986, -167.8000000000002, -26.199999999999747, 109.99999999999997, 130.69999999999996, -160.60000000000065, -3.099999999999958, 90.20000000000002, 125.89999999999992, 20.000000000000014, -40.89999999999976, 107.59999999999988, 86.59999999999977, 128.9, 20.000000000000014, 9.499999999999964, 117.79999999999994, -82.90000000000046, 9.499999999999964, 5.299999999999965, 5.299999999999965, 15.799999999999962, -131.2000000000004, 133.39999999999992, 117.19999999999999, 109.39999999999998, 121.69999999999997, 150.49999999999991, -0.9999999999999881, 64.40000000000005, -93.10000000000008, -134.20000000000022, 126.1999999999999, 120.49999999999996, 144.49999999999986, 145.69999999999987, -7.299999999999891, 92.29999999999988, 107.29999999999998, 102.19999999999996, 136.09999999999982, 156.49999999999991, -3.099999999999979, 140.59999999999994, -24.099999999999746, 15.799999999999963, 113.89999999999995, 129.49999999999983, 20.000000000000014, 106.39999999999996, 14.599999999999973, 148.99999999999974, 48.80000000000004, 128.89999999999995, 158.89999999999992, -53.49999999999995, -66.39999999999998, 138.19999999999985, 157.39999999999984, 29.00000000000009, 70.69999999999993, 119.59999999999992, 124.39999999999996, -40.89999999999976, 93.19999999999993, -5.1999999999999265, 150.19999999999987, 154.39999999999992, 19.99999999999993, 127.09999999999978, 56.60000000000003, 39.80000000000005, 149.5999999999999, 93.49999999999997, 77.90000000000003, 38.900000000000034, -0.9999999999999881, 128.89999999999998, 149.89999999999986, 20.000000000000014, 15.799999999999963, 38.299999999999976, -13.599999999999783, 90.49999999999997, 5.299999999999965, 90.50000000000007, -9.399999999999855, 109.39999999999995, -59.80000000000062, 20.000000000000014, 3.1999999999999633, 89.30000000000007, 20.000000000000014, 30.49999999999996, 163.99999999999983, 136.09999999999997, 122.29999999999993, 90.20000000000002, 112.99999999999994, 142.7, 31.399999999999963, 13.699999999999964, 4.39999999999999, 113.59999999999994, 112.69999999999996, -173.20000000000056, -19.899999999999743, -7.299999999999894, 13.699999999999964, -21.999999999999744, 7.399999999999965, 26.300000000000026, 121.99999999999994, 11.599999999999964, 70.39999999999999, -64.60000000000011, -33.100000000000065, 123.19999999999996, 47.299999999999976, 107.2999999999999, 171.79999999999998, 139.09999999999974, 169.39999999999995, 90.79999999999997, 45.800000000000026, 20.000000000000014, 20.000000000000014, 121.09999999999988, 162.19999999999993, 127.09999999999988, 133.39999999999992, 32.60000000000003, -11.499999999999819, 83.29999999999995, 37.69999999999991, 143.29999999999976, 164.2999999999999, -33.69999999999981, 130.39999999999995, 163.69999999999996, 109.99999999999987, 151.39999999999998, 17.899999999999988, 128.89999999999998, 126.79999999999986, 163.09999999999982, 28.400000000000023, 20.000000000000014, -0.9999999999999846, -0.9999999999999917, 9.499999999999964, 73.69999999999993, 49.69999999999999, 20.000000000000014, 150.1999999999999, 102.19999999999996, 143.29999999999987, 150.5, -85.60000000000008, 20.000000000000014, 55.40000000000003, 159.4999999999999, 130.39999999999995, 135.49999999999997], "policy_predator_policy_reward": [3.0, 19.0, 2.0, 13.0, 34.0, 1.0, 7.0, 14.0, 7.0, 0.0, 2.0, 21.0, 9.0, 31.0, 14.0, 19.0, 27.0, 6.0, 161.0, 131.0, 10.0, 48.0, 1.0, 10.0, 4.0, 10.0, 19.0, 0.0, 0.0, 9.0, 11.0, 14.0, 36.0, 9.0, 26.0, 38.0, 80.0, 84.0, 22.0, 0.0, 61.0, 67.0, 19.0, 20.0, 0.0, 10.0, 35.0, 17.0, 16.0, 0.0, 5.0, 0.0, 49.0, 10.0, 7.0, 5.0, 9.0, 7.0, 4.0, 72.0, 14.0, 27.0, 18.0, 6.0, 33.0, 30.0, 122.0, 69.0, 12.0, 16.0, 8.0, 7.0, 12.0, 25.0, 29.0, 0.0, 5.0, 5.0, 11.0, 9.0, 21.0, 2.0, 19.0, 4.0, 0.0, 6.0, 6.0, 9.0, 4.0, 54.0, 34.0, 9.0, 51.0, 44.0, 6.0, 25.0, 14.0, 36.0, 29.0, 21.0, 0.0, 23.0, 9.0, 0.0, 36.0, 48.0, 20.0, 39.0, 30.0, 16.0, 31.0, 19.0, 18.0, 8.0, 6.0, 7.0, 10.0, 36.0, 17.0, 15.0, 7.0, 17.0, 25.0, 7.0, 38.0, 8.0, 15.0, 14.0, 52.0, 34.0, 4.0, 5.0, 19.0, 24.0, 18.0, 6.0, 47.0, 12.0, 34.0, 36.0, 3.0, 92.0, 5.0, 19.0, 9.0, 20.0, 20.0, 34.0, 11.0, 21.0, 67.0, 40.0, 40.0, 37.0, 15.0, 13.0, 6.0, 3.0, 31.0, 30.0, 8.0, 46.0, 13.0, 4.0, 10.0, 11.0, 52.0, 31.0, 22.0, 20.0, 39.0, 27.0, 15.0, 34.0, 11.0, 3.0, 21.0, 15.0, 1.0, 0.0, 0.0, 16.0, 34.0, 44.0, 0.0, 13.0, 35.0, 1.0, 45.0, 0.0, 16.0, 11.0, 5.0, 5.0, 21.0, 75.0, 13.0, 37.0, 16.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7512029160860145, "mean_inference_ms": 1.9775072298967649, "mean_action_processing_ms": 0.30312865949501033, "mean_env_wait_ms": 0.2581190367527577, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011728882789611816, "StateBufferConnector_ms": 0.004030704498291016, "ViewRequirementAgentConnector_ms": 0.1089482307434082}, "num_episodes": 22, "episode_return_max": 321.2000000000001, "episode_return_min": -53.20000000000027, "episode_return_mean": 160.90099999999975, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.50270679625885, "num_env_steps_trained_throughput_per_sec": 340.50270679625885, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 11904.032, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11903.975, "sample_time_ms": 1628.652, "learn_time_ms": 10244.569, "learn_throughput": 390.451, "synch_weights_time_ms": 26.383}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "f0d88_00000", "date": "2024-08-14_10-51-52", "timestamp": 1723647112, "time_this_iter_s": 11.87761402130127, "time_total_s": 331.3845555782318, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad49fa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 331.3845555782318, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 47.01176470588235, "ram_util_percent": 83.22352941176469}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1725641764030255, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.128587498488249, "policy_loss": -0.014475124707524344, "vf_loss": 6.1209931567863185, "vf_explained_var": 0.3448760751693968, "kl": 0.014531338451135006, "entropy": 1.3066962553079797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4008774522751097, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.9580687201212323, "policy_loss": -0.031020375137665757, "vf_loss": 2.9680091821958148, "vf_explained_var": 0.23697992645243487, "kl": 0.013879781682684058, "entropy": 1.0923352826209296, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 339.40000000000003, "episode_reward_min": -79.50000000000014, "episode_reward_mean": 171.53899999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -236.2000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.5, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": 62.664499999999954, "predator_policy": 23.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [118.69999999999956, 231.49999999999943, 34.50000000000022, 93.89999999999992, 26.800000000000086, 37.10000000000026, 78.19999999999999, 267.59999999999985, 296.19999999999993, 126.39999999999966, -36.30000000000014, 274.6999999999998, 305.20000000000005, 121.99999999999952, 238.49999999999994, 302.59999999999985, 157.49999999999946, 14.700000000000001, 266.39999999999986, 132.39999999999966, 178.5999999999992, 235.69999999999982, 148.3999999999994, 166.79999999999984, 217.39999999999986, 240.29999999999984, 133.49999999999963, 110.99999999999955, 313.5999999999999, 231.09999999999962, 155.39999999999995, 289.1, 166.79999999999976, 153.89999999999955, 182.89999999999918, 100.09999999999994, 108.8999999999998, 119.79999999999976, 131.9999999999996, 6.200000000000113, 121.49999999999967, 136.49999999999963, 309.1000000000001, 255.49999999999991, 279.6999999999999, 104.09999999999975, 187.99999999999966, 34.50000000000006, -3.199999999999702, 20.69999999999998, 87.69999999999968, 165.5999999999993, 112.80000000000013, 167.0999999999998, 182.59999999999985, 319.90000000000043, 321.2000000000001, 119.79999999999976, 158.09999999999926, 310.3000000000002, 248.9999999999998, 113.79999999999944, 246.99999999999966, 179.5999999999992, 308.0999999999999, 297.3999999999999, 147.79999999999959, 305.90000000000015, 126.3999999999997, 11.000000000000092, 119.19999999999929, 114.6999999999995, 279.39999999999986, 303.79999999999984, 30.40000000000006, 264.8999999999998, 298.9, 257.2999999999998, 303.6999999999997, 33.90000000000014, 301.8000000000003, 106.59999999999926, 279.0, -16.799999999999848, 287.0, 223.69999999999987, -79.50000000000014, 290.79999999999984, -0.4999999999998921, 1.3000000000001544, 165.99999999999946, 106.99999999999966, 46.50000000000018, 306.0, 339.40000000000003, 304.50000000000034, 321.70000000000005, 114.39999999999955, 63.70000000000017, 127.49999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-40.89999999999976, 107.59999999999988, 86.59999999999977, 128.9, 20.000000000000014, 9.499999999999964, 117.79999999999994, -82.90000000000046, 9.499999999999964, 5.299999999999965, 5.299999999999965, 15.799999999999962, -131.2000000000004, 133.39999999999992, 117.19999999999999, 109.39999999999998, 121.69999999999997, 150.49999999999991, -0.9999999999999881, 64.40000000000005, -93.10000000000008, -134.20000000000022, 126.1999999999999, 120.49999999999996, 144.49999999999986, 145.69999999999987, -7.299999999999891, 92.29999999999988, 107.29999999999998, 102.19999999999996, 136.09999999999982, 156.49999999999991, -3.099999999999979, 140.59999999999994, -24.099999999999746, 15.799999999999963, 113.89999999999995, 129.49999999999983, 20.000000000000014, 106.39999999999996, 14.599999999999973, 148.99999999999974, 48.80000000000004, 128.89999999999995, 158.89999999999992, -53.49999999999995, -66.39999999999998, 138.19999999999985, 157.39999999999984, 29.00000000000009, 70.69999999999993, 119.59999999999992, 124.39999999999996, -40.89999999999976, 93.19999999999993, -5.1999999999999265, 150.19999999999987, 154.39999999999992, 19.99999999999993, 127.09999999999978, 56.60000000000003, 39.80000000000005, 149.5999999999999, 93.49999999999997, 77.90000000000003, 38.900000000000034, -0.9999999999999881, 128.89999999999998, 149.89999999999986, 20.000000000000014, 15.799999999999963, 38.299999999999976, -13.599999999999783, 90.49999999999997, 5.299999999999965, 90.50000000000007, -9.399999999999855, 109.39999999999995, -59.80000000000062, 20.000000000000014, 3.1999999999999633, 89.30000000000007, 20.000000000000014, 30.49999999999996, 163.99999999999983, 136.09999999999997, 122.29999999999993, 90.20000000000002, 112.99999999999994, 142.7, 31.399999999999963, 13.699999999999964, 4.39999999999999, 113.59999999999994, 112.69999999999996, -173.20000000000056, -19.899999999999743, -7.299999999999894, 13.699999999999964, -21.999999999999744, 7.399999999999965, 26.300000000000026, 121.99999999999994, 11.599999999999964, 70.39999999999999, -64.60000000000011, -33.100000000000065, 123.19999999999996, 47.299999999999976, 107.2999999999999, 171.79999999999998, 139.09999999999974, 169.39999999999995, 90.79999999999997, 45.800000000000026, 20.000000000000014, 20.000000000000014, 121.09999999999988, 162.19999999999993, 127.09999999999988, 133.39999999999992, 32.60000000000003, -11.499999999999819, 83.29999999999995, 37.69999999999991, 143.29999999999976, 164.2999999999999, -33.69999999999981, 130.39999999999995, 163.69999999999996, 109.99999999999987, 151.39999999999998, 17.899999999999988, 128.89999999999998, 126.79999999999986, 163.09999999999982, 28.400000000000023, 20.000000000000014, -0.9999999999999846, -0.9999999999999917, 9.499999999999964, 73.69999999999993, 49.69999999999999, 20.000000000000014, 150.1999999999999, 102.19999999999996, 143.29999999999987, 150.5, -85.60000000000008, 20.000000000000014, 55.40000000000003, 159.4999999999999, 130.39999999999995, 135.49999999999997, 42.20000000000002, 172.09999999999994, 136.39999999999998, 146.29999999999984, -236.2000000000002, 103.09999999999994, 149.2999999999999, 105.49999999999994, 34.10000000000021, 18.50000000000002, 95.29999999999987, 154.6999999999999, -142.30000000000007, -11.499999999999819, 130.39999999999992, 134.59999999999997, 83.29999999999995, 91.40000000000003, -64.00000000000074, -173.5, 144.19999999999985, 131.59999999999988, -66.10000000000042, -51.400000000000006, -21.999999999999744, -75.70000000000002, 20.000000000000014, 127.99999999999999, 11.599999999999964, 52.40000000000005, 33.20000000000002, -78.70000000000084, 150.2, 144.7999999999999, 155.8999999999999, 177.5, 130.09999999999988, 154.39999999999986, 173.89999999999986, 147.7999999999999, 73.40000000000003, -0.9999999999999846, 3.1999999999999615, -71.50000000000009, 61.7, -32.20000000000003], "policy_predator_policy_reward": [35.0, 17.0, 16.0, 0.0, 5.0, 0.0, 49.0, 10.0, 7.0, 5.0, 9.0, 7.0, 4.0, 72.0, 14.0, 27.0, 18.0, 6.0, 33.0, 30.0, 122.0, 69.0, 12.0, 16.0, 8.0, 7.0, 12.0, 25.0, 29.0, 0.0, 5.0, 5.0, 11.0, 9.0, 21.0, 2.0, 19.0, 4.0, 0.0, 6.0, 6.0, 9.0, 4.0, 54.0, 34.0, 9.0, 51.0, 44.0, 6.0, 25.0, 14.0, 36.0, 29.0, 21.0, 0.0, 23.0, 9.0, 0.0, 36.0, 48.0, 20.0, 39.0, 30.0, 16.0, 31.0, 19.0, 18.0, 8.0, 6.0, 7.0, 10.0, 36.0, 17.0, 15.0, 7.0, 17.0, 25.0, 7.0, 38.0, 8.0, 15.0, 14.0, 52.0, 34.0, 4.0, 5.0, 19.0, 24.0, 18.0, 6.0, 47.0, 12.0, 34.0, 36.0, 3.0, 92.0, 5.0, 19.0, 9.0, 20.0, 20.0, 34.0, 11.0, 21.0, 67.0, 40.0, 40.0, 37.0, 15.0, 13.0, 6.0, 3.0, 31.0, 30.0, 8.0, 46.0, 13.0, 4.0, 10.0, 11.0, 52.0, 31.0, 22.0, 20.0, 39.0, 27.0, 15.0, 34.0, 11.0, 3.0, 21.0, 15.0, 1.0, 0.0, 0.0, 16.0, 34.0, 44.0, 0.0, 13.0, 35.0, 1.0, 45.0, 0.0, 16.0, 11.0, 5.0, 5.0, 21.0, 75.0, 13.0, 37.0, 16.0, 17.0, 43.0, 0.0, 11.0, 10.0, 106.0, 61.0, 22.0, 25.0, 16.0, 38.0, 20.0, 9.0, 71.0, 66.0, 13.0, 9.0, 23.0, 26.0, 153.0, 5.0, 12.0, 3.0, 80.0, 37.0, 93.0, 6.0, 17.0, 1.0, 3.0, 40.0, 78.0, 14.0, 7.0, 4.0, 6.0, 0.0, 16.0, 4.0, 0.0, 0.0, 35.0, 7.0, 88.0, 44.0, 32.0, 66.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7497657490151348, "mean_inference_ms": 1.9819245356263473, "mean_action_processing_ms": 0.31288197067776663, "mean_env_wait_ms": 0.25883433634762215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01593339443206787, "StateBufferConnector_ms": 0.003899812698364258, "ViewRequirementAgentConnector_ms": 0.1243140697479248}, "num_episodes": 23, "episode_return_max": 339.40000000000003, "episode_return_min": -79.50000000000014, "episode_return_mean": 171.53899999999985, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.1493587086528, "num_env_steps_trained_throughput_per_sec": 306.1493587086528, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 11984.465, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11984.407, "sample_time_ms": 1659.89, "learn_time_ms": 10293.345, "learn_throughput": 388.601, "synch_weights_time_ms": 26.794}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "f0d88_00000", "date": "2024-08-14_10-52-06", "timestamp": 1723647126, "time_this_iter_s": 13.125555992126465, "time_total_s": 344.5101115703583, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac05f5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 344.5101115703583, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 50.577777777777776, "ram_util_percent": 83.49444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8105244476013085, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.13951722755634, "policy_loss": -0.010724787109423053, "vf_loss": 6.129801948991402, "vf_explained_var": 0.017459421183066395, "kl": 0.013458475499749377, "entropy": 1.3025965051045494, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.14964243416433, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.362574324279866, "policy_loss": -0.024731808939391857, "vf_loss": 3.3675528544597526, "vf_explained_var": 0.20417000326530013, "kl": 0.013006274728445219, "entropy": 1.1171107427783744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 347.9, "episode_reward_min": -238.20000000000002, "episode_reward_mean": 169.02799999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -236.2000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.5, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": 59.33399999999994, "predator_policy": 25.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [266.39999999999986, 132.39999999999966, 178.5999999999992, 235.69999999999982, 148.3999999999994, 166.79999999999984, 217.39999999999986, 240.29999999999984, 133.49999999999963, 110.99999999999955, 313.5999999999999, 231.09999999999962, 155.39999999999995, 289.1, 166.79999999999976, 153.89999999999955, 182.89999999999918, 100.09999999999994, 108.8999999999998, 119.79999999999976, 131.9999999999996, 6.200000000000113, 121.49999999999967, 136.49999999999963, 309.1000000000001, 255.49999999999991, 279.6999999999999, 104.09999999999975, 187.99999999999966, 34.50000000000006, -3.199999999999702, 20.69999999999998, 87.69999999999968, 165.5999999999993, 112.80000000000013, 167.0999999999998, 182.59999999999985, 319.90000000000043, 321.2000000000001, 119.79999999999976, 158.09999999999926, 310.3000000000002, 248.9999999999998, 113.79999999999944, 246.99999999999966, 179.5999999999992, 308.0999999999999, 297.3999999999999, 147.79999999999959, 305.90000000000015, 126.3999999999997, 11.000000000000092, 119.19999999999929, 114.6999999999995, 279.39999999999986, 303.79999999999984, 30.40000000000006, 264.8999999999998, 298.9, 257.2999999999998, 303.6999999999997, 33.90000000000014, 301.8000000000003, 106.59999999999926, 279.0, -16.799999999999848, 287.0, 223.69999999999987, -79.50000000000014, 290.79999999999984, -0.4999999999998921, 1.3000000000001544, 165.99999999999946, 106.99999999999966, 46.50000000000018, 306.0, 339.40000000000003, 304.50000000000034, 321.70000000000005, 114.39999999999955, 63.70000000000017, 127.49999999999997, 241.49999999999983, 37.50000000000026, 247.39999999999986, 103.09999999999951, 106.69999999999942, -60.99999999999993, 258.4999999999999, 156.29999999999973, 186.20000000000002, 347.9, 274.7999999999997, 28.10000000000008, 34.80000000000011, 117.89999999999934, -18.099999999999973, 331.3000000000004, -238.20000000000002, 283.99999999999966], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [113.89999999999995, 129.49999999999983, 20.000000000000014, 106.39999999999996, 14.599999999999973, 148.99999999999974, 48.80000000000004, 128.89999999999995, 158.89999999999992, -53.49999999999995, -66.39999999999998, 138.19999999999985, 157.39999999999984, 29.00000000000009, 70.69999999999993, 119.59999999999992, 124.39999999999996, -40.89999999999976, 93.19999999999993, -5.1999999999999265, 150.19999999999987, 154.39999999999992, 19.99999999999993, 127.09999999999978, 56.60000000000003, 39.80000000000005, 149.5999999999999, 93.49999999999997, 77.90000000000003, 38.900000000000034, -0.9999999999999881, 128.89999999999998, 149.89999999999986, 20.000000000000014, 15.799999999999963, 38.299999999999976, -13.599999999999783, 90.49999999999997, 5.299999999999965, 90.50000000000007, -9.399999999999855, 109.39999999999995, -59.80000000000062, 20.000000000000014, 3.1999999999999633, 89.30000000000007, 20.000000000000014, 30.49999999999996, 163.99999999999983, 136.09999999999997, 122.29999999999993, 90.20000000000002, 112.99999999999994, 142.7, 31.399999999999963, 13.699999999999964, 4.39999999999999, 113.59999999999994, 112.69999999999996, -173.20000000000056, -19.899999999999743, -7.299999999999894, 13.699999999999964, -21.999999999999744, 7.399999999999965, 26.300000000000026, 121.99999999999994, 11.599999999999964, 70.39999999999999, -64.60000000000011, -33.100000000000065, 123.19999999999996, 47.299999999999976, 107.2999999999999, 171.79999999999998, 139.09999999999974, 169.39999999999995, 90.79999999999997, 45.800000000000026, 20.000000000000014, 20.000000000000014, 121.09999999999988, 162.19999999999993, 127.09999999999988, 133.39999999999992, 32.60000000000003, -11.499999999999819, 83.29999999999995, 37.69999999999991, 143.29999999999976, 164.2999999999999, -33.69999999999981, 130.39999999999995, 163.69999999999996, 109.99999999999987, 151.39999999999998, 17.899999999999988, 128.89999999999998, 126.79999999999986, 163.09999999999982, 28.400000000000023, 20.000000000000014, -0.9999999999999846, -0.9999999999999917, 9.499999999999964, 73.69999999999993, 49.69999999999999, 20.000000000000014, 150.1999999999999, 102.19999999999996, 143.29999999999987, 150.5, -85.60000000000008, 20.000000000000014, 55.40000000000003, 159.4999999999999, 130.39999999999995, 135.49999999999997, 42.20000000000002, 172.09999999999994, 136.39999999999998, 146.29999999999984, -236.2000000000002, 103.09999999999994, 149.2999999999999, 105.49999999999994, 34.10000000000021, 18.50000000000002, 95.29999999999987, 154.6999999999999, -142.30000000000007, -11.499999999999819, 130.39999999999992, 134.59999999999997, 83.29999999999995, 91.40000000000003, -64.00000000000074, -173.5, 144.19999999999985, 131.59999999999988, -66.10000000000042, -51.400000000000006, -21.999999999999744, -75.70000000000002, 20.000000000000014, 127.99999999999999, 11.599999999999964, 52.40000000000005, 33.20000000000002, -78.70000000000084, 150.2, 144.7999999999999, 155.8999999999999, 177.5, 130.09999999999988, 154.39999999999986, 173.89999999999986, 147.7999999999999, 73.40000000000003, -0.9999999999999846, 3.1999999999999615, -71.50000000000009, 61.7, -32.20000000000003, 120.49999999999996, 92.00000000000009, 11.59999999999997, 17.899999999999988, 107.29999999999995, 118.09999999999995, 20.000000000000014, 43.099999999999994, 7.399999999999965, 59.29999999999998, 0.5000000000000007, -233.5, 161.29999999999998, 39.19999999999987, 49.99999999999993, 62.299999999999955, 76.39999999999999, 78.79999999999997, 174.79999999999998, 163.09999999999997, 91.70000000000003, 160.09999999999982, -59.80000000000037, 23.899999999999984, -99.4, -75.80000000000092, 17.899999999999988, 62.000000000000036, -169.60000000000005, 27.499999999999993, 154.0999999999999, 171.19999999999985, -199.6, -220.60000000000002, 129.1999999999998, 123.79999999999987], "policy_predator_policy_reward": [19.0, 4.0, 0.0, 6.0, 6.0, 9.0, 4.0, 54.0, 34.0, 9.0, 51.0, 44.0, 6.0, 25.0, 14.0, 36.0, 29.0, 21.0, 0.0, 23.0, 9.0, 0.0, 36.0, 48.0, 20.0, 39.0, 30.0, 16.0, 31.0, 19.0, 18.0, 8.0, 6.0, 7.0, 10.0, 36.0, 17.0, 15.0, 7.0, 17.0, 25.0, 7.0, 38.0, 8.0, 15.0, 14.0, 52.0, 34.0, 4.0, 5.0, 19.0, 24.0, 18.0, 6.0, 47.0, 12.0, 34.0, 36.0, 3.0, 92.0, 5.0, 19.0, 9.0, 20.0, 20.0, 34.0, 11.0, 21.0, 67.0, 40.0, 40.0, 37.0, 15.0, 13.0, 6.0, 3.0, 31.0, 30.0, 8.0, 46.0, 13.0, 4.0, 10.0, 11.0, 52.0, 31.0, 22.0, 20.0, 39.0, 27.0, 15.0, 34.0, 11.0, 3.0, 21.0, 15.0, 1.0, 0.0, 0.0, 16.0, 34.0, 44.0, 0.0, 13.0, 35.0, 1.0, 45.0, 0.0, 16.0, 11.0, 5.0, 5.0, 21.0, 75.0, 13.0, 37.0, 16.0, 17.0, 43.0, 0.0, 11.0, 10.0, 106.0, 61.0, 22.0, 25.0, 16.0, 38.0, 20.0, 9.0, 71.0, 66.0, 13.0, 9.0, 23.0, 26.0, 153.0, 5.0, 12.0, 3.0, 80.0, 37.0, 93.0, 6.0, 17.0, 1.0, 3.0, 40.0, 78.0, 14.0, 7.0, 4.0, 6.0, 0.0, 16.0, 4.0, 0.0, 0.0, 35.0, 7.0, 88.0, 44.0, 32.0, 66.0, 11.0, 18.0, 5.0, 3.0, 14.0, 8.0, 13.0, 27.0, 34.0, 6.0, 149.0, 23.0, 38.0, 20.0, 4.0, 40.0, 9.0, 22.0, 4.0, 6.0, 19.0, 4.0, 59.0, 5.0, 107.0, 103.0, 0.0, 38.0, 39.0, 85.0, 0.0, 6.0, 109.0, 73.0, 17.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7493946713119735, "mean_inference_ms": 1.9861593990670918, "mean_action_processing_ms": 0.3192705523841934, "mean_env_wait_ms": 0.2590641130961259, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015088081359863281, "StateBufferConnector_ms": 0.0031890869140625, "ViewRequirementAgentConnector_ms": 0.12780559062957764}, "num_episodes": 18, "episode_return_max": 347.9, "episode_return_min": -238.20000000000002, "episode_return_mean": 169.02799999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 335.7471784452166, "num_env_steps_trained_throughput_per_sec": 335.7471784452166, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 11923.521, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11923.464, "sample_time_ms": 1610.395, "learn_time_ms": 10281.434, "learn_throughput": 389.051, "synch_weights_time_ms": 27.228}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "f0d88_00000", "date": "2024-08-14_10-52-18", "timestamp": 1723647138, "time_this_iter_s": 12.007966995239258, "time_total_s": 356.51807856559753, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4bcb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 356.51807856559753, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 46.470588235294116, "ram_util_percent": 83.38823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1353419006501557, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.470297162747257, "policy_loss": -0.01248300439510593, "vf_loss": 6.465162840091362, "vf_explained_var": -0.47748251226213245, "kl": 0.01159988426648692, "entropy": 1.3339817864554269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4504858018859985, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.35370852808473, "policy_loss": -0.01976500709353892, "vf_loss": 5.348921356251631, "vf_explained_var": 0.25250960339314094, "kl": 0.01616604776824966, "entropy": 1.1436937738347936, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 347.9, "episode_reward_min": -371.40000000000003, "episode_reward_mean": 133.90799999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -362.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.5, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": 36.518999999999956, "predator_policy": 30.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [108.8999999999998, 119.79999999999976, 131.9999999999996, 6.200000000000113, 121.49999999999967, 136.49999999999963, 309.1000000000001, 255.49999999999991, 279.6999999999999, 104.09999999999975, 187.99999999999966, 34.50000000000006, -3.199999999999702, 20.69999999999998, 87.69999999999968, 165.5999999999993, 112.80000000000013, 167.0999999999998, 182.59999999999985, 319.90000000000043, 321.2000000000001, 119.79999999999976, 158.09999999999926, 310.3000000000002, 248.9999999999998, 113.79999999999944, 246.99999999999966, 179.5999999999992, 308.0999999999999, 297.3999999999999, 147.79999999999959, 305.90000000000015, 126.3999999999997, 11.000000000000092, 119.19999999999929, 114.6999999999995, 279.39999999999986, 303.79999999999984, 30.40000000000006, 264.8999999999998, 298.9, 257.2999999999998, 303.6999999999997, 33.90000000000014, 301.8000000000003, 106.59999999999926, 279.0, -16.799999999999848, 287.0, 223.69999999999987, -79.50000000000014, 290.79999999999984, -0.4999999999998921, 1.3000000000001544, 165.99999999999946, 106.99999999999966, 46.50000000000018, 306.0, 339.40000000000003, 304.50000000000034, 321.70000000000005, 114.39999999999955, 63.70000000000017, 127.49999999999997, 241.49999999999983, 37.50000000000026, 247.39999999999986, 103.09999999999951, 106.69999999999942, -60.99999999999993, 258.4999999999999, 156.29999999999973, 186.20000000000002, 347.9, 274.7999999999997, 28.10000000000008, 34.80000000000011, 117.89999999999934, -18.099999999999973, 331.3000000000004, -238.20000000000002, 283.99999999999966, -56.89999999999993, -142.20000000000056, 84.20000000000005, 73.29999999999939, 17.79999999999999, -95.70000000000016, 32.20000000000018, -58.80000000000135, -363.7, 139.79999999999933, 158.49999999999977, 135.09999999999997, 117.69999999999953, -371.40000000000003, 132.90000000000023, 8.00000000000014, 264.4999999999998, -163.90000000000066], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-13.599999999999783, 90.49999999999997, 5.299999999999965, 90.50000000000007, -9.399999999999855, 109.39999999999995, -59.80000000000062, 20.000000000000014, 3.1999999999999633, 89.30000000000007, 20.000000000000014, 30.49999999999996, 163.99999999999983, 136.09999999999997, 122.29999999999993, 90.20000000000002, 112.99999999999994, 142.7, 31.399999999999963, 13.699999999999964, 4.39999999999999, 113.59999999999994, 112.69999999999996, -173.20000000000056, -19.899999999999743, -7.299999999999894, 13.699999999999964, -21.999999999999744, 7.399999999999965, 26.300000000000026, 121.99999999999994, 11.599999999999964, 70.39999999999999, -64.60000000000011, -33.100000000000065, 123.19999999999996, 47.299999999999976, 107.2999999999999, 171.79999999999998, 139.09999999999974, 169.39999999999995, 90.79999999999997, 45.800000000000026, 20.000000000000014, 20.000000000000014, 121.09999999999988, 162.19999999999993, 127.09999999999988, 133.39999999999992, 32.60000000000003, -11.499999999999819, 83.29999999999995, 37.69999999999991, 143.29999999999976, 164.2999999999999, -33.69999999999981, 130.39999999999995, 163.69999999999996, 109.99999999999987, 151.39999999999998, 17.899999999999988, 128.89999999999998, 126.79999999999986, 163.09999999999982, 28.400000000000023, 20.000000000000014, -0.9999999999999846, -0.9999999999999917, 9.499999999999964, 73.69999999999993, 49.69999999999999, 20.000000000000014, 150.1999999999999, 102.19999999999996, 143.29999999999987, 150.5, -85.60000000000008, 20.000000000000014, 55.40000000000003, 159.4999999999999, 130.39999999999995, 135.49999999999997, 42.20000000000002, 172.09999999999994, 136.39999999999998, 146.29999999999984, -236.2000000000002, 103.09999999999994, 149.2999999999999, 105.49999999999994, 34.10000000000021, 18.50000000000002, 95.29999999999987, 154.6999999999999, -142.30000000000007, -11.499999999999819, 130.39999999999992, 134.59999999999997, 83.29999999999995, 91.40000000000003, -64.00000000000074, -173.5, 144.19999999999985, 131.59999999999988, -66.10000000000042, -51.400000000000006, -21.999999999999744, -75.70000000000002, 20.000000000000014, 127.99999999999999, 11.599999999999964, 52.40000000000005, 33.20000000000002, -78.70000000000084, 150.2, 144.7999999999999, 155.8999999999999, 177.5, 130.09999999999988, 154.39999999999986, 173.89999999999986, 147.7999999999999, 73.40000000000003, -0.9999999999999846, 3.1999999999999615, -71.50000000000009, 61.7, -32.20000000000003, 120.49999999999996, 92.00000000000009, 11.59999999999997, 17.899999999999988, 107.29999999999995, 118.09999999999995, 20.000000000000014, 43.099999999999994, 7.399999999999965, 59.29999999999998, 0.5000000000000007, -233.5, 161.29999999999998, 39.19999999999987, 49.99999999999993, 62.299999999999955, 76.39999999999999, 78.79999999999997, 174.79999999999998, 163.09999999999997, 91.70000000000003, 160.09999999999982, -59.80000000000037, 23.899999999999984, -99.4, -75.80000000000092, 17.899999999999988, 62.000000000000036, -169.60000000000005, 27.499999999999993, 154.0999999999999, 171.19999999999985, -199.6, -220.60000000000002, 129.1999999999998, 123.79999999999987, -143.8, -24.099999999999746, -337.29999999999995, -19.899999999999757, 20.000000000000014, 6.2000000000000135, 20.000000000000014, -24.69999999999999, 7.099999999999959, -28.29999999999979, -314.2, 9.499999999999964, 3.1999999999999615, 20.000000000000014, -28.29999999999975, -95.50000000000082, -246.7, -301.0, 20.000000000000014, 108.79999999999984, 50.59999999999988, 53.899999999999906, 52.39999999999998, 16.700000000000003, 44.59999999999994, 28.099999999999966, -344.4999999999999, -253.9, 89.60000000000008, 26.300000000000196, -47.19999999999976, -80.79999999999998, 143.29999999999987, 54.200000000000024, -362.5, 11.599999999999964], "policy_predator_policy_reward": [17.0, 15.0, 7.0, 17.0, 25.0, 7.0, 38.0, 8.0, 15.0, 14.0, 52.0, 34.0, 4.0, 5.0, 19.0, 24.0, 18.0, 6.0, 47.0, 12.0, 34.0, 36.0, 3.0, 92.0, 5.0, 19.0, 9.0, 20.0, 20.0, 34.0, 11.0, 21.0, 67.0, 40.0, 40.0, 37.0, 15.0, 13.0, 6.0, 3.0, 31.0, 30.0, 8.0, 46.0, 13.0, 4.0, 10.0, 11.0, 52.0, 31.0, 22.0, 20.0, 39.0, 27.0, 15.0, 34.0, 11.0, 3.0, 21.0, 15.0, 1.0, 0.0, 0.0, 16.0, 34.0, 44.0, 0.0, 13.0, 35.0, 1.0, 45.0, 0.0, 16.0, 11.0, 5.0, 5.0, 21.0, 75.0, 13.0, 37.0, 16.0, 17.0, 43.0, 0.0, 11.0, 10.0, 106.0, 61.0, 22.0, 25.0, 16.0, 38.0, 20.0, 9.0, 71.0, 66.0, 13.0, 9.0, 23.0, 26.0, 153.0, 5.0, 12.0, 3.0, 80.0, 37.0, 93.0, 6.0, 17.0, 1.0, 3.0, 40.0, 78.0, 14.0, 7.0, 4.0, 6.0, 0.0, 16.0, 4.0, 0.0, 0.0, 35.0, 7.0, 88.0, 44.0, 32.0, 66.0, 11.0, 18.0, 5.0, 3.0, 14.0, 8.0, 13.0, 27.0, 34.0, 6.0, 149.0, 23.0, 38.0, 20.0, 4.0, 40.0, 9.0, 22.0, 4.0, 6.0, 19.0, 4.0, 59.0, 5.0, 107.0, 103.0, 0.0, 38.0, 39.0, 85.0, 0.0, 6.0, 109.0, 73.0, 17.0, 14.0, 111.0, 0.0, 165.0, 50.0, 23.0, 35.0, 71.0, 7.0, 36.0, 3.0, 44.0, 165.0, 3.0, 6.0, 10.0, 55.0, 9.0, 175.0, 4.0, 7.0, 53.0, 1.0, 35.0, 31.0, 45.0, 0.0, 102.0, 125.0, 0.0, 17.0, 22.0, 114.0, 35.0, 32.0, 186.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.748905141640284, "mean_inference_ms": 1.9890988417500772, "mean_action_processing_ms": 0.3253736756413328, "mean_env_wait_ms": 0.25915546631353675, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014267921447753906, "StateBufferConnector_ms": 0.003925204277038574, "ViewRequirementAgentConnector_ms": 0.1225893497467041}, "num_episodes": 18, "episode_return_max": 347.9, "episode_return_min": -371.40000000000003, "episode_return_mean": 133.90799999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.4749154030285, "num_env_steps_trained_throughput_per_sec": 336.4749154030285, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 11911.13, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11911.073, "sample_time_ms": 1585.049, "learn_time_ms": 10294.424, "learn_throughput": 388.56, "synch_weights_time_ms": 27.01}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "f0d88_00000", "date": "2024-08-14_10-52-30", "timestamp": 1723647150, "time_this_iter_s": 12.026381969451904, "time_total_s": 368.54446053504944, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0d8af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 368.54446053504944, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 47.62777777777778, "ram_util_percent": 83.46666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.476391342392674, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.986048284914128, "policy_loss": -0.013588588374972383, "vf_loss": 6.979347225219485, "vf_explained_var": -0.3393183633133217, "kl": 0.013359431302738, "entropy": 1.3098257917575735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0951051613641165, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.924475415295394, "policy_loss": -0.03027440086425967, "vf_loss": 5.928649939935674, "vf_explained_var": 0.23876524227006093, "kl": 0.017185093351326317, "entropy": 1.141773083853343, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 347.9, "episode_reward_min": -371.40000000000003, "episode_reward_mean": 105.30099999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -362.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.5, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": 14.32049999999996, "predator_policy": 38.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [182.59999999999985, 319.90000000000043, 321.2000000000001, 119.79999999999976, 158.09999999999926, 310.3000000000002, 248.9999999999998, 113.79999999999944, 246.99999999999966, 179.5999999999992, 308.0999999999999, 297.3999999999999, 147.79999999999959, 305.90000000000015, 126.3999999999997, 11.000000000000092, 119.19999999999929, 114.6999999999995, 279.39999999999986, 303.79999999999984, 30.40000000000006, 264.8999999999998, 298.9, 257.2999999999998, 303.6999999999997, 33.90000000000014, 301.8000000000003, 106.59999999999926, 279.0, -16.799999999999848, 287.0, 223.69999999999987, -79.50000000000014, 290.79999999999984, -0.4999999999998921, 1.3000000000001544, 165.99999999999946, 106.99999999999966, 46.50000000000018, 306.0, 339.40000000000003, 304.50000000000034, 321.70000000000005, 114.39999999999955, 63.70000000000017, 127.49999999999997, 241.49999999999983, 37.50000000000026, 247.39999999999986, 103.09999999999951, 106.69999999999942, -60.99999999999993, 258.4999999999999, 156.29999999999973, 186.20000000000002, 347.9, 274.7999999999997, 28.10000000000008, 34.80000000000011, 117.89999999999934, -18.099999999999973, 331.3000000000004, -238.20000000000002, 283.99999999999966, -56.89999999999993, -142.20000000000056, 84.20000000000005, 73.29999999999939, 17.79999999999999, -95.70000000000016, 32.20000000000018, -58.80000000000135, -363.7, 139.79999999999933, 158.49999999999977, 135.09999999999997, 117.69999999999953, -371.40000000000003, 132.90000000000023, 8.00000000000014, 264.4999999999998, -163.90000000000066, -132.40000000000018, -183.50000000000009, -109.79999999999998, 312.09999999999997, -202.50000000000009, 120.09999999999893, -82.30000000000008, -203.2, 309.00000000000034, 17.900000000000034, -24.999999999999936, -57.50000000000008, 26.80000000000009, -292.6, -31.099999999999937, -274.90000000000003, 164.6999999999993, 129.99999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [47.299999999999976, 107.2999999999999, 171.79999999999998, 139.09999999999974, 169.39999999999995, 90.79999999999997, 45.800000000000026, 20.000000000000014, 20.000000000000014, 121.09999999999988, 162.19999999999993, 127.09999999999988, 133.39999999999992, 32.60000000000003, -11.499999999999819, 83.29999999999995, 37.69999999999991, 143.29999999999976, 164.2999999999999, -33.69999999999981, 130.39999999999995, 163.69999999999996, 109.99999999999987, 151.39999999999998, 17.899999999999988, 128.89999999999998, 126.79999999999986, 163.09999999999982, 28.400000000000023, 20.000000000000014, -0.9999999999999846, -0.9999999999999917, 9.499999999999964, 73.69999999999993, 49.69999999999999, 20.000000000000014, 150.1999999999999, 102.19999999999996, 143.29999999999987, 150.5, -85.60000000000008, 20.000000000000014, 55.40000000000003, 159.4999999999999, 130.39999999999995, 135.49999999999997, 42.20000000000002, 172.09999999999994, 136.39999999999998, 146.29999999999984, -236.2000000000002, 103.09999999999994, 149.2999999999999, 105.49999999999994, 34.10000000000021, 18.50000000000002, 95.29999999999987, 154.6999999999999, -142.30000000000007, -11.499999999999819, 130.39999999999992, 134.59999999999997, 83.29999999999995, 91.40000000000003, -64.00000000000074, -173.5, 144.19999999999985, 131.59999999999988, -66.10000000000042, -51.400000000000006, -21.999999999999744, -75.70000000000002, 20.000000000000014, 127.99999999999999, 11.599999999999964, 52.40000000000005, 33.20000000000002, -78.70000000000084, 150.2, 144.7999999999999, 155.8999999999999, 177.5, 130.09999999999988, 154.39999999999986, 173.89999999999986, 147.7999999999999, 73.40000000000003, -0.9999999999999846, 3.1999999999999615, -71.50000000000009, 61.7, -32.20000000000003, 120.49999999999996, 92.00000000000009, 11.59999999999997, 17.899999999999988, 107.29999999999995, 118.09999999999995, 20.000000000000014, 43.099999999999994, 7.399999999999965, 59.29999999999998, 0.5000000000000007, -233.5, 161.29999999999998, 39.19999999999987, 49.99999999999993, 62.299999999999955, 76.39999999999999, 78.79999999999997, 174.79999999999998, 163.09999999999997, 91.70000000000003, 160.09999999999982, -59.80000000000037, 23.899999999999984, -99.4, -75.80000000000092, 17.899999999999988, 62.000000000000036, -169.60000000000005, 27.499999999999993, 154.0999999999999, 171.19999999999985, -199.6, -220.60000000000002, 129.1999999999998, 123.79999999999987, -143.8, -24.099999999999746, -337.29999999999995, -19.899999999999757, 20.000000000000014, 6.2000000000000135, 20.000000000000014, -24.69999999999999, 7.099999999999959, -28.29999999999979, -314.2, 9.499999999999964, 3.1999999999999615, 20.000000000000014, -28.29999999999975, -95.50000000000082, -246.7, -301.0, 20.000000000000014, 108.79999999999984, 50.59999999999988, 53.899999999999906, 52.39999999999998, 16.700000000000003, 44.59999999999994, 28.099999999999966, -344.4999999999999, -253.9, 89.60000000000008, 26.300000000000196, -47.19999999999976, -80.79999999999998, 143.29999999999987, 54.200000000000024, -362.5, 11.599999999999964, -111.10000000000008, -130.29999999999998, -218.20000000000007, -142.30000000000004, -136.6, -143.2, 155.89999999999998, 138.19999999999996, -186.70000000000005, -251.80000000000007, 20.000000000000014, 85.09999999999957, -103.89999999999999, -138.39999999999998, -319.6, -202.59999999999997, 159.49999999999991, 132.4999999999999, 20.000000000000014, -294.1, -199.30000000000004, 5.299999999999965, -80.5, -73.0, 20.000000000000014, -5.1999999999999265, -234.4, -239.20000000000002, -167.2, -67.89999999999992, -207.1, -254.8, 20.000000000000014, 124.69999999999996, 13.699999999999989, 47.299999999999955], "policy_predator_policy_reward": [15.0, 13.0, 6.0, 3.0, 31.0, 30.0, 8.0, 46.0, 13.0, 4.0, 10.0, 11.0, 52.0, 31.0, 22.0, 20.0, 39.0, 27.0, 15.0, 34.0, 11.0, 3.0, 21.0, 15.0, 1.0, 0.0, 0.0, 16.0, 34.0, 44.0, 0.0, 13.0, 35.0, 1.0, 45.0, 0.0, 16.0, 11.0, 5.0, 5.0, 21.0, 75.0, 13.0, 37.0, 16.0, 17.0, 43.0, 0.0, 11.0, 10.0, 106.0, 61.0, 22.0, 25.0, 16.0, 38.0, 20.0, 9.0, 71.0, 66.0, 13.0, 9.0, 23.0, 26.0, 153.0, 5.0, 12.0, 3.0, 80.0, 37.0, 93.0, 6.0, 17.0, 1.0, 3.0, 40.0, 78.0, 14.0, 7.0, 4.0, 6.0, 0.0, 16.0, 4.0, 0.0, 0.0, 35.0, 7.0, 88.0, 44.0, 32.0, 66.0, 11.0, 18.0, 5.0, 3.0, 14.0, 8.0, 13.0, 27.0, 34.0, 6.0, 149.0, 23.0, 38.0, 20.0, 4.0, 40.0, 9.0, 22.0, 4.0, 6.0, 19.0, 4.0, 59.0, 5.0, 107.0, 103.0, 0.0, 38.0, 39.0, 85.0, 0.0, 6.0, 109.0, 73.0, 17.0, 14.0, 111.0, 0.0, 165.0, 50.0, 23.0, 35.0, 71.0, 7.0, 36.0, 3.0, 44.0, 165.0, 3.0, 6.0, 10.0, 55.0, 9.0, 175.0, 4.0, 7.0, 53.0, 1.0, 35.0, 31.0, 45.0, 0.0, 102.0, 125.0, 0.0, 17.0, 22.0, 114.0, 35.0, 32.0, 186.0, 1.0, 3.0, 106.0, 139.0, 38.0, 75.0, 95.0, 14.0, 4.0, 92.0, 144.0, 1.0, 14.0, 44.0, 116.0, 172.0, 147.0, 5.0, 12.0, 153.0, 139.0, 42.0, 127.0, 16.0, 80.0, 0.0, 12.0, 26.0, 155.0, 114.0, 90.0, 82.0, 105.0, 20.0, 0.0, 34.0, 35.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7491862531712562, "mean_inference_ms": 1.9929321224837002, "mean_action_processing_ms": 0.33114301132394375, "mean_env_wait_ms": 0.25937699723144325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009706974029541016, "StateBufferConnector_ms": 0.003897428512573242, "ViewRequirementAgentConnector_ms": 0.13423395156860352}, "num_episodes": 18, "episode_return_max": 347.9, "episode_return_min": -371.40000000000003, "episode_return_mean": 105.30099999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 335.1354614397527, "num_env_steps_trained_throughput_per_sec": 335.1354614397527, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 11931.963, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11931.906, "sample_time_ms": 1606.153, "learn_time_ms": 10294.668, "learn_throughput": 388.551, "synch_weights_time_ms": 27.07}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "f0d88_00000", "date": "2024-08-14_10-52-42", "timestamp": 1723647162, "time_this_iter_s": 11.951161861419678, "time_total_s": 380.4956223964691, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4bcc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 380.4956223964691, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 44.45294117647059, "ram_util_percent": 83.29411764705883}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1872455336429453, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.015007645490939, "policy_loss": -0.010811888955277267, "vf_loss": 7.006945376925998, "vf_explained_var": -0.4029178546850013, "kl": 0.012427429409756406, "entropy": 1.3217171701173933, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2837032685519527, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.001778017528474, "policy_loss": -0.024576052574800555, "vf_loss": 6.996142455005141, "vf_explained_var": 0.2083807446969249, "kl": 0.01989242793477378, "entropy": 1.1939719823302415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 347.9, "episode_reward_min": -467.0, "episode_reward_mean": 43.92699999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999995, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -32.70150000000004, "predator_policy": 54.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [106.59999999999926, 279.0, -16.799999999999848, 287.0, 223.69999999999987, -79.50000000000014, 290.79999999999984, -0.4999999999998921, 1.3000000000001544, 165.99999999999946, 106.99999999999966, 46.50000000000018, 306.0, 339.40000000000003, 304.50000000000034, 321.70000000000005, 114.39999999999955, 63.70000000000017, 127.49999999999997, 241.49999999999983, 37.50000000000026, 247.39999999999986, 103.09999999999951, 106.69999999999942, -60.99999999999993, 258.4999999999999, 156.29999999999973, 186.20000000000002, 347.9, 274.7999999999997, 28.10000000000008, 34.80000000000011, 117.89999999999934, -18.099999999999973, 331.3000000000004, -238.20000000000002, 283.99999999999966, -56.89999999999993, -142.20000000000056, 84.20000000000005, 73.29999999999939, 17.79999999999999, -95.70000000000016, 32.20000000000018, -58.80000000000135, -363.7, 139.79999999999933, 158.49999999999977, 135.09999999999997, 117.69999999999953, -371.40000000000003, 132.90000000000023, 8.00000000000014, 264.4999999999998, -163.90000000000066, -132.40000000000018, -183.50000000000009, -109.79999999999998, 312.09999999999997, -202.50000000000009, 120.09999999999893, -82.30000000000008, -203.2, 309.00000000000034, 17.900000000000034, -24.999999999999936, -57.50000000000008, 26.80000000000009, -292.6, -31.099999999999937, -274.90000000000003, 164.6999999999993, 129.99999999999983, 164.9999999999993, 279.89999999999975, 45.49999999999983, 328.60000000000036, -467.0, 294.7, -156.20000000000076, -155.20000000000005, 317.60000000000014, 294.9999999999998, -48.39999999999983, 24.300000000000058, -20.99999999999995, -406.70000000000005, 78.89999999999934, 115.29999999999984, 10.300000000000034, 32.10000000000018, 139.89999999999995, -251.5, -431.90000000000003, -16.0, -8.900000000000066, -376.3, -3.9999999999999645, -203.60000000000005, -11.899999999999888], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [34.10000000000021, 18.50000000000002, 95.29999999999987, 154.6999999999999, -142.30000000000007, -11.499999999999819, 130.39999999999992, 134.59999999999997, 83.29999999999995, 91.40000000000003, -64.00000000000074, -173.5, 144.19999999999985, 131.59999999999988, -66.10000000000042, -51.400000000000006, -21.999999999999744, -75.70000000000002, 20.000000000000014, 127.99999999999999, 11.599999999999964, 52.40000000000005, 33.20000000000002, -78.70000000000084, 150.2, 144.7999999999999, 155.8999999999999, 177.5, 130.09999999999988, 154.39999999999986, 173.89999999999986, 147.7999999999999, 73.40000000000003, -0.9999999999999846, 3.1999999999999615, -71.50000000000009, 61.7, -32.20000000000003, 120.49999999999996, 92.00000000000009, 11.59999999999997, 17.899999999999988, 107.29999999999995, 118.09999999999995, 20.000000000000014, 43.099999999999994, 7.399999999999965, 59.29999999999998, 0.5000000000000007, -233.5, 161.29999999999998, 39.19999999999987, 49.99999999999993, 62.299999999999955, 76.39999999999999, 78.79999999999997, 174.79999999999998, 163.09999999999997, 91.70000000000003, 160.09999999999982, -59.80000000000037, 23.899999999999984, -99.4, -75.80000000000092, 17.899999999999988, 62.000000000000036, -169.60000000000005, 27.499999999999993, 154.0999999999999, 171.19999999999985, -199.6, -220.60000000000002, 129.1999999999998, 123.79999999999987, -143.8, -24.099999999999746, -337.29999999999995, -19.899999999999757, 20.000000000000014, 6.2000000000000135, 20.000000000000014, -24.69999999999999, 7.099999999999959, -28.29999999999979, -314.2, 9.499999999999964, 3.1999999999999615, 20.000000000000014, -28.29999999999975, -95.50000000000082, -246.7, -301.0, 20.000000000000014, 108.79999999999984, 50.59999999999988, 53.899999999999906, 52.39999999999998, 16.700000000000003, 44.59999999999994, 28.099999999999966, -344.4999999999999, -253.9, 89.60000000000008, 26.300000000000196, -47.19999999999976, -80.79999999999998, 143.29999999999987, 54.200000000000024, -362.5, 11.599999999999964, -111.10000000000008, -130.29999999999998, -218.20000000000007, -142.30000000000004, -136.6, -143.2, 155.89999999999998, 138.19999999999996, -186.70000000000005, -251.80000000000007, 20.000000000000014, 85.09999999999957, -103.89999999999999, -138.39999999999998, -319.6, -202.59999999999997, 159.49999999999991, 132.4999999999999, 20.000000000000014, -294.1, -199.30000000000004, 5.299999999999965, -80.5, -73.0, 20.000000000000014, -5.1999999999999265, -234.4, -239.20000000000002, -167.2, -67.89999999999992, -207.1, -254.8, 20.000000000000014, 124.69999999999996, 13.699999999999989, 47.299999999999955, 130.99999999999997, 20.000000000000014, 65.60000000000005, 161.3, -19.60000000000008, -10.899999999999979, 128.2999999999999, 188.29999999999995, -385.0, -400.0, 135.2, 144.49999999999997, -390.7, -116.50000000000077, -215.49999999999994, -108.70000000000005, 181.0999999999999, 129.49999999999983, 150.49999999999977, 126.50000000000003, -308.8, 7.399999999999965, 20.000000000000014, -36.699999999999754, -400.0, 20.000000000000014, -294.40000000000003, -376.3, 20.000000000000014, -99.10000000000002, 18.199999999999974, 55.099999999999966, -112.0, -120.7000000000007, 3.1999999999999615, 17.899999999999988, 78.80000000000001, -37.89999999999994, -227.8, -327.70000000000005, -262.3, -370.6, 13.699999999999964, -303.7, 20.000000000000014, -370.9, -353.5, -311.8, -147.9999999999999, 20.000000000000014, -229.9, -201.70000000000005, -191.8, 14.899999999999965], "policy_predator_policy_reward": [16.0, 38.0, 20.0, 9.0, 71.0, 66.0, 13.0, 9.0, 23.0, 26.0, 153.0, 5.0, 12.0, 3.0, 80.0, 37.0, 93.0, 6.0, 17.0, 1.0, 3.0, 40.0, 78.0, 14.0, 7.0, 4.0, 6.0, 0.0, 16.0, 4.0, 0.0, 0.0, 35.0, 7.0, 88.0, 44.0, 32.0, 66.0, 11.0, 18.0, 5.0, 3.0, 14.0, 8.0, 13.0, 27.0, 34.0, 6.0, 149.0, 23.0, 38.0, 20.0, 4.0, 40.0, 9.0, 22.0, 4.0, 6.0, 19.0, 4.0, 59.0, 5.0, 107.0, 103.0, 0.0, 38.0, 39.0, 85.0, 0.0, 6.0, 109.0, 73.0, 17.0, 14.0, 111.0, 0.0, 165.0, 50.0, 23.0, 35.0, 71.0, 7.0, 36.0, 3.0, 44.0, 165.0, 3.0, 6.0, 10.0, 55.0, 9.0, 175.0, 4.0, 7.0, 53.0, 1.0, 35.0, 31.0, 45.0, 0.0, 102.0, 125.0, 0.0, 17.0, 22.0, 114.0, 35.0, 32.0, 186.0, 1.0, 3.0, 106.0, 139.0, 38.0, 75.0, 95.0, 14.0, 4.0, 92.0, 144.0, 1.0, 14.0, 44.0, 116.0, 172.0, 147.0, 5.0, 12.0, 153.0, 139.0, 42.0, 127.0, 16.0, 80.0, 0.0, 12.0, 26.0, 155.0, 114.0, 90.0, 82.0, 105.0, 20.0, 0.0, 34.0, 35.0, 3.0, 11.0, 27.0, 26.0, 74.0, 2.0, 8.0, 4.0, 118.0, 200.0, 8.0, 7.0, 161.0, 190.0, 110.0, 59.0, 7.0, 0.0, 10.0, 8.0, 104.0, 149.0, 24.0, 17.0, 194.0, 165.0, 154.0, 110.0, 84.0, 74.0, 0.0, 42.0, 125.0, 118.0, 8.0, 3.0, 57.0, 42.0, 145.0, 159.0, 7.0, 194.0, 125.0, 149.0, 165.0, 177.0, 192.0, 97.0, 41.0, 83.0, 149.0, 79.0, 101.0, 64.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7503007363042462, "mean_inference_ms": 1.994708123715801, "mean_action_processing_ms": 0.33757958383207337, "mean_env_wait_ms": 0.25978591222363884, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010763406753540039, "StateBufferConnector_ms": 0.004705190658569336, "ViewRequirementAgentConnector_ms": 0.1726388931274414}, "num_episodes": 27, "episode_return_max": 347.9, "episode_return_min": -467.0, "episode_return_mean": 43.92699999999987, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.2598005666544, "num_env_steps_trained_throughput_per_sec": 341.2598005666544, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 11921.997, "restore_workers_time_ms": 0.023, "training_step_time_ms": 11921.933, "sample_time_ms": 1587.646, "learn_time_ms": 10303.407, "learn_throughput": 388.221, "synch_weights_time_ms": 26.735}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "f0d88_00000", "date": "2024-08-14_10-52-54", "timestamp": 1723647174, "time_this_iter_s": 11.78770399093628, "time_total_s": 392.2833263874054, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac006ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 392.2833263874054, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 47.2764705882353, "ram_util_percent": 83.4235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.091661642878144, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.861810185417297, "policy_loss": -0.011366209918238893, "vf_loss": 7.85175680912361, "vf_explained_var": -0.49422844711434905, "kl": 0.014103445820825884, "entropy": 1.2976254930571904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5200432411577336, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.501535569801533, "policy_loss": -0.019435090323289234, "vf_loss": 7.490737191709892, "vf_explained_var": 0.24827559353813292, "kl": 0.019906812673835, "entropy": 1.1913396183775846, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 347.9, "episode_reward_min": -467.0, "episode_reward_mean": 6.0079999999998845, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999995, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -61.89600000000004, "predator_policy": 64.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [127.49999999999997, 241.49999999999983, 37.50000000000026, 247.39999999999986, 103.09999999999951, 106.69999999999942, -60.99999999999993, 258.4999999999999, 156.29999999999973, 186.20000000000002, 347.9, 274.7999999999997, 28.10000000000008, 34.80000000000011, 117.89999999999934, -18.099999999999973, 331.3000000000004, -238.20000000000002, 283.99999999999966, -56.89999999999993, -142.20000000000056, 84.20000000000005, 73.29999999999939, 17.79999999999999, -95.70000000000016, 32.20000000000018, -58.80000000000135, -363.7, 139.79999999999933, 158.49999999999977, 135.09999999999997, 117.69999999999953, -371.40000000000003, 132.90000000000023, 8.00000000000014, 264.4999999999998, -163.90000000000066, -132.40000000000018, -183.50000000000009, -109.79999999999998, 312.09999999999997, -202.50000000000009, 120.09999999999893, -82.30000000000008, -203.2, 309.00000000000034, 17.900000000000034, -24.999999999999936, -57.50000000000008, 26.80000000000009, -292.6, -31.099999999999937, -274.90000000000003, 164.6999999999993, 129.99999999999983, 164.9999999999993, 279.89999999999975, 45.49999999999983, 328.60000000000036, -467.0, 294.7, -156.20000000000076, -155.20000000000005, 317.60000000000014, 294.9999999999998, -48.39999999999983, 24.300000000000058, -20.99999999999995, -406.70000000000005, 78.89999999999934, 115.29999999999984, 10.300000000000034, 32.10000000000018, 139.89999999999995, -251.5, -431.90000000000003, -16.0, -8.900000000000066, -376.3, -3.9999999999999645, -203.60000000000005, -11.899999999999888, -1.9999999999999356, 60.599999999999824, -97.40000000000012, -51.700000000000074, 322.20000000000016, -27.49999999999988, -107.50000000000031, -208.59999999999997, 240.50000000000003, -25.899999999999856, 19.299999999999812, -459.0, -124.39999999999995, -282.1, 20.399999999999864, -80.80000000000058, -23.899999999999928, -103.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [61.7, -32.20000000000003, 120.49999999999996, 92.00000000000009, 11.59999999999997, 17.899999999999988, 107.29999999999995, 118.09999999999995, 20.000000000000014, 43.099999999999994, 7.399999999999965, 59.29999999999998, 0.5000000000000007, -233.5, 161.29999999999998, 39.19999999999987, 49.99999999999993, 62.299999999999955, 76.39999999999999, 78.79999999999997, 174.79999999999998, 163.09999999999997, 91.70000000000003, 160.09999999999982, -59.80000000000037, 23.899999999999984, -99.4, -75.80000000000092, 17.899999999999988, 62.000000000000036, -169.60000000000005, 27.499999999999993, 154.0999999999999, 171.19999999999985, -199.6, -220.60000000000002, 129.1999999999998, 123.79999999999987, -143.8, -24.099999999999746, -337.29999999999995, -19.899999999999757, 20.000000000000014, 6.2000000000000135, 20.000000000000014, -24.69999999999999, 7.099999999999959, -28.29999999999979, -314.2, 9.499999999999964, 3.1999999999999615, 20.000000000000014, -28.29999999999975, -95.50000000000082, -246.7, -301.0, 20.000000000000014, 108.79999999999984, 50.59999999999988, 53.899999999999906, 52.39999999999998, 16.700000000000003, 44.59999999999994, 28.099999999999966, -344.4999999999999, -253.9, 89.60000000000008, 26.300000000000196, -47.19999999999976, -80.79999999999998, 143.29999999999987, 54.200000000000024, -362.5, 11.599999999999964, -111.10000000000008, -130.29999999999998, -218.20000000000007, -142.30000000000004, -136.6, -143.2, 155.89999999999998, 138.19999999999996, -186.70000000000005, -251.80000000000007, 20.000000000000014, 85.09999999999957, -103.89999999999999, -138.39999999999998, -319.6, -202.59999999999997, 159.49999999999991, 132.4999999999999, 20.000000000000014, -294.1, -199.30000000000004, 5.299999999999965, -80.5, -73.0, 20.000000000000014, -5.1999999999999265, -234.4, -239.20000000000002, -167.2, -67.89999999999992, -207.1, -254.8, 20.000000000000014, 124.69999999999996, 13.699999999999989, 47.299999999999955, 130.99999999999997, 20.000000000000014, 65.60000000000005, 161.3, -19.60000000000008, -10.899999999999979, 128.2999999999999, 188.29999999999995, -385.0, -400.0, 135.2, 144.49999999999997, -390.7, -116.50000000000077, -215.49999999999994, -108.70000000000005, 181.0999999999999, 129.49999999999983, 150.49999999999977, 126.50000000000003, -308.8, 7.399999999999965, 20.000000000000014, -36.699999999999754, -400.0, 20.000000000000014, -294.40000000000003, -376.3, 20.000000000000014, -99.10000000000002, 18.199999999999974, 55.099999999999966, -112.0, -120.7000000000007, 3.1999999999999615, 17.899999999999988, 78.80000000000001, -37.89999999999994, -227.8, -327.70000000000005, -262.3, -370.6, 13.699999999999964, -303.7, 20.000000000000014, -370.9, -353.5, -311.8, -147.9999999999999, 20.000000000000014, -229.9, -201.70000000000005, -191.8, 14.899999999999965, 20.000000000000014, -88.00000000000057, 6.500000000000014, -118.89999999999996, -276.40000000000003, 20.000000000000014, -98.19999999999999, -56.500000000000014, 154.99999999999991, 150.19999999999993, -285.40000000000003, -0.09999999999998366, -73.30000000000032, -275.20000000000005, -223.6, -232.0, 85.99999999999997, 99.50000000000001, 20.000000000000014, -337.9, -74.79999999999998, -4.900000000000034, -379.6, -354.4, -144.7, -105.69999999999999, -301.0, -285.1, -46.30000000000001, -46.29999999999998, -400.0, 3.1999999999999615, -151.9, 20.000000000000014, -151.30000000000004, -90.99999999999999], "policy_predator_policy_reward": [32.0, 66.0, 11.0, 18.0, 5.0, 3.0, 14.0, 8.0, 13.0, 27.0, 34.0, 6.0, 149.0, 23.0, 38.0, 20.0, 4.0, 40.0, 9.0, 22.0, 4.0, 6.0, 19.0, 4.0, 59.0, 5.0, 107.0, 103.0, 0.0, 38.0, 39.0, 85.0, 0.0, 6.0, 109.0, 73.0, 17.0, 14.0, 111.0, 0.0, 165.0, 50.0, 23.0, 35.0, 71.0, 7.0, 36.0, 3.0, 44.0, 165.0, 3.0, 6.0, 10.0, 55.0, 9.0, 175.0, 4.0, 7.0, 53.0, 1.0, 35.0, 31.0, 45.0, 0.0, 102.0, 125.0, 0.0, 17.0, 22.0, 114.0, 35.0, 32.0, 186.0, 1.0, 3.0, 106.0, 139.0, 38.0, 75.0, 95.0, 14.0, 4.0, 92.0, 144.0, 1.0, 14.0, 44.0, 116.0, 172.0, 147.0, 5.0, 12.0, 153.0, 139.0, 42.0, 127.0, 16.0, 80.0, 0.0, 12.0, 26.0, 155.0, 114.0, 90.0, 82.0, 105.0, 20.0, 0.0, 34.0, 35.0, 3.0, 11.0, 27.0, 26.0, 74.0, 2.0, 8.0, 4.0, 118.0, 200.0, 8.0, 7.0, 161.0, 190.0, 110.0, 59.0, 7.0, 0.0, 10.0, 8.0, 104.0, 149.0, 24.0, 17.0, 194.0, 165.0, 154.0, 110.0, 84.0, 74.0, 0.0, 42.0, 125.0, 118.0, 8.0, 3.0, 57.0, 42.0, 145.0, 159.0, 7.0, 194.0, 125.0, 149.0, 165.0, 177.0, 192.0, 97.0, 41.0, 83.0, 149.0, 79.0, 101.0, 64.0, 53.0, 13.0, 83.0, 90.0, 157.0, 2.0, 87.0, 16.0, 9.0, 8.0, 112.0, 146.0, 156.0, 85.0, 108.0, 139.0, 33.0, 22.0, 126.0, 166.0, 85.0, 14.0, 176.0, 99.0, 114.0, 12.0, 160.0, 144.0, 88.0, 25.0, 200.0, 116.0, 96.0, 12.0, 111.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7483363322403297, "mean_inference_ms": 1.992752881566405, "mean_action_processing_ms": 0.33523665136543945, "mean_env_wait_ms": 0.2590853655419879, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006080269813537598, "StateBufferConnector_ms": 0.004683375358581543, "ViewRequirementAgentConnector_ms": 0.15856003761291504}, "num_episodes": 18, "episode_return_max": 347.9, "episode_return_min": -467.0, "episode_return_mean": 6.0079999999998845, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.4322422661444, "num_env_steps_trained_throughput_per_sec": 347.4322422661444, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 11907.908, "restore_workers_time_ms": 0.022, "training_step_time_ms": 11907.846, "sample_time_ms": 1565.512, "learn_time_ms": 10314.912, "learn_throughput": 387.788, "synch_weights_time_ms": 23.09}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "f0d88_00000", "date": "2024-08-14_10-53-05", "timestamp": 1723647185, "time_this_iter_s": 11.544920206069946, "time_total_s": 403.82824659347534, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3abf4e310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 403.82824659347534, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 45.550000000000004, "ram_util_percent": 83.51249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9195996641797364, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.113533899519179, "policy_loss": -0.014949055239262562, "vf_loss": 6.110924007526781, "vf_explained_var": -0.6908476131933706, "kl": 0.011561436458339808, "entropy": 1.292245216218252, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4764475771359034, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.658164321051704, "policy_loss": -0.021017409309316133, "vf_loss": 7.650578072966722, "vf_explained_var": 0.24930301784838318, "kl": 0.018833690578471833, "entropy": 1.1871847400589595, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 328.60000000000036, "episode_reward_min": -467.0, "episode_reward_mean": -34.75800000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999995, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -95.65400000000001, "predator_policy": 78.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [283.99999999999966, -56.89999999999993, -142.20000000000056, 84.20000000000005, 73.29999999999939, 17.79999999999999, -95.70000000000016, 32.20000000000018, -58.80000000000135, -363.7, 139.79999999999933, 158.49999999999977, 135.09999999999997, 117.69999999999953, -371.40000000000003, 132.90000000000023, 8.00000000000014, 264.4999999999998, -163.90000000000066, -132.40000000000018, -183.50000000000009, -109.79999999999998, 312.09999999999997, -202.50000000000009, 120.09999999999893, -82.30000000000008, -203.2, 309.00000000000034, 17.900000000000034, -24.999999999999936, -57.50000000000008, 26.80000000000009, -292.6, -31.099999999999937, -274.90000000000003, 164.6999999999993, 129.99999999999983, 164.9999999999993, 279.89999999999975, 45.49999999999983, 328.60000000000036, -467.0, 294.7, -156.20000000000076, -155.20000000000005, 317.60000000000014, 294.9999999999998, -48.39999999999983, 24.300000000000058, -20.99999999999995, -406.70000000000005, 78.89999999999934, 115.29999999999984, 10.300000000000034, 32.10000000000018, 139.89999999999995, -251.5, -431.90000000000003, -16.0, -8.900000000000066, -376.3, -3.9999999999999645, -203.60000000000005, -11.899999999999888, -1.9999999999999356, 60.599999999999824, -97.40000000000012, -51.700000000000074, 322.20000000000016, -27.49999999999988, -107.50000000000031, -208.59999999999997, 240.50000000000003, -25.899999999999856, 19.299999999999812, -459.0, -124.39999999999995, -282.1, 20.399999999999864, -80.80000000000058, -23.899999999999928, -103.3, -297.79999999999995, 4.800000000000161, -31.8999999999997, -301.5999999999991, -244.5, 94.9999999999998, -387.4, -2.699999999999834, -125.00000000000017, 37.80000000000027, -4.999999999999671, -215.0, -190.00000000000006, -1.300000000000039, -47.399999999999885, -59.599999999999824, -24.099999999999824, 1.3000000000001437], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [129.1999999999998, 123.79999999999987, -143.8, -24.099999999999746, -337.29999999999995, -19.899999999999757, 20.000000000000014, 6.2000000000000135, 20.000000000000014, -24.69999999999999, 7.099999999999959, -28.29999999999979, -314.2, 9.499999999999964, 3.1999999999999615, 20.000000000000014, -28.29999999999975, -95.50000000000082, -246.7, -301.0, 20.000000000000014, 108.79999999999984, 50.59999999999988, 53.899999999999906, 52.39999999999998, 16.700000000000003, 44.59999999999994, 28.099999999999966, -344.4999999999999, -253.9, 89.60000000000008, 26.300000000000196, -47.19999999999976, -80.79999999999998, 143.29999999999987, 54.200000000000024, -362.5, 11.599999999999964, -111.10000000000008, -130.29999999999998, -218.20000000000007, -142.30000000000004, -136.6, -143.2, 155.89999999999998, 138.19999999999996, -186.70000000000005, -251.80000000000007, 20.000000000000014, 85.09999999999957, -103.89999999999999, -138.39999999999998, -319.6, -202.59999999999997, 159.49999999999991, 132.4999999999999, 20.000000000000014, -294.1, -199.30000000000004, 5.299999999999965, -80.5, -73.0, 20.000000000000014, -5.1999999999999265, -234.4, -239.20000000000002, -167.2, -67.89999999999992, -207.1, -254.8, 20.000000000000014, 124.69999999999996, 13.699999999999989, 47.299999999999955, 130.99999999999997, 20.000000000000014, 65.60000000000005, 161.3, -19.60000000000008, -10.899999999999979, 128.2999999999999, 188.29999999999995, -385.0, -400.0, 135.2, 144.49999999999997, -390.7, -116.50000000000077, -215.49999999999994, -108.70000000000005, 181.0999999999999, 129.49999999999983, 150.49999999999977, 126.50000000000003, -308.8, 7.399999999999965, 20.000000000000014, -36.699999999999754, -400.0, 20.000000000000014, -294.40000000000003, -376.3, 20.000000000000014, -99.10000000000002, 18.199999999999974, 55.099999999999966, -112.0, -120.7000000000007, 3.1999999999999615, 17.899999999999988, 78.80000000000001, -37.89999999999994, -227.8, -327.70000000000005, -262.3, -370.6, 13.699999999999964, -303.7, 20.000000000000014, -370.9, -353.5, -311.8, -147.9999999999999, 20.000000000000014, -229.9, -201.70000000000005, -191.8, 14.899999999999965, 20.000000000000014, -88.00000000000057, 6.500000000000014, -118.89999999999996, -276.40000000000003, 20.000000000000014, -98.19999999999999, -56.500000000000014, 154.99999999999991, 150.19999999999993, -285.40000000000003, -0.09999999999998366, -73.30000000000032, -275.20000000000005, -223.6, -232.0, 85.99999999999997, 99.50000000000001, 20.000000000000014, -337.9, -74.79999999999998, -4.900000000000034, -379.6, -354.4, -144.7, -105.69999999999999, -301.0, -285.1, -46.30000000000001, -46.29999999999998, -400.0, 3.1999999999999615, -151.9, 20.000000000000014, -151.30000000000004, -90.99999999999999, -332.79999999999995, -268.0, -240.40000000000003, 3.1999999999999615, -358.0, 1.0999999999999865, -235.00000000000023, -316.6, -222.7, -179.8, 17.899999999999878, 13.099999999999937, -332.5, -397.9, -238.60000000000002, 17.899999999999988, -301.6, -9.399999999999821, 15.799999999999963, 20.000000000000014, -5.1999999999999265, -17.79999999999974, -220.0, -373.0, -369.39999999999986, -145.6, -374.8, 9.499999999999964, -198.4, 20.000000000000014, -268.6, 20.000000000000014, -6.899999999999942, -206.20000000000007, -207.70000000000005, 20.000000000000014], "policy_predator_policy_reward": [17.0, 14.0, 111.0, 0.0, 165.0, 50.0, 23.0, 35.0, 71.0, 7.0, 36.0, 3.0, 44.0, 165.0, 3.0, 6.0, 10.0, 55.0, 9.0, 175.0, 4.0, 7.0, 53.0, 1.0, 35.0, 31.0, 45.0, 0.0, 102.0, 125.0, 0.0, 17.0, 22.0, 114.0, 35.0, 32.0, 186.0, 1.0, 3.0, 106.0, 139.0, 38.0, 75.0, 95.0, 14.0, 4.0, 92.0, 144.0, 1.0, 14.0, 44.0, 116.0, 172.0, 147.0, 5.0, 12.0, 153.0, 139.0, 42.0, 127.0, 16.0, 80.0, 0.0, 12.0, 26.0, 155.0, 114.0, 90.0, 82.0, 105.0, 20.0, 0.0, 34.0, 35.0, 3.0, 11.0, 27.0, 26.0, 74.0, 2.0, 8.0, 4.0, 118.0, 200.0, 8.0, 7.0, 161.0, 190.0, 110.0, 59.0, 7.0, 0.0, 10.0, 8.0, 104.0, 149.0, 24.0, 17.0, 194.0, 165.0, 154.0, 110.0, 84.0, 74.0, 0.0, 42.0, 125.0, 118.0, 8.0, 3.0, 57.0, 42.0, 145.0, 159.0, 7.0, 194.0, 125.0, 149.0, 165.0, 177.0, 192.0, 97.0, 41.0, 83.0, 149.0, 79.0, 101.0, 64.0, 53.0, 13.0, 83.0, 90.0, 157.0, 2.0, 87.0, 16.0, 9.0, 8.0, 112.0, 146.0, 156.0, 85.0, 108.0, 139.0, 33.0, 22.0, 126.0, 166.0, 85.0, 14.0, 176.0, 99.0, 114.0, 12.0, 160.0, 144.0, 88.0, 25.0, 200.0, 116.0, 96.0, 12.0, 111.0, 28.0, 129.0, 174.0, 122.0, 120.0, 167.0, 158.0, 179.0, 71.0, 44.0, 114.0, 11.0, 53.0, 171.0, 172.0, 140.0, 78.0, 166.0, 20.0, 2.0, 0.0, 0.0, 18.0, 187.0, 191.0, 199.0, 126.0, 179.0, 185.0, 0.0, 131.0, 50.0, 139.0, 67.0, 122.0, 116.0, 73.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7467691568210378, "mean_inference_ms": 1.9870110750217986, "mean_action_processing_ms": 0.3335034108842595, "mean_env_wait_ms": 0.25832832376279385, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006211519241333008, "StateBufferConnector_ms": 0.004749298095703125, "ViewRequirementAgentConnector_ms": 0.15507948398590088}, "num_episodes": 18, "episode_return_max": 328.60000000000036, "episode_return_min": -467.0, "episode_return_mean": -34.75800000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.64736400338523, "num_env_steps_trained_throughput_per_sec": 351.64736400338523, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 11873.957, "restore_workers_time_ms": 0.022, "training_step_time_ms": 11873.896, "sample_time_ms": 1546.416, "learn_time_ms": 10301.848, "learn_throughput": 388.28, "synch_weights_time_ms": 22.365}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "f0d88_00000", "date": "2024-08-14_10-53-17", "timestamp": 1723647197, "time_this_iter_s": 11.448143005371094, "time_total_s": 415.27638959884644, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4e5e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 415.27638959884644, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 44.64375, "ram_util_percent": 83.09375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3093484260417796, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.776490367909588, "policy_loss": -0.011001398763496173, "vf_loss": 6.767338906898701, "vf_explained_var": -0.44394111387313356, "kl": 0.013269362895809047, "entropy": 1.3102455212325645, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6195714676821673, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.353448012770799, "policy_loss": -0.020646863314569507, "vf_loss": 7.345718053535179, "vf_explained_var": 0.3775730184146336, "kl": 0.01868432770227465, "entropy": 1.1745326019468763, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 328.60000000000036, "episode_reward_min": -467.0, "episode_reward_mean": -43.85600000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999995, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -105.75800000000002, "predator_policy": 83.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-163.90000000000066, -132.40000000000018, -183.50000000000009, -109.79999999999998, 312.09999999999997, -202.50000000000009, 120.09999999999893, -82.30000000000008, -203.2, 309.00000000000034, 17.900000000000034, -24.999999999999936, -57.50000000000008, 26.80000000000009, -292.6, -31.099999999999937, -274.90000000000003, 164.6999999999993, 129.99999999999983, 164.9999999999993, 279.89999999999975, 45.49999999999983, 328.60000000000036, -467.0, 294.7, -156.20000000000076, -155.20000000000005, 317.60000000000014, 294.9999999999998, -48.39999999999983, 24.300000000000058, -20.99999999999995, -406.70000000000005, 78.89999999999934, 115.29999999999984, 10.300000000000034, 32.10000000000018, 139.89999999999995, -251.5, -431.90000000000003, -16.0, -8.900000000000066, -376.3, -3.9999999999999645, -203.60000000000005, -11.899999999999888, -1.9999999999999356, 60.599999999999824, -97.40000000000012, -51.700000000000074, 322.20000000000016, -27.49999999999988, -107.50000000000031, -208.59999999999997, 240.50000000000003, -25.899999999999856, 19.299999999999812, -459.0, -124.39999999999995, -282.1, 20.399999999999864, -80.80000000000058, -23.899999999999928, -103.3, -297.79999999999995, 4.800000000000161, -31.8999999999997, -301.5999999999991, -244.5, 94.9999999999998, -387.4, -2.699999999999834, -125.00000000000017, 37.80000000000027, -4.999999999999671, -215.0, -190.00000000000006, -1.300000000000039, -47.399999999999885, -59.599999999999824, -24.099999999999824, 1.3000000000001437, 76.89999999999944, -230.30000000000004, -158.89999999999995, 213.39999999999986, 126.0999999999998, 5.1999999999999815, 33.1000000000002, -355.9, 76.29999999999961, -382.3, -9.89999999999964, -19.699999999999875, -265.1, -30.099999999999987, 187.39999999999927, 216.2999999999998, 19.500000000000142, -52.4999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-362.5, 11.599999999999964, -111.10000000000008, -130.29999999999998, -218.20000000000007, -142.30000000000004, -136.6, -143.2, 155.89999999999998, 138.19999999999996, -186.70000000000005, -251.80000000000007, 20.000000000000014, 85.09999999999957, -103.89999999999999, -138.39999999999998, -319.6, -202.59999999999997, 159.49999999999991, 132.4999999999999, 20.000000000000014, -294.1, -199.30000000000004, 5.299999999999965, -80.5, -73.0, 20.000000000000014, -5.1999999999999265, -234.4, -239.20000000000002, -167.2, -67.89999999999992, -207.1, -254.8, 20.000000000000014, 124.69999999999996, 13.699999999999989, 47.299999999999955, 130.99999999999997, 20.000000000000014, 65.60000000000005, 161.3, -19.60000000000008, -10.899999999999979, 128.2999999999999, 188.29999999999995, -385.0, -400.0, 135.2, 144.49999999999997, -390.7, -116.50000000000077, -215.49999999999994, -108.70000000000005, 181.0999999999999, 129.49999999999983, 150.49999999999977, 126.50000000000003, -308.8, 7.399999999999965, 20.000000000000014, -36.699999999999754, -400.0, 20.000000000000014, -294.40000000000003, -376.3, 20.000000000000014, -99.10000000000002, 18.199999999999974, 55.099999999999966, -112.0, -120.7000000000007, 3.1999999999999615, 17.899999999999988, 78.80000000000001, -37.89999999999994, -227.8, -327.70000000000005, -262.3, -370.6, 13.699999999999964, -303.7, 20.000000000000014, -370.9, -353.5, -311.8, -147.9999999999999, 20.000000000000014, -229.9, -201.70000000000005, -191.8, 14.899999999999965, 20.000000000000014, -88.00000000000057, 6.500000000000014, -118.89999999999996, -276.40000000000003, 20.000000000000014, -98.19999999999999, -56.500000000000014, 154.99999999999991, 150.19999999999993, -285.40000000000003, -0.09999999999998366, -73.30000000000032, -275.20000000000005, -223.6, -232.0, 85.99999999999997, 99.50000000000001, 20.000000000000014, -337.9, -74.79999999999998, -4.900000000000034, -379.6, -354.4, -144.7, -105.69999999999999, -301.0, -285.1, -46.30000000000001, -46.29999999999998, -400.0, 3.1999999999999615, -151.9, 20.000000000000014, -151.30000000000004, -90.99999999999999, -332.79999999999995, -268.0, -240.40000000000003, 3.1999999999999615, -358.0, 1.0999999999999865, -235.00000000000023, -316.6, -222.7, -179.8, 17.899999999999878, 13.099999999999937, -332.5, -397.9, -238.60000000000002, 17.899999999999988, -301.6, -9.399999999999821, 15.799999999999963, 20.000000000000014, -5.1999999999999265, -17.79999999999974, -220.0, -373.0, -369.39999999999986, -145.6, -374.8, 9.499999999999964, -198.4, 20.000000000000014, -268.6, 20.000000000000014, -6.899999999999942, -206.20000000000007, -207.70000000000005, 20.000000000000014, 20.000000000000014, -27.09999999999998, -188.8, -179.5, -178.90000000000006, -135.99999999999997, 96.19999999999993, 75.19999999999999, 1.6999999999999602, 52.39999999999995, -389.5, 13.699999999999966, 9.499999999999964, 11.599999999999966, -370.9, -295.0, 5.299999999999965, 40.99999999999993, -271.9, -366.4, -64.00000000000091, 1.0999999999999759, -176.2, -35.50000000000003, -226.9, -272.2, -400.0, 17.899999999999988, 157.39999999999998, 20.000000000000014, 49.40000000000004, 125.89999999999998, 7.399999999999965, -76.90000000000006, -5.1999999999999265, -328.3], "policy_predator_policy_reward": [186.0, 1.0, 3.0, 106.0, 139.0, 38.0, 75.0, 95.0, 14.0, 4.0, 92.0, 144.0, 1.0, 14.0, 44.0, 116.0, 172.0, 147.0, 5.0, 12.0, 153.0, 139.0, 42.0, 127.0, 16.0, 80.0, 0.0, 12.0, 26.0, 155.0, 114.0, 90.0, 82.0, 105.0, 20.0, 0.0, 34.0, 35.0, 3.0, 11.0, 27.0, 26.0, 74.0, 2.0, 8.0, 4.0, 118.0, 200.0, 8.0, 7.0, 161.0, 190.0, 110.0, 59.0, 7.0, 0.0, 10.0, 8.0, 104.0, 149.0, 24.0, 17.0, 194.0, 165.0, 154.0, 110.0, 84.0, 74.0, 0.0, 42.0, 125.0, 118.0, 8.0, 3.0, 57.0, 42.0, 145.0, 159.0, 7.0, 194.0, 125.0, 149.0, 165.0, 177.0, 192.0, 97.0, 41.0, 83.0, 149.0, 79.0, 101.0, 64.0, 53.0, 13.0, 83.0, 90.0, 157.0, 2.0, 87.0, 16.0, 9.0, 8.0, 112.0, 146.0, 156.0, 85.0, 108.0, 139.0, 33.0, 22.0, 126.0, 166.0, 85.0, 14.0, 176.0, 99.0, 114.0, 12.0, 160.0, 144.0, 88.0, 25.0, 200.0, 116.0, 96.0, 12.0, 111.0, 28.0, 129.0, 174.0, 122.0, 120.0, 167.0, 158.0, 179.0, 71.0, 44.0, 114.0, 11.0, 53.0, 171.0, 172.0, 140.0, 78.0, 166.0, 20.0, 2.0, 0.0, 0.0, 18.0, 187.0, 191.0, 199.0, 126.0, 179.0, 185.0, 0.0, 131.0, 50.0, 139.0, 67.0, 122.0, 116.0, 73.0, 14.0, 70.0, 123.0, 15.0, 39.0, 117.0, 32.0, 10.0, 11.0, 61.0, 193.0, 188.0, 7.0, 5.0, 190.0, 120.0, 23.0, 7.0, 95.0, 161.0, 5.0, 48.0, 110.0, 82.0, 85.0, 149.0, 196.0, 156.0, 7.0, 3.0, 25.0, 16.0, 88.0, 1.0, 155.0, 126.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7445796427004359, "mean_inference_ms": 1.9799089307428517, "mean_action_processing_ms": 0.3315240016397024, "mean_env_wait_ms": 0.2575990598087745, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005848407745361328, "StateBufferConnector_ms": 0.004173994064331055, "ViewRequirementAgentConnector_ms": 0.15443050861358643}, "num_episodes": 18, "episode_return_max": 328.60000000000036, "episode_return_min": -467.0, "episode_return_mean": -43.85600000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.4503763057905, "num_env_steps_trained_throughput_per_sec": 350.4503763057905, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 11824.666, "restore_workers_time_ms": 0.022, "training_step_time_ms": 11824.605, "sample_time_ms": 1511.774, "learn_time_ms": 10288.824, "learn_throughput": 388.771, "synch_weights_time_ms": 22.055}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "f0d88_00000", "date": "2024-08-14_10-53-28", "timestamp": 1723647208, "time_this_iter_s": 11.476299047470093, "time_total_s": 426.7526886463165, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5165e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 426.7526886463165, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 46.82941176470588, "ram_util_percent": 83.25294117647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1476574908173274, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.374038420783149, "policy_loss": -0.009672725669270943, "vf_loss": 7.363546706759741, "vf_explained_var": -0.48011726506803404, "kl": 0.013277010197249837, "entropy": 1.2972051065434855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.392123741762979, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.776909869562381, "policy_loss": -0.020768728033792247, "vf_loss": 7.768882476968109, "vf_explained_var": 0.32803968001925754, "kl": 0.01896041904853456, "entropy": 1.1802462597372672, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 328.60000000000036, "episode_reward_min": -503.9, "episode_reward_mean": -62.312000000000026, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999995, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -121.54100000000003, "predator_policy": 90.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [328.60000000000036, -467.0, 294.7, -156.20000000000076, -155.20000000000005, 317.60000000000014, 294.9999999999998, -48.39999999999983, 24.300000000000058, -20.99999999999995, -406.70000000000005, 78.89999999999934, 115.29999999999984, 10.300000000000034, 32.10000000000018, 139.89999999999995, -251.5, -431.90000000000003, -16.0, -8.900000000000066, -376.3, -3.9999999999999645, -203.60000000000005, -11.899999999999888, -1.9999999999999356, 60.599999999999824, -97.40000000000012, -51.700000000000074, 322.20000000000016, -27.49999999999988, -107.50000000000031, -208.59999999999997, 240.50000000000003, -25.899999999999856, 19.299999999999812, -459.0, -124.39999999999995, -282.1, 20.399999999999864, -80.80000000000058, -23.899999999999928, -103.3, -297.79999999999995, 4.800000000000161, -31.8999999999997, -301.5999999999991, -244.5, 94.9999999999998, -387.4, -2.699999999999834, -125.00000000000017, 37.80000000000027, -4.999999999999671, -215.0, -190.00000000000006, -1.300000000000039, -47.399999999999885, -59.599999999999824, -24.099999999999824, 1.3000000000001437, 76.89999999999944, -230.30000000000004, -158.89999999999995, 213.39999999999986, 126.0999999999998, 5.1999999999999815, 33.1000000000002, -355.9, 76.29999999999961, -382.3, -9.89999999999964, -19.699999999999875, -265.1, -30.099999999999987, 187.39999999999927, 216.2999999999998, 19.500000000000142, -52.4999999999998, 47.20000000000023, -99.5, -386.0, -24.399999999999967, -347.30000000000007, 80.5999999999994, 56.89999999999972, -7.300000000000125, -196.6, -503.9, -379.9, 67.69999999999919, -118.5000000000006, 36.70000000000025, 24.60000000000005, -17.500000000000007, -77.09999999999991, -42.29999999999976, 65.59999999999985, 233.49999999999977, -118.00000000000023, -327.79999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [128.2999999999999, 188.29999999999995, -385.0, -400.0, 135.2, 144.49999999999997, -390.7, -116.50000000000077, -215.49999999999994, -108.70000000000005, 181.0999999999999, 129.49999999999983, 150.49999999999977, 126.50000000000003, -308.8, 7.399999999999965, 20.000000000000014, -36.699999999999754, -400.0, 20.000000000000014, -294.40000000000003, -376.3, 20.000000000000014, -99.10000000000002, 18.199999999999974, 55.099999999999966, -112.0, -120.7000000000007, 3.1999999999999615, 17.899999999999988, 78.80000000000001, -37.89999999999994, -227.8, -327.70000000000005, -262.3, -370.6, 13.699999999999964, -303.7, 20.000000000000014, -370.9, -353.5, -311.8, -147.9999999999999, 20.000000000000014, -229.9, -201.70000000000005, -191.8, 14.899999999999965, 20.000000000000014, -88.00000000000057, 6.500000000000014, -118.89999999999996, -276.40000000000003, 20.000000000000014, -98.19999999999999, -56.500000000000014, 154.99999999999991, 150.19999999999993, -285.40000000000003, -0.09999999999998366, -73.30000000000032, -275.20000000000005, -223.6, -232.0, 85.99999999999997, 99.50000000000001, 20.000000000000014, -337.9, -74.79999999999998, -4.900000000000034, -379.6, -354.4, -144.7, -105.69999999999999, -301.0, -285.1, -46.30000000000001, -46.29999999999998, -400.0, 3.1999999999999615, -151.9, 20.000000000000014, -151.30000000000004, -90.99999999999999, -332.79999999999995, -268.0, -240.40000000000003, 3.1999999999999615, -358.0, 1.0999999999999865, -235.00000000000023, -316.6, -222.7, -179.8, 17.899999999999878, 13.099999999999937, -332.5, -397.9, -238.60000000000002, 17.899999999999988, -301.6, -9.399999999999821, 15.799999999999963, 20.000000000000014, -5.1999999999999265, -17.79999999999974, -220.0, -373.0, -369.39999999999986, -145.6, -374.8, 9.499999999999964, -198.4, 20.000000000000014, -268.6, 20.000000000000014, -6.899999999999942, -206.20000000000007, -207.70000000000005, 20.000000000000014, 20.000000000000014, -27.09999999999998, -188.8, -179.5, -178.90000000000006, -135.99999999999997, 96.19999999999993, 75.19999999999999, 1.6999999999999602, 52.39999999999995, -389.5, 13.699999999999966, 9.499999999999964, 11.599999999999966, -370.9, -295.0, 5.299999999999965, 40.99999999999993, -271.9, -366.4, -64.00000000000091, 1.0999999999999759, -176.2, -35.50000000000003, -226.9, -272.2, -400.0, 17.899999999999988, 157.39999999999998, 20.000000000000014, 49.40000000000004, 125.89999999999998, 7.399999999999965, -76.90000000000006, -5.1999999999999265, -328.3, -170.5, -7.299999999999891, -91.29999999999998, -179.20000000000005, -379.0, -391.0, -89.5, -139.89999999999998, -383.20000000000005, -309.1, 20.000000000000014, -21.400000000000006, -34.60000000000002, 21.499999999999943, -55.30000000000001, -79.0, -180.40000000000012, -194.2, -352.0, -397.9, -298.9, -373.0, 1.0999999999999865, -12.400000000000098, 3.1999999999999615, -372.7, 20.000000000000014, 13.699999999999964, 15.799999999999962, -5.1999999999999265, -386.5, 20.000000000000014, 13.699999999999964, -230.8, -38.799999999999756, -365.5, -41.19999999999999, -11.200000000000017, 130.09999999999988, 67.40000000000006, -13.599999999999783, -273.4, -264.4, -309.4], "policy_predator_policy_reward": [8.0, 4.0, 118.0, 200.0, 8.0, 7.0, 161.0, 190.0, 110.0, 59.0, 7.0, 0.0, 10.0, 8.0, 104.0, 149.0, 24.0, 17.0, 194.0, 165.0, 154.0, 110.0, 84.0, 74.0, 0.0, 42.0, 125.0, 118.0, 8.0, 3.0, 57.0, 42.0, 145.0, 159.0, 7.0, 194.0, 125.0, 149.0, 165.0, 177.0, 192.0, 97.0, 41.0, 83.0, 149.0, 79.0, 101.0, 64.0, 53.0, 13.0, 83.0, 90.0, 157.0, 2.0, 87.0, 16.0, 9.0, 8.0, 112.0, 146.0, 156.0, 85.0, 108.0, 139.0, 33.0, 22.0, 126.0, 166.0, 85.0, 14.0, 176.0, 99.0, 114.0, 12.0, 160.0, 144.0, 88.0, 25.0, 200.0, 116.0, 96.0, 12.0, 111.0, 28.0, 129.0, 174.0, 122.0, 120.0, 167.0, 158.0, 179.0, 71.0, 44.0, 114.0, 11.0, 53.0, 171.0, 172.0, 140.0, 78.0, 166.0, 20.0, 2.0, 0.0, 0.0, 18.0, 187.0, 191.0, 199.0, 126.0, 179.0, 185.0, 0.0, 131.0, 50.0, 139.0, 67.0, 122.0, 116.0, 73.0, 14.0, 70.0, 123.0, 15.0, 39.0, 117.0, 32.0, 10.0, 11.0, 61.0, 193.0, 188.0, 7.0, 5.0, 190.0, 120.0, 23.0, 7.0, 95.0, 161.0, 5.0, 48.0, 110.0, 82.0, 85.0, 149.0, 196.0, 156.0, 7.0, 3.0, 25.0, 16.0, 88.0, 1.0, 155.0, 126.0, 108.0, 117.0, 127.0, 44.0, 197.0, 187.0, 95.0, 110.0, 190.0, 155.0, 26.0, 56.0, 70.0, 0.0, 83.0, 44.0, 47.0, 131.0, 199.0, 47.0, 131.0, 161.0, 70.0, 9.0, 194.0, 57.0, 0.0, 3.0, 13.0, 1.0, 171.0, 178.0, 82.0, 58.0, 185.0, 177.0, 74.0, 44.0, 5.0, 31.0, 157.0, 12.0, 96.0, 150.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7410844358858065, "mean_inference_ms": 1.9685537040251753, "mean_action_processing_ms": 0.327183415484965, "mean_env_wait_ms": 0.2558302657432274, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005724310874938965, "StateBufferConnector_ms": 0.004215121269226074, "ViewRequirementAgentConnector_ms": 0.13799726963043213}, "num_episodes": 22, "episode_return_max": 328.60000000000036, "episode_return_min": -503.9, "episode_return_mean": -62.312000000000026, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.5317562527268, "num_env_steps_trained_throughput_per_sec": 343.5317562527268, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 11821.709, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11821.652, "sample_time_ms": 1479.85, "learn_time_ms": 10318.865, "learn_throughput": 387.64, "synch_weights_time_ms": 21.045}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "f0d88_00000", "date": "2024-08-14_10-53-40", "timestamp": 1723647220, "time_this_iter_s": 11.690669059753418, "time_total_s": 438.44335770606995, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad516d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 438.44335770606995, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 45.14375, "ram_util_percent": 83.20625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1886466721693676, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.197352044039933, "policy_loss": -0.011822996372307734, "vf_loss": 6.193041654617067, "vf_explained_var": -0.5293345059667315, "kl": 0.010622793092642259, "entropy": 1.321115074397395, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5801325224064016, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.252342339924404, "policy_loss": -0.01917689806934466, "vf_loss": 7.242575938865621, "vf_explained_var": 0.4785733455072635, "kl": 0.01905732200245857, "entropy": 1.187331473007404, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 322.20000000000016, "episode_reward_min": -503.9, "episode_reward_mean": -72.16700000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 157.39999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -128.0885, "predator_policy": 92.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.899999999999888, -1.9999999999999356, 60.599999999999824, -97.40000000000012, -51.700000000000074, 322.20000000000016, -27.49999999999988, -107.50000000000031, -208.59999999999997, 240.50000000000003, -25.899999999999856, 19.299999999999812, -459.0, -124.39999999999995, -282.1, 20.399999999999864, -80.80000000000058, -23.899999999999928, -103.3, -297.79999999999995, 4.800000000000161, -31.8999999999997, -301.5999999999991, -244.5, 94.9999999999998, -387.4, -2.699999999999834, -125.00000000000017, 37.80000000000027, -4.999999999999671, -215.0, -190.00000000000006, -1.300000000000039, -47.399999999999885, -59.599999999999824, -24.099999999999824, 1.3000000000001437, 76.89999999999944, -230.30000000000004, -158.89999999999995, 213.39999999999986, 126.0999999999998, 5.1999999999999815, 33.1000000000002, -355.9, 76.29999999999961, -382.3, -9.89999999999964, -19.699999999999875, -265.1, -30.099999999999987, 187.39999999999927, 216.2999999999998, 19.500000000000142, -52.4999999999998, 47.20000000000023, -99.5, -386.0, -24.399999999999967, -347.30000000000007, 80.5999999999994, 56.89999999999972, -7.300000000000125, -196.6, -503.9, -379.9, 67.69999999999919, -118.5000000000006, 36.70000000000025, 24.60000000000005, -17.500000000000007, -77.09999999999991, -42.29999999999976, 65.59999999999985, 233.49999999999977, -118.00000000000023, -327.79999999999995, -435.09999999999997, -87.40000000000043, -321.2, -75.10000000000063, -144.5000000000004, 3.4000000000000954, -292.8, -32.29999999999979, 5.400000000000157, -405.0, 167.79999999999933, -73.8000000000007, -96.60000000000059, -12.800000000000006, -361.0, 173.50000000000003, 288.39999999999975, 172.19999999999985, 27.200000000000102, 10.099999999999778, -401.70000000000005, -86.30000000000034, 82.09999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-191.8, 14.899999999999965, 20.000000000000014, -88.00000000000057, 6.500000000000014, -118.89999999999996, -276.40000000000003, 20.000000000000014, -98.19999999999999, -56.500000000000014, 154.99999999999991, 150.19999999999993, -285.40000000000003, -0.09999999999998366, -73.30000000000032, -275.20000000000005, -223.6, -232.0, 85.99999999999997, 99.50000000000001, 20.000000000000014, -337.9, -74.79999999999998, -4.900000000000034, -379.6, -354.4, -144.7, -105.69999999999999, -301.0, -285.1, -46.30000000000001, -46.29999999999998, -400.0, 3.1999999999999615, -151.9, 20.000000000000014, -151.30000000000004, -90.99999999999999, -332.79999999999995, -268.0, -240.40000000000003, 3.1999999999999615, -358.0, 1.0999999999999865, -235.00000000000023, -316.6, -222.7, -179.8, 17.899999999999878, 13.099999999999937, -332.5, -397.9, -238.60000000000002, 17.899999999999988, -301.6, -9.399999999999821, 15.799999999999963, 20.000000000000014, -5.1999999999999265, -17.79999999999974, -220.0, -373.0, -369.39999999999986, -145.6, -374.8, 9.499999999999964, -198.4, 20.000000000000014, -268.6, 20.000000000000014, -6.899999999999942, -206.20000000000007, -207.70000000000005, 20.000000000000014, 20.000000000000014, -27.09999999999998, -188.8, -179.5, -178.90000000000006, -135.99999999999997, 96.19999999999993, 75.19999999999999, 1.6999999999999602, 52.39999999999995, -389.5, 13.699999999999966, 9.499999999999964, 11.599999999999966, -370.9, -295.0, 5.299999999999965, 40.99999999999993, -271.9, -366.4, -64.00000000000091, 1.0999999999999759, -176.2, -35.50000000000003, -226.9, -272.2, -400.0, 17.899999999999988, 157.39999999999998, 20.000000000000014, 49.40000000000004, 125.89999999999998, 7.399999999999965, -76.90000000000006, -5.1999999999999265, -328.3, -170.5, -7.299999999999891, -91.29999999999998, -179.20000000000005, -379.0, -391.0, -89.5, -139.89999999999998, -383.20000000000005, -309.1, 20.000000000000014, -21.400000000000006, -34.60000000000002, 21.499999999999943, -55.30000000000001, -79.0, -180.40000000000012, -194.2, -352.0, -397.9, -298.9, -373.0, 1.0999999999999865, -12.400000000000098, 3.1999999999999615, -372.7, 20.000000000000014, 13.699999999999964, 15.799999999999962, -5.1999999999999265, -386.5, 20.000000000000014, 13.699999999999964, -230.8, -38.799999999999756, -365.5, -41.19999999999999, -11.200000000000017, 130.09999999999988, 67.40000000000006, -13.599999999999783, -273.4, -264.4, -309.4, -328.0, -303.1, 3.1999999999999615, -346.6, -283.90000000000003, -295.3, -394.9, 21.800000000000043, -342.4, 17.899999999999988, -85.6000000000007, 20.000000000000014, -313.3, -314.5, -45.09999999999976, -242.2, 20.000000000000014, -112.6, -400.0, -400.0, 138.79999999999993, 20.000000000000014, -318.7, -66.10000000000076, 17.899999999999988, -377.5, -13.599999999999808, -263.20000000000005, -285.1, -373.9, 57.499999999999915, 40.99999999999997, 144.49999999999994, 122.89999999999992, 125.89999999999995, 5.300000000000175, 0.7999999999999723, 7.399999999999965, 20.000000000000014, -115.9, -397.9, -395.8, -319.3, 20.000000000000014, -34.599999999999795, 22.69999999999999], "policy_predator_policy_reward": [101.0, 64.0, 53.0, 13.0, 83.0, 90.0, 157.0, 2.0, 87.0, 16.0, 9.0, 8.0, 112.0, 146.0, 156.0, 85.0, 108.0, 139.0, 33.0, 22.0, 126.0, 166.0, 85.0, 14.0, 176.0, 99.0, 114.0, 12.0, 160.0, 144.0, 88.0, 25.0, 200.0, 116.0, 96.0, 12.0, 111.0, 28.0, 129.0, 174.0, 122.0, 120.0, 167.0, 158.0, 179.0, 71.0, 44.0, 114.0, 11.0, 53.0, 171.0, 172.0, 140.0, 78.0, 166.0, 20.0, 2.0, 0.0, 0.0, 18.0, 187.0, 191.0, 199.0, 126.0, 179.0, 185.0, 0.0, 131.0, 50.0, 139.0, 67.0, 122.0, 116.0, 73.0, 14.0, 70.0, 123.0, 15.0, 39.0, 117.0, 32.0, 10.0, 11.0, 61.0, 193.0, 188.0, 7.0, 5.0, 190.0, 120.0, 23.0, 7.0, 95.0, 161.0, 5.0, 48.0, 110.0, 82.0, 85.0, 149.0, 196.0, 156.0, 7.0, 3.0, 25.0, 16.0, 88.0, 1.0, 155.0, 126.0, 108.0, 117.0, 127.0, 44.0, 197.0, 187.0, 95.0, 110.0, 190.0, 155.0, 26.0, 56.0, 70.0, 0.0, 83.0, 44.0, 47.0, 131.0, 199.0, 47.0, 131.0, 161.0, 70.0, 9.0, 194.0, 57.0, 0.0, 3.0, 13.0, 1.0, 171.0, 178.0, 82.0, 58.0, 185.0, 177.0, 74.0, 44.0, 5.0, 31.0, 157.0, 12.0, 96.0, 150.0, 11.0, 185.0, 117.0, 139.0, 164.0, 94.0, 101.0, 197.0, 1.0, 179.0, 58.0, 11.0, 168.0, 167.0, 159.0, 96.0, 85.0, 13.0, 198.0, 197.0, 3.0, 6.0, 152.0, 159.0, 89.0, 174.0, 120.0, 144.0, 116.0, 182.0, 24.0, 51.0, 17.0, 4.0, 16.0, 25.0, 5.0, 14.0, 95.0, 11.0, 198.0, 194.0, 63.0, 150.0, 58.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7364175661450542, "mean_inference_ms": 1.9537171661712984, "mean_action_processing_ms": 0.3260679805513035, "mean_env_wait_ms": 0.2544505266319941, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045702457427978516, "StateBufferConnector_ms": 0.003445267677307129, "ViewRequirementAgentConnector_ms": 0.10657322406768799}, "num_episodes": 23, "episode_return_max": 322.20000000000016, "episode_return_min": -503.9, "episode_return_mean": -72.16700000000006, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.0996060934535, "num_env_steps_trained_throughput_per_sec": 350.0996060934535, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 11789.507, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11789.454, "sample_time_ms": 1450.273, "learn_time_ms": 10317.81, "learn_throughput": 387.679, "synch_weights_time_ms": 19.462}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "f0d88_00000", "date": "2024-08-14_10-53-51", "timestamp": 1723647231, "time_this_iter_s": 11.504998207092285, "time_total_s": 449.94835591316223, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4e5430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 449.94835591316223, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 45.05882352941177, "ram_util_percent": 83.32352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.724564205149494, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.562933744450725, "policy_loss": -0.010548054178802188, "vf_loss": 6.555652627490816, "vf_explained_var": -0.8013258951050894, "kl": 0.011739370331612663, "entropy": 1.2969282582323387, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6766564405153668, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 7.438568577186141, "policy_loss": -0.01888649260253207, "vf_loss": 7.429625748578833, "vf_explained_var": 0.5565019644442059, "kl": 0.01832382908776506, "entropy": 1.1757152791376466, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 288.39999999999975, "episode_reward_min": -503.9, "episode_reward_mean": -75.70200000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 157.39999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -132.086, "predator_policy": 94.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-103.3, -297.79999999999995, 4.800000000000161, -31.8999999999997, -301.5999999999991, -244.5, 94.9999999999998, -387.4, -2.699999999999834, -125.00000000000017, 37.80000000000027, -4.999999999999671, -215.0, -190.00000000000006, -1.300000000000039, -47.399999999999885, -59.599999999999824, -24.099999999999824, 1.3000000000001437, 76.89999999999944, -230.30000000000004, -158.89999999999995, 213.39999999999986, 126.0999999999998, 5.1999999999999815, 33.1000000000002, -355.9, 76.29999999999961, -382.3, -9.89999999999964, -19.699999999999875, -265.1, -30.099999999999987, 187.39999999999927, 216.2999999999998, 19.500000000000142, -52.4999999999998, 47.20000000000023, -99.5, -386.0, -24.399999999999967, -347.30000000000007, 80.5999999999994, 56.89999999999972, -7.300000000000125, -196.6, -503.9, -379.9, 67.69999999999919, -118.5000000000006, 36.70000000000025, 24.60000000000005, -17.500000000000007, -77.09999999999991, -42.29999999999976, 65.59999999999985, 233.49999999999977, -118.00000000000023, -327.79999999999995, -435.09999999999997, -87.40000000000043, -321.2, -75.10000000000063, -144.5000000000004, 3.4000000000000954, -292.8, -32.29999999999979, 5.400000000000157, -405.0, 167.79999999999933, -73.8000000000007, -96.60000000000059, -12.800000000000006, -361.0, 173.50000000000003, 288.39999999999975, 172.19999999999985, 27.200000000000102, 10.099999999999778, -401.70000000000005, -86.30000000000034, 82.09999999999974, -161.00000000000074, 41.09999999999963, 56.10000000000023, 197.69999999999948, -365.30000000000007, -309.4, -56.999999999999865, 39.60000000000024, 15.700000000000145, -175.60000000000073, 11.699999999999818, -12.999999999999876, -35.49999999999974, -68.39999999999995, 17.29999999999987, -100.60000000000016, -310.19999999999993, 23.600000000000158], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-151.30000000000004, -90.99999999999999, -332.79999999999995, -268.0, -240.40000000000003, 3.1999999999999615, -358.0, 1.0999999999999865, -235.00000000000023, -316.6, -222.7, -179.8, 17.899999999999878, 13.099999999999937, -332.5, -397.9, -238.60000000000002, 17.899999999999988, -301.6, -9.399999999999821, 15.799999999999963, 20.000000000000014, -5.1999999999999265, -17.79999999999974, -220.0, -373.0, -369.39999999999986, -145.6, -374.8, 9.499999999999964, -198.4, 20.000000000000014, -268.6, 20.000000000000014, -6.899999999999942, -206.20000000000007, -207.70000000000005, 20.000000000000014, 20.000000000000014, -27.09999999999998, -188.8, -179.5, -178.90000000000006, -135.99999999999997, 96.19999999999993, 75.19999999999999, 1.6999999999999602, 52.39999999999995, -389.5, 13.699999999999966, 9.499999999999964, 11.599999999999966, -370.9, -295.0, 5.299999999999965, 40.99999999999993, -271.9, -366.4, -64.00000000000091, 1.0999999999999759, -176.2, -35.50000000000003, -226.9, -272.2, -400.0, 17.899999999999988, 157.39999999999998, 20.000000000000014, 49.40000000000004, 125.89999999999998, 7.399999999999965, -76.90000000000006, -5.1999999999999265, -328.3, -170.5, -7.299999999999891, -91.29999999999998, -179.20000000000005, -379.0, -391.0, -89.5, -139.89999999999998, -383.20000000000005, -309.1, 20.000000000000014, -21.400000000000006, -34.60000000000002, 21.499999999999943, -55.30000000000001, -79.0, -180.40000000000012, -194.2, -352.0, -397.9, -298.9, -373.0, 1.0999999999999865, -12.400000000000098, 3.1999999999999615, -372.7, 20.000000000000014, 13.699999999999964, 15.799999999999962, -5.1999999999999265, -386.5, 20.000000000000014, 13.699999999999964, -230.8, -38.799999999999756, -365.5, -41.19999999999999, -11.200000000000017, 130.09999999999988, 67.40000000000006, -13.599999999999783, -273.4, -264.4, -309.4, -328.0, -303.1, 3.1999999999999615, -346.6, -283.90000000000003, -295.3, -394.9, 21.800000000000043, -342.4, 17.899999999999988, -85.6000000000007, 20.000000000000014, -313.3, -314.5, -45.09999999999976, -242.2, 20.000000000000014, -112.6, -400.0, -400.0, 138.79999999999993, 20.000000000000014, -318.7, -66.10000000000076, 17.899999999999988, -377.5, -13.599999999999808, -263.20000000000005, -285.1, -373.9, 57.499999999999915, 40.99999999999997, 144.49999999999994, 122.89999999999992, 125.89999999999995, 5.300000000000175, 0.7999999999999723, 7.399999999999965, 20.000000000000014, -115.9, -397.9, -395.8, -319.3, 20.000000000000014, -34.599999999999795, 22.69999999999999, -352.0, -118.00000000000074, 13.699999999999964, -52.599999999999966, -36.69999999999985, 30.800000000000196, 100.09999999999967, 59.599999999999994, -326.20000000000005, -285.1, -294.1, -268.29999999999995, -198.4, 7.399999999999965, -270.4, 20.000000000000014, 20.000000000000014, -175.3, -355.0, -34.599999999999774, -68.19999999999997, -45.10000000000008, 22.100000000000044, -147.1, -400.0, -11.499999999999819, -30.39999999999975, -193.0, -67.30000000000001, -90.39999999999999, -187.0, -106.60000000000014, -290.19999999999993, -304.0, -323.5, 1.0999999999999865], "policy_predator_policy_reward": [111.0, 28.0, 129.0, 174.0, 122.0, 120.0, 167.0, 158.0, 179.0, 71.0, 44.0, 114.0, 11.0, 53.0, 171.0, 172.0, 140.0, 78.0, 166.0, 20.0, 2.0, 0.0, 0.0, 18.0, 187.0, 191.0, 199.0, 126.0, 179.0, 185.0, 0.0, 131.0, 50.0, 139.0, 67.0, 122.0, 116.0, 73.0, 14.0, 70.0, 123.0, 15.0, 39.0, 117.0, 32.0, 10.0, 11.0, 61.0, 193.0, 188.0, 7.0, 5.0, 190.0, 120.0, 23.0, 7.0, 95.0, 161.0, 5.0, 48.0, 110.0, 82.0, 85.0, 149.0, 196.0, 156.0, 7.0, 3.0, 25.0, 16.0, 88.0, 1.0, 155.0, 126.0, 108.0, 117.0, 127.0, 44.0, 197.0, 187.0, 95.0, 110.0, 190.0, 155.0, 26.0, 56.0, 70.0, 0.0, 83.0, 44.0, 47.0, 131.0, 199.0, 47.0, 131.0, 161.0, 70.0, 9.0, 194.0, 57.0, 0.0, 3.0, 13.0, 1.0, 171.0, 178.0, 82.0, 58.0, 185.0, 177.0, 74.0, 44.0, 5.0, 31.0, 157.0, 12.0, 96.0, 150.0, 11.0, 185.0, 117.0, 139.0, 164.0, 94.0, 101.0, 197.0, 1.0, 179.0, 58.0, 11.0, 168.0, 167.0, 159.0, 96.0, 85.0, 13.0, 198.0, 197.0, 3.0, 6.0, 152.0, 159.0, 89.0, 174.0, 120.0, 144.0, 116.0, 182.0, 24.0, 51.0, 17.0, 4.0, 16.0, 25.0, 5.0, 14.0, 95.0, 11.0, 198.0, 194.0, 63.0, 150.0, 58.0, 36.0, 190.0, 119.0, 73.0, 7.0, 45.0, 17.0, 33.0, 5.0, 175.0, 71.0, 161.0, 92.0, 116.0, 18.0, 145.0, 145.0, 110.0, 61.0, 165.0, 49.0, 52.0, 73.0, 110.0, 2.0, 183.0, 193.0, 151.0, 4.0, 86.0, 89.0, 74.0, 119.0, 129.0, 155.0, 179.0, 167.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7330318309067851, "mean_inference_ms": 1.9427921480570531, "mean_action_processing_ms": 0.32401482250050323, "mean_env_wait_ms": 0.2531158292507991, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004597902297973633, "StateBufferConnector_ms": 0.0034400224685668945, "ViewRequirementAgentConnector_ms": 0.10459446907043457}, "num_episodes": 18, "episode_return_max": 288.39999999999975, "episode_return_min": -503.9, "episode_return_mean": -75.70200000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.90758480819926, "num_env_steps_trained_throughput_per_sec": 347.90758480819926, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 11632.685, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11632.633, "sample_time_ms": 1327.333, "learn_time_ms": 10285.25, "learn_throughput": 388.906, "synch_weights_time_ms": 18.11}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "f0d88_00000", "date": "2024-08-14_10-54-03", "timestamp": 1723647243, "time_this_iter_s": 11.549444913864136, "time_total_s": 461.49780082702637, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4e5550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 461.49780082702637, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 45.01875, "ram_util_percent": 83.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6841777734024814, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.725831998088372, "policy_loss": -0.01229847524581211, "vf_loss": 5.72087762570255, "vf_explained_var": -0.7593801025360349, "kl": 0.011359892094884947, "entropy": 1.310566406590598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.855737501098996, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 8.624500325369457, "policy_loss": -0.008080690185214201, "vf_loss": 8.599776634085115, "vf_explained_var": -0.0028019467358866698, "kl": 0.02159958651242749, "entropy": 1.2661096560261238, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 288.39999999999975, "episode_reward_min": -503.9, "episode_reward_mean": -70.4800000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 157.39999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -130.79, "predator_policy": 95.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.3000000000001437, 76.89999999999944, -230.30000000000004, -158.89999999999995, 213.39999999999986, 126.0999999999998, 5.1999999999999815, 33.1000000000002, -355.9, 76.29999999999961, -382.3, -9.89999999999964, -19.699999999999875, -265.1, -30.099999999999987, 187.39999999999927, 216.2999999999998, 19.500000000000142, -52.4999999999998, 47.20000000000023, -99.5, -386.0, -24.399999999999967, -347.30000000000007, 80.5999999999994, 56.89999999999972, -7.300000000000125, -196.6, -503.9, -379.9, 67.69999999999919, -118.5000000000006, 36.70000000000025, 24.60000000000005, -17.500000000000007, -77.09999999999991, -42.29999999999976, 65.59999999999985, 233.49999999999977, -118.00000000000023, -327.79999999999995, -435.09999999999997, -87.40000000000043, -321.2, -75.10000000000063, -144.5000000000004, 3.4000000000000954, -292.8, -32.29999999999979, 5.400000000000157, -405.0, 167.79999999999933, -73.8000000000007, -96.60000000000059, -12.800000000000006, -361.0, 173.50000000000003, 288.39999999999975, 172.19999999999985, 27.200000000000102, 10.099999999999778, -401.70000000000005, -86.30000000000034, 82.09999999999974, -161.00000000000074, 41.09999999999963, 56.10000000000023, 197.69999999999948, -365.30000000000007, -309.4, -56.999999999999865, 39.60000000000024, 15.700000000000145, -175.60000000000073, 11.699999999999818, -12.999999999999876, -35.49999999999974, -68.39999999999995, 17.29999999999987, -100.60000000000016, -310.19999999999993, 23.600000000000158, -103.30000000000015, -83.20000000000141, -50.199999999999804, -348.8, -83.7999999999999, -112.0000000000007, 46.20000000000037, -70.90000000000072, -15.599999999999831, 63.29999999999998, -80.90000000000063, -402.9, -27.69999999999974, 34.50000000000022, -18.099999999999852, 3.9999999999999813, -58.19999999999982, -69.19999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-207.70000000000005, 20.000000000000014, 20.000000000000014, -27.09999999999998, -188.8, -179.5, -178.90000000000006, -135.99999999999997, 96.19999999999993, 75.19999999999999, 1.6999999999999602, 52.39999999999995, -389.5, 13.699999999999966, 9.499999999999964, 11.599999999999966, -370.9, -295.0, 5.299999999999965, 40.99999999999993, -271.9, -366.4, -64.00000000000091, 1.0999999999999759, -176.2, -35.50000000000003, -226.9, -272.2, -400.0, 17.899999999999988, 157.39999999999998, 20.000000000000014, 49.40000000000004, 125.89999999999998, 7.399999999999965, -76.90000000000006, -5.1999999999999265, -328.3, -170.5, -7.299999999999891, -91.29999999999998, -179.20000000000005, -379.0, -391.0, -89.5, -139.89999999999998, -383.20000000000005, -309.1, 20.000000000000014, -21.400000000000006, -34.60000000000002, 21.499999999999943, -55.30000000000001, -79.0, -180.40000000000012, -194.2, -352.0, -397.9, -298.9, -373.0, 1.0999999999999865, -12.400000000000098, 3.1999999999999615, -372.7, 20.000000000000014, 13.699999999999964, 15.799999999999962, -5.1999999999999265, -386.5, 20.000000000000014, 13.699999999999964, -230.8, -38.799999999999756, -365.5, -41.19999999999999, -11.200000000000017, 130.09999999999988, 67.40000000000006, -13.599999999999783, -273.4, -264.4, -309.4, -328.0, -303.1, 3.1999999999999615, -346.6, -283.90000000000003, -295.3, -394.9, 21.800000000000043, -342.4, 17.899999999999988, -85.6000000000007, 20.000000000000014, -313.3, -314.5, -45.09999999999976, -242.2, 20.000000000000014, -112.6, -400.0, -400.0, 138.79999999999993, 20.000000000000014, -318.7, -66.10000000000076, 17.899999999999988, -377.5, -13.599999999999808, -263.20000000000005, -285.1, -373.9, 57.499999999999915, 40.99999999999997, 144.49999999999994, 122.89999999999992, 125.89999999999995, 5.300000000000175, 0.7999999999999723, 7.399999999999965, 20.000000000000014, -115.9, -397.9, -395.8, -319.3, 20.000000000000014, -34.599999999999795, 22.69999999999999, -352.0, -118.00000000000074, 13.699999999999964, -52.599999999999966, -36.69999999999985, 30.800000000000196, 100.09999999999967, 59.599999999999994, -326.20000000000005, -285.1, -294.1, -268.29999999999995, -198.4, 7.399999999999965, -270.4, 20.000000000000014, 20.000000000000014, -175.3, -355.0, -34.599999999999774, -68.19999999999997, -45.10000000000008, 22.100000000000044, -147.1, -400.0, -11.499999999999819, -30.39999999999975, -193.0, -67.30000000000001, -90.39999999999999, -187.0, -106.60000000000014, -290.19999999999993, -304.0, -323.5, 1.0999999999999865, -17.79999999999974, -248.5, -95.50000000000071, -107.70000000000073, -200.2, 20.000000000000014, -368.8, -325.0, -225.1, -36.70000000000004, -376.0, -67.00000000000071, 20.300000000000022, -15.099999999999863, -40.89999999999976, -379.0, -211.59999999999997, 20.000000000000014, -159.7, 20.000000000000014, 7.399999999999965, -229.30000000000015, -391.9, -355.0, -400.0, -15.699999999999747, 13.699999999999964, 15.799999999999963, -166.60000000000008, -11.4999999999999, -397.0, 20.000000000000014, -385.0, 15.799999999999963, -334.0, -56.2], "policy_predator_policy_reward": [116.0, 73.0, 14.0, 70.0, 123.0, 15.0, 39.0, 117.0, 32.0, 10.0, 11.0, 61.0, 193.0, 188.0, 7.0, 5.0, 190.0, 120.0, 23.0, 7.0, 95.0, 161.0, 5.0, 48.0, 110.0, 82.0, 85.0, 149.0, 196.0, 156.0, 7.0, 3.0, 25.0, 16.0, 88.0, 1.0, 155.0, 126.0, 108.0, 117.0, 127.0, 44.0, 197.0, 187.0, 95.0, 110.0, 190.0, 155.0, 26.0, 56.0, 70.0, 0.0, 83.0, 44.0, 47.0, 131.0, 199.0, 47.0, 131.0, 161.0, 70.0, 9.0, 194.0, 57.0, 0.0, 3.0, 13.0, 1.0, 171.0, 178.0, 82.0, 58.0, 185.0, 177.0, 74.0, 44.0, 5.0, 31.0, 157.0, 12.0, 96.0, 150.0, 11.0, 185.0, 117.0, 139.0, 164.0, 94.0, 101.0, 197.0, 1.0, 179.0, 58.0, 11.0, 168.0, 167.0, 159.0, 96.0, 85.0, 13.0, 198.0, 197.0, 3.0, 6.0, 152.0, 159.0, 89.0, 174.0, 120.0, 144.0, 116.0, 182.0, 24.0, 51.0, 17.0, 4.0, 16.0, 25.0, 5.0, 14.0, 95.0, 11.0, 198.0, 194.0, 63.0, 150.0, 58.0, 36.0, 190.0, 119.0, 73.0, 7.0, 45.0, 17.0, 33.0, 5.0, 175.0, 71.0, 161.0, 92.0, 116.0, 18.0, 145.0, 145.0, 110.0, 61.0, 165.0, 49.0, 52.0, 73.0, 110.0, 2.0, 183.0, 193.0, 151.0, 4.0, 86.0, 89.0, 74.0, 119.0, 129.0, 155.0, 179.0, 167.0, 155.0, 8.0, 41.0, 79.0, 128.0, 2.0, 156.0, 189.0, 145.0, 33.0, 139.0, 192.0, 16.0, 25.0, 182.0, 167.0, 125.0, 51.0, 116.0, 87.0, 6.0, 135.0, 199.0, 145.0, 195.0, 193.0, 3.0, 2.0, 109.0, 51.0, 197.0, 184.0, 141.0, 170.0, 173.0, 148.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7296956901184282, "mean_inference_ms": 1.9322411431845825, "mean_action_processing_ms": 0.32210036905844774, "mean_env_wait_ms": 0.25188708730408843, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004428267478942871, "StateBufferConnector_ms": 0.003346562385559082, "ViewRequirementAgentConnector_ms": 0.10410535335540771}, "num_episodes": 18, "episode_return_max": 288.39999999999975, "episode_return_min": -503.9, "episode_return_mean": -70.4800000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.28902354770185, "num_env_steps_trained_throughput_per_sec": 347.28902354770185, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 11593.091, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11593.038, "sample_time_ms": 1300.567, "learn_time_ms": 10275.165, "learn_throughput": 389.288, "synch_weights_time_ms": 15.318}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "f0d88_00000", "date": "2024-08-14_10-54-15", "timestamp": 1723647255, "time_this_iter_s": 11.577217102050781, "time_total_s": 473.07501792907715, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad49faf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 473.07501792907715, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 45.01764705882353, "ram_util_percent": 83.12941176470588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8809705452313499, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 6.911740581320707, "policy_loss": -0.015150657166337605, "vf_loss": 6.905716741400421, "vf_explained_var": -0.025951023045040312, "kl": 0.013942070143260984, "entropy": 1.286833818438192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.319952576501029, "cur_kl_coeff": 2.278124999999999, "cur_lr": 0.0010000000000000005, "total_loss": 8.31548035914305, "policy_loss": -0.012211659296893726, "vf_loss": 8.279674358468839, "vf_explained_var": -0.2546850938014883, "kl": 0.021077708298545026, "entropy": 1.2713549021059873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 288.39999999999975, "episode_reward_min": -503.9, "episode_reward_mean": -81.37200000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 144.49999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -145.681, "predator_policy": 104.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.399999999999967, -347.30000000000007, 80.5999999999994, 56.89999999999972, -7.300000000000125, -196.6, -503.9, -379.9, 67.69999999999919, -118.5000000000006, 36.70000000000025, 24.60000000000005, -17.500000000000007, -77.09999999999991, -42.29999999999976, 65.59999999999985, 233.49999999999977, -118.00000000000023, -327.79999999999995, -435.09999999999997, -87.40000000000043, -321.2, -75.10000000000063, -144.5000000000004, 3.4000000000000954, -292.8, -32.29999999999979, 5.400000000000157, -405.0, 167.79999999999933, -73.8000000000007, -96.60000000000059, -12.800000000000006, -361.0, 173.50000000000003, 288.39999999999975, 172.19999999999985, 27.200000000000102, 10.099999999999778, -401.70000000000005, -86.30000000000034, 82.09999999999974, -161.00000000000074, 41.09999999999963, 56.10000000000023, 197.69999999999948, -365.30000000000007, -309.4, -56.999999999999865, 39.60000000000024, 15.700000000000145, -175.60000000000073, 11.699999999999818, -12.999999999999876, -35.49999999999974, -68.39999999999995, 17.29999999999987, -100.60000000000016, -310.19999999999993, 23.600000000000158, -103.30000000000015, -83.20000000000141, -50.199999999999804, -348.8, -83.7999999999999, -112.0000000000007, 46.20000000000037, -70.90000000000072, -15.599999999999831, 63.29999999999998, -80.90000000000063, -402.9, -27.69999999999974, 34.50000000000022, -18.099999999999852, 3.9999999999999813, -58.19999999999982, -69.19999999999999, 44.90000000000022, -9.999999999999886, -304.1999999999999, -10.899999999999842, -160.29999999999995, 10.699999999999978, -17.299999999999557, -222.70000000000002, -102.89999999999998, -61.29999999999987, 61.1, -289.09999999999945, 32.40000000000018, -113.60000000000068, 14.199999999999953, -147.10000000000085, -277.89999999999975, -284.3, 47.60000000000044, 5.999999999999966, -316.29999999999995, 24.300000000000246], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-89.5, -139.89999999999998, -383.20000000000005, -309.1, 20.000000000000014, -21.400000000000006, -34.60000000000002, 21.499999999999943, -55.30000000000001, -79.0, -180.40000000000012, -194.2, -352.0, -397.9, -298.9, -373.0, 1.0999999999999865, -12.400000000000098, 3.1999999999999615, -372.7, 20.000000000000014, 13.699999999999964, 15.799999999999962, -5.1999999999999265, -386.5, 20.000000000000014, 13.699999999999964, -230.8, -38.799999999999756, -365.5, -41.19999999999999, -11.200000000000017, 130.09999999999988, 67.40000000000006, -13.599999999999783, -273.4, -264.4, -309.4, -328.0, -303.1, 3.1999999999999615, -346.6, -283.90000000000003, -295.3, -394.9, 21.800000000000043, -342.4, 17.899999999999988, -85.6000000000007, 20.000000000000014, -313.3, -314.5, -45.09999999999976, -242.2, 20.000000000000014, -112.6, -400.0, -400.0, 138.79999999999993, 20.000000000000014, -318.7, -66.10000000000076, 17.899999999999988, -377.5, -13.599999999999808, -263.20000000000005, -285.1, -373.9, 57.499999999999915, 40.99999999999997, 144.49999999999994, 122.89999999999992, 125.89999999999995, 5.300000000000175, 0.7999999999999723, 7.399999999999965, 20.000000000000014, -115.9, -397.9, -395.8, -319.3, 20.000000000000014, -34.599999999999795, 22.69999999999999, -352.0, -118.00000000000074, 13.699999999999964, -52.599999999999966, -36.69999999999985, 30.800000000000196, 100.09999999999967, 59.599999999999994, -326.20000000000005, -285.1, -294.1, -268.29999999999995, -198.4, 7.399999999999965, -270.4, 20.000000000000014, 20.000000000000014, -175.3, -355.0, -34.599999999999774, -68.19999999999997, -45.10000000000008, 22.100000000000044, -147.1, -400.0, -11.499999999999819, -30.39999999999975, -193.0, -67.30000000000001, -90.39999999999999, -187.0, -106.60000000000014, -290.19999999999993, -304.0, -323.5, 1.0999999999999865, -17.79999999999974, -248.5, -95.50000000000071, -107.70000000000073, -200.2, 20.000000000000014, -368.8, -325.0, -225.1, -36.70000000000004, -376.0, -67.00000000000071, 20.300000000000022, -15.099999999999863, -40.89999999999976, -379.0, -211.59999999999997, 20.000000000000014, -159.7, 20.000000000000014, 7.399999999999965, -229.30000000000015, -391.9, -355.0, -400.0, -15.699999999999747, 13.699999999999964, 15.799999999999963, -166.60000000000008, -11.4999999999999, -397.0, 20.000000000000014, -385.0, 15.799999999999963, -334.0, -56.2, 20.000000000000014, -210.1, 20.000000000000014, -334.0, -248.50000000000003, -327.69999999999993, 17.899999999999988, -308.8, -145.6, -217.70000000000002, 20.000000000000014, -265.2999999999993, -93.40000000000083, 1.0999999999999617, -233.8, -343.9, -345.70000000000005, -89.20000000000002, -364.2999999999999, -25.000000000000007, 5.299999999999965, -122.2, -272.5, -343.59999999999945, 17.899999999999988, 9.499999999999964, -380.5, 17.899999999999977, -309.699999999999, 17.899999999999988, -87.10000000000085, -400.0, -204.10000000000005, -260.8, -274.9, -366.4, -0.40000000000002767, 20.000000000000014, 20.000000000000014, -400.0, -369.1, -278.20000000000005, 3.1999999999999615, -235.9], "policy_predator_policy_reward": [95.0, 110.0, 190.0, 155.0, 26.0, 56.0, 70.0, 0.0, 83.0, 44.0, 47.0, 131.0, 199.0, 47.0, 131.0, 161.0, 70.0, 9.0, 194.0, 57.0, 0.0, 3.0, 13.0, 1.0, 171.0, 178.0, 82.0, 58.0, 185.0, 177.0, 74.0, 44.0, 5.0, 31.0, 157.0, 12.0, 96.0, 150.0, 11.0, 185.0, 117.0, 139.0, 164.0, 94.0, 101.0, 197.0, 1.0, 179.0, 58.0, 11.0, 168.0, 167.0, 159.0, 96.0, 85.0, 13.0, 198.0, 197.0, 3.0, 6.0, 152.0, 159.0, 89.0, 174.0, 120.0, 144.0, 116.0, 182.0, 24.0, 51.0, 17.0, 4.0, 16.0, 25.0, 5.0, 14.0, 95.0, 11.0, 198.0, 194.0, 63.0, 150.0, 58.0, 36.0, 190.0, 119.0, 73.0, 7.0, 45.0, 17.0, 33.0, 5.0, 175.0, 71.0, 161.0, 92.0, 116.0, 18.0, 145.0, 145.0, 110.0, 61.0, 165.0, 49.0, 52.0, 73.0, 110.0, 2.0, 183.0, 193.0, 151.0, 4.0, 86.0, 89.0, 74.0, 119.0, 129.0, 155.0, 179.0, 167.0, 155.0, 8.0, 41.0, 79.0, 128.0, 2.0, 156.0, 189.0, 145.0, 33.0, 139.0, 192.0, 16.0, 25.0, 182.0, 167.0, 125.0, 51.0, 116.0, 87.0, 6.0, 135.0, 199.0, 145.0, 195.0, 193.0, 3.0, 2.0, 109.0, 51.0, 197.0, 184.0, 141.0, 170.0, 173.0, 148.0, 134.0, 101.0, 149.0, 155.0, 167.0, 105.0, 163.0, 117.0, 78.0, 125.0, 123.0, 133.0, 38.0, 37.0, 161.0, 194.0, 174.0, 158.0, 143.0, 185.0, 99.0, 79.0, 130.0, 197.0, 0.0, 5.0, 187.0, 62.0, 156.0, 150.0, 143.0, 197.0, 24.0, 163.0, 171.0, 186.0, 11.0, 17.0, 186.0, 200.0, 195.0, 136.0, 152.0, 105.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7262011537719796, "mean_inference_ms": 1.9214769581283844, "mean_action_processing_ms": 0.31846699462635514, "mean_env_wait_ms": 0.25011230695327463, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008075118064880371, "StateBufferConnector_ms": 0.003161787986755371, "ViewRequirementAgentConnector_ms": 0.09850513935089111}, "num_episodes": 22, "episode_return_max": 288.39999999999975, "episode_return_min": -503.9, "episode_return_mean": -81.37200000000009, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.06592996783223, "num_env_steps_trained_throughput_per_sec": 353.06592996783223, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 11537.228, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11537.176, "sample_time_ms": 1274.255, "learn_time_ms": 10247.067, "learn_throughput": 390.356, "synch_weights_time_ms": 14.247}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "f0d88_00000", "date": "2024-08-14_10-54-26", "timestamp": 1723647266, "time_this_iter_s": 11.376290082931519, "time_total_s": 484.45130801200867, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4bc5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 484.45130801200867, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 45.85, "ram_util_percent": 83.43125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.079798299641836, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.5217511767432805, "policy_loss": -0.014786928251543372, "vf_loss": 5.515226972418487, "vf_explained_var": -0.014713158052434366, "kl": 0.014032025454413236, "entropy": 1.3224415962658231, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3613552829575917, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 8.055754857088523, "policy_loss": -0.01230266249908637, "vf_loss": 8.024776043967595, "vf_explained_var": -0.17666931776773362, "kl": 0.012665821597050358, "entropy": 1.2482600450515746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 288.39999999999975, "episode_reward_min": -405.0, "episode_reward_mean": -71.94800000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 144.49999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -146.719, "predator_policy": 110.745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-144.5000000000004, 3.4000000000000954, -292.8, -32.29999999999979, 5.400000000000157, -405.0, 167.79999999999933, -73.8000000000007, -96.60000000000059, -12.800000000000006, -361.0, 173.50000000000003, 288.39999999999975, 172.19999999999985, 27.200000000000102, 10.099999999999778, -401.70000000000005, -86.30000000000034, 82.09999999999974, -161.00000000000074, 41.09999999999963, 56.10000000000023, 197.69999999999948, -365.30000000000007, -309.4, -56.999999999999865, 39.60000000000024, 15.700000000000145, -175.60000000000073, 11.699999999999818, -12.999999999999876, -35.49999999999974, -68.39999999999995, 17.29999999999987, -100.60000000000016, -310.19999999999993, 23.600000000000158, -103.30000000000015, -83.20000000000141, -50.199999999999804, -348.8, -83.7999999999999, -112.0000000000007, 46.20000000000037, -70.90000000000072, -15.599999999999831, 63.29999999999998, -80.90000000000063, -402.9, -27.69999999999974, 34.50000000000022, -18.099999999999852, 3.9999999999999813, -58.19999999999982, -69.19999999999999, 44.90000000000022, -9.999999999999886, -304.1999999999999, -10.899999999999842, -160.29999999999995, 10.699999999999978, -17.299999999999557, -222.70000000000002, -102.89999999999998, -61.29999999999987, 61.1, -289.09999999999945, 32.40000000000018, -113.60000000000068, 14.199999999999953, -147.10000000000085, -277.89999999999975, -284.3, 47.60000000000044, 5.999999999999966, -316.29999999999995, 24.300000000000246, -57.99999999999994, 8.100000000000067, 25.40000000000022, -379.8, 36.50000000000015, 15.30000000000002, -21.599999999999746, -4.399999999999979, 40.30000000000004, -36.999999999999766, -44.09999999999967, -349.70000000000005, -18.89999999999973, -59.300000000000814, 121.10000000000008, -325.9, -392.79999999999995, -248.69999999999987, 77.49999999999994, 15.999999999999982, 29.400000000000247, -45.09999999999973, 44.300000000000125], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-342.4, 17.899999999999988, -85.6000000000007, 20.000000000000014, -313.3, -314.5, -45.09999999999976, -242.2, 20.000000000000014, -112.6, -400.0, -400.0, 138.79999999999993, 20.000000000000014, -318.7, -66.10000000000076, 17.899999999999988, -377.5, -13.599999999999808, -263.20000000000005, -285.1, -373.9, 57.499999999999915, 40.99999999999997, 144.49999999999994, 122.89999999999992, 125.89999999999995, 5.300000000000175, 0.7999999999999723, 7.399999999999965, 20.000000000000014, -115.9, -397.9, -395.8, -319.3, 20.000000000000014, -34.599999999999795, 22.69999999999999, -352.0, -118.00000000000074, 13.699999999999964, -52.599999999999966, -36.69999999999985, 30.800000000000196, 100.09999999999967, 59.599999999999994, -326.20000000000005, -285.1, -294.1, -268.29999999999995, -198.4, 7.399999999999965, -270.4, 20.000000000000014, 20.000000000000014, -175.3, -355.0, -34.599999999999774, -68.19999999999997, -45.10000000000008, 22.100000000000044, -147.1, -400.0, -11.499999999999819, -30.39999999999975, -193.0, -67.30000000000001, -90.39999999999999, -187.0, -106.60000000000014, -290.19999999999993, -304.0, -323.5, 1.0999999999999865, -17.79999999999974, -248.5, -95.50000000000071, -107.70000000000073, -200.2, 20.000000000000014, -368.8, -325.0, -225.1, -36.70000000000004, -376.0, -67.00000000000071, 20.300000000000022, -15.099999999999863, -40.89999999999976, -379.0, -211.59999999999997, 20.000000000000014, -159.7, 20.000000000000014, 7.399999999999965, -229.30000000000015, -391.9, -355.0, -400.0, -15.699999999999747, 13.699999999999964, 15.799999999999963, -166.60000000000008, -11.4999999999999, -397.0, 20.000000000000014, -385.0, 15.799999999999963, -334.0, -56.2, 20.000000000000014, -210.1, 20.000000000000014, -334.0, -248.50000000000003, -327.69999999999993, 17.899999999999988, -308.8, -145.6, -217.70000000000002, 20.000000000000014, -265.2999999999993, -93.40000000000083, 1.0999999999999617, -233.8, -343.9, -345.70000000000005, -89.20000000000002, -364.2999999999999, -25.000000000000007, 5.299999999999965, -122.2, -272.5, -343.59999999999945, 17.899999999999988, 9.499999999999964, -380.5, 17.899999999999977, -309.699999999999, 17.899999999999988, -87.10000000000085, -400.0, -204.10000000000005, -260.8, -274.9, -366.4, -0.40000000000002767, 20.000000000000014, 20.000000000000014, -400.0, -369.1, -278.20000000000005, 3.1999999999999615, -235.9, -200.79999999999998, -167.19999999999996, 9.499999999999964, -30.39999999999975, -161.8, 3.199999999999972, -374.8, -400.0, 17.899999999999988, -165.39999999999995, 1.0999999999999865, 3.1999999999999615, -372.39999999999986, -5.1999999999999265, -275.8, 31.40000000000022, -42.99999999999976, -33.700000000000024, -355.9, -15.09999999999977, 3.1999999999999615, -298.29999999999893, -369.40000000000003, -352.3, -7.299999999999891, -388.5999999999999, 17.899999999999988, -173.20000000000056, 111.79999999999998, -306.7, -382.9, -286.0, -368.79999999999995, -400.0, -352.0, -183.70000000000059, -101.80000000000058, 71.3, 7.399999999999965, -9.399999999999855, -316.0, 7.399999999999965, -334.6, -11.499999999999819, 11.599999999999964, -94.30000000000001], "policy_predator_policy_reward": [1.0, 179.0, 58.0, 11.0, 168.0, 167.0, 159.0, 96.0, 85.0, 13.0, 198.0, 197.0, 3.0, 6.0, 152.0, 159.0, 89.0, 174.0, 120.0, 144.0, 116.0, 182.0, 24.0, 51.0, 17.0, 4.0, 16.0, 25.0, 5.0, 14.0, 95.0, 11.0, 198.0, 194.0, 63.0, 150.0, 58.0, 36.0, 190.0, 119.0, 73.0, 7.0, 45.0, 17.0, 33.0, 5.0, 175.0, 71.0, 161.0, 92.0, 116.0, 18.0, 145.0, 145.0, 110.0, 61.0, 165.0, 49.0, 52.0, 73.0, 110.0, 2.0, 183.0, 193.0, 151.0, 4.0, 86.0, 89.0, 74.0, 119.0, 129.0, 155.0, 179.0, 167.0, 155.0, 8.0, 41.0, 79.0, 128.0, 2.0, 156.0, 189.0, 145.0, 33.0, 139.0, 192.0, 16.0, 25.0, 182.0, 167.0, 125.0, 51.0, 116.0, 87.0, 6.0, 135.0, 199.0, 145.0, 195.0, 193.0, 3.0, 2.0, 109.0, 51.0, 197.0, 184.0, 141.0, 170.0, 173.0, 148.0, 134.0, 101.0, 149.0, 155.0, 167.0, 105.0, 163.0, 117.0, 78.0, 125.0, 123.0, 133.0, 38.0, 37.0, 161.0, 194.0, 174.0, 158.0, 143.0, 185.0, 99.0, 79.0, 130.0, 197.0, 0.0, 5.0, 187.0, 62.0, 156.0, 150.0, 143.0, 197.0, 24.0, 163.0, 171.0, 186.0, 11.0, 17.0, 186.0, 200.0, 195.0, 136.0, 152.0, 105.0, 150.0, 160.0, 24.0, 5.0, 117.0, 67.0, 197.0, 198.0, 82.0, 102.0, 10.0, 1.0, 175.0, 181.0, 123.0, 117.0, 70.0, 47.0, 144.0, 190.0, 127.0, 124.0, 192.0, 180.0, 184.0, 193.0, 20.0, 76.0, 158.0, 158.0, 194.0, 149.0, 177.0, 199.0, 89.0, 198.0, 48.0, 60.0, 15.0, 3.0, 172.0, 166.0, 127.0, 174.0, 62.0, 65.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7231853244123968, "mean_inference_ms": 1.9077872457573262, "mean_action_processing_ms": 0.3183793783946308, "mean_env_wait_ms": 0.24929806365912177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008800148963928223, "StateBufferConnector_ms": 0.0031244754791259766, "ViewRequirementAgentConnector_ms": 0.1055448055267334}, "num_episodes": 23, "episode_return_max": 288.39999999999975, "episode_return_min": -405.0, "episode_return_mean": -71.94800000000004, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.09685185662045, "num_env_steps_trained_throughput_per_sec": 350.09685185662045, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 11486.221, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11486.171, "sample_time_ms": 1232.844, "learn_time_ms": 10238.837, "learn_throughput": 390.669, "synch_weights_time_ms": 12.833}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "f0d88_00000", "date": "2024-08-14_10-54-38", "timestamp": 1723647278, "time_this_iter_s": 11.482829809188843, "time_total_s": 495.9341378211975, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0d84c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 495.9341378211975, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 45.125, "ram_util_percent": 83.5625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8885457682231115, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.706102406915534, "policy_loss": -0.01781185580708244, "vf_loss": 5.7033912741948685, "vf_explained_var": 0.03604238339202114, "kl": 0.013513061793793347, "entropy": 1.2498814211320626, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.623867900094027, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 7.568067159349956, "policy_loss": -0.012251954970551192, "vf_loss": 7.54387673700928, "vf_explained_var": -0.1323284444039461, "kl": 0.010664433833805229, "entropy": 1.2360847864832196, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 197.69999999999948, "episode_reward_min": -402.9, "episode_reward_mean": -67.92699999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 111.79999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -145.62849999999997, "predator_policy": 111.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [82.09999999999974, -161.00000000000074, 41.09999999999963, 56.10000000000023, 197.69999999999948, -365.30000000000007, -309.4, -56.999999999999865, 39.60000000000024, 15.700000000000145, -175.60000000000073, 11.699999999999818, -12.999999999999876, -35.49999999999974, -68.39999999999995, 17.29999999999987, -100.60000000000016, -310.19999999999993, 23.600000000000158, -103.30000000000015, -83.20000000000141, -50.199999999999804, -348.8, -83.7999999999999, -112.0000000000007, 46.20000000000037, -70.90000000000072, -15.599999999999831, 63.29999999999998, -80.90000000000063, -402.9, -27.69999999999974, 34.50000000000022, -18.099999999999852, 3.9999999999999813, -58.19999999999982, -69.19999999999999, 44.90000000000022, -9.999999999999886, -304.1999999999999, -10.899999999999842, -160.29999999999995, 10.699999999999978, -17.299999999999557, -222.70000000000002, -102.89999999999998, -61.29999999999987, 61.1, -289.09999999999945, 32.40000000000018, -113.60000000000068, 14.199999999999953, -147.10000000000085, -277.89999999999975, -284.3, 47.60000000000044, 5.999999999999966, -316.29999999999995, 24.300000000000246, -57.99999999999994, 8.100000000000067, 25.40000000000022, -379.8, 36.50000000000015, 15.30000000000002, -21.599999999999746, -4.399999999999979, 40.30000000000004, -36.999999999999766, -44.09999999999967, -349.70000000000005, -18.89999999999973, -59.300000000000814, 121.10000000000008, -325.9, -392.79999999999995, -248.69999999999987, 77.49999999999994, 15.999999999999982, 29.400000000000247, -45.09999999999973, 44.300000000000125, 74.19999999999987, -280.69999999999914, -0.5000000000000311, 12.399999999999988, 35.000000000000206, 29.000000000000128, 60.70000000000042, -379.8, -167.30000000000004, 36.300000000000246, -50.69999999999982, 70.1000000000002, -15.199999999999868, 27.59999999999995, 11.299999999999969, 30.100000000000144, -114.1, -35.099999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-34.599999999999795, 22.69999999999999, -352.0, -118.00000000000074, 13.699999999999964, -52.599999999999966, -36.69999999999985, 30.800000000000196, 100.09999999999967, 59.599999999999994, -326.20000000000005, -285.1, -294.1, -268.29999999999995, -198.4, 7.399999999999965, -270.4, 20.000000000000014, 20.000000000000014, -175.3, -355.0, -34.599999999999774, -68.19999999999997, -45.10000000000008, 22.100000000000044, -147.1, -400.0, -11.499999999999819, -30.39999999999975, -193.0, -67.30000000000001, -90.39999999999999, -187.0, -106.60000000000014, -290.19999999999993, -304.0, -323.5, 1.0999999999999865, -17.79999999999974, -248.5, -95.50000000000071, -107.70000000000073, -200.2, 20.000000000000014, -368.8, -325.0, -225.1, -36.70000000000004, -376.0, -67.00000000000071, 20.300000000000022, -15.099999999999863, -40.89999999999976, -379.0, -211.59999999999997, 20.000000000000014, -159.7, 20.000000000000014, 7.399999999999965, -229.30000000000015, -391.9, -355.0, -400.0, -15.699999999999747, 13.699999999999964, 15.799999999999963, -166.60000000000008, -11.4999999999999, -397.0, 20.000000000000014, -385.0, 15.799999999999963, -334.0, -56.2, 20.000000000000014, -210.1, 20.000000000000014, -334.0, -248.50000000000003, -327.69999999999993, 17.899999999999988, -308.8, -145.6, -217.70000000000002, 20.000000000000014, -265.2999999999993, -93.40000000000083, 1.0999999999999617, -233.8, -343.9, -345.70000000000005, -89.20000000000002, -364.2999999999999, -25.000000000000007, 5.299999999999965, -122.2, -272.5, -343.59999999999945, 17.899999999999988, 9.499999999999964, -380.5, 17.899999999999977, -309.699999999999, 17.899999999999988, -87.10000000000085, -400.0, -204.10000000000005, -260.8, -274.9, -366.4, -0.40000000000002767, 20.000000000000014, 20.000000000000014, -400.0, -369.1, -278.20000000000005, 3.1999999999999615, -235.9, -200.79999999999998, -167.19999999999996, 9.499999999999964, -30.39999999999975, -161.8, 3.199999999999972, -374.8, -400.0, 17.899999999999988, -165.39999999999995, 1.0999999999999865, 3.1999999999999615, -372.39999999999986, -5.1999999999999265, -275.8, 31.40000000000022, -42.99999999999976, -33.700000000000024, -355.9, -15.09999999999977, 3.1999999999999615, -298.29999999999893, -369.40000000000003, -352.3, -7.299999999999891, -388.5999999999999, 17.899999999999988, -173.20000000000056, 111.79999999999998, -306.7, -382.9, -286.0, -368.79999999999995, -400.0, -352.0, -183.70000000000059, -101.80000000000058, 71.3, 7.399999999999965, -9.399999999999855, -316.0, 7.399999999999965, -334.6, -11.499999999999819, 11.599999999999964, -94.30000000000001, 11.299999999999997, 17.899999999999988, -371.20000000000005, -281.4999999999991, -83.50000000000038, -172.0, -36.699999999999754, 4.0999999999999766, 20.000000000000014, -310.0, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, -20.49999999999983, -371.8, -259.0, -333.39999999999986, -196.9, 20.000000000000014, 5.299999999999965, 5.299999999999965, -358.0, 11.599999999999964, 51.499999999999964, 30.800000000000033, -388.0, -202.00000000000048, 95.60000000000001, 20.000000000000014, -390.69999999999993, 15.799999999999963, 5.299999999999965, -85.60000000000002, -275.5, -24.400000000000006, -360.70000000000005], "policy_predator_policy_reward": [58.0, 36.0, 190.0, 119.0, 73.0, 7.0, 45.0, 17.0, 33.0, 5.0, 175.0, 71.0, 161.0, 92.0, 116.0, 18.0, 145.0, 145.0, 110.0, 61.0, 165.0, 49.0, 52.0, 73.0, 110.0, 2.0, 183.0, 193.0, 151.0, 4.0, 86.0, 89.0, 74.0, 119.0, 129.0, 155.0, 179.0, 167.0, 155.0, 8.0, 41.0, 79.0, 128.0, 2.0, 156.0, 189.0, 145.0, 33.0, 139.0, 192.0, 16.0, 25.0, 182.0, 167.0, 125.0, 51.0, 116.0, 87.0, 6.0, 135.0, 199.0, 145.0, 195.0, 193.0, 3.0, 2.0, 109.0, 51.0, 197.0, 184.0, 141.0, 170.0, 173.0, 148.0, 134.0, 101.0, 149.0, 155.0, 167.0, 105.0, 163.0, 117.0, 78.0, 125.0, 123.0, 133.0, 38.0, 37.0, 161.0, 194.0, 174.0, 158.0, 143.0, 185.0, 99.0, 79.0, 130.0, 197.0, 0.0, 5.0, 187.0, 62.0, 156.0, 150.0, 143.0, 197.0, 24.0, 163.0, 171.0, 186.0, 11.0, 17.0, 186.0, 200.0, 195.0, 136.0, 152.0, 105.0, 150.0, 160.0, 24.0, 5.0, 117.0, 67.0, 197.0, 198.0, 82.0, 102.0, 10.0, 1.0, 175.0, 181.0, 123.0, 117.0, 70.0, 47.0, 144.0, 190.0, 127.0, 124.0, 192.0, 180.0, 184.0, 193.0, 20.0, 76.0, 158.0, 158.0, 194.0, 149.0, 177.0, 199.0, 89.0, 198.0, 48.0, 60.0, 15.0, 3.0, 172.0, 166.0, 127.0, 174.0, 62.0, 65.0, 22.0, 23.0, 195.0, 177.0, 125.0, 130.0, 17.0, 28.0, 165.0, 160.0, 10.0, 0.0, 34.0, 44.0, 52.0, 199.0, 178.0, 185.0, 4.0, 7.0, 141.0, 161.0, 4.0, 3.0, 194.0, 148.0, 107.0, 27.0, 196.0, 186.0, 7.0, 2.0, 85.0, 162.0, 174.0, 176.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7200490189336, "mean_inference_ms": 1.900822688036003, "mean_action_processing_ms": 0.3161687350923766, "mean_env_wait_ms": 0.24804459248452632, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008784651756286621, "StateBufferConnector_ms": 0.0030279159545898438, "ViewRequirementAgentConnector_ms": 0.09961175918579102}, "num_episodes": 18, "episode_return_max": 197.69999999999948, "episode_return_min": -402.9, "episode_return_mean": -67.92699999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.1005360828627, "num_env_steps_trained_throughput_per_sec": 348.1005360828627, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 11463.186, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11463.142, "sample_time_ms": 1215.982, "learn_time_ms": 10232.517, "learn_throughput": 390.911, "synch_weights_time_ms": 12.886}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "f0d88_00000", "date": "2024-08-14_10-54-49", "timestamp": 1723647289, "time_this_iter_s": 11.529419898986816, "time_total_s": 507.4635577201843, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e5ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 507.4635577201843, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 45.38125, "ram_util_percent": 83.51249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9834067303036886, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.946248698108411, "policy_loss": -0.016802130094556895, "vf_loss": 5.941904112397047, "vf_explained_var": 0.09864457501936211, "kl": 0.013923760088482751, "entropy": 1.2292120430204603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.833543711743027, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 7.284312578483864, "policy_loss": -0.012087632694759619, "vf_loss": 7.263825950168428, "vf_explained_var": -0.29516254127340974, "kl": 0.009532473156803322, "entropy": 1.262900047453623, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 130.59999999999923, "episode_reward_min": -402.9, "episode_reward_mean": -58.70799999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 111.79999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -142.87900000000002, "predator_policy": 113.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.600000000000158, -103.30000000000015, -83.20000000000141, -50.199999999999804, -348.8, -83.7999999999999, -112.0000000000007, 46.20000000000037, -70.90000000000072, -15.599999999999831, 63.29999999999998, -80.90000000000063, -402.9, -27.69999999999974, 34.50000000000022, -18.099999999999852, 3.9999999999999813, -58.19999999999982, -69.19999999999999, 44.90000000000022, -9.999999999999886, -304.1999999999999, -10.899999999999842, -160.29999999999995, 10.699999999999978, -17.299999999999557, -222.70000000000002, -102.89999999999998, -61.29999999999987, 61.1, -289.09999999999945, 32.40000000000018, -113.60000000000068, 14.199999999999953, -147.10000000000085, -277.89999999999975, -284.3, 47.60000000000044, 5.999999999999966, -316.29999999999995, 24.300000000000246, -57.99999999999994, 8.100000000000067, 25.40000000000022, -379.8, 36.50000000000015, 15.30000000000002, -21.599999999999746, -4.399999999999979, 40.30000000000004, -36.999999999999766, -44.09999999999967, -349.70000000000005, -18.89999999999973, -59.300000000000814, 121.10000000000008, -325.9, -392.79999999999995, -248.69999999999987, 77.49999999999994, 15.999999999999982, 29.400000000000247, -45.09999999999973, 44.300000000000125, 74.19999999999987, -280.69999999999914, -0.5000000000000311, 12.399999999999988, 35.000000000000206, 29.000000000000128, 60.70000000000042, -379.8, -167.30000000000004, 36.300000000000246, -50.69999999999982, 70.1000000000002, -15.199999999999868, 27.59999999999995, 11.299999999999969, 30.100000000000144, -114.1, -35.099999999999994, -21.09999999999983, -259.0999999999987, -43.69999999999977, 40.400000000000304, -5.4999999999999485, -20.90000000000009, 54.50000000000013, 117.6000000000002, -66.60000000000122, 130.59999999999923, 25.90000000000009, -202.70000000000013, -28.09999999999981, -63.20000000000158, 2.320088565710421e-13, 87.50000000000011, 33.099999999999994, 8.499999999999977], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-323.5, 1.0999999999999865, -17.79999999999974, -248.5, -95.50000000000071, -107.70000000000073, -200.2, 20.000000000000014, -368.8, -325.0, -225.1, -36.70000000000004, -376.0, -67.00000000000071, 20.300000000000022, -15.099999999999863, -40.89999999999976, -379.0, -211.59999999999997, 20.000000000000014, -159.7, 20.000000000000014, 7.399999999999965, -229.30000000000015, -391.9, -355.0, -400.0, -15.699999999999747, 13.699999999999964, 15.799999999999963, -166.60000000000008, -11.4999999999999, -397.0, 20.000000000000014, -385.0, 15.799999999999963, -334.0, -56.2, 20.000000000000014, -210.1, 20.000000000000014, -334.0, -248.50000000000003, -327.69999999999993, 17.899999999999988, -308.8, -145.6, -217.70000000000002, 20.000000000000014, -265.2999999999993, -93.40000000000083, 1.0999999999999617, -233.8, -343.9, -345.70000000000005, -89.20000000000002, -364.2999999999999, -25.000000000000007, 5.299999999999965, -122.2, -272.5, -343.59999999999945, 17.899999999999988, 9.499999999999964, -380.5, 17.899999999999977, -309.699999999999, 17.899999999999988, -87.10000000000085, -400.0, -204.10000000000005, -260.8, -274.9, -366.4, -0.40000000000002767, 20.000000000000014, 20.000000000000014, -400.0, -369.1, -278.20000000000005, 3.1999999999999615, -235.9, -200.79999999999998, -167.19999999999996, 9.499999999999964, -30.39999999999975, -161.8, 3.199999999999972, -374.8, -400.0, 17.899999999999988, -165.39999999999995, 1.0999999999999865, 3.1999999999999615, -372.39999999999986, -5.1999999999999265, -275.8, 31.40000000000022, -42.99999999999976, -33.700000000000024, -355.9, -15.09999999999977, 3.1999999999999615, -298.29999999999893, -369.40000000000003, -352.3, -7.299999999999891, -388.5999999999999, 17.899999999999988, -173.20000000000056, 111.79999999999998, -306.7, -382.9, -286.0, -368.79999999999995, -400.0, -352.0, -183.70000000000059, -101.80000000000058, 71.3, 7.399999999999965, -9.399999999999855, -316.0, 7.399999999999965, -334.6, -11.499999999999819, 11.599999999999964, -94.30000000000001, 11.299999999999997, 17.899999999999988, -371.20000000000005, -281.4999999999991, -83.50000000000038, -172.0, -36.699999999999754, 4.0999999999999766, 20.000000000000014, -310.0, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, -20.49999999999983, -371.8, -259.0, -333.39999999999986, -196.9, 20.000000000000014, 5.299999999999965, 5.299999999999965, -358.0, 11.599999999999964, 51.499999999999964, 30.800000000000033, -388.0, -202.00000000000048, 95.60000000000001, 20.000000000000014, -390.69999999999993, 15.799999999999963, 5.299999999999965, -85.60000000000002, -275.5, -24.400000000000006, -360.70000000000005, 7.399999999999965, -239.5, -384.69999999999993, -252.3999999999999, -356.2, -53.50000000000011, 11.599999999999964, 21.80000000000004, 7.399999999999965, -301.8999999999994, -231.4000000000001, -92.5, -137.5, 20.000000000000018, -193.89999999999998, 69.49999999999999, -45.099999999999845, -74.50000000000054, -18.400000000000034, -0.9999999999999846, -22.89999999999978, 15.799999999999963, -200.20000000000013, -386.5, -0.9999999999999846, -306.1, -97.60000000000079, -55.60000000000012, -15.699999999999761, -28.29999999999975, -0.09999999999999937, 53.600000000000136, 92.5999999999998, -335.50000000000006, -352.0, -11.499999999999819], "policy_predator_policy_reward": [179.0, 167.0, 155.0, 8.0, 41.0, 79.0, 128.0, 2.0, 156.0, 189.0, 145.0, 33.0, 139.0, 192.0, 16.0, 25.0, 182.0, 167.0, 125.0, 51.0, 116.0, 87.0, 6.0, 135.0, 199.0, 145.0, 195.0, 193.0, 3.0, 2.0, 109.0, 51.0, 197.0, 184.0, 141.0, 170.0, 173.0, 148.0, 134.0, 101.0, 149.0, 155.0, 167.0, 105.0, 163.0, 117.0, 78.0, 125.0, 123.0, 133.0, 38.0, 37.0, 161.0, 194.0, 174.0, 158.0, 143.0, 185.0, 99.0, 79.0, 130.0, 197.0, 0.0, 5.0, 187.0, 62.0, 156.0, 150.0, 143.0, 197.0, 24.0, 163.0, 171.0, 186.0, 11.0, 17.0, 186.0, 200.0, 195.0, 136.0, 152.0, 105.0, 150.0, 160.0, 24.0, 5.0, 117.0, 67.0, 197.0, 198.0, 82.0, 102.0, 10.0, 1.0, 175.0, 181.0, 123.0, 117.0, 70.0, 47.0, 144.0, 190.0, 127.0, 124.0, 192.0, 180.0, 184.0, 193.0, 20.0, 76.0, 158.0, 158.0, 194.0, 149.0, 177.0, 199.0, 89.0, 198.0, 48.0, 60.0, 15.0, 3.0, 172.0, 166.0, 127.0, 174.0, 62.0, 65.0, 22.0, 23.0, 195.0, 177.0, 125.0, 130.0, 17.0, 28.0, 165.0, 160.0, 10.0, 0.0, 34.0, 44.0, 52.0, 199.0, 178.0, 185.0, 4.0, 7.0, 141.0, 161.0, 4.0, 3.0, 194.0, 148.0, 107.0, 27.0, 196.0, 186.0, 7.0, 2.0, 85.0, 162.0, 174.0, 176.0, 142.0, 69.0, 185.0, 193.0, 183.0, 183.0, 3.0, 4.0, 153.0, 136.0, 139.0, 164.0, 73.0, 99.0, 120.0, 122.0, 9.0, 44.0, 76.0, 74.0, 22.0, 11.0, 188.0, 196.0, 159.0, 120.0, 61.0, 29.0, 27.0, 17.0, 14.0, 20.0, 108.0, 168.0, 195.0, 177.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7175946934711069, "mean_inference_ms": 1.8929891636337015, "mean_action_processing_ms": 0.3145819606455197, "mean_env_wait_ms": 0.24712080610883486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008737683296203613, "StateBufferConnector_ms": 0.0035778284072875977, "ViewRequirementAgentConnector_ms": 0.09966051578521729}, "num_episodes": 18, "episode_return_max": 130.59999999999923, "episode_return_min": -402.9, "episode_return_mean": -58.70799999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 313.533462047905, "num_env_steps_trained_throughput_per_sec": 313.533462047905, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 11587.663, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11587.619, "sample_time_ms": 1226.094, "learn_time_ms": 10347.117, "learn_throughput": 386.581, "synch_weights_time_ms": 12.78}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "f0d88_00000", "date": "2024-08-14_10-55-02", "timestamp": 1723647302, "time_this_iter_s": 12.796557188034058, "time_total_s": 520.2601149082184, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0d8af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 520.2601149082184, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 55.3421052631579, "ram_util_percent": 83.48947368421052}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9178976560395862, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.155911169481025, "policy_loss": -0.01874765609699011, "vf_loss": 5.1558240638208135, "vf_explained_var": 0.12365182915692607, "kl": 0.01240149617006147, "entropy": 1.246033376045328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.080908943484069, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 8.383773140427927, "policy_loss": -0.012108099014158286, "vf_loss": 8.369115141964464, "vf_explained_var": -0.13310065509150268, "kl": 0.007832778156860589, "entropy": 1.229665566689123, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 203.60000000000002, "episode_reward_min": -392.79999999999995, "episode_reward_mean": -46.29599999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 116.29999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -131.08800000000002, "predator_policy": 107.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-69.19999999999999, 44.90000000000022, -9.999999999999886, -304.1999999999999, -10.899999999999842, -160.29999999999995, 10.699999999999978, -17.299999999999557, -222.70000000000002, -102.89999999999998, -61.29999999999987, 61.1, -289.09999999999945, 32.40000000000018, -113.60000000000068, 14.199999999999953, -147.10000000000085, -277.89999999999975, -284.3, 47.60000000000044, 5.999999999999966, -316.29999999999995, 24.300000000000246, -57.99999999999994, 8.100000000000067, 25.40000000000022, -379.8, 36.50000000000015, 15.30000000000002, -21.599999999999746, -4.399999999999979, 40.30000000000004, -36.999999999999766, -44.09999999999967, -349.70000000000005, -18.89999999999973, -59.300000000000814, 121.10000000000008, -325.9, -392.79999999999995, -248.69999999999987, 77.49999999999994, 15.999999999999982, 29.400000000000247, -45.09999999999973, 44.300000000000125, 74.19999999999987, -280.69999999999914, -0.5000000000000311, 12.399999999999988, 35.000000000000206, 29.000000000000128, 60.70000000000042, -379.8, -167.30000000000004, 36.300000000000246, -50.69999999999982, 70.1000000000002, -15.199999999999868, 27.59999999999995, 11.299999999999969, 30.100000000000144, -114.1, -35.099999999999994, -21.09999999999983, -259.0999999999987, -43.69999999999977, 40.400000000000304, -5.4999999999999485, -20.90000000000009, 54.50000000000013, 117.6000000000002, -66.60000000000122, 130.59999999999923, 25.90000000000009, -202.70000000000013, -28.09999999999981, -63.20000000000158, 2.320088565710421e-13, 87.50000000000011, 33.099999999999994, 8.499999999999977, 30.899999999999977, -55.999999999999744, -104.80000000000099, 9.699999999999962, 19.19999999999996, -45.900000000000205, 162.50000000000009, -213.10000000000056, 203.60000000000002, 187.20000000000007, -20.09999999999971, 22.400000000000016, -60.80000000000053, 21.09999999999999, -27.199999999999676, 37.80000000000027, -324.8, 115.49999999999977], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-334.0, -56.2, 20.000000000000014, -210.1, 20.000000000000014, -334.0, -248.50000000000003, -327.69999999999993, 17.899999999999988, -308.8, -145.6, -217.70000000000002, 20.000000000000014, -265.2999999999993, -93.40000000000083, 1.0999999999999617, -233.8, -343.9, -345.70000000000005, -89.20000000000002, -364.2999999999999, -25.000000000000007, 5.299999999999965, -122.2, -272.5, -343.59999999999945, 17.899999999999988, 9.499999999999964, -380.5, 17.899999999999977, -309.699999999999, 17.899999999999988, -87.10000000000085, -400.0, -204.10000000000005, -260.8, -274.9, -366.4, -0.40000000000002767, 20.000000000000014, 20.000000000000014, -400.0, -369.1, -278.20000000000005, 3.1999999999999615, -235.9, -200.79999999999998, -167.19999999999996, 9.499999999999964, -30.39999999999975, -161.8, 3.199999999999972, -374.8, -400.0, 17.899999999999988, -165.39999999999995, 1.0999999999999865, 3.1999999999999615, -372.39999999999986, -5.1999999999999265, -275.8, 31.40000000000022, -42.99999999999976, -33.700000000000024, -355.9, -15.09999999999977, 3.1999999999999615, -298.29999999999893, -369.40000000000003, -352.3, -7.299999999999891, -388.5999999999999, 17.899999999999988, -173.20000000000056, 111.79999999999998, -306.7, -382.9, -286.0, -368.79999999999995, -400.0, -352.0, -183.70000000000059, -101.80000000000058, 71.3, 7.399999999999965, -9.399999999999855, -316.0, 7.399999999999965, -334.6, -11.499999999999819, 11.599999999999964, -94.30000000000001, 11.299999999999997, 17.899999999999988, -371.20000000000005, -281.4999999999991, -83.50000000000038, -172.0, -36.699999999999754, 4.0999999999999766, 20.000000000000014, -310.0, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, -20.49999999999983, -371.8, -259.0, -333.39999999999986, -196.9, 20.000000000000014, 5.299999999999965, 5.299999999999965, -358.0, 11.599999999999964, 51.499999999999964, 30.800000000000033, -388.0, -202.00000000000048, 95.60000000000001, 20.000000000000014, -390.69999999999993, 15.799999999999963, 5.299999999999965, -85.60000000000002, -275.5, -24.400000000000006, -360.70000000000005, 7.399999999999965, -239.5, -384.69999999999993, -252.3999999999999, -356.2, -53.50000000000011, 11.599999999999964, 21.80000000000004, 7.399999999999965, -301.8999999999994, -231.4000000000001, -92.5, -137.5, 20.000000000000018, -193.89999999999998, 69.49999999999999, -45.099999999999845, -74.50000000000054, -18.400000000000034, -0.9999999999999846, -22.89999999999978, 15.799999999999963, -200.20000000000013, -386.5, -0.9999999999999846, -306.1, -97.60000000000079, -55.60000000000012, -15.699999999999761, -28.29999999999975, -0.09999999999999937, 53.600000000000136, 92.5999999999998, -335.50000000000006, -352.0, -11.499999999999819, 21.799999999999983, -247.9, -364.9, 17.899999999999988, -244.00000000000037, -74.80000000000064, -143.80000000000038, -47.499999999999766, -18.09999999999976, 5.299999999999965, -307.0, -19.900000000000205, 116.29999999999998, -173.8, -312.39999999999964, -225.70000000000047, 70.10000000000005, 87.5, -53.8, 91.99999999999999, -156.70000000000036, 11.599999999999964, 15.799999999999963, -51.400000000000034, -84.10000000000082, -252.7, -28.29999999999975, 7.399999999999965, -97.6000000000004, -76.60000000000085, 20.000000000000014, 15.799999999999963, -327.1, -321.70000000000005, 20.000000000000014, 90.49999999999999], "policy_predator_policy_reward": [173.0, 148.0, 134.0, 101.0, 149.0, 155.0, 167.0, 105.0, 163.0, 117.0, 78.0, 125.0, 123.0, 133.0, 38.0, 37.0, 161.0, 194.0, 174.0, 158.0, 143.0, 185.0, 99.0, 79.0, 130.0, 197.0, 0.0, 5.0, 187.0, 62.0, 156.0, 150.0, 143.0, 197.0, 24.0, 163.0, 171.0, 186.0, 11.0, 17.0, 186.0, 200.0, 195.0, 136.0, 152.0, 105.0, 150.0, 160.0, 24.0, 5.0, 117.0, 67.0, 197.0, 198.0, 82.0, 102.0, 10.0, 1.0, 175.0, 181.0, 123.0, 117.0, 70.0, 47.0, 144.0, 190.0, 127.0, 124.0, 192.0, 180.0, 184.0, 193.0, 20.0, 76.0, 158.0, 158.0, 194.0, 149.0, 177.0, 199.0, 89.0, 198.0, 48.0, 60.0, 15.0, 3.0, 172.0, 166.0, 127.0, 174.0, 62.0, 65.0, 22.0, 23.0, 195.0, 177.0, 125.0, 130.0, 17.0, 28.0, 165.0, 160.0, 10.0, 0.0, 34.0, 44.0, 52.0, 199.0, 178.0, 185.0, 4.0, 7.0, 141.0, 161.0, 4.0, 3.0, 194.0, 148.0, 107.0, 27.0, 196.0, 186.0, 7.0, 2.0, 85.0, 162.0, 174.0, 176.0, 142.0, 69.0, 185.0, 193.0, 183.0, 183.0, 3.0, 4.0, 153.0, 136.0, 139.0, 164.0, 73.0, 99.0, 120.0, 122.0, 9.0, 44.0, 76.0, 74.0, 22.0, 11.0, 188.0, 196.0, 159.0, 120.0, 61.0, 29.0, 27.0, 17.0, 14.0, 20.0, 108.0, 168.0, 195.0, 177.0, 153.0, 104.0, 171.0, 120.0, 120.0, 94.0, 91.0, 110.0, 10.0, 22.0, 109.0, 172.0, 115.0, 105.0, 163.0, 162.0, 28.0, 18.0, 65.0, 84.0, 55.0, 70.0, 26.0, 32.0, 142.0, 134.0, 18.0, 24.0, 69.0, 78.0, 0.0, 2.0, 176.0, 148.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7155663973738072, "mean_inference_ms": 1.8864792360622806, "mean_action_processing_ms": 0.3131727236575737, "mean_env_wait_ms": 0.24628543769476152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008808255195617676, "StateBufferConnector_ms": 0.003613591194152832, "ViewRequirementAgentConnector_ms": 0.10193562507629395}, "num_episodes": 18, "episode_return_max": 203.60000000000002, "episode_return_min": -392.79999999999995, "episode_return_mean": -46.29599999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.3955763825539, "num_env_steps_trained_throughput_per_sec": 315.3955763825539, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 11718.409, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11718.365, "sample_time_ms": 1243.686, "learn_time_ms": 10459.958, "learn_throughput": 382.411, "synch_weights_time_ms": 12.778}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "f0d88_00000", "date": "2024-08-14_10-55-15", "timestamp": 1723647315, "time_this_iter_s": 12.728647947311401, "time_total_s": 532.9887628555298, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4bcaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 532.9887628555298, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 59.9888888888889, "ram_util_percent": 83.43333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8626672359055312, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.228956393590049, "policy_loss": -0.016721691014171237, "vf_loss": 5.226952142816372, "vf_explained_var": 0.0428146863740588, "kl": 0.012329838088767928, "entropy": 1.2387533343658246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0891695751084223, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 8.448016300655546, "policy_loss": -0.009678554837961519, "vf_loss": 8.427303120951173, "vf_explained_var": -0.10375220441313648, "kl": 0.008893783732936653, "entropy": 1.21314102272508, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 232.1, "episode_reward_min": -392.79999999999995, "episode_reward_mean": -18.188000000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -106.83400000000005, "predator_policy": 97.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.300000000000246, -57.99999999999994, 8.100000000000067, 25.40000000000022, -379.8, 36.50000000000015, 15.30000000000002, -21.599999999999746, -4.399999999999979, 40.30000000000004, -36.999999999999766, -44.09999999999967, -349.70000000000005, -18.89999999999973, -59.300000000000814, 121.10000000000008, -325.9, -392.79999999999995, -248.69999999999987, 77.49999999999994, 15.999999999999982, 29.400000000000247, -45.09999999999973, 44.300000000000125, 74.19999999999987, -280.69999999999914, -0.5000000000000311, 12.399999999999988, 35.000000000000206, 29.000000000000128, 60.70000000000042, -379.8, -167.30000000000004, 36.300000000000246, -50.69999999999982, 70.1000000000002, -15.199999999999868, 27.59999999999995, 11.299999999999969, 30.100000000000144, -114.1, -35.099999999999994, -21.09999999999983, -259.0999999999987, -43.69999999999977, 40.400000000000304, -5.4999999999999485, -20.90000000000009, 54.50000000000013, 117.6000000000002, -66.60000000000122, 130.59999999999923, 25.90000000000009, -202.70000000000013, -28.09999999999981, -63.20000000000158, 2.320088565710421e-13, 87.50000000000011, 33.099999999999994, 8.499999999999977, 30.899999999999977, -55.999999999999744, -104.80000000000099, 9.699999999999962, 19.19999999999996, -45.900000000000205, 162.50000000000009, -213.10000000000056, 203.60000000000002, 187.20000000000007, -20.09999999999971, 22.400000000000016, -60.80000000000053, 21.09999999999999, -27.199999999999676, 37.80000000000027, -324.8, 115.49999999999977, 17.499999999999982, -74.30000000000084, 65.6000000000003, -84.20000000000132, 2.1000000000001475, -9.199999999999848, 115.19999999999976, 34.30000000000022, 6.199999999999974, 147.29999999999995, -21.799999999999514, 7.400000000000009, -71.20000000000095, -32.59999999999975, 5.299999999999956, 47.700000000000045, -18.099999999999987, 232.1, -4.899999999999952, 11.900000000000029, 159.29999999999956, 104.99999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, -235.9, -200.79999999999998, -167.19999999999996, 9.499999999999964, -30.39999999999975, -161.8, 3.199999999999972, -374.8, -400.0, 17.899999999999988, -165.39999999999995, 1.0999999999999865, 3.1999999999999615, -372.39999999999986, -5.1999999999999265, -275.8, 31.40000000000022, -42.99999999999976, -33.700000000000024, -355.9, -15.09999999999977, 3.1999999999999615, -298.29999999999893, -369.40000000000003, -352.3, -7.299999999999891, -388.5999999999999, 17.899999999999988, -173.20000000000056, 111.79999999999998, -306.7, -382.9, -286.0, -368.79999999999995, -400.0, -352.0, -183.70000000000059, -101.80000000000058, 71.3, 7.399999999999965, -9.399999999999855, -316.0, 7.399999999999965, -334.6, -11.499999999999819, 11.599999999999964, -94.30000000000001, 11.299999999999997, 17.899999999999988, -371.20000000000005, -281.4999999999991, -83.50000000000038, -172.0, -36.699999999999754, 4.0999999999999766, 20.000000000000014, -310.0, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, -20.49999999999983, -371.8, -259.0, -333.39999999999986, -196.9, 20.000000000000014, 5.299999999999965, 5.299999999999965, -358.0, 11.599999999999964, 51.499999999999964, 30.800000000000033, -388.0, -202.00000000000048, 95.60000000000001, 20.000000000000014, -390.69999999999993, 15.799999999999963, 5.299999999999965, -85.60000000000002, -275.5, -24.400000000000006, -360.70000000000005, 7.399999999999965, -239.5, -384.69999999999993, -252.3999999999999, -356.2, -53.50000000000011, 11.599999999999964, 21.80000000000004, 7.399999999999965, -301.8999999999994, -231.4000000000001, -92.5, -137.5, 20.000000000000018, -193.89999999999998, 69.49999999999999, -45.099999999999845, -74.50000000000054, -18.400000000000034, -0.9999999999999846, -22.89999999999978, 15.799999999999963, -200.20000000000013, -386.5, -0.9999999999999846, -306.1, -97.60000000000079, -55.60000000000012, -15.699999999999761, -28.29999999999975, -0.09999999999999937, 53.600000000000136, 92.5999999999998, -335.50000000000006, -352.0, -11.499999999999819, 21.799999999999983, -247.9, -364.9, 17.899999999999988, -244.00000000000037, -74.80000000000064, -143.80000000000038, -47.499999999999766, -18.09999999999976, 5.299999999999965, -307.0, -19.900000000000205, 116.29999999999998, -173.8, -312.39999999999964, -225.70000000000047, 70.10000000000005, 87.5, -53.8, 91.99999999999999, -156.70000000000036, 11.599999999999964, 15.799999999999963, -51.400000000000034, -84.10000000000082, -252.7, -28.29999999999975, 7.399999999999965, -97.6000000000004, -76.60000000000085, 20.000000000000014, 15.799999999999963, -327.1, -321.70000000000005, 20.000000000000014, 90.49999999999999, 5.299999999999965, -8.799999999999871, -21.39999999999975, -382.9, 7.699999999999967, 14.89999999999982, -102.10000000000079, -186.10000000000053, -21.399999999999764, -74.50000000000084, -248.50000000000003, 5.299999999999965, 24.20000000000008, 32.00000000000001, 5.299999999999965, 20.000000000000014, -78.70000000000076, -153.1, -78.69999999999999, 119.00000000000004, -42.99999999999977, -17.79999999999974, -194.50000000000006, -33.099999999999774, -244.60000000000008, -76.60000000000088, -328.9, -36.699999999999754, -348.7, 20.000000000000014, -198.70000000000024, 115.39999999999998, -170.50000000000026, -82.60000000000025, 161.0, -115.9, -257.19999999999936, 5.299999999999965, -182.49999999999997, -22.599999999999923, 15.799999999999962, 141.5, -80.80000000000064, 123.79999999999998], "policy_predator_policy_reward": [152.0, 105.0, 150.0, 160.0, 24.0, 5.0, 117.0, 67.0, 197.0, 198.0, 82.0, 102.0, 10.0, 1.0, 175.0, 181.0, 123.0, 117.0, 70.0, 47.0, 144.0, 190.0, 127.0, 124.0, 192.0, 180.0, 184.0, 193.0, 20.0, 76.0, 158.0, 158.0, 194.0, 149.0, 177.0, 199.0, 89.0, 198.0, 48.0, 60.0, 15.0, 3.0, 172.0, 166.0, 127.0, 174.0, 62.0, 65.0, 22.0, 23.0, 195.0, 177.0, 125.0, 130.0, 17.0, 28.0, 165.0, 160.0, 10.0, 0.0, 34.0, 44.0, 52.0, 199.0, 178.0, 185.0, 4.0, 7.0, 141.0, 161.0, 4.0, 3.0, 194.0, 148.0, 107.0, 27.0, 196.0, 186.0, 7.0, 2.0, 85.0, 162.0, 174.0, 176.0, 142.0, 69.0, 185.0, 193.0, 183.0, 183.0, 3.0, 4.0, 153.0, 136.0, 139.0, 164.0, 73.0, 99.0, 120.0, 122.0, 9.0, 44.0, 76.0, 74.0, 22.0, 11.0, 188.0, 196.0, 159.0, 120.0, 61.0, 29.0, 27.0, 17.0, 14.0, 20.0, 108.0, 168.0, 195.0, 177.0, 153.0, 104.0, 171.0, 120.0, 120.0, 94.0, 91.0, 110.0, 10.0, 22.0, 109.0, 172.0, 115.0, 105.0, 163.0, 162.0, 28.0, 18.0, 65.0, 84.0, 55.0, 70.0, 26.0, 32.0, 142.0, 134.0, 18.0, 24.0, 69.0, 78.0, 0.0, 2.0, 176.0, 148.0, 5.0, 0.0, 18.0, 3.0, 135.0, 195.0, 8.0, 35.0, 103.0, 101.0, 51.0, 47.0, 108.0, 126.0, 13.0, 46.0, 7.0, 2.0, 98.0, 140.0, 15.0, 92.0, 38.0, 1.0, 121.0, 114.0, 136.0, 114.0, 162.0, 171.0, 164.0, 170.0, 17.0, 114.0, 125.0, 110.0, 99.0, 88.0, 97.0, 150.0, 100.0, 117.0, 1.0, 1.0, 14.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.713526302348325, "mean_inference_ms": 1.880500985002178, "mean_action_processing_ms": 0.31178377897522913, "mean_env_wait_ms": 0.24552921693979962, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005434870719909668, "StateBufferConnector_ms": 0.0038357973098754883, "ViewRequirementAgentConnector_ms": 0.11138856410980225}, "num_episodes": 22, "episode_return_max": 232.1, "episode_return_min": -392.79999999999995, "episode_return_mean": -18.188000000000006, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 328.240489869293, "num_env_steps_trained_throughput_per_sec": 328.240489869293, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 11795.639, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11795.595, "sample_time_ms": 1271.811, "learn_time_ms": 10508.782, "learn_throughput": 380.634, "synch_weights_time_ms": 12.847}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "f0d88_00000", "date": "2024-08-14_10-55-27", "timestamp": 1723647327, "time_this_iter_s": 12.253535985946655, "time_total_s": 545.2422988414764, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac096a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 545.2422988414764, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 50.252941176470586, "ram_util_percent": 83.39999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.131835353248334, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.810757654306119, "policy_loss": -0.013355849201239094, "vf_loss": 4.80496700541683, "vf_explained_var": -0.13167677852842544, "kl": 0.012606735047796434, "entropy": 1.1763542109065586, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.697099285340183, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 9.145293731033487, "policy_loss": -0.011002295243026561, "vf_loss": 9.13066955571452, "vf_explained_var": -0.1421385608022175, "kl": 0.007499293181137572, "entropy": 1.2351303139060894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 232.1, "episode_reward_min": -379.8, "episode_reward_mean": 13.497999999999951, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -390.69999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -74.97100000000005, "predator_policy": 81.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.300000000000125, 74.19999999999987, -280.69999999999914, -0.5000000000000311, 12.399999999999988, 35.000000000000206, 29.000000000000128, 60.70000000000042, -379.8, -167.30000000000004, 36.300000000000246, -50.69999999999982, 70.1000000000002, -15.199999999999868, 27.59999999999995, 11.299999999999969, 30.100000000000144, -114.1, -35.099999999999994, -21.09999999999983, -259.0999999999987, -43.69999999999977, 40.400000000000304, -5.4999999999999485, -20.90000000000009, 54.50000000000013, 117.6000000000002, -66.60000000000122, 130.59999999999923, 25.90000000000009, -202.70000000000013, -28.09999999999981, -63.20000000000158, 2.320088565710421e-13, 87.50000000000011, 33.099999999999994, 8.499999999999977, 30.899999999999977, -55.999999999999744, -104.80000000000099, 9.699999999999962, 19.19999999999996, -45.900000000000205, 162.50000000000009, -213.10000000000056, 203.60000000000002, 187.20000000000007, -20.09999999999971, 22.400000000000016, -60.80000000000053, 21.09999999999999, -27.199999999999676, 37.80000000000027, -324.8, 115.49999999999977, 17.499999999999982, -74.30000000000084, 65.6000000000003, -84.20000000000132, 2.1000000000001475, -9.199999999999848, 115.19999999999976, 34.30000000000022, 6.199999999999974, 147.29999999999995, -21.799999999999514, 7.400000000000009, -71.20000000000095, -32.59999999999975, 5.299999999999956, 47.700000000000045, -18.099999999999987, 232.1, -4.899999999999952, 11.900000000000029, 159.29999999999956, 104.99999999999982, 139.09999999999985, 31.600000000000183, 56.50000000000031, 83.6999999999991, 58.1000000000005, 186.59999999999985, 180.19999999999945, 23.600000000000147, 91.69999999999999, 90.699999999999, 58.400000000000226, 89.09999999999962, 53.40000000000007, 28.40000000000013, 38.90000000000028, 83.2999999999993, 30.200000000000173, -126.90000000000052, 36.20000000000031, 131.39999999999935, 66.40000000000018, 78.50000000000009, 68.09999999999967], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, -94.30000000000001, 11.299999999999997, 17.899999999999988, -371.20000000000005, -281.4999999999991, -83.50000000000038, -172.0, -36.699999999999754, 4.0999999999999766, 20.000000000000014, -310.0, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, -20.49999999999983, -371.8, -259.0, -333.39999999999986, -196.9, 20.000000000000014, 5.299999999999965, 5.299999999999965, -358.0, 11.599999999999964, 51.499999999999964, 30.800000000000033, -388.0, -202.00000000000048, 95.60000000000001, 20.000000000000014, -390.69999999999993, 15.799999999999963, 5.299999999999965, -85.60000000000002, -275.5, -24.400000000000006, -360.70000000000005, 7.399999999999965, -239.5, -384.69999999999993, -252.3999999999999, -356.2, -53.50000000000011, 11.599999999999964, 21.80000000000004, 7.399999999999965, -301.8999999999994, -231.4000000000001, -92.5, -137.5, 20.000000000000018, -193.89999999999998, 69.49999999999999, -45.099999999999845, -74.50000000000054, -18.400000000000034, -0.9999999999999846, -22.89999999999978, 15.799999999999963, -200.20000000000013, -386.5, -0.9999999999999846, -306.1, -97.60000000000079, -55.60000000000012, -15.699999999999761, -28.29999999999975, -0.09999999999999937, 53.600000000000136, 92.5999999999998, -335.50000000000006, -352.0, -11.499999999999819, 21.799999999999983, -247.9, -364.9, 17.899999999999988, -244.00000000000037, -74.80000000000064, -143.80000000000038, -47.499999999999766, -18.09999999999976, 5.299999999999965, -307.0, -19.900000000000205, 116.29999999999998, -173.8, -312.39999999999964, -225.70000000000047, 70.10000000000005, 87.5, -53.8, 91.99999999999999, -156.70000000000036, 11.599999999999964, 15.799999999999963, -51.400000000000034, -84.10000000000082, -252.7, -28.29999999999975, 7.399999999999965, -97.6000000000004, -76.60000000000085, 20.000000000000014, 15.799999999999963, -327.1, -321.70000000000005, 20.000000000000014, 90.49999999999999, 5.299999999999965, -8.799999999999871, -21.39999999999975, -382.9, 7.699999999999967, 14.89999999999982, -102.10000000000079, -186.10000000000053, -21.399999999999764, -74.50000000000084, -248.50000000000003, 5.299999999999965, 24.20000000000008, 32.00000000000001, 5.299999999999965, 20.000000000000014, -78.70000000000076, -153.1, -78.69999999999999, 119.00000000000004, -42.99999999999977, -17.79999999999974, -194.50000000000006, -33.099999999999774, -244.60000000000008, -76.60000000000088, -328.9, -36.699999999999754, -348.7, 20.000000000000014, -198.70000000000024, 115.39999999999998, -170.50000000000026, -82.60000000000025, 161.0, -115.9, -257.19999999999936, 5.299999999999965, -182.49999999999997, -22.599999999999923, 15.799999999999962, 141.5, -80.80000000000064, 123.79999999999998, -66.70000000000007, 102.79999999999998, -30.39999999999977, -79.00000000000055, -3.0999999999999863, 2.599999999999642, 20.000000000000014, -34.299999999999926, 44.300000000000246, 0.7999999999999563, 15.199999999999978, 73.39999999999998, 160.7, 9.499999999999964, 13.699999999999964, -81.10000000000048, 25.400000000000098, -99.70000000000002, -31.599999999999916, -36.699999999999754, -94.9, 5.299999999999965, 15.799999999999963, -9.699999999999982, 36.20000000000008, -179.80000000000018, 20.000000000000014, -28.599999999999753, 20.000000000000014, 17.899999999999988, -17.79999999999974, -28.899999999999963, -103.00000000000057, -5.799999999999981, -330.7, -20.199999999999868, -65.8000000000005, 20.000000000000014, 20.299999999999898, -46.89999999999987, -158.50000000000065, 131.9, -38.799999999999756, 89.29999999999997, -97.30000000000072, 25.400000000000027], "policy_predator_policy_reward": [62.0, 65.0, 22.0, 23.0, 195.0, 177.0, 125.0, 130.0, 17.0, 28.0, 165.0, 160.0, 10.0, 0.0, 34.0, 44.0, 52.0, 199.0, 178.0, 185.0, 4.0, 7.0, 141.0, 161.0, 4.0, 3.0, 194.0, 148.0, 107.0, 27.0, 196.0, 186.0, 7.0, 2.0, 85.0, 162.0, 174.0, 176.0, 142.0, 69.0, 185.0, 193.0, 183.0, 183.0, 3.0, 4.0, 153.0, 136.0, 139.0, 164.0, 73.0, 99.0, 120.0, 122.0, 9.0, 44.0, 76.0, 74.0, 22.0, 11.0, 188.0, 196.0, 159.0, 120.0, 61.0, 29.0, 27.0, 17.0, 14.0, 20.0, 108.0, 168.0, 195.0, 177.0, 153.0, 104.0, 171.0, 120.0, 120.0, 94.0, 91.0, 110.0, 10.0, 22.0, 109.0, 172.0, 115.0, 105.0, 163.0, 162.0, 28.0, 18.0, 65.0, 84.0, 55.0, 70.0, 26.0, 32.0, 142.0, 134.0, 18.0, 24.0, 69.0, 78.0, 0.0, 2.0, 176.0, 148.0, 5.0, 0.0, 18.0, 3.0, 135.0, 195.0, 8.0, 35.0, 103.0, 101.0, 51.0, 47.0, 108.0, 126.0, 13.0, 46.0, 7.0, 2.0, 98.0, 140.0, 15.0, 92.0, 38.0, 1.0, 121.0, 114.0, 136.0, 114.0, 162.0, 171.0, 164.0, 170.0, 17.0, 114.0, 125.0, 110.0, 99.0, 88.0, 97.0, 150.0, 100.0, 117.0, 1.0, 1.0, 14.0, 48.0, 54.0, 49.0, 83.0, 58.0, 11.0, 46.0, 59.0, 39.0, 2.0, 11.0, 46.0, 52.0, 5.0, 5.0, 37.0, 54.0, 82.0, 84.0, 81.0, 78.0, 95.0, 53.0, 41.0, 42.0, 95.0, 102.0, 20.0, 17.0, 1.0, 0.0, 71.0, 59.0, 66.0, 73.0, 182.0, 42.0, 43.0, 39.0, 78.0, 80.0, 17.0, 76.0, 28.0, 0.0, 36.0, 104.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7110236510584759, "mean_inference_ms": 1.8741906115775637, "mean_action_processing_ms": 0.3102313404961619, "mean_env_wait_ms": 0.24470420444059598, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004461050033569336, "StateBufferConnector_ms": 0.0037652254104614258, "ViewRequirementAgentConnector_ms": 0.10578453540802002}, "num_episodes": 23, "episode_return_max": 232.1, "episode_return_min": -379.8, "episode_return_mean": 13.497999999999951, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.32823079980835, "num_env_steps_trained_throughput_per_sec": 348.32823079980835, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 11779.605, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11779.561, "sample_time_ms": 1267.358, "learn_time_ms": 10494.995, "learn_throughput": 381.134, "synch_weights_time_ms": 14.817}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "f0d88_00000", "date": "2024-08-14_10-55-39", "timestamp": 1723647339, "time_this_iter_s": 11.5437650680542, "time_total_s": 556.7860639095306, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5165e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 556.7860639095306, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 47.51764705882353, "ram_util_percent": 82.78823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9041741048848186, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.6470215247421667, "policy_loss": -0.021680298036398, "vf_loss": 3.652768942666432, "vf_explained_var": 0.12791377656043523, "kl": 0.010490782873773703, "entropy": 1.1931019274646013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5787438538339402, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 9.227558666814572, "policy_loss": -0.010379462736712955, "vf_loss": 9.209336585090274, "vf_explained_var": -0.15106550855611367, "kl": 0.008369901875434268, "entropy": 1.227697617856283, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 232.1, "episode_reward_min": -324.8, "episode_reward_mean": 26.66099999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.0, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -58.88450000000005, "predator_policy": 72.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.099999999999994, -21.09999999999983, -259.0999999999987, -43.69999999999977, 40.400000000000304, -5.4999999999999485, -20.90000000000009, 54.50000000000013, 117.6000000000002, -66.60000000000122, 130.59999999999923, 25.90000000000009, -202.70000000000013, -28.09999999999981, -63.20000000000158, 2.320088565710421e-13, 87.50000000000011, 33.099999999999994, 8.499999999999977, 30.899999999999977, -55.999999999999744, -104.80000000000099, 9.699999999999962, 19.19999999999996, -45.900000000000205, 162.50000000000009, -213.10000000000056, 203.60000000000002, 187.20000000000007, -20.09999999999971, 22.400000000000016, -60.80000000000053, 21.09999999999999, -27.199999999999676, 37.80000000000027, -324.8, 115.49999999999977, 17.499999999999982, -74.30000000000084, 65.6000000000003, -84.20000000000132, 2.1000000000001475, -9.199999999999848, 115.19999999999976, 34.30000000000022, 6.199999999999974, 147.29999999999995, -21.799999999999514, 7.400000000000009, -71.20000000000095, -32.59999999999975, 5.299999999999956, 47.700000000000045, -18.099999999999987, 232.1, -4.899999999999952, 11.900000000000029, 159.29999999999956, 104.99999999999982, 139.09999999999985, 31.600000000000183, 56.50000000000031, 83.6999999999991, 58.1000000000005, 186.59999999999985, 180.19999999999945, 23.600000000000147, 91.69999999999999, 90.699999999999, 58.400000000000226, 89.09999999999962, 53.40000000000007, 28.40000000000013, 38.90000000000028, 83.2999999999993, 30.200000000000173, -126.90000000000052, 36.20000000000031, 131.39999999999935, 66.40000000000018, 78.50000000000009, 68.09999999999967, 93.90000000000006, 9.300000000000038, -111.50000000000036, 34.500000000000206, 28.400000000000137, 104.69999999999993, 54.60000000000023, 159.79999999999956, 24.500000000000046, 94.00000000000009, -18.599999999999525, 2.9999999999999365, 13.600000000000005, -6.799999999999729, 109.19999999999979, 76.29999999999967, 33.40000000000022, 36.70000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.400000000000006, -360.70000000000005, 7.399999999999965, -239.5, -384.69999999999993, -252.3999999999999, -356.2, -53.50000000000011, 11.599999999999964, 21.80000000000004, 7.399999999999965, -301.8999999999994, -231.4000000000001, -92.5, -137.5, 20.000000000000018, -193.89999999999998, 69.49999999999999, -45.099999999999845, -74.50000000000054, -18.400000000000034, -0.9999999999999846, -22.89999999999978, 15.799999999999963, -200.20000000000013, -386.5, -0.9999999999999846, -306.1, -97.60000000000079, -55.60000000000012, -15.699999999999761, -28.29999999999975, -0.09999999999999937, 53.600000000000136, 92.5999999999998, -335.50000000000006, -352.0, -11.499999999999819, 21.799999999999983, -247.9, -364.9, 17.899999999999988, -244.00000000000037, -74.80000000000064, -143.80000000000038, -47.499999999999766, -18.09999999999976, 5.299999999999965, -307.0, -19.900000000000205, 116.29999999999998, -173.8, -312.39999999999964, -225.70000000000047, 70.10000000000005, 87.5, -53.8, 91.99999999999999, -156.70000000000036, 11.599999999999964, 15.799999999999963, -51.400000000000034, -84.10000000000082, -252.7, -28.29999999999975, 7.399999999999965, -97.6000000000004, -76.60000000000085, 20.000000000000014, 15.799999999999963, -327.1, -321.70000000000005, 20.000000000000014, 90.49999999999999, 5.299999999999965, -8.799999999999871, -21.39999999999975, -382.9, 7.699999999999967, 14.89999999999982, -102.10000000000079, -186.10000000000053, -21.399999999999764, -74.50000000000084, -248.50000000000003, 5.299999999999965, 24.20000000000008, 32.00000000000001, 5.299999999999965, 20.000000000000014, -78.70000000000076, -153.1, -78.69999999999999, 119.00000000000004, -42.99999999999977, -17.79999999999974, -194.50000000000006, -33.099999999999774, -244.60000000000008, -76.60000000000088, -328.9, -36.699999999999754, -348.7, 20.000000000000014, -198.70000000000024, 115.39999999999998, -170.50000000000026, -82.60000000000025, 161.0, -115.9, -257.19999999999936, 5.299999999999965, -182.49999999999997, -22.599999999999923, 15.799999999999962, 141.5, -80.80000000000064, 123.79999999999998, -66.70000000000007, 102.79999999999998, -30.39999999999977, -79.00000000000055, -3.0999999999999863, 2.599999999999642, 20.000000000000014, -34.299999999999926, 44.300000000000246, 0.7999999999999563, 15.199999999999978, 73.39999999999998, 160.7, 9.499999999999964, 13.699999999999964, -81.10000000000048, 25.400000000000098, -99.70000000000002, -31.599999999999916, -36.699999999999754, -94.9, 5.299999999999965, 15.799999999999963, -9.699999999999982, 36.20000000000008, -179.80000000000018, 20.000000000000014, -28.599999999999753, 20.000000000000014, 17.899999999999988, -17.79999999999974, -28.899999999999963, -103.00000000000057, -5.799999999999981, -330.7, -20.199999999999868, -65.8000000000005, 20.000000000000014, 20.299999999999898, -46.89999999999987, -158.50000000000065, 131.9, -38.799999999999756, 89.29999999999997, -97.30000000000072, 25.400000000000027, 38.599999999999966, 20.300000000000022, -64.00000000000091, 32.30000000000025, -18.999999999999968, -361.4999999999992, 20.000000000000014, -26.49999999999975, 20.000000000000014, -37.59999999999978, 65.0, -28.29999999999975, 66.80000000000014, -176.20000000000056, 135.79999999999998, 20.000000000000014, -5.1999999999999265, 13.699999999999964, 94.4000000000001, -45.399999999999764, -34.599999999999774, -21.999999999999744, -171.40000000000046, -13.599999999999783, -26.79999999999977, 7.399999999999965, -83.20000000000067, 7.399999999999965, 105.49999999999997, -28.29999999999975, -52.0, -168.70000000000059, 9.499999999999964, 17.899999999999977, 20.000000000000014, 4.699999999999973], "policy_predator_policy_reward": [174.0, 176.0, 142.0, 69.0, 185.0, 193.0, 183.0, 183.0, 3.0, 4.0, 153.0, 136.0, 139.0, 164.0, 73.0, 99.0, 120.0, 122.0, 9.0, 44.0, 76.0, 74.0, 22.0, 11.0, 188.0, 196.0, 159.0, 120.0, 61.0, 29.0, 27.0, 17.0, 14.0, 20.0, 108.0, 168.0, 195.0, 177.0, 153.0, 104.0, 171.0, 120.0, 120.0, 94.0, 91.0, 110.0, 10.0, 22.0, 109.0, 172.0, 115.0, 105.0, 163.0, 162.0, 28.0, 18.0, 65.0, 84.0, 55.0, 70.0, 26.0, 32.0, 142.0, 134.0, 18.0, 24.0, 69.0, 78.0, 0.0, 2.0, 176.0, 148.0, 5.0, 0.0, 18.0, 3.0, 135.0, 195.0, 8.0, 35.0, 103.0, 101.0, 51.0, 47.0, 108.0, 126.0, 13.0, 46.0, 7.0, 2.0, 98.0, 140.0, 15.0, 92.0, 38.0, 1.0, 121.0, 114.0, 136.0, 114.0, 162.0, 171.0, 164.0, 170.0, 17.0, 114.0, 125.0, 110.0, 99.0, 88.0, 97.0, 150.0, 100.0, 117.0, 1.0, 1.0, 14.0, 48.0, 54.0, 49.0, 83.0, 58.0, 11.0, 46.0, 59.0, 39.0, 2.0, 11.0, 46.0, 52.0, 5.0, 5.0, 37.0, 54.0, 82.0, 84.0, 81.0, 78.0, 95.0, 53.0, 41.0, 42.0, 95.0, 102.0, 20.0, 17.0, 1.0, 0.0, 71.0, 59.0, 66.0, 73.0, 182.0, 42.0, 43.0, 39.0, 78.0, 80.0, 17.0, 76.0, 28.0, 0.0, 36.0, 104.0, 20.0, 15.0, 40.0, 1.0, 41.0, 228.0, 20.0, 21.0, 24.0, 22.0, 45.0, 23.0, 68.0, 96.0, 0.0, 4.0, 5.0, 11.0, 13.0, 32.0, 38.0, 0.0, 83.0, 105.0, 27.0, 6.0, 46.0, 23.0, 23.0, 9.0, 153.0, 144.0, 6.0, 0.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7096983508642851, "mean_inference_ms": 1.8709770058532098, "mean_action_processing_ms": 0.30931210461778513, "mean_env_wait_ms": 0.24428973442271137, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006156563758850098, "StateBufferConnector_ms": 0.0038796663284301758, "ViewRequirementAgentConnector_ms": 0.11127638816833496}, "num_episodes": 18, "episode_return_max": 232.1, "episode_return_min": -324.8, "episode_return_mean": 26.66099999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.0359002227438, "num_env_steps_trained_throughput_per_sec": 347.0359002227438, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 11789.692, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11789.647, "sample_time_ms": 1303.444, "learn_time_ms": 10468.63, "learn_throughput": 382.094, "synch_weights_time_ms": 15.213}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "f0d88_00000", "date": "2024-08-14_10-55-50", "timestamp": 1723647350, "time_this_iter_s": 11.578124046325684, "time_total_s": 568.3641879558563, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0c85e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 568.3641879558563, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 44.95, "ram_util_percent": 82.9375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0808674326964787, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.709258492913826, "policy_loss": -0.018654783610402355, "vf_loss": 4.7099265407632895, "vf_explained_var": 0.3925071524249183, "kl": 0.011843115598861458, "entropy": 1.1384442109279531, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2789343713137207, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 9.299699286304454, "policy_loss": -0.014370067412078026, "vf_loss": 9.290101734544866, "vf_explained_var": -0.1342520621718553, "kl": 0.007013839708571433, "entropy": 1.2105139797957485, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 278.4000000000001, "episode_reward_min": -324.8, "episode_reward_mean": 47.55299999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -382.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.0, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -35.308500000000066, "predator_policy": 59.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.499999999999977, 30.899999999999977, -55.999999999999744, -104.80000000000099, 9.699999999999962, 19.19999999999996, -45.900000000000205, 162.50000000000009, -213.10000000000056, 203.60000000000002, 187.20000000000007, -20.09999999999971, 22.400000000000016, -60.80000000000053, 21.09999999999999, -27.199999999999676, 37.80000000000027, -324.8, 115.49999999999977, 17.499999999999982, -74.30000000000084, 65.6000000000003, -84.20000000000132, 2.1000000000001475, -9.199999999999848, 115.19999999999976, 34.30000000000022, 6.199999999999974, 147.29999999999995, -21.799999999999514, 7.400000000000009, -71.20000000000095, -32.59999999999975, 5.299999999999956, 47.700000000000045, -18.099999999999987, 232.1, -4.899999999999952, 11.900000000000029, 159.29999999999956, 104.99999999999982, 139.09999999999985, 31.600000000000183, 56.50000000000031, 83.6999999999991, 58.1000000000005, 186.59999999999985, 180.19999999999945, 23.600000000000147, 91.69999999999999, 90.699999999999, 58.400000000000226, 89.09999999999962, 53.40000000000007, 28.40000000000013, 38.90000000000028, 83.2999999999993, 30.200000000000173, -126.90000000000052, 36.20000000000031, 131.39999999999935, 66.40000000000018, 78.50000000000009, 68.09999999999967, 93.90000000000006, 9.300000000000038, -111.50000000000036, 34.500000000000206, 28.400000000000137, 104.69999999999993, 54.60000000000023, 159.79999999999956, 24.500000000000046, 94.00000000000009, -18.599999999999525, 2.9999999999999365, 13.600000000000005, -6.799999999999729, 109.19999999999979, 76.29999999999967, 33.40000000000022, 36.70000000000025, 174.09999999999945, 31.60000000000016, 138.99999999999963, 177.59999999999945, 76.00000000000009, 177.8999999999995, 48.9000000000004, 35.90000000000006, 278.4000000000001, 36.40000000000025, 238.8000000000001, 4.800000000000066, 66.20000000000005, 89.30000000000008, 143.19999999999965, 50.20000000000031, 34.50000000000022, 30.000000000000135], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-352.0, -11.499999999999819, 21.799999999999983, -247.9, -364.9, 17.899999999999988, -244.00000000000037, -74.80000000000064, -143.80000000000038, -47.499999999999766, -18.09999999999976, 5.299999999999965, -307.0, -19.900000000000205, 116.29999999999998, -173.8, -312.39999999999964, -225.70000000000047, 70.10000000000005, 87.5, -53.8, 91.99999999999999, -156.70000000000036, 11.599999999999964, 15.799999999999963, -51.400000000000034, -84.10000000000082, -252.7, -28.29999999999975, 7.399999999999965, -97.6000000000004, -76.60000000000085, 20.000000000000014, 15.799999999999963, -327.1, -321.70000000000005, 20.000000000000014, 90.49999999999999, 5.299999999999965, -8.799999999999871, -21.39999999999975, -382.9, 7.699999999999967, 14.89999999999982, -102.10000000000079, -186.10000000000053, -21.399999999999764, -74.50000000000084, -248.50000000000003, 5.299999999999965, 24.20000000000008, 32.00000000000001, 5.299999999999965, 20.000000000000014, -78.70000000000076, -153.1, -78.69999999999999, 119.00000000000004, -42.99999999999977, -17.79999999999974, -194.50000000000006, -33.099999999999774, -244.60000000000008, -76.60000000000088, -328.9, -36.699999999999754, -348.7, 20.000000000000014, -198.70000000000024, 115.39999999999998, -170.50000000000026, -82.60000000000025, 161.0, -115.9, -257.19999999999936, 5.299999999999965, -182.49999999999997, -22.599999999999923, 15.799999999999962, 141.5, -80.80000000000064, 123.79999999999998, -66.70000000000007, 102.79999999999998, -30.39999999999977, -79.00000000000055, -3.0999999999999863, 2.599999999999642, 20.000000000000014, -34.299999999999926, 44.300000000000246, 0.7999999999999563, 15.199999999999978, 73.39999999999998, 160.7, 9.499999999999964, 13.699999999999964, -81.10000000000048, 25.400000000000098, -99.70000000000002, -31.599999999999916, -36.699999999999754, -94.9, 5.299999999999965, 15.799999999999963, -9.699999999999982, 36.20000000000008, -179.80000000000018, 20.000000000000014, -28.599999999999753, 20.000000000000014, 17.899999999999988, -17.79999999999974, -28.899999999999963, -103.00000000000057, -5.799999999999981, -330.7, -20.199999999999868, -65.8000000000005, 20.000000000000014, 20.299999999999898, -46.89999999999987, -158.50000000000065, 131.9, -38.799999999999756, 89.29999999999997, -97.30000000000072, 25.400000000000027, 38.599999999999966, 20.300000000000022, -64.00000000000091, 32.30000000000025, -18.999999999999968, -361.4999999999992, 20.000000000000014, -26.49999999999975, 20.000000000000014, -37.59999999999978, 65.0, -28.29999999999975, 66.80000000000014, -176.20000000000056, 135.79999999999998, 20.000000000000014, -5.1999999999999265, 13.699999999999964, 94.4000000000001, -45.399999999999764, -34.599999999999774, -21.999999999999744, -171.40000000000046, -13.599999999999783, -26.79999999999977, 7.399999999999965, -83.20000000000067, 7.399999999999965, 105.49999999999997, -28.29999999999975, -52.0, -168.70000000000059, 9.499999999999964, 17.899999999999977, 20.000000000000014, 4.699999999999973, -36.699999999999754, 174.8, -62.80000000000072, 7.399999999999974, 153.20000000000002, -68.20000000000039, 188.0, -51.40000000000005, 60.49999999999996, 9.499999999999964, 120.80000000000001, 37.10000000000022, 20.000000000000014, -66.10000000000062, 128.3, -248.40000000000043, 122.30000000000005, 133.10000000000002, 20.000000000000014, 7.399999999999965, 146.89999999999998, 50.899999999999835, 20.000000000000014, -167.20000000000056, -65.80000000000044, 17.0, 93.19999999999999, -40.89999999999976, 183.8, -97.60000000000079, -72.70000000000087, 35.90000000000014, 11.599999999999964, 17.899999999999988, 11.599999999999971, 4.399999999999999], "policy_predator_policy_reward": [195.0, 177.0, 153.0, 104.0, 171.0, 120.0, 120.0, 94.0, 91.0, 110.0, 10.0, 22.0, 109.0, 172.0, 115.0, 105.0, 163.0, 162.0, 28.0, 18.0, 65.0, 84.0, 55.0, 70.0, 26.0, 32.0, 142.0, 134.0, 18.0, 24.0, 69.0, 78.0, 0.0, 2.0, 176.0, 148.0, 5.0, 0.0, 18.0, 3.0, 135.0, 195.0, 8.0, 35.0, 103.0, 101.0, 51.0, 47.0, 108.0, 126.0, 13.0, 46.0, 7.0, 2.0, 98.0, 140.0, 15.0, 92.0, 38.0, 1.0, 121.0, 114.0, 136.0, 114.0, 162.0, 171.0, 164.0, 170.0, 17.0, 114.0, 125.0, 110.0, 99.0, 88.0, 97.0, 150.0, 100.0, 117.0, 1.0, 1.0, 14.0, 48.0, 54.0, 49.0, 83.0, 58.0, 11.0, 46.0, 59.0, 39.0, 2.0, 11.0, 46.0, 52.0, 5.0, 5.0, 37.0, 54.0, 82.0, 84.0, 81.0, 78.0, 95.0, 53.0, 41.0, 42.0, 95.0, 102.0, 20.0, 17.0, 1.0, 0.0, 71.0, 59.0, 66.0, 73.0, 182.0, 42.0, 43.0, 39.0, 78.0, 80.0, 17.0, 76.0, 28.0, 0.0, 36.0, 104.0, 20.0, 15.0, 40.0, 1.0, 41.0, 228.0, 20.0, 21.0, 24.0, 22.0, 45.0, 23.0, 68.0, 96.0, 0.0, 4.0, 5.0, 11.0, 13.0, 32.0, 38.0, 0.0, 83.0, 105.0, 27.0, 6.0, 46.0, 23.0, 23.0, 9.0, 153.0, 144.0, 6.0, 0.0, 0.0, 12.0, 30.0, 6.0, 43.0, 44.0, 44.0, 10.0, 34.0, 7.0, 1.0, 5.0, 9.0, 11.0, 52.0, 43.0, 133.0, 23.0, 19.0, 4.0, 6.0, 3.0, 41.0, 0.0, 92.0, 60.0, 81.0, 34.0, 8.0, 29.0, 1.0, 56.0, 40.0, 47.0, 4.0, 1.0, 11.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7092515337688156, "mean_inference_ms": 1.869513384123952, "mean_action_processing_ms": 0.30884053672821365, "mean_env_wait_ms": 0.24407927754247305, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006803750991821289, "StateBufferConnector_ms": 0.00397944450378418, "ViewRequirementAgentConnector_ms": 0.14071202278137207}, "num_episodes": 18, "episode_return_max": 278.4000000000001, "episode_return_min": -324.8, "episode_return_mean": 47.55299999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.74251747534515, "num_env_steps_trained_throughput_per_sec": 340.74251747534515, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 11813.871, "restore_workers_time_ms": 0.024, "training_step_time_ms": 11813.812, "sample_time_ms": 1344.147, "learn_time_ms": 10451.692, "learn_throughput": 382.713, "synch_weights_time_ms": 15.637}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "f0d88_00000", "date": "2024-08-14_10-56-02", "timestamp": 1723647362, "time_this_iter_s": 11.812076091766357, "time_total_s": 580.1762640476227, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5428b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 580.1762640476227, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 45.870588235294115, "ram_util_percent": 82.57058823529414}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.393594599716247, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.1105832974116, "policy_loss": -0.02304315369196788, "vf_loss": 4.116738946854122, "vf_explained_var": 0.36362220329582373, "kl": 0.011119348997114331, "entropy": 1.2002601851861943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6679460126256185, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 9.074586907391826, "policy_loss": -0.00904700076737239, "vf_loss": 9.054288352481903, "vf_explained_var": -0.15140133424410745, "kl": 0.008587631832195484, "entropy": 1.2247924565638184, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 298.5, "episode_reward_min": -175.60000000000048, "episode_reward_mean": 66.18299999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.4999999999992, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.2, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -13.543500000000067, "predator_policy": 46.635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-84.20000000000132, 2.1000000000001475, -9.199999999999848, 115.19999999999976, 34.30000000000022, 6.199999999999974, 147.29999999999995, -21.799999999999514, 7.400000000000009, -71.20000000000095, -32.59999999999975, 5.299999999999956, 47.700000000000045, -18.099999999999987, 232.1, -4.899999999999952, 11.900000000000029, 159.29999999999956, 104.99999999999982, 139.09999999999985, 31.600000000000183, 56.50000000000031, 83.6999999999991, 58.1000000000005, 186.59999999999985, 180.19999999999945, 23.600000000000147, 91.69999999999999, 90.699999999999, 58.400000000000226, 89.09999999999962, 53.40000000000007, 28.40000000000013, 38.90000000000028, 83.2999999999993, 30.200000000000173, -126.90000000000052, 36.20000000000031, 131.39999999999935, 66.40000000000018, 78.50000000000009, 68.09999999999967, 93.90000000000006, 9.300000000000038, -111.50000000000036, 34.500000000000206, 28.400000000000137, 104.69999999999993, 54.60000000000023, 159.79999999999956, 24.500000000000046, 94.00000000000009, -18.599999999999525, 2.9999999999999365, 13.600000000000005, -6.799999999999729, 109.19999999999979, 76.29999999999967, 33.40000000000022, 36.70000000000025, 174.09999999999945, 31.60000000000016, 138.99999999999963, 177.59999999999945, 76.00000000000009, 177.8999999999995, 48.9000000000004, 35.90000000000006, 278.4000000000001, 36.40000000000025, 238.8000000000001, 4.800000000000066, 66.20000000000005, 89.30000000000008, 143.19999999999965, 50.20000000000031, 34.50000000000022, 30.000000000000135, 157.99999999999991, 62.70000000000042, -102.80000000000157, 246.60000000000008, 7.000000000000087, 17.99999999999996, 23.900000000000052, 141.5999999999997, 35.500000000000234, 152.1999999999996, 109.29999999999984, 117.19999999999979, 96.09999999999913, 155.19999999999956, 115.79999999999887, 45.500000000000405, 24.200000000000042, 66.50000000000026, 298.5, -175.60000000000048, 52.6000000000005, 189.49999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-102.10000000000079, -186.10000000000053, -21.399999999999764, -74.50000000000084, -248.50000000000003, 5.299999999999965, 24.20000000000008, 32.00000000000001, 5.299999999999965, 20.000000000000014, -78.70000000000076, -153.1, -78.69999999999999, 119.00000000000004, -42.99999999999977, -17.79999999999974, -194.50000000000006, -33.099999999999774, -244.60000000000008, -76.60000000000088, -328.9, -36.699999999999754, -348.7, 20.000000000000014, -198.70000000000024, 115.39999999999998, -170.50000000000026, -82.60000000000025, 161.0, -115.9, -257.19999999999936, 5.299999999999965, -182.49999999999997, -22.599999999999923, 15.799999999999962, 141.5, -80.80000000000064, 123.79999999999998, -66.70000000000007, 102.79999999999998, -30.39999999999977, -79.00000000000055, -3.0999999999999863, 2.599999999999642, 20.000000000000014, -34.299999999999926, 44.300000000000246, 0.7999999999999563, 15.199999999999978, 73.39999999999998, 160.7, 9.499999999999964, 13.699999999999964, -81.10000000000048, 25.400000000000098, -99.70000000000002, -31.599999999999916, -36.699999999999754, -94.9, 5.299999999999965, 15.799999999999963, -9.699999999999982, 36.20000000000008, -179.80000000000018, 20.000000000000014, -28.599999999999753, 20.000000000000014, 17.899999999999988, -17.79999999999974, -28.899999999999963, -103.00000000000057, -5.799999999999981, -330.7, -20.199999999999868, -65.8000000000005, 20.000000000000014, 20.299999999999898, -46.89999999999987, -158.50000000000065, 131.9, -38.799999999999756, 89.29999999999997, -97.30000000000072, 25.400000000000027, 38.599999999999966, 20.300000000000022, -64.00000000000091, 32.30000000000025, -18.999999999999968, -361.4999999999992, 20.000000000000014, -26.49999999999975, 20.000000000000014, -37.59999999999978, 65.0, -28.29999999999975, 66.80000000000014, -176.20000000000056, 135.79999999999998, 20.000000000000014, -5.1999999999999265, 13.699999999999964, 94.4000000000001, -45.399999999999764, -34.599999999999774, -21.999999999999744, -171.40000000000046, -13.599999999999783, -26.79999999999977, 7.399999999999965, -83.20000000000067, 7.399999999999965, 105.49999999999997, -28.29999999999975, -52.0, -168.70000000000059, 9.499999999999964, 17.899999999999977, 20.000000000000014, 4.699999999999973, -36.699999999999754, 174.8, -62.80000000000072, 7.399999999999974, 153.20000000000002, -68.20000000000039, 188.0, -51.40000000000005, 60.49999999999996, 9.499999999999964, 120.80000000000001, 37.10000000000022, 20.000000000000014, -66.10000000000062, 128.3, -248.40000000000043, 122.30000000000005, 133.10000000000002, 20.000000000000014, 7.399999999999965, 146.89999999999998, 50.899999999999835, 20.000000000000014, -167.20000000000056, -65.80000000000044, 17.0, 93.19999999999999, -40.89999999999976, 183.8, -97.60000000000079, -72.70000000000087, 35.90000000000014, 11.599999999999964, 17.899999999999988, 11.599999999999971, 4.399999999999999, 189.2, -344.1999999999999, 34.40000000000026, -36.69999999999984, -113.60000000000082, -126.20000000000078, 89.30000000000011, 125.30000000000001, -64.30000000000055, 5.299999999999965, 7.399999999999965, -24.39999999999975, 14.299999999999967, -30.39999999999975, 102.20000000000003, 7.399999999999965, -2.499999999999986, 20.000000000000014, 11.599999999999964, 134.6, -108.70000000000076, 122.0, -66.7000000000007, 71.9, 15.799999999999963, 8.299999999999992, -6.4000000000000625, 143.59999999999997, 91.39999999999952, 7.399999999999965, 21.500000000000032, 20.000000000000014, 0.7999999999999865, 7.399999999999965, -0.9999999999999846, 48.5000000000002, 157.4, 133.09999999999997, -141.70000000000036, -176.90000000000015, 15.499999999999963, 25.100000000000094, 172.09999999999997, 7.399999999999965], "policy_predator_policy_reward": [103.0, 101.0, 51.0, 47.0, 108.0, 126.0, 13.0, 46.0, 7.0, 2.0, 98.0, 140.0, 15.0, 92.0, 38.0, 1.0, 121.0, 114.0, 136.0, 114.0, 162.0, 171.0, 164.0, 170.0, 17.0, 114.0, 125.0, 110.0, 99.0, 88.0, 97.0, 150.0, 100.0, 117.0, 1.0, 1.0, 14.0, 48.0, 54.0, 49.0, 83.0, 58.0, 11.0, 46.0, 59.0, 39.0, 2.0, 11.0, 46.0, 52.0, 5.0, 5.0, 37.0, 54.0, 82.0, 84.0, 81.0, 78.0, 95.0, 53.0, 41.0, 42.0, 95.0, 102.0, 20.0, 17.0, 1.0, 0.0, 71.0, 59.0, 66.0, 73.0, 182.0, 42.0, 43.0, 39.0, 78.0, 80.0, 17.0, 76.0, 28.0, 0.0, 36.0, 104.0, 20.0, 15.0, 40.0, 1.0, 41.0, 228.0, 20.0, 21.0, 24.0, 22.0, 45.0, 23.0, 68.0, 96.0, 0.0, 4.0, 5.0, 11.0, 13.0, 32.0, 38.0, 0.0, 83.0, 105.0, 27.0, 6.0, 46.0, 23.0, 23.0, 9.0, 153.0, 144.0, 6.0, 0.0, 0.0, 12.0, 30.0, 6.0, 43.0, 44.0, 44.0, 10.0, 34.0, 7.0, 1.0, 5.0, 9.0, 11.0, 52.0, 43.0, 133.0, 23.0, 19.0, 4.0, 6.0, 3.0, 41.0, 0.0, 92.0, 60.0, 81.0, 34.0, 8.0, 29.0, 1.0, 56.0, 40.0, 47.0, 4.0, 1.0, 11.0, 3.0, 156.0, 157.0, 41.0, 24.0, 80.0, 57.0, 15.0, 17.0, 7.0, 59.0, 22.0, 13.0, 18.0, 22.0, 24.0, 8.0, 3.0, 15.0, 2.0, 4.0, 37.0, 59.0, 57.0, 55.0, 31.0, 41.0, 10.0, 8.0, 9.0, 8.0, 0.0, 4.0, 10.0, 6.0, 14.0, 5.0, 1.0, 7.0, 5.0, 138.0, 3.0, 9.0, 5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7093794966651887, "mean_inference_ms": 1.8693208558796106, "mean_action_processing_ms": 0.3070880772263332, "mean_env_wait_ms": 0.24366038021767467, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007495760917663574, "StateBufferConnector_ms": 0.003474712371826172, "ViewRequirementAgentConnector_ms": 0.1342473030090332}, "num_episodes": 22, "episode_return_max": 298.5, "episode_return_min": -175.60000000000048, "episode_return_mean": 66.18299999999991, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.2962988631549, "num_env_steps_trained_throughput_per_sec": 347.2962988631549, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 11813.847, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11813.787, "sample_time_ms": 1373.186, "learn_time_ms": 10417.133, "learn_throughput": 383.983, "synch_weights_time_ms": 19.318}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "f0d88_00000", "date": "2024-08-14_10-56-14", "timestamp": 1723647374, "time_this_iter_s": 11.527529954910278, "time_total_s": 591.703794002533, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad516670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 591.703794002533, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 42.8875, "ram_util_percent": 82.65625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0503823827498806, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.583479947640152, "policy_loss": -0.009330061770403984, "vf_loss": 4.579115221740077, "vf_explained_var": 0.6081338589468961, "kl": 0.009017144306540804, "entropy": 1.0454198124862852, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.749164329508625, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 8.77753031670101, "policy_loss": -0.008564047696482804, "vf_loss": 8.75961037792226, "vf_explained_var": -0.22553017968853944, "kl": 0.007750227640434338, "entropy": 1.2528088092173217, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 298.5, "episode_reward_min": -175.60000000000048, "episode_reward_mean": 85.6379999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.4999999999992, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.2, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": 10.253999999999955, "predator_policy": 32.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.1000000000005, 186.59999999999985, 180.19999999999945, 23.600000000000147, 91.69999999999999, 90.699999999999, 58.400000000000226, 89.09999999999962, 53.40000000000007, 28.40000000000013, 38.90000000000028, 83.2999999999993, 30.200000000000173, -126.90000000000052, 36.20000000000031, 131.39999999999935, 66.40000000000018, 78.50000000000009, 68.09999999999967, 93.90000000000006, 9.300000000000038, -111.50000000000036, 34.500000000000206, 28.400000000000137, 104.69999999999993, 54.60000000000023, 159.79999999999956, 24.500000000000046, 94.00000000000009, -18.599999999999525, 2.9999999999999365, 13.600000000000005, -6.799999999999729, 109.19999999999979, 76.29999999999967, 33.40000000000022, 36.70000000000025, 174.09999999999945, 31.60000000000016, 138.99999999999963, 177.59999999999945, 76.00000000000009, 177.8999999999995, 48.9000000000004, 35.90000000000006, 278.4000000000001, 36.40000000000025, 238.8000000000001, 4.800000000000066, 66.20000000000005, 89.30000000000008, 143.19999999999965, 50.20000000000031, 34.50000000000022, 30.000000000000135, 157.99999999999991, 62.70000000000042, -102.80000000000157, 246.60000000000008, 7.000000000000087, 17.99999999999996, 23.900000000000052, 141.5999999999997, 35.500000000000234, 152.1999999999996, 109.29999999999984, 117.19999999999979, 96.09999999999913, 155.19999999999956, 115.79999999999887, 45.500000000000405, 24.200000000000042, 66.50000000000026, 298.5, -175.60000000000048, 52.6000000000005, 189.49999999999935, 206.69999999999933, 204.39999999999932, 155.99999999999957, 31.200000000000166, 79.30000000000008, 195.5999999999994, 157.3999999999996, 169.49999999999952, 27.900000000000105, 128.2999999999998, 45.000000000000014, 30.100000000000147, 280.00000000000006, 244.7, 208.99999999999946, 37.90000000000027, 30.100000000000147, 4.299999999999943, 164.5999999999995, -11.099999999999607, 189.6999999999994, 147.0999999999996, 160.49999999999955], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [44.300000000000246, 0.7999999999999563, 15.199999999999978, 73.39999999999998, 160.7, 9.499999999999964, 13.699999999999964, -81.10000000000048, 25.400000000000098, -99.70000000000002, -31.599999999999916, -36.699999999999754, -94.9, 5.299999999999965, 15.799999999999963, -9.699999999999982, 36.20000000000008, -179.80000000000018, 20.000000000000014, -28.599999999999753, 20.000000000000014, 17.899999999999988, -17.79999999999974, -28.899999999999963, -103.00000000000057, -5.799999999999981, -330.7, -20.199999999999868, -65.8000000000005, 20.000000000000014, 20.299999999999898, -46.89999999999987, -158.50000000000065, 131.9, -38.799999999999756, 89.29999999999997, -97.30000000000072, 25.400000000000027, 38.599999999999966, 20.300000000000022, -64.00000000000091, 32.30000000000025, -18.999999999999968, -361.4999999999992, 20.000000000000014, -26.49999999999975, 20.000000000000014, -37.59999999999978, 65.0, -28.29999999999975, 66.80000000000014, -176.20000000000056, 135.79999999999998, 20.000000000000014, -5.1999999999999265, 13.699999999999964, 94.4000000000001, -45.399999999999764, -34.599999999999774, -21.999999999999744, -171.40000000000046, -13.599999999999783, -26.79999999999977, 7.399999999999965, -83.20000000000067, 7.399999999999965, 105.49999999999997, -28.29999999999975, -52.0, -168.70000000000059, 9.499999999999964, 17.899999999999977, 20.000000000000014, 4.699999999999973, -36.699999999999754, 174.8, -62.80000000000072, 7.399999999999974, 153.20000000000002, -68.20000000000039, 188.0, -51.40000000000005, 60.49999999999996, 9.499999999999964, 120.80000000000001, 37.10000000000022, 20.000000000000014, -66.10000000000062, 128.3, -248.40000000000043, 122.30000000000005, 133.10000000000002, 20.000000000000014, 7.399999999999965, 146.89999999999998, 50.899999999999835, 20.000000000000014, -167.20000000000056, -65.80000000000044, 17.0, 93.19999999999999, -40.89999999999976, 183.8, -97.60000000000079, -72.70000000000087, 35.90000000000014, 11.599999999999964, 17.899999999999988, 11.599999999999971, 4.399999999999999, 189.2, -344.1999999999999, 34.40000000000026, -36.69999999999984, -113.60000000000082, -126.20000000000078, 89.30000000000011, 125.30000000000001, -64.30000000000055, 5.299999999999965, 7.399999999999965, -24.39999999999975, 14.299999999999967, -30.39999999999975, 102.20000000000003, 7.399999999999965, -2.499999999999986, 20.000000000000014, 11.599999999999964, 134.6, -108.70000000000076, 122.0, -66.7000000000007, 71.9, 15.799999999999963, 8.299999999999992, -6.4000000000000625, 143.59999999999997, 91.39999999999952, 7.399999999999965, 21.500000000000032, 20.000000000000014, 0.7999999999999865, 7.399999999999965, -0.9999999999999846, 48.5000000000002, 157.4, 133.09999999999997, -141.70000000000036, -176.90000000000015, 15.499999999999963, 25.100000000000094, 172.09999999999997, 7.399999999999965, 187.1, 11.599999999999964, 19.400000000000006, 143.0, 20.000000000000014, 80.0, 20.000000000000014, 3.199999999999967, 27.5, -26.199999999999747, 184.70000000000002, -3.0999999999999934, 116.0, 7.399999999999965, 153.2, 5.299999999999965, 5.299999999999965, 11.599999999999964, 5.299999999999965, 74.0, -32.8, -20.200000000000017, 17.899999999999977, 3.1999999999999766, 106.70000000000007, 161.3, 119.60000000000005, 79.1, 154.7, -21.699999999999868, 20.000000000000014, -3.099999999999958, 17.899999999999988, 3.1999999999999615, 11.599999999999946, -88.30000000000076, 23.60000000000007, 122.00000000000007, -30.39999999999975, -48.69999999999984, 173.0, -16.29999999999975, 20.000000000000014, 127.1, 159.5, -21.99999999999976], "policy_predator_policy_reward": [2.0, 11.0, 46.0, 52.0, 5.0, 5.0, 37.0, 54.0, 82.0, 84.0, 81.0, 78.0, 95.0, 53.0, 41.0, 42.0, 95.0, 102.0, 20.0, 17.0, 1.0, 0.0, 71.0, 59.0, 66.0, 73.0, 182.0, 42.0, 43.0, 39.0, 78.0, 80.0, 17.0, 76.0, 28.0, 0.0, 36.0, 104.0, 20.0, 15.0, 40.0, 1.0, 41.0, 228.0, 20.0, 21.0, 24.0, 22.0, 45.0, 23.0, 68.0, 96.0, 0.0, 4.0, 5.0, 11.0, 13.0, 32.0, 38.0, 0.0, 83.0, 105.0, 27.0, 6.0, 46.0, 23.0, 23.0, 9.0, 153.0, 144.0, 6.0, 0.0, 0.0, 12.0, 30.0, 6.0, 43.0, 44.0, 44.0, 10.0, 34.0, 7.0, 1.0, 5.0, 9.0, 11.0, 52.0, 43.0, 133.0, 23.0, 19.0, 4.0, 6.0, 3.0, 41.0, 0.0, 92.0, 60.0, 81.0, 34.0, 8.0, 29.0, 1.0, 56.0, 40.0, 47.0, 4.0, 1.0, 11.0, 3.0, 156.0, 157.0, 41.0, 24.0, 80.0, 57.0, 15.0, 17.0, 7.0, 59.0, 22.0, 13.0, 18.0, 22.0, 24.0, 8.0, 3.0, 15.0, 2.0, 4.0, 37.0, 59.0, 57.0, 55.0, 31.0, 41.0, 10.0, 8.0, 9.0, 8.0, 0.0, 4.0, 10.0, 6.0, 14.0, 5.0, 1.0, 7.0, 5.0, 138.0, 3.0, 9.0, 5.0, 5.0, 4.0, 4.0, 19.0, 23.0, 33.0, 23.0, 1.0, 7.0, 22.0, 56.0, 12.0, 2.0, 6.0, 28.0, 7.0, 4.0, 4.0, 7.0, 7.0, 42.0, 78.0, 20.0, 6.0, 3.0, 0.0, 12.0, 10.0, 36.0, 39.0, 37.0, 11.0, 10.0, 8.0, 1.0, 34.0, 47.0, 5.0, 14.0, 32.0, 36.0, 27.0, 6.0, 0.0, 0.0, 20.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7100720346792064, "mean_inference_ms": 1.8674691844570912, "mean_action_processing_ms": 0.3085062627603818, "mean_env_wait_ms": 0.2440986864348285, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007930874824523926, "StateBufferConnector_ms": 0.003301858901977539, "ViewRequirementAgentConnector_ms": 0.12631750106811523}, "num_episodes": 23, "episode_return_max": 298.5, "episode_return_min": -175.60000000000048, "episode_return_mean": 85.6379999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.3551987277679, "num_env_steps_trained_throughput_per_sec": 344.3551987277679, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 11842.505, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11842.445, "sample_time_ms": 1416.074, "learn_time_ms": 10401.215, "learn_throughput": 384.57, "synch_weights_time_ms": 20.773}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "f0d88_00000", "date": "2024-08-14_10-56-25", "timestamp": 1723647385, "time_this_iter_s": 11.67479133605957, "time_total_s": 603.3785853385925, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad516f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 603.3785853385925, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 46.094117647058816, "ram_util_percent": 82.73529411764706}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.695650105722367, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.778841065225147, "policy_loss": -0.01917158601492663, "vf_loss": 4.774992876330381, "vf_explained_var": 0.510423681029567, "kl": 0.015157048252595545, "entropy": 1.2090486189675709, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3379742004253248, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 8.05791661903341, "policy_loss": -0.010152700158062751, "vf_loss": 8.034939751297077, "vf_explained_var": 0.22528771455325777, "kl": 0.009694986124411926, "entropy": 1.2330300757493922, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 301.90000000000003, "episode_reward_min": -272.20000000000005, "episode_reward_mean": 92.51799999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.4999999999992, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.2, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": 18.863999999999965, "predator_policy": 27.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [68.09999999999967, 93.90000000000006, 9.300000000000038, -111.50000000000036, 34.500000000000206, 28.400000000000137, 104.69999999999993, 54.60000000000023, 159.79999999999956, 24.500000000000046, 94.00000000000009, -18.599999999999525, 2.9999999999999365, 13.600000000000005, -6.799999999999729, 109.19999999999979, 76.29999999999967, 33.40000000000022, 36.70000000000025, 174.09999999999945, 31.60000000000016, 138.99999999999963, 177.59999999999945, 76.00000000000009, 177.8999999999995, 48.9000000000004, 35.90000000000006, 278.4000000000001, 36.40000000000025, 238.8000000000001, 4.800000000000066, 66.20000000000005, 89.30000000000008, 143.19999999999965, 50.20000000000031, 34.50000000000022, 30.000000000000135, 157.99999999999991, 62.70000000000042, -102.80000000000157, 246.60000000000008, 7.000000000000087, 17.99999999999996, 23.900000000000052, 141.5999999999997, 35.500000000000234, 152.1999999999996, 109.29999999999984, 117.19999999999979, 96.09999999999913, 155.19999999999956, 115.79999999999887, 45.500000000000405, 24.200000000000042, 66.50000000000026, 298.5, -175.60000000000048, 52.6000000000005, 189.49999999999935, 206.69999999999933, 204.39999999999932, 155.99999999999957, 31.200000000000166, 79.30000000000008, 195.5999999999994, 157.3999999999996, 169.49999999999952, 27.900000000000105, 128.2999999999998, 45.000000000000014, 30.100000000000147, 280.00000000000006, 244.7, 208.99999999999946, 37.90000000000027, 30.100000000000147, 4.299999999999943, 164.5999999999995, -11.099999999999607, 189.6999999999994, 147.0999999999996, 160.49999999999955, 301.90000000000003, 54.00000000000051, -272.20000000000005, 136.3999999999997, 27.600000000000122, 222.69999999999922, 36.40000000000025, 143.99999999999963, 99.1, 46.90000000000035, 117.79999999999941, 164.99999999999935, 131.6999999999997, 48.50000000000047, 232.09999999999974, 207.0999999999993, 23.900000000000038, 163.2999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-97.30000000000072, 25.400000000000027, 38.599999999999966, 20.300000000000022, -64.00000000000091, 32.30000000000025, -18.999999999999968, -361.4999999999992, 20.000000000000014, -26.49999999999975, 20.000000000000014, -37.59999999999978, 65.0, -28.29999999999975, 66.80000000000014, -176.20000000000056, 135.79999999999998, 20.000000000000014, -5.1999999999999265, 13.699999999999964, 94.4000000000001, -45.399999999999764, -34.599999999999774, -21.999999999999744, -171.40000000000046, -13.599999999999783, -26.79999999999977, 7.399999999999965, -83.20000000000067, 7.399999999999965, 105.49999999999997, -28.29999999999975, -52.0, -168.70000000000059, 9.499999999999964, 17.899999999999977, 20.000000000000014, 4.699999999999973, -36.699999999999754, 174.8, -62.80000000000072, 7.399999999999974, 153.20000000000002, -68.20000000000039, 188.0, -51.40000000000005, 60.49999999999996, 9.499999999999964, 120.80000000000001, 37.10000000000022, 20.000000000000014, -66.10000000000062, 128.3, -248.40000000000043, 122.30000000000005, 133.10000000000002, 20.000000000000014, 7.399999999999965, 146.89999999999998, 50.899999999999835, 20.000000000000014, -167.20000000000056, -65.80000000000044, 17.0, 93.19999999999999, -40.89999999999976, 183.8, -97.60000000000079, -72.70000000000087, 35.90000000000014, 11.599999999999964, 17.899999999999988, 11.599999999999971, 4.399999999999999, 189.2, -344.1999999999999, 34.40000000000026, -36.69999999999984, -113.60000000000082, -126.20000000000078, 89.30000000000011, 125.30000000000001, -64.30000000000055, 5.299999999999965, 7.399999999999965, -24.39999999999975, 14.299999999999967, -30.39999999999975, 102.20000000000003, 7.399999999999965, -2.499999999999986, 20.000000000000014, 11.599999999999964, 134.6, -108.70000000000076, 122.0, -66.7000000000007, 71.9, 15.799999999999963, 8.299999999999992, -6.4000000000000625, 143.59999999999997, 91.39999999999952, 7.399999999999965, 21.500000000000032, 20.000000000000014, 0.7999999999999865, 7.399999999999965, -0.9999999999999846, 48.5000000000002, 157.4, 133.09999999999997, -141.70000000000036, -176.90000000000015, 15.499999999999963, 25.100000000000094, 172.09999999999997, 7.399999999999965, 187.1, 11.599999999999964, 19.400000000000006, 143.0, 20.000000000000014, 80.0, 20.000000000000014, 3.199999999999967, 27.5, -26.199999999999747, 184.70000000000002, -3.0999999999999934, 116.0, 7.399999999999965, 153.2, 5.299999999999965, 5.299999999999965, 11.599999999999964, 5.299999999999965, 74.0, -32.8, -20.200000000000017, 17.899999999999977, 3.1999999999999766, 106.70000000000007, 161.3, 119.60000000000005, 79.1, 154.7, -21.699999999999868, 20.000000000000014, -3.099999999999958, 17.899999999999988, 3.1999999999999615, 11.599999999999946, -88.30000000000076, 23.60000000000007, 122.00000000000007, -30.39999999999975, -48.69999999999984, 173.0, -16.29999999999975, 20.000000000000014, 127.1, 159.5, -21.99999999999976, 137.89999999999998, 128.0, 33.80000000000025, -17.79999999999974, -321.5000000000001, -149.69999999999987, 76.4, 20.000000000000014, 13.699999999999955, -3.099999999999958, 175.70000000000002, 32.00000000000021, 20.000000000000014, 7.399999999999965, 10.999999999999973, 62.0, 7.399999999999977, -13.300000000000011, -7.299999999999919, 3.19999999999999, 1.0999999999999865, 64.69999999999997, 134.9, 1.0999999999999688, 126.19999999999999, -41.49999999999979, 20.000000000000014, 6.49999999999998, 60.49999999999997, 149.6, 15.799999999999963, 185.3, -12.6999999999998, 17.599999999999984, 165.49999999999997, -47.19999999999976], "policy_predator_policy_reward": [36.0, 104.0, 20.0, 15.0, 40.0, 1.0, 41.0, 228.0, 20.0, 21.0, 24.0, 22.0, 45.0, 23.0, 68.0, 96.0, 0.0, 4.0, 5.0, 11.0, 13.0, 32.0, 38.0, 0.0, 83.0, 105.0, 27.0, 6.0, 46.0, 23.0, 23.0, 9.0, 153.0, 144.0, 6.0, 0.0, 0.0, 12.0, 30.0, 6.0, 43.0, 44.0, 44.0, 10.0, 34.0, 7.0, 1.0, 5.0, 9.0, 11.0, 52.0, 43.0, 133.0, 23.0, 19.0, 4.0, 6.0, 3.0, 41.0, 0.0, 92.0, 60.0, 81.0, 34.0, 8.0, 29.0, 1.0, 56.0, 40.0, 47.0, 4.0, 1.0, 11.0, 3.0, 156.0, 157.0, 41.0, 24.0, 80.0, 57.0, 15.0, 17.0, 7.0, 59.0, 22.0, 13.0, 18.0, 22.0, 24.0, 8.0, 3.0, 15.0, 2.0, 4.0, 37.0, 59.0, 57.0, 55.0, 31.0, 41.0, 10.0, 8.0, 9.0, 8.0, 0.0, 4.0, 10.0, 6.0, 14.0, 5.0, 1.0, 7.0, 5.0, 138.0, 3.0, 9.0, 5.0, 5.0, 4.0, 4.0, 19.0, 23.0, 33.0, 23.0, 1.0, 7.0, 22.0, 56.0, 12.0, 2.0, 6.0, 28.0, 7.0, 4.0, 4.0, 7.0, 7.0, 42.0, 78.0, 20.0, 6.0, 3.0, 0.0, 12.0, 10.0, 36.0, 39.0, 37.0, 11.0, 10.0, 8.0, 1.0, 34.0, 47.0, 5.0, 14.0, 32.0, 36.0, 27.0, 6.0, 0.0, 0.0, 20.0, 3.0, 24.0, 12.0, 18.0, 20.0, 186.0, 13.0, 0.0, 40.0, 11.0, 6.0, 11.0, 4.0, 3.0, 6.0, 33.0, 38.0, 20.0, 85.0, 19.0, 32.0, 12.0, 40.0, 9.0, 20.0, 37.0, 10.0, 12.0, 10.0, 15.0, 7.0, 2.0, 4.0, 3.0, 16.0, 32.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7108142983488609, "mean_inference_ms": 1.871264675844938, "mean_action_processing_ms": 0.3082158617447143, "mean_env_wait_ms": 0.24408175273994687, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007540583610534668, "StateBufferConnector_ms": 0.003282308578491211, "ViewRequirementAgentConnector_ms": 0.13214194774627686}, "num_episodes": 18, "episode_return_max": 301.90000000000003, "episode_return_min": -272.20000000000005, "episode_return_mean": 92.51799999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.9044910254374, "num_env_steps_trained_throughput_per_sec": 336.9044910254374, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 11887.245, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11887.183, "sample_time_ms": 1453.73, "learn_time_ms": 10407.965, "learn_throughput": 384.321, "synch_weights_time_ms": 21.18}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "f0d88_00000", "date": "2024-08-14_10-56-37", "timestamp": 1723647397, "time_this_iter_s": 12.00032901763916, "time_total_s": 615.3789143562317, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac05f9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 615.3789143562317, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 46.60588235294117, "ram_util_percent": 82.72941176470589}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.760329558168139, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.7379632088242385, "policy_loss": -0.017830065096649663, "vf_loss": 4.736327415420895, "vf_explained_var": 0.7122344364880254, "kl": 0.012817022478288724, "entropy": 1.1401011873174596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.6569600524095, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 5.317259280391471, "policy_loss": -0.012088117544618115, "vf_loss": 5.303382285057553, "vf_explained_var": 0.3876176262974108, "kl": 0.007598391525344748, "entropy": 1.22788521940746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 376.6, "episode_reward_min": -272.20000000000005, "episode_reward_mean": 109.31599999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -344.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.4, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": 32.292999999999964, "predator_policy": 22.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.70000000000025, 174.09999999999945, 31.60000000000016, 138.99999999999963, 177.59999999999945, 76.00000000000009, 177.8999999999995, 48.9000000000004, 35.90000000000006, 278.4000000000001, 36.40000000000025, 238.8000000000001, 4.800000000000066, 66.20000000000005, 89.30000000000008, 143.19999999999965, 50.20000000000031, 34.50000000000022, 30.000000000000135, 157.99999999999991, 62.70000000000042, -102.80000000000157, 246.60000000000008, 7.000000000000087, 17.99999999999996, 23.900000000000052, 141.5999999999997, 35.500000000000234, 152.1999999999996, 109.29999999999984, 117.19999999999979, 96.09999999999913, 155.19999999999956, 115.79999999999887, 45.500000000000405, 24.200000000000042, 66.50000000000026, 298.5, -175.60000000000048, 52.6000000000005, 189.49999999999935, 206.69999999999933, 204.39999999999932, 155.99999999999957, 31.200000000000166, 79.30000000000008, 195.5999999999994, 157.3999999999996, 169.49999999999952, 27.900000000000105, 128.2999999999998, 45.000000000000014, 30.100000000000147, 280.00000000000006, 244.7, 208.99999999999946, 37.90000000000027, 30.100000000000147, 4.299999999999943, 164.5999999999995, -11.099999999999607, 189.6999999999994, 147.0999999999996, 160.49999999999955, 301.90000000000003, 54.00000000000051, -272.20000000000005, 136.3999999999997, 27.600000000000122, 222.69999999999922, 36.40000000000025, 143.99999999999963, 99.1, 46.90000000000035, 117.79999999999941, 164.99999999999935, 131.6999999999997, 48.50000000000047, 232.09999999999974, 207.0999999999993, 23.900000000000038, 163.2999999999995, 288.2, 376.6, 30.100000000000147, 230.3, 259.49999999999966, 17.999999999999943, 30.000000000000085, 88.99999999999903, 35.600000000000236, 162.19999999999953, 130.99999999999963, 147.99999999999966, 157.89999999999955, 30.60000000000016, 35.600000000000236, 35.600000000000236, 197.39999999999938, 194.59999999999937], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 4.699999999999973, -36.699999999999754, 174.8, -62.80000000000072, 7.399999999999974, 153.20000000000002, -68.20000000000039, 188.0, -51.40000000000005, 60.49999999999996, 9.499999999999964, 120.80000000000001, 37.10000000000022, 20.000000000000014, -66.10000000000062, 128.3, -248.40000000000043, 122.30000000000005, 133.10000000000002, 20.000000000000014, 7.399999999999965, 146.89999999999998, 50.899999999999835, 20.000000000000014, -167.20000000000056, -65.80000000000044, 17.0, 93.19999999999999, -40.89999999999976, 183.8, -97.60000000000079, -72.70000000000087, 35.90000000000014, 11.599999999999964, 17.899999999999988, 11.599999999999971, 4.399999999999999, 189.2, -344.1999999999999, 34.40000000000026, -36.69999999999984, -113.60000000000082, -126.20000000000078, 89.30000000000011, 125.30000000000001, -64.30000000000055, 5.299999999999965, 7.399999999999965, -24.39999999999975, 14.299999999999967, -30.39999999999975, 102.20000000000003, 7.399999999999965, -2.499999999999986, 20.000000000000014, 11.599999999999964, 134.6, -108.70000000000076, 122.0, -66.7000000000007, 71.9, 15.799999999999963, 8.299999999999992, -6.4000000000000625, 143.59999999999997, 91.39999999999952, 7.399999999999965, 21.500000000000032, 20.000000000000014, 0.7999999999999865, 7.399999999999965, -0.9999999999999846, 48.5000000000002, 157.4, 133.09999999999997, -141.70000000000036, -176.90000000000015, 15.499999999999963, 25.100000000000094, 172.09999999999997, 7.399999999999965, 187.1, 11.599999999999964, 19.400000000000006, 143.0, 20.000000000000014, 80.0, 20.000000000000014, 3.199999999999967, 27.5, -26.199999999999747, 184.70000000000002, -3.0999999999999934, 116.0, 7.399999999999965, 153.2, 5.299999999999965, 5.299999999999965, 11.599999999999964, 5.299999999999965, 74.0, -32.8, -20.200000000000017, 17.899999999999977, 3.1999999999999766, 106.70000000000007, 161.3, 119.60000000000005, 79.1, 154.7, -21.699999999999868, 20.000000000000014, -3.099999999999958, 17.899999999999988, 3.1999999999999615, 11.599999999999946, -88.30000000000076, 23.60000000000007, 122.00000000000007, -30.39999999999975, -48.69999999999984, 173.0, -16.29999999999975, 20.000000000000014, 127.1, 159.5, -21.99999999999976, 137.89999999999998, 128.0, 33.80000000000025, -17.79999999999974, -321.5000000000001, -149.69999999999987, 76.4, 20.000000000000014, 13.699999999999955, -3.099999999999958, 175.70000000000002, 32.00000000000021, 20.000000000000014, 7.399999999999965, 10.999999999999973, 62.0, 7.399999999999977, -13.300000000000011, -7.299999999999919, 3.19999999999999, 1.0999999999999865, 64.69999999999997, 134.9, 1.0999999999999688, 126.19999999999999, -41.49999999999979, 20.000000000000014, 6.49999999999998, 60.49999999999997, 149.6, 15.799999999999963, 185.3, -12.6999999999998, 17.599999999999984, 165.49999999999997, -47.19999999999976, 42.2, 173.0, 168.2, 196.4, 20.000000000000014, 1.0999999999999865, 42.2, 91.1, 162.2, 71.29999999999959, -53.50000000000019, 9.499999999999964, 7.399999999999965, 5.600000000000188, 17.899999999999988, 46.10000000000013, 3.7999999999999674, 15.799999999999963, 17.899999999999977, 143.3, 77.0, 7.999999999999966, 92.0, 20.000000000000014, 13.699999999999946, 108.20000000000002, -28.29999999999975, 17.899999999999988, 11.599999999999964, 20.000000000000014, 11.599999999999966, 20.000000000000014, 47.30000000000022, 139.09999999999997, 179.3, 5.299999999999965], "policy_predator_policy_reward": [0.0, 12.0, 30.0, 6.0, 43.0, 44.0, 44.0, 10.0, 34.0, 7.0, 1.0, 5.0, 9.0, 11.0, 52.0, 43.0, 133.0, 23.0, 19.0, 4.0, 6.0, 3.0, 41.0, 0.0, 92.0, 60.0, 81.0, 34.0, 8.0, 29.0, 1.0, 56.0, 40.0, 47.0, 4.0, 1.0, 11.0, 3.0, 156.0, 157.0, 41.0, 24.0, 80.0, 57.0, 15.0, 17.0, 7.0, 59.0, 22.0, 13.0, 18.0, 22.0, 24.0, 8.0, 3.0, 15.0, 2.0, 4.0, 37.0, 59.0, 57.0, 55.0, 31.0, 41.0, 10.0, 8.0, 9.0, 8.0, 0.0, 4.0, 10.0, 6.0, 14.0, 5.0, 1.0, 7.0, 5.0, 138.0, 3.0, 9.0, 5.0, 5.0, 4.0, 4.0, 19.0, 23.0, 33.0, 23.0, 1.0, 7.0, 22.0, 56.0, 12.0, 2.0, 6.0, 28.0, 7.0, 4.0, 4.0, 7.0, 7.0, 42.0, 78.0, 20.0, 6.0, 3.0, 0.0, 12.0, 10.0, 36.0, 39.0, 37.0, 11.0, 10.0, 8.0, 1.0, 34.0, 47.0, 5.0, 14.0, 32.0, 36.0, 27.0, 6.0, 0.0, 0.0, 20.0, 3.0, 24.0, 12.0, 18.0, 20.0, 186.0, 13.0, 0.0, 40.0, 11.0, 6.0, 11.0, 4.0, 3.0, 6.0, 33.0, 38.0, 20.0, 85.0, 19.0, 32.0, 12.0, 40.0, 9.0, 20.0, 37.0, 10.0, 12.0, 10.0, 15.0, 7.0, 2.0, 4.0, 3.0, 16.0, 32.0, 13.0, 28.0, 45.0, 10.0, 2.0, 0.0, 9.0, 47.0, 50.0, 21.0, 5.0, 35.0, 27.0, 2.0, 15.0, 24.0, 1.0, 9.0, 7.0, 0.0, 1.0, 11.0, 35.0, 36.0, 0.0, 30.0, 6.0, 20.0, 21.0, 0.0, 4.0, 3.0, 1.0, 7.0, 4.0, 7.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7119647460137548, "mean_inference_ms": 1.8740886680978646, "mean_action_processing_ms": 0.30846498576069, "mean_env_wait_ms": 0.2442147831413766, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005779266357421875, "StateBufferConnector_ms": 0.0031952857971191406, "ViewRequirementAgentConnector_ms": 0.13574039936065674}, "num_episodes": 18, "episode_return_max": 376.6, "episode_return_min": -272.20000000000005, "episode_return_mean": 109.31599999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.2395027355777, "num_env_steps_trained_throughput_per_sec": 311.2395027355777, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 12023.335, "restore_workers_time_ms": 0.025, "training_step_time_ms": 12023.274, "sample_time_ms": 1488.227, "learn_time_ms": 10502.452, "learn_throughput": 380.863, "synch_weights_time_ms": 28.105}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "f0d88_00000", "date": "2024-08-14_10-56-50", "timestamp": 1723647410, "time_this_iter_s": 12.961616277694702, "time_total_s": 628.3405306339264, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0d88b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 628.3405306339264, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 55.199999999999996, "ram_util_percent": 83.08333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4467875088648823, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.931134545613849, "policy_loss": -0.013770299708032143, "vf_loss": 4.926174300309842, "vf_explained_var": 0.7460931701319559, "kl": 0.012332875448212944, "entropy": 1.0810846376355994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.319777489023864, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 2.7792994423518107, "policy_loss": -0.01288326675092023, "vf_loss": 2.7689237052801423, "vf_explained_var": 0.3231761180219196, "kl": 0.006806474971893103, "entropy": 1.1989330001609035, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 376.6, "episode_reward_min": -272.20000000000005, "episode_reward_mean": 121.15099999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 38.89549999999999, "predator_policy": 21.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.000000000000135, 157.99999999999991, 62.70000000000042, -102.80000000000157, 246.60000000000008, 7.000000000000087, 17.99999999999996, 23.900000000000052, 141.5999999999997, 35.500000000000234, 152.1999999999996, 109.29999999999984, 117.19999999999979, 96.09999999999913, 155.19999999999956, 115.79999999999887, 45.500000000000405, 24.200000000000042, 66.50000000000026, 298.5, -175.60000000000048, 52.6000000000005, 189.49999999999935, 206.69999999999933, 204.39999999999932, 155.99999999999957, 31.200000000000166, 79.30000000000008, 195.5999999999994, 157.3999999999996, 169.49999999999952, 27.900000000000105, 128.2999999999998, 45.000000000000014, 30.100000000000147, 280.00000000000006, 244.7, 208.99999999999946, 37.90000000000027, 30.100000000000147, 4.299999999999943, 164.5999999999995, -11.099999999999607, 189.6999999999994, 147.0999999999996, 160.49999999999955, 301.90000000000003, 54.00000000000051, -272.20000000000005, 136.3999999999997, 27.600000000000122, 222.69999999999922, 36.40000000000025, 143.99999999999963, 99.1, 46.90000000000035, 117.79999999999941, 164.99999999999935, 131.6999999999997, 48.50000000000047, 232.09999999999974, 207.0999999999993, 23.900000000000038, 163.2999999999995, 288.2, 376.6, 30.100000000000147, 230.3, 259.49999999999966, 17.999999999999943, 30.000000000000085, 88.99999999999903, 35.600000000000236, 162.19999999999953, 130.99999999999963, 147.99999999999966, 157.89999999999955, 30.60000000000016, 35.600000000000236, 35.600000000000236, 197.39999999999938, 194.59999999999937, 361.1, 126.69999999999972, 237.2, 194.39999999999938, 331.6, 34.50000000000022, -232.5000000000006, 269.80000000000007, 197.89999999999932, 107.80000000000004, 20.199999999999996, 288.0, 215.79999999999927, 320.2, 188.19999999999948, 26.800000000000086, 172.9999999999995, 162.29999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999971, 4.399999999999999, 189.2, -344.1999999999999, 34.40000000000026, -36.69999999999984, -113.60000000000082, -126.20000000000078, 89.30000000000011, 125.30000000000001, -64.30000000000055, 5.299999999999965, 7.399999999999965, -24.39999999999975, 14.299999999999967, -30.39999999999975, 102.20000000000003, 7.399999999999965, -2.499999999999986, 20.000000000000014, 11.599999999999964, 134.6, -108.70000000000076, 122.0, -66.7000000000007, 71.9, 15.799999999999963, 8.299999999999992, -6.4000000000000625, 143.59999999999997, 91.39999999999952, 7.399999999999965, 21.500000000000032, 20.000000000000014, 0.7999999999999865, 7.399999999999965, -0.9999999999999846, 48.5000000000002, 157.4, 133.09999999999997, -141.70000000000036, -176.90000000000015, 15.499999999999963, 25.100000000000094, 172.09999999999997, 7.399999999999965, 187.1, 11.599999999999964, 19.400000000000006, 143.0, 20.000000000000014, 80.0, 20.000000000000014, 3.199999999999967, 27.5, -26.199999999999747, 184.70000000000002, -3.0999999999999934, 116.0, 7.399999999999965, 153.2, 5.299999999999965, 5.299999999999965, 11.599999999999964, 5.299999999999965, 74.0, -32.8, -20.200000000000017, 17.899999999999977, 3.1999999999999766, 106.70000000000007, 161.3, 119.60000000000005, 79.1, 154.7, -21.699999999999868, 20.000000000000014, -3.099999999999958, 17.899999999999988, 3.1999999999999615, 11.599999999999946, -88.30000000000076, 23.60000000000007, 122.00000000000007, -30.39999999999975, -48.69999999999984, 173.0, -16.29999999999975, 20.000000000000014, 127.1, 159.5, -21.99999999999976, 137.89999999999998, 128.0, 33.80000000000025, -17.79999999999974, -321.5000000000001, -149.69999999999987, 76.4, 20.000000000000014, 13.699999999999955, -3.099999999999958, 175.70000000000002, 32.00000000000021, 20.000000000000014, 7.399999999999965, 10.999999999999973, 62.0, 7.399999999999977, -13.300000000000011, -7.299999999999919, 3.19999999999999, 1.0999999999999865, 64.69999999999997, 134.9, 1.0999999999999688, 126.19999999999999, -41.49999999999979, 20.000000000000014, 6.49999999999998, 60.49999999999997, 149.6, 15.799999999999963, 185.3, -12.6999999999998, 17.599999999999984, 165.49999999999997, -47.19999999999976, 42.2, 173.0, 168.2, 196.4, 20.000000000000014, 1.0999999999999865, 42.2, 91.1, 162.2, 71.29999999999959, -53.50000000000019, 9.499999999999964, 7.399999999999965, 5.600000000000188, 17.899999999999988, 46.10000000000013, 3.7999999999999674, 15.799999999999963, 17.899999999999977, 143.3, 77.0, 7.999999999999966, 92.0, 20.000000000000014, 13.699999999999946, 108.20000000000002, -28.29999999999975, 17.899999999999988, 11.599999999999964, 20.000000000000014, 11.599999999999966, 20.000000000000014, 47.30000000000022, 139.09999999999997, 179.3, 5.299999999999965, 193.1, 146.0, -10.0, 49.70000000000024, 97.1, 91.1, 157.4, 20.000000000000014, 162.5, 151.1, 11.599999999999964, 17.899999999999988, -63.99999999999999, -392.4999999999998, 36.80000000000001, 80.0, 164.60000000000002, -48.69999999999984, 96.50000000000011, -15.699999999999747, -3.9999999999999587, 3.1999999999999615, 131.0, 113.0, -5.199999999999962, 200.0, 121.1, 163.1, 143.59999999999997, 38.60000000000025, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 95.0, 127.40000000000006, 20.90000000000003], "policy_predator_policy_reward": [11.0, 3.0, 156.0, 157.0, 41.0, 24.0, 80.0, 57.0, 15.0, 17.0, 7.0, 59.0, 22.0, 13.0, 18.0, 22.0, 24.0, 8.0, 3.0, 15.0, 2.0, 4.0, 37.0, 59.0, 57.0, 55.0, 31.0, 41.0, 10.0, 8.0, 9.0, 8.0, 0.0, 4.0, 10.0, 6.0, 14.0, 5.0, 1.0, 7.0, 5.0, 138.0, 3.0, 9.0, 5.0, 5.0, 4.0, 4.0, 19.0, 23.0, 33.0, 23.0, 1.0, 7.0, 22.0, 56.0, 12.0, 2.0, 6.0, 28.0, 7.0, 4.0, 4.0, 7.0, 7.0, 42.0, 78.0, 20.0, 6.0, 3.0, 0.0, 12.0, 10.0, 36.0, 39.0, 37.0, 11.0, 10.0, 8.0, 1.0, 34.0, 47.0, 5.0, 14.0, 32.0, 36.0, 27.0, 6.0, 0.0, 0.0, 20.0, 3.0, 24.0, 12.0, 18.0, 20.0, 186.0, 13.0, 0.0, 40.0, 11.0, 6.0, 11.0, 4.0, 3.0, 6.0, 33.0, 38.0, 20.0, 85.0, 19.0, 32.0, 12.0, 40.0, 9.0, 20.0, 37.0, 10.0, 12.0, 10.0, 15.0, 7.0, 2.0, 4.0, 3.0, 16.0, 32.0, 13.0, 28.0, 45.0, 10.0, 2.0, 0.0, 9.0, 47.0, 50.0, 21.0, 5.0, 35.0, 27.0, 2.0, 15.0, 24.0, 1.0, 9.0, 7.0, 0.0, 1.0, 11.0, 35.0, 36.0, 0.0, 30.0, 6.0, 20.0, 21.0, 0.0, 4.0, 3.0, 1.0, 7.0, 4.0, 7.0, 3.0, 4.0, 18.0, 44.0, 43.0, 35.0, 14.0, 7.0, 10.0, 2.0, 16.0, 1.0, 4.0, 220.0, 4.0, 73.0, 80.0, 38.0, 44.0, 17.0, 10.0, 7.0, 14.0, 28.0, 16.0, 12.0, 9.0, 21.0, 15.0, 0.0, 6.0, 10.0, 2.0, 35.0, 23.0, 3.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7166623951333579, "mean_inference_ms": 1.8887263930756848, "mean_action_processing_ms": 0.3098654108701318, "mean_env_wait_ms": 0.24599180853431904, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005823016166687012, "StateBufferConnector_ms": 0.006433606147766113, "ViewRequirementAgentConnector_ms": 0.19921743869781494}, "num_episodes": 18, "episode_return_max": 376.6, "episode_return_min": -272.20000000000005, "episode_return_mean": 121.15099999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.1339986762442, "num_env_steps_trained_throughput_per_sec": 269.1339986762442, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 12233.803, "restore_workers_time_ms": 0.028, "training_step_time_ms": 12233.73, "sample_time_ms": 1760.72, "learn_time_ms": 10436.379, "learn_throughput": 383.275, "synch_weights_time_ms": 31.72}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "f0d88_00000", "date": "2024-08-14_10-57-05", "timestamp": 1723647425, "time_this_iter_s": 14.941944122314453, "time_total_s": 643.2824747562408, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad542ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 643.2824747562408, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 73.95238095238095, "ram_util_percent": 82.97619047619048}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.878599133945647, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.932765551849648, "policy_loss": -0.02441826160977442, "vf_loss": 4.934099122329995, "vf_explained_var": 0.7068363944689433, "kl": 0.01519979396933843, "entropy": 1.151538275663184, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.17657276732581, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 2.6059349461207315, "policy_loss": -0.011232163836297495, "vf_loss": 2.59957528953199, "vf_explained_var": 0.24633121490478516, "kl": 0.00514804055702362, "entropy": 1.1846296726711212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 376.6, "episode_reward_min": -272.20000000000005, "episode_reward_mean": 135.03699999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 46.613500000000016, "predator_policy": 20.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [189.49999999999935, 206.69999999999933, 204.39999999999932, 155.99999999999957, 31.200000000000166, 79.30000000000008, 195.5999999999994, 157.3999999999996, 169.49999999999952, 27.900000000000105, 128.2999999999998, 45.000000000000014, 30.100000000000147, 280.00000000000006, 244.7, 208.99999999999946, 37.90000000000027, 30.100000000000147, 4.299999999999943, 164.5999999999995, -11.099999999999607, 189.6999999999994, 147.0999999999996, 160.49999999999955, 301.90000000000003, 54.00000000000051, -272.20000000000005, 136.3999999999997, 27.600000000000122, 222.69999999999922, 36.40000000000025, 143.99999999999963, 99.1, 46.90000000000035, 117.79999999999941, 164.99999999999935, 131.6999999999997, 48.50000000000047, 232.09999999999974, 207.0999999999993, 23.900000000000038, 163.2999999999995, 288.2, 376.6, 30.100000000000147, 230.3, 259.49999999999966, 17.999999999999943, 30.000000000000085, 88.99999999999903, 35.600000000000236, 162.19999999999953, 130.99999999999963, 147.99999999999966, 157.89999999999955, 30.60000000000016, 35.600000000000236, 35.600000000000236, 197.39999999999938, 194.59999999999937, 361.1, 126.69999999999972, 237.2, 194.39999999999938, 331.6, 34.50000000000022, -232.5000000000006, 269.80000000000007, 197.89999999999932, 107.80000000000004, 20.199999999999996, 288.0, 215.79999999999927, 320.2, 188.19999999999948, 26.800000000000086, 172.9999999999995, 162.29999999999956, 45.300000000000395, 4.500000000000063, 7.800000000000047, 39.700000000000294, 10.599999999999907, 187.09999999999934, 149.9999999999996, 149.6999999999996, 30.100000000000147, 314.0, 13.999999999999972, 101.29999999999997, 42.70000000000034, 337.9, 143.99999999999963, 325.5, 174.2, 301.1, 128.0999999999998, 34.50000000000022, 357.1, 167.3999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [172.09999999999997, 7.399999999999965, 187.1, 11.599999999999964, 19.400000000000006, 143.0, 20.000000000000014, 80.0, 20.000000000000014, 3.199999999999967, 27.5, -26.199999999999747, 184.70000000000002, -3.0999999999999934, 116.0, 7.399999999999965, 153.2, 5.299999999999965, 5.299999999999965, 11.599999999999964, 5.299999999999965, 74.0, -32.8, -20.200000000000017, 17.899999999999977, 3.1999999999999766, 106.70000000000007, 161.3, 119.60000000000005, 79.1, 154.7, -21.699999999999868, 20.000000000000014, -3.099999999999958, 17.899999999999988, 3.1999999999999615, 11.599999999999946, -88.30000000000076, 23.60000000000007, 122.00000000000007, -30.39999999999975, -48.69999999999984, 173.0, -16.29999999999975, 20.000000000000014, 127.1, 159.5, -21.99999999999976, 137.89999999999998, 128.0, 33.80000000000025, -17.79999999999974, -321.5000000000001, -149.69999999999987, 76.4, 20.000000000000014, 13.699999999999955, -3.099999999999958, 175.70000000000002, 32.00000000000021, 20.000000000000014, 7.399999999999965, 10.999999999999973, 62.0, 7.399999999999977, -13.300000000000011, -7.299999999999919, 3.19999999999999, 1.0999999999999865, 64.69999999999997, 134.9, 1.0999999999999688, 126.19999999999999, -41.49999999999979, 20.000000000000014, 6.49999999999998, 60.49999999999997, 149.6, 15.799999999999963, 185.3, -12.6999999999998, 17.599999999999984, 165.49999999999997, -47.19999999999976, 42.2, 173.0, 168.2, 196.4, 20.000000000000014, 1.0999999999999865, 42.2, 91.1, 162.2, 71.29999999999959, -53.50000000000019, 9.499999999999964, 7.399999999999965, 5.600000000000188, 17.899999999999988, 46.10000000000013, 3.7999999999999674, 15.799999999999963, 17.899999999999977, 143.3, 77.0, 7.999999999999966, 92.0, 20.000000000000014, 13.699999999999946, 108.20000000000002, -28.29999999999975, 17.899999999999988, 11.599999999999964, 20.000000000000014, 11.599999999999966, 20.000000000000014, 47.30000000000022, 139.09999999999997, 179.3, 5.299999999999965, 193.1, 146.0, -10.0, 49.70000000000024, 97.1, 91.1, 157.4, 20.000000000000014, 162.5, 151.1, 11.599999999999964, 17.899999999999988, -63.99999999999999, -392.4999999999998, 36.80000000000001, 80.0, 164.60000000000002, -48.69999999999984, 96.50000000000011, -15.699999999999747, -3.9999999999999587, 3.1999999999999615, 131.0, 113.0, -5.199999999999962, 200.0, 121.1, 163.1, 143.59999999999997, 38.60000000000025, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 95.0, 127.40000000000006, 20.90000000000003, -9.399999999999855, 13.699999999999967, 158.6, -342.09999999999974, 13.699999999999966, -82.90000000000084, 20.000000000000014, 13.699999999999964, -1.0000000000000542, -18.399999999999835, 163.69999999999996, 7.399999999999965, -15.700000000000035, 148.7, 124.69999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 137.0, 134.0, 133.1, -263.1, -30.39999999999975, 19.69999999999996, 20.000000000000014, 4.699999999999967, 146.0, 155.9, 110.00000000000009, 20.000000000000014, 41.0, 195.5, 52.099999999999994, 10.099999999999994, 124.1, 137.0, 1.0999999999999768, 77.0, 20.000000000000014, 9.499999999999966, 155.0, 187.1, 146.9, -32.49999999999975], "policy_predator_policy_reward": [5.0, 5.0, 4.0, 4.0, 19.0, 23.0, 33.0, 23.0, 1.0, 7.0, 22.0, 56.0, 12.0, 2.0, 6.0, 28.0, 7.0, 4.0, 4.0, 7.0, 7.0, 42.0, 78.0, 20.0, 6.0, 3.0, 0.0, 12.0, 10.0, 36.0, 39.0, 37.0, 11.0, 10.0, 8.0, 1.0, 34.0, 47.0, 5.0, 14.0, 32.0, 36.0, 27.0, 6.0, 0.0, 0.0, 20.0, 3.0, 24.0, 12.0, 18.0, 20.0, 186.0, 13.0, 0.0, 40.0, 11.0, 6.0, 11.0, 4.0, 3.0, 6.0, 33.0, 38.0, 20.0, 85.0, 19.0, 32.0, 12.0, 40.0, 9.0, 20.0, 37.0, 10.0, 12.0, 10.0, 15.0, 7.0, 2.0, 4.0, 3.0, 16.0, 32.0, 13.0, 28.0, 45.0, 10.0, 2.0, 0.0, 9.0, 47.0, 50.0, 21.0, 5.0, 35.0, 27.0, 2.0, 15.0, 24.0, 1.0, 9.0, 7.0, 0.0, 1.0, 11.0, 35.0, 36.0, 0.0, 30.0, 6.0, 20.0, 21.0, 0.0, 4.0, 3.0, 1.0, 7.0, 4.0, 7.0, 3.0, 4.0, 18.0, 44.0, 43.0, 35.0, 14.0, 7.0, 10.0, 2.0, 16.0, 1.0, 4.0, 220.0, 4.0, 73.0, 80.0, 38.0, 44.0, 17.0, 10.0, 7.0, 14.0, 28.0, 16.0, 12.0, 9.0, 21.0, 15.0, 0.0, 6.0, 10.0, 2.0, 35.0, 23.0, 3.0, 11.0, 17.0, 24.0, 188.0, 0.0, 42.0, 35.0, 3.0, 3.0, 11.0, 19.0, 10.0, 6.0, 17.0, 0.0, 0.0, 5.0, 0.0, 9.0, 21.0, 22.0, 136.0, 8.0, 54.0, 58.0, 9.0, 9.0, 15.0, 21.0, 2.0, 12.0, 44.0, 45.0, 64.0, 48.0, 15.0, 25.0, 9.0, 41.0, 0.0, 5.0, 5.0, 10.0, 22.0, 31.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7233479189916678, "mean_inference_ms": 1.9090405128541044, "mean_action_processing_ms": 0.31200448221256966, "mean_env_wait_ms": 0.2484490478653629, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004979729652404785, "StateBufferConnector_ms": 0.006720900535583496, "ViewRequirementAgentConnector_ms": 0.2032414674758911}, "num_episodes": 22, "episode_return_max": 376.6, "episode_return_min": -272.20000000000005, "episode_return_mean": 135.03699999999986, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.6857172087884, "num_env_steps_trained_throughput_per_sec": 316.6857172087884, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 12228.636, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12228.562, "sample_time_ms": 1819.175, "learn_time_ms": 10372.049, "learn_throughput": 385.652, "synch_weights_time_ms": 32.019}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "f0d88_00000", "date": "2024-08-14_10-57-18", "timestamp": 1723647438, "time_this_iter_s": 12.69930911064148, "time_total_s": 655.9817838668823, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0eb160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 655.9817838668823, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 57.415789473684214, "ram_util_percent": 83.7421052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.501802835451863, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.298991481715409, "policy_loss": -0.025903563294066952, "vf_loss": 4.304667747209942, "vf_explained_var": 0.7006977052284927, "kl": 0.013318391128432852, "entropy": 1.082367543505613, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.72872386606282, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.0010000000000000005, "total_loss": 1.7219956731670116, "policy_loss": -0.013905618409749377, "vf_loss": 1.7200035337417845, "vf_explained_var": 0.15368356301040245, "kl": 0.004652294180633607, "entropy": 1.1855605862758778, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 376.6, "episode_reward_min": -272.20000000000005, "episode_reward_mean": 142.02899999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -424.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 47.79950000000001, "predator_policy": 23.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [160.49999999999955, 301.90000000000003, 54.00000000000051, -272.20000000000005, 136.3999999999997, 27.600000000000122, 222.69999999999922, 36.40000000000025, 143.99999999999963, 99.1, 46.90000000000035, 117.79999999999941, 164.99999999999935, 131.6999999999997, 48.50000000000047, 232.09999999999974, 207.0999999999993, 23.900000000000038, 163.2999999999995, 288.2, 376.6, 30.100000000000147, 230.3, 259.49999999999966, 17.999999999999943, 30.000000000000085, 88.99999999999903, 35.600000000000236, 162.19999999999953, 130.99999999999963, 147.99999999999966, 157.89999999999955, 30.60000000000016, 35.600000000000236, 35.600000000000236, 197.39999999999938, 194.59999999999937, 361.1, 126.69999999999972, 237.2, 194.39999999999938, 331.6, 34.50000000000022, -232.5000000000006, 269.80000000000007, 197.89999999999932, 107.80000000000004, 20.199999999999996, 288.0, 215.79999999999927, 320.2, 188.19999999999948, 26.800000000000086, 172.9999999999995, 162.29999999999956, 45.300000000000395, 4.500000000000063, 7.800000000000047, 39.700000000000294, 10.599999999999907, 187.09999999999934, 149.9999999999996, 149.6999999999996, 30.100000000000147, 314.0, 13.999999999999972, 101.29999999999997, 42.70000000000034, 337.9, 143.99999999999963, 325.5, 174.2, 301.1, 128.0999999999998, 34.50000000000022, 357.1, 167.3999999999994, 137.9999999999997, 158.69999999999956, 87.20000000000027, 131.09999999999968, 215.99999999999926, -48.10000000000041, 196.90000000000003, 175.29999999999947, 171.79999999999944, 31.900000000000183, 26.90000000000015, 157.3999999999996, 83.10000000000004, 31.200000000000163, 139.89999999999966, 302.40000000000003, 9.600000000000067, 180.99999999999946, 145.7999999999996, 323.0, 301.6, 291.3, 364.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [159.5, -21.99999999999976, 137.89999999999998, 128.0, 33.80000000000025, -17.79999999999974, -321.5000000000001, -149.69999999999987, 76.4, 20.000000000000014, 13.699999999999955, -3.099999999999958, 175.70000000000002, 32.00000000000021, 20.000000000000014, 7.399999999999965, 10.999999999999973, 62.0, 7.399999999999977, -13.300000000000011, -7.299999999999919, 3.19999999999999, 1.0999999999999865, 64.69999999999997, 134.9, 1.0999999999999688, 126.19999999999999, -41.49999999999979, 20.000000000000014, 6.49999999999998, 60.49999999999997, 149.6, 15.799999999999963, 185.3, -12.6999999999998, 17.599999999999984, 165.49999999999997, -47.19999999999976, 42.2, 173.0, 168.2, 196.4, 20.000000000000014, 1.0999999999999865, 42.2, 91.1, 162.2, 71.29999999999959, -53.50000000000019, 9.499999999999964, 7.399999999999965, 5.600000000000188, 17.899999999999988, 46.10000000000013, 3.7999999999999674, 15.799999999999963, 17.899999999999977, 143.3, 77.0, 7.999999999999966, 92.0, 20.000000000000014, 13.699999999999946, 108.20000000000002, -28.29999999999975, 17.899999999999988, 11.599999999999964, 20.000000000000014, 11.599999999999966, 20.000000000000014, 47.30000000000022, 139.09999999999997, 179.3, 5.299999999999965, 193.1, 146.0, -10.0, 49.70000000000024, 97.1, 91.1, 157.4, 20.000000000000014, 162.5, 151.1, 11.599999999999964, 17.899999999999988, -63.99999999999999, -392.4999999999998, 36.80000000000001, 80.0, 164.60000000000002, -48.69999999999984, 96.50000000000011, -15.699999999999747, -3.9999999999999587, 3.1999999999999615, 131.0, 113.0, -5.199999999999962, 200.0, 121.1, 163.1, 143.59999999999997, 38.60000000000025, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 95.0, 127.40000000000006, 20.90000000000003, -9.399999999999855, 13.699999999999967, 158.6, -342.09999999999974, 13.699999999999966, -82.90000000000084, 20.000000000000014, 13.699999999999964, -1.0000000000000542, -18.399999999999835, 163.69999999999996, 7.399999999999965, -15.700000000000035, 148.7, 124.69999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 137.0, 134.0, 133.1, -263.1, -30.39999999999975, 19.69999999999996, 20.000000000000014, 4.699999999999967, 146.0, 155.9, 110.00000000000009, 20.000000000000014, 41.0, 195.5, 52.099999999999994, 10.099999999999994, 124.1, 137.0, 1.0999999999999768, 77.0, 20.000000000000014, 9.499999999999966, 155.0, 187.1, 146.9, -32.49999999999975, 20.000000000000014, 26.0, 147.8, -3.1000000000000134, 33.79999999999996, 40.40000000000024, 119.89999999999998, 3.1999999999999615, 198.2, 15.799999999999955, -424.5, -13.599999999999854, 9.199999999999989, 118.69999999999999, 5.299999999999965, 125.0, 17.900000000000013, 137.89999999999998, -6.699999999999907, 11.599999999999964, 20.000000000000014, -15.09999999999992, 116.0, 7.399999999999965, -117.60000000000062, 100.70000000000002, 9.499999999999964, 13.699999999999964, -84.10000000000068, 101.0, 134.3, 127.10000000000002, -49.29999999999985, -3.099999999999958, 158.0, -0.9999999999999846, 17.899999999999988, 116.9, 152.0, 128.0, 104.0, 140.59999999999997, 81.49999999999991, 165.8, 170.3, 184.10000000000002], "policy_predator_policy_reward": [20.0, 3.0, 24.0, 12.0, 18.0, 20.0, 186.0, 13.0, 0.0, 40.0, 11.0, 6.0, 11.0, 4.0, 3.0, 6.0, 33.0, 38.0, 20.0, 85.0, 19.0, 32.0, 12.0, 40.0, 9.0, 20.0, 37.0, 10.0, 12.0, 10.0, 15.0, 7.0, 2.0, 4.0, 3.0, 16.0, 32.0, 13.0, 28.0, 45.0, 10.0, 2.0, 0.0, 9.0, 47.0, 50.0, 21.0, 5.0, 35.0, 27.0, 2.0, 15.0, 24.0, 1.0, 9.0, 7.0, 0.0, 1.0, 11.0, 35.0, 36.0, 0.0, 30.0, 6.0, 20.0, 21.0, 0.0, 4.0, 3.0, 1.0, 7.0, 4.0, 7.0, 3.0, 4.0, 18.0, 44.0, 43.0, 35.0, 14.0, 7.0, 10.0, 2.0, 16.0, 1.0, 4.0, 220.0, 4.0, 73.0, 80.0, 38.0, 44.0, 17.0, 10.0, 7.0, 14.0, 28.0, 16.0, 12.0, 9.0, 21.0, 15.0, 0.0, 6.0, 10.0, 2.0, 35.0, 23.0, 3.0, 11.0, 17.0, 24.0, 188.0, 0.0, 42.0, 35.0, 3.0, 3.0, 11.0, 19.0, 10.0, 6.0, 17.0, 0.0, 0.0, 5.0, 0.0, 9.0, 21.0, 22.0, 136.0, 8.0, 54.0, 58.0, 9.0, 9.0, 15.0, 21.0, 2.0, 12.0, 44.0, 45.0, 64.0, 48.0, 15.0, 25.0, 9.0, 41.0, 0.0, 5.0, 5.0, 10.0, 22.0, 31.0, 53.0, 39.0, 11.0, 3.0, 9.0, 4.0, 8.0, 0.0, 0.0, 2.0, 197.0, 193.0, 59.0, 10.0, 17.0, 28.0, 1.0, 15.0, 12.0, 15.0, 20.0, 2.0, 28.0, 6.0, 78.0, 22.0, 5.0, 3.0, 56.0, 67.0, 24.0, 17.0, 12.0, 50.0, 17.0, 7.0, 1.0, 10.0, 20.0, 23.0, 25.0, 32.0, 14.0, 30.0, 2.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.733087260446196, "mean_inference_ms": 1.9347432309966919, "mean_action_processing_ms": 0.3150479143828374, "mean_env_wait_ms": 0.25209612271530674, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004346728324890137, "StateBufferConnector_ms": 0.007543444633483887, "ViewRequirementAgentConnector_ms": 0.22192072868347168}, "num_episodes": 23, "episode_return_max": 376.6, "episode_return_min": -272.20000000000005, "episode_return_mean": 142.02899999999983, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.5093266809075, "num_env_steps_trained_throughput_per_sec": 317.5093266809075, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 12269.823, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12269.749, "sample_time_ms": 1940.57, "learn_time_ms": 10292.25, "learn_throughput": 388.642, "synch_weights_time_ms": 31.856}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "f0d88_00000", "date": "2024-08-14_10-57-31", "timestamp": 1723647451, "time_this_iter_s": 12.624396085739136, "time_total_s": 668.6061799526215, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e5a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 668.6061799526215, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 49.088235294117645, "ram_util_percent": 83.71764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8166270913270415, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.5626256745643716, "policy_loss": -0.013318192087626331, "vf_loss": 2.555077497038261, "vf_explained_var": 0.7824274683440173, "kl": 0.013739176573242336, "entropy": 1.0965322116064646, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4106104340818195, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.5345874955099095, "policy_loss": -0.01806843764291554, "vf_loss": 1.5373465695709148, "vf_explained_var": 0.2845923293835272, "kl": 0.00896021421522164, "entropy": 1.19272195453997, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 376.6, "episode_reward_min": -232.5000000000006, "episode_reward_mean": 149.37699999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -424.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 52.038500000000006, "predator_policy": 22.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [163.2999999999995, 288.2, 376.6, 30.100000000000147, 230.3, 259.49999999999966, 17.999999999999943, 30.000000000000085, 88.99999999999903, 35.600000000000236, 162.19999999999953, 130.99999999999963, 147.99999999999966, 157.89999999999955, 30.60000000000016, 35.600000000000236, 35.600000000000236, 197.39999999999938, 194.59999999999937, 361.1, 126.69999999999972, 237.2, 194.39999999999938, 331.6, 34.50000000000022, -232.5000000000006, 269.80000000000007, 197.89999999999932, 107.80000000000004, 20.199999999999996, 288.0, 215.79999999999927, 320.2, 188.19999999999948, 26.800000000000086, 172.9999999999995, 162.29999999999956, 45.300000000000395, 4.500000000000063, 7.800000000000047, 39.700000000000294, 10.599999999999907, 187.09999999999934, 149.9999999999996, 149.6999999999996, 30.100000000000147, 314.0, 13.999999999999972, 101.29999999999997, 42.70000000000034, 337.9, 143.99999999999963, 325.5, 174.2, 301.1, 128.0999999999998, 34.50000000000022, 357.1, 167.3999999999994, 137.9999999999997, 158.69999999999956, 87.20000000000027, 131.09999999999968, 215.99999999999926, -48.10000000000041, 196.90000000000003, 175.29999999999947, 171.79999999999944, 31.900000000000183, 26.90000000000015, 157.3999999999996, 83.10000000000004, 31.200000000000163, 139.89999999999966, 302.40000000000003, 9.600000000000067, 180.99999999999946, 145.7999999999996, 323.0, 301.6, 291.3, 364.4, 34.50000000000022, 125.89999999999972, 323.5, 32.00000000000018, 272.4, 110.2999999999999, 22.800000000000015, 314.79999999999995, 165.7000000000001, 36.300000000000246, 195.99999999999937, 94.19999999999942, 205.29999999999936, 23.100000000000442, 137.9999999999997, 294.20000000000005, 165.19999999999953, 64.00000000000034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [165.49999999999997, -47.19999999999976, 42.2, 173.0, 168.2, 196.4, 20.000000000000014, 1.0999999999999865, 42.2, 91.1, 162.2, 71.29999999999959, -53.50000000000019, 9.499999999999964, 7.399999999999965, 5.600000000000188, 17.899999999999988, 46.10000000000013, 3.7999999999999674, 15.799999999999963, 17.899999999999977, 143.3, 77.0, 7.999999999999966, 92.0, 20.000000000000014, 13.699999999999946, 108.20000000000002, -28.29999999999975, 17.899999999999988, 11.599999999999964, 20.000000000000014, 11.599999999999966, 20.000000000000014, 47.30000000000022, 139.09999999999997, 179.3, 5.299999999999965, 193.1, 146.0, -10.0, 49.70000000000024, 97.1, 91.1, 157.4, 20.000000000000014, 162.5, 151.1, 11.599999999999964, 17.899999999999988, -63.99999999999999, -392.4999999999998, 36.80000000000001, 80.0, 164.60000000000002, -48.69999999999984, 96.50000000000011, -15.699999999999747, -3.9999999999999587, 3.1999999999999615, 131.0, 113.0, -5.199999999999962, 200.0, 121.1, 163.1, 143.59999999999997, 38.60000000000025, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 95.0, 127.40000000000006, 20.90000000000003, -9.399999999999855, 13.699999999999967, 158.6, -342.09999999999974, 13.699999999999966, -82.90000000000084, 20.000000000000014, 13.699999999999964, -1.0000000000000542, -18.399999999999835, 163.69999999999996, 7.399999999999965, -15.700000000000035, 148.7, 124.69999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 137.0, 134.0, 133.1, -263.1, -30.39999999999975, 19.69999999999996, 20.000000000000014, 4.699999999999967, 146.0, 155.9, 110.00000000000009, 20.000000000000014, 41.0, 195.5, 52.099999999999994, 10.099999999999994, 124.1, 137.0, 1.0999999999999768, 77.0, 20.000000000000014, 9.499999999999966, 155.0, 187.1, 146.9, -32.49999999999975, 20.000000000000014, 26.0, 147.8, -3.1000000000000134, 33.79999999999996, 40.40000000000024, 119.89999999999998, 3.1999999999999615, 198.2, 15.799999999999955, -424.5, -13.599999999999854, 9.199999999999989, 118.69999999999999, 5.299999999999965, 125.0, 17.900000000000013, 137.89999999999998, -6.699999999999907, 11.599999999999964, 20.000000000000014, -15.09999999999992, 116.0, 7.399999999999965, -117.60000000000062, 100.70000000000002, 9.499999999999964, 13.699999999999964, -84.10000000000068, 101.0, 134.3, 127.10000000000002, -49.29999999999985, -3.099999999999958, 158.0, -0.9999999999999846, 17.899999999999988, 116.9, 152.0, 128.0, 104.0, 140.59999999999997, 81.49999999999991, 165.8, 170.3, 184.10000000000002, 9.499999999999964, 20.000000000000014, 5.299999999999965, 113.59999999999998, 153.5, 104.0, -0.9999999999999846, -12.99999999999982, 137.3, 121.09999999999998, 61.699999999999996, -9.399999999999855, 7.399999999999965, 7.399999999999965, 145.1, 160.7, -51.400000000000006, 112.10000000000008, 20.000000000000014, 11.299999999999965, 137.0, 20.000000000000014, -16.899999999999743, 82.09999999999974, 130.09999999999997, 69.19999999999969, 40.70000000000025, -118.59999999999987, 71.0, 20.000000000000014, 128.0, 132.2, 111.5, 22.700000000000053, 20.000000000000014, -33.999999999999844], "policy_predator_policy_reward": [32.0, 13.0, 28.0, 45.0, 10.0, 2.0, 0.0, 9.0, 47.0, 50.0, 21.0, 5.0, 35.0, 27.0, 2.0, 15.0, 24.0, 1.0, 9.0, 7.0, 0.0, 1.0, 11.0, 35.0, 36.0, 0.0, 30.0, 6.0, 20.0, 21.0, 0.0, 4.0, 3.0, 1.0, 7.0, 4.0, 7.0, 3.0, 4.0, 18.0, 44.0, 43.0, 35.0, 14.0, 7.0, 10.0, 2.0, 16.0, 1.0, 4.0, 220.0, 4.0, 73.0, 80.0, 38.0, 44.0, 17.0, 10.0, 7.0, 14.0, 28.0, 16.0, 12.0, 9.0, 21.0, 15.0, 0.0, 6.0, 10.0, 2.0, 35.0, 23.0, 3.0, 11.0, 17.0, 24.0, 188.0, 0.0, 42.0, 35.0, 3.0, 3.0, 11.0, 19.0, 10.0, 6.0, 17.0, 0.0, 0.0, 5.0, 0.0, 9.0, 21.0, 22.0, 136.0, 8.0, 54.0, 58.0, 9.0, 9.0, 15.0, 21.0, 2.0, 12.0, 44.0, 45.0, 64.0, 48.0, 15.0, 25.0, 9.0, 41.0, 0.0, 5.0, 5.0, 10.0, 22.0, 31.0, 53.0, 39.0, 11.0, 3.0, 9.0, 4.0, 8.0, 0.0, 0.0, 2.0, 197.0, 193.0, 59.0, 10.0, 17.0, 28.0, 1.0, 15.0, 12.0, 15.0, 20.0, 2.0, 28.0, 6.0, 78.0, 22.0, 5.0, 3.0, 56.0, 67.0, 24.0, 17.0, 12.0, 50.0, 17.0, 7.0, 1.0, 10.0, 20.0, 23.0, 25.0, 32.0, 14.0, 30.0, 2.0, 8.0, 0.0, 5.0, 7.0, 0.0, 34.0, 32.0, 21.0, 25.0, 1.0, 13.0, 44.0, 14.0, 6.0, 2.0, 3.0, 6.0, 49.0, 56.0, 0.0, 5.0, 21.0, 18.0, 16.0, 13.0, 5.0, 1.0, 53.0, 48.0, 4.0, 43.0, 13.0, 21.0, 16.0, 15.0, 33.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7414856619014876, "mean_inference_ms": 1.9572355431688357, "mean_action_processing_ms": 0.31779229675410525, "mean_env_wait_ms": 0.25516308066174287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004547238349914551, "StateBufferConnector_ms": 0.007686257362365723, "ViewRequirementAgentConnector_ms": 0.21820759773254395}, "num_episodes": 18, "episode_return_max": 376.6, "episode_return_min": -232.5000000000006, "episode_return_mean": 149.37699999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.0270477884917, "num_env_steps_trained_throughput_per_sec": 310.0270477884917, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 12411.691, "restore_workers_time_ms": 0.028, "training_step_time_ms": 12411.618, "sample_time_ms": 2051.041, "learn_time_ms": 10325.722, "learn_throughput": 387.382, "synch_weights_time_ms": 30.039}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "f0d88_00000", "date": "2024-08-14_10-57-44", "timestamp": 1723647464, "time_this_iter_s": 12.943150758743286, "time_total_s": 681.5493307113647, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e2310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 681.5493307113647, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 53.16842105263157, "ram_util_percent": 83.62631578947368}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2507665566981783, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.179491803412715, "policy_loss": -0.02161720971744409, "vf_loss": 2.1851491136525674, "vf_explained_var": 0.6159551612599187, "kl": 0.010508572365989932, "entropy": 1.1061333021474262, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1529527325163444, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 0.9040489824202956, "policy_loss": -0.019497583604851373, "vf_loss": 0.9118126003672837, "vf_explained_var": 0.4947876691502869, "kl": 0.006867615092514841, "entropy": 1.1854452515405323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 364.4, "episode_reward_min": -232.5000000000006, "episode_reward_mean": 153.4949999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -424.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 53.9075, "predator_policy": 22.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [194.59999999999937, 361.1, 126.69999999999972, 237.2, 194.39999999999938, 331.6, 34.50000000000022, -232.5000000000006, 269.80000000000007, 197.89999999999932, 107.80000000000004, 20.199999999999996, 288.0, 215.79999999999927, 320.2, 188.19999999999948, 26.800000000000086, 172.9999999999995, 162.29999999999956, 45.300000000000395, 4.500000000000063, 7.800000000000047, 39.700000000000294, 10.599999999999907, 187.09999999999934, 149.9999999999996, 149.6999999999996, 30.100000000000147, 314.0, 13.999999999999972, 101.29999999999997, 42.70000000000034, 337.9, 143.99999999999963, 325.5, 174.2, 301.1, 128.0999999999998, 34.50000000000022, 357.1, 167.3999999999994, 137.9999999999997, 158.69999999999956, 87.20000000000027, 131.09999999999968, 215.99999999999926, -48.10000000000041, 196.90000000000003, 175.29999999999947, 171.79999999999944, 31.900000000000183, 26.90000000000015, 157.3999999999996, 83.10000000000004, 31.200000000000163, 139.89999999999966, 302.40000000000003, 9.600000000000067, 180.99999999999946, 145.7999999999996, 323.0, 301.6, 291.3, 364.4, 34.50000000000022, 125.89999999999972, 323.5, 32.00000000000018, 272.4, 110.2999999999999, 22.800000000000015, 314.79999999999995, 165.7000000000001, 36.300000000000246, 195.99999999999937, 94.19999999999942, 205.29999999999936, 23.100000000000442, 137.9999999999997, 294.20000000000005, 165.19999999999953, 64.00000000000034, 336.0, 210.8999999999993, 161.49999999999957, -0.49999999999982836, 157.69999999999894, 195.89999999999935, 352.7, 187.4999999999996, 222.49999999999946, 14.700000000000015, 96.89999999999935, 161.49999999999957, 209.69999999999968, 55.40000000000005, 204.19999999999933, 34.30000000000021, 200.99999999999935, 28.80000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [179.3, 5.299999999999965, 193.1, 146.0, -10.0, 49.70000000000024, 97.1, 91.1, 157.4, 20.000000000000014, 162.5, 151.1, 11.599999999999964, 17.899999999999988, -63.99999999999999, -392.4999999999998, 36.80000000000001, 80.0, 164.60000000000002, -48.69999999999984, 96.50000000000011, -15.699999999999747, -3.9999999999999587, 3.1999999999999615, 131.0, 113.0, -5.199999999999962, 200.0, 121.1, 163.1, 143.59999999999997, 38.60000000000025, 15.799999999999963, -0.9999999999999846, 20.000000000000014, 95.0, 127.40000000000006, 20.90000000000003, -9.399999999999855, 13.699999999999967, 158.6, -342.09999999999974, 13.699999999999966, -82.90000000000084, 20.000000000000014, 13.699999999999964, -1.0000000000000542, -18.399999999999835, 163.69999999999996, 7.399999999999965, -15.700000000000035, 148.7, 124.69999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 137.0, 134.0, 133.1, -263.1, -30.39999999999975, 19.69999999999996, 20.000000000000014, 4.699999999999967, 146.0, 155.9, 110.00000000000009, 20.000000000000014, 41.0, 195.5, 52.099999999999994, 10.099999999999994, 124.1, 137.0, 1.0999999999999768, 77.0, 20.000000000000014, 9.499999999999966, 155.0, 187.1, 146.9, -32.49999999999975, 20.000000000000014, 26.0, 147.8, -3.1000000000000134, 33.79999999999996, 40.40000000000024, 119.89999999999998, 3.1999999999999615, 198.2, 15.799999999999955, -424.5, -13.599999999999854, 9.199999999999989, 118.69999999999999, 5.299999999999965, 125.0, 17.900000000000013, 137.89999999999998, -6.699999999999907, 11.599999999999964, 20.000000000000014, -15.09999999999992, 116.0, 7.399999999999965, -117.60000000000062, 100.70000000000002, 9.499999999999964, 13.699999999999964, -84.10000000000068, 101.0, 134.3, 127.10000000000002, -49.29999999999985, -3.099999999999958, 158.0, -0.9999999999999846, 17.899999999999988, 116.9, 152.0, 128.0, 104.0, 140.59999999999997, 81.49999999999991, 165.8, 170.3, 184.10000000000002, 9.499999999999964, 20.000000000000014, 5.299999999999965, 113.59999999999998, 153.5, 104.0, -0.9999999999999846, -12.99999999999982, 137.3, 121.09999999999998, 61.699999999999996, -9.399999999999855, 7.399999999999965, 7.399999999999965, 145.1, 160.7, -51.400000000000006, 112.10000000000008, 20.000000000000014, 11.299999999999965, 137.0, 20.000000000000014, -16.899999999999743, 82.09999999999974, 130.09999999999997, 69.19999999999969, 40.70000000000025, -118.59999999999987, 71.0, 20.000000000000014, 128.0, 132.2, 111.5, 22.700000000000053, 20.000000000000014, -33.999999999999844, 146.0, 155.0, 17.899999999999988, 188.0, -11.499999999999833, 143.0, 17.899999999999988, -66.40000000000083, -22.299999999999805, 133.99999999999966, 167.0, 17.899999999999988, 175.7, 149.0, 97.3999999999997, 64.09999999999998, 98.0, 75.49999999999946, -9.399999999999862, 1.0999999999999865, 15.799999999999963, 46.10000000000008, -33.99999999999983, 147.5, 130.70000000000002, 23.000000000000085, -70.6000000000003, 8.0, 15.799999999999963, 181.4, 9.499999999999964, 15.799999999999946, 170.0, 20.000000000000014, 11.599999999999964, 3.1999999999999615], "policy_predator_policy_reward": [7.0, 3.0, 4.0, 18.0, 44.0, 43.0, 35.0, 14.0, 7.0, 10.0, 2.0, 16.0, 1.0, 4.0, 220.0, 4.0, 73.0, 80.0, 38.0, 44.0, 17.0, 10.0, 7.0, 14.0, 28.0, 16.0, 12.0, 9.0, 21.0, 15.0, 0.0, 6.0, 10.0, 2.0, 35.0, 23.0, 3.0, 11.0, 17.0, 24.0, 188.0, 0.0, 42.0, 35.0, 3.0, 3.0, 11.0, 19.0, 10.0, 6.0, 17.0, 0.0, 0.0, 5.0, 0.0, 9.0, 21.0, 22.0, 136.0, 8.0, 54.0, 58.0, 9.0, 9.0, 15.0, 21.0, 2.0, 12.0, 44.0, 45.0, 64.0, 48.0, 15.0, 25.0, 9.0, 41.0, 0.0, 5.0, 5.0, 10.0, 22.0, 31.0, 53.0, 39.0, 11.0, 3.0, 9.0, 4.0, 8.0, 0.0, 0.0, 2.0, 197.0, 193.0, 59.0, 10.0, 17.0, 28.0, 1.0, 15.0, 12.0, 15.0, 20.0, 2.0, 28.0, 6.0, 78.0, 22.0, 5.0, 3.0, 56.0, 67.0, 24.0, 17.0, 12.0, 50.0, 17.0, 7.0, 1.0, 10.0, 20.0, 23.0, 25.0, 32.0, 14.0, 30.0, 2.0, 8.0, 0.0, 5.0, 7.0, 0.0, 34.0, 32.0, 21.0, 25.0, 1.0, 13.0, 44.0, 14.0, 6.0, 2.0, 3.0, 6.0, 49.0, 56.0, 0.0, 5.0, 21.0, 18.0, 16.0, 13.0, 5.0, 1.0, 53.0, 48.0, 4.0, 43.0, 13.0, 21.0, 16.0, 15.0, 33.0, 45.0, 18.0, 17.0, 1.0, 4.0, 9.0, 21.0, 22.0, 26.0, 13.0, 33.0, 6.0, 5.0, 14.0, 14.0, 8.0, 18.0, 15.0, 34.0, 18.0, 5.0, 2.0, 33.0, 22.0, 26.0, 14.0, 42.0, 43.0, 75.0, 5.0, 2.0, 6.0, 3.0, 10.0, 1.0, 7.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7513499979131855, "mean_inference_ms": 1.9832574986501657, "mean_action_processing_ms": 0.3208107372840711, "mean_env_wait_ms": 0.2586830898573143, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0048667192459106445, "StateBufferConnector_ms": 0.007832050323486328, "ViewRequirementAgentConnector_ms": 0.2472705841064453}, "num_episodes": 18, "episode_return_max": 364.4, "episode_return_min": -232.5000000000006, "episode_return_mean": 153.4949999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.81317532721516, "num_env_steps_trained_throughput_per_sec": 305.81317532721516, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 12567.061, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12566.987, "sample_time_ms": 2160.584, "learn_time_ms": 10371.964, "learn_throughput": 385.655, "synch_weights_time_ms": 29.62}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "f0d88_00000", "date": "2024-08-14_10-57-57", "timestamp": 1723647477, "time_this_iter_s": 13.12824296951294, "time_total_s": 694.6775736808777, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad516430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 694.6775736808777, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 52.47222222222222, "ram_util_percent": 83.5111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1074579875620585, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.7973274334713265, "policy_loss": -0.019591455396126816, "vf_loss": 1.8026453349956129, "vf_explained_var": 0.6540688725375624, "kl": 0.009398223517127826, "entropy": 1.0392313804260638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1128564140784047, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 0.9866415745682187, "policy_loss": -0.015968563099189724, "vf_loss": 0.9895005017834365, "vf_explained_var": 0.5099406291883458, "kl": 0.00767276344305034, "entropy": 1.1846649502951, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 364.4, "episode_reward_min": -48.10000000000041, "episode_reward_mean": 148.68999999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -424.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 53.29999999999999, "predator_policy": 21.045}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.700000000000294, 10.599999999999907, 187.09999999999934, 149.9999999999996, 149.6999999999996, 30.100000000000147, 314.0, 13.999999999999972, 101.29999999999997, 42.70000000000034, 337.9, 143.99999999999963, 325.5, 174.2, 301.1, 128.0999999999998, 34.50000000000022, 357.1, 167.3999999999994, 137.9999999999997, 158.69999999999956, 87.20000000000027, 131.09999999999968, 215.99999999999926, -48.10000000000041, 196.90000000000003, 175.29999999999947, 171.79999999999944, 31.900000000000183, 26.90000000000015, 157.3999999999996, 83.10000000000004, 31.200000000000163, 139.89999999999966, 302.40000000000003, 9.600000000000067, 180.99999999999946, 145.7999999999996, 323.0, 301.6, 291.3, 364.4, 34.50000000000022, 125.89999999999972, 323.5, 32.00000000000018, 272.4, 110.2999999999999, 22.800000000000015, 314.79999999999995, 165.7000000000001, 36.300000000000246, 195.99999999999937, 94.19999999999942, 205.29999999999936, 23.100000000000442, 137.9999999999997, 294.20000000000005, 165.19999999999953, 64.00000000000034, 336.0, 210.8999999999993, 161.49999999999957, -0.49999999999982836, 157.69999999999894, 195.89999999999935, 352.7, 187.4999999999996, 222.49999999999946, 14.700000000000015, 96.89999999999935, 161.49999999999957, 209.69999999999968, 55.40000000000005, 204.19999999999933, 34.30000000000021, 200.99999999999935, 28.80000000000012, 103.49999999999986, -31.9999999999998, 326.30000000000007, 160.19999999999956, 110.49999999999997, 149.59999999999962, 34.00000000000024, 35.40000000000023, 306.5000000000001, 20.500000000000096, 193.6999999999994, 176.69999999999945, 19.400000000000002, 323.20000000000005, 52.200000000000486, 245.8, 152.39999999999958, 34.40000000000022, 154.49999999999957, 37.500000000000256, 152.5999999999996, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 13.699999999999964, -1.0000000000000542, -18.399999999999835, 163.69999999999996, 7.399999999999965, -15.700000000000035, 148.7, 124.69999999999999, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 137.0, 134.0, 133.1, -263.1, -30.39999999999975, 19.69999999999996, 20.000000000000014, 4.699999999999967, 146.0, 155.9, 110.00000000000009, 20.000000000000014, 41.0, 195.5, 52.099999999999994, 10.099999999999994, 124.1, 137.0, 1.0999999999999768, 77.0, 20.000000000000014, 9.499999999999966, 155.0, 187.1, 146.9, -32.49999999999975, 20.000000000000014, 26.0, 147.8, -3.1000000000000134, 33.79999999999996, 40.40000000000024, 119.89999999999998, 3.1999999999999615, 198.2, 15.799999999999955, -424.5, -13.599999999999854, 9.199999999999989, 118.69999999999999, 5.299999999999965, 125.0, 17.900000000000013, 137.89999999999998, -6.699999999999907, 11.599999999999964, 20.000000000000014, -15.09999999999992, 116.0, 7.399999999999965, -117.60000000000062, 100.70000000000002, 9.499999999999964, 13.699999999999964, -84.10000000000068, 101.0, 134.3, 127.10000000000002, -49.29999999999985, -3.099999999999958, 158.0, -0.9999999999999846, 17.899999999999988, 116.9, 152.0, 128.0, 104.0, 140.59999999999997, 81.49999999999991, 165.8, 170.3, 184.10000000000002, 9.499999999999964, 20.000000000000014, 5.299999999999965, 113.59999999999998, 153.5, 104.0, -0.9999999999999846, -12.99999999999982, 137.3, 121.09999999999998, 61.699999999999996, -9.399999999999855, 7.399999999999965, 7.399999999999965, 145.1, 160.7, -51.400000000000006, 112.10000000000008, 20.000000000000014, 11.299999999999965, 137.0, 20.000000000000014, -16.899999999999743, 82.09999999999974, 130.09999999999997, 69.19999999999969, 40.70000000000025, -118.59999999999987, 71.0, 20.000000000000014, 128.0, 132.2, 111.5, 22.700000000000053, 20.000000000000014, -33.999999999999844, 146.0, 155.0, 17.899999999999988, 188.0, -11.499999999999833, 143.0, 17.899999999999988, -66.40000000000083, -22.299999999999805, 133.99999999999966, 167.0, 17.899999999999988, 175.7, 149.0, 97.3999999999997, 64.09999999999998, 98.0, 75.49999999999946, -9.399999999999862, 1.0999999999999865, 15.799999999999963, 46.10000000000008, -33.99999999999983, 147.5, 130.70000000000002, 23.000000000000085, -70.6000000000003, 8.0, 15.799999999999963, 181.4, 9.499999999999964, 15.799999999999946, 170.0, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 15.799999999999963, 31.700000000000003, 20.000000000000014, -223.0, 145.1, 168.2, 15.799999999999963, 115.4, -81.09999999999997, 74.60000000000002, 101.0, 11.599999999999964, 7.399999999999987, 8.599999999999968, 7.399999999999979, 20.000000000000014, 126.49999999999997, 143.0, 17.899999999999988, -45.399999999999835, 164.0, -1.3000000000000136, 144.2, 9.499999999999964, 17.899999999999988, -32.49999999999978, 136.4, 147.8, 40.100000000000236, 1.0999999999999865, 59.0, 132.8, 9.499999999999964, 110.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, 108.5, 11.599999999999964, 17.899999999999984, 80.60000000000001, 20.000000000000014, 20.000000000000014, 15.799999999999963], "policy_predator_policy_reward": [3.0, 3.0, 11.0, 19.0, 10.0, 6.0, 17.0, 0.0, 0.0, 5.0, 0.0, 9.0, 21.0, 22.0, 136.0, 8.0, 54.0, 58.0, 9.0, 9.0, 15.0, 21.0, 2.0, 12.0, 44.0, 45.0, 64.0, 48.0, 15.0, 25.0, 9.0, 41.0, 0.0, 5.0, 5.0, 10.0, 22.0, 31.0, 53.0, 39.0, 11.0, 3.0, 9.0, 4.0, 8.0, 0.0, 0.0, 2.0, 197.0, 193.0, 59.0, 10.0, 17.0, 28.0, 1.0, 15.0, 12.0, 15.0, 20.0, 2.0, 28.0, 6.0, 78.0, 22.0, 5.0, 3.0, 56.0, 67.0, 24.0, 17.0, 12.0, 50.0, 17.0, 7.0, 1.0, 10.0, 20.0, 23.0, 25.0, 32.0, 14.0, 30.0, 2.0, 8.0, 0.0, 5.0, 7.0, 0.0, 34.0, 32.0, 21.0, 25.0, 1.0, 13.0, 44.0, 14.0, 6.0, 2.0, 3.0, 6.0, 49.0, 56.0, 0.0, 5.0, 21.0, 18.0, 16.0, 13.0, 5.0, 1.0, 53.0, 48.0, 4.0, 43.0, 13.0, 21.0, 16.0, 15.0, 33.0, 45.0, 18.0, 17.0, 1.0, 4.0, 9.0, 21.0, 22.0, 26.0, 13.0, 33.0, 6.0, 5.0, 14.0, 14.0, 8.0, 18.0, 15.0, 34.0, 18.0, 5.0, 2.0, 33.0, 22.0, 26.0, 14.0, 42.0, 43.0, 75.0, 5.0, 2.0, 6.0, 3.0, 10.0, 1.0, 7.0, 7.0, 2.0, 54.0, 140.0, 31.0, 4.0, 9.0, 2.0, 27.0, 87.0, 30.0, 33.0, 4.0, 9.0, 9.0, 4.0, 4.0, 28.0, 9.0, 1.0, 47.0, 12.0, 19.0, 5.0, 18.0, 24.0, 10.0, 19.0, 20.0, 2.0, 9.0, 35.0, 19.0, 27.0, 5.0, 1.0, 6.0, 15.0, 11.0, 4.0, 4.0, 21.0, 31.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7602848492208313, "mean_inference_ms": 2.0049676398201326, "mean_action_processing_ms": 0.32221057402444225, "mean_env_wait_ms": 0.26072089082764177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004426717758178711, "StateBufferConnector_ms": 0.005240797996520996, "ViewRequirementAgentConnector_ms": 0.1814783811569214}, "num_episodes": 22, "episode_return_max": 364.4, "episode_return_min": -48.10000000000041, "episode_return_mean": 148.68999999999988, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 309.0493009168977, "num_env_steps_trained_throughput_per_sec": 309.0493009168977, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 12687.444, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12687.383, "sample_time_ms": 2236.754, "learn_time_ms": 10416.459, "learn_throughput": 384.008, "synch_weights_time_ms": 29.106}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "f0d88_00000", "date": "2024-08-14_10-58-10", "timestamp": 1723647490, "time_this_iter_s": 13.011643171310425, "time_total_s": 707.6892168521881, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0c8430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 707.6892168521881, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 53.56842105263158, "ram_util_percent": 83.27894736842104}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5926664398460793, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.4061206227887877, "policy_loss": -0.017209249667616354, "vf_loss": 2.40951450053977, "vf_explained_var": 0.6811586015123539, "kl": 0.009096544659654615, "entropy": 0.9435892831711542, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.051072342812069, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.744144762476916, "policy_loss": -0.016284733763575632, "vf_loss": 1.747660277570997, "vf_explained_var": 0.3055489388092485, "kl": 0.007473525113690007, "entropy": 1.1534931443355703, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 368.1, "episode_reward_min": -48.10000000000041, "episode_reward_mean": 152.40399999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -424.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 56.27699999999999, "predator_policy": 19.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [167.3999999999994, 137.9999999999997, 158.69999999999956, 87.20000000000027, 131.09999999999968, 215.99999999999926, -48.10000000000041, 196.90000000000003, 175.29999999999947, 171.79999999999944, 31.900000000000183, 26.90000000000015, 157.3999999999996, 83.10000000000004, 31.200000000000163, 139.89999999999966, 302.40000000000003, 9.600000000000067, 180.99999999999946, 145.7999999999996, 323.0, 301.6, 291.3, 364.4, 34.50000000000022, 125.89999999999972, 323.5, 32.00000000000018, 272.4, 110.2999999999999, 22.800000000000015, 314.79999999999995, 165.7000000000001, 36.300000000000246, 195.99999999999937, 94.19999999999942, 205.29999999999936, 23.100000000000442, 137.9999999999997, 294.20000000000005, 165.19999999999953, 64.00000000000034, 336.0, 210.8999999999993, 161.49999999999957, -0.49999999999982836, 157.69999999999894, 195.89999999999935, 352.7, 187.4999999999996, 222.49999999999946, 14.700000000000015, 96.89999999999935, 161.49999999999957, 209.69999999999968, 55.40000000000005, 204.19999999999933, 34.30000000000021, 200.99999999999935, 28.80000000000012, 103.49999999999986, -31.9999999999998, 326.30000000000007, 160.19999999999956, 110.49999999999997, 149.59999999999962, 34.00000000000024, 35.40000000000023, 306.5000000000001, 20.500000000000096, 193.6999999999994, 176.69999999999945, 19.400000000000002, 323.20000000000005, 52.200000000000486, 245.8, 152.39999999999958, 34.40000000000022, 154.49999999999957, 37.500000000000256, 152.5999999999996, 37.80000000000027, 38.80000000000028, 135.2999999999996, 69.30000000000004, 180.19999999999945, 34.10000000000018, 312.90000000000003, 368.1, 217.49999999999926, 178.09999999999945, 197.59999999999937, 180.7999999999999, 212.5, 193.99999999999937, 95.1, 191.8999999999994, 108.99999999999986, 313.0, 184.79999999999941], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [146.9, -32.49999999999975, 20.000000000000014, 26.0, 147.8, -3.1000000000000134, 33.79999999999996, 40.40000000000024, 119.89999999999998, 3.1999999999999615, 198.2, 15.799999999999955, -424.5, -13.599999999999854, 9.199999999999989, 118.69999999999999, 5.299999999999965, 125.0, 17.900000000000013, 137.89999999999998, -6.699999999999907, 11.599999999999964, 20.000000000000014, -15.09999999999992, 116.0, 7.399999999999965, -117.60000000000062, 100.70000000000002, 9.499999999999964, 13.699999999999964, -84.10000000000068, 101.0, 134.3, 127.10000000000002, -49.29999999999985, -3.099999999999958, 158.0, -0.9999999999999846, 17.899999999999988, 116.9, 152.0, 128.0, 104.0, 140.59999999999997, 81.49999999999991, 165.8, 170.3, 184.10000000000002, 9.499999999999964, 20.000000000000014, 5.299999999999965, 113.59999999999998, 153.5, 104.0, -0.9999999999999846, -12.99999999999982, 137.3, 121.09999999999998, 61.699999999999996, -9.399999999999855, 7.399999999999965, 7.399999999999965, 145.1, 160.7, -51.400000000000006, 112.10000000000008, 20.000000000000014, 11.299999999999965, 137.0, 20.000000000000014, -16.899999999999743, 82.09999999999974, 130.09999999999997, 69.19999999999969, 40.70000000000025, -118.59999999999987, 71.0, 20.000000000000014, 128.0, 132.2, 111.5, 22.700000000000053, 20.000000000000014, -33.999999999999844, 146.0, 155.0, 17.899999999999988, 188.0, -11.499999999999833, 143.0, 17.899999999999988, -66.40000000000083, -22.299999999999805, 133.99999999999966, 167.0, 17.899999999999988, 175.7, 149.0, 97.3999999999997, 64.09999999999998, 98.0, 75.49999999999946, -9.399999999999862, 1.0999999999999865, 15.799999999999963, 46.10000000000008, -33.99999999999983, 147.5, 130.70000000000002, 23.000000000000085, -70.6000000000003, 8.0, 15.799999999999963, 181.4, 9.499999999999964, 15.799999999999946, 170.0, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 15.799999999999963, 31.700000000000003, 20.000000000000014, -223.0, 145.1, 168.2, 15.799999999999963, 115.4, -81.09999999999997, 74.60000000000002, 101.0, 11.599999999999964, 7.399999999999987, 8.599999999999968, 7.399999999999979, 20.000000000000014, 126.49999999999997, 143.0, 17.899999999999988, -45.399999999999835, 164.0, -1.3000000000000136, 144.2, 9.499999999999964, 17.899999999999988, -32.49999999999978, 136.4, 147.8, 40.100000000000236, 1.0999999999999865, 59.0, 132.8, 9.499999999999964, 110.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, 108.5, 11.599999999999964, 17.899999999999984, 80.60000000000001, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, 20.000000000000014, 113.89999999999999, 7.399999999999965, -173.20000000000027, 144.5, 17.899999999999988, 161.3, 7.099999999999966, 20.000000000000014, 137.0, 149.89999999999998, 199.1, 143.0, 200.0, 9.499999999999964, 152.6, 9.499999999999964, 173.0, 11.599999999999964, 20.0, 90.80000000000004, 30.5, 95.0, 20.000000000000014, 149.0, 32.0, 13.099999999999994, 16.69999999999997, 165.2, 23.0, 20.000000000000014, 168.5, 141.5, 157.10000000000002, 13.699999999999964], "policy_predator_policy_reward": [22.0, 31.0, 53.0, 39.0, 11.0, 3.0, 9.0, 4.0, 8.0, 0.0, 0.0, 2.0, 197.0, 193.0, 59.0, 10.0, 17.0, 28.0, 1.0, 15.0, 12.0, 15.0, 20.0, 2.0, 28.0, 6.0, 78.0, 22.0, 5.0, 3.0, 56.0, 67.0, 24.0, 17.0, 12.0, 50.0, 17.0, 7.0, 1.0, 10.0, 20.0, 23.0, 25.0, 32.0, 14.0, 30.0, 2.0, 8.0, 0.0, 5.0, 7.0, 0.0, 34.0, 32.0, 21.0, 25.0, 1.0, 13.0, 44.0, 14.0, 6.0, 2.0, 3.0, 6.0, 49.0, 56.0, 0.0, 5.0, 21.0, 18.0, 16.0, 13.0, 5.0, 1.0, 53.0, 48.0, 4.0, 43.0, 13.0, 21.0, 16.0, 15.0, 33.0, 45.0, 18.0, 17.0, 1.0, 4.0, 9.0, 21.0, 22.0, 26.0, 13.0, 33.0, 6.0, 5.0, 14.0, 14.0, 8.0, 18.0, 15.0, 34.0, 18.0, 5.0, 2.0, 33.0, 22.0, 26.0, 14.0, 42.0, 43.0, 75.0, 5.0, 2.0, 6.0, 3.0, 10.0, 1.0, 7.0, 7.0, 2.0, 54.0, 140.0, 31.0, 4.0, 9.0, 2.0, 27.0, 87.0, 30.0, 33.0, 4.0, 9.0, 9.0, 4.0, 4.0, 28.0, 9.0, 1.0, 47.0, 12.0, 19.0, 5.0, 18.0, 24.0, 10.0, 19.0, 20.0, 2.0, 9.0, 35.0, 19.0, 27.0, 5.0, 1.0, 6.0, 15.0, 11.0, 4.0, 4.0, 21.0, 31.0, 0.0, 2.0, 2.0, 1.0, 11.0, 3.0, 6.0, 92.0, 0.0, 1.0, 7.0, 0.0, 5.0, 21.0, 11.0, 15.0, 5.0, 3.0, 11.0, 5.0, 9.0, 4.0, 10.0, 60.0, 20.0, 67.0, 17.0, 8.0, 0.0, 50.0, 2.0, 8.0, 59.0, 7.0, 0.0, 3.0, 3.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7675656887030243, "mean_inference_ms": 2.0193929148613, "mean_action_processing_ms": 0.3252533494104855, "mean_env_wait_ms": 0.263489196774615, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045013427734375, "StateBufferConnector_ms": 0.0068312883377075195, "ViewRequirementAgentConnector_ms": 0.1972733736038208}, "num_episodes": 18, "episode_return_max": 368.1, "episode_return_min": -48.10000000000041, "episode_return_mean": 152.40399999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.8359662070974, "num_env_steps_trained_throughput_per_sec": 315.8359662070974, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 12802.17, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12802.11, "sample_time_ms": 2299.498, "learn_time_ms": 10473.853, "learn_throughput": 381.903, "synch_weights_time_ms": 25.46}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "f0d88_00000", "date": "2024-08-14_10-58-23", "timestamp": 1723647503, "time_this_iter_s": 12.746377944946289, "time_total_s": 720.4355947971344, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad5954c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 720.4355947971344, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 52.199999999999996, "ram_util_percent": 81.78888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.850667661113083, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.3423804457856234, "policy_loss": -0.014941209423720403, "vf_loss": 3.3431506223779506, "vf_explained_var": 0.17869492614710772, "kl": 0.00933072648329809, "entropy": 1.0644149151744036, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.483742571192444, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 3.309606966896663, "policy_loss": -0.01672887305492565, "vf_loss": 3.308090296245757, "vf_explained_var": 0.36551106480694323, "kl": 0.01067869431870051, "entropy": 1.0549416024218161, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 368.1, "episode_reward_min": -68.99999999999994, "episode_reward_mean": 145.25099999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": 50.28049999999999, "predator_policy": 22.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [364.4, 34.50000000000022, 125.89999999999972, 323.5, 32.00000000000018, 272.4, 110.2999999999999, 22.800000000000015, 314.79999999999995, 165.7000000000001, 36.300000000000246, 195.99999999999937, 94.19999999999942, 205.29999999999936, 23.100000000000442, 137.9999999999997, 294.20000000000005, 165.19999999999953, 64.00000000000034, 336.0, 210.8999999999993, 161.49999999999957, -0.49999999999982836, 157.69999999999894, 195.89999999999935, 352.7, 187.4999999999996, 222.49999999999946, 14.700000000000015, 96.89999999999935, 161.49999999999957, 209.69999999999968, 55.40000000000005, 204.19999999999933, 34.30000000000021, 200.99999999999935, 28.80000000000012, 103.49999999999986, -31.9999999999998, 326.30000000000007, 160.19999999999956, 110.49999999999997, 149.59999999999962, 34.00000000000024, 35.40000000000023, 306.5000000000001, 20.500000000000096, 193.6999999999994, 176.69999999999945, 19.400000000000002, 323.20000000000005, 52.200000000000486, 245.8, 152.39999999999958, 34.40000000000022, 154.49999999999957, 37.500000000000256, 152.5999999999996, 37.80000000000027, 38.80000000000028, 135.2999999999996, 69.30000000000004, 180.19999999999945, 34.10000000000018, 312.90000000000003, 368.1, 217.49999999999926, 178.09999999999945, 197.59999999999937, 180.7999999999999, 212.5, 193.99999999999937, 95.1, 191.8999999999994, 108.99999999999986, 313.0, 184.79999999999941, 34.50000000000022, 245.0, 53.80000000000007, -68.99999999999994, 5.200000000000003, 47.400000000000425, 217.09999999999926, 272.8999999999999, 201.99999999999935, 158.79999999999953, 179.59999999999945, 96.59999999999987, 198.69999999999936, 190.9999999999994, 334.40000000000003, -24.99999999999985, 21.100000000000016, 51.600000000000115, -64.10000000000034, 55.79999999999991, 91.39999999999993, 274.4, 130.89999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.3, 184.10000000000002, 9.499999999999964, 20.000000000000014, 5.299999999999965, 113.59999999999998, 153.5, 104.0, -0.9999999999999846, -12.99999999999982, 137.3, 121.09999999999998, 61.699999999999996, -9.399999999999855, 7.399999999999965, 7.399999999999965, 145.1, 160.7, -51.400000000000006, 112.10000000000008, 20.000000000000014, 11.299999999999965, 137.0, 20.000000000000014, -16.899999999999743, 82.09999999999974, 130.09999999999997, 69.19999999999969, 40.70000000000025, -118.59999999999987, 71.0, 20.000000000000014, 128.0, 132.2, 111.5, 22.700000000000053, 20.000000000000014, -33.999999999999844, 146.0, 155.0, 17.899999999999988, 188.0, -11.499999999999833, 143.0, 17.899999999999988, -66.40000000000083, -22.299999999999805, 133.99999999999966, 167.0, 17.899999999999988, 175.7, 149.0, 97.3999999999997, 64.09999999999998, 98.0, 75.49999999999946, -9.399999999999862, 1.0999999999999865, 15.799999999999963, 46.10000000000008, -33.99999999999983, 147.5, 130.70000000000002, 23.000000000000085, -70.6000000000003, 8.0, 15.799999999999963, 181.4, 9.499999999999964, 15.799999999999946, 170.0, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 15.799999999999963, 31.700000000000003, 20.000000000000014, -223.0, 145.1, 168.2, 15.799999999999963, 115.4, -81.09999999999997, 74.60000000000002, 101.0, 11.599999999999964, 7.399999999999987, 8.599999999999968, 7.399999999999979, 20.000000000000014, 126.49999999999997, 143.0, 17.899999999999988, -45.399999999999835, 164.0, -1.3000000000000136, 144.2, 9.499999999999964, 17.899999999999988, -32.49999999999978, 136.4, 147.8, 40.100000000000236, 1.0999999999999865, 59.0, 132.8, 9.499999999999964, 110.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, 108.5, 11.599999999999964, 17.899999999999984, 80.60000000000001, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, 20.000000000000014, 113.89999999999999, 7.399999999999965, -173.20000000000027, 144.5, 17.899999999999988, 161.3, 7.099999999999966, 20.000000000000014, 137.0, 149.89999999999998, 199.1, 143.0, 200.0, 9.499999999999964, 152.6, 9.499999999999964, 173.0, 11.599999999999964, 20.0, 90.80000000000004, 30.5, 95.0, 20.000000000000014, 149.0, 32.0, 13.099999999999994, 16.69999999999997, 165.2, 23.0, 20.000000000000014, 168.5, 141.5, 157.10000000000002, 13.699999999999964, 9.499999999999964, 20.000000000000014, 101.0, 86.0, 15.799999999999963, -27.99999999999997, -319.0, 20.000000000000014, -98.19999999999999, -31.599999999999994, 19.40000000000001, 20.000000000000014, 197.3, 15.799999999999963, 199.1, 18.799999999999613, 3.1999999999999615, 183.8, 20.000000000000014, 138.79999999999998, 11.599999999999964, 146.0, 32.0, -57.39999999999992, 186.5, 3.1999999999999615, 155.0, 20.000000000000014, 127.39999999999998, 200.0, -300.7, 58.70000000000022, -181.9, -94.0, 20.000000000000014, -45.400000000000006, -189.10000000000002, -0.9999999999999846, -67.0, 30.800000000000196, 50.0, -34.59999999999977, 127.4, 89.0, 33.499999999999915, 10.399999999999972], "policy_predator_policy_reward": [2.0, 8.0, 0.0, 5.0, 7.0, 0.0, 34.0, 32.0, 21.0, 25.0, 1.0, 13.0, 44.0, 14.0, 6.0, 2.0, 3.0, 6.0, 49.0, 56.0, 0.0, 5.0, 21.0, 18.0, 16.0, 13.0, 5.0, 1.0, 53.0, 48.0, 4.0, 43.0, 13.0, 21.0, 16.0, 15.0, 33.0, 45.0, 18.0, 17.0, 1.0, 4.0, 9.0, 21.0, 22.0, 26.0, 13.0, 33.0, 6.0, 5.0, 14.0, 14.0, 8.0, 18.0, 15.0, 34.0, 18.0, 5.0, 2.0, 33.0, 22.0, 26.0, 14.0, 42.0, 43.0, 75.0, 5.0, 2.0, 6.0, 3.0, 10.0, 1.0, 7.0, 7.0, 2.0, 54.0, 140.0, 31.0, 4.0, 9.0, 2.0, 27.0, 87.0, 30.0, 33.0, 4.0, 9.0, 9.0, 4.0, 4.0, 28.0, 9.0, 1.0, 47.0, 12.0, 19.0, 5.0, 18.0, 24.0, 10.0, 19.0, 20.0, 2.0, 9.0, 35.0, 19.0, 27.0, 5.0, 1.0, 6.0, 15.0, 11.0, 4.0, 4.0, 21.0, 31.0, 0.0, 2.0, 2.0, 1.0, 11.0, 3.0, 6.0, 92.0, 0.0, 1.0, 7.0, 0.0, 5.0, 21.0, 11.0, 15.0, 5.0, 3.0, 11.0, 5.0, 9.0, 4.0, 10.0, 60.0, 20.0, 67.0, 17.0, 8.0, 0.0, 50.0, 2.0, 8.0, 59.0, 7.0, 0.0, 3.0, 3.0, 11.0, 5.0, 0.0, 37.0, 21.0, 63.0, 3.0, 63.0, 167.0, 54.0, 81.0, 3.0, 5.0, 2.0, 2.0, 25.0, 30.0, 8.0, 7.0, 0.0, 0.0, 5.0, 17.0, 65.0, 57.0, 1.0, 8.0, 1.0, 15.0, 2.0, 5.0, 60.0, 157.0, 154.0, 143.0, 65.0, 12.0, 13.0, 113.0, 57.0, 35.0, 26.0, 50.0, 13.0, 45.0, 47.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7745615259673042, "mean_inference_ms": 2.035975695496946, "mean_action_processing_ms": 0.32696144595851045, "mean_env_wait_ms": 0.2653392832219359, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0051991939544677734, "StateBufferConnector_ms": 0.006253600120544434, "ViewRequirementAgentConnector_ms": 0.19243288040161133}, "num_episodes": 23, "episode_return_max": 368.1, "episode_return_min": -68.99999999999994, "episode_return_mean": 145.25099999999983, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.42759549936915, "num_env_steps_trained_throughput_per_sec": 326.42759549936915, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 12865.965, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12865.906, "sample_time_ms": 2339.602, "learn_time_ms": 10499.282, "learn_throughput": 380.978, "synch_weights_time_ms": 23.963}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "f0d88_00000", "date": "2024-08-14_10-58-35", "timestamp": 1723647515, "time_this_iter_s": 12.258364915847778, "time_total_s": 732.6939597129822, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad595700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 732.6939597129822, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 48.9, "ram_util_percent": 81.52352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4944551165141757, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.2449596710306, "policy_loss": -0.0198027280972354, "vf_loss": 4.248401318529926, "vf_explained_var": -0.13576676656329442, "kl": 0.010772725230362056, "entropy": 1.1700794213663332, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.19347648595376, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 4.230795245952707, "policy_loss": -0.012566409825234028, "vf_loss": 4.225794849698506, "vf_explained_var": 0.210800340692833, "kl": 0.010281439352802636, "entropy": 0.9699989193961733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 368.1, "episode_reward_min": -107.90000000000023, "episode_reward_mean": 122.13299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -324.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": 33.011499999999984, "predator_policy": 28.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [64.00000000000034, 336.0, 210.8999999999993, 161.49999999999957, -0.49999999999982836, 157.69999999999894, 195.89999999999935, 352.7, 187.4999999999996, 222.49999999999946, 14.700000000000015, 96.89999999999935, 161.49999999999957, 209.69999999999968, 55.40000000000005, 204.19999999999933, 34.30000000000021, 200.99999999999935, 28.80000000000012, 103.49999999999986, -31.9999999999998, 326.30000000000007, 160.19999999999956, 110.49999999999997, 149.59999999999962, 34.00000000000024, 35.40000000000023, 306.5000000000001, 20.500000000000096, 193.6999999999994, 176.69999999999945, 19.400000000000002, 323.20000000000005, 52.200000000000486, 245.8, 152.39999999999958, 34.40000000000022, 154.49999999999957, 37.500000000000256, 152.5999999999996, 37.80000000000027, 38.80000000000028, 135.2999999999996, 69.30000000000004, 180.19999999999945, 34.10000000000018, 312.90000000000003, 368.1, 217.49999999999926, 178.09999999999945, 197.59999999999937, 180.7999999999999, 212.5, 193.99999999999937, 95.1, 191.8999999999994, 108.99999999999986, 313.0, 184.79999999999941, 34.50000000000022, 245.0, 53.80000000000007, -68.99999999999994, 5.200000000000003, 47.400000000000425, 217.09999999999926, 272.8999999999999, 201.99999999999935, 158.79999999999953, 179.59999999999945, 96.59999999999987, 198.69999999999936, 190.9999999999994, 334.40000000000003, -24.99999999999985, 21.100000000000016, 51.600000000000115, -64.10000000000034, 55.79999999999991, 91.39999999999993, 274.4, 130.89999999999972, 26.1, 148.59999999999962, 154.7999999999994, 26.099999999999966, 25.700000000000067, -1.7999999999999057, 35.500000000000234, 35.40000000000032, 33.50000000000001, 66.70000000000017, 80.50000000000003, -62.30000000000029, -107.90000000000023, 39.700000000000294, 25.90000000000007, -17.499999999999915, 61.70000000000019, 36.100000000000236], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -33.999999999999844, 146.0, 155.0, 17.899999999999988, 188.0, -11.499999999999833, 143.0, 17.899999999999988, -66.40000000000083, -22.299999999999805, 133.99999999999966, 167.0, 17.899999999999988, 175.7, 149.0, 97.3999999999997, 64.09999999999998, 98.0, 75.49999999999946, -9.399999999999862, 1.0999999999999865, 15.799999999999963, 46.10000000000008, -33.99999999999983, 147.5, 130.70000000000002, 23.000000000000085, -70.6000000000003, 8.0, 15.799999999999963, 181.4, 9.499999999999964, 15.799999999999946, 170.0, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 15.799999999999963, 31.700000000000003, 20.000000000000014, -223.0, 145.1, 168.2, 15.799999999999963, 115.4, -81.09999999999997, 74.60000000000002, 101.0, 11.599999999999964, 7.399999999999987, 8.599999999999968, 7.399999999999979, 20.000000000000014, 126.49999999999997, 143.0, 17.899999999999988, -45.399999999999835, 164.0, -1.3000000000000136, 144.2, 9.499999999999964, 17.899999999999988, -32.49999999999978, 136.4, 147.8, 40.100000000000236, 1.0999999999999865, 59.0, 132.8, 9.499999999999964, 110.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, 108.5, 11.599999999999964, 17.899999999999984, 80.60000000000001, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, 20.000000000000014, 113.89999999999999, 7.399999999999965, -173.20000000000027, 144.5, 17.899999999999988, 161.3, 7.099999999999966, 20.000000000000014, 137.0, 149.89999999999998, 199.1, 143.0, 200.0, 9.499999999999964, 152.6, 9.499999999999964, 173.0, 11.599999999999964, 20.0, 90.80000000000004, 30.5, 95.0, 20.000000000000014, 149.0, 32.0, 13.099999999999994, 16.69999999999997, 165.2, 23.0, 20.000000000000014, 168.5, 141.5, 157.10000000000002, 13.699999999999964, 9.499999999999964, 20.000000000000014, 101.0, 86.0, 15.799999999999963, -27.99999999999997, -319.0, 20.000000000000014, -98.19999999999999, -31.599999999999994, 19.40000000000001, 20.000000000000014, 197.3, 15.799999999999963, 199.1, 18.799999999999613, 3.1999999999999615, 183.8, 20.000000000000014, 138.79999999999998, 11.599999999999964, 146.0, 32.0, -57.39999999999992, 186.5, 3.1999999999999615, 155.0, 20.000000000000014, 127.39999999999998, 200.0, -300.7, 58.70000000000022, -181.9, -94.0, 20.000000000000014, -45.400000000000006, -189.10000000000002, -0.9999999999999846, -67.0, 30.800000000000196, 50.0, -34.59999999999977, 127.4, 89.0, 33.499999999999915, 10.399999999999972, -324.39999999999986, 186.5, -89.20000000000067, 183.8, 11.599999999999975, 114.19999999999999, -127.6, 13.699999999999964, -5.1999999999999265, 17.899999999999988, -110.80000000000052, -76.0, 11.599999999999964, 17.899999999999988, -25.60000000000035, 20.000000000000014, -119.50000000000003, -130.0, 1.6999999999999729, 23.000000000000085, -223.0, 102.5, -3.099999999999958, -152.2000000000006, -11.499999999999819, -290.40000000000003, 20.000000000000014, 13.699999999999964, 9.499999999999966, 7.399999999999965, -127.30000000000001, 15.799999999999963, 10.699999999999974, -43.0, 20.000000000000014, -97.9], "policy_predator_policy_reward": [33.0, 45.0, 18.0, 17.0, 1.0, 4.0, 9.0, 21.0, 22.0, 26.0, 13.0, 33.0, 6.0, 5.0, 14.0, 14.0, 8.0, 18.0, 15.0, 34.0, 18.0, 5.0, 2.0, 33.0, 22.0, 26.0, 14.0, 42.0, 43.0, 75.0, 5.0, 2.0, 6.0, 3.0, 10.0, 1.0, 7.0, 7.0, 2.0, 54.0, 140.0, 31.0, 4.0, 9.0, 2.0, 27.0, 87.0, 30.0, 33.0, 4.0, 9.0, 9.0, 4.0, 4.0, 28.0, 9.0, 1.0, 47.0, 12.0, 19.0, 5.0, 18.0, 24.0, 10.0, 19.0, 20.0, 2.0, 9.0, 35.0, 19.0, 27.0, 5.0, 1.0, 6.0, 15.0, 11.0, 4.0, 4.0, 21.0, 31.0, 0.0, 2.0, 2.0, 1.0, 11.0, 3.0, 6.0, 92.0, 0.0, 1.0, 7.0, 0.0, 5.0, 21.0, 11.0, 15.0, 5.0, 3.0, 11.0, 5.0, 9.0, 4.0, 10.0, 60.0, 20.0, 67.0, 17.0, 8.0, 0.0, 50.0, 2.0, 8.0, 59.0, 7.0, 0.0, 3.0, 3.0, 11.0, 5.0, 0.0, 37.0, 21.0, 63.0, 3.0, 63.0, 167.0, 54.0, 81.0, 3.0, 5.0, 2.0, 2.0, 25.0, 30.0, 8.0, 7.0, 0.0, 0.0, 5.0, 17.0, 65.0, 57.0, 1.0, 8.0, 1.0, 15.0, 2.0, 5.0, 60.0, 157.0, 154.0, 143.0, 65.0, 12.0, 13.0, 113.0, 57.0, 35.0, 26.0, 50.0, 13.0, 45.0, 47.0, 40.0, 0.0, 164.0, 2.0, 52.0, 4.0, 25.0, 70.0, 70.0, 12.0, 1.0, 76.0, 109.0, 4.0, 2.0, 0.0, 41.0, 125.0, 158.0, 35.0, 7.0, 132.0, 69.0, 82.0, 11.0, 29.0, 165.0, 3.0, 3.0, 7.0, 2.0, 92.0, 2.0, 82.0, 12.0, 33.0, 81.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7791511970937086, "mean_inference_ms": 2.0455038403669783, "mean_action_processing_ms": 0.3279934736655727, "mean_env_wait_ms": 0.266390614371853, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005224704742431641, "StateBufferConnector_ms": 0.006223440170288086, "ViewRequirementAgentConnector_ms": 0.19039642810821533}, "num_episodes": 18, "episode_return_max": 368.1, "episode_return_min": -107.90000000000023, "episode_return_mean": 122.13299999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.8648180659871, "num_env_steps_trained_throughput_per_sec": 322.8648180659871, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 12917.594, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12917.535, "sample_time_ms": 2362.391, "learn_time_ms": 10528.324, "learn_throughput": 379.928, "synch_weights_time_ms": 23.715}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "f0d88_00000", "date": "2024-08-14_10-58-48", "timestamp": 1723647528, "time_this_iter_s": 12.395936012268066, "time_total_s": 745.0898957252502, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0eb0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 745.0898957252502, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 52.81666666666667, "ram_util_percent": 81.73333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9450270718367642, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.593442736100898, "policy_loss": -0.011180026042299769, "vf_loss": 4.58678977174103, "vf_explained_var": -0.4350314874182302, "kl": 0.011741883767769955, "entropy": 1.097615797368307, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.904600660069279, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 4.60368118904255, "policy_loss": -0.010041247132584138, "vf_loss": 4.5930815444421516, "vf_explained_var": 0.2082240361700613, "kl": 0.012080634130402664, "entropy": 1.0419516849770116, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 368.1, "episode_reward_min": -107.90000000000023, "episode_reward_mean": 105.5909999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -324.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": 20.24049999999997, "predator_policy": 32.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.80000000000012, 103.49999999999986, -31.9999999999998, 326.30000000000007, 160.19999999999956, 110.49999999999997, 149.59999999999962, 34.00000000000024, 35.40000000000023, 306.5000000000001, 20.500000000000096, 193.6999999999994, 176.69999999999945, 19.400000000000002, 323.20000000000005, 52.200000000000486, 245.8, 152.39999999999958, 34.40000000000022, 154.49999999999957, 37.500000000000256, 152.5999999999996, 37.80000000000027, 38.80000000000028, 135.2999999999996, 69.30000000000004, 180.19999999999945, 34.10000000000018, 312.90000000000003, 368.1, 217.49999999999926, 178.09999999999945, 197.59999999999937, 180.7999999999999, 212.5, 193.99999999999937, 95.1, 191.8999999999994, 108.99999999999986, 313.0, 184.79999999999941, 34.50000000000022, 245.0, 53.80000000000007, -68.99999999999994, 5.200000000000003, 47.400000000000425, 217.09999999999926, 272.8999999999999, 201.99999999999935, 158.79999999999953, 179.59999999999945, 96.59999999999987, 198.69999999999936, 190.9999999999994, 334.40000000000003, -24.99999999999985, 21.100000000000016, 51.600000000000115, -64.10000000000034, 55.79999999999991, 91.39999999999993, 274.4, 130.89999999999972, 26.1, 148.59999999999962, 154.7999999999994, 26.099999999999966, 25.700000000000067, -1.7999999999999057, 35.500000000000234, 35.40000000000032, 33.50000000000001, 66.70000000000017, 80.50000000000003, -62.30000000000029, -107.90000000000023, 39.700000000000294, 25.90000000000007, -17.499999999999915, 61.70000000000019, 36.100000000000236, -63.99999999999994, 247.29999999999959, 31.100000000000165, -34.7999999999998, 173.09999999999948, 131.3999999999997, 66.90000000000015, 114.79999999999916, 128.3999999999995, 56.10000000000011, 113.09999999999951, 62.60000000000005, 103.0, -33.49999999999964, -23.09999999999983, 42.600000000000165, 17.200000000000006, 79.50000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 3.1999999999999615, 15.799999999999963, 31.700000000000003, 20.000000000000014, -223.0, 145.1, 168.2, 15.799999999999963, 115.4, -81.09999999999997, 74.60000000000002, 101.0, 11.599999999999964, 7.399999999999987, 8.599999999999968, 7.399999999999979, 20.000000000000014, 126.49999999999997, 143.0, 17.899999999999988, -45.399999999999835, 164.0, -1.3000000000000136, 144.2, 9.499999999999964, 17.899999999999988, -32.49999999999978, 136.4, 147.8, 40.100000000000236, 1.0999999999999865, 59.0, 132.8, 9.499999999999964, 110.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, 108.5, 11.599999999999964, 17.899999999999984, 80.60000000000001, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, 20.000000000000014, 113.89999999999999, 7.399999999999965, -173.20000000000027, 144.5, 17.899999999999988, 161.3, 7.099999999999966, 20.000000000000014, 137.0, 149.89999999999998, 199.1, 143.0, 200.0, 9.499999999999964, 152.6, 9.499999999999964, 173.0, 11.599999999999964, 20.0, 90.80000000000004, 30.5, 95.0, 20.000000000000014, 149.0, 32.0, 13.099999999999994, 16.69999999999997, 165.2, 23.0, 20.000000000000014, 168.5, 141.5, 157.10000000000002, 13.699999999999964, 9.499999999999964, 20.000000000000014, 101.0, 86.0, 15.799999999999963, -27.99999999999997, -319.0, 20.000000000000014, -98.19999999999999, -31.599999999999994, 19.40000000000001, 20.000000000000014, 197.3, 15.799999999999963, 199.1, 18.799999999999613, 3.1999999999999615, 183.8, 20.000000000000014, 138.79999999999998, 11.599999999999964, 146.0, 32.0, -57.39999999999992, 186.5, 3.1999999999999615, 155.0, 20.000000000000014, 127.39999999999998, 200.0, -300.7, 58.70000000000022, -181.9, -94.0, 20.000000000000014, -45.400000000000006, -189.10000000000002, -0.9999999999999846, -67.0, 30.800000000000196, 50.0, -34.59999999999977, 127.4, 89.0, 33.499999999999915, 10.399999999999972, -324.39999999999986, 186.5, -89.20000000000067, 183.8, 11.599999999999975, 114.19999999999999, -127.6, 13.699999999999964, -5.1999999999999265, 17.899999999999988, -110.80000000000052, -76.0, 11.599999999999964, 17.899999999999988, -25.60000000000035, 20.000000000000014, -119.50000000000003, -130.0, 1.6999999999999729, 23.000000000000085, -223.0, 102.5, -3.099999999999958, -152.2000000000006, -11.499999999999819, -290.40000000000003, 20.000000000000014, 13.699999999999964, 9.499999999999966, 7.399999999999965, -127.30000000000001, 15.799999999999963, 10.699999999999974, -43.0, 20.000000000000014, -97.9, -103.00000000000028, -223.0, 102.49999999999952, 132.8, 20.000000000000014, 1.0999999999999865, -13.599999999999932, -68.20000000000043, 7.399999999999965, 133.69999999999996, -31.59999999999978, 97.99999999999999, -18.099999999999753, -13.0, 15.799999999999962, 76.9999999999996, 79.69999999999985, 13.699999999999964, 68.0, -124.90000000000069, 94.69999999999939, -160.60000000000002, 17.299999999999997, -42.699999999999925, -31.0, 20.0, -49.299999999999876, -128.2000000000005, -171.10000000000056, -36.99999999999997, 17.899999999999988, -43.3, 5.299999999999965, -3.099999999999958, 20.000000000000014, -14.5], "policy_predator_policy_reward": [7.0, 7.0, 2.0, 54.0, 140.0, 31.0, 4.0, 9.0, 2.0, 27.0, 87.0, 30.0, 33.0, 4.0, 9.0, 9.0, 4.0, 4.0, 28.0, 9.0, 1.0, 47.0, 12.0, 19.0, 5.0, 18.0, 24.0, 10.0, 19.0, 20.0, 2.0, 9.0, 35.0, 19.0, 27.0, 5.0, 1.0, 6.0, 15.0, 11.0, 4.0, 4.0, 21.0, 31.0, 0.0, 2.0, 2.0, 1.0, 11.0, 3.0, 6.0, 92.0, 0.0, 1.0, 7.0, 0.0, 5.0, 21.0, 11.0, 15.0, 5.0, 3.0, 11.0, 5.0, 9.0, 4.0, 10.0, 60.0, 20.0, 67.0, 17.0, 8.0, 0.0, 50.0, 2.0, 8.0, 59.0, 7.0, 0.0, 3.0, 3.0, 11.0, 5.0, 0.0, 37.0, 21.0, 63.0, 3.0, 63.0, 167.0, 54.0, 81.0, 3.0, 5.0, 2.0, 2.0, 25.0, 30.0, 8.0, 7.0, 0.0, 0.0, 5.0, 17.0, 65.0, 57.0, 1.0, 8.0, 1.0, 15.0, 2.0, 5.0, 60.0, 157.0, 154.0, 143.0, 65.0, 12.0, 13.0, 113.0, 57.0, 35.0, 26.0, 50.0, 13.0, 45.0, 47.0, 40.0, 0.0, 164.0, 2.0, 52.0, 4.0, 25.0, 70.0, 70.0, 12.0, 1.0, 76.0, 109.0, 4.0, 2.0, 0.0, 41.0, 125.0, 158.0, 35.0, 7.0, 132.0, 69.0, 82.0, 11.0, 29.0, 165.0, 3.0, 3.0, 7.0, 2.0, 92.0, 2.0, 82.0, 12.0, 33.0, 81.0, 143.0, 119.0, 9.0, 3.0, 9.0, 1.0, 42.0, 5.0, 20.0, 12.0, 48.0, 17.0, 71.0, 27.0, 9.0, 13.0, 32.0, 3.0, 44.0, 69.0, 98.0, 81.0, 66.0, 22.0, 74.0, 40.0, 82.0, 62.0, 40.0, 145.0, 67.0, 1.0, 11.0, 4.0, 44.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7826706504109973, "mean_inference_ms": 2.052565627219569, "mean_action_processing_ms": 0.3287458540233872, "mean_env_wait_ms": 0.26718956663336785, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005418658256530762, "StateBufferConnector_ms": 0.006175994873046875, "ViewRequirementAgentConnector_ms": 0.17270994186401367}, "num_episodes": 18, "episode_return_max": 368.1, "episode_return_min": -107.90000000000023, "episode_return_mean": 105.5909999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.388168075934, "num_env_steps_trained_throughput_per_sec": 316.388168075934, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 12896.679, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12896.621, "sample_time_ms": 2418.437, "learn_time_ms": 10458.811, "learn_throughput": 382.453, "synch_weights_time_ms": 16.483}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "f0d88_00000", "date": "2024-08-14_10-59-00", "timestamp": 1723647540, "time_this_iter_s": 12.685962200164795, "time_total_s": 757.775857925415, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0eb4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 757.775857925415, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 50.25555555555556, "ram_util_percent": 82.25555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.941164521975492, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.431910295208926, "policy_loss": -0.0132003377733762, "vf_loss": 4.4278466323065375, "vf_explained_var": -0.3801264864742441, "kl": 0.011367243369615357, "entropy": 1.134409178186346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2797479258643256, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 4.600436845910612, "policy_loss": -0.010707198850386752, "vf_loss": 4.591144272637746, "vf_explained_var": 0.13476487618905528, "kl": 0.011705395395036913, "entropy": 1.0488384068642975, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 368.1, "episode_reward_min": -107.90000000000023, "episode_reward_mean": 92.0059999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -324.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": 9.822999999999956, "predator_policy": 36.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 38.80000000000028, 135.2999999999996, 69.30000000000004, 180.19999999999945, 34.10000000000018, 312.90000000000003, 368.1, 217.49999999999926, 178.09999999999945, 197.59999999999937, 180.7999999999999, 212.5, 193.99999999999937, 95.1, 191.8999999999994, 108.99999999999986, 313.0, 184.79999999999941, 34.50000000000022, 245.0, 53.80000000000007, -68.99999999999994, 5.200000000000003, 47.400000000000425, 217.09999999999926, 272.8999999999999, 201.99999999999935, 158.79999999999953, 179.59999999999945, 96.59999999999987, 198.69999999999936, 190.9999999999994, 334.40000000000003, -24.99999999999985, 21.100000000000016, 51.600000000000115, -64.10000000000034, 55.79999999999991, 91.39999999999993, 274.4, 130.89999999999972, 26.1, 148.59999999999962, 154.7999999999994, 26.099999999999966, 25.700000000000067, -1.7999999999999057, 35.500000000000234, 35.40000000000032, 33.50000000000001, 66.70000000000017, 80.50000000000003, -62.30000000000029, -107.90000000000023, 39.700000000000294, 25.90000000000007, -17.499999999999915, 61.70000000000019, 36.100000000000236, -63.99999999999994, 247.29999999999959, 31.100000000000165, -34.7999999999998, 173.09999999999948, 131.3999999999997, 66.90000000000015, 114.79999999999916, 128.3999999999995, 56.10000000000011, 113.09999999999951, 62.60000000000005, 103.0, -33.49999999999964, -23.09999999999983, 42.600000000000165, 17.200000000000006, 79.50000000000006, -54.10000000000029, 65.60000000000001, -9.199999999999967, 22.80000000000004, 33.500000000000206, 202.9999999999991, 106.99999999999983, 141.60000000000005, 89.7, 117.8999999999993, 40.80000000000031, 70.5, 105.39999999999927, 35.600000000000236, 63.50000000000042, 172.69999999999948, -71.80000000000013, 34.800000000000345, 5.500000000000005, 126.39999999999966, 38.60000000000028, 87.40000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 15.799999999999963, 15.799999999999963, 20.000000000000014, 113.89999999999999, 7.399999999999965, -173.20000000000027, 144.5, 17.899999999999988, 161.3, 7.099999999999966, 20.000000000000014, 137.0, 149.89999999999998, 199.1, 143.0, 200.0, 9.499999999999964, 152.6, 9.499999999999964, 173.0, 11.599999999999964, 20.0, 90.80000000000004, 30.5, 95.0, 20.000000000000014, 149.0, 32.0, 13.099999999999994, 16.69999999999997, 165.2, 23.0, 20.000000000000014, 168.5, 141.5, 157.10000000000002, 13.699999999999964, 9.499999999999964, 20.000000000000014, 101.0, 86.0, 15.799999999999963, -27.99999999999997, -319.0, 20.000000000000014, -98.19999999999999, -31.599999999999994, 19.40000000000001, 20.000000000000014, 197.3, 15.799999999999963, 199.1, 18.799999999999613, 3.1999999999999615, 183.8, 20.000000000000014, 138.79999999999998, 11.599999999999964, 146.0, 32.0, -57.39999999999992, 186.5, 3.1999999999999615, 155.0, 20.000000000000014, 127.39999999999998, 200.0, -300.7, 58.70000000000022, -181.9, -94.0, 20.000000000000014, -45.400000000000006, -189.10000000000002, -0.9999999999999846, -67.0, 30.800000000000196, 50.0, -34.59999999999977, 127.4, 89.0, 33.499999999999915, 10.399999999999972, -324.39999999999986, 186.5, -89.20000000000067, 183.8, 11.599999999999975, 114.19999999999999, -127.6, 13.699999999999964, -5.1999999999999265, 17.899999999999988, -110.80000000000052, -76.0, 11.599999999999964, 17.899999999999988, -25.60000000000035, 20.000000000000014, -119.50000000000003, -130.0, 1.6999999999999729, 23.000000000000085, -223.0, 102.5, -3.099999999999958, -152.2000000000006, -11.499999999999819, -290.40000000000003, 20.000000000000014, 13.699999999999964, 9.499999999999966, 7.399999999999965, -127.30000000000001, 15.799999999999963, 10.699999999999974, -43.0, 20.000000000000014, -97.9, -103.00000000000028, -223.0, 102.49999999999952, 132.8, 20.000000000000014, 1.0999999999999865, -13.599999999999932, -68.20000000000043, 7.399999999999965, 133.69999999999996, -31.59999999999978, 97.99999999999999, -18.099999999999753, -13.0, 15.799999999999962, 76.9999999999996, 79.69999999999985, 13.699999999999964, 68.0, -124.90000000000069, 94.69999999999939, -160.60000000000002, 17.299999999999997, -42.699999999999925, -31.0, 20.0, -49.299999999999876, -128.2000000000005, -171.10000000000056, -36.99999999999997, 17.899999999999988, -43.3, 5.299999999999965, -3.099999999999958, 20.000000000000014, -14.5, -95.20000000000036, -136.9, -119.20000000000016, 24.80000000000009, 20.000000000000014, -140.2, -102.10000000000062, -36.099999999999994, 9.499999999999964, 4.999999999999966, 9.799999999999981, 144.19999999999976, 20.000000000000014, -55.0, -12.099999999999987, 76.69999999999999, 12.500000000000014, -2.799999999999997, -15.099999999999778, 82.99999999999976, 20.000000000000014, 15.79999999999996, 146.0, -245.50000000000009, 1.0999999999999865, 65.3, 11.599999999999964, 20.000000000000014, 34.400000000000254, 7.099999999999989, 154.1, 11.599999999999964, -148.0, -59.800000000000026, 13.699999999999964, -31.899999999999856, -65.50000000000071, 20.000000000000014, 106.39999999999995, 20.000000000000014, 11.599999999999964, 20.000000000000014, 7.399999999999965, 11.0], "policy_predator_policy_reward": [0.0, 2.0, 2.0, 1.0, 11.0, 3.0, 6.0, 92.0, 0.0, 1.0, 7.0, 0.0, 5.0, 21.0, 11.0, 15.0, 5.0, 3.0, 11.0, 5.0, 9.0, 4.0, 10.0, 60.0, 20.0, 67.0, 17.0, 8.0, 0.0, 50.0, 2.0, 8.0, 59.0, 7.0, 0.0, 3.0, 3.0, 11.0, 5.0, 0.0, 37.0, 21.0, 63.0, 3.0, 63.0, 167.0, 54.0, 81.0, 3.0, 5.0, 2.0, 2.0, 25.0, 30.0, 8.0, 7.0, 0.0, 0.0, 5.0, 17.0, 65.0, 57.0, 1.0, 8.0, 1.0, 15.0, 2.0, 5.0, 60.0, 157.0, 154.0, 143.0, 65.0, 12.0, 13.0, 113.0, 57.0, 35.0, 26.0, 50.0, 13.0, 45.0, 47.0, 40.0, 0.0, 164.0, 2.0, 52.0, 4.0, 25.0, 70.0, 70.0, 12.0, 1.0, 76.0, 109.0, 4.0, 2.0, 0.0, 41.0, 125.0, 158.0, 35.0, 7.0, 132.0, 69.0, 82.0, 11.0, 29.0, 165.0, 3.0, 3.0, 7.0, 2.0, 92.0, 2.0, 82.0, 12.0, 33.0, 81.0, 143.0, 119.0, 9.0, 3.0, 9.0, 1.0, 42.0, 5.0, 20.0, 12.0, 48.0, 17.0, 71.0, 27.0, 9.0, 13.0, 32.0, 3.0, 44.0, 69.0, 98.0, 81.0, 66.0, 22.0, 74.0, 40.0, 82.0, 62.0, 40.0, 145.0, 67.0, 1.0, 11.0, 4.0, 44.0, 30.0, 84.0, 94.0, 62.0, 98.0, 111.0, 0.0, 130.0, 31.0, 10.0, 9.0, 21.0, 28.0, 79.0, 63.0, 75.0, 2.0, 63.0, 17.0, 25.0, 25.0, 0.0, 5.0, 53.0, 117.0, 19.0, 20.0, 0.0, 4.0, 8.0, 14.0, 3.0, 4.0, 68.0, 68.0, 4.0, 49.0, 0.0, 51.0, 0.0, 0.0, 3.0, 4.0, 63.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7858650033243387, "mean_inference_ms": 2.0588841968015585, "mean_action_processing_ms": 0.32948949318629434, "mean_env_wait_ms": 0.2677790930974267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00566864013671875, "StateBufferConnector_ms": 0.005692601203918457, "ViewRequirementAgentConnector_ms": 0.16295361518859863}, "num_episodes": 22, "episode_return_max": 368.1, "episode_return_min": -107.90000000000023, "episode_return_mean": 92.0059999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.16897845557037, "num_env_steps_trained_throughput_per_sec": 318.16897845557037, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 12667.624, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12667.578, "sample_time_ms": 2211.889, "learn_time_ms": 10440.195, "learn_throughput": 383.135, "synch_weights_time_ms": 13.063}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "f0d88_00000", "date": "2024-08-14_10-59-13", "timestamp": 1723647553, "time_this_iter_s": 12.624148845672607, "time_total_s": 770.4000067710876, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad595700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 770.4000067710876, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 49.766666666666666, "ram_util_percent": 81.95555555555558}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.785026907416248, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.592244423634161, "policy_loss": -0.016135746769597212, "vf_loss": 5.588412623430686, "vf_explained_var": -0.6612844689813241, "kl": 0.013147352102488755, "entropy": 1.1985275870908505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.637926837565407, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 6.452188313701165, "policy_loss": -0.010747835182377862, "vf_loss": 6.444133180032963, "vf_explained_var": -0.007081387503437264, "kl": 0.011004931883792847, "entropy": 1.0447184094360897, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 334.40000000000003, "episode_reward_min": -153.5000000000002, "episode_reward_mean": 59.4479999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -327.99999999999983, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 165.0}, "policy_reward_mean": {"prey_policy": -16.466000000000037, "predator_policy": 46.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.200000000000003, 47.400000000000425, 217.09999999999926, 272.8999999999999, 201.99999999999935, 158.79999999999953, 179.59999999999945, 96.59999999999987, 198.69999999999936, 190.9999999999994, 334.40000000000003, -24.99999999999985, 21.100000000000016, 51.600000000000115, -64.10000000000034, 55.79999999999991, 91.39999999999993, 274.4, 130.89999999999972, 26.1, 148.59999999999962, 154.7999999999994, 26.099999999999966, 25.700000000000067, -1.7999999999999057, 35.500000000000234, 35.40000000000032, 33.50000000000001, 66.70000000000017, 80.50000000000003, -62.30000000000029, -107.90000000000023, 39.700000000000294, 25.90000000000007, -17.499999999999915, 61.70000000000019, 36.100000000000236, -63.99999999999994, 247.29999999999959, 31.100000000000165, -34.7999999999998, 173.09999999999948, 131.3999999999997, 66.90000000000015, 114.79999999999916, 128.3999999999995, 56.10000000000011, 113.09999999999951, 62.60000000000005, 103.0, -33.49999999999964, -23.09999999999983, 42.600000000000165, 17.200000000000006, 79.50000000000006, -54.10000000000029, 65.60000000000001, -9.199999999999967, 22.80000000000004, 33.500000000000206, 202.9999999999991, 106.99999999999983, 141.60000000000005, 89.7, 117.8999999999993, 40.80000000000031, 70.5, 105.39999999999927, 35.600000000000236, 63.50000000000042, 172.69999999999948, -71.80000000000013, 34.800000000000345, 5.500000000000005, 126.39999999999966, 38.60000000000028, 87.40000000000006, -16.999999999999837, 156.59999999999948, 153.39999999999924, -17.79999999999972, -8.599999999999959, 35.80000000000003, 40.80000000000032, -153.5000000000002, 165.5999999999993, -62.099999999999795, -47.89999999999969, 144.19999999999962, -92.70000000000022, -64.19999999999996, -49.59999999999984, 60.89999999999982, 40.10000000000031, -77.40000000000057, -3.3999999999997024, -93.3000000000001, 72.99999999999955, 79.00000000000003, -2.5999999999999654], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-98.19999999999999, -31.599999999999994, 19.40000000000001, 20.000000000000014, 197.3, 15.799999999999963, 199.1, 18.799999999999613, 3.1999999999999615, 183.8, 20.000000000000014, 138.79999999999998, 11.599999999999964, 146.0, 32.0, -57.39999999999992, 186.5, 3.1999999999999615, 155.0, 20.000000000000014, 127.39999999999998, 200.0, -300.7, 58.70000000000022, -181.9, -94.0, 20.000000000000014, -45.400000000000006, -189.10000000000002, -0.9999999999999846, -67.0, 30.800000000000196, 50.0, -34.59999999999977, 127.4, 89.0, 33.499999999999915, 10.399999999999972, -324.39999999999986, 186.5, -89.20000000000067, 183.8, 11.599999999999975, 114.19999999999999, -127.6, 13.699999999999964, -5.1999999999999265, 17.899999999999988, -110.80000000000052, -76.0, 11.599999999999964, 17.899999999999988, -25.60000000000035, 20.000000000000014, -119.50000000000003, -130.0, 1.6999999999999729, 23.000000000000085, -223.0, 102.5, -3.099999999999958, -152.2000000000006, -11.499999999999819, -290.40000000000003, 20.000000000000014, 13.699999999999964, 9.499999999999966, 7.399999999999965, -127.30000000000001, 15.799999999999963, 10.699999999999974, -43.0, 20.000000000000014, -97.9, -103.00000000000028, -223.0, 102.49999999999952, 132.8, 20.000000000000014, 1.0999999999999865, -13.599999999999932, -68.20000000000043, 7.399999999999965, 133.69999999999996, -31.59999999999978, 97.99999999999999, -18.099999999999753, -13.0, 15.799999999999962, 76.9999999999996, 79.69999999999985, 13.699999999999964, 68.0, -124.90000000000069, 94.69999999999939, -160.60000000000002, 17.299999999999997, -42.699999999999925, -31.0, 20.0, -49.299999999999876, -128.2000000000005, -171.10000000000056, -36.99999999999997, 17.899999999999988, -43.3, 5.299999999999965, -3.099999999999958, 20.000000000000014, -14.5, -95.20000000000036, -136.9, -119.20000000000016, 24.80000000000009, 20.000000000000014, -140.2, -102.10000000000062, -36.099999999999994, 9.499999999999964, 4.999999999999966, 9.799999999999981, 144.19999999999976, 20.000000000000014, -55.0, -12.099999999999987, 76.69999999999999, 12.500000000000014, -2.799999999999997, -15.099999999999778, 82.99999999999976, 20.000000000000014, 15.79999999999996, 146.0, -245.50000000000009, 1.0999999999999865, 65.3, 11.599999999999964, 20.000000000000014, 34.400000000000254, 7.099999999999989, 154.1, 11.599999999999964, -148.0, -59.800000000000026, 13.699999999999964, -31.899999999999856, -65.50000000000071, 20.000000000000014, 106.39999999999995, 20.000000000000014, 11.599999999999964, 20.000000000000014, 7.399999999999965, 11.0, 20.000000000000014, -160.0, 9.499999999999964, 112.1, 48.50000000000019, 44.900000000000006, -79.30000000000015, -56.499999999999886, -60.699999999999996, -127.89999999999998, 13.699999999999964, -61.89999999999998, 26.30000000000012, 9.499999999999964, -226.0, -167.5000000000002, -30.69999999999999, 89.2999999999993, -210.39999999999998, 5.299999999999965, -185.2000000000005, 5.299999999999965, 145.1, -19.899999999999743, -277.0, 5.299999999999965, -260.8, 8.600000000000001, 26.300000000000114, -256.9, 53.900000000000226, -175.0, -21.09999999999976, 33.200000000000244, 20.000000000000014, -243.39999999999998, -15.699999999999747, -15.699999999999747, -61.30000000000001, -327.99999999999983, -13.300000000000017, -15.699999999999932, 78.79999999999967, -158.8, -297.1000000000001, 129.5], "policy_predator_policy_reward": [54.0, 81.0, 3.0, 5.0, 2.0, 2.0, 25.0, 30.0, 8.0, 7.0, 0.0, 0.0, 5.0, 17.0, 65.0, 57.0, 1.0, 8.0, 1.0, 15.0, 2.0, 5.0, 60.0, 157.0, 154.0, 143.0, 65.0, 12.0, 13.0, 113.0, 57.0, 35.0, 26.0, 50.0, 13.0, 45.0, 47.0, 40.0, 0.0, 164.0, 2.0, 52.0, 4.0, 25.0, 70.0, 70.0, 12.0, 1.0, 76.0, 109.0, 4.0, 2.0, 0.0, 41.0, 125.0, 158.0, 35.0, 7.0, 132.0, 69.0, 82.0, 11.0, 29.0, 165.0, 3.0, 3.0, 7.0, 2.0, 92.0, 2.0, 82.0, 12.0, 33.0, 81.0, 143.0, 119.0, 9.0, 3.0, 9.0, 1.0, 42.0, 5.0, 20.0, 12.0, 48.0, 17.0, 71.0, 27.0, 9.0, 13.0, 32.0, 3.0, 44.0, 69.0, 98.0, 81.0, 66.0, 22.0, 74.0, 40.0, 82.0, 62.0, 40.0, 145.0, 67.0, 1.0, 11.0, 4.0, 44.0, 30.0, 84.0, 94.0, 62.0, 98.0, 111.0, 0.0, 130.0, 31.0, 10.0, 9.0, 21.0, 28.0, 79.0, 63.0, 75.0, 2.0, 63.0, 17.0, 25.0, 25.0, 0.0, 5.0, 53.0, 117.0, 19.0, 20.0, 0.0, 4.0, 8.0, 14.0, 3.0, 4.0, 68.0, 68.0, 4.0, 49.0, 0.0, 51.0, 0.0, 0.0, 3.0, 4.0, 63.0, 6.0, 9.0, 114.0, 15.0, 20.0, 39.0, 21.0, 67.0, 51.0, 96.0, 84.0, 3.0, 81.0, 0.0, 5.0, 107.0, 133.0, 60.0, 47.0, 99.0, 44.0, 66.0, 66.0, 0.0, 19.0, 159.0, 20.0, 133.0, 55.0, 124.0, 57.0, 112.0, 70.0, 23.0, 5.0, 21.0, 125.0, 15.0, 13.0, 154.0, 142.0, 57.0, 45.0, 79.0, 80.0, 14.0, 151.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7892308434070944, "mean_inference_ms": 2.0643626909372217, "mean_action_processing_ms": 0.3306792239478424, "mean_env_wait_ms": 0.268441300735912, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005647897720336914, "StateBufferConnector_ms": 0.0036345720291137695, "ViewRequirementAgentConnector_ms": 0.14380121231079102}, "num_episodes": 23, "episode_return_max": 334.40000000000003, "episode_return_min": -153.5000000000002, "episode_return_mean": 59.4479999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.06991255128605, "num_env_steps_trained_throughput_per_sec": 316.06991255128605, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 12670.085, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12670.04, "sample_time_ms": 2223.026, "learn_time_ms": 10432.622, "learn_throughput": 383.413, "synch_weights_time_ms": 12.585}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "f0d88_00000", "date": "2024-08-14_10-59-26", "timestamp": 1723647566, "time_this_iter_s": 12.709500074386597, "time_total_s": 783.1095068454742, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad542e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 783.1095068454742, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 50.42777777777778, "ram_util_percent": 82.20555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8317576093963845, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 5.180906239640776, "policy_loss": -0.01768308456928011, "vf_loss": 5.18087388825795, "vf_explained_var": -0.4491305532909575, "kl": 0.011664485791195637, "entropy": 1.0877074769249668, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.931379648743483, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 6.630283570668054, "policy_loss": -0.00929008986574238, "vf_loss": 6.615166141621019, "vf_explained_var": 0.07769795690894758, "kl": 0.014285153687355397, "entropy": 0.9889572712794813, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 247.29999999999959, "episode_reward_min": -195.10000000000028, "episode_reward_mean": 38.05199999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -327.99999999999983, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.5, "predator_policy": 167.0}, "policy_reward_mean": {"prey_policy": -31.184000000000047, "predator_policy": 50.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [130.89999999999972, 26.1, 148.59999999999962, 154.7999999999994, 26.099999999999966, 25.700000000000067, -1.7999999999999057, 35.500000000000234, 35.40000000000032, 33.50000000000001, 66.70000000000017, 80.50000000000003, -62.30000000000029, -107.90000000000023, 39.700000000000294, 25.90000000000007, -17.499999999999915, 61.70000000000019, 36.100000000000236, -63.99999999999994, 247.29999999999959, 31.100000000000165, -34.7999999999998, 173.09999999999948, 131.3999999999997, 66.90000000000015, 114.79999999999916, 128.3999999999995, 56.10000000000011, 113.09999999999951, 62.60000000000005, 103.0, -33.49999999999964, -23.09999999999983, 42.600000000000165, 17.200000000000006, 79.50000000000006, -54.10000000000029, 65.60000000000001, -9.199999999999967, 22.80000000000004, 33.500000000000206, 202.9999999999991, 106.99999999999983, 141.60000000000005, 89.7, 117.8999999999993, 40.80000000000031, 70.5, 105.39999999999927, 35.600000000000236, 63.50000000000042, 172.69999999999948, -71.80000000000013, 34.800000000000345, 5.500000000000005, 126.39999999999966, 38.60000000000028, 87.40000000000006, -16.999999999999837, 156.59999999999948, 153.39999999999924, -17.79999999999972, -8.599999999999959, 35.80000000000003, 40.80000000000032, -153.5000000000002, 165.5999999999993, -62.099999999999795, -47.89999999999969, 144.19999999999962, -92.70000000000022, -64.19999999999996, -49.59999999999984, 60.89999999999982, 40.10000000000031, -77.40000000000057, -3.3999999999997024, -93.3000000000001, 72.99999999999955, 79.00000000000003, -2.5999999999999654, 124.99999999999969, 21.700000000000173, -185.80000000000013, 113.99999999999892, -3.2999999999998533, 54.59999999999985, 38.70000000000028, 122.69999999999973, -190.60000000000002, 138.20000000000002, 27.10000000000005, 8.999999999999972, 1.5000000000000107, 94.29999999999987, 32.500000000000185, 159.29999999999956, -195.10000000000028, -194.50000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [33.499999999999915, 10.399999999999972, -324.39999999999986, 186.5, -89.20000000000067, 183.8, 11.599999999999975, 114.19999999999999, -127.6, 13.699999999999964, -5.1999999999999265, 17.899999999999988, -110.80000000000052, -76.0, 11.599999999999964, 17.899999999999988, -25.60000000000035, 20.000000000000014, -119.50000000000003, -130.0, 1.6999999999999729, 23.000000000000085, -223.0, 102.5, -3.099999999999958, -152.2000000000006, -11.499999999999819, -290.40000000000003, 20.000000000000014, 13.699999999999964, 9.499999999999966, 7.399999999999965, -127.30000000000001, 15.799999999999963, 10.699999999999974, -43.0, 20.000000000000014, -97.9, -103.00000000000028, -223.0, 102.49999999999952, 132.8, 20.000000000000014, 1.0999999999999865, -13.599999999999932, -68.20000000000043, 7.399999999999965, 133.69999999999996, -31.59999999999978, 97.99999999999999, -18.099999999999753, -13.0, 15.799999999999962, 76.9999999999996, 79.69999999999985, 13.699999999999964, 68.0, -124.90000000000069, 94.69999999999939, -160.60000000000002, 17.299999999999997, -42.699999999999925, -31.0, 20.0, -49.299999999999876, -128.2000000000005, -171.10000000000056, -36.99999999999997, 17.899999999999988, -43.3, 5.299999999999965, -3.099999999999958, 20.000000000000014, -14.5, -95.20000000000036, -136.9, -119.20000000000016, 24.80000000000009, 20.000000000000014, -140.2, -102.10000000000062, -36.099999999999994, 9.499999999999964, 4.999999999999966, 9.799999999999981, 144.19999999999976, 20.000000000000014, -55.0, -12.099999999999987, 76.69999999999999, 12.500000000000014, -2.799999999999997, -15.099999999999778, 82.99999999999976, 20.000000000000014, 15.79999999999996, 146.0, -245.50000000000009, 1.0999999999999865, 65.3, 11.599999999999964, 20.000000000000014, 34.400000000000254, 7.099999999999989, 154.1, 11.599999999999964, -148.0, -59.800000000000026, 13.699999999999964, -31.899999999999856, -65.50000000000071, 20.000000000000014, 106.39999999999995, 20.000000000000014, 11.599999999999964, 20.000000000000014, 7.399999999999965, 11.0, 20.000000000000014, -160.0, 9.499999999999964, 112.1, 48.50000000000019, 44.900000000000006, -79.30000000000015, -56.499999999999886, -60.699999999999996, -127.89999999999998, 13.699999999999964, -61.89999999999998, 26.30000000000012, 9.499999999999964, -226.0, -167.5000000000002, -30.69999999999999, 89.2999999999993, -210.39999999999998, 5.299999999999965, -185.2000000000005, 5.299999999999965, 145.1, -19.899999999999743, -277.0, 5.299999999999965, -260.8, 8.600000000000001, 26.300000000000114, -256.9, 53.900000000000226, -175.0, -21.09999999999976, 33.200000000000244, 20.000000000000014, -243.39999999999998, -15.699999999999747, -15.699999999999747, -61.30000000000001, -327.99999999999983, -13.300000000000017, -15.699999999999932, 78.79999999999967, -158.8, -297.1000000000001, 129.5, 92.0, 20.000000000000014, -92.19999999999999, 17.899999999999988, -142.3, -236.50000000000014, 17.899999999999988, 79.09999999999955, 3.1999999999999615, -134.5, -45.7, -39.69999999999977, 13.699999999999964, 20.000000000000014, -9.399999999999858, 82.1, -172.00000000000003, -265.6, 135.2, -115.0, 21.80000000000004, -204.7, -196.00000000000003, 20.0, 12.499999999999968, -283.0, 20.000000000000014, 23.300000000000026, 7.399999999999965, 10.099999999999985, 137.3, 20.000000000000014, -256.6000000000001, -146.5000000000002, -118.60000000000042, -265.9], "policy_predator_policy_reward": [47.0, 40.0, 0.0, 164.0, 2.0, 52.0, 4.0, 25.0, 70.0, 70.0, 12.0, 1.0, 76.0, 109.0, 4.0, 2.0, 0.0, 41.0, 125.0, 158.0, 35.0, 7.0, 132.0, 69.0, 82.0, 11.0, 29.0, 165.0, 3.0, 3.0, 7.0, 2.0, 92.0, 2.0, 82.0, 12.0, 33.0, 81.0, 143.0, 119.0, 9.0, 3.0, 9.0, 1.0, 42.0, 5.0, 20.0, 12.0, 48.0, 17.0, 71.0, 27.0, 9.0, 13.0, 32.0, 3.0, 44.0, 69.0, 98.0, 81.0, 66.0, 22.0, 74.0, 40.0, 82.0, 62.0, 40.0, 145.0, 67.0, 1.0, 11.0, 4.0, 44.0, 30.0, 84.0, 94.0, 62.0, 98.0, 111.0, 0.0, 130.0, 31.0, 10.0, 9.0, 21.0, 28.0, 79.0, 63.0, 75.0, 2.0, 63.0, 17.0, 25.0, 25.0, 0.0, 5.0, 53.0, 117.0, 19.0, 20.0, 0.0, 4.0, 8.0, 14.0, 3.0, 4.0, 68.0, 68.0, 4.0, 49.0, 0.0, 51.0, 0.0, 0.0, 3.0, 4.0, 63.0, 6.0, 9.0, 114.0, 15.0, 20.0, 39.0, 21.0, 67.0, 51.0, 96.0, 84.0, 3.0, 81.0, 0.0, 5.0, 107.0, 133.0, 60.0, 47.0, 99.0, 44.0, 66.0, 66.0, 0.0, 19.0, 159.0, 20.0, 133.0, 55.0, 124.0, 57.0, 112.0, 70.0, 23.0, 5.0, 21.0, 125.0, 15.0, 13.0, 154.0, 142.0, 57.0, 45.0, 79.0, 80.0, 14.0, 151.0, 12.0, 1.0, 95.0, 1.0, 65.0, 128.0, 15.0, 2.0, 112.0, 16.0, 89.0, 51.0, 2.0, 3.0, 36.0, 14.0, 119.0, 128.0, 57.0, 61.0, 115.0, 95.0, 99.0, 86.0, 158.0, 114.0, 22.0, 29.0, 9.0, 6.0, 2.0, 0.0, 139.0, 69.0, 167.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.791858061623597, "mean_inference_ms": 2.071348790649775, "mean_action_processing_ms": 0.3311400015517954, "mean_env_wait_ms": 0.26912186933127896, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004965782165527344, "StateBufferConnector_ms": 0.003512740135192871, "ViewRequirementAgentConnector_ms": 0.1476231813430786}, "num_episodes": 18, "episode_return_max": 247.29999999999959, "episode_return_min": -195.10000000000028, "episode_return_mean": 38.05199999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.9311380805872, "num_env_steps_trained_throughput_per_sec": 316.9311380805872, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 12672.383, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12672.338, "sample_time_ms": 2187.724, "learn_time_ms": 10469.995, "learn_throughput": 382.044, "synch_weights_time_ms": 12.683}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "f0d88_00000", "date": "2024-08-14_10-59-38", "timestamp": 1723647578, "time_this_iter_s": 12.677132844924927, "time_total_s": 795.7866396903992, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad542040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 795.7866396903992, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 48.638888888888886, "ram_util_percent": 82.06666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5882782577522216, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.153314099046919, "policy_loss": -0.016863407340472338, "vf_loss": 3.1547999710002275, "vf_explained_var": -0.9627963139266564, "kl": 0.01012512713570966, "entropy": 1.1583384685415439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9171444078601856, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 4.496665765368749, "policy_loss": -0.009300486101133246, "vf_loss": 4.488304356923179, "vf_explained_var": -0.001333287342515572, "kl": 0.010337096165793093, "entropy": 1.0364540363430346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 247.29999999999959, "episode_reward_min": -280.29999999999853, "episode_reward_mean": 25.862999999999925, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.1, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -38.46850000000004, "predator_policy": 51.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.100000000000236, -63.99999999999994, 247.29999999999959, 31.100000000000165, -34.7999999999998, 173.09999999999948, 131.3999999999997, 66.90000000000015, 114.79999999999916, 128.3999999999995, 56.10000000000011, 113.09999999999951, 62.60000000000005, 103.0, -33.49999999999964, -23.09999999999983, 42.600000000000165, 17.200000000000006, 79.50000000000006, -54.10000000000029, 65.60000000000001, -9.199999999999967, 22.80000000000004, 33.500000000000206, 202.9999999999991, 106.99999999999983, 141.60000000000005, 89.7, 117.8999999999993, 40.80000000000031, 70.5, 105.39999999999927, 35.600000000000236, 63.50000000000042, 172.69999999999948, -71.80000000000013, 34.800000000000345, 5.500000000000005, 126.39999999999966, 38.60000000000028, 87.40000000000006, -16.999999999999837, 156.59999999999948, 153.39999999999924, -17.79999999999972, -8.599999999999959, 35.80000000000003, 40.80000000000032, -153.5000000000002, 165.5999999999993, -62.099999999999795, -47.89999999999969, 144.19999999999962, -92.70000000000022, -64.19999999999996, -49.59999999999984, 60.89999999999982, 40.10000000000031, -77.40000000000057, -3.3999999999997024, -93.3000000000001, 72.99999999999955, 79.00000000000003, -2.5999999999999654, 124.99999999999969, 21.700000000000173, -185.80000000000013, 113.99999999999892, -3.2999999999998533, 54.59999999999985, 38.70000000000028, 122.69999999999973, -190.60000000000002, 138.20000000000002, 27.10000000000005, 8.999999999999972, 1.5000000000000107, 94.29999999999987, 32.500000000000185, 159.29999999999956, -195.10000000000028, -194.50000000000045, 60.39999999999966, 14.60000000000001, -53.2000000000001, 38.20000000000027, -86.60000000000034, -179.90000000000035, 12.60000000000013, 31.300000000000168, 67.6000000000001, 8.900000000000128, 29.90000000000014, 8.100000000000064, -280.29999999999853, 11.400000000000027, -90.60000000000072, -180.5000000000007, 48.30000000000018, 22.50000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -97.9, -103.00000000000028, -223.0, 102.49999999999952, 132.8, 20.000000000000014, 1.0999999999999865, -13.599999999999932, -68.20000000000043, 7.399999999999965, 133.69999999999996, -31.59999999999978, 97.99999999999999, -18.099999999999753, -13.0, 15.799999999999962, 76.9999999999996, 79.69999999999985, 13.699999999999964, 68.0, -124.90000000000069, 94.69999999999939, -160.60000000000002, 17.299999999999997, -42.699999999999925, -31.0, 20.0, -49.299999999999876, -128.2000000000005, -171.10000000000056, -36.99999999999997, 17.899999999999988, -43.3, 5.299999999999965, -3.099999999999958, 20.000000000000014, -14.5, -95.20000000000036, -136.9, -119.20000000000016, 24.80000000000009, 20.000000000000014, -140.2, -102.10000000000062, -36.099999999999994, 9.499999999999964, 4.999999999999966, 9.799999999999981, 144.19999999999976, 20.000000000000014, -55.0, -12.099999999999987, 76.69999999999999, 12.500000000000014, -2.799999999999997, -15.099999999999778, 82.99999999999976, 20.000000000000014, 15.79999999999996, 146.0, -245.50000000000009, 1.0999999999999865, 65.3, 11.599999999999964, 20.000000000000014, 34.400000000000254, 7.099999999999989, 154.1, 11.599999999999964, -148.0, -59.800000000000026, 13.699999999999964, -31.899999999999856, -65.50000000000071, 20.000000000000014, 106.39999999999995, 20.000000000000014, 11.599999999999964, 20.000000000000014, 7.399999999999965, 11.0, 20.000000000000014, -160.0, 9.499999999999964, 112.1, 48.50000000000019, 44.900000000000006, -79.30000000000015, -56.499999999999886, -60.699999999999996, -127.89999999999998, 13.699999999999964, -61.89999999999998, 26.30000000000012, 9.499999999999964, -226.0, -167.5000000000002, -30.69999999999999, 89.2999999999993, -210.39999999999998, 5.299999999999965, -185.2000000000005, 5.299999999999965, 145.1, -19.899999999999743, -277.0, 5.299999999999965, -260.8, 8.600000000000001, 26.300000000000114, -256.9, 53.900000000000226, -175.0, -21.09999999999976, 33.200000000000244, 20.000000000000014, -243.39999999999998, -15.699999999999747, -15.699999999999747, -61.30000000000001, -327.99999999999983, -13.300000000000017, -15.699999999999932, 78.79999999999967, -158.8, -297.1000000000001, 129.5, 92.0, 20.000000000000014, -92.19999999999999, 17.899999999999988, -142.3, -236.50000000000014, 17.899999999999988, 79.09999999999955, 3.1999999999999615, -134.5, -45.7, -39.69999999999977, 13.699999999999964, 20.000000000000014, -9.399999999999858, 82.1, -172.00000000000003, -265.6, 135.2, -115.0, 21.80000000000004, -204.7, -196.00000000000003, 20.0, 12.499999999999968, -283.0, 20.000000000000014, 23.300000000000026, 7.399999999999965, 10.099999999999985, 137.3, 20.000000000000014, -256.6000000000001, -146.5000000000002, -118.60000000000042, -265.9, -120.70000000000036, -10.899999999999949, 9.499999999999964, -67.89999999999986, -190.6000000000002, 7.399999999999965, 20.000000000000014, -8.799999999999871, -286.6, -39.99999999999985, -213.10000000000042, -122.80000000000021, -88.30000000000027, 17.899999999999988, 13.699999999999966, 11.599999999999964, 20.000000000000014, -27.39999999999987, -7.299999999999891, 3.1999999999999615, 5.299999999999965, 11.599999999999966, -40.89999999999978, 20.000000000000014, -214.90000000000023, -276.39999999999947, 13.699999999999964, -28.29999999999975, -113.80000000000047, -134.80000000000024, -361.0, -83.50000000000071, -138.40000000000012, 13.699999999999964, 1.0999999999999865, -82.60000000000046], "policy_predator_policy_reward": [33.0, 81.0, 143.0, 119.0, 9.0, 3.0, 9.0, 1.0, 42.0, 5.0, 20.0, 12.0, 48.0, 17.0, 71.0, 27.0, 9.0, 13.0, 32.0, 3.0, 44.0, 69.0, 98.0, 81.0, 66.0, 22.0, 74.0, 40.0, 82.0, 62.0, 40.0, 145.0, 67.0, 1.0, 11.0, 4.0, 44.0, 30.0, 84.0, 94.0, 62.0, 98.0, 111.0, 0.0, 130.0, 31.0, 10.0, 9.0, 21.0, 28.0, 79.0, 63.0, 75.0, 2.0, 63.0, 17.0, 25.0, 25.0, 0.0, 5.0, 53.0, 117.0, 19.0, 20.0, 0.0, 4.0, 8.0, 14.0, 3.0, 4.0, 68.0, 68.0, 4.0, 49.0, 0.0, 51.0, 0.0, 0.0, 3.0, 4.0, 63.0, 6.0, 9.0, 114.0, 15.0, 20.0, 39.0, 21.0, 67.0, 51.0, 96.0, 84.0, 3.0, 81.0, 0.0, 5.0, 107.0, 133.0, 60.0, 47.0, 99.0, 44.0, 66.0, 66.0, 0.0, 19.0, 159.0, 20.0, 133.0, 55.0, 124.0, 57.0, 112.0, 70.0, 23.0, 5.0, 21.0, 125.0, 15.0, 13.0, 154.0, 142.0, 57.0, 45.0, 79.0, 80.0, 14.0, 151.0, 12.0, 1.0, 95.0, 1.0, 65.0, 128.0, 15.0, 2.0, 112.0, 16.0, 89.0, 51.0, 2.0, 3.0, 36.0, 14.0, 119.0, 128.0, 57.0, 61.0, 115.0, 95.0, 99.0, 86.0, 158.0, 114.0, 22.0, 29.0, 9.0, 6.0, 2.0, 0.0, 139.0, 69.0, 167.0, 23.0, 114.0, 78.0, 51.0, 22.0, 15.0, 115.0, 13.0, 14.0, 123.0, 117.0, 1.0, 155.0, 82.0, 1.0, 5.0, 1.0, 30.0, 45.0, 0.0, 13.0, 6.0, 7.0, 0.0, 29.0, 50.0, 161.0, 3.0, 23.0, 97.0, 61.0, 173.0, 91.0, 86.0, 87.0, 45.0, 59.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7955249478978612, "mean_inference_ms": 2.0799761368752696, "mean_action_processing_ms": 0.33244201656571176, "mean_env_wait_ms": 0.27014260806993606, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0089033842086792, "StateBufferConnector_ms": 0.0035163164138793945, "ViewRequirementAgentConnector_ms": 0.15330743789672852}, "num_episodes": 18, "episode_return_max": 247.29999999999959, "episode_return_min": -280.29999999999853, "episode_return_mean": 25.862999999999925, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.5312172996848, "num_env_steps_trained_throughput_per_sec": 318.5312172996848, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 12637.937, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12637.893, "sample_time_ms": 2196.012, "learn_time_ms": 10427.303, "learn_throughput": 383.608, "synch_weights_time_ms": 12.692}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "f0d88_00000", "date": "2024-08-14_10-59-51", "timestamp": 1723647591, "time_this_iter_s": 12.562915802001953, "time_total_s": 808.3495554924011, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad502700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 808.3495554924011, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 47.977777777777774, "ram_util_percent": 81.99444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6913076624037728, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.985485573042007, "policy_loss": -0.022523677837911735, "vf_loss": 3.9880396879539286, "vf_explained_var": -0.9993968201692773, "kl": 0.013148686821723949, "entropy": 1.1510678940349155, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0771702831384364, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 4.759256151870445, "policy_loss": -0.009079907997141754, "vf_loss": 4.749903827243381, "vf_explained_var": 0.025448592346181315, "kl": 0.010787957223383562, "entropy": 1.040017682566214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 202.9999999999991, "episode_reward_min": -280.29999999999853, "episode_reward_mean": 13.390999999999927, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.1, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -44.784500000000044, "predator_policy": 51.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.80000000000004, 33.500000000000206, 202.9999999999991, 106.99999999999983, 141.60000000000005, 89.7, 117.8999999999993, 40.80000000000031, 70.5, 105.39999999999927, 35.600000000000236, 63.50000000000042, 172.69999999999948, -71.80000000000013, 34.800000000000345, 5.500000000000005, 126.39999999999966, 38.60000000000028, 87.40000000000006, -16.999999999999837, 156.59999999999948, 153.39999999999924, -17.79999999999972, -8.599999999999959, 35.80000000000003, 40.80000000000032, -153.5000000000002, 165.5999999999993, -62.099999999999795, -47.89999999999969, 144.19999999999962, -92.70000000000022, -64.19999999999996, -49.59999999999984, 60.89999999999982, 40.10000000000031, -77.40000000000057, -3.3999999999997024, -93.3000000000001, 72.99999999999955, 79.00000000000003, -2.5999999999999654, 124.99999999999969, 21.700000000000173, -185.80000000000013, 113.99999999999892, -3.2999999999998533, 54.59999999999985, 38.70000000000028, 122.69999999999973, -190.60000000000002, 138.20000000000002, 27.10000000000005, 8.999999999999972, 1.5000000000000107, 94.29999999999987, 32.500000000000185, 159.29999999999956, -195.10000000000028, -194.50000000000045, 60.39999999999966, 14.60000000000001, -53.2000000000001, 38.20000000000027, -86.60000000000034, -179.90000000000035, 12.60000000000013, 31.300000000000168, 67.6000000000001, 8.900000000000128, 29.90000000000014, 8.100000000000064, -280.29999999999853, 11.400000000000027, -90.60000000000072, -180.5000000000007, 48.30000000000018, 22.50000000000004, 50.400000000000475, -63.30000000000033, -98.00000000000097, 31.700000000000273, 33.500000000000206, 31.200000000000163, 134.89999999999955, -107.50000000000034, 7.500000000000057, 32.30000000000018, 124.59999999999926, -232.10000000000016, 24.300000000000132, 134.69999999999962, 37.30000000000026, -91.60000000000034, 24.400000000000148, -1.7999999999998146, 74.1, -211.4000000000004, 15.099999999999943, 52.60000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-102.10000000000062, -36.099999999999994, 9.499999999999964, 4.999999999999966, 9.799999999999981, 144.19999999999976, 20.000000000000014, -55.0, -12.099999999999987, 76.69999999999999, 12.500000000000014, -2.799999999999997, -15.099999999999778, 82.99999999999976, 20.000000000000014, 15.79999999999996, 146.0, -245.50000000000009, 1.0999999999999865, 65.3, 11.599999999999964, 20.000000000000014, 34.400000000000254, 7.099999999999989, 154.1, 11.599999999999964, -148.0, -59.800000000000026, 13.699999999999964, -31.899999999999856, -65.50000000000071, 20.000000000000014, 106.39999999999995, 20.000000000000014, 11.599999999999964, 20.000000000000014, 7.399999999999965, 11.0, 20.000000000000014, -160.0, 9.499999999999964, 112.1, 48.50000000000019, 44.900000000000006, -79.30000000000015, -56.499999999999886, -60.699999999999996, -127.89999999999998, 13.699999999999964, -61.89999999999998, 26.30000000000012, 9.499999999999964, -226.0, -167.5000000000002, -30.69999999999999, 89.2999999999993, -210.39999999999998, 5.299999999999965, -185.2000000000005, 5.299999999999965, 145.1, -19.899999999999743, -277.0, 5.299999999999965, -260.8, 8.600000000000001, 26.300000000000114, -256.9, 53.900000000000226, -175.0, -21.09999999999976, 33.200000000000244, 20.000000000000014, -243.39999999999998, -15.699999999999747, -15.699999999999747, -61.30000000000001, -327.99999999999983, -13.300000000000017, -15.699999999999932, 78.79999999999967, -158.8, -297.1000000000001, 129.5, 92.0, 20.000000000000014, -92.19999999999999, 17.899999999999988, -142.3, -236.50000000000014, 17.899999999999988, 79.09999999999955, 3.1999999999999615, -134.5, -45.7, -39.69999999999977, 13.699999999999964, 20.000000000000014, -9.399999999999858, 82.1, -172.00000000000003, -265.6, 135.2, -115.0, 21.80000000000004, -204.7, -196.00000000000003, 20.0, 12.499999999999968, -283.0, 20.000000000000014, 23.300000000000026, 7.399999999999965, 10.099999999999985, 137.3, 20.000000000000014, -256.6000000000001, -146.5000000000002, -118.60000000000042, -265.9, -120.70000000000036, -10.899999999999949, 9.499999999999964, -67.89999999999986, -190.6000000000002, 7.399999999999965, 20.000000000000014, -8.799999999999871, -286.6, -39.99999999999985, -213.10000000000042, -122.80000000000021, -88.30000000000027, 17.899999999999988, 13.699999999999966, 11.599999999999964, 20.000000000000014, -27.39999999999987, -7.299999999999891, 3.1999999999999615, 5.299999999999965, 11.599999999999966, -40.89999999999978, 20.000000000000014, -214.90000000000023, -276.39999999999947, 13.699999999999964, -28.29999999999975, -113.80000000000047, -134.80000000000024, -361.0, -83.50000000000071, -138.40000000000012, 13.699999999999964, 1.0999999999999865, -82.60000000000046, 20.000000000000014, 25.4000000000001, -162.1000000000005, -74.20000000000014, -11.499999999999819, -236.5000000000002, 20.000000000000014, -55.29999999999993, 15.799999999999963, -4.299999999999944, 11.599999999999964, 11.599999999999968, 13.699999999999964, 84.19999999999999, 15.799999999999963, -292.29999999999995, -146.50000000000054, 10.999999999999966, 5.299999999999965, 20.000000000000014, 59.59999999999998, 20.000000000000014, -132.7000000000001, -249.40000000000026, 13.699999999999964, -84.40000000000049, 4.999999999999973, 94.7, 5.299999999999965, 20.000000000000014, -37.59999999999991, -256.00000000000017, 20.000000000000014, -85.60000000000001, -1.9000000000000283, -69.90000000000077, -172.9, -79.0, -288.39999999999964, -166.00000000000026, -57.400000000000304, 24.50000000000008, -3.099999999999958, 10.699999999999985], "policy_predator_policy_reward": [130.0, 31.0, 10.0, 9.0, 21.0, 28.0, 79.0, 63.0, 75.0, 2.0, 63.0, 17.0, 25.0, 25.0, 0.0, 5.0, 53.0, 117.0, 19.0, 20.0, 0.0, 4.0, 8.0, 14.0, 3.0, 4.0, 68.0, 68.0, 4.0, 49.0, 0.0, 51.0, 0.0, 0.0, 3.0, 4.0, 63.0, 6.0, 9.0, 114.0, 15.0, 20.0, 39.0, 21.0, 67.0, 51.0, 96.0, 84.0, 3.0, 81.0, 0.0, 5.0, 107.0, 133.0, 60.0, 47.0, 99.0, 44.0, 66.0, 66.0, 0.0, 19.0, 159.0, 20.0, 133.0, 55.0, 124.0, 57.0, 112.0, 70.0, 23.0, 5.0, 21.0, 125.0, 15.0, 13.0, 154.0, 142.0, 57.0, 45.0, 79.0, 80.0, 14.0, 151.0, 12.0, 1.0, 95.0, 1.0, 65.0, 128.0, 15.0, 2.0, 112.0, 16.0, 89.0, 51.0, 2.0, 3.0, 36.0, 14.0, 119.0, 128.0, 57.0, 61.0, 115.0, 95.0, 99.0, 86.0, 158.0, 114.0, 22.0, 29.0, 9.0, 6.0, 2.0, 0.0, 139.0, 69.0, 167.0, 23.0, 114.0, 78.0, 51.0, 22.0, 15.0, 115.0, 13.0, 14.0, 123.0, 117.0, 1.0, 155.0, 82.0, 1.0, 5.0, 1.0, 30.0, 45.0, 0.0, 13.0, 6.0, 7.0, 0.0, 29.0, 50.0, 161.0, 3.0, 23.0, 97.0, 61.0, 173.0, 91.0, 86.0, 87.0, 45.0, 59.0, 2.0, 3.0, 114.0, 59.0, 135.0, 15.0, 56.0, 11.0, 11.0, 11.0, 4.0, 4.0, 23.0, 14.0, 16.0, 153.0, 70.0, 73.0, 7.0, 0.0, 39.0, 6.0, 83.0, 67.0, 29.0, 66.0, 11.0, 24.0, 7.0, 5.0, 138.0, 64.0, 80.0, 10.0, 22.0, 48.0, 158.0, 168.0, 114.0, 129.0, 25.0, 23.0, 8.0, 37.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.800211082072654, "mean_inference_ms": 2.0926684044969006, "mean_action_processing_ms": 0.33324560505617873, "mean_env_wait_ms": 0.27068929762929683, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008686423301696777, "StateBufferConnector_ms": 0.0034810304641723633, "ViewRequirementAgentConnector_ms": 0.1680670976638794}, "num_episodes": 22, "episode_return_max": 202.9999999999991, "episode_return_min": -280.29999999999853, "episode_return_mean": 13.390999999999927, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.93389976381684, "num_env_steps_trained_throughput_per_sec": 322.93389976381684, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 12568.593, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12568.549, "sample_time_ms": 2156.878, "learn_time_ms": 10397.082, "learn_throughput": 384.723, "synch_weights_time_ms": 12.723}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "f0d88_00000", "date": "2024-08-14_11-00-03", "timestamp": 1723647603, "time_this_iter_s": 12.392230987548828, "time_total_s": 820.74178647995, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad542d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 820.74178647995, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 47.27222222222222, "ram_util_percent": 82.03888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.85011099677868, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.412247192291987, "policy_loss": -0.02166539623535105, "vf_loss": 4.416776160336045, "vf_explained_var": -0.6955184790192458, "kl": 0.01128324870305175, "entropy": 1.2413109769896855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.392348954917262, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 4.510163893901482, "policy_loss": -0.010900682007903775, "vf_loss": 4.505861990035526, "vf_explained_var": 0.02926781489735558, "kl": 0.008897715245246098, "entropy": 0.9998336358045145, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 165.5999999999993, "episode_reward_min": -280.29999999999853, "episode_reward_mean": 4.630999999999918, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.1, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -50.28950000000006, "predator_policy": 52.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.40000000000006, -16.999999999999837, 156.59999999999948, 153.39999999999924, -17.79999999999972, -8.599999999999959, 35.80000000000003, 40.80000000000032, -153.5000000000002, 165.5999999999993, -62.099999999999795, -47.89999999999969, 144.19999999999962, -92.70000000000022, -64.19999999999996, -49.59999999999984, 60.89999999999982, 40.10000000000031, -77.40000000000057, -3.3999999999997024, -93.3000000000001, 72.99999999999955, 79.00000000000003, -2.5999999999999654, 124.99999999999969, 21.700000000000173, -185.80000000000013, 113.99999999999892, -3.2999999999998533, 54.59999999999985, 38.70000000000028, 122.69999999999973, -190.60000000000002, 138.20000000000002, 27.10000000000005, 8.999999999999972, 1.5000000000000107, 94.29999999999987, 32.500000000000185, 159.29999999999956, -195.10000000000028, -194.50000000000045, 60.39999999999966, 14.60000000000001, -53.2000000000001, 38.20000000000027, -86.60000000000034, -179.90000000000035, 12.60000000000013, 31.300000000000168, 67.6000000000001, 8.900000000000128, 29.90000000000014, 8.100000000000064, -280.29999999999853, 11.400000000000027, -90.60000000000072, -180.5000000000007, 48.30000000000018, 22.50000000000004, 50.400000000000475, -63.30000000000033, -98.00000000000097, 31.700000000000273, 33.500000000000206, 31.200000000000163, 134.89999999999955, -107.50000000000034, 7.500000000000057, 32.30000000000018, 124.59999999999926, -232.10000000000016, 24.300000000000132, 134.69999999999962, 37.30000000000026, -91.60000000000034, 24.400000000000148, -1.7999999999998146, 74.1, -211.4000000000004, 15.099999999999943, 52.60000000000036, 8.200000000000228, -64.19999999999996, 23.70000000000012, 77.1, 99.29999999999934, 138.99999999999898, 22.500000000000053, -87.00000000000105, 53.00000000000022, -86.90000000000171, 29.50000000000014, 50.40000000000037, 53.50000000000034, -54.000000000000085, 36.40000000000025, 133.09999999999968, -12.099999999999717, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 11.0, 20.000000000000014, -160.0, 9.499999999999964, 112.1, 48.50000000000019, 44.900000000000006, -79.30000000000015, -56.499999999999886, -60.699999999999996, -127.89999999999998, 13.699999999999964, -61.89999999999998, 26.30000000000012, 9.499999999999964, -226.0, -167.5000000000002, -30.69999999999999, 89.2999999999993, -210.39999999999998, 5.299999999999965, -185.2000000000005, 5.299999999999965, 145.1, -19.899999999999743, -277.0, 5.299999999999965, -260.8, 8.600000000000001, 26.300000000000114, -256.9, 53.900000000000226, -175.0, -21.09999999999976, 33.200000000000244, 20.000000000000014, -243.39999999999998, -15.699999999999747, -15.699999999999747, -61.30000000000001, -327.99999999999983, -13.300000000000017, -15.699999999999932, 78.79999999999967, -158.8, -297.1000000000001, 129.5, 92.0, 20.000000000000014, -92.19999999999999, 17.899999999999988, -142.3, -236.50000000000014, 17.899999999999988, 79.09999999999955, 3.1999999999999615, -134.5, -45.7, -39.69999999999977, 13.699999999999964, 20.000000000000014, -9.399999999999858, 82.1, -172.00000000000003, -265.6, 135.2, -115.0, 21.80000000000004, -204.7, -196.00000000000003, 20.0, 12.499999999999968, -283.0, 20.000000000000014, 23.300000000000026, 7.399999999999965, 10.099999999999985, 137.3, 20.000000000000014, -256.6000000000001, -146.5000000000002, -118.60000000000042, -265.9, -120.70000000000036, -10.899999999999949, 9.499999999999964, -67.89999999999986, -190.6000000000002, 7.399999999999965, 20.000000000000014, -8.799999999999871, -286.6, -39.99999999999985, -213.10000000000042, -122.80000000000021, -88.30000000000027, 17.899999999999988, 13.699999999999966, 11.599999999999964, 20.000000000000014, -27.39999999999987, -7.299999999999891, 3.1999999999999615, 5.299999999999965, 11.599999999999966, -40.89999999999978, 20.000000000000014, -214.90000000000023, -276.39999999999947, 13.699999999999964, -28.29999999999975, -113.80000000000047, -134.80000000000024, -361.0, -83.50000000000071, -138.40000000000012, 13.699999999999964, 1.0999999999999865, -82.60000000000046, 20.000000000000014, 25.4000000000001, -162.1000000000005, -74.20000000000014, -11.499999999999819, -236.5000000000002, 20.000000000000014, -55.29999999999993, 15.799999999999963, -4.299999999999944, 11.599999999999964, 11.599999999999968, 13.699999999999964, 84.19999999999999, 15.799999999999963, -292.29999999999995, -146.50000000000054, 10.999999999999966, 5.299999999999965, 20.000000000000014, 59.59999999999998, 20.000000000000014, -132.7000000000001, -249.40000000000026, 13.699999999999964, -84.40000000000049, 4.999999999999973, 94.7, 5.299999999999965, 20.000000000000014, -37.59999999999991, -256.00000000000017, 20.000000000000014, -85.60000000000001, -1.9000000000000283, -69.90000000000077, -172.9, -79.0, -288.39999999999964, -166.00000000000026, -57.400000000000304, 24.50000000000008, -3.099999999999958, 10.699999999999985, -69.6999999999999, -75.10000000000085, -185.5, -84.70000000000002, -4.600000000000001, -78.70000000000053, -25.900000000000006, 20.000000000000014, 42.19999999999993, 1.0999999999999865, 5.299999999999965, 121.69999999999962, -3.3999999999999866, -3.099999999999958, -78.7000000000005, -178.30000000000055, 1.0999999999999865, 35.89999999999995, -72.40000000000089, -74.50000000000081, 15.799999999999963, -7.299999999999905, 13.999999999999968, 7.399999999999965, 7.399999999999965, 10.099999999999975, -55.00000000000004, -109.00000000000037, 17.899999999999988, 9.499999999999964, 106.09999999999997, 20.000000000000014, -20.19999999999976, -184.90000000000046, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [63.0, 6.0, 9.0, 114.0, 15.0, 20.0, 39.0, 21.0, 67.0, 51.0, 96.0, 84.0, 3.0, 81.0, 0.0, 5.0, 107.0, 133.0, 60.0, 47.0, 99.0, 44.0, 66.0, 66.0, 0.0, 19.0, 159.0, 20.0, 133.0, 55.0, 124.0, 57.0, 112.0, 70.0, 23.0, 5.0, 21.0, 125.0, 15.0, 13.0, 154.0, 142.0, 57.0, 45.0, 79.0, 80.0, 14.0, 151.0, 12.0, 1.0, 95.0, 1.0, 65.0, 128.0, 15.0, 2.0, 112.0, 16.0, 89.0, 51.0, 2.0, 3.0, 36.0, 14.0, 119.0, 128.0, 57.0, 61.0, 115.0, 95.0, 99.0, 86.0, 158.0, 114.0, 22.0, 29.0, 9.0, 6.0, 2.0, 0.0, 139.0, 69.0, 167.0, 23.0, 114.0, 78.0, 51.0, 22.0, 15.0, 115.0, 13.0, 14.0, 123.0, 117.0, 1.0, 155.0, 82.0, 1.0, 5.0, 1.0, 30.0, 45.0, 0.0, 13.0, 6.0, 7.0, 0.0, 29.0, 50.0, 161.0, 3.0, 23.0, 97.0, 61.0, 173.0, 91.0, 86.0, 87.0, 45.0, 59.0, 2.0, 3.0, 114.0, 59.0, 135.0, 15.0, 56.0, 11.0, 11.0, 11.0, 4.0, 4.0, 23.0, 14.0, 16.0, 153.0, 70.0, 73.0, 7.0, 0.0, 39.0, 6.0, 83.0, 67.0, 29.0, 66.0, 11.0, 24.0, 7.0, 5.0, 138.0, 64.0, 80.0, 10.0, 22.0, 48.0, 158.0, 168.0, 114.0, 129.0, 25.0, 23.0, 8.0, 37.0, 81.0, 72.0, 88.0, 118.0, 46.0, 61.0, 40.0, 43.0, 32.0, 24.0, 5.0, 7.0, 18.0, 11.0, 97.0, 73.0, 9.0, 7.0, 5.0, 55.0, 9.0, 12.0, 13.0, 16.0, 30.0, 6.0, 63.0, 47.0, 5.0, 4.0, 0.0, 7.0, 99.0, 94.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.804902278718171, "mean_inference_ms": 2.1008922355486455, "mean_action_processing_ms": 0.335554011855464, "mean_env_wait_ms": 0.27250815905070974, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008985638618469238, "StateBufferConnector_ms": 0.0033789873123168945, "ViewRequirementAgentConnector_ms": 0.16086995601654053}, "num_episodes": 18, "episode_return_max": 165.5999999999993, "episode_return_min": -280.29999999999853, "episode_return_mean": 4.630999999999918, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 308.760029648826, "num_env_steps_trained_throughput_per_sec": 308.760029648826, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 12569.805, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12569.762, "sample_time_ms": 2146.022, "learn_time_ms": 10408.921, "learn_throughput": 384.286, "synch_weights_time_ms": 13.151}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "f0d88_00000", "date": "2024-08-14_11-00-16", "timestamp": 1723647616, "time_this_iter_s": 13.014979839324951, "time_total_s": 833.7567663192749, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e5dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 833.7567663192749, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 51.42222222222222, "ram_util_percent": 82.18333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8610936209322915, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.089380879566152, "policy_loss": -0.03139243288970892, "vf_loss": 3.1001793860127687, "vf_explained_var": -0.964379248984907, "kl": 0.013559790161383159, "entropy": 1.2450502290296808, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1899941298381362, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 3.063967295046206, "policy_loss": -0.011605747793579386, "vf_loss": 3.061413879053933, "vf_explained_var": 0.03165132220459994, "kl": 0.008287021408062482, "entropy": 1.0700861338900511, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 174.99999999999898, "episode_reward_min": -280.29999999999853, "episode_reward_mean": 3.244999999999919, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.99999999999972, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -46.557500000000076, "predator_policy": 48.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.5999999999999654, 124.99999999999969, 21.700000000000173, -185.80000000000013, 113.99999999999892, -3.2999999999998533, 54.59999999999985, 38.70000000000028, 122.69999999999973, -190.60000000000002, 138.20000000000002, 27.10000000000005, 8.999999999999972, 1.5000000000000107, 94.29999999999987, 32.500000000000185, 159.29999999999956, -195.10000000000028, -194.50000000000045, 60.39999999999966, 14.60000000000001, -53.2000000000001, 38.20000000000027, -86.60000000000034, -179.90000000000035, 12.60000000000013, 31.300000000000168, 67.6000000000001, 8.900000000000128, 29.90000000000014, 8.100000000000064, -280.29999999999853, 11.400000000000027, -90.60000000000072, -180.5000000000007, 48.30000000000018, 22.50000000000004, 50.400000000000475, -63.30000000000033, -98.00000000000097, 31.700000000000273, 33.500000000000206, 31.200000000000163, 134.89999999999955, -107.50000000000034, 7.500000000000057, 32.30000000000018, 124.59999999999926, -232.10000000000016, 24.300000000000132, 134.69999999999962, 37.30000000000026, -91.60000000000034, 24.400000000000148, -1.7999999999998146, 74.1, -211.4000000000004, 15.099999999999943, 52.60000000000036, 8.200000000000228, -64.19999999999996, 23.70000000000012, 77.1, 99.29999999999934, 138.99999999999898, 22.500000000000053, -87.00000000000105, 53.00000000000022, -86.90000000000171, 29.50000000000014, 50.40000000000037, 53.50000000000034, -54.000000000000085, 36.40000000000025, 133.09999999999968, -12.099999999999717, 40.0000000000003, 24.800000000000104, 29.000000000000128, 25.000000000000092, 4.6999999999999424, 22.90000000000006, -44.59999999999971, 81.79999999999917, 75.79999999999959, 49.30000000000008, 19.400000000000055, -72.90000000000006, -19.199999999999527, 28.700000000000124, -11.79999999999991, 24.00000000000003, 29.60000000000013, 174.99999999999898, -80.4000000000008, -53.4999999999997, -22.599999999999767, -137.3000000000008, 34.00000000000021, 29.000000000000128], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-297.1000000000001, 129.5, 92.0, 20.000000000000014, -92.19999999999999, 17.899999999999988, -142.3, -236.50000000000014, 17.899999999999988, 79.09999999999955, 3.1999999999999615, -134.5, -45.7, -39.69999999999977, 13.699999999999964, 20.000000000000014, -9.399999999999858, 82.1, -172.00000000000003, -265.6, 135.2, -115.0, 21.80000000000004, -204.7, -196.00000000000003, 20.0, 12.499999999999968, -283.0, 20.000000000000014, 23.300000000000026, 7.399999999999965, 10.099999999999985, 137.3, 20.000000000000014, -256.6000000000001, -146.5000000000002, -118.60000000000042, -265.9, -120.70000000000036, -10.899999999999949, 9.499999999999964, -67.89999999999986, -190.6000000000002, 7.399999999999965, 20.000000000000014, -8.799999999999871, -286.6, -39.99999999999985, -213.10000000000042, -122.80000000000021, -88.30000000000027, 17.899999999999988, 13.699999999999966, 11.599999999999964, 20.000000000000014, -27.39999999999987, -7.299999999999891, 3.1999999999999615, 5.299999999999965, 11.599999999999966, -40.89999999999978, 20.000000000000014, -214.90000000000023, -276.39999999999947, 13.699999999999964, -28.29999999999975, -113.80000000000047, -134.80000000000024, -361.0, -83.50000000000071, -138.40000000000012, 13.699999999999964, 1.0999999999999865, -82.60000000000046, 20.000000000000014, 25.4000000000001, -162.1000000000005, -74.20000000000014, -11.499999999999819, -236.5000000000002, 20.000000000000014, -55.29999999999993, 15.799999999999963, -4.299999999999944, 11.599999999999964, 11.599999999999968, 13.699999999999964, 84.19999999999999, 15.799999999999963, -292.29999999999995, -146.50000000000054, 10.999999999999966, 5.299999999999965, 20.000000000000014, 59.59999999999998, 20.000000000000014, -132.7000000000001, -249.40000000000026, 13.699999999999964, -84.40000000000049, 4.999999999999973, 94.7, 5.299999999999965, 20.000000000000014, -37.59999999999991, -256.00000000000017, 20.000000000000014, -85.60000000000001, -1.9000000000000283, -69.90000000000077, -172.9, -79.0, -288.39999999999964, -166.00000000000026, -57.400000000000304, 24.50000000000008, -3.099999999999958, 10.699999999999985, -69.6999999999999, -75.10000000000085, -185.5, -84.70000000000002, -4.600000000000001, -78.70000000000053, -25.900000000000006, 20.000000000000014, 42.19999999999993, 1.0999999999999865, 5.299999999999965, 121.69999999999962, -3.3999999999999866, -3.099999999999958, -78.7000000000005, -178.30000000000055, 1.0999999999999865, 35.89999999999995, -72.40000000000089, -74.50000000000081, 15.799999999999963, -7.299999999999905, 13.999999999999968, 7.399999999999965, 7.399999999999965, 10.099999999999975, -55.00000000000004, -109.00000000000037, 17.899999999999988, 9.499999999999964, 106.09999999999997, 20.000000000000014, -20.19999999999976, -184.90000000000046, 20.000000000000014, 20.000000000000014, 15.199999999999966, -30.399999999999906, 9.499999999999964, 9.499999999999964, 20.000000000000014, -106.0000000000008, 20.000000000000014, -214.3000000000005, 3.1999999999999615, -34.29999999999976, -156.10000000000045, 9.499999999999964, 20.000000000000014, 54.800000000000196, 20.000000000000014, 24.800000000000107, -153.70000000000005, 56.00000000000023, 24.500000000000064, -93.10000000000056, -116.20000000000002, -129.70000000000053, -30.399999999999764, -38.799999999999756, 9.499999999999964, 3.199999999999965, -75.40000000000023, -27.399999999999793, -187.6000000000003, 20.60000000000001, -103.9, 9.499999999999964, 20.000000000000014, 154.99999999999972, 20.000000000000014, -231.40000000000026, -60.699999999999854, -80.8000000000002, -121.60000000000053, 20.000000000000014, -232.00000000000026, -67.2999999999998, 15.799999999999963, 3.1999999999999615, -0.9999999999999846, 20.000000000000014], "policy_predator_policy_reward": [14.0, 151.0, 12.0, 1.0, 95.0, 1.0, 65.0, 128.0, 15.0, 2.0, 112.0, 16.0, 89.0, 51.0, 2.0, 3.0, 36.0, 14.0, 119.0, 128.0, 57.0, 61.0, 115.0, 95.0, 99.0, 86.0, 158.0, 114.0, 22.0, 29.0, 9.0, 6.0, 2.0, 0.0, 139.0, 69.0, 167.0, 23.0, 114.0, 78.0, 51.0, 22.0, 15.0, 115.0, 13.0, 14.0, 123.0, 117.0, 1.0, 155.0, 82.0, 1.0, 5.0, 1.0, 30.0, 45.0, 0.0, 13.0, 6.0, 7.0, 0.0, 29.0, 50.0, 161.0, 3.0, 23.0, 97.0, 61.0, 173.0, 91.0, 86.0, 87.0, 45.0, 59.0, 2.0, 3.0, 114.0, 59.0, 135.0, 15.0, 56.0, 11.0, 11.0, 11.0, 4.0, 4.0, 23.0, 14.0, 16.0, 153.0, 70.0, 73.0, 7.0, 0.0, 39.0, 6.0, 83.0, 67.0, 29.0, 66.0, 11.0, 24.0, 7.0, 5.0, 138.0, 64.0, 80.0, 10.0, 22.0, 48.0, 158.0, 168.0, 114.0, 129.0, 25.0, 23.0, 8.0, 37.0, 81.0, 72.0, 88.0, 118.0, 46.0, 61.0, 40.0, 43.0, 32.0, 24.0, 5.0, 7.0, 18.0, 11.0, 97.0, 73.0, 9.0, 7.0, 5.0, 55.0, 9.0, 12.0, 13.0, 16.0, 30.0, 6.0, 63.0, 47.0, 5.0, 4.0, 0.0, 7.0, 99.0, 94.0, 0.0, 0.0, 2.0, 38.0, 5.0, 5.0, 60.0, 51.0, 106.0, 93.0, 28.0, 26.0, 67.0, 35.0, 4.0, 3.0, 15.0, 16.0, 84.0, 63.0, 28.0, 60.0, 98.0, 75.0, 22.0, 28.0, 5.0, 11.0, 59.0, 32.0, 92.0, 99.0, 88.0, 36.0, 0.0, 0.0, 130.0, 1.0, 80.0, 8.0, 79.0, 0.0, 134.0, 28.0, 8.0, 7.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8110834035510754, "mean_inference_ms": 2.115393828132718, "mean_action_processing_ms": 0.3375106597733089, "mean_env_wait_ms": 0.2740555485899169, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010480523109436035, "StateBufferConnector_ms": 0.008161425590515137, "ViewRequirementAgentConnector_ms": 0.17468547821044922}, "num_episodes": 23, "episode_return_max": 174.99999999999898, "episode_return_min": -280.29999999999853, "episode_return_mean": 3.244999999999919, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.4820074412198, "num_env_steps_trained_throughput_per_sec": 310.4820074412198, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 12591.644, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12591.601, "sample_time_ms": 2187.293, "learn_time_ms": 10388.743, "learn_throughput": 385.032, "synch_weights_time_ms": 13.938}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "f0d88_00000", "date": "2024-08-14_11-00-29", "timestamp": 1723647629, "time_this_iter_s": 12.937540292739868, "time_total_s": 846.6943066120148, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4e5a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 846.6943066120148, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 52.31578947368422, "ram_util_percent": 82.87894736842104}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.640474187570905, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.873418176426459, "policy_loss": -0.034619924587212386, "vf_loss": 2.888246372010973, "vf_explained_var": -0.9028486863645927, "kl": 0.013031591348307775, "entropy": 1.267915349536472, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.197460541144881, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 2.890384584759909, "policy_loss": -0.017592632313007638, "vf_loss": 2.8946523037537064, "vf_explained_var": 0.06159844688637547, "kl": 0.007798757388303061, "entropy": 1.0696991243375042, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 174.99999999999898, "episode_reward_min": -280.29999999999853, "episode_reward_mean": 4.5679999999999445, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.99999999999972, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -39.971000000000075, "predator_policy": 42.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-194.50000000000045, 60.39999999999966, 14.60000000000001, -53.2000000000001, 38.20000000000027, -86.60000000000034, -179.90000000000035, 12.60000000000013, 31.300000000000168, 67.6000000000001, 8.900000000000128, 29.90000000000014, 8.100000000000064, -280.29999999999853, 11.400000000000027, -90.60000000000072, -180.5000000000007, 48.30000000000018, 22.50000000000004, 50.400000000000475, -63.30000000000033, -98.00000000000097, 31.700000000000273, 33.500000000000206, 31.200000000000163, 134.89999999999955, -107.50000000000034, 7.500000000000057, 32.30000000000018, 124.59999999999926, -232.10000000000016, 24.300000000000132, 134.69999999999962, 37.30000000000026, -91.60000000000034, 24.400000000000148, -1.7999999999998146, 74.1, -211.4000000000004, 15.099999999999943, 52.60000000000036, 8.200000000000228, -64.19999999999996, 23.70000000000012, 77.1, 99.29999999999934, 138.99999999999898, 22.500000000000053, -87.00000000000105, 53.00000000000022, -86.90000000000171, 29.50000000000014, 50.40000000000037, 53.50000000000034, -54.000000000000085, 36.40000000000025, 133.09999999999968, -12.099999999999717, 40.0000000000003, 24.800000000000104, 29.000000000000128, 25.000000000000092, 4.6999999999999424, 22.90000000000006, -44.59999999999971, 81.79999999999917, 75.79999999999959, 49.30000000000008, 19.400000000000055, -72.90000000000006, -19.199999999999527, 28.700000000000124, -11.79999999999991, 24.00000000000003, 29.60000000000013, 174.99999999999898, -80.4000000000008, -53.4999999999997, -22.599999999999767, -137.3000000000008, 34.00000000000021, 29.000000000000128, 31.600000000000183, -22.500000000000107, -77.50000000000006, 65.89999999999998, 54.5000000000004, 28.600000000000122, 18.900000000000023, 79.89999999999915, -40.09999999999998, 11.100000000000097, 10.899999999999975, 144.09999999999937, 30.400000000000166, 38.90000000000028, 37.600000000000264, 35.600000000000236, 72.19999999999993, -26.59999999999951], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-118.60000000000042, -265.9, -120.70000000000036, -10.899999999999949, 9.499999999999964, -67.89999999999986, -190.6000000000002, 7.399999999999965, 20.000000000000014, -8.799999999999871, -286.6, -39.99999999999985, -213.10000000000042, -122.80000000000021, -88.30000000000027, 17.899999999999988, 13.699999999999966, 11.599999999999964, 20.000000000000014, -27.39999999999987, -7.299999999999891, 3.1999999999999615, 5.299999999999965, 11.599999999999966, -40.89999999999978, 20.000000000000014, -214.90000000000023, -276.39999999999947, 13.699999999999964, -28.29999999999975, -113.80000000000047, -134.80000000000024, -361.0, -83.50000000000071, -138.40000000000012, 13.699999999999964, 1.0999999999999865, -82.60000000000046, 20.000000000000014, 25.4000000000001, -162.1000000000005, -74.20000000000014, -11.499999999999819, -236.5000000000002, 20.000000000000014, -55.29999999999993, 15.799999999999963, -4.299999999999944, 11.599999999999964, 11.599999999999968, 13.699999999999964, 84.19999999999999, 15.799999999999963, -292.29999999999995, -146.50000000000054, 10.999999999999966, 5.299999999999965, 20.000000000000014, 59.59999999999998, 20.000000000000014, -132.7000000000001, -249.40000000000026, 13.699999999999964, -84.40000000000049, 4.999999999999973, 94.7, 5.299999999999965, 20.000000000000014, -37.59999999999991, -256.00000000000017, 20.000000000000014, -85.60000000000001, -1.9000000000000283, -69.90000000000077, -172.9, -79.0, -288.39999999999964, -166.00000000000026, -57.400000000000304, 24.50000000000008, -3.099999999999958, 10.699999999999985, -69.6999999999999, -75.10000000000085, -185.5, -84.70000000000002, -4.600000000000001, -78.70000000000053, -25.900000000000006, 20.000000000000014, 42.19999999999993, 1.0999999999999865, 5.299999999999965, 121.69999999999962, -3.3999999999999866, -3.099999999999958, -78.7000000000005, -178.30000000000055, 1.0999999999999865, 35.89999999999995, -72.40000000000089, -74.50000000000081, 15.799999999999963, -7.299999999999905, 13.999999999999968, 7.399999999999965, 7.399999999999965, 10.099999999999975, -55.00000000000004, -109.00000000000037, 17.899999999999988, 9.499999999999964, 106.09999999999997, 20.000000000000014, -20.19999999999976, -184.90000000000046, 20.000000000000014, 20.000000000000014, 15.199999999999966, -30.399999999999906, 9.499999999999964, 9.499999999999964, 20.000000000000014, -106.0000000000008, 20.000000000000014, -214.3000000000005, 3.1999999999999615, -34.29999999999976, -156.10000000000045, 9.499999999999964, 20.000000000000014, 54.800000000000196, 20.000000000000014, 24.800000000000107, -153.70000000000005, 56.00000000000023, 24.500000000000064, -93.10000000000056, -116.20000000000002, -129.70000000000053, -30.399999999999764, -38.799999999999756, 9.499999999999964, 3.199999999999965, -75.40000000000023, -27.399999999999793, -187.6000000000003, 20.60000000000001, -103.9, 9.499999999999964, 20.000000000000014, 154.99999999999972, 20.000000000000014, -231.40000000000026, -60.699999999999854, -80.8000000000002, -121.60000000000053, 20.000000000000014, -232.00000000000026, -67.2999999999998, 15.799999999999963, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, 2.899999999999965, 13.699999999999964, -122.50000000000003, -18.999999999999744, 11.599999999999964, -192.1000000000005, 9.499999999999964, -7.5999999999999375, 10.699999999999967, 15.79999999999996, 5.299999999999965, 11.29999999999997, 23.30000000000008, -72.40000000000069, -63.1000000000005, 11.000000000000007, -124.90000000000006, 15.799999999999935, -130.00000000000003, 28.100000000000147, -57.10000000000036, 20.000000000000014, 13.699999999999964, 124.39999999999985, -21.99999999999976, 7.399999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, -3.399999999999958, 15.799999999999963, 15.799999999999963, -15.699999999999747, 50.89999999999999, -7.299999999999891, -64.30000000000089], "policy_predator_policy_reward": [167.0, 23.0, 114.0, 78.0, 51.0, 22.0, 15.0, 115.0, 13.0, 14.0, 123.0, 117.0, 1.0, 155.0, 82.0, 1.0, 5.0, 1.0, 30.0, 45.0, 0.0, 13.0, 6.0, 7.0, 0.0, 29.0, 50.0, 161.0, 3.0, 23.0, 97.0, 61.0, 173.0, 91.0, 86.0, 87.0, 45.0, 59.0, 2.0, 3.0, 114.0, 59.0, 135.0, 15.0, 56.0, 11.0, 11.0, 11.0, 4.0, 4.0, 23.0, 14.0, 16.0, 153.0, 70.0, 73.0, 7.0, 0.0, 39.0, 6.0, 83.0, 67.0, 29.0, 66.0, 11.0, 24.0, 7.0, 5.0, 138.0, 64.0, 80.0, 10.0, 22.0, 48.0, 158.0, 168.0, 114.0, 129.0, 25.0, 23.0, 8.0, 37.0, 81.0, 72.0, 88.0, 118.0, 46.0, 61.0, 40.0, 43.0, 32.0, 24.0, 5.0, 7.0, 18.0, 11.0, 97.0, 73.0, 9.0, 7.0, 5.0, 55.0, 9.0, 12.0, 13.0, 16.0, 30.0, 6.0, 63.0, 47.0, 5.0, 4.0, 0.0, 7.0, 99.0, 94.0, 0.0, 0.0, 2.0, 38.0, 5.0, 5.0, 60.0, 51.0, 106.0, 93.0, 28.0, 26.0, 67.0, 35.0, 4.0, 3.0, 15.0, 16.0, 84.0, 63.0, 28.0, 60.0, 98.0, 75.0, 22.0, 28.0, 5.0, 11.0, 59.0, 32.0, 92.0, 99.0, 88.0, 36.0, 0.0, 0.0, 130.0, 1.0, 80.0, 8.0, 79.0, 0.0, 134.0, 28.0, 8.0, 7.0, 0.0, 10.0, 12.0, 3.0, 100.0, 19.0, 2.0, 101.0, 54.0, 10.0, 1.0, 27.0, 12.0, 0.0, 22.0, 46.0, 76.0, 56.0, 69.0, 0.0, 49.0, 64.0, 24.0, 24.0, 3.0, 3.0, 19.0, 26.0, 1.0, 0.0, 9.0, 12.0, 2.0, 2.0, 32.0, 5.0, 44.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8158126697534891, "mean_inference_ms": 2.1265412726987125, "mean_action_processing_ms": 0.3390916529658291, "mean_env_wait_ms": 0.275179491631293, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01098012924194336, "StateBufferConnector_ms": 0.008157014846801758, "ViewRequirementAgentConnector_ms": 0.18499839305877686}, "num_episodes": 18, "episode_return_max": 174.99999999999898, "episode_return_min": -280.29999999999853, "episode_return_mean": 4.5679999999999445, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.13435482440434, "num_env_steps_trained_throughput_per_sec": 310.13435482440434, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 12656.021, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12655.978, "sample_time_ms": 2224.073, "learn_time_ms": 10415.838, "learn_throughput": 384.031, "synch_weights_time_ms": 14.419}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "f0d88_00000", "date": "2024-08-14_11-00-42", "timestamp": 1723647642, "time_this_iter_s": 12.946825981140137, "time_total_s": 859.6411325931549, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0e2310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 859.6411325931549, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 49.06111111111111, "ram_util_percent": 82.45555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6194299753065462, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.4544150185332727, "policy_loss": -0.03176863917504393, "vf_loss": 3.4675425624090526, "vf_explained_var": -0.9372011872195692, "kl": 0.012273968555160965, "entropy": 1.2699527826889483, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.33662138530817, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 2.8305040717755676, "policy_loss": -0.018421919258784444, "vf_loss": 2.8339598398675365, "vf_explained_var": 0.039540297202963044, "kl": 0.008759340587553751, "entropy": 1.074853247309488, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 174.99999999999898, "episode_reward_min": -232.10000000000016, "episode_reward_mean": 15.181999999999952, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -292.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.99999999999972, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": -30.179000000000084, "predator_policy": 37.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.50000000000004, 50.400000000000475, -63.30000000000033, -98.00000000000097, 31.700000000000273, 33.500000000000206, 31.200000000000163, 134.89999999999955, -107.50000000000034, 7.500000000000057, 32.30000000000018, 124.59999999999926, -232.10000000000016, 24.300000000000132, 134.69999999999962, 37.30000000000026, -91.60000000000034, 24.400000000000148, -1.7999999999998146, 74.1, -211.4000000000004, 15.099999999999943, 52.60000000000036, 8.200000000000228, -64.19999999999996, 23.70000000000012, 77.1, 99.29999999999934, 138.99999999999898, 22.500000000000053, -87.00000000000105, 53.00000000000022, -86.90000000000171, 29.50000000000014, 50.40000000000037, 53.50000000000034, -54.000000000000085, 36.40000000000025, 133.09999999999968, -12.099999999999717, 40.0000000000003, 24.800000000000104, 29.000000000000128, 25.000000000000092, 4.6999999999999424, 22.90000000000006, -44.59999999999971, 81.79999999999917, 75.79999999999959, 49.30000000000008, 19.400000000000055, -72.90000000000006, -19.199999999999527, 28.700000000000124, -11.79999999999991, 24.00000000000003, 29.60000000000013, 174.99999999999898, -80.4000000000008, -53.4999999999997, -22.599999999999767, -137.3000000000008, 34.00000000000021, 29.000000000000128, 31.600000000000183, -22.500000000000107, -77.50000000000006, 65.89999999999998, 54.5000000000004, 28.600000000000122, 18.900000000000023, 79.89999999999915, -40.09999999999998, 11.100000000000097, 10.899999999999975, 144.09999999999937, 30.400000000000166, 38.90000000000028, 37.600000000000264, 35.600000000000236, 72.19999999999993, -26.59999999999951, -31.59999999999969, -15.30000000000002, 38.10000000000019, 38.300000000000274, -17.599999999999582, 33.1000000000002, 16.499999999999996, 157.29999999999924, 25.900000000000084, -117.90000000000109, 40.80000000000031, 50.900000000000176, 52.80000000000022, 63.10000000000035, -69.50000000000071, 16.40000000000041, 16.000000000000053, 29.800000000000143], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, -82.60000000000046, 20.000000000000014, 25.4000000000001, -162.1000000000005, -74.20000000000014, -11.499999999999819, -236.5000000000002, 20.000000000000014, -55.29999999999993, 15.799999999999963, -4.299999999999944, 11.599999999999964, 11.599999999999968, 13.699999999999964, 84.19999999999999, 15.799999999999963, -292.29999999999995, -146.50000000000054, 10.999999999999966, 5.299999999999965, 20.000000000000014, 59.59999999999998, 20.000000000000014, -132.7000000000001, -249.40000000000026, 13.699999999999964, -84.40000000000049, 4.999999999999973, 94.7, 5.299999999999965, 20.000000000000014, -37.59999999999991, -256.00000000000017, 20.000000000000014, -85.60000000000001, -1.9000000000000283, -69.90000000000077, -172.9, -79.0, -288.39999999999964, -166.00000000000026, -57.400000000000304, 24.50000000000008, -3.099999999999958, 10.699999999999985, -69.6999999999999, -75.10000000000085, -185.5, -84.70000000000002, -4.600000000000001, -78.70000000000053, -25.900000000000006, 20.000000000000014, 42.19999999999993, 1.0999999999999865, 5.299999999999965, 121.69999999999962, -3.3999999999999866, -3.099999999999958, -78.7000000000005, -178.30000000000055, 1.0999999999999865, 35.89999999999995, -72.40000000000089, -74.50000000000081, 15.799999999999963, -7.299999999999905, 13.999999999999968, 7.399999999999965, 7.399999999999965, 10.099999999999975, -55.00000000000004, -109.00000000000037, 17.899999999999988, 9.499999999999964, 106.09999999999997, 20.000000000000014, -20.19999999999976, -184.90000000000046, 20.000000000000014, 20.000000000000014, 15.199999999999966, -30.399999999999906, 9.499999999999964, 9.499999999999964, 20.000000000000014, -106.0000000000008, 20.000000000000014, -214.3000000000005, 3.1999999999999615, -34.29999999999976, -156.10000000000045, 9.499999999999964, 20.000000000000014, 54.800000000000196, 20.000000000000014, 24.800000000000107, -153.70000000000005, 56.00000000000023, 24.500000000000064, -93.10000000000056, -116.20000000000002, -129.70000000000053, -30.399999999999764, -38.799999999999756, 9.499999999999964, 3.199999999999965, -75.40000000000023, -27.399999999999793, -187.6000000000003, 20.60000000000001, -103.9, 9.499999999999964, 20.000000000000014, 154.99999999999972, 20.000000000000014, -231.40000000000026, -60.699999999999854, -80.8000000000002, -121.60000000000053, 20.000000000000014, -232.00000000000026, -67.2999999999998, 15.799999999999963, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, 2.899999999999965, 13.699999999999964, -122.50000000000003, -18.999999999999744, 11.599999999999964, -192.1000000000005, 9.499999999999964, -7.5999999999999375, 10.699999999999967, 15.79999999999996, 5.299999999999965, 11.29999999999997, 23.30000000000008, -72.40000000000069, -63.1000000000005, 11.000000000000007, -124.90000000000006, 15.799999999999935, -130.00000000000003, 28.100000000000147, -57.10000000000036, 20.000000000000014, 13.699999999999964, 124.39999999999985, -21.99999999999976, 7.399999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, -3.399999999999958, 15.799999999999963, 15.799999999999963, -15.699999999999747, 50.89999999999999, -7.299999999999891, -64.30000000000089, 13.399999999999968, -124.00000000000048, -145.3, 20.000000000000014, -37.60000000000028, -88.3, 5.299999999999965, 20.000000000000014, -96.70000000000023, 1.0999999999999865, -25.899999999999828, 20.000000000000014, -3.399999999999958, -3.099999999999958, -7.2999999999999154, 149.59999999999982, -48.09999999999978, 20.000000000000014, -119.20000000000061, -126.70000000000047, 24.200000000000077, 2.599999999999961, -167.2000000000005, 94.09999999999998, 21.500000000000036, -3.7000000000000015, -13.899999999999931, 20.000000000000014, -124.90000000000046, -34.59999999999991, 5.600000000000193, -47.19999999999976, -59.50000000000016, 9.499999999999964, 3.1999999999999615, 11.599999999999968], "policy_predator_policy_reward": [45.0, 59.0, 2.0, 3.0, 114.0, 59.0, 135.0, 15.0, 56.0, 11.0, 11.0, 11.0, 4.0, 4.0, 23.0, 14.0, 16.0, 153.0, 70.0, 73.0, 7.0, 0.0, 39.0, 6.0, 83.0, 67.0, 29.0, 66.0, 11.0, 24.0, 7.0, 5.0, 138.0, 64.0, 80.0, 10.0, 22.0, 48.0, 158.0, 168.0, 114.0, 129.0, 25.0, 23.0, 8.0, 37.0, 81.0, 72.0, 88.0, 118.0, 46.0, 61.0, 40.0, 43.0, 32.0, 24.0, 5.0, 7.0, 18.0, 11.0, 97.0, 73.0, 9.0, 7.0, 5.0, 55.0, 9.0, 12.0, 13.0, 16.0, 30.0, 6.0, 63.0, 47.0, 5.0, 4.0, 0.0, 7.0, 99.0, 94.0, 0.0, 0.0, 2.0, 38.0, 5.0, 5.0, 60.0, 51.0, 106.0, 93.0, 28.0, 26.0, 67.0, 35.0, 4.0, 3.0, 15.0, 16.0, 84.0, 63.0, 28.0, 60.0, 98.0, 75.0, 22.0, 28.0, 5.0, 11.0, 59.0, 32.0, 92.0, 99.0, 88.0, 36.0, 0.0, 0.0, 130.0, 1.0, 80.0, 8.0, 79.0, 0.0, 134.0, 28.0, 8.0, 7.0, 0.0, 10.0, 12.0, 3.0, 100.0, 19.0, 2.0, 101.0, 54.0, 10.0, 1.0, 27.0, 12.0, 0.0, 22.0, 46.0, 76.0, 56.0, 69.0, 0.0, 49.0, 64.0, 24.0, 24.0, 3.0, 3.0, 19.0, 26.0, 1.0, 0.0, 9.0, 12.0, 2.0, 2.0, 32.0, 5.0, 44.0, 1.0, 7.0, 72.0, 25.0, 85.0, 77.0, 87.0, 7.0, 6.0, 68.0, 10.0, 16.0, 23.0, 11.0, 12.0, 13.0, 2.0, 34.0, 20.0, 101.0, 27.0, 10.0, 4.0, 48.0, 76.0, 2.0, 33.0, 21.0, 36.0, 6.0, 84.0, 3.0, 55.0, 11.0, 55.0, 8.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8205478944316983, "mean_inference_ms": 2.1369906749370324, "mean_action_processing_ms": 0.34045096975017297, "mean_env_wait_ms": 0.27621852321932283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008291482925415039, "StateBufferConnector_ms": 0.008134007453918457, "ViewRequirementAgentConnector_ms": 0.18489038944244385}, "num_episodes": 18, "episode_return_max": 174.99999999999898, "episode_return_min": -232.10000000000016, "episode_return_mean": 15.181999999999952, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.9924229429385, "num_env_steps_trained_throughput_per_sec": 317.9924229429385, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 12675.004, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12674.961, "sample_time_ms": 2265.768, "learn_time_ms": 10393.217, "learn_throughput": 384.866, "synch_weights_time_ms": 14.368}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "f0d88_00000", "date": "2024-08-14_11-00-55", "timestamp": 1723647655, "time_this_iter_s": 12.631994009017944, "time_total_s": 872.2731266021729, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4f7a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 872.2731266021729, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 50.05, "ram_util_percent": 82.47222222222221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8143683346175643, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.4179490055356707, "policy_loss": -0.03331087312523138, "vf_loss": 3.428935549435792, "vf_explained_var": -0.4961602579664301, "kl": 0.014699148417954668, "entropy": 1.2522618962343408, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9977808816723093, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 3.8355697394678834, "policy_loss": -0.015410234135817047, "vf_loss": 3.833368933894647, "vf_explained_var": 0.08944185997443224, "kl": 0.010307334950089436, "entropy": 1.0175408609960446, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 191.0999999999996, "episode_reward_min": -137.3000000000008, "episode_reward_mean": 19.402000000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -388.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.99999999999972, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -24.529000000000067, "predator_policy": 34.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [52.60000000000036, 8.200000000000228, -64.19999999999996, 23.70000000000012, 77.1, 99.29999999999934, 138.99999999999898, 22.500000000000053, -87.00000000000105, 53.00000000000022, -86.90000000000171, 29.50000000000014, 50.40000000000037, 53.50000000000034, -54.000000000000085, 36.40000000000025, 133.09999999999968, -12.099999999999717, 40.0000000000003, 24.800000000000104, 29.000000000000128, 25.000000000000092, 4.6999999999999424, 22.90000000000006, -44.59999999999971, 81.79999999999917, 75.79999999999959, 49.30000000000008, 19.400000000000055, -72.90000000000006, -19.199999999999527, 28.700000000000124, -11.79999999999991, 24.00000000000003, 29.60000000000013, 174.99999999999898, -80.4000000000008, -53.4999999999997, -22.599999999999767, -137.3000000000008, 34.00000000000021, 29.000000000000128, 31.600000000000183, -22.500000000000107, -77.50000000000006, 65.89999999999998, 54.5000000000004, 28.600000000000122, 18.900000000000023, 79.89999999999915, -40.09999999999998, 11.100000000000097, 10.899999999999975, 144.09999999999937, 30.400000000000166, 38.90000000000028, 37.600000000000264, 35.600000000000236, 72.19999999999993, -26.59999999999951, -31.59999999999969, -15.30000000000002, 38.10000000000019, 38.300000000000274, -17.599999999999582, 33.1000000000002, 16.499999999999996, 157.29999999999924, 25.900000000000084, -117.90000000000109, 40.80000000000031, 50.900000000000176, 52.80000000000022, 63.10000000000035, -69.50000000000071, 16.40000000000041, 16.000000000000053, 29.800000000000143, -19.399999999999757, -31.099999999999888, -5.700000000000003, 29.50000000000014, 30.000000000000142, 28.900000000000155, 191.0999999999996, -25.399999999999537, 35.30000000000033, -67.6, 37.90000000000027, 40.60000000000031, 50.40000000000048, 43.90000000000036, 36.40000000000017, 20.200000000000006, -33.899999999999906, -119.0999999999998, 37.000000000000256, 36.200000000000244, 47.100000000000286, 32.49999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.099999999999958, 10.699999999999985, -69.6999999999999, -75.10000000000085, -185.5, -84.70000000000002, -4.600000000000001, -78.70000000000053, -25.900000000000006, 20.000000000000014, 42.19999999999993, 1.0999999999999865, 5.299999999999965, 121.69999999999962, -3.3999999999999866, -3.099999999999958, -78.7000000000005, -178.30000000000055, 1.0999999999999865, 35.89999999999995, -72.40000000000089, -74.50000000000081, 15.799999999999963, -7.299999999999905, 13.999999999999968, 7.399999999999965, 7.399999999999965, 10.099999999999975, -55.00000000000004, -109.00000000000037, 17.899999999999988, 9.499999999999964, 106.09999999999997, 20.000000000000014, -20.19999999999976, -184.90000000000046, 20.000000000000014, 20.000000000000014, 15.199999999999966, -30.399999999999906, 9.499999999999964, 9.499999999999964, 20.000000000000014, -106.0000000000008, 20.000000000000014, -214.3000000000005, 3.1999999999999615, -34.29999999999976, -156.10000000000045, 9.499999999999964, 20.000000000000014, 54.800000000000196, 20.000000000000014, 24.800000000000107, -153.70000000000005, 56.00000000000023, 24.500000000000064, -93.10000000000056, -116.20000000000002, -129.70000000000053, -30.399999999999764, -38.799999999999756, 9.499999999999964, 3.199999999999965, -75.40000000000023, -27.399999999999793, -187.6000000000003, 20.60000000000001, -103.9, 9.499999999999964, 20.000000000000014, 154.99999999999972, 20.000000000000014, -231.40000000000026, -60.699999999999854, -80.8000000000002, -121.60000000000053, 20.000000000000014, -232.00000000000026, -67.2999999999998, 15.799999999999963, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, 2.899999999999965, 13.699999999999964, -122.50000000000003, -18.999999999999744, 11.599999999999964, -192.1000000000005, 9.499999999999964, -7.5999999999999375, 10.699999999999967, 15.79999999999996, 5.299999999999965, 11.29999999999997, 23.30000000000008, -72.40000000000069, -63.1000000000005, 11.000000000000007, -124.90000000000006, 15.799999999999935, -130.00000000000003, 28.100000000000147, -57.10000000000036, 20.000000000000014, 13.699999999999964, 124.39999999999985, -21.99999999999976, 7.399999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, -3.399999999999958, 15.799999999999963, 15.799999999999963, -15.699999999999747, 50.89999999999999, -7.299999999999891, -64.30000000000089, 13.399999999999968, -124.00000000000048, -145.3, 20.000000000000014, -37.60000000000028, -88.3, 5.299999999999965, 20.000000000000014, -96.70000000000023, 1.0999999999999865, -25.899999999999828, 20.000000000000014, -3.399999999999958, -3.099999999999958, -7.2999999999999154, 149.59999999999982, -48.09999999999978, 20.000000000000014, -119.20000000000061, -126.70000000000047, 24.200000000000077, 2.599999999999961, -167.2000000000005, 94.09999999999998, 21.500000000000036, -3.7000000000000015, -13.899999999999931, 20.000000000000014, -124.90000000000046, -34.59999999999991, 5.600000000000193, -47.19999999999976, -59.50000000000016, 9.499999999999964, 3.1999999999999615, 11.599999999999968, 17.899999999999988, -103.30000000000041, -100.90000000000052, -47.19999999999999, 20.000000000000014, -123.70000000000036, -11.499999999999819, 20.000000000000014, 15.799999999999963, 3.1999999999999615, -62.499999999999865, 31.400000000000208, 108.2, 47.90000000000018, -76.60000000000079, -17.79999999999974, -78.70000000000002, 29.000000000000163, -388.9, -3.700000000000012, -3.099999999999958, 20.000000000000014, 3.1999999999999615, -10.599999999999865, 5.299999999999965, 28.10000000000015, 20.000000000000014, 20.900000000000027, -37.29999999999995, -7.299999999999891, 4.099999999999966, 1.0999999999999865, -0.9999999999999846, -175.9, -165.70000000000047, -156.39999999999984, 17.899999999999988, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 17.899999999999988, 27.200000000000003, 11.599999999999964, -21.100000000000023], "policy_predator_policy_reward": [8.0, 37.0, 81.0, 72.0, 88.0, 118.0, 46.0, 61.0, 40.0, 43.0, 32.0, 24.0, 5.0, 7.0, 18.0, 11.0, 97.0, 73.0, 9.0, 7.0, 5.0, 55.0, 9.0, 12.0, 13.0, 16.0, 30.0, 6.0, 63.0, 47.0, 5.0, 4.0, 0.0, 7.0, 99.0, 94.0, 0.0, 0.0, 2.0, 38.0, 5.0, 5.0, 60.0, 51.0, 106.0, 93.0, 28.0, 26.0, 67.0, 35.0, 4.0, 3.0, 15.0, 16.0, 84.0, 63.0, 28.0, 60.0, 98.0, 75.0, 22.0, 28.0, 5.0, 11.0, 59.0, 32.0, 92.0, 99.0, 88.0, 36.0, 0.0, 0.0, 130.0, 1.0, 80.0, 8.0, 79.0, 0.0, 134.0, 28.0, 8.0, 7.0, 0.0, 10.0, 12.0, 3.0, 100.0, 19.0, 2.0, 101.0, 54.0, 10.0, 1.0, 27.0, 12.0, 0.0, 22.0, 46.0, 76.0, 56.0, 69.0, 0.0, 49.0, 64.0, 24.0, 24.0, 3.0, 3.0, 19.0, 26.0, 1.0, 0.0, 9.0, 12.0, 2.0, 2.0, 32.0, 5.0, 44.0, 1.0, 7.0, 72.0, 25.0, 85.0, 77.0, 87.0, 7.0, 6.0, 68.0, 10.0, 16.0, 23.0, 11.0, 12.0, 13.0, 2.0, 34.0, 20.0, 101.0, 27.0, 10.0, 4.0, 48.0, 76.0, 2.0, 33.0, 21.0, 36.0, 6.0, 84.0, 3.0, 55.0, 11.0, 55.0, 8.0, 7.0, 3.0, 63.0, 13.0, 104.0, 75.0, 23.0, 6.0, 15.0, 8.0, 3.0, 12.0, 48.0, 28.0, 7.0, 16.0, 53.0, 44.0, 41.0, 132.0, 193.0, 11.0, 10.0, 27.0, 21.0, 8.0, 9.0, 1.0, 2.0, 13.0, 68.0, 6.0, 9.0, 76.0, 67.0, 114.0, 89.0, 9.0, 9.0, 8.0, 5.0, 1.0, 1.0, 37.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8257546742547368, "mean_inference_ms": 2.149265407103394, "mean_action_processing_ms": 0.34221908465233036, "mean_env_wait_ms": 0.2774580854583142, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009013652801513672, "StateBufferConnector_ms": 0.008992195129394531, "ViewRequirementAgentConnector_ms": 0.16355609893798828}, "num_episodes": 22, "episode_return_max": 191.0999999999996, "episode_return_min": -137.3000000000008, "episode_return_mean": 19.402000000000015, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.60006740284683, "num_env_steps_trained_throughput_per_sec": 316.60006740284683, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 12674.158, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12674.114, "sample_time_ms": 2286.195, "learn_time_ms": 10372.03, "learn_throughput": 385.653, "synch_weights_time_ms": 14.404}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "f0d88_00000", "date": "2024-08-14_11-01-08", "timestamp": 1723647668, "time_this_iter_s": 12.670653820037842, "time_total_s": 884.9437804222107, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4f7ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 884.9437804222107, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 48.86666666666666, "ram_util_percent": 82.50555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7464463603244256, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.684551539622918, "policy_loss": -0.03079736753682256, "vf_loss": 4.693823310811684, "vf_explained_var": -0.8728281394514458, "kl": 0.014173226744692305, "entropy": 1.2624199018276558, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.371731083260642, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 3.8876633052472713, "policy_loss": -0.01361786820457647, "vf_loss": 3.885284377279736, "vf_explained_var": 0.13502250632281027, "kl": 0.009362547672147316, "entropy": 0.9940878397573238, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 191.0999999999996, "episode_reward_min": -171.20000000000036, "episode_reward_mean": 14.243000000000022, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -388.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.99999999999972, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -28.98350000000006, "predator_policy": 36.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.90000000000006, -44.59999999999971, 81.79999999999917, 75.79999999999959, 49.30000000000008, 19.400000000000055, -72.90000000000006, -19.199999999999527, 28.700000000000124, -11.79999999999991, 24.00000000000003, 29.60000000000013, 174.99999999999898, -80.4000000000008, -53.4999999999997, -22.599999999999767, -137.3000000000008, 34.00000000000021, 29.000000000000128, 31.600000000000183, -22.500000000000107, -77.50000000000006, 65.89999999999998, 54.5000000000004, 28.600000000000122, 18.900000000000023, 79.89999999999915, -40.09999999999998, 11.100000000000097, 10.899999999999975, 144.09999999999937, 30.400000000000166, 38.90000000000028, 37.600000000000264, 35.600000000000236, 72.19999999999993, -26.59999999999951, -31.59999999999969, -15.30000000000002, 38.10000000000019, 38.300000000000274, -17.599999999999582, 33.1000000000002, 16.499999999999996, 157.29999999999924, 25.900000000000084, -117.90000000000109, 40.80000000000031, 50.900000000000176, 52.80000000000022, 63.10000000000035, -69.50000000000071, 16.40000000000041, 16.000000000000053, 29.800000000000143, -19.399999999999757, -31.099999999999888, -5.700000000000003, 29.50000000000014, 30.000000000000142, 28.900000000000155, 191.0999999999996, -25.399999999999537, 35.30000000000033, -67.6, 37.90000000000027, 40.60000000000031, 50.40000000000048, 43.90000000000036, 36.40000000000017, 20.200000000000006, -33.899999999999906, -119.0999999999998, 37.000000000000256, 36.200000000000244, 47.100000000000286, 32.49999999999996, 145.29999999999944, 10.79999999999996, -121.70000000000046, 71.39999999999984, -24.799999999999613, 39.20000000000026, 9.59999999999997, 11.300000000000145, -84.09999999999991, -66.70000000000061, 48.60000000000029, 134.49999999999966, -15.19999999999955, 19.499999999999975, 35.90000000000016, -10.900000000000082, -43.1000000000002, 74.09999999999945, -42.49999999999968, 37.600000000000264, 4.900000000000128, 19.2, -171.20000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, -34.29999999999976, -156.10000000000045, 9.499999999999964, 20.000000000000014, 54.800000000000196, 20.000000000000014, 24.800000000000107, -153.70000000000005, 56.00000000000023, 24.500000000000064, -93.10000000000056, -116.20000000000002, -129.70000000000053, -30.399999999999764, -38.799999999999756, 9.499999999999964, 3.199999999999965, -75.40000000000023, -27.399999999999793, -187.6000000000003, 20.60000000000001, -103.9, 9.499999999999964, 20.000000000000014, 154.99999999999972, 20.000000000000014, -231.40000000000026, -60.699999999999854, -80.8000000000002, -121.60000000000053, 20.000000000000014, -232.00000000000026, -67.2999999999998, 15.799999999999963, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, 2.899999999999965, 13.699999999999964, -122.50000000000003, -18.999999999999744, 11.599999999999964, -192.1000000000005, 9.499999999999964, -7.5999999999999375, 10.699999999999967, 15.79999999999996, 5.299999999999965, 11.29999999999997, 23.30000000000008, -72.40000000000069, -63.1000000000005, 11.000000000000007, -124.90000000000006, 15.799999999999935, -130.00000000000003, 28.100000000000147, -57.10000000000036, 20.000000000000014, 13.699999999999964, 124.39999999999985, -21.99999999999976, 7.399999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, -3.399999999999958, 15.799999999999963, 15.799999999999963, -15.699999999999747, 50.89999999999999, -7.299999999999891, -64.30000000000089, 13.399999999999968, -124.00000000000048, -145.3, 20.000000000000014, -37.60000000000028, -88.3, 5.299999999999965, 20.000000000000014, -96.70000000000023, 1.0999999999999865, -25.899999999999828, 20.000000000000014, -3.399999999999958, -3.099999999999958, -7.2999999999999154, 149.59999999999982, -48.09999999999978, 20.000000000000014, -119.20000000000061, -126.70000000000047, 24.200000000000077, 2.599999999999961, -167.2000000000005, 94.09999999999998, 21.500000000000036, -3.7000000000000015, -13.899999999999931, 20.000000000000014, -124.90000000000046, -34.59999999999991, 5.600000000000193, -47.19999999999976, -59.50000000000016, 9.499999999999964, 3.1999999999999615, 11.599999999999968, 17.899999999999988, -103.30000000000041, -100.90000000000052, -47.19999999999999, 20.000000000000014, -123.70000000000036, -11.499999999999819, 20.000000000000014, 15.799999999999963, 3.1999999999999615, -62.499999999999865, 31.400000000000208, 108.2, 47.90000000000018, -76.60000000000079, -17.79999999999974, -78.70000000000002, 29.000000000000163, -388.9, -3.700000000000012, -3.099999999999958, 20.000000000000014, 3.1999999999999615, -10.599999999999865, 5.299999999999965, 28.10000000000015, 20.000000000000014, 20.900000000000027, -37.29999999999995, -7.299999999999891, 4.099999999999966, 1.0999999999999865, -0.9999999999999846, -175.9, -165.70000000000047, -156.39999999999984, 17.899999999999988, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 17.899999999999988, 27.200000000000003, 11.599999999999964, -21.100000000000023, 86.3, 20.000000000000014, -24.099999999999852, -30.099999999999817, -267.7000000000001, -0.9999999999999846, 11.599999999999964, 36.79999999999998, -160.6000000000006, -35.19999999999976, 26.90000000000012, -27.699999999999754, -274.0, -9.399999999999928, 0.19999999999998655, -19.900000000000013, -9.099999999999984, -295.00000000000017, -89.20000000000036, -74.50000000000085, 85.39999999999992, -101.8000000000008, 20.000000000000014, 81.50000000000006, 20.000000000000014, -86.20000000000084, -10.599999999999843, 1.0999999999999865, 17.899999999999988, -94.00000000000009, -68.19999999999995, 5.299999999999965, -164.70000000000033, 11.599999999999964, -40.599999999999994, 13.699999999999964, -17.800000000000022, -90.69999999999996, 13.699999999999964, 17.899999999999988, -15.99999999999976, -48.09999999999979, 20.000000000000014, -53.80000000000014, -91.60000000000034, -283.6], "policy_predator_policy_reward": [28.0, 26.0, 67.0, 35.0, 4.0, 3.0, 15.0, 16.0, 84.0, 63.0, 28.0, 60.0, 98.0, 75.0, 22.0, 28.0, 5.0, 11.0, 59.0, 32.0, 92.0, 99.0, 88.0, 36.0, 0.0, 0.0, 130.0, 1.0, 80.0, 8.0, 79.0, 0.0, 134.0, 28.0, 8.0, 7.0, 0.0, 10.0, 12.0, 3.0, 100.0, 19.0, 2.0, 101.0, 54.0, 10.0, 1.0, 27.0, 12.0, 0.0, 22.0, 46.0, 76.0, 56.0, 69.0, 0.0, 49.0, 64.0, 24.0, 24.0, 3.0, 3.0, 19.0, 26.0, 1.0, 0.0, 9.0, 12.0, 2.0, 2.0, 32.0, 5.0, 44.0, 1.0, 7.0, 72.0, 25.0, 85.0, 77.0, 87.0, 7.0, 6.0, 68.0, 10.0, 16.0, 23.0, 11.0, 12.0, 13.0, 2.0, 34.0, 20.0, 101.0, 27.0, 10.0, 4.0, 48.0, 76.0, 2.0, 33.0, 21.0, 36.0, 6.0, 84.0, 3.0, 55.0, 11.0, 55.0, 8.0, 7.0, 3.0, 63.0, 13.0, 104.0, 75.0, 23.0, 6.0, 15.0, 8.0, 3.0, 12.0, 48.0, 28.0, 7.0, 16.0, 53.0, 44.0, 41.0, 132.0, 193.0, 11.0, 10.0, 27.0, 21.0, 8.0, 9.0, 1.0, 2.0, 13.0, 68.0, 6.0, 9.0, 76.0, 67.0, 114.0, 89.0, 9.0, 9.0, 8.0, 5.0, 1.0, 1.0, 37.0, 5.0, 7.0, 32.0, 49.0, 16.0, 10.0, 137.0, 19.0, 4.0, 83.0, 88.0, 16.0, 24.0, 149.0, 144.0, 19.0, 12.0, 95.0, 125.0, 97.0, 0.0, 7.0, 58.0, 17.0, 16.0, 51.0, 0.0, 12.0, 17.0, 41.0, 71.0, 45.0, 7.0, 10.0, 100.0, 33.0, 68.0, 2.0, 64.0, 3.0, 3.0, 35.0, 34.0, 22.0, 31.0, 67.0, 137.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8319075222836289, "mean_inference_ms": 2.161243791361851, "mean_action_processing_ms": 0.344445365714801, "mean_env_wait_ms": 0.27880950015109973, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008821368217468262, "StateBufferConnector_ms": 0.009974241256713867, "ViewRequirementAgentConnector_ms": 0.1809687614440918}, "num_episodes": 23, "episode_return_max": 191.0999999999996, "episode_return_min": -171.20000000000036, "episode_return_mean": 14.243000000000022, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 309.15154554802996, "num_env_steps_trained_throughput_per_sec": 309.15154554802996, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 12710.828, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12710.785, "sample_time_ms": 2334.349, "learn_time_ms": 10360.566, "learn_throughput": 386.079, "synch_weights_time_ms": 14.384}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "f0d88_00000", "date": "2024-08-14_11-01-21", "timestamp": 1723647681, "time_this_iter_s": 12.99990701675415, "time_total_s": 897.9436874389648, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad595790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 897.9436874389648, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 50.544444444444444, "ram_util_percent": 82.68888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.009928465015674, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.118478562466051, "policy_loss": -0.02048758271928857, "vf_loss": 4.11822361555049, "vf_explained_var": -0.5970941916975395, "kl": 0.013657644145799744, "entropy": 1.3078592772206301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2821170518322598, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 3.2655957883627957, "policy_loss": -0.011515862346385365, "vf_loss": 3.2624491296748004, "vf_explained_var": 0.13121847295887257, "kl": 0.008581627515166024, "entropy": 1.018756884872598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 191.0999999999996, "episode_reward_min": -190.10000000000096, "episode_reward_mean": 14.53700000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -388.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 149.59999999999982, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -27.591500000000067, "predator_policy": 34.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.000000000000128, 31.600000000000183, -22.500000000000107, -77.50000000000006, 65.89999999999998, 54.5000000000004, 28.600000000000122, 18.900000000000023, 79.89999999999915, -40.09999999999998, 11.100000000000097, 10.899999999999975, 144.09999999999937, 30.400000000000166, 38.90000000000028, 37.600000000000264, 35.600000000000236, 72.19999999999993, -26.59999999999951, -31.59999999999969, -15.30000000000002, 38.10000000000019, 38.300000000000274, -17.599999999999582, 33.1000000000002, 16.499999999999996, 157.29999999999924, 25.900000000000084, -117.90000000000109, 40.80000000000031, 50.900000000000176, 52.80000000000022, 63.10000000000035, -69.50000000000071, 16.40000000000041, 16.000000000000053, 29.800000000000143, -19.399999999999757, -31.099999999999888, -5.700000000000003, 29.50000000000014, 30.000000000000142, 28.900000000000155, 191.0999999999996, -25.399999999999537, 35.30000000000033, -67.6, 37.90000000000027, 40.60000000000031, 50.40000000000048, 43.90000000000036, 36.40000000000017, 20.200000000000006, -33.899999999999906, -119.0999999999998, 37.000000000000256, 36.200000000000244, 47.100000000000286, 32.49999999999996, 145.29999999999944, 10.79999999999996, -121.70000000000046, 71.39999999999984, -24.799999999999613, 39.20000000000026, 9.59999999999997, 11.300000000000145, -84.09999999999991, -66.70000000000061, 48.60000000000029, 134.49999999999966, -15.19999999999955, 19.499999999999975, 35.90000000000016, -10.900000000000082, -43.1000000000002, 74.09999999999945, -42.49999999999968, 37.600000000000264, 4.900000000000128, 19.2, -171.20000000000036, 144.9999999999997, 24.600000000000048, -133.40000000000052, 11.299999999999997, -66.69999999999982, 40.0000000000003, -14.399999999999991, 116.99999999999903, 97.2999999999989, -190.10000000000096, 33.400000000000226, 11.100000000000014, 49.100000000000456, -21.10000000000003, 7.200000000000035, -16.59999999999991, 0.5000000000001716, 33.400000000000205], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.9999999999999846, 20.000000000000014, 2.899999999999965, 13.699999999999964, -122.50000000000003, -18.999999999999744, 11.599999999999964, -192.1000000000005, 9.499999999999964, -7.5999999999999375, 10.699999999999967, 15.79999999999996, 5.299999999999965, 11.29999999999997, 23.30000000000008, -72.40000000000069, -63.1000000000005, 11.000000000000007, -124.90000000000006, 15.799999999999935, -130.00000000000003, 28.100000000000147, -57.10000000000036, 20.000000000000014, 13.699999999999964, 124.39999999999985, -21.99999999999976, 7.399999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, -3.399999999999958, 15.799999999999963, 15.799999999999963, -15.699999999999747, 50.89999999999999, -7.299999999999891, -64.30000000000089, 13.399999999999968, -124.00000000000048, -145.3, 20.000000000000014, -37.60000000000028, -88.3, 5.299999999999965, 20.000000000000014, -96.70000000000023, 1.0999999999999865, -25.899999999999828, 20.000000000000014, -3.399999999999958, -3.099999999999958, -7.2999999999999154, 149.59999999999982, -48.09999999999978, 20.000000000000014, -119.20000000000061, -126.70000000000047, 24.200000000000077, 2.599999999999961, -167.2000000000005, 94.09999999999998, 21.500000000000036, -3.7000000000000015, -13.899999999999931, 20.000000000000014, -124.90000000000046, -34.59999999999991, 5.600000000000193, -47.19999999999976, -59.50000000000016, 9.499999999999964, 3.1999999999999615, 11.599999999999968, 17.899999999999988, -103.30000000000041, -100.90000000000052, -47.19999999999999, 20.000000000000014, -123.70000000000036, -11.499999999999819, 20.000000000000014, 15.799999999999963, 3.1999999999999615, -62.499999999999865, 31.400000000000208, 108.2, 47.90000000000018, -76.60000000000079, -17.79999999999974, -78.70000000000002, 29.000000000000163, -388.9, -3.700000000000012, -3.099999999999958, 20.000000000000014, 3.1999999999999615, -10.599999999999865, 5.299999999999965, 28.10000000000015, 20.000000000000014, 20.900000000000027, -37.29999999999995, -7.299999999999891, 4.099999999999966, 1.0999999999999865, -0.9999999999999846, -175.9, -165.70000000000047, -156.39999999999984, 17.899999999999988, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 17.899999999999988, 27.200000000000003, 11.599999999999964, -21.100000000000023, 86.3, 20.000000000000014, -24.099999999999852, -30.099999999999817, -267.7000000000001, -0.9999999999999846, 11.599999999999964, 36.79999999999998, -160.6000000000006, -35.19999999999976, 26.90000000000012, -27.699999999999754, -274.0, -9.399999999999928, 0.19999999999998655, -19.900000000000013, -9.099999999999984, -295.00000000000017, -89.20000000000036, -74.50000000000085, 85.39999999999992, -101.8000000000008, 20.000000000000014, 81.50000000000006, 20.000000000000014, -86.20000000000084, -10.599999999999843, 1.0999999999999865, 17.899999999999988, -94.00000000000009, -68.19999999999995, 5.299999999999965, -164.70000000000033, 11.599999999999964, -40.599999999999994, 13.699999999999964, -17.800000000000022, -90.69999999999996, 13.699999999999964, 17.899999999999988, -15.99999999999976, -48.09999999999979, 20.000000000000014, -53.80000000000014, -91.60000000000034, -283.6, -32.79999999999977, 144.79999999999998, 5.299999999999965, 5.299999999999965, -277.0, -33.399999999999814, -101.80000000000081, 31.100000000000158, -34.59999999999993, -129.10000000000042, 20.000000000000014, 20.000000000000014, -9.400000000000032, -127.0, 13.699999999999964, 74.2999999999997, 92.89999999999947, -13.599999999999989, -129.10000000000045, -211.00000000000045, -24.999999999999858, 7.399999999999965, 20.000000000000014, -61.900000000000766, -23.499999999999766, 23.600000000000065, 5.000000000000042, -129.1000000000007, -110.80000000000075, 20.000000000000014, -143.8000000000007, 0.20000000000000195, -26.799999999999756, -63.70000000000065, 20.000000000000014, 7.399999999999965], "policy_predator_policy_reward": [0.0, 10.0, 12.0, 3.0, 100.0, 19.0, 2.0, 101.0, 54.0, 10.0, 1.0, 27.0, 12.0, 0.0, 22.0, 46.0, 76.0, 56.0, 69.0, 0.0, 49.0, 64.0, 24.0, 24.0, 3.0, 3.0, 19.0, 26.0, 1.0, 0.0, 9.0, 12.0, 2.0, 2.0, 32.0, 5.0, 44.0, 1.0, 7.0, 72.0, 25.0, 85.0, 77.0, 87.0, 7.0, 6.0, 68.0, 10.0, 16.0, 23.0, 11.0, 12.0, 13.0, 2.0, 34.0, 20.0, 101.0, 27.0, 10.0, 4.0, 48.0, 76.0, 2.0, 33.0, 21.0, 36.0, 6.0, 84.0, 3.0, 55.0, 11.0, 55.0, 8.0, 7.0, 3.0, 63.0, 13.0, 104.0, 75.0, 23.0, 6.0, 15.0, 8.0, 3.0, 12.0, 48.0, 28.0, 7.0, 16.0, 53.0, 44.0, 41.0, 132.0, 193.0, 11.0, 10.0, 27.0, 21.0, 8.0, 9.0, 1.0, 2.0, 13.0, 68.0, 6.0, 9.0, 76.0, 67.0, 114.0, 89.0, 9.0, 9.0, 8.0, 5.0, 1.0, 1.0, 37.0, 5.0, 7.0, 32.0, 49.0, 16.0, 10.0, 137.0, 19.0, 4.0, 83.0, 88.0, 16.0, 24.0, 149.0, 144.0, 19.0, 12.0, 95.0, 125.0, 97.0, 0.0, 7.0, 58.0, 17.0, 16.0, 51.0, 0.0, 12.0, 17.0, 41.0, 71.0, 45.0, 7.0, 10.0, 100.0, 33.0, 68.0, 2.0, 64.0, 3.0, 3.0, 35.0, 34.0, 22.0, 31.0, 67.0, 137.0, 8.0, 25.0, 7.0, 7.0, 60.0, 117.0, 33.0, 49.0, 0.0, 97.0, 0.0, 0.0, 56.0, 66.0, 9.0, 20.0, 6.0, 12.0, 8.0, 142.0, 45.0, 6.0, 14.0, 39.0, 25.0, 24.0, 83.0, 20.0, 55.0, 43.0, 49.0, 78.0, 46.0, 45.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8353567673308845, "mean_inference_ms": 2.171354426733612, "mean_action_processing_ms": 0.34557388790312615, "mean_env_wait_ms": 0.27963570206800037, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007462620735168457, "StateBufferConnector_ms": 0.005344271659851074, "ViewRequirementAgentConnector_ms": 0.16874456405639648}, "num_episodes": 18, "episode_return_max": 191.0999999999996, "episode_return_min": -190.10000000000096, "episode_return_mean": 14.53700000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 312.312295318198, "num_env_steps_trained_throughput_per_sec": 312.312295318198, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 12726.055, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12726.009, "sample_time_ms": 2355.899, "learn_time_ms": 10353.914, "learn_throughput": 386.327, "synch_weights_time_ms": 14.675}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "f0d88_00000", "date": "2024-08-14_11-01-34", "timestamp": 1723647694, "time_this_iter_s": 12.847604036331177, "time_total_s": 910.791291475296, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4f7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 910.791291475296, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 49.810526315789474, "ram_util_percent": 82.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0615545448487396, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.946521584823649, "policy_loss": -0.023559161946399225, "vf_loss": 3.9487228358233417, "vf_explained_var": -0.5247434671278353, "kl": 0.014062821541971905, "entropy": 1.3462165223227607, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.141121993556855, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 2.536153677720872, "policy_loss": -0.015320235413065545, "vf_loss": 2.5383692757793206, "vf_explained_var": 0.18841299260104144, "kl": 0.007669836398752753, "entropy": 1.0801153236280674, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 191.0999999999996, "episode_reward_min": -190.10000000000096, "episode_reward_mean": 9.519000000000032, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -388.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 149.59999999999982, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -31.110500000000073, "predator_policy": 35.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-26.59999999999951, -31.59999999999969, -15.30000000000002, 38.10000000000019, 38.300000000000274, -17.599999999999582, 33.1000000000002, 16.499999999999996, 157.29999999999924, 25.900000000000084, -117.90000000000109, 40.80000000000031, 50.900000000000176, 52.80000000000022, 63.10000000000035, -69.50000000000071, 16.40000000000041, 16.000000000000053, 29.800000000000143, -19.399999999999757, -31.099999999999888, -5.700000000000003, 29.50000000000014, 30.000000000000142, 28.900000000000155, 191.0999999999996, -25.399999999999537, 35.30000000000033, -67.6, 37.90000000000027, 40.60000000000031, 50.40000000000048, 43.90000000000036, 36.40000000000017, 20.200000000000006, -33.899999999999906, -119.0999999999998, 37.000000000000256, 36.200000000000244, 47.100000000000286, 32.49999999999996, 145.29999999999944, 10.79999999999996, -121.70000000000046, 71.39999999999984, -24.799999999999613, 39.20000000000026, 9.59999999999997, 11.300000000000145, -84.09999999999991, -66.70000000000061, 48.60000000000029, 134.49999999999966, -15.19999999999955, 19.499999999999975, 35.90000000000016, -10.900000000000082, -43.1000000000002, 74.09999999999945, -42.49999999999968, 37.600000000000264, 4.900000000000128, 19.2, -171.20000000000036, 144.9999999999997, 24.600000000000048, -133.40000000000052, 11.299999999999997, -66.69999999999982, 40.0000000000003, -14.399999999999991, 116.99999999999903, 97.2999999999989, -190.10000000000096, 33.400000000000226, 11.100000000000014, 49.100000000000456, -21.10000000000003, 7.200000000000035, -16.59999999999991, 0.5000000000001716, 33.400000000000205, 76.1999999999999, 37.10000000000025, -27.59999999999954, -23.79999999999957, 25.500000000000068, 49.700000000000315, -65.80000000000035, 31.000000000000163, -56.79999999999969, 29.300000000000136, 40.0000000000003, 81.09999999999991, 27.90000000000011, 29.000000000000124, -148.10000000000082, 47.20000000000044, -81.40000000000074, -23.199999999999577], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-7.299999999999891, -64.30000000000089, 13.399999999999968, -124.00000000000048, -145.3, 20.000000000000014, -37.60000000000028, -88.3, 5.299999999999965, 20.000000000000014, -96.70000000000023, 1.0999999999999865, -25.899999999999828, 20.000000000000014, -3.399999999999958, -3.099999999999958, -7.2999999999999154, 149.59999999999982, -48.09999999999978, 20.000000000000014, -119.20000000000061, -126.70000000000047, 24.200000000000077, 2.599999999999961, -167.2000000000005, 94.09999999999998, 21.500000000000036, -3.7000000000000015, -13.899999999999931, 20.000000000000014, -124.90000000000046, -34.59999999999991, 5.600000000000193, -47.19999999999976, -59.50000000000016, 9.499999999999964, 3.1999999999999615, 11.599999999999968, 17.899999999999988, -103.30000000000041, -100.90000000000052, -47.19999999999999, 20.000000000000014, -123.70000000000036, -11.499999999999819, 20.000000000000014, 15.799999999999963, 3.1999999999999615, -62.499999999999865, 31.400000000000208, 108.2, 47.90000000000018, -76.60000000000079, -17.79999999999974, -78.70000000000002, 29.000000000000163, -388.9, -3.700000000000012, -3.099999999999958, 20.000000000000014, 3.1999999999999615, -10.599999999999865, 5.299999999999965, 28.10000000000015, 20.000000000000014, 20.900000000000027, -37.29999999999995, -7.299999999999891, 4.099999999999966, 1.0999999999999865, -0.9999999999999846, -175.9, -165.70000000000047, -156.39999999999984, 17.899999999999988, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 17.899999999999988, 27.200000000000003, 11.599999999999964, -21.100000000000023, 86.3, 20.000000000000014, -24.099999999999852, -30.099999999999817, -267.7000000000001, -0.9999999999999846, 11.599999999999964, 36.79999999999998, -160.6000000000006, -35.19999999999976, 26.90000000000012, -27.699999999999754, -274.0, -9.399999999999928, 0.19999999999998655, -19.900000000000013, -9.099999999999984, -295.00000000000017, -89.20000000000036, -74.50000000000085, 85.39999999999992, -101.8000000000008, 20.000000000000014, 81.50000000000006, 20.000000000000014, -86.20000000000084, -10.599999999999843, 1.0999999999999865, 17.899999999999988, -94.00000000000009, -68.19999999999995, 5.299999999999965, -164.70000000000033, 11.599999999999964, -40.599999999999994, 13.699999999999964, -17.800000000000022, -90.69999999999996, 13.699999999999964, 17.899999999999988, -15.99999999999976, -48.09999999999979, 20.000000000000014, -53.80000000000014, -91.60000000000034, -283.6, -32.79999999999977, 144.79999999999998, 5.299999999999965, 5.299999999999965, -277.0, -33.399999999999814, -101.80000000000081, 31.100000000000158, -34.59999999999993, -129.10000000000042, 20.000000000000014, 20.000000000000014, -9.400000000000032, -127.0, 13.699999999999964, 74.2999999999997, 92.89999999999947, -13.599999999999989, -129.10000000000045, -211.00000000000045, -24.999999999999858, 7.399999999999965, 20.000000000000014, -61.900000000000766, -23.499999999999766, 23.600000000000065, 5.000000000000042, -129.1000000000007, -110.80000000000075, 20.000000000000014, -143.8000000000007, 0.20000000000000195, -26.799999999999756, -63.70000000000065, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 65.00000000000004, 9.499999999999964, 14.599999999999968, -90.40000000000077, -5.1999999999999265, -0.9999999999999846, -89.80000000000075, 17.899999999999988, -6.399999999999908, -30.39999999999975, 28.100000000000087, -9.099999999999941, -291.69999999999925, 1.9999999999999731, 20.000000000000014, -132.40000000000023, -36.399999999999764, -71.80000000000081, 28.10000000000015, 20.000000000000014, 20.000000000000014, 15.799999999999963, 53.3000000000001, 17.899999999999988, -0.9999999999999846, 11.599999999999964, 7.399999999999965, -99.70000000000051, -177.40000000000038, -4.600000000000014, -17.199999999999747, -231.10000000000014, 13.699999999999964, -11.499999999999826, -90.70000000000041], "policy_predator_policy_reward": [44.0, 1.0, 7.0, 72.0, 25.0, 85.0, 77.0, 87.0, 7.0, 6.0, 68.0, 10.0, 16.0, 23.0, 11.0, 12.0, 13.0, 2.0, 34.0, 20.0, 101.0, 27.0, 10.0, 4.0, 48.0, 76.0, 2.0, 33.0, 21.0, 36.0, 6.0, 84.0, 3.0, 55.0, 11.0, 55.0, 8.0, 7.0, 3.0, 63.0, 13.0, 104.0, 75.0, 23.0, 6.0, 15.0, 8.0, 3.0, 12.0, 48.0, 28.0, 7.0, 16.0, 53.0, 44.0, 41.0, 132.0, 193.0, 11.0, 10.0, 27.0, 21.0, 8.0, 9.0, 1.0, 2.0, 13.0, 68.0, 6.0, 9.0, 76.0, 67.0, 114.0, 89.0, 9.0, 9.0, 8.0, 5.0, 1.0, 1.0, 37.0, 5.0, 7.0, 32.0, 49.0, 16.0, 10.0, 137.0, 19.0, 4.0, 83.0, 88.0, 16.0, 24.0, 149.0, 144.0, 19.0, 12.0, 95.0, 125.0, 97.0, 0.0, 7.0, 58.0, 17.0, 16.0, 51.0, 0.0, 12.0, 17.0, 41.0, 71.0, 45.0, 7.0, 10.0, 100.0, 33.0, 68.0, 2.0, 64.0, 3.0, 3.0, 35.0, 34.0, 22.0, 31.0, 67.0, 137.0, 8.0, 25.0, 7.0, 7.0, 60.0, 117.0, 33.0, 49.0, 0.0, 97.0, 0.0, 0.0, 56.0, 66.0, 9.0, 20.0, 6.0, 12.0, 8.0, 142.0, 45.0, 6.0, 14.0, 39.0, 25.0, 24.0, 83.0, 20.0, 55.0, 43.0, 49.0, 78.0, 46.0, 45.0, 0.0, 6.0, 0.0, 8.0, 8.0, 5.0, 12.0, 56.0, 56.0, 11.0, 11.0, 3.0, 24.0, 28.0, 133.0, 102.0, 0.0, 9.0, 49.0, 63.0, 46.0, 27.0, 0.0, 0.0, 0.0, 12.0, 10.0, 1.0, 4.0, 6.0, 121.0, 8.0, 38.0, 31.0, 29.0, 107.0, 47.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8394747988902451, "mean_inference_ms": 2.1810158725080813, "mean_action_processing_ms": 0.34694815702512216, "mean_env_wait_ms": 0.2806105304642492, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007113456726074219, "StateBufferConnector_ms": 0.0053446292877197266, "ViewRequirementAgentConnector_ms": 0.16976511478424072}, "num_episodes": 18, "episode_return_max": 191.0999999999996, "episode_return_min": -190.10000000000096, "episode_return_mean": 9.519000000000032, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.47624509689626, "num_env_steps_trained_throughput_per_sec": 315.47624509689626, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 12731.876, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12731.83, "sample_time_ms": 2369.629, "learn_time_ms": 10345.218, "learn_throughput": 386.652, "synch_weights_time_ms": 15.171}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "f0d88_00000", "date": "2024-08-14_11-01-46", "timestamp": 1723647706, "time_this_iter_s": 12.7270348072052, "time_total_s": 923.5183262825012, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad542790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 923.5183262825012, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 49.327777777777776, "ram_util_percent": 82.8111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1496780907035506, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.199690826860055, "policy_loss": -0.02191365607348936, "vf_loss": 4.199341608986022, "vf_explained_var": -0.47426818855225095, "kl": 0.014658684109881215, "entropy": 1.3333584617054652, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9428496780849638, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 2.424433503642915, "policy_loss": -0.015365977510415688, "vf_loss": 2.4247409840109486, "vf_explained_var": 0.1598691562496165, "kl": 0.008813382495176728, "entropy": 1.0331193303935742, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 191.0999999999996, "episode_reward_min": -194.8000000000013, "episode_reward_mean": 8.510000000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -388.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 144.79999999999998, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -30.590000000000074, "predator_policy": 34.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.50000000000014, 30.000000000000142, 28.900000000000155, 191.0999999999996, -25.399999999999537, 35.30000000000033, -67.6, 37.90000000000027, 40.60000000000031, 50.40000000000048, 43.90000000000036, 36.40000000000017, 20.200000000000006, -33.899999999999906, -119.0999999999998, 37.000000000000256, 36.200000000000244, 47.100000000000286, 32.49999999999996, 145.29999999999944, 10.79999999999996, -121.70000000000046, 71.39999999999984, -24.799999999999613, 39.20000000000026, 9.59999999999997, 11.300000000000145, -84.09999999999991, -66.70000000000061, 48.60000000000029, 134.49999999999966, -15.19999999999955, 19.499999999999975, 35.90000000000016, -10.900000000000082, -43.1000000000002, 74.09999999999945, -42.49999999999968, 37.600000000000264, 4.900000000000128, 19.2, -171.20000000000036, 144.9999999999997, 24.600000000000048, -133.40000000000052, 11.299999999999997, -66.69999999999982, 40.0000000000003, -14.399999999999991, 116.99999999999903, 97.2999999999989, -190.10000000000096, 33.400000000000226, 11.100000000000014, 49.100000000000456, -21.10000000000003, 7.200000000000035, -16.59999999999991, 0.5000000000001716, 33.400000000000205, 76.1999999999999, 37.10000000000025, -27.59999999999954, -23.79999999999957, 25.500000000000068, 49.700000000000315, -65.80000000000035, 31.000000000000163, -56.79999999999969, 29.300000000000136, 40.0000000000003, 81.09999999999991, 27.90000000000011, 29.000000000000124, -148.10000000000082, 47.20000000000044, -81.40000000000074, -23.199999999999577, -95.40000000000073, 35.600000000000236, 34.1000000000002, 30.50000000000016, 13.699999999999958, 3.899999999999955, 145.39999999999935, 12.200000000000045, -56.40000000000014, 38.70000000000028, 22.400000000000013, 32.30000000000018, 13.200000000000014, 47.90000000000014, 37.30000000000026, 32.00000000000018, 36.40000000000025, -14.999999999999593, -39.99999999999973, -194.8000000000013, 9.60000000000025, -0.19999999999997362], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.499999999999819, 20.000000000000014, 15.799999999999963, 3.1999999999999615, -62.499999999999865, 31.400000000000208, 108.2, 47.90000000000018, -76.60000000000079, -17.79999999999974, -78.70000000000002, 29.000000000000163, -388.9, -3.700000000000012, -3.099999999999958, 20.000000000000014, 3.1999999999999615, -10.599999999999865, 5.299999999999965, 28.10000000000015, 20.000000000000014, 20.900000000000027, -37.29999999999995, -7.299999999999891, 4.099999999999966, 1.0999999999999865, -0.9999999999999846, -175.9, -165.70000000000047, -156.39999999999984, 17.899999999999988, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 17.899999999999988, 27.200000000000003, 11.599999999999964, -21.100000000000023, 86.3, 20.000000000000014, -24.099999999999852, -30.099999999999817, -267.7000000000001, -0.9999999999999846, 11.599999999999964, 36.79999999999998, -160.6000000000006, -35.19999999999976, 26.90000000000012, -27.699999999999754, -274.0, -9.399999999999928, 0.19999999999998655, -19.900000000000013, -9.099999999999984, -295.00000000000017, -89.20000000000036, -74.50000000000085, 85.39999999999992, -101.8000000000008, 20.000000000000014, 81.50000000000006, 20.000000000000014, -86.20000000000084, -10.599999999999843, 1.0999999999999865, 17.899999999999988, -94.00000000000009, -68.19999999999995, 5.299999999999965, -164.70000000000033, 11.599999999999964, -40.599999999999994, 13.699999999999964, -17.800000000000022, -90.69999999999996, 13.699999999999964, 17.899999999999988, -15.99999999999976, -48.09999999999979, 20.000000000000014, -53.80000000000014, -91.60000000000034, -283.6, -32.79999999999977, 144.79999999999998, 5.299999999999965, 5.299999999999965, -277.0, -33.399999999999814, -101.80000000000081, 31.100000000000158, -34.59999999999993, -129.10000000000042, 20.000000000000014, 20.000000000000014, -9.400000000000032, -127.0, 13.699999999999964, 74.2999999999997, 92.89999999999947, -13.599999999999989, -129.10000000000045, -211.00000000000045, -24.999999999999858, 7.399999999999965, 20.000000000000014, -61.900000000000766, -23.499999999999766, 23.600000000000065, 5.000000000000042, -129.1000000000007, -110.80000000000075, 20.000000000000014, -143.8000000000007, 0.20000000000000195, -26.799999999999756, -63.70000000000065, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 65.00000000000004, 9.499999999999964, 14.599999999999968, -90.40000000000077, -5.1999999999999265, -0.9999999999999846, -89.80000000000075, 17.899999999999988, -6.399999999999908, -30.39999999999975, 28.100000000000087, -9.099999999999941, -291.69999999999925, 1.9999999999999731, 20.000000000000014, -132.40000000000023, -36.399999999999764, -71.80000000000081, 28.10000000000015, 20.000000000000014, 20.000000000000014, 15.799999999999963, 53.3000000000001, 17.899999999999988, -0.9999999999999846, 11.599999999999964, 7.399999999999965, -99.70000000000051, -177.40000000000038, -4.600000000000014, -17.199999999999747, -231.10000000000014, 13.699999999999964, -11.499999999999826, -90.70000000000041, -51.39999999999989, -211.00000000000048, 15.799999999999963, 15.799999999999963, 20.000000000000014, 1.0999999999999617, 20.000000000000014, -11.499999999999819, -133.90000000000057, 11.599999999999964, 9.499999999999964, -34.59999999999996, 20.000000000000014, 103.39999999999998, -11.499999999999833, -7.299999999999905, -196.0, -12.399999999999823, 20.000000000000014, 13.699999999999964, 20.000000000000018, -13.599999999999783, 13.699999999999966, 11.599999999999964, -68.80000000000058, 20.000000000000014, 3.1999999999999615, -28.300000000000075, 11.599999999999968, 16.69999999999997, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, 0.19999999999998655, -137.20000000000067, 15.799999999999963, -158.8000000000004, -148.00000000000063, -143.8000000000006, -52.60000000000001, 0.19999999999998122, -130.30000000000072, 1.0999999999999723], "policy_predator_policy_reward": [6.0, 15.0, 8.0, 3.0, 12.0, 48.0, 28.0, 7.0, 16.0, 53.0, 44.0, 41.0, 132.0, 193.0, 11.0, 10.0, 27.0, 21.0, 8.0, 9.0, 1.0, 2.0, 13.0, 68.0, 6.0, 9.0, 76.0, 67.0, 114.0, 89.0, 9.0, 9.0, 8.0, 5.0, 1.0, 1.0, 37.0, 5.0, 7.0, 32.0, 49.0, 16.0, 10.0, 137.0, 19.0, 4.0, 83.0, 88.0, 16.0, 24.0, 149.0, 144.0, 19.0, 12.0, 95.0, 125.0, 97.0, 0.0, 7.0, 58.0, 17.0, 16.0, 51.0, 0.0, 12.0, 17.0, 41.0, 71.0, 45.0, 7.0, 10.0, 100.0, 33.0, 68.0, 2.0, 64.0, 3.0, 3.0, 35.0, 34.0, 22.0, 31.0, 67.0, 137.0, 8.0, 25.0, 7.0, 7.0, 60.0, 117.0, 33.0, 49.0, 0.0, 97.0, 0.0, 0.0, 56.0, 66.0, 9.0, 20.0, 6.0, 12.0, 8.0, 142.0, 45.0, 6.0, 14.0, 39.0, 25.0, 24.0, 83.0, 20.0, 55.0, 43.0, 49.0, 78.0, 46.0, 45.0, 0.0, 6.0, 0.0, 8.0, 8.0, 5.0, 12.0, 56.0, 56.0, 11.0, 11.0, 3.0, 24.0, 28.0, 133.0, 102.0, 0.0, 9.0, 49.0, 63.0, 46.0, 27.0, 0.0, 0.0, 0.0, 12.0, 10.0, 1.0, 4.0, 6.0, 121.0, 8.0, 38.0, 31.0, 29.0, 107.0, 47.0, 32.0, 124.0, 43.0, 2.0, 2.0, 12.0, 1.0, 15.0, 7.0, 64.0, 72.0, 3.0, 26.0, 22.0, 0.0, 19.0, 12.0, 117.0, 35.0, 2.0, 3.0, 0.0, 16.0, 4.0, 3.0, 29.0, 33.0, 65.0, 8.0, 7.0, 2.0, 3.0, 10.0, 6.0, 3.0, 75.0, 47.0, 32.0, 71.0, 96.0, 1.0, 40.0, 22.0, 71.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.843933750607014, "mean_inference_ms": 2.193301227959575, "mean_action_processing_ms": 0.34767666962315397, "mean_env_wait_ms": 0.28112880305520965, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005672812461853027, "StateBufferConnector_ms": 0.005263805389404297, "ViewRequirementAgentConnector_ms": 0.16101408004760742}, "num_episodes": 22, "episode_return_max": 191.0999999999996, "episode_return_min": -194.8000000000013, "episode_return_mean": 8.510000000000016, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.47118789704336, "num_env_steps_trained_throughput_per_sec": 318.47118789704336, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 12732.113, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12732.064, "sample_time_ms": 2370.416, "learn_time_ms": 10343.953, "learn_throughput": 386.699, "synch_weights_time_ms": 15.742}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "f0d88_00000", "date": "2024-08-14_11-01-59", "timestamp": 1723647719, "time_this_iter_s": 12.622680902481079, "time_total_s": 936.1410071849823, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad542b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 936.1410071849823, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 48.77222222222222, "ram_util_percent": 83.02222222222221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9158141620575435, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.366138920203719, "policy_loss": -0.02420720638320461, "vf_loss": 4.369989890774722, "vf_explained_var": -0.3921649053929344, "kl": 0.013403289302270322, "entropy": 1.3544856101116807, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3786707538776297, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 3.6330420359101874, "policy_loss": -0.00792497345024631, "vf_loss": 3.6265974845205036, "vf_explained_var": 0.19566145630740614, "kl": 0.0084101545569923, "entropy": 0.9738255350047318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 145.39999999999935, "episode_reward_min": -359.79999999999853, "episode_reward_mean": 5.3069999999999915, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -334.89999999999947, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.59999999999985, "predator_policy": 149.0}, "policy_reward_mean": {"prey_policy": -31.236500000000074, "predator_policy": 33.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.49999999999996, 145.29999999999944, 10.79999999999996, -121.70000000000046, 71.39999999999984, -24.799999999999613, 39.20000000000026, 9.59999999999997, 11.300000000000145, -84.09999999999991, -66.70000000000061, 48.60000000000029, 134.49999999999966, -15.19999999999955, 19.499999999999975, 35.90000000000016, -10.900000000000082, -43.1000000000002, 74.09999999999945, -42.49999999999968, 37.600000000000264, 4.900000000000128, 19.2, -171.20000000000036, 144.9999999999997, 24.600000000000048, -133.40000000000052, 11.299999999999997, -66.69999999999982, 40.0000000000003, -14.399999999999991, 116.99999999999903, 97.2999999999989, -190.10000000000096, 33.400000000000226, 11.100000000000014, 49.100000000000456, -21.10000000000003, 7.200000000000035, -16.59999999999991, 0.5000000000001716, 33.400000000000205, 76.1999999999999, 37.10000000000025, -27.59999999999954, -23.79999999999957, 25.500000000000068, 49.700000000000315, -65.80000000000035, 31.000000000000163, -56.79999999999969, 29.300000000000136, 40.0000000000003, 81.09999999999991, 27.90000000000011, 29.000000000000124, -148.10000000000082, 47.20000000000044, -81.40000000000074, -23.199999999999577, -95.40000000000073, 35.600000000000236, 34.1000000000002, 30.50000000000016, 13.699999999999958, 3.899999999999955, 145.39999999999935, 12.200000000000045, -56.40000000000014, 38.70000000000028, 22.400000000000013, 32.30000000000018, 13.200000000000014, 47.90000000000014, 37.30000000000026, 32.00000000000018, 36.40000000000025, -14.999999999999593, -39.99999999999973, -194.8000000000013, 9.60000000000025, -0.19999999999997362, 27.500000000000103, -11.700000000000054, 48.10000000000041, 23.200000000000028, 113.2999999999987, -32.29999999999997, 33.4000000000002, -115.80000000000007, -23.399999999999995, -359.79999999999853, 52.000000000000504, 60.50000000000039, 23.50000000000002, 29.00000000000013, 36.900000000000254, 98.99999999999915, 125.79999999999959, -30.999999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, -21.100000000000023, 86.3, 20.000000000000014, -24.099999999999852, -30.099999999999817, -267.7000000000001, -0.9999999999999846, 11.599999999999964, 36.79999999999998, -160.6000000000006, -35.19999999999976, 26.90000000000012, -27.699999999999754, -274.0, -9.399999999999928, 0.19999999999998655, -19.900000000000013, -9.099999999999984, -295.00000000000017, -89.20000000000036, -74.50000000000085, 85.39999999999992, -101.8000000000008, 20.000000000000014, 81.50000000000006, 20.000000000000014, -86.20000000000084, -10.599999999999843, 1.0999999999999865, 17.899999999999988, -94.00000000000009, -68.19999999999995, 5.299999999999965, -164.70000000000033, 11.599999999999964, -40.599999999999994, 13.699999999999964, -17.800000000000022, -90.69999999999996, 13.699999999999964, 17.899999999999988, -15.99999999999976, -48.09999999999979, 20.000000000000014, -53.80000000000014, -91.60000000000034, -283.6, -32.79999999999977, 144.79999999999998, 5.299999999999965, 5.299999999999965, -277.0, -33.399999999999814, -101.80000000000081, 31.100000000000158, -34.59999999999993, -129.10000000000042, 20.000000000000014, 20.000000000000014, -9.400000000000032, -127.0, 13.699999999999964, 74.2999999999997, 92.89999999999947, -13.599999999999989, -129.10000000000045, -211.00000000000045, -24.999999999999858, 7.399999999999965, 20.000000000000014, -61.900000000000766, -23.499999999999766, 23.600000000000065, 5.000000000000042, -129.1000000000007, -110.80000000000075, 20.000000000000014, -143.8000000000007, 0.20000000000000195, -26.799999999999756, -63.70000000000065, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 65.00000000000004, 9.499999999999964, 14.599999999999968, -90.40000000000077, -5.1999999999999265, -0.9999999999999846, -89.80000000000075, 17.899999999999988, -6.399999999999908, -30.39999999999975, 28.100000000000087, -9.099999999999941, -291.69999999999925, 1.9999999999999731, 20.000000000000014, -132.40000000000023, -36.399999999999764, -71.80000000000081, 28.10000000000015, 20.000000000000014, 20.000000000000014, 15.799999999999963, 53.3000000000001, 17.899999999999988, -0.9999999999999846, 11.599999999999964, 7.399999999999965, -99.70000000000051, -177.40000000000038, -4.600000000000014, -17.199999999999747, -231.10000000000014, 13.699999999999964, -11.499999999999826, -90.70000000000041, -51.39999999999989, -211.00000000000048, 15.799999999999963, 15.799999999999963, 20.000000000000014, 1.0999999999999617, 20.000000000000014, -11.499999999999819, -133.90000000000057, 11.599999999999964, 9.499999999999964, -34.59999999999996, 20.000000000000014, 103.39999999999998, -11.499999999999833, -7.299999999999905, -196.0, -12.399999999999823, 20.000000000000014, 13.699999999999964, 20.000000000000018, -13.599999999999783, 13.699999999999966, 11.599999999999964, -68.80000000000058, 20.000000000000014, 3.1999999999999615, -28.300000000000075, 11.599999999999968, 16.69999999999997, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, 0.19999999999998655, -137.20000000000067, 15.799999999999963, -158.8000000000004, -148.00000000000063, -143.8000000000006, -52.60000000000001, 0.19999999999998122, -130.30000000000072, 1.0999999999999723, -3.399999999999958, 17.899999999999988, 20.000000000000014, -105.69999999999985, -54.69999999999998, 45.80000000000024, 20.000000000000014, -17.79999999999974, 85.69999999999939, 20.600000000000026, -5.1999999999999265, -105.10000000000011, 13.699999999999964, 13.699999999999964, -92.80000000000001, -94.00000000000003, -70.3000000000001, -3.100000000000026, -292.89999999999964, -334.89999999999947, 13.699999999999964, 35.30000000000026, 20.000000000000014, 18.499999999999996, 15.799999999999963, -7.3000000000000504, 1.0999999999999794, 17.899999999999988, 20.000000000000014, -3.099999999999958, 72.19999999999965, -5.1999999999999265, 176.59999999999985, -206.80000000000035, -91.30000000000013, -15.699999999999775], "policy_predator_policy_reward": [37.0, 5.0, 7.0, 32.0, 49.0, 16.0, 10.0, 137.0, 19.0, 4.0, 83.0, 88.0, 16.0, 24.0, 149.0, 144.0, 19.0, 12.0, 95.0, 125.0, 97.0, 0.0, 7.0, 58.0, 17.0, 16.0, 51.0, 0.0, 12.0, 17.0, 41.0, 71.0, 45.0, 7.0, 10.0, 100.0, 33.0, 68.0, 2.0, 64.0, 3.0, 3.0, 35.0, 34.0, 22.0, 31.0, 67.0, 137.0, 8.0, 25.0, 7.0, 7.0, 60.0, 117.0, 33.0, 49.0, 0.0, 97.0, 0.0, 0.0, 56.0, 66.0, 9.0, 20.0, 6.0, 12.0, 8.0, 142.0, 45.0, 6.0, 14.0, 39.0, 25.0, 24.0, 83.0, 20.0, 55.0, 43.0, 49.0, 78.0, 46.0, 45.0, 0.0, 6.0, 0.0, 8.0, 8.0, 5.0, 12.0, 56.0, 56.0, 11.0, 11.0, 3.0, 24.0, 28.0, 133.0, 102.0, 0.0, 9.0, 49.0, 63.0, 46.0, 27.0, 0.0, 0.0, 0.0, 12.0, 10.0, 1.0, 4.0, 6.0, 121.0, 8.0, 38.0, 31.0, 29.0, 107.0, 47.0, 32.0, 124.0, 43.0, 2.0, 2.0, 12.0, 1.0, 15.0, 7.0, 64.0, 72.0, 3.0, 26.0, 22.0, 0.0, 19.0, 12.0, 117.0, 35.0, 2.0, 3.0, 0.0, 16.0, 4.0, 3.0, 29.0, 33.0, 65.0, 8.0, 7.0, 2.0, 3.0, 10.0, 6.0, 3.0, 75.0, 47.0, 32.0, 71.0, 96.0, 1.0, 40.0, 22.0, 71.0, 58.0, 7.0, 6.0, 7.0, 67.0, 30.0, 27.0, 17.0, 4.0, 6.0, 1.0, 66.0, 12.0, 3.0, 3.0, 67.0, 4.0, 5.0, 45.0, 136.0, 132.0, 3.0, 0.0, 9.0, 13.0, 13.0, 2.0, 10.0, 0.0, 11.0, 9.0, 16.0, 16.0, 55.0, 101.0, 53.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.847617555357853, "mean_inference_ms": 2.201682539555067, "mean_action_processing_ms": 0.3497676171386979, "mean_env_wait_ms": 0.2826243545539262, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004974484443664551, "StateBufferConnector_ms": 0.005687355995178223, "ViewRequirementAgentConnector_ms": 0.20898902416229248}, "num_episodes": 18, "episode_return_max": 145.39999999999935, "episode_return_min": -359.79999999999853, "episode_return_mean": 5.3069999999999915, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.9719567787086, "num_env_steps_trained_throughput_per_sec": 316.9719567787086, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 12755.41, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12755.362, "sample_time_ms": 2381.402, "learn_time_ms": 10356.283, "learn_throughput": 386.239, "synch_weights_time_ms": 15.69}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "f0d88_00000", "date": "2024-08-14_11-02-12", "timestamp": 1723647732, "time_this_iter_s": 12.674798727035522, "time_total_s": 948.8158059120178, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad504dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 948.8158059120178, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 50.96666666666667, "ram_util_percent": 83.10555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9634812437983418, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.389374127842131, "policy_loss": -0.028256066876005324, "vf_loss": 3.399340979762809, "vf_explained_var": 0.03626873199901884, "kl": 0.012042280335086981, "entropy": 1.2778527459770284, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.078687776869567, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.8967013106775032, "policy_loss": -0.012088575057941612, "vf_loss": 1.8947761461848305, "vf_explained_var": 0.29558281955264865, "kl": 0.008201913660978168, "entropy": 1.0388033109997945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 171.89999999999935, "episode_reward_min": -359.79999999999853, "episode_reward_mean": 7.29000000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -334.89999999999947, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.59999999999985, "predator_policy": 142.0}, "policy_reward_mean": {"prey_policy": -25.085000000000072, "predator_policy": 28.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-171.20000000000036, 144.9999999999997, 24.600000000000048, -133.40000000000052, 11.299999999999997, -66.69999999999982, 40.0000000000003, -14.399999999999991, 116.99999999999903, 97.2999999999989, -190.10000000000096, 33.400000000000226, 11.100000000000014, 49.100000000000456, -21.10000000000003, 7.200000000000035, -16.59999999999991, 0.5000000000001716, 33.400000000000205, 76.1999999999999, 37.10000000000025, -27.59999999999954, -23.79999999999957, 25.500000000000068, 49.700000000000315, -65.80000000000035, 31.000000000000163, -56.79999999999969, 29.300000000000136, 40.0000000000003, 81.09999999999991, 27.90000000000011, 29.000000000000124, -148.10000000000082, 47.20000000000044, -81.40000000000074, -23.199999999999577, -95.40000000000073, 35.600000000000236, 34.1000000000002, 30.50000000000016, 13.699999999999958, 3.899999999999955, 145.39999999999935, 12.200000000000045, -56.40000000000014, 38.70000000000028, 22.400000000000013, 32.30000000000018, 13.200000000000014, 47.90000000000014, 37.30000000000026, 32.00000000000018, 36.40000000000025, -14.999999999999593, -39.99999999999973, -194.8000000000013, 9.60000000000025, -0.19999999999997362, 27.500000000000103, -11.700000000000054, 48.10000000000041, 23.200000000000028, 113.2999999999987, -32.29999999999997, 33.4000000000002, -115.80000000000007, -23.399999999999995, -359.79999999999853, 52.000000000000504, 60.50000000000039, 23.50000000000002, 29.00000000000013, 36.900000000000254, 98.99999999999915, 125.79999999999959, -30.999999999999943, 37.80000000000027, -21.499999999999602, 171.89999999999935, -90.10000000000167, -7.199999999999898, 32.20000000000018, 37.80000000000027, -51.299999999999606, 29.000000000000135, 41.60000000000032, 31.200000000000166, 25.70000000000025, 22.200000000000006, 16.899999999999977, 21.30000000000004, -2.499999999999858, 35.00000000000023, 38.0000000000003, 46.1000000000004, 25.800000000000143, -26.599999999999824, 20.19999999999998, 50.20000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-91.60000000000034, -283.6, -32.79999999999977, 144.79999999999998, 5.299999999999965, 5.299999999999965, -277.0, -33.399999999999814, -101.80000000000081, 31.100000000000158, -34.59999999999993, -129.10000000000042, 20.000000000000014, 20.000000000000014, -9.400000000000032, -127.0, 13.699999999999964, 74.2999999999997, 92.89999999999947, -13.599999999999989, -129.10000000000045, -211.00000000000045, -24.999999999999858, 7.399999999999965, 20.000000000000014, -61.900000000000766, -23.499999999999766, 23.600000000000065, 5.000000000000042, -129.1000000000007, -110.80000000000075, 20.000000000000014, -143.8000000000007, 0.20000000000000195, -26.799999999999756, -63.70000000000065, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 65.00000000000004, 9.499999999999964, 14.599999999999968, -90.40000000000077, -5.1999999999999265, -0.9999999999999846, -89.80000000000075, 17.899999999999988, -6.399999999999908, -30.39999999999975, 28.100000000000087, -9.099999999999941, -291.69999999999925, 1.9999999999999731, 20.000000000000014, -132.40000000000023, -36.399999999999764, -71.80000000000081, 28.10000000000015, 20.000000000000014, 20.000000000000014, 15.799999999999963, 53.3000000000001, 17.899999999999988, -0.9999999999999846, 11.599999999999964, 7.399999999999965, -99.70000000000051, -177.40000000000038, -4.600000000000014, -17.199999999999747, -231.10000000000014, 13.699999999999964, -11.499999999999826, -90.70000000000041, -51.39999999999989, -211.00000000000048, 15.799999999999963, 15.799999999999963, 20.000000000000014, 1.0999999999999617, 20.000000000000014, -11.499999999999819, -133.90000000000057, 11.599999999999964, 9.499999999999964, -34.59999999999996, 20.000000000000014, 103.39999999999998, -11.499999999999833, -7.299999999999905, -196.0, -12.399999999999823, 20.000000000000014, 13.699999999999964, 20.000000000000018, -13.599999999999783, 13.699999999999966, 11.599999999999964, -68.80000000000058, 20.000000000000014, 3.1999999999999615, -28.300000000000075, 11.599999999999968, 16.69999999999997, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, 0.19999999999998655, -137.20000000000067, 15.799999999999963, -158.8000000000004, -148.00000000000063, -143.8000000000006, -52.60000000000001, 0.19999999999998122, -130.30000000000072, 1.0999999999999723, -3.399999999999958, 17.899999999999988, 20.000000000000014, -105.69999999999985, -54.69999999999998, 45.80000000000024, 20.000000000000014, -17.79999999999974, 85.69999999999939, 20.600000000000026, -5.1999999999999265, -105.10000000000011, 13.699999999999964, 13.699999999999964, -92.80000000000001, -94.00000000000003, -70.3000000000001, -3.100000000000026, -292.89999999999964, -334.89999999999947, 13.699999999999964, 35.30000000000026, 20.000000000000014, 18.499999999999996, 15.799999999999963, -7.3000000000000504, 1.0999999999999794, 17.899999999999988, 20.000000000000014, -3.099999999999958, 72.19999999999965, -5.1999999999999265, 176.59999999999985, -206.80000000000035, -91.30000000000013, -15.699999999999775, 20.000000000000014, 15.799999999999963, -110.50000000000068, 20.000000000000014, 25.1000000000001, 108.79999999999997, -91.30000000000081, -59.80000000000055, 20.000000000000014, -107.2000000000005, 5.299999999999965, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -183.3000000000006, 15.799999999999963, 3.1999999999999686, 20.000000000000014, 11.599999999999968, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -7.300000000000027, -10.599999999999843, 15.799999999999963, -21.999999999999744, 17.899999999999988, 20.000000000000014, -189.69999999999987, -28.299999999999777, -5.200000000000012, 3.1999999999999615, 15.799999999999963, -5.199999999999958, 0.19999999999997412, 20.000000000000014, 13.09999999999997, 20.000000000000014, -47.199999999999875, -109.60000000000035, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 31.400000000000208, 15.799999999999963], "policy_predator_policy_reward": [67.0, 137.0, 8.0, 25.0, 7.0, 7.0, 60.0, 117.0, 33.0, 49.0, 0.0, 97.0, 0.0, 0.0, 56.0, 66.0, 9.0, 20.0, 6.0, 12.0, 8.0, 142.0, 45.0, 6.0, 14.0, 39.0, 25.0, 24.0, 83.0, 20.0, 55.0, 43.0, 49.0, 78.0, 46.0, 45.0, 0.0, 6.0, 0.0, 8.0, 8.0, 5.0, 12.0, 56.0, 56.0, 11.0, 11.0, 3.0, 24.0, 28.0, 133.0, 102.0, 0.0, 9.0, 49.0, 63.0, 46.0, 27.0, 0.0, 0.0, 0.0, 12.0, 10.0, 1.0, 4.0, 6.0, 121.0, 8.0, 38.0, 31.0, 29.0, 107.0, 47.0, 32.0, 124.0, 43.0, 2.0, 2.0, 12.0, 1.0, 15.0, 7.0, 64.0, 72.0, 3.0, 26.0, 22.0, 0.0, 19.0, 12.0, 117.0, 35.0, 2.0, 3.0, 0.0, 16.0, 4.0, 3.0, 29.0, 33.0, 65.0, 8.0, 7.0, 2.0, 3.0, 10.0, 6.0, 3.0, 75.0, 47.0, 32.0, 71.0, 96.0, 1.0, 40.0, 22.0, 71.0, 58.0, 7.0, 6.0, 7.0, 67.0, 30.0, 27.0, 17.0, 4.0, 6.0, 1.0, 66.0, 12.0, 3.0, 3.0, 67.0, 4.0, 5.0, 45.0, 136.0, 132.0, 3.0, 0.0, 9.0, 13.0, 13.0, 2.0, 10.0, 0.0, 11.0, 9.0, 16.0, 16.0, 55.0, 101.0, 53.0, 23.0, 0.0, 2.0, 57.0, 12.0, 23.0, 15.0, 60.0, 1.0, 25.0, 55.0, 5.0, 4.0, 2.0, 0.0, 80.0, 32.0, 2.0, 8.0, 3.0, 7.0, 0.0, 8.0, 0.0, 13.0, 7.0, 10.0, 1.0, 20.0, 95.0, 96.0, 31.0, 0.0, 8.0, 8.0, 30.0, 13.0, 7.0, 6.0, 32.0, 21.0, 0.0, 63.0, 11.0, 7.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8519347830182389, "mean_inference_ms": 2.2117173554343585, "mean_action_processing_ms": 0.35107383675912823, "mean_env_wait_ms": 0.28361134730983345, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043866634368896484, "StateBufferConnector_ms": 0.0046579837799072266, "ViewRequirementAgentConnector_ms": 0.19570624828338623}, "num_episodes": 23, "episode_return_max": 171.89999999999935, "episode_return_min": -359.79999999999853, "episode_return_mean": 7.29000000000002, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.2325917507041, "num_env_steps_trained_throughput_per_sec": 310.2325917507041, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 12749.261, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12749.213, "sample_time_ms": 2356.55, "learn_time_ms": 10375.058, "learn_throughput": 385.54, "synch_weights_time_ms": 15.483}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "f0d88_00000", "date": "2024-08-14_11-02-25", "timestamp": 1723647745, "time_this_iter_s": 12.940951108932495, "time_total_s": 961.7567570209503, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4eb8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 961.7567570209503, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 56.40555555555555, "ram_util_percent": 83.57777777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.982711013252773, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.365138336085769, "policy_loss": -0.027015783478599533, "vf_loss": 4.373828709693182, "vf_explained_var": -0.2961082066177691, "kl": 0.01206610896889485, "entropy": 1.266327658721379, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8389997998558025, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.337900342323162, "policy_loss": -0.010473418443724907, "vf_loss": 1.3370580159167134, "vf_explained_var": 0.1207447004381311, "kl": 0.006622840569828262, "entropy": 1.0346312872316472, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 171.89999999999935, "episode_reward_min": -359.79999999999853, "episode_reward_mean": 12.632000000000078, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -334.89999999999947, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.59999999999985, "predator_policy": 136.0}, "policy_reward_mean": {"prey_policy": -17.279000000000057, "predator_policy": 23.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.400000000000205, 76.1999999999999, 37.10000000000025, -27.59999999999954, -23.79999999999957, 25.500000000000068, 49.700000000000315, -65.80000000000035, 31.000000000000163, -56.79999999999969, 29.300000000000136, 40.0000000000003, 81.09999999999991, 27.90000000000011, 29.000000000000124, -148.10000000000082, 47.20000000000044, -81.40000000000074, -23.199999999999577, -95.40000000000073, 35.600000000000236, 34.1000000000002, 30.50000000000016, 13.699999999999958, 3.899999999999955, 145.39999999999935, 12.200000000000045, -56.40000000000014, 38.70000000000028, 22.400000000000013, 32.30000000000018, 13.200000000000014, 47.90000000000014, 37.30000000000026, 32.00000000000018, 36.40000000000025, -14.999999999999593, -39.99999999999973, -194.8000000000013, 9.60000000000025, -0.19999999999997362, 27.500000000000103, -11.700000000000054, 48.10000000000041, 23.200000000000028, 113.2999999999987, -32.29999999999997, 33.4000000000002, -115.80000000000007, -23.399999999999995, -359.79999999999853, 52.000000000000504, 60.50000000000039, 23.50000000000002, 29.00000000000013, 36.900000000000254, 98.99999999999915, 125.79999999999959, -30.999999999999943, 37.80000000000027, -21.499999999999602, 171.89999999999935, -90.10000000000167, -7.199999999999898, 32.20000000000018, 37.80000000000027, -51.299999999999606, 29.000000000000135, 41.60000000000032, 31.200000000000166, 25.70000000000025, 22.200000000000006, 16.899999999999977, 21.30000000000004, -2.499999999999858, 35.00000000000023, 38.0000000000003, 46.1000000000004, 25.800000000000143, -26.599999999999824, 20.19999999999998, 50.20000000000047, 33.2000000000002, 21.30000000000002, 30.60000000000022, 40.0000000000003, 56.70000000000006, 41.300000000000345, -13.89999999999954, 30.100000000000144, 29.000000000000124, 12.500000000000005, 54.70000000000048, 30.100000000000144, 36.70000000000025, 29.500000000000135, -63.40000000000025, 13.60000000000004, 38.50000000000028, 36.70000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 7.399999999999965, 3.1999999999999615, 65.00000000000004, 9.499999999999964, 14.599999999999968, -90.40000000000077, -5.1999999999999265, -0.9999999999999846, -89.80000000000075, 17.899999999999988, -6.399999999999908, -30.39999999999975, 28.100000000000087, -9.099999999999941, -291.69999999999925, 1.9999999999999731, 20.000000000000014, -132.40000000000023, -36.399999999999764, -71.80000000000081, 28.10000000000015, 20.000000000000014, 20.000000000000014, 15.799999999999963, 53.3000000000001, 17.899999999999988, -0.9999999999999846, 11.599999999999964, 7.399999999999965, -99.70000000000051, -177.40000000000038, -4.600000000000014, -17.199999999999747, -231.10000000000014, 13.699999999999964, -11.499999999999826, -90.70000000000041, -51.39999999999989, -211.00000000000048, 15.799999999999963, 15.799999999999963, 20.000000000000014, 1.0999999999999617, 20.000000000000014, -11.499999999999819, -133.90000000000057, 11.599999999999964, 9.499999999999964, -34.59999999999996, 20.000000000000014, 103.39999999999998, -11.499999999999833, -7.299999999999905, -196.0, -12.399999999999823, 20.000000000000014, 13.699999999999964, 20.000000000000018, -13.599999999999783, 13.699999999999966, 11.599999999999964, -68.80000000000058, 20.000000000000014, 3.1999999999999615, -28.300000000000075, 11.599999999999968, 16.69999999999997, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, 0.19999999999998655, -137.20000000000067, 15.799999999999963, -158.8000000000004, -148.00000000000063, -143.8000000000006, -52.60000000000001, 0.19999999999998122, -130.30000000000072, 1.0999999999999723, -3.399999999999958, 17.899999999999988, 20.000000000000014, -105.69999999999985, -54.69999999999998, 45.80000000000024, 20.000000000000014, -17.79999999999974, 85.69999999999939, 20.600000000000026, -5.1999999999999265, -105.10000000000011, 13.699999999999964, 13.699999999999964, -92.80000000000001, -94.00000000000003, -70.3000000000001, -3.100000000000026, -292.89999999999964, -334.89999999999947, 13.699999999999964, 35.30000000000026, 20.000000000000014, 18.499999999999996, 15.799999999999963, -7.3000000000000504, 1.0999999999999794, 17.899999999999988, 20.000000000000014, -3.099999999999958, 72.19999999999965, -5.1999999999999265, 176.59999999999985, -206.80000000000035, -91.30000000000013, -15.699999999999775, 20.000000000000014, 15.799999999999963, -110.50000000000068, 20.000000000000014, 25.1000000000001, 108.79999999999997, -91.30000000000081, -59.80000000000055, 20.000000000000014, -107.2000000000005, 5.299999999999965, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -183.3000000000006, 15.799999999999963, 3.1999999999999686, 20.000000000000014, 11.599999999999968, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -7.300000000000027, -10.599999999999843, 15.799999999999963, -21.999999999999744, 17.899999999999988, 20.000000000000014, -189.69999999999987, -28.299999999999777, -5.200000000000012, 3.1999999999999615, 15.799999999999963, -5.199999999999958, 0.19999999999997412, 20.000000000000014, 13.09999999999997, 20.000000000000014, -47.199999999999875, -109.60000000000035, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 31.400000000000208, 15.799999999999963, -17.79999999999974, 20.000000000000014, 7.399999999999965, -3.100000000000056, -9.999999999999917, 11.599999999999946, 20.000000000000014, 20.000000000000014, -75.7000000000007, 61.399999999999984, -13.299999999999898, 11.599999999999964, -66.10000000000086, 3.1999999999999615, 15.799999999999963, 5.299999999999965, 13.699999999999964, 5.299999999999965, -9.399999999999855, -3.1000000000000285, -3.1000000000000365, 45.80000000000024, 9.499999999999964, 11.599999999999964, 13.699999999999964, 20.000000000000014, 15.799999999999963, 1.6999999999999729, -28.29999999999975, -129.10000000000034, -13.599999999999783, 3.1999999999999615, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999891], "policy_predator_policy_reward": [0.0, 6.0, 0.0, 8.0, 8.0, 5.0, 12.0, 56.0, 56.0, 11.0, 11.0, 3.0, 24.0, 28.0, 133.0, 102.0, 0.0, 9.0, 49.0, 63.0, 46.0, 27.0, 0.0, 0.0, 0.0, 12.0, 10.0, 1.0, 4.0, 6.0, 121.0, 8.0, 38.0, 31.0, 29.0, 107.0, 47.0, 32.0, 124.0, 43.0, 2.0, 2.0, 12.0, 1.0, 15.0, 7.0, 64.0, 72.0, 3.0, 26.0, 22.0, 0.0, 19.0, 12.0, 117.0, 35.0, 2.0, 3.0, 0.0, 16.0, 4.0, 3.0, 29.0, 33.0, 65.0, 8.0, 7.0, 2.0, 3.0, 10.0, 6.0, 3.0, 75.0, 47.0, 32.0, 71.0, 96.0, 1.0, 40.0, 22.0, 71.0, 58.0, 7.0, 6.0, 7.0, 67.0, 30.0, 27.0, 17.0, 4.0, 6.0, 1.0, 66.0, 12.0, 3.0, 3.0, 67.0, 4.0, 5.0, 45.0, 136.0, 132.0, 3.0, 0.0, 9.0, 13.0, 13.0, 2.0, 10.0, 0.0, 11.0, 9.0, 16.0, 16.0, 55.0, 101.0, 53.0, 23.0, 0.0, 2.0, 57.0, 12.0, 23.0, 15.0, 60.0, 1.0, 25.0, 55.0, 5.0, 4.0, 2.0, 0.0, 80.0, 32.0, 2.0, 8.0, 3.0, 7.0, 0.0, 8.0, 0.0, 13.0, 7.0, 10.0, 1.0, 20.0, 95.0, 96.0, 31.0, 0.0, 8.0, 8.0, 30.0, 13.0, 7.0, 6.0, 32.0, 21.0, 0.0, 63.0, 11.0, 7.0, 1.0, 2.0, 15.0, 16.0, 13.0, 4.0, 25.0, 4.0, 0.0, 0.0, 41.0, 30.0, 39.0, 4.0, 41.0, 8.0, 7.0, 2.0, 7.0, 3.0, 10.0, 15.0, 11.0, 1.0, 4.0, 5.0, 0.0, 3.0, 10.0, 2.0, 79.0, 15.0, 10.0, 14.0, 4.0, 5.0, 11.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8546221388133577, "mean_inference_ms": 2.218114456362668, "mean_action_processing_ms": 0.35176562629819486, "mean_env_wait_ms": 0.2841392104008113, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004967331886291504, "StateBufferConnector_ms": 0.004609584808349609, "ViewRequirementAgentConnector_ms": 0.19223904609680176}, "num_episodes": 18, "episode_return_max": 171.89999999999935, "episode_return_min": -359.79999999999853, "episode_return_mean": 12.632000000000078, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.49838854063665, "num_env_steps_trained_throughput_per_sec": 320.49838854063665, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 12708.997, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12708.949, "sample_time_ms": 2283.872, "learn_time_ms": 10407.816, "learn_throughput": 384.327, "synch_weights_time_ms": 14.717}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "f0d88_00000", "date": "2024-08-14_11-02-37", "timestamp": 1723647757, "time_this_iter_s": 12.521284103393555, "time_total_s": 974.2780411243439, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad502ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 974.2780411243439, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 54.17777777777778, "ram_util_percent": 83.01666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.462870373170843, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.725852550148333, "policy_loss": -0.019758798995809186, "vf_loss": 4.723405999229068, "vf_explained_var": 0.26165736030649256, "kl": 0.014620805815480805, "entropy": 1.2789280053799745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2072738686882, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.9202283133274665, "policy_loss": -0.011607424546003579, "vf_loss": 1.916418653253525, "vf_explained_var": 0.312331451057757, "kl": 0.009023262325475664, "entropy": 0.8597049460524604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 211.39999999999935, "episode_reward_min": -359.79999999999853, "episode_reward_mean": 14.565000000000063, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -334.89999999999947, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.59999999999985, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -15.542500000000048, "predator_policy": 22.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.50000000000016, 13.699999999999958, 3.899999999999955, 145.39999999999935, 12.200000000000045, -56.40000000000014, 38.70000000000028, 22.400000000000013, 32.30000000000018, 13.200000000000014, 47.90000000000014, 37.30000000000026, 32.00000000000018, 36.40000000000025, -14.999999999999593, -39.99999999999973, -194.8000000000013, 9.60000000000025, -0.19999999999997362, 27.500000000000103, -11.700000000000054, 48.10000000000041, 23.200000000000028, 113.2999999999987, -32.29999999999997, 33.4000000000002, -115.80000000000007, -23.399999999999995, -359.79999999999853, 52.000000000000504, 60.50000000000039, 23.50000000000002, 29.00000000000013, 36.900000000000254, 98.99999999999915, 125.79999999999959, -30.999999999999943, 37.80000000000027, -21.499999999999602, 171.89999999999935, -90.10000000000167, -7.199999999999898, 32.20000000000018, 37.80000000000027, -51.299999999999606, 29.000000000000135, 41.60000000000032, 31.200000000000166, 25.70000000000025, 22.200000000000006, 16.899999999999977, 21.30000000000004, -2.499999999999858, 35.00000000000023, 38.0000000000003, 46.1000000000004, 25.800000000000143, -26.599999999999824, 20.19999999999998, 50.20000000000047, 33.2000000000002, 21.30000000000002, 30.60000000000022, 40.0000000000003, 56.70000000000006, 41.300000000000345, -13.89999999999954, 30.100000000000144, 29.000000000000124, 12.500000000000005, 54.70000000000048, 30.100000000000144, 36.70000000000025, 29.500000000000135, -63.40000000000025, 13.60000000000004, 38.50000000000028, 36.70000000000025, 211.39999999999935, 32.30000000000019, 33.7000000000002, 40.200000000000294, -146.3000000000003, 37.700000000000266, 14.599999999999932, -97.50000000000101, 58.90000000000046, 0.4000000000002356, 24.600000000000225, 32.30000000000018, -73.000000000001, 37.10000000000026, -71.60000000000119, -30.099999999999852, 34.200000000000216, -18.299999999999507, 26.70000000000016, 35.30000000000023, 32.30000000000018, 33.400000000000205], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -11.499999999999819, -133.90000000000057, 11.599999999999964, 9.499999999999964, -34.59999999999996, 20.000000000000014, 103.39999999999998, -11.499999999999833, -7.299999999999905, -196.0, -12.399999999999823, 20.000000000000014, 13.699999999999964, 20.000000000000018, -13.599999999999783, 13.699999999999966, 11.599999999999964, -68.80000000000058, 20.000000000000014, 3.1999999999999615, -28.300000000000075, 11.599999999999968, 16.69999999999997, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, 0.19999999999998655, -137.20000000000067, 15.799999999999963, -158.8000000000004, -148.00000000000063, -143.8000000000006, -52.60000000000001, 0.19999999999998122, -130.30000000000072, 1.0999999999999723, -3.399999999999958, 17.899999999999988, 20.000000000000014, -105.69999999999985, -54.69999999999998, 45.80000000000024, 20.000000000000014, -17.79999999999974, 85.69999999999939, 20.600000000000026, -5.1999999999999265, -105.10000000000011, 13.699999999999964, 13.699999999999964, -92.80000000000001, -94.00000000000003, -70.3000000000001, -3.100000000000026, -292.89999999999964, -334.89999999999947, 13.699999999999964, 35.30000000000026, 20.000000000000014, 18.499999999999996, 15.799999999999963, -7.3000000000000504, 1.0999999999999794, 17.899999999999988, 20.000000000000014, -3.099999999999958, 72.19999999999965, -5.1999999999999265, 176.59999999999985, -206.80000000000035, -91.30000000000013, -15.699999999999775, 20.000000000000014, 15.799999999999963, -110.50000000000068, 20.000000000000014, 25.1000000000001, 108.79999999999997, -91.30000000000081, -59.80000000000055, 20.000000000000014, -107.2000000000005, 5.299999999999965, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -183.3000000000006, 15.799999999999963, 3.1999999999999686, 20.000000000000014, 11.599999999999968, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -7.300000000000027, -10.599999999999843, 15.799999999999963, -21.999999999999744, 17.899999999999988, 20.000000000000014, -189.69999999999987, -28.299999999999777, -5.200000000000012, 3.1999999999999615, 15.799999999999963, -5.199999999999958, 0.19999999999997412, 20.000000000000014, 13.09999999999997, 20.000000000000014, -47.199999999999875, -109.60000000000035, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 31.400000000000208, 15.799999999999963, -17.79999999999974, 20.000000000000014, 7.399999999999965, -3.100000000000056, -9.999999999999917, 11.599999999999946, 20.000000000000014, 20.000000000000014, -75.7000000000007, 61.399999999999984, -13.299999999999898, 11.599999999999964, -66.10000000000086, 3.1999999999999615, 15.799999999999963, 5.299999999999965, 13.699999999999964, 5.299999999999965, -9.399999999999855, -3.1000000000000285, -3.1000000000000365, 45.80000000000024, 9.499999999999964, 11.599999999999964, 13.699999999999964, 20.000000000000014, 15.799999999999963, 1.6999999999999729, -28.29999999999975, -129.10000000000034, -13.599999999999783, 3.1999999999999615, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999891, 170.0, 25.400000000000013, 5.299999999999965, 20.000000000000014, 20.000000000000014, -28.29999999999975, 26.900000000000126, 5.299999999999967, -140.80000000000018, -116.49999999999991, 20.000000000000014, 13.699999999999964, -9.399999999999855, -288.9999999999993, -72.00000000000003, -116.5000000000005, 17.300000000000054, 11.599999999999968, -1.0000000000000275, -34.59999999999975, -9.400000000000032, 20.000000000000014, 5.299999999999965, 20.000000000000014, -99.70000000000041, -70.30000000000075, 20.000000000000014, 1.0999999999999865, -112.30000000000058, -28.29999999999975, -49.30000000000001, -109.80000000000064, 16.69999999999997, -32.49999999999975, -76.60000000000088, 5.299999999999965, -10.29999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014], "policy_predator_policy_reward": [15.0, 7.0, 64.0, 72.0, 3.0, 26.0, 22.0, 0.0, 19.0, 12.0, 117.0, 35.0, 2.0, 3.0, 0.0, 16.0, 4.0, 3.0, 29.0, 33.0, 65.0, 8.0, 7.0, 2.0, 3.0, 10.0, 6.0, 3.0, 75.0, 47.0, 32.0, 71.0, 96.0, 1.0, 40.0, 22.0, 71.0, 58.0, 7.0, 6.0, 7.0, 67.0, 30.0, 27.0, 17.0, 4.0, 6.0, 1.0, 66.0, 12.0, 3.0, 3.0, 67.0, 4.0, 5.0, 45.0, 136.0, 132.0, 3.0, 0.0, 9.0, 13.0, 13.0, 2.0, 10.0, 0.0, 11.0, 9.0, 16.0, 16.0, 55.0, 101.0, 53.0, 23.0, 0.0, 2.0, 57.0, 12.0, 23.0, 15.0, 60.0, 1.0, 25.0, 55.0, 5.0, 4.0, 2.0, 0.0, 80.0, 32.0, 2.0, 8.0, 3.0, 7.0, 0.0, 8.0, 0.0, 13.0, 7.0, 10.0, 1.0, 20.0, 95.0, 96.0, 31.0, 0.0, 8.0, 8.0, 30.0, 13.0, 7.0, 6.0, 32.0, 21.0, 0.0, 63.0, 11.0, 7.0, 1.0, 2.0, 15.0, 16.0, 13.0, 4.0, 25.0, 4.0, 0.0, 0.0, 41.0, 30.0, 39.0, 4.0, 41.0, 8.0, 7.0, 2.0, 7.0, 3.0, 10.0, 15.0, 11.0, 1.0, 4.0, 5.0, 0.0, 3.0, 10.0, 2.0, 79.0, 15.0, 10.0, 14.0, 4.0, 5.0, 11.0, 13.0, 8.0, 8.0, 6.0, 1.0, 19.0, 23.0, 1.0, 7.0, 7.0, 104.0, 3.0, 1.0, 158.0, 155.0, 16.0, 75.0, 17.0, 13.0, 30.0, 6.0, 4.0, 10.0, 0.0, 7.0, 0.0, 97.0, 7.0, 9.0, 14.0, 55.0, 54.0, 75.0, 25.0, 25.0, 46.0, 7.0, 0.0, 17.0, 3.0, 7.0, 7.0, 0.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8563845050938451, "mean_inference_ms": 2.222984033409197, "mean_action_processing_ms": 0.3514917406036308, "mean_env_wait_ms": 0.28380124288804653, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004813551902770996, "StateBufferConnector_ms": 0.004605770111083984, "ViewRequirementAgentConnector_ms": 0.18165409564971924}, "num_episodes": 22, "episode_return_max": 211.39999999999935, "episode_return_min": -359.79999999999853, "episode_return_mean": 14.565000000000063, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.30702484480963, "num_env_steps_trained_throughput_per_sec": 310.30702484480963, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 12708.28, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12708.232, "sample_time_ms": 2251.099, "learn_time_ms": 10440.138, "learn_throughput": 383.137, "synch_weights_time_ms": 14.346}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "f0d88_00000", "date": "2024-08-14_11-02-50", "timestamp": 1723647770, "time_this_iter_s": 12.945157051086426, "time_total_s": 987.2231981754303, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad502f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 987.2231981754303, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 54.76666666666667, "ram_util_percent": 83.27222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.216145862662603, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.736156674415346, "policy_loss": -0.02299754307593007, "vf_loss": 4.737202211662575, "vf_explained_var": -0.37084117793532273, "kl": 0.014454006350677008, "entropy": 1.2836134085579525, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.76841558911813, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 2.211757132111403, "policy_loss": -0.008040838178355622, "vf_loss": 2.2077872693538665, "vf_explained_var": 0.17275791269130808, "kl": 0.007029580421056723, "entropy": 1.05663699050429, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 211.39999999999935, "episode_reward_min": -359.79999999999853, "episode_reward_mean": 16.691000000000066, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -334.89999999999947, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.59999999999985, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -13.649500000000039, "predator_policy": 21.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.19999999999997362, 27.500000000000103, -11.700000000000054, 48.10000000000041, 23.200000000000028, 113.2999999999987, -32.29999999999997, 33.4000000000002, -115.80000000000007, -23.399999999999995, -359.79999999999853, 52.000000000000504, 60.50000000000039, 23.50000000000002, 29.00000000000013, 36.900000000000254, 98.99999999999915, 125.79999999999959, -30.999999999999943, 37.80000000000027, -21.499999999999602, 171.89999999999935, -90.10000000000167, -7.199999999999898, 32.20000000000018, 37.80000000000027, -51.299999999999606, 29.000000000000135, 41.60000000000032, 31.200000000000166, 25.70000000000025, 22.200000000000006, 16.899999999999977, 21.30000000000004, -2.499999999999858, 35.00000000000023, 38.0000000000003, 46.1000000000004, 25.800000000000143, -26.599999999999824, 20.19999999999998, 50.20000000000047, 33.2000000000002, 21.30000000000002, 30.60000000000022, 40.0000000000003, 56.70000000000006, 41.300000000000345, -13.89999999999954, 30.100000000000144, 29.000000000000124, 12.500000000000005, 54.70000000000048, 30.100000000000144, 36.70000000000025, 29.500000000000135, -63.40000000000025, 13.60000000000004, 38.50000000000028, 36.70000000000025, 211.39999999999935, 32.30000000000019, 33.7000000000002, 40.200000000000294, -146.3000000000003, 37.700000000000266, 14.599999999999932, -97.50000000000101, 58.90000000000046, 0.4000000000002356, 24.600000000000225, 32.30000000000018, -73.000000000001, 37.10000000000026, -71.60000000000119, -30.099999999999852, 34.200000000000216, -18.299999999999507, 26.70000000000016, 35.30000000000023, 32.30000000000018, 33.400000000000205, 9.900000000000068, 40.0000000000003, 35.600000000000236, 30.599999999999994, 21.300000000000185, -105.9000000000012, 75.00000000000007, -23.799999999999685, 166.59999999999954, 36.40000000000025, 21.300000000000004, 35.600000000000236, 22.30000000000001, -44.399999999999885, 24.600000000000055, 15.90000000000021, -7.700000000000026, 28.60000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-130.30000000000072, 1.0999999999999723, -3.399999999999958, 17.899999999999988, 20.000000000000014, -105.69999999999985, -54.69999999999998, 45.80000000000024, 20.000000000000014, -17.79999999999974, 85.69999999999939, 20.600000000000026, -5.1999999999999265, -105.10000000000011, 13.699999999999964, 13.699999999999964, -92.80000000000001, -94.00000000000003, -70.3000000000001, -3.100000000000026, -292.89999999999964, -334.89999999999947, 13.699999999999964, 35.30000000000026, 20.000000000000014, 18.499999999999996, 15.799999999999963, -7.3000000000000504, 1.0999999999999794, 17.899999999999988, 20.000000000000014, -3.099999999999958, 72.19999999999965, -5.1999999999999265, 176.59999999999985, -206.80000000000035, -91.30000000000013, -15.699999999999775, 20.000000000000014, 15.799999999999963, -110.50000000000068, 20.000000000000014, 25.1000000000001, 108.79999999999997, -91.30000000000081, -59.80000000000055, 20.000000000000014, -107.2000000000005, 5.299999999999965, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -183.3000000000006, 15.799999999999963, 3.1999999999999686, 20.000000000000014, 11.599999999999968, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -7.300000000000027, -10.599999999999843, 15.799999999999963, -21.999999999999744, 17.899999999999988, 20.000000000000014, -189.69999999999987, -28.299999999999777, -5.200000000000012, 3.1999999999999615, 15.799999999999963, -5.199999999999958, 0.19999999999997412, 20.000000000000014, 13.09999999999997, 20.000000000000014, -47.199999999999875, -109.60000000000035, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 31.400000000000208, 15.799999999999963, -17.79999999999974, 20.000000000000014, 7.399999999999965, -3.100000000000056, -9.999999999999917, 11.599999999999946, 20.000000000000014, 20.000000000000014, -75.7000000000007, 61.399999999999984, -13.299999999999898, 11.599999999999964, -66.10000000000086, 3.1999999999999615, 15.799999999999963, 5.299999999999965, 13.699999999999964, 5.299999999999965, -9.399999999999855, -3.1000000000000285, -3.1000000000000365, 45.80000000000024, 9.499999999999964, 11.599999999999964, 13.699999999999964, 20.000000000000014, 15.799999999999963, 1.6999999999999729, -28.29999999999975, -129.10000000000034, -13.599999999999783, 3.1999999999999615, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999891, 170.0, 25.400000000000013, 5.299999999999965, 20.000000000000014, 20.000000000000014, -28.29999999999975, 26.900000000000126, 5.299999999999967, -140.80000000000018, -116.49999999999991, 20.000000000000014, 13.699999999999964, -9.399999999999855, -288.9999999999993, -72.00000000000003, -116.5000000000005, 17.300000000000054, 11.599999999999968, -1.0000000000000275, -34.59999999999975, -9.400000000000032, 20.000000000000014, 5.299999999999965, 20.000000000000014, -99.70000000000041, -70.30000000000075, 20.000000000000014, 1.0999999999999865, -112.30000000000058, -28.29999999999975, -49.30000000000001, -109.80000000000064, 16.69999999999997, -32.49999999999975, -76.60000000000088, 5.299999999999965, -10.29999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 11.599999999999964, -51.70000000000005, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, -28.59999999999981, 3.1999999999999615, 7.3999999999999755, -3.1000000000000325, -107.2000000000005, -141.7000000000007, 52.39999999999996, -24.39999999999982, -101.80000000000055, 20.000000000000014, -49.29999999999985, 143.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, -33.69999999999978, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 3.1999999999999615, -48.39999999999979, -130.00000000000006, -7.299999999999891, 17.89999999999998, 13.099999999999943, -50.19999999999992, 20.000000000000014, -99.70000000000016, -5.1999999999999265, 15.799999999999963], "policy_predator_policy_reward": [71.0, 58.0, 7.0, 6.0, 7.0, 67.0, 30.0, 27.0, 17.0, 4.0, 6.0, 1.0, 66.0, 12.0, 3.0, 3.0, 67.0, 4.0, 5.0, 45.0, 136.0, 132.0, 3.0, 0.0, 9.0, 13.0, 13.0, 2.0, 10.0, 0.0, 11.0, 9.0, 16.0, 16.0, 55.0, 101.0, 53.0, 23.0, 0.0, 2.0, 57.0, 12.0, 23.0, 15.0, 60.0, 1.0, 25.0, 55.0, 5.0, 4.0, 2.0, 0.0, 80.0, 32.0, 2.0, 8.0, 3.0, 7.0, 0.0, 8.0, 0.0, 13.0, 7.0, 10.0, 1.0, 20.0, 95.0, 96.0, 31.0, 0.0, 8.0, 8.0, 30.0, 13.0, 7.0, 6.0, 32.0, 21.0, 0.0, 63.0, 11.0, 7.0, 1.0, 2.0, 15.0, 16.0, 13.0, 4.0, 25.0, 4.0, 0.0, 0.0, 41.0, 30.0, 39.0, 4.0, 41.0, 8.0, 7.0, 2.0, 7.0, 3.0, 10.0, 15.0, 11.0, 1.0, 4.0, 5.0, 0.0, 3.0, 10.0, 2.0, 79.0, 15.0, 10.0, 14.0, 4.0, 5.0, 11.0, 13.0, 8.0, 8.0, 6.0, 1.0, 19.0, 23.0, 1.0, 7.0, 7.0, 104.0, 3.0, 1.0, 158.0, 155.0, 16.0, 75.0, 17.0, 13.0, 30.0, 6.0, 4.0, 10.0, 0.0, 7.0, 0.0, 97.0, 7.0, 9.0, 14.0, 55.0, 54.0, 75.0, 25.0, 25.0, 46.0, 7.0, 0.0, 17.0, 3.0, 7.0, 7.0, 0.0, 6.0, 0.0, 33.0, 17.0, 0.0, 0.0, 2.0, 2.0, 36.0, 20.0, 4.0, 13.0, 108.0, 35.0, 23.0, 24.0, 58.0, 0.0, 35.0, 37.0, 6.0, 3.0, 20.0, 15.0, 0.0, 4.0, 9.0, 9.0, 64.0, 70.0, 13.0, 1.0, 41.0, 12.0, 36.0, 36.0, 12.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8579589924661613, "mean_inference_ms": 2.225135802004745, "mean_action_processing_ms": 0.3526021802198327, "mean_env_wait_ms": 0.28460631463301267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004850506782531738, "StateBufferConnector_ms": 0.009656786918640137, "ViewRequirementAgentConnector_ms": 0.20164000988006592}, "num_episodes": 18, "episode_return_max": 211.39999999999935, "episode_return_min": -359.79999999999853, "episode_return_mean": 16.691000000000066, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.30801775692896, "num_env_steps_trained_throughput_per_sec": 310.30801775692896, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 12739.43, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12739.381, "sample_time_ms": 2239.138, "learn_time_ms": 10482.628, "learn_throughput": 381.584, "synch_weights_time_ms": 14.638}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "f0d88_00000", "date": "2024-08-14_11-03-03", "timestamp": 1723647783, "time_this_iter_s": 12.927332162857056, "time_total_s": 1000.1505303382874, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0c8ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1000.1505303382874, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 51.91052631578947, "ram_util_percent": 83.36842105263156}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1673622630575977, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 4.16554594620195, "policy_loss": -0.018914162208419787, "vf_loss": 4.165011304270023, "vf_explained_var": -0.3693407713105439, "kl": 0.012805793233482287, "entropy": 1.2926627367261856, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9255441100351394, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 2.3815063870142374, "policy_loss": -0.00979786409981667, "vf_loss": 2.378245687043225, "vf_explained_var": 0.33479468898167686, "kl": 0.0076428736337574976, "entropy": 1.042739914239399, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 211.39999999999935, "episode_reward_min": -225.50000000000085, "episode_reward_mean": 13.850000000000062, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -309.70000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 170.0, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -15.055000000000032, "predator_policy": 21.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.199999999999898, 32.20000000000018, 37.80000000000027, -51.299999999999606, 29.000000000000135, 41.60000000000032, 31.200000000000166, 25.70000000000025, 22.200000000000006, 16.899999999999977, 21.30000000000004, -2.499999999999858, 35.00000000000023, 38.0000000000003, 46.1000000000004, 25.800000000000143, -26.599999999999824, 20.19999999999998, 50.20000000000047, 33.2000000000002, 21.30000000000002, 30.60000000000022, 40.0000000000003, 56.70000000000006, 41.300000000000345, -13.89999999999954, 30.100000000000144, 29.000000000000124, 12.500000000000005, 54.70000000000048, 30.100000000000144, 36.70000000000025, 29.500000000000135, -63.40000000000025, 13.60000000000004, 38.50000000000028, 36.70000000000025, 211.39999999999935, 32.30000000000019, 33.7000000000002, 40.200000000000294, -146.3000000000003, 37.700000000000266, 14.599999999999932, -97.50000000000101, 58.90000000000046, 0.4000000000002356, 24.600000000000225, 32.30000000000018, -73.000000000001, 37.10000000000026, -71.60000000000119, -30.099999999999852, 34.200000000000216, -18.299999999999507, 26.70000000000016, 35.30000000000023, 32.30000000000018, 33.400000000000205, 9.900000000000068, 40.0000000000003, 35.600000000000236, 30.599999999999994, 21.300000000000185, -105.9000000000012, 75.00000000000007, -23.799999999999685, 166.59999999999954, 36.40000000000025, 21.300000000000004, 35.600000000000236, 22.30000000000001, -44.399999999999885, 24.600000000000055, 15.90000000000021, -7.700000000000026, 28.60000000000012, 75.1999999999993, -204.7000000000007, 29.400000000000137, 49.50000000000016, 24.600000000000048, 24.0000000000002, 34.50000000000022, 35.400000000000226, -225.50000000000085, -19.59999999999951, 22.000000000000007, 100.89999999999904, 1.4000000000000785, 15.599999999999921, 36.70000000000025, 24.200000000000045, 33.70000000000021, -39.799999999999635, 12.300000000000045, -97.40000000000059, 38.60000000000028, 58.700000000000514, -117.7000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -107.2000000000005, 5.299999999999965, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -183.3000000000006, 15.799999999999963, 3.1999999999999686, 20.000000000000014, 11.599999999999968, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -7.300000000000027, -10.599999999999843, 15.799999999999963, -21.999999999999744, 17.899999999999988, 20.000000000000014, -189.69999999999987, -28.299999999999777, -5.200000000000012, 3.1999999999999615, 15.799999999999963, -5.199999999999958, 0.19999999999997412, 20.000000000000014, 13.09999999999997, 20.000000000000014, -47.199999999999875, -109.60000000000035, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 31.400000000000208, 15.799999999999963, -17.79999999999974, 20.000000000000014, 7.399999999999965, -3.100000000000056, -9.999999999999917, 11.599999999999946, 20.000000000000014, 20.000000000000014, -75.7000000000007, 61.399999999999984, -13.299999999999898, 11.599999999999964, -66.10000000000086, 3.1999999999999615, 15.799999999999963, 5.299999999999965, 13.699999999999964, 5.299999999999965, -9.399999999999855, -3.1000000000000285, -3.1000000000000365, 45.80000000000024, 9.499999999999964, 11.599999999999964, 13.699999999999964, 20.000000000000014, 15.799999999999963, 1.6999999999999729, -28.29999999999975, -129.10000000000034, -13.599999999999783, 3.1999999999999615, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999891, 170.0, 25.400000000000013, 5.299999999999965, 20.000000000000014, 20.000000000000014, -28.29999999999975, 26.900000000000126, 5.299999999999967, -140.80000000000018, -116.49999999999991, 20.000000000000014, 13.699999999999964, -9.399999999999855, -288.9999999999993, -72.00000000000003, -116.5000000000005, 17.300000000000054, 11.599999999999968, -1.0000000000000275, -34.59999999999975, -9.400000000000032, 20.000000000000014, 5.299999999999965, 20.000000000000014, -99.70000000000041, -70.30000000000075, 20.000000000000014, 1.0999999999999865, -112.30000000000058, -28.29999999999975, -49.30000000000001, -109.80000000000064, 16.69999999999997, -32.49999999999975, -76.60000000000088, 5.299999999999965, -10.29999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 11.599999999999964, -51.70000000000005, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, -28.59999999999981, 3.1999999999999615, 7.3999999999999755, -3.1000000000000325, -107.2000000000005, -141.7000000000007, 52.39999999999996, -24.39999999999982, -101.80000000000055, 20.000000000000014, -49.29999999999985, 143.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, -33.69999999999978, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 3.1999999999999615, -48.39999999999979, -130.00000000000006, -7.299999999999891, 17.89999999999998, 13.099999999999943, -50.19999999999992, 20.000000000000014, -99.70000000000016, -5.1999999999999265, 15.799999999999963, -1.0000000000000027, 3.1999999999999615, -190.0000000000005, -309.70000000000016, -11.499999999999819, 17.899999999999988, 22.100000000000144, 7.399999999999965, 9.499999999999964, 1.0999999999999865, 1.099999999999967, 5.899999999999967, 9.499999999999964, 20.000000000000014, 3.1999999999999615, -5.799999999999953, -200.5000000000003, -187.0000000000005, -17.79999999999974, -47.79999999999977, 15.799999999999963, -11.799999999999818, 11.599999999999964, 65.30000000000003, -79.9, 26.300000000000004, 10.699999999999967, -45.09999999999976, 13.699999999999964, 20.000000000000014, -17.79999999999974, 20.000000000000014, 6.799999999999967, 17.899999999999988, 20.000000000000014, -134.80000000000055, -25.29999999999975, 11.599999999999964, -140.80000000000055, -76.59999999999982, 11.599999999999964, 20.000000000000014, 39.80000000000025, 17.899999999999988, -5.199999999999944, -284.4999999999999], "policy_predator_policy_reward": [25.0, 55.0, 5.0, 4.0, 2.0, 0.0, 80.0, 32.0, 2.0, 8.0, 3.0, 7.0, 0.0, 8.0, 0.0, 13.0, 7.0, 10.0, 1.0, 20.0, 95.0, 96.0, 31.0, 0.0, 8.0, 8.0, 30.0, 13.0, 7.0, 6.0, 32.0, 21.0, 0.0, 63.0, 11.0, 7.0, 1.0, 2.0, 15.0, 16.0, 13.0, 4.0, 25.0, 4.0, 0.0, 0.0, 41.0, 30.0, 39.0, 4.0, 41.0, 8.0, 7.0, 2.0, 7.0, 3.0, 10.0, 15.0, 11.0, 1.0, 4.0, 5.0, 0.0, 3.0, 10.0, 2.0, 79.0, 15.0, 10.0, 14.0, 4.0, 5.0, 11.0, 13.0, 8.0, 8.0, 6.0, 1.0, 19.0, 23.0, 1.0, 7.0, 7.0, 104.0, 3.0, 1.0, 158.0, 155.0, 16.0, 75.0, 17.0, 13.0, 30.0, 6.0, 4.0, 10.0, 0.0, 7.0, 0.0, 97.0, 7.0, 9.0, 14.0, 55.0, 54.0, 75.0, 25.0, 25.0, 46.0, 7.0, 0.0, 17.0, 3.0, 7.0, 7.0, 0.0, 6.0, 0.0, 33.0, 17.0, 0.0, 0.0, 2.0, 2.0, 36.0, 20.0, 4.0, 13.0, 108.0, 35.0, 23.0, 24.0, 58.0, 0.0, 35.0, 37.0, 6.0, 3.0, 20.0, 15.0, 0.0, 4.0, 9.0, 9.0, 64.0, 70.0, 13.0, 1.0, 41.0, 12.0, 36.0, 36.0, 12.0, 6.0, 43.0, 30.0, 143.0, 152.0, 8.0, 15.0, 6.0, 14.0, 5.0, 9.0, 8.0, 9.0, 0.0, 5.0, 25.0, 13.0, 139.0, 23.0, 12.0, 34.0, 4.0, 14.0, 0.0, 24.0, 52.0, 3.0, 19.0, 31.0, 0.0, 3.0, 4.0, 18.0, 1.0, 8.0, 72.0, 3.0, 4.0, 22.0, 6.0, 114.0, 4.0, 3.0, 0.0, 1.0, 18.0, 154.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8598133237059171, "mean_inference_ms": 2.227121888245284, "mean_action_processing_ms": 0.3531739543870529, "mean_env_wait_ms": 0.2849150012498993, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015589356422424316, "StateBufferConnector_ms": 0.008639931678771973, "ViewRequirementAgentConnector_ms": 0.17467224597930908}, "num_episodes": 23, "episode_return_max": 211.39999999999935, "episode_return_min": -225.50000000000085, "episode_return_mean": 13.850000000000062, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.79950493335497, "num_env_steps_trained_throughput_per_sec": 334.79950493335497, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 12670.751, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12670.701, "sample_time_ms": 2207.574, "learn_time_ms": 10445.25, "learn_throughput": 382.949, "synch_weights_time_ms": 14.628}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "f0d88_00000", "date": "2024-08-14_11-03-15", "timestamp": 1723647795, "time_this_iter_s": 11.990767002105713, "time_total_s": 1012.1412973403931, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4ebaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1012.1412973403931, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 47.42352941176471, "ram_util_percent": 82.70588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.118872875669015, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.0170666389995153, "policy_loss": -0.01726827372318853, "vf_loss": 3.0181164913076572, "vf_explained_var": -0.48048344948304395, "kl": 0.01067879857045907, "entropy": 1.3024034356314038, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.279375286140139, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 2.2727764798219874, "policy_loss": -0.008234836391380264, "vf_loss": 2.2677839272867435, "vf_explained_var": 0.24699638400759016, "kl": 0.007741679813852657, "entropy": 1.0519489715654384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 211.39999999999935, "episode_reward_min": -225.50000000000085, "episode_reward_mean": 10.77600000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 170.0, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -17.63200000000003, "predator_policy": 23.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.20000000000047, 33.2000000000002, 21.30000000000002, 30.60000000000022, 40.0000000000003, 56.70000000000006, 41.300000000000345, -13.89999999999954, 30.100000000000144, 29.000000000000124, 12.500000000000005, 54.70000000000048, 30.100000000000144, 36.70000000000025, 29.500000000000135, -63.40000000000025, 13.60000000000004, 38.50000000000028, 36.70000000000025, 211.39999999999935, 32.30000000000019, 33.7000000000002, 40.200000000000294, -146.3000000000003, 37.700000000000266, 14.599999999999932, -97.50000000000101, 58.90000000000046, 0.4000000000002356, 24.600000000000225, 32.30000000000018, -73.000000000001, 37.10000000000026, -71.60000000000119, -30.099999999999852, 34.200000000000216, -18.299999999999507, 26.70000000000016, 35.30000000000023, 32.30000000000018, 33.400000000000205, 9.900000000000068, 40.0000000000003, 35.600000000000236, 30.599999999999994, 21.300000000000185, -105.9000000000012, 75.00000000000007, -23.799999999999685, 166.59999999999954, 36.40000000000025, 21.300000000000004, 35.600000000000236, 22.30000000000001, -44.399999999999885, 24.600000000000055, 15.90000000000021, -7.700000000000026, 28.60000000000012, 75.1999999999993, -204.7000000000007, 29.400000000000137, 49.50000000000016, 24.600000000000048, 24.0000000000002, 34.50000000000022, 35.400000000000226, -225.50000000000085, -19.59999999999951, 22.000000000000007, 100.89999999999904, 1.4000000000000785, 15.599999999999921, 36.70000000000025, 24.200000000000045, 33.70000000000021, -39.799999999999635, 12.300000000000045, -97.40000000000059, 38.60000000000028, 58.700000000000514, -117.7000000000005, 29.30000000000014, 21.299999999999994, -167.90000000000077, -144.00000000000045, 71.59999999999992, 50.400000000000475, 40.0000000000003, 34.50000000000022, 13.59999999999999, 18.199999999999974, -17.3999999999996, -5.099999999999749, 22.40000000000001, -18.99999999999997, 42.30000000000033, 27.000000000000103, -11.70000000000003, 22.500000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.400000000000208, 15.799999999999963, -17.79999999999974, 20.000000000000014, 7.399999999999965, -3.100000000000056, -9.999999999999917, 11.599999999999946, 20.000000000000014, 20.000000000000014, -75.7000000000007, 61.399999999999984, -13.299999999999898, 11.599999999999964, -66.10000000000086, 3.1999999999999615, 15.799999999999963, 5.299999999999965, 13.699999999999964, 5.299999999999965, -9.399999999999855, -3.1000000000000285, -3.1000000000000365, 45.80000000000024, 9.499999999999964, 11.599999999999964, 13.699999999999964, 20.000000000000014, 15.799999999999963, 1.6999999999999729, -28.29999999999975, -129.10000000000034, -13.599999999999783, 3.1999999999999615, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999891, 170.0, 25.400000000000013, 5.299999999999965, 20.000000000000014, 20.000000000000014, -28.29999999999975, 26.900000000000126, 5.299999999999967, -140.80000000000018, -116.49999999999991, 20.000000000000014, 13.699999999999964, -9.399999999999855, -288.9999999999993, -72.00000000000003, -116.5000000000005, 17.300000000000054, 11.599999999999968, -1.0000000000000275, -34.59999999999975, -9.400000000000032, 20.000000000000014, 5.299999999999965, 20.000000000000014, -99.70000000000041, -70.30000000000075, 20.000000000000014, 1.0999999999999865, -112.30000000000058, -28.29999999999975, -49.30000000000001, -109.80000000000064, 16.69999999999997, -32.49999999999975, -76.60000000000088, 5.299999999999965, -10.29999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 11.599999999999964, -51.70000000000005, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, -28.59999999999981, 3.1999999999999615, 7.3999999999999755, -3.1000000000000325, -107.2000000000005, -141.7000000000007, 52.39999999999996, -24.39999999999982, -101.80000000000055, 20.000000000000014, -49.29999999999985, 143.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, -33.69999999999978, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 3.1999999999999615, -48.39999999999979, -130.00000000000006, -7.299999999999891, 17.89999999999998, 13.099999999999943, -50.19999999999992, 20.000000000000014, -99.70000000000016, -5.1999999999999265, 15.799999999999963, -1.0000000000000027, 3.1999999999999615, -190.0000000000005, -309.70000000000016, -11.499999999999819, 17.899999999999988, 22.100000000000144, 7.399999999999965, 9.499999999999964, 1.0999999999999865, 1.099999999999967, 5.899999999999967, 9.499999999999964, 20.000000000000014, 3.1999999999999615, -5.799999999999953, -200.5000000000003, -187.0000000000005, -17.79999999999974, -47.79999999999977, 15.799999999999963, -11.799999999999818, 11.599999999999964, 65.30000000000003, -79.9, 26.300000000000004, 10.699999999999967, -45.09999999999976, 13.699999999999964, 20.000000000000014, -17.79999999999974, 20.000000000000014, 6.799999999999967, 17.899999999999988, 20.000000000000014, -134.80000000000055, -25.29999999999975, 11.599999999999964, -140.80000000000055, -76.59999999999982, 11.599999999999964, 20.000000000000014, 39.80000000000025, 17.899999999999988, -5.199999999999944, -284.4999999999999, 2.300000000000196, -82.0000000000002, 17.899999999999988, -13.599999999999783, -141.7000000000004, -160.2000000000005, 29.000000000000163, -361.0, 17.899999999999988, 49.70000000000022, 35.30000000000026, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -24.099999999999746, 13.699999999999964, -12.999999999999813, 3.1999999999999615, -156.10000000000062, 13.699999999999964, 17.899999999999988, -64.00000000000085, 13.699999999999964, -7.299999999999891, -148.00000000000006, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 20.000000000000014, -21.999999999999744, -70.3000000000001, 11.599999999999964, 3.1999999999999615, 5.299999999999965], "policy_predator_policy_reward": [1.0, 2.0, 15.0, 16.0, 13.0, 4.0, 25.0, 4.0, 0.0, 0.0, 41.0, 30.0, 39.0, 4.0, 41.0, 8.0, 7.0, 2.0, 7.0, 3.0, 10.0, 15.0, 11.0, 1.0, 4.0, 5.0, 0.0, 3.0, 10.0, 2.0, 79.0, 15.0, 10.0, 14.0, 4.0, 5.0, 11.0, 13.0, 8.0, 8.0, 6.0, 1.0, 19.0, 23.0, 1.0, 7.0, 7.0, 104.0, 3.0, 1.0, 158.0, 155.0, 16.0, 75.0, 17.0, 13.0, 30.0, 6.0, 4.0, 10.0, 0.0, 7.0, 0.0, 97.0, 7.0, 9.0, 14.0, 55.0, 54.0, 75.0, 25.0, 25.0, 46.0, 7.0, 0.0, 17.0, 3.0, 7.0, 7.0, 0.0, 6.0, 0.0, 33.0, 17.0, 0.0, 0.0, 2.0, 2.0, 36.0, 20.0, 4.0, 13.0, 108.0, 35.0, 23.0, 24.0, 58.0, 0.0, 35.0, 37.0, 6.0, 3.0, 20.0, 15.0, 0.0, 4.0, 9.0, 9.0, 64.0, 70.0, 13.0, 1.0, 41.0, 12.0, 36.0, 36.0, 12.0, 6.0, 43.0, 30.0, 143.0, 152.0, 8.0, 15.0, 6.0, 14.0, 5.0, 9.0, 8.0, 9.0, 0.0, 5.0, 25.0, 13.0, 139.0, 23.0, 12.0, 34.0, 4.0, 14.0, 0.0, 24.0, 52.0, 3.0, 19.0, 31.0, 0.0, 3.0, 4.0, 18.0, 1.0, 8.0, 72.0, 3.0, 4.0, 22.0, 6.0, 114.0, 4.0, 3.0, 0.0, 1.0, 18.0, 154.0, 58.0, 51.0, 1.0, 16.0, 12.0, 122.0, 9.0, 179.0, 3.0, 1.0, 5.0, 9.0, 0.0, 0.0, 5.0, 0.0, 21.0, 3.0, 9.0, 19.0, 44.0, 81.0, 1.0, 40.0, 3.0, 13.0, 63.0, 46.0, 9.0, 5.0, 19.0, 10.0, 4.0, 43.0, 8.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8601849734473549, "mean_inference_ms": 2.2302711044582537, "mean_action_processing_ms": 0.35290865652424214, "mean_env_wait_ms": 0.28481063607491963, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015574932098388672, "StateBufferConnector_ms": 0.008544564247131348, "ViewRequirementAgentConnector_ms": 0.1646333932876587}, "num_episodes": 18, "episode_return_max": 211.39999999999935, "episode_return_min": -225.50000000000085, "episode_return_mean": 10.77600000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.78612865360805, "num_env_steps_trained_throughput_per_sec": 340.78612865360805, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 12550.644, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12550.593, "sample_time_ms": 2163.445, "learn_time_ms": 10369.395, "learn_throughput": 385.751, "synch_weights_time_ms": 14.507}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "f0d88_00000", "date": "2024-08-14_11-03-27", "timestamp": 1723647807, "time_this_iter_s": 11.778968095779419, "time_total_s": 1023.9202654361725, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4eba60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1023.9202654361725, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 45.550000000000004, "ram_util_percent": 82.71875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.001135442244313, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.7280181159418095, "policy_loss": -0.01914641210432386, "vf_loss": 3.7261634001656185, "vf_explained_var": -0.04459954897562663, "kl": 0.013827900775231201, "entropy": 1.3263290164962647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7549859634152165, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.4761264315988651, "policy_loss": -0.009974782570960029, "vf_loss": 1.4747793365092505, "vf_explained_var": 0.6606789236661619, "kl": 0.006626430632061942, "entropy": 1.0044006214255379, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 211.39999999999935, "episode_reward_min": -225.50000000000085, "episode_reward_mean": 5.087999999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 170.0, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -22.426000000000045, "predator_policy": 24.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.70000000000025, 211.39999999999935, 32.30000000000019, 33.7000000000002, 40.200000000000294, -146.3000000000003, 37.700000000000266, 14.599999999999932, -97.50000000000101, 58.90000000000046, 0.4000000000002356, 24.600000000000225, 32.30000000000018, -73.000000000001, 37.10000000000026, -71.60000000000119, -30.099999999999852, 34.200000000000216, -18.299999999999507, 26.70000000000016, 35.30000000000023, 32.30000000000018, 33.400000000000205, 9.900000000000068, 40.0000000000003, 35.600000000000236, 30.599999999999994, 21.300000000000185, -105.9000000000012, 75.00000000000007, -23.799999999999685, 166.59999999999954, 36.40000000000025, 21.300000000000004, 35.600000000000236, 22.30000000000001, -44.399999999999885, 24.600000000000055, 15.90000000000021, -7.700000000000026, 28.60000000000012, 75.1999999999993, -204.7000000000007, 29.400000000000137, 49.50000000000016, 24.600000000000048, 24.0000000000002, 34.50000000000022, 35.400000000000226, -225.50000000000085, -19.59999999999951, 22.000000000000007, 100.89999999999904, 1.4000000000000785, 15.599999999999921, 36.70000000000025, 24.200000000000045, 33.70000000000021, -39.799999999999635, 12.300000000000045, -97.40000000000059, 38.60000000000028, 58.700000000000514, -117.7000000000005, 29.30000000000014, 21.299999999999994, -167.90000000000077, -144.00000000000045, 71.59999999999992, 50.400000000000475, 40.0000000000003, 34.50000000000022, 13.59999999999999, 18.199999999999974, -17.3999999999996, -5.099999999999749, 22.40000000000001, -18.99999999999997, 42.30000000000033, 27.000000000000103, -11.70000000000003, 22.500000000000014, 3.3000000000000598, 30.100000000000147, 32.30000000000019, 112.69999999999864, 38.500000000000355, 28.900000000000126, 19.300000000000008, 43.70000000000035, 37.700000000000266, -45.700000000000365, -114.70000000000053, 0.3999999999999724, -3.399999999999809, 41.600000000000335, -152.30000000000035, 22.700000000000017, -191.300000000001, -1.9000000000000647], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -7.299999999999891, 170.0, 25.400000000000013, 5.299999999999965, 20.000000000000014, 20.000000000000014, -28.29999999999975, 26.900000000000126, 5.299999999999967, -140.80000000000018, -116.49999999999991, 20.000000000000014, 13.699999999999964, -9.399999999999855, -288.9999999999993, -72.00000000000003, -116.5000000000005, 17.300000000000054, 11.599999999999968, -1.0000000000000275, -34.59999999999975, -9.400000000000032, 20.000000000000014, 5.299999999999965, 20.000000000000014, -99.70000000000041, -70.30000000000075, 20.000000000000014, 1.0999999999999865, -112.30000000000058, -28.29999999999975, -49.30000000000001, -109.80000000000064, 16.69999999999997, -32.49999999999975, -76.60000000000088, 5.299999999999965, -10.29999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 11.599999999999964, -51.70000000000005, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, -28.59999999999981, 3.1999999999999615, 7.3999999999999755, -3.1000000000000325, -107.2000000000005, -141.7000000000007, 52.39999999999996, -24.39999999999982, -101.80000000000055, 20.000000000000014, -49.29999999999985, 143.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, -33.69999999999978, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 3.1999999999999615, -48.39999999999979, -130.00000000000006, -7.299999999999891, 17.89999999999998, 13.099999999999943, -50.19999999999992, 20.000000000000014, -99.70000000000016, -5.1999999999999265, 15.799999999999963, -1.0000000000000027, 3.1999999999999615, -190.0000000000005, -309.70000000000016, -11.499999999999819, 17.899999999999988, 22.100000000000144, 7.399999999999965, 9.499999999999964, 1.0999999999999865, 1.099999999999967, 5.899999999999967, 9.499999999999964, 20.000000000000014, 3.1999999999999615, -5.799999999999953, -200.5000000000003, -187.0000000000005, -17.79999999999974, -47.79999999999977, 15.799999999999963, -11.799999999999818, 11.599999999999964, 65.30000000000003, -79.9, 26.300000000000004, 10.699999999999967, -45.09999999999976, 13.699999999999964, 20.000000000000014, -17.79999999999974, 20.000000000000014, 6.799999999999967, 17.899999999999988, 20.000000000000014, -134.80000000000055, -25.29999999999975, 11.599999999999964, -140.80000000000055, -76.59999999999982, 11.599999999999964, 20.000000000000014, 39.80000000000025, 17.899999999999988, -5.199999999999944, -284.4999999999999, 2.300000000000196, -82.0000000000002, 17.899999999999988, -13.599999999999783, -141.7000000000004, -160.2000000000005, 29.000000000000163, -361.0, 17.899999999999988, 49.70000000000022, 35.30000000000026, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -24.099999999999746, 13.699999999999964, -12.999999999999813, 3.1999999999999615, -156.10000000000062, 13.699999999999964, 17.899999999999988, -64.00000000000085, 13.699999999999964, -7.299999999999891, -148.00000000000006, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 20.000000000000014, -21.999999999999744, -70.3000000000001, 11.599999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, -102.70000000000053, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 5.299999999999969, 5.299999999999965, 91.39999999999935, 20.000000000000014, -44.49999999999988, -3.099999999999958, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 28.100000000000147, 11.599999999999964, 13.699999999999964, 20.000000000000014, -36.699999999999754, -42.99999999999976, -131.2000000000004, -116.50000000000031, 20.000000000000014, -55.59999999999992, 9.499999999999964, -73.90000000000074, 2.2999999999999643, 11.299999999999976, -150.10000000000045, -131.2000000000001, 5.299999999999965, 7.399999999999965, -181.6000000000005, -162.7000000000005, 15.799999999999963, -57.69999999999977], "policy_predator_policy_reward": [11.0, 13.0, 8.0, 8.0, 6.0, 1.0, 19.0, 23.0, 1.0, 7.0, 7.0, 104.0, 3.0, 1.0, 158.0, 155.0, 16.0, 75.0, 17.0, 13.0, 30.0, 6.0, 4.0, 10.0, 0.0, 7.0, 0.0, 97.0, 7.0, 9.0, 14.0, 55.0, 54.0, 75.0, 25.0, 25.0, 46.0, 7.0, 0.0, 17.0, 3.0, 7.0, 7.0, 0.0, 6.0, 0.0, 33.0, 17.0, 0.0, 0.0, 2.0, 2.0, 36.0, 20.0, 4.0, 13.0, 108.0, 35.0, 23.0, 24.0, 58.0, 0.0, 35.0, 37.0, 6.0, 3.0, 20.0, 15.0, 0.0, 4.0, 9.0, 9.0, 64.0, 70.0, 13.0, 1.0, 41.0, 12.0, 36.0, 36.0, 12.0, 6.0, 43.0, 30.0, 143.0, 152.0, 8.0, 15.0, 6.0, 14.0, 5.0, 9.0, 8.0, 9.0, 0.0, 5.0, 25.0, 13.0, 139.0, 23.0, 12.0, 34.0, 4.0, 14.0, 0.0, 24.0, 52.0, 3.0, 19.0, 31.0, 0.0, 3.0, 4.0, 18.0, 1.0, 8.0, 72.0, 3.0, 4.0, 22.0, 6.0, 114.0, 4.0, 3.0, 0.0, 1.0, 18.0, 154.0, 58.0, 51.0, 1.0, 16.0, 12.0, 122.0, 9.0, 179.0, 3.0, 1.0, 5.0, 9.0, 0.0, 0.0, 5.0, 0.0, 21.0, 3.0, 9.0, 19.0, 44.0, 81.0, 1.0, 40.0, 3.0, 13.0, 63.0, 46.0, 9.0, 5.0, 19.0, 10.0, 4.0, 43.0, 8.0, 6.0, 40.0, 46.0, 0.0, 9.0, 0.0, 7.0, 8.0, 8.0, 13.0, 50.0, 1.0, 11.0, 10.0, 5.0, 4.0, 0.0, 3.0, 1.0, 2.0, 32.0, 77.0, 56.0, 0.0, 36.0, 38.0, 23.0, 15.0, 13.0, 122.0, 7.0, 3.0, 7.0, 143.0, 10.0, 32.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8614883670059311, "mean_inference_ms": 2.233023311737598, "mean_action_processing_ms": 0.35325989928848545, "mean_env_wait_ms": 0.2850862464144193, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015004396438598633, "StateBufferConnector_ms": 0.008971333503723145, "ViewRequirementAgentConnector_ms": 0.1882617473602295}, "num_episodes": 18, "episode_return_max": 211.39999999999935, "episode_return_min": -225.50000000000085, "episode_return_mean": 5.087999999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.5060088268807, "num_env_steps_trained_throughput_per_sec": 339.5060088268807, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 12448.057, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12448.008, "sample_time_ms": 2134.871, "learn_time_ms": 10295.456, "learn_throughput": 388.521, "synch_weights_time_ms": 14.582}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "f0d88_00000", "date": "2024-08-14_11-03-39", "timestamp": 1723647819, "time_this_iter_s": 11.836785316467285, "time_total_s": 1035.7570507526398, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4d1040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1035.7570507526398, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 44.45882352941176, "ram_util_percent": 82.64117647058823}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9280625337015385, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.210538854170098, "policy_loss": -0.021528252143112242, "vf_loss": 3.2148506115353297, "vf_explained_var": -0.06340271821097722, "kl": 0.011335961092726433, "entropy": 1.2911144252176638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5774366517546317, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.8687343896381439, "policy_loss": -0.011783266802214913, "vf_loss": 1.8677943586357055, "vf_explained_var": 0.6020501372675416, "kl": 0.007446649518990531, "entropy": 0.9302069766811593, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 166.59999999999954, "episode_reward_min": -225.50000000000085, "episode_reward_mean": 8.736000000000011, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 143.9, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -18.36200000000003, "predator_policy": 22.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.400000000000205, 9.900000000000068, 40.0000000000003, 35.600000000000236, 30.599999999999994, 21.300000000000185, -105.9000000000012, 75.00000000000007, -23.799999999999685, 166.59999999999954, 36.40000000000025, 21.300000000000004, 35.600000000000236, 22.30000000000001, -44.399999999999885, 24.600000000000055, 15.90000000000021, -7.700000000000026, 28.60000000000012, 75.1999999999993, -204.7000000000007, 29.400000000000137, 49.50000000000016, 24.600000000000048, 24.0000000000002, 34.50000000000022, 35.400000000000226, -225.50000000000085, -19.59999999999951, 22.000000000000007, 100.89999999999904, 1.4000000000000785, 15.599999999999921, 36.70000000000025, 24.200000000000045, 33.70000000000021, -39.799999999999635, 12.300000000000045, -97.40000000000059, 38.60000000000028, 58.700000000000514, -117.7000000000005, 29.30000000000014, 21.299999999999994, -167.90000000000077, -144.00000000000045, 71.59999999999992, 50.400000000000475, 40.0000000000003, 34.50000000000022, 13.59999999999999, 18.199999999999974, -17.3999999999996, -5.099999999999749, 22.40000000000001, -18.99999999999997, 42.30000000000033, 27.000000000000103, -11.70000000000003, 22.500000000000014, 3.3000000000000598, 30.100000000000147, 32.30000000000019, 112.69999999999864, 38.500000000000355, 28.900000000000126, 19.300000000000008, 43.70000000000035, 37.700000000000266, -45.700000000000365, -114.70000000000053, 0.3999999999999724, -3.399999999999809, 41.600000000000335, -152.30000000000035, 22.700000000000017, -191.300000000001, -1.9000000000000647, 73.39999999999976, 38.60000000000028, 51.40000000000049, 30.50000000000016, -7.699999999999648, 22.40000000000001, 32.9000000000002, 33.400000000000205, 31.200000000000163, 32.200000000000266, 92.8999999999985, -42.09999999999959, 49.70000000000046, 37.80000000000027, 37.10000000000026, 36.70000000000025, 37.80000000000027, -15.199999999999863, 19.29999999999996, 14.600000000000017, 14.19999999999996, -4.700000000000065], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 20.000000000000014, 11.599999999999964, -51.70000000000005, 20.000000000000014, 20.000000000000014, 15.799999999999963, 15.799999999999963, -28.59999999999981, 3.1999999999999615, 7.3999999999999755, -3.1000000000000325, -107.2000000000005, -141.7000000000007, 52.39999999999996, -24.39999999999982, -101.80000000000055, 20.000000000000014, -49.29999999999985, 143.9, 20.000000000000014, 7.399999999999965, 20.000000000000014, -33.69999999999978, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 3.1999999999999615, -48.39999999999979, -130.00000000000006, -7.299999999999891, 17.89999999999998, 13.099999999999943, -50.19999999999992, 20.000000000000014, -99.70000000000016, -5.1999999999999265, 15.799999999999963, -1.0000000000000027, 3.1999999999999615, -190.0000000000005, -309.70000000000016, -11.499999999999819, 17.899999999999988, 22.100000000000144, 7.399999999999965, 9.499999999999964, 1.0999999999999865, 1.099999999999967, 5.899999999999967, 9.499999999999964, 20.000000000000014, 3.1999999999999615, -5.799999999999953, -200.5000000000003, -187.0000000000005, -17.79999999999974, -47.79999999999977, 15.799999999999963, -11.799999999999818, 11.599999999999964, 65.30000000000003, -79.9, 26.300000000000004, 10.699999999999967, -45.09999999999976, 13.699999999999964, 20.000000000000014, -17.79999999999974, 20.000000000000014, 6.799999999999967, 17.899999999999988, 20.000000000000014, -134.80000000000055, -25.29999999999975, 11.599999999999964, -140.80000000000055, -76.59999999999982, 11.599999999999964, 20.000000000000014, 39.80000000000025, 17.899999999999988, -5.199999999999944, -284.4999999999999, 2.300000000000196, -82.0000000000002, 17.899999999999988, -13.599999999999783, -141.7000000000004, -160.2000000000005, 29.000000000000163, -361.0, 17.899999999999988, 49.70000000000022, 35.30000000000026, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -24.099999999999746, 13.699999999999964, -12.999999999999813, 3.1999999999999615, -156.10000000000062, 13.699999999999964, 17.899999999999988, -64.00000000000085, 13.699999999999964, -7.299999999999891, -148.00000000000006, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 20.000000000000014, -21.999999999999744, -70.3000000000001, 11.599999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, -102.70000000000053, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 5.299999999999969, 5.299999999999965, 91.39999999999935, 20.000000000000014, -44.49999999999988, -3.099999999999958, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 28.100000000000147, 11.599999999999964, 13.699999999999964, 20.000000000000014, -36.699999999999754, -42.99999999999976, -131.2000000000004, -116.50000000000031, 20.000000000000014, -55.59999999999992, 9.499999999999964, -73.90000000000074, 2.2999999999999643, 11.299999999999976, -150.10000000000045, -131.2000000000001, 5.299999999999965, 7.399999999999965, -181.6000000000005, -162.7000000000005, 15.799999999999963, -57.69999999999977, 20.000000000000014, 40.40000000000019, 11.599999999999964, 20.000000000000014, 15.799999999999963, 32.60000000000023, -11.499999999999819, 20.000000000000014, -11.799999999999818, -40.89999999999976, -11.499999999999819, 17.899999999999988, 20.000000000000014, -3.099999999999958, 7.399999999999965, 20.000000000000014, 9.499999999999964, 13.699999999999964, -4.3000000000000345, 15.499999999999963, 77.59999999999923, 5.299999999999965, -9.699999999999854, -177.40000000000057, 21.500000000000036, 27.20000000000013, 20.000000000000014, 15.799999999999963, 15.799999999999963, 5.299999999999967, 17.899999999999988, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, -225.70000000000016, -28.29999999999975, 11.599999999999964, -18.399999999999984, 4.999999999999966, -15.699999999999775, -24.099999999999746, -57.69999999999995, 4.99999999999997], "policy_predator_policy_reward": [6.0, 0.0, 33.0, 17.0, 0.0, 0.0, 2.0, 2.0, 36.0, 20.0, 4.0, 13.0, 108.0, 35.0, 23.0, 24.0, 58.0, 0.0, 35.0, 37.0, 6.0, 3.0, 20.0, 15.0, 0.0, 4.0, 9.0, 9.0, 64.0, 70.0, 13.0, 1.0, 41.0, 12.0, 36.0, 36.0, 12.0, 6.0, 43.0, 30.0, 143.0, 152.0, 8.0, 15.0, 6.0, 14.0, 5.0, 9.0, 8.0, 9.0, 0.0, 5.0, 25.0, 13.0, 139.0, 23.0, 12.0, 34.0, 4.0, 14.0, 0.0, 24.0, 52.0, 3.0, 19.0, 31.0, 0.0, 3.0, 4.0, 18.0, 1.0, 8.0, 72.0, 3.0, 4.0, 22.0, 6.0, 114.0, 4.0, 3.0, 0.0, 1.0, 18.0, 154.0, 58.0, 51.0, 1.0, 16.0, 12.0, 122.0, 9.0, 179.0, 3.0, 1.0, 5.0, 9.0, 0.0, 0.0, 5.0, 0.0, 21.0, 3.0, 9.0, 19.0, 44.0, 81.0, 1.0, 40.0, 3.0, 13.0, 63.0, 46.0, 9.0, 5.0, 19.0, 10.0, 4.0, 43.0, 8.0, 6.0, 40.0, 46.0, 0.0, 9.0, 0.0, 7.0, 8.0, 8.0, 13.0, 50.0, 1.0, 11.0, 10.0, 5.0, 4.0, 0.0, 3.0, 1.0, 2.0, 32.0, 77.0, 56.0, 0.0, 36.0, 38.0, 23.0, 15.0, 13.0, 122.0, 7.0, 3.0, 7.0, 143.0, 10.0, 32.0, 8.0, 13.0, 0.0, 4.0, 3.0, 2.0, 1.0, 15.0, 7.0, 16.0, 29.0, 1.0, 15.0, 5.0, 11.0, 0.0, 6.0, 3.0, 5.0, 20.0, 1.0, 7.0, 3.0, 79.0, 66.0, 1.0, 0.0, 0.0, 2.0, 7.0, 9.0, 1.0, 2.0, 0.0, 2.0, 102.0, 99.0, 13.0, 23.0, 8.0, 20.0, 21.0, 33.0, 7.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8642317704854173, "mean_inference_ms": 2.237864500542776, "mean_action_processing_ms": 0.353980167098985, "mean_env_wait_ms": 0.28556580288175987, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015037775039672852, "StateBufferConnector_ms": 0.016576170921325684, "ViewRequirementAgentConnector_ms": 0.20123279094696045}, "num_episodes": 22, "episode_return_max": 166.59999999999954, "episode_return_min": -225.50000000000085, "episode_return_mean": 8.736000000000011, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.0245666029362, "num_env_steps_trained_throughput_per_sec": 329.0245666029362, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 12395.847, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12395.799, "sample_time_ms": 2105.49, "learn_time_ms": 10271.445, "learn_throughput": 389.429, "synch_weights_time_ms": 16.188}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "f0d88_00000", "date": "2024-08-14_11-03-51", "timestamp": 1723647831, "time_this_iter_s": 12.246414184570312, "time_total_s": 1048.00346493721, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4f7040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1048.00346493721, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 44.06111111111112, "ram_util_percent": 82.59444444444445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6820522213423694, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.5022799328836816, "policy_loss": -0.023622583337473097, "vf_loss": 2.5092408732131677, "vf_explained_var": 4.968945942227803e-07, "kl": 0.01097062769307519, "entropy": 1.2998697445506142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1474221511808023, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 2.322251150343153, "policy_loss": -0.007898445744018155, "vf_loss": 2.318486074921946, "vf_explained_var": 0.6764907617732961, "kl": 0.006826385543786751, "entropy": 0.794328035122503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 112.69999999999864, "episode_reward_min": -225.50000000000085, "episode_reward_mean": 4.670000000000021, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 91.39999999999935, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -20.66000000000003, "predator_policy": 22.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.60000000000012, 75.1999999999993, -204.7000000000007, 29.400000000000137, 49.50000000000016, 24.600000000000048, 24.0000000000002, 34.50000000000022, 35.400000000000226, -225.50000000000085, -19.59999999999951, 22.000000000000007, 100.89999999999904, 1.4000000000000785, 15.599999999999921, 36.70000000000025, 24.200000000000045, 33.70000000000021, -39.799999999999635, 12.300000000000045, -97.40000000000059, 38.60000000000028, 58.700000000000514, -117.7000000000005, 29.30000000000014, 21.299999999999994, -167.90000000000077, -144.00000000000045, 71.59999999999992, 50.400000000000475, 40.0000000000003, 34.50000000000022, 13.59999999999999, 18.199999999999974, -17.3999999999996, -5.099999999999749, 22.40000000000001, -18.99999999999997, 42.30000000000033, 27.000000000000103, -11.70000000000003, 22.500000000000014, 3.3000000000000598, 30.100000000000147, 32.30000000000019, 112.69999999999864, 38.500000000000355, 28.900000000000126, 19.300000000000008, 43.70000000000035, 37.700000000000266, -45.700000000000365, -114.70000000000053, 0.3999999999999724, -3.399999999999809, 41.600000000000335, -152.30000000000035, 22.700000000000017, -191.300000000001, -1.9000000000000647, 73.39999999999976, 38.60000000000028, 51.40000000000049, 30.50000000000016, -7.699999999999648, 22.40000000000001, 32.9000000000002, 33.400000000000205, 31.200000000000163, 32.200000000000266, 92.8999999999985, -42.09999999999959, 49.70000000000046, 37.80000000000027, 37.10000000000026, 36.70000000000025, 37.80000000000027, -15.199999999999863, 19.29999999999996, 14.600000000000017, 14.19999999999996, -4.700000000000065, 16.599999999999955, 25.000000000000103, 27.4000000000001, 21.299999999999994, -21.69999999999954, 35.40000000000023, -10.299999999999645, 34.50000000000022, -169.9000000000004, 8.89999999999993, 19.799999999999976, 29.20000000000013, 37.80000000000027, -93.10000000000046, 37.80000000000027, 24.900000000000052, 12.100000000000046, -55.599999999999596], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.1999999999999265, 15.799999999999963, -1.0000000000000027, 3.1999999999999615, -190.0000000000005, -309.70000000000016, -11.499999999999819, 17.899999999999988, 22.100000000000144, 7.399999999999965, 9.499999999999964, 1.0999999999999865, 1.099999999999967, 5.899999999999967, 9.499999999999964, 20.000000000000014, 3.1999999999999615, -5.799999999999953, -200.5000000000003, -187.0000000000005, -17.79999999999974, -47.79999999999977, 15.799999999999963, -11.799999999999818, 11.599999999999964, 65.30000000000003, -79.9, 26.300000000000004, 10.699999999999967, -45.09999999999976, 13.699999999999964, 20.000000000000014, -17.79999999999974, 20.000000000000014, 6.799999999999967, 17.899999999999988, 20.000000000000014, -134.80000000000055, -25.29999999999975, 11.599999999999964, -140.80000000000055, -76.59999999999982, 11.599999999999964, 20.000000000000014, 39.80000000000025, 17.899999999999988, -5.199999999999944, -284.4999999999999, 2.300000000000196, -82.0000000000002, 17.899999999999988, -13.599999999999783, -141.7000000000004, -160.2000000000005, 29.000000000000163, -361.0, 17.899999999999988, 49.70000000000022, 35.30000000000026, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -24.099999999999746, 13.699999999999964, -12.999999999999813, 3.1999999999999615, -156.10000000000062, 13.699999999999964, 17.899999999999988, -64.00000000000085, 13.699999999999964, -7.299999999999891, -148.00000000000006, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 20.000000000000014, -21.999999999999744, -70.3000000000001, 11.599999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, -102.70000000000053, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 5.299999999999969, 5.299999999999965, 91.39999999999935, 20.000000000000014, -44.49999999999988, -3.099999999999958, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 28.100000000000147, 11.599999999999964, 13.699999999999964, 20.000000000000014, -36.699999999999754, -42.99999999999976, -131.2000000000004, -116.50000000000031, 20.000000000000014, -55.59999999999992, 9.499999999999964, -73.90000000000074, 2.2999999999999643, 11.299999999999976, -150.10000000000045, -131.2000000000001, 5.299999999999965, 7.399999999999965, -181.6000000000005, -162.7000000000005, 15.799999999999963, -57.69999999999977, 20.000000000000014, 40.40000000000019, 11.599999999999964, 20.000000000000014, 15.799999999999963, 32.60000000000023, -11.499999999999819, 20.000000000000014, -11.799999999999818, -40.89999999999976, -11.499999999999819, 17.899999999999988, 20.000000000000014, -3.099999999999958, 7.399999999999965, 20.000000000000014, 9.499999999999964, 13.699999999999964, -4.3000000000000345, 15.499999999999963, 77.59999999999923, 5.299999999999965, -9.699999999999854, -177.40000000000057, 21.500000000000036, 27.20000000000013, 20.000000000000014, 15.799999999999963, 15.799999999999963, 5.299999999999967, 17.899999999999988, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, -225.70000000000016, -28.29999999999975, 11.599999999999964, -18.399999999999984, 4.999999999999966, -15.699999999999775, -24.099999999999746, -57.69999999999995, 4.99999999999997, -33.399999999999764, 20.000000000000014, -12.099999999999817, -1.9000000000000283, 20.000000000000014, -13.599999999999783, -7.299999999999891, 11.599999999999964, -39.69999999999982, -42.99999999999976, 20.000000000000014, 7.399999999999965, -51.399999999999764, 1.0999999999999865, 20.000000000000014, 9.499999999999964, -194.2000000000005, -204.70000000000041, -45.0999999999998, 20.000000000000014, 13.699999999999964, -13.899999999999796, 15.799999999999963, 7.39999999999997, 15.799999999999963, 20.000000000000014, -101.80000000000027, -175.30000000000052, 15.799999999999963, 20.000000000000014, 13.699999999999964, 3.1999999999999615, 7.399999999999965, -28.29999999999975, -181.6000000000006, 20.000000000000014], "policy_predator_policy_reward": [12.0, 6.0, 43.0, 30.0, 143.0, 152.0, 8.0, 15.0, 6.0, 14.0, 5.0, 9.0, 8.0, 9.0, 0.0, 5.0, 25.0, 13.0, 139.0, 23.0, 12.0, 34.0, 4.0, 14.0, 0.0, 24.0, 52.0, 3.0, 19.0, 31.0, 0.0, 3.0, 4.0, 18.0, 1.0, 8.0, 72.0, 3.0, 4.0, 22.0, 6.0, 114.0, 4.0, 3.0, 0.0, 1.0, 18.0, 154.0, 58.0, 51.0, 1.0, 16.0, 12.0, 122.0, 9.0, 179.0, 3.0, 1.0, 5.0, 9.0, 0.0, 0.0, 5.0, 0.0, 21.0, 3.0, 9.0, 19.0, 44.0, 81.0, 1.0, 40.0, 3.0, 13.0, 63.0, 46.0, 9.0, 5.0, 19.0, 10.0, 4.0, 43.0, 8.0, 6.0, 40.0, 46.0, 0.0, 9.0, 0.0, 7.0, 8.0, 8.0, 13.0, 50.0, 1.0, 11.0, 10.0, 5.0, 4.0, 0.0, 3.0, 1.0, 2.0, 32.0, 77.0, 56.0, 0.0, 36.0, 38.0, 23.0, 15.0, 13.0, 122.0, 7.0, 3.0, 7.0, 143.0, 10.0, 32.0, 8.0, 13.0, 0.0, 4.0, 3.0, 2.0, 1.0, 15.0, 7.0, 16.0, 29.0, 1.0, 15.0, 5.0, 11.0, 0.0, 6.0, 3.0, 5.0, 20.0, 1.0, 7.0, 3.0, 79.0, 66.0, 1.0, 0.0, 0.0, 2.0, 7.0, 9.0, 1.0, 2.0, 0.0, 2.0, 102.0, 99.0, 13.0, 23.0, 8.0, 20.0, 21.0, 33.0, 7.0, 41.0, 25.0, 5.0, 19.0, 20.0, 5.0, 16.0, 4.0, 13.0, 6.0, 55.0, 2.0, 6.0, 6.0, 34.0, 0.0, 5.0, 115.0, 114.0, 17.0, 17.0, 17.0, 3.0, 6.0, 0.0, 2.0, 0.0, 95.0, 89.0, 0.0, 2.0, 8.0, 0.0, 10.0, 23.0, 44.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8662060264498705, "mean_inference_ms": 2.24155277822571, "mean_action_processing_ms": 0.3544740813822689, "mean_env_wait_ms": 0.28599761077029556, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01492762565612793, "StateBufferConnector_ms": 0.011504530906677246, "ViewRequirementAgentConnector_ms": 0.18914341926574707}, "num_episodes": 18, "episode_return_max": 112.69999999999864, "episode_return_min": -225.50000000000085, "episode_return_mean": 4.670000000000021, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.4636212149475, "num_env_steps_trained_throughput_per_sec": 334.4636212149475, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 12335.791, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12335.744, "sample_time_ms": 2072.858, "learn_time_ms": 10243.987, "learn_throughput": 390.473, "synch_weights_time_ms": 16.357}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "f0d88_00000", "date": "2024-08-14_11-04-03", "timestamp": 1723647843, "time_this_iter_s": 12.09653615951538, "time_total_s": 1060.1000010967255, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4f73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1060.1000010967255, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 44.629411764705885, "ram_util_percent": 82.23529411764706}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3646674346671532, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.6395166583792875, "policy_loss": -0.012256337732271286, "vf_loss": 3.627246425391505, "vf_explained_var": 0.043425705161674946, "kl": 0.016149181686706524, "entropy": 1.315202783718311, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8779810171909432, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.3376810135034027, "policy_loss": -0.0062199430458898105, "vf_loss": 1.3349498074836832, "vf_explained_var": 0.6674882253641805, "kl": 0.005238898279618447, "entropy": 0.9464492510235499, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 112.69999999999864, "episode_reward_min": -191.300000000001, "episode_reward_mean": 6.564000000000039, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 91.39999999999935, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -18.428000000000026, "predator_policy": 21.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-117.7000000000005, 29.30000000000014, 21.299999999999994, -167.90000000000077, -144.00000000000045, 71.59999999999992, 50.400000000000475, 40.0000000000003, 34.50000000000022, 13.59999999999999, 18.199999999999974, -17.3999999999996, -5.099999999999749, 22.40000000000001, -18.99999999999997, 42.30000000000033, 27.000000000000103, -11.70000000000003, 22.500000000000014, 3.3000000000000598, 30.100000000000147, 32.30000000000019, 112.69999999999864, 38.500000000000355, 28.900000000000126, 19.300000000000008, 43.70000000000035, 37.700000000000266, -45.700000000000365, -114.70000000000053, 0.3999999999999724, -3.399999999999809, 41.600000000000335, -152.30000000000035, 22.700000000000017, -191.300000000001, -1.9000000000000647, 73.39999999999976, 38.60000000000028, 51.40000000000049, 30.50000000000016, -7.699999999999648, 22.40000000000001, 32.9000000000002, 33.400000000000205, 31.200000000000163, 32.200000000000266, 92.8999999999985, -42.09999999999959, 49.70000000000046, 37.80000000000027, 37.10000000000026, 36.70000000000025, 37.80000000000027, -15.199999999999863, 19.29999999999996, 14.600000000000017, 14.19999999999996, -4.700000000000065, 16.599999999999955, 25.000000000000103, 27.4000000000001, 21.299999999999994, -21.69999999999954, 35.40000000000023, -10.299999999999645, 34.50000000000022, -169.9000000000004, 8.89999999999993, 19.799999999999976, 29.20000000000013, 37.80000000000027, -93.10000000000046, 37.80000000000027, 24.900000000000052, 12.100000000000046, -55.599999999999596, 25.100000000000108, 70.99999999999996, 15.30000000000002, 25.700000000000074, 39.60000000000029, 17.99999999999995, 33.3000000000002, 34.30000000000022, 14.699999999999944, -87.70000000000005, -34.7999999999999, 32.30000000000018, 34.40000000000022, 13.899999999999938, 32.10000000000018, 53.400000000000425, 37.40000000000026, 22.600000000000016, 19.79999999999997, 36.900000000000254, -94.30000000000082, 29.70000000000014, -125.0000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.199999999999944, -284.4999999999999, 2.300000000000196, -82.0000000000002, 17.899999999999988, -13.599999999999783, -141.7000000000004, -160.2000000000005, 29.000000000000163, -361.0, 17.899999999999988, 49.70000000000022, 35.30000000000026, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, -24.099999999999746, 13.699999999999964, -12.999999999999813, 3.1999999999999615, -156.10000000000062, 13.699999999999964, 17.899999999999988, -64.00000000000085, 13.699999999999964, -7.299999999999891, -148.00000000000006, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 20.000000000000014, -21.999999999999744, -70.3000000000001, 11.599999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, -102.70000000000053, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 5.299999999999969, 5.299999999999965, 91.39999999999935, 20.000000000000014, -44.49999999999988, -3.099999999999958, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 28.100000000000147, 11.599999999999964, 13.699999999999964, 20.000000000000014, -36.699999999999754, -42.99999999999976, -131.2000000000004, -116.50000000000031, 20.000000000000014, -55.59999999999992, 9.499999999999964, -73.90000000000074, 2.2999999999999643, 11.299999999999976, -150.10000000000045, -131.2000000000001, 5.299999999999965, 7.399999999999965, -181.6000000000005, -162.7000000000005, 15.799999999999963, -57.69999999999977, 20.000000000000014, 40.40000000000019, 11.599999999999964, 20.000000000000014, 15.799999999999963, 32.60000000000023, -11.499999999999819, 20.000000000000014, -11.799999999999818, -40.89999999999976, -11.499999999999819, 17.899999999999988, 20.000000000000014, -3.099999999999958, 7.399999999999965, 20.000000000000014, 9.499999999999964, 13.699999999999964, -4.3000000000000345, 15.499999999999963, 77.59999999999923, 5.299999999999965, -9.699999999999854, -177.40000000000057, 21.500000000000036, 27.20000000000013, 20.000000000000014, 15.799999999999963, 15.799999999999963, 5.299999999999967, 17.899999999999988, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, -225.70000000000016, -28.29999999999975, 11.599999999999964, -18.399999999999984, 4.999999999999966, -15.699999999999775, -24.099999999999746, -57.69999999999995, 4.99999999999997, -33.399999999999764, 20.000000000000014, -12.099999999999817, -1.9000000000000283, 20.000000000000014, -13.599999999999783, -7.299999999999891, 11.599999999999964, -39.69999999999982, -42.99999999999976, 20.000000000000014, 7.399999999999965, -51.399999999999764, 1.0999999999999865, 20.000000000000014, 9.499999999999964, -194.2000000000005, -204.70000000000041, -45.0999999999998, 20.000000000000014, 13.699999999999964, -13.899999999999796, 15.799999999999963, 7.39999999999997, 15.799999999999963, 20.000000000000014, -101.80000000000027, -175.30000000000052, 15.799999999999963, 20.000000000000014, 13.699999999999964, 3.1999999999999615, 7.399999999999965, -28.29999999999975, -181.6000000000006, 20.000000000000014, 20.90000000000003, -29.799999999999784, 55.10000000000023, -21.099999999999774, 7.399999999999965, -3.099999999999958, 20.000000000000014, -19.29999999999975, 17.899999999999988, 10.69999999999997, -13.599999999999783, 11.599999999999964, 5.299999999999965, 20.000000000000014, 5.299999999999965, 20.000000000000014, 5.299999999999965, -13.599999999999783, -99.69999999999999, -106.00000000000017, -122.80000000000013, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 7.399999999999965, -42.09999999999979, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 5.599999999999981, 15.799999999999962, 7.399999999999965, 20.000000000000014, 13.699999999999964, -24.099999999999746, -26.199999999999747, 20.000000000000014, -3.099999999999958, 20.000000000000014, -154.30000000000064, -106.00000000000077, -1.2999999999999847, 20.000000000000014, -116.50000000000034, -149.50000000000006], "policy_predator_policy_reward": [18.0, 154.0, 58.0, 51.0, 1.0, 16.0, 12.0, 122.0, 9.0, 179.0, 3.0, 1.0, 5.0, 9.0, 0.0, 0.0, 5.0, 0.0, 21.0, 3.0, 9.0, 19.0, 44.0, 81.0, 1.0, 40.0, 3.0, 13.0, 63.0, 46.0, 9.0, 5.0, 19.0, 10.0, 4.0, 43.0, 8.0, 6.0, 40.0, 46.0, 0.0, 9.0, 0.0, 7.0, 8.0, 8.0, 13.0, 50.0, 1.0, 11.0, 10.0, 5.0, 4.0, 0.0, 3.0, 1.0, 2.0, 32.0, 77.0, 56.0, 0.0, 36.0, 38.0, 23.0, 15.0, 13.0, 122.0, 7.0, 3.0, 7.0, 143.0, 10.0, 32.0, 8.0, 13.0, 0.0, 4.0, 3.0, 2.0, 1.0, 15.0, 7.0, 16.0, 29.0, 1.0, 15.0, 5.0, 11.0, 0.0, 6.0, 3.0, 5.0, 20.0, 1.0, 7.0, 3.0, 79.0, 66.0, 1.0, 0.0, 0.0, 2.0, 7.0, 9.0, 1.0, 2.0, 0.0, 2.0, 102.0, 99.0, 13.0, 23.0, 8.0, 20.0, 21.0, 33.0, 7.0, 41.0, 25.0, 5.0, 19.0, 20.0, 5.0, 16.0, 4.0, 13.0, 6.0, 55.0, 2.0, 6.0, 6.0, 34.0, 0.0, 5.0, 115.0, 114.0, 17.0, 17.0, 17.0, 3.0, 6.0, 0.0, 2.0, 0.0, 95.0, 89.0, 0.0, 2.0, 8.0, 0.0, 10.0, 23.0, 44.0, 62.0, 30.0, 4.0, 13.0, 24.0, 11.0, 0.0, 5.0, 20.0, 3.0, 8.0, 4.0, 16.0, 1.0, 7.0, 2.0, 7.0, 16.0, 7.0, 116.0, 2.0, 68.0, 0.0, 1.0, 6.0, 1.0, 6.0, 2.0, 34.0, 9.0, 2.0, 17.0, 15.0, 4.0, 6.0, 18.0, 15.0, 10.0, 16.0, 9.0, 11.0, 91.0, 75.0, 0.0, 11.0, 139.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8683370651814538, "mean_inference_ms": 2.245232530007842, "mean_action_processing_ms": 0.35503811833889004, "mean_env_wait_ms": 0.28658768439364835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004055500030517578, "StateBufferConnector_ms": 0.011161088943481445, "ViewRequirementAgentConnector_ms": 0.17706644535064697}, "num_episodes": 23, "episode_return_max": 112.69999999999864, "episode_return_min": -191.300000000001, "episode_return_mean": 6.564000000000039, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 330.2352533217426, "num_env_steps_trained_throughput_per_sec": 330.2352533217426, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 12285.108, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12285.06, "sample_time_ms": 2020.19, "learn_time_ms": 10244.671, "learn_throughput": 390.447, "synch_weights_time_ms": 17.643}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "f0d88_00000", "date": "2024-08-14_11-04-16", "timestamp": 1723647856, "time_this_iter_s": 12.155606985092163, "time_total_s": 1072.2556080818176, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad504ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1072.2556080818176, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 47.0, "ram_util_percent": 82.43529411764706}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.978497748053263, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.9148995594372824, "policy_loss": -0.028323330104144083, "vf_loss": 1.9287568456596798, "vf_explained_var": 0.017608176116590147, "kl": 0.009524968460501012, "entropy": 1.3001538250812148, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6546968600421987, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.4819257827662917, "policy_loss": -0.008490500211833962, "vf_loss": 1.4817747851528187, "vf_explained_var": 0.6236359719561522, "kl": 0.005057668964495644, "entropy": 0.9528745099350259, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 112.69999999999864, "episode_reward_min": -191.300000000001, "episode_reward_mean": 9.935000000000041, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.89999999999964, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 91.39999999999935, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -15.18250000000002, "predator_policy": 20.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.500000000000014, 3.3000000000000598, 30.100000000000147, 32.30000000000019, 112.69999999999864, 38.500000000000355, 28.900000000000126, 19.300000000000008, 43.70000000000035, 37.700000000000266, -45.700000000000365, -114.70000000000053, 0.3999999999999724, -3.399999999999809, 41.600000000000335, -152.30000000000035, 22.700000000000017, -191.300000000001, -1.9000000000000647, 73.39999999999976, 38.60000000000028, 51.40000000000049, 30.50000000000016, -7.699999999999648, 22.40000000000001, 32.9000000000002, 33.400000000000205, 31.200000000000163, 32.200000000000266, 92.8999999999985, -42.09999999999959, 49.70000000000046, 37.80000000000027, 37.10000000000026, 36.70000000000025, 37.80000000000027, -15.199999999999863, 19.29999999999996, 14.600000000000017, 14.19999999999996, -4.700000000000065, 16.599999999999955, 25.000000000000103, 27.4000000000001, 21.299999999999994, -21.69999999999954, 35.40000000000023, -10.299999999999645, 34.50000000000022, -169.9000000000004, 8.89999999999993, 19.799999999999976, 29.20000000000013, 37.80000000000027, -93.10000000000046, 37.80000000000027, 24.900000000000052, 12.100000000000046, -55.599999999999596, 25.100000000000108, 70.99999999999996, 15.30000000000002, 25.700000000000074, 39.60000000000029, 17.99999999999995, 33.3000000000002, 34.30000000000022, 14.699999999999944, -87.70000000000005, -34.7999999999999, 32.30000000000018, 34.40000000000022, 13.899999999999938, 32.10000000000018, 53.400000000000425, 37.40000000000026, 22.600000000000016, 19.79999999999997, 36.900000000000254, -94.30000000000082, 29.70000000000014, -125.0000000000002, 96.59999999999845, -59.599999999999746, -2.400000000000074, -8.199999999999982, 30.100000000000147, 38.70000000000028, 34.50000000000022, -11.699999999999584, 52.30000000000051, 5.9000000000001105, 31.800000000000182, 25.700000000000067, 35.60000000000023, 3.5000000000002163, 28.900000000000126, 17.400000000000027, -129.60000000000093, 35.40000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, 5.299999999999965, 20.000000000000014, -102.70000000000053, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 5.299999999999969, 5.299999999999965, 91.39999999999935, 20.000000000000014, -44.49999999999988, -3.099999999999958, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 28.100000000000147, 11.599999999999964, 13.699999999999964, 20.000000000000014, -36.699999999999754, -42.99999999999976, -131.2000000000004, -116.50000000000031, 20.000000000000014, -55.59999999999992, 9.499999999999964, -73.90000000000074, 2.2999999999999643, 11.299999999999976, -150.10000000000045, -131.2000000000001, 5.299999999999965, 7.399999999999965, -181.6000000000005, -162.7000000000005, 15.799999999999963, -57.69999999999977, 20.000000000000014, 40.40000000000019, 11.599999999999964, 20.000000000000014, 15.799999999999963, 32.60000000000023, -11.499999999999819, 20.000000000000014, -11.799999999999818, -40.89999999999976, -11.499999999999819, 17.899999999999988, 20.000000000000014, -3.099999999999958, 7.399999999999965, 20.000000000000014, 9.499999999999964, 13.699999999999964, -4.3000000000000345, 15.499999999999963, 77.59999999999923, 5.299999999999965, -9.699999999999854, -177.40000000000057, 21.500000000000036, 27.20000000000013, 20.000000000000014, 15.799999999999963, 15.799999999999963, 5.299999999999967, 17.899999999999988, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, -225.70000000000016, -28.29999999999975, 11.599999999999964, -18.399999999999984, 4.999999999999966, -15.699999999999775, -24.099999999999746, -57.69999999999995, 4.99999999999997, -33.399999999999764, 20.000000000000014, -12.099999999999817, -1.9000000000000283, 20.000000000000014, -13.599999999999783, -7.299999999999891, 11.599999999999964, -39.69999999999982, -42.99999999999976, 20.000000000000014, 7.399999999999965, -51.399999999999764, 1.0999999999999865, 20.000000000000014, 9.499999999999964, -194.2000000000005, -204.70000000000041, -45.0999999999998, 20.000000000000014, 13.699999999999964, -13.899999999999796, 15.799999999999963, 7.39999999999997, 15.799999999999963, 20.000000000000014, -101.80000000000027, -175.30000000000052, 15.799999999999963, 20.000000000000014, 13.699999999999964, 3.1999999999999615, 7.399999999999965, -28.29999999999975, -181.6000000000006, 20.000000000000014, 20.90000000000003, -29.799999999999784, 55.10000000000023, -21.099999999999774, 7.399999999999965, -3.099999999999958, 20.000000000000014, -19.29999999999975, 17.899999999999988, 10.69999999999997, -13.599999999999783, 11.599999999999964, 5.299999999999965, 20.000000000000014, 5.299999999999965, 20.000000000000014, 5.299999999999965, -13.599999999999783, -99.69999999999999, -106.00000000000017, -122.80000000000013, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 7.399999999999965, -42.09999999999979, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 5.599999999999981, 15.799999999999962, 7.399999999999965, 20.000000000000014, 13.699999999999964, -24.099999999999746, -26.199999999999747, 20.000000000000014, -3.099999999999958, 20.000000000000014, -154.30000000000064, -106.00000000000077, -1.2999999999999847, 20.000000000000014, -116.50000000000034, -149.50000000000006, 32.60000000000023, 59.0000000000002, -15.699999999999783, -355.89999999999964, -54.99999999999977, 11.599999999999964, 28.100000000000147, -91.3000000000005, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999964, 7.399999999999965, -66.1000000000009, 15.799999999999963, 33.50000000000024, -38.799999999999756, 13.69999999999996, -12.6999999999998, 27.50000000000014, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 2.5999999999999646, -7.299999999999891, -5.1999999999999265, 20.000000000000014, -3.099999999999958, 9.499999999999964, -15.099999999999763, -200.80000000000052, -80.80000000000048, 16.69999999999997, 13.699999999999966], "policy_predator_policy_reward": [8.0, 6.0, 40.0, 46.0, 0.0, 9.0, 0.0, 7.0, 8.0, 8.0, 13.0, 50.0, 1.0, 11.0, 10.0, 5.0, 4.0, 0.0, 3.0, 1.0, 2.0, 32.0, 77.0, 56.0, 0.0, 36.0, 38.0, 23.0, 15.0, 13.0, 122.0, 7.0, 3.0, 7.0, 143.0, 10.0, 32.0, 8.0, 13.0, 0.0, 4.0, 3.0, 2.0, 1.0, 15.0, 7.0, 16.0, 29.0, 1.0, 15.0, 5.0, 11.0, 0.0, 6.0, 3.0, 5.0, 20.0, 1.0, 7.0, 3.0, 79.0, 66.0, 1.0, 0.0, 0.0, 2.0, 7.0, 9.0, 1.0, 2.0, 0.0, 2.0, 102.0, 99.0, 13.0, 23.0, 8.0, 20.0, 21.0, 33.0, 7.0, 41.0, 25.0, 5.0, 19.0, 20.0, 5.0, 16.0, 4.0, 13.0, 6.0, 55.0, 2.0, 6.0, 6.0, 34.0, 0.0, 5.0, 115.0, 114.0, 17.0, 17.0, 17.0, 3.0, 6.0, 0.0, 2.0, 0.0, 95.0, 89.0, 0.0, 2.0, 8.0, 0.0, 10.0, 23.0, 44.0, 62.0, 30.0, 4.0, 13.0, 24.0, 11.0, 0.0, 5.0, 20.0, 3.0, 8.0, 4.0, 16.0, 1.0, 7.0, 2.0, 7.0, 16.0, 7.0, 116.0, 2.0, 68.0, 0.0, 1.0, 6.0, 1.0, 6.0, 2.0, 34.0, 9.0, 2.0, 17.0, 15.0, 4.0, 6.0, 18.0, 15.0, 10.0, 16.0, 9.0, 11.0, 91.0, 75.0, 0.0, 11.0, 139.0, 2.0, 5.0, 0.0, 152.0, 160.0, 4.0, 37.0, 2.0, 53.0, 9.0, 0.0, 2.0, 3.0, 0.0, 5.0, 6.0, 41.0, 1.0, 2.0, 30.0, 1.0, 1.0, 16.0, 4.0, 9.0, 13.0, 0.0, 14.0, 2.0, 1.0, 11.0, 5.0, 18.0, 31.0, 121.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8696103372164643, "mean_inference_ms": 2.2473385295322448, "mean_action_processing_ms": 0.3553220399294736, "mean_env_wait_ms": 0.2868983593300735, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003949761390686035, "StateBufferConnector_ms": 0.011146068572998047, "ViewRequirementAgentConnector_ms": 0.1970686912536621}, "num_episodes": 18, "episode_return_max": 112.69999999999864, "episode_return_min": -191.300000000001, "episode_return_mean": 9.935000000000041, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.8882556389435, "num_env_steps_trained_throughput_per_sec": 351.8882556389435, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 12132.477, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12132.429, "sample_time_ms": 1988.273, "learn_time_ms": 10123.333, "learn_throughput": 395.127, "synch_weights_time_ms": 18.43}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "f0d88_00000", "date": "2024-08-14_11-04-27", "timestamp": 1723647867, "time_this_iter_s": 11.42426586151123, "time_total_s": 1083.6798739433289, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad504e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1083.6798739433289, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 46.22941176470587, "ram_util_percent": 82.7470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8357535643552345, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.7085061778309485, "policy_loss": -0.017664825896826133, "vf_loss": 1.709712302495563, "vf_explained_var": 0.17373875184033913, "kl": 0.010837006602338394, "entropy": 1.2783118123099917, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.696277627206984, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.0010000000000000005, "total_loss": 1.0423109298029904, "policy_loss": -0.007720513871954705, "vf_loss": 1.0420978002683827, "vf_explained_var": 0.7528638357838625, "kl": 0.004643375952549098, "entropy": 0.9543412771489885, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 96.69999999999986, "episode_reward_min": -169.9000000000004, "episode_reward_mean": 14.441000000000088, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.89999999999964, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 77.59999999999923, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -11.994500000000011, "predator_policy": 19.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.50000000000016, -7.699999999999648, 22.40000000000001, 32.9000000000002, 33.400000000000205, 31.200000000000163, 32.200000000000266, 92.8999999999985, -42.09999999999959, 49.70000000000046, 37.80000000000027, 37.10000000000026, 36.70000000000025, 37.80000000000027, -15.199999999999863, 19.29999999999996, 14.600000000000017, 14.19999999999996, -4.700000000000065, 16.599999999999955, 25.000000000000103, 27.4000000000001, 21.299999999999994, -21.69999999999954, 35.40000000000023, -10.299999999999645, 34.50000000000022, -169.9000000000004, 8.89999999999993, 19.799999999999976, 29.20000000000013, 37.80000000000027, -93.10000000000046, 37.80000000000027, 24.900000000000052, 12.100000000000046, -55.599999999999596, 25.100000000000108, 70.99999999999996, 15.30000000000002, 25.700000000000074, 39.60000000000029, 17.99999999999995, 33.3000000000002, 34.30000000000022, 14.699999999999944, -87.70000000000005, -34.7999999999999, 32.30000000000018, 34.40000000000022, 13.899999999999938, 32.10000000000018, 53.400000000000425, 37.40000000000026, 22.600000000000016, 19.79999999999997, 36.900000000000254, -94.30000000000082, 29.70000000000014, -125.0000000000002, 96.59999999999845, -59.599999999999746, -2.400000000000074, -8.199999999999982, 30.100000000000147, 38.70000000000028, 34.50000000000022, -11.699999999999584, 52.30000000000051, 5.9000000000001105, 31.800000000000182, 25.700000000000067, 35.60000000000023, 3.5000000000002163, 28.900000000000126, 17.400000000000027, -129.60000000000093, 35.40000000000023, 30.200000000000163, 50.500000000000476, 35.600000000000236, 27.900000000000105, 57.500000000000476, -63.40000000000002, -65.69999999999978, 49.300000000000466, 27.300000000000107, 38.400000000000276, 33.400000000000205, 68.80000000000001, 41.900000000000325, 27.1000000000001, -124.80000000000048, 96.69999999999986, 33.80000000000021, 58.10000000000049, 26.700000000000085, 30.100000000000144, 26.900000000000087, 32.10000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.499999999999819, 20.000000000000014, -11.799999999999818, -40.89999999999976, -11.499999999999819, 17.899999999999988, 20.000000000000014, -3.099999999999958, 7.399999999999965, 20.000000000000014, 9.499999999999964, 13.699999999999964, -4.3000000000000345, 15.499999999999963, 77.59999999999923, 5.299999999999965, -9.699999999999854, -177.40000000000057, 21.500000000000036, 27.20000000000013, 20.000000000000014, 15.799999999999963, 15.799999999999963, 5.299999999999967, 17.899999999999988, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, -225.70000000000016, -28.29999999999975, 11.599999999999964, -18.399999999999984, 4.999999999999966, -15.699999999999775, -24.099999999999746, -57.69999999999995, 4.99999999999997, -33.399999999999764, 20.000000000000014, -12.099999999999817, -1.9000000000000283, 20.000000000000014, -13.599999999999783, -7.299999999999891, 11.599999999999964, -39.69999999999982, -42.99999999999976, 20.000000000000014, 7.399999999999965, -51.399999999999764, 1.0999999999999865, 20.000000000000014, 9.499999999999964, -194.2000000000005, -204.70000000000041, -45.0999999999998, 20.000000000000014, 13.699999999999964, -13.899999999999796, 15.799999999999963, 7.39999999999997, 15.799999999999963, 20.000000000000014, -101.80000000000027, -175.30000000000052, 15.799999999999963, 20.000000000000014, 13.699999999999964, 3.1999999999999615, 7.399999999999965, -28.29999999999975, -181.6000000000006, 20.000000000000014, 20.90000000000003, -29.799999999999784, 55.10000000000023, -21.099999999999774, 7.399999999999965, -3.099999999999958, 20.000000000000014, -19.29999999999975, 17.899999999999988, 10.69999999999997, -13.599999999999783, 11.599999999999964, 5.299999999999965, 20.000000000000014, 5.299999999999965, 20.000000000000014, 5.299999999999965, -13.599999999999783, -99.69999999999999, -106.00000000000017, -122.80000000000013, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 7.399999999999965, -42.09999999999979, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 5.599999999999981, 15.799999999999962, 7.399999999999965, 20.000000000000014, 13.699999999999964, -24.099999999999746, -26.199999999999747, 20.000000000000014, -3.099999999999958, 20.000000000000014, -154.30000000000064, -106.00000000000077, -1.2999999999999847, 20.000000000000014, -116.50000000000034, -149.50000000000006, 32.60000000000023, 59.0000000000002, -15.699999999999783, -355.89999999999964, -54.99999999999977, 11.599999999999964, 28.100000000000147, -91.3000000000005, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999964, 7.399999999999965, -66.1000000000009, 15.799999999999963, 33.50000000000024, -38.799999999999756, 13.69999999999996, -12.6999999999998, 27.50000000000014, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 2.5999999999999646, -7.299999999999891, -5.1999999999999265, 20.000000000000014, -3.099999999999958, 9.499999999999964, -15.099999999999763, -200.80000000000052, -80.80000000000048, 16.69999999999997, 13.699999999999966, 20.000000000000014, -59.800000000000566, 23.600000000000065, 20.900000000000027, 20.000000000000014, 11.599999999999964, 15.799999999999963, 1.0999999999999865, 24.500000000000092, 20.000000000000014, -173.2000000000004, 15.799999999999963, -181.2000000000006, 9.499999999999982, 25.700000000000113, 11.600000000000005, 20.000000000000014, -15.699999999999747, 7.399999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, -23.20000000000025, 20.000000000000014, 17.899999999999984, 20.000000000000014, -19.899999999999743, 20.000000000000014, -103.90000000000032, -166.90000000000006, 24.200000000000077, 54.50000000000015, -5.1999999999999265, 20.000000000000014, 36.200000000000244, 17.899999999999988, 15.799999999999963, -3.099999999999958, 11.599999999999964, 9.499999999999964, 7.399999999999965, 9.49999999999997, 13.699999999999964, 7.399999999999965], "policy_predator_policy_reward": [15.0, 7.0, 16.0, 29.0, 1.0, 15.0, 5.0, 11.0, 0.0, 6.0, 3.0, 5.0, 20.0, 1.0, 7.0, 3.0, 79.0, 66.0, 1.0, 0.0, 0.0, 2.0, 7.0, 9.0, 1.0, 2.0, 0.0, 2.0, 102.0, 99.0, 13.0, 23.0, 8.0, 20.0, 21.0, 33.0, 7.0, 41.0, 25.0, 5.0, 19.0, 20.0, 5.0, 16.0, 4.0, 13.0, 6.0, 55.0, 2.0, 6.0, 6.0, 34.0, 0.0, 5.0, 115.0, 114.0, 17.0, 17.0, 17.0, 3.0, 6.0, 0.0, 2.0, 0.0, 95.0, 89.0, 0.0, 2.0, 8.0, 0.0, 10.0, 23.0, 44.0, 62.0, 30.0, 4.0, 13.0, 24.0, 11.0, 0.0, 5.0, 20.0, 3.0, 8.0, 4.0, 16.0, 1.0, 7.0, 2.0, 7.0, 16.0, 7.0, 116.0, 2.0, 68.0, 0.0, 1.0, 6.0, 1.0, 6.0, 2.0, 34.0, 9.0, 2.0, 17.0, 15.0, 4.0, 6.0, 18.0, 15.0, 10.0, 16.0, 9.0, 11.0, 91.0, 75.0, 0.0, 11.0, 139.0, 2.0, 5.0, 0.0, 152.0, 160.0, 4.0, 37.0, 2.0, 53.0, 9.0, 0.0, 2.0, 3.0, 0.0, 5.0, 6.0, 41.0, 1.0, 2.0, 30.0, 1.0, 1.0, 16.0, 4.0, 9.0, 13.0, 0.0, 14.0, 2.0, 1.0, 11.0, 5.0, 18.0, 31.0, 121.0, 3.0, 2.0, 38.0, 32.0, 3.0, 3.0, 4.0, 0.0, 2.0, 9.0, 9.0, 4.0, 92.0, 2.0, 5.0, 101.0, 6.0, 6.0, 17.0, 6.0, 6.0, 5.0, 1.0, 5.0, 39.0, 33.0, 4.0, 0.0, 8.0, 19.0, 140.0, 6.0, 1.0, 17.0, 7.0, 12.0, 3.0, 1.0, 3.0, 11.0, 5.0, 4.0, 7.0, 3.0, 6.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8703547828966307, "mean_inference_ms": 2.2503779334850273, "mean_action_processing_ms": 0.3549853598068339, "mean_env_wait_ms": 0.28660840178482483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037616491317749023, "StateBufferConnector_ms": 0.010660648345947266, "ViewRequirementAgentConnector_ms": 0.18320703506469727}, "num_episodes": 22, "episode_return_max": 96.69999999999986, "episode_return_min": -169.9000000000004, "episode_return_mean": 14.441000000000088, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.92689148129784, "num_env_steps_trained_throughput_per_sec": 341.92689148129784, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 12054.262, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12054.213, "sample_time_ms": 1987.546, "learn_time_ms": 10045.774, "learn_throughput": 398.177, "synch_weights_time_ms": 18.979}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "f0d88_00000", "date": "2024-08-14_11-04-39", "timestamp": 1723647879, "time_this_iter_s": 11.791188955307007, "time_total_s": 1095.4710628986359, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4d1160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1095.4710628986359, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 42.3125, "ram_util_percent": 82.84375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.929972344447696, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 3.0831618349072794, "policy_loss": -0.015897159975406434, "vf_loss": 3.0833885985076743, "vf_explained_var": 0.058279068444771744, "kl": 0.010317954876559881, "entropy": 1.2729205726315735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6295122376667759, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 2.184623021675796, "policy_loss": -0.005207629498863031, "vf_loss": 2.1826073606178245, "vf_explained_var": 0.7222804305099305, "kl": 0.00845524607831579, "entropy": 0.8284578583858632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 96.69999999999986, "episode_reward_min": -169.9000000000004, "episode_reward_mean": 9.730000000000096, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.89999999999964, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 59.0000000000002, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -15.020000000000014, "predator_policy": 19.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.700000000000065, 16.599999999999955, 25.000000000000103, 27.4000000000001, 21.299999999999994, -21.69999999999954, 35.40000000000023, -10.299999999999645, 34.50000000000022, -169.9000000000004, 8.89999999999993, 19.799999999999976, 29.20000000000013, 37.80000000000027, -93.10000000000046, 37.80000000000027, 24.900000000000052, 12.100000000000046, -55.599999999999596, 25.100000000000108, 70.99999999999996, 15.30000000000002, 25.700000000000074, 39.60000000000029, 17.99999999999995, 33.3000000000002, 34.30000000000022, 14.699999999999944, -87.70000000000005, -34.7999999999999, 32.30000000000018, 34.40000000000022, 13.899999999999938, 32.10000000000018, 53.400000000000425, 37.40000000000026, 22.600000000000016, 19.79999999999997, 36.900000000000254, -94.30000000000082, 29.70000000000014, -125.0000000000002, 96.59999999999845, -59.599999999999746, -2.400000000000074, -8.199999999999982, 30.100000000000147, 38.70000000000028, 34.50000000000022, -11.699999999999584, 52.30000000000051, 5.9000000000001105, 31.800000000000182, 25.700000000000067, 35.60000000000023, 3.5000000000002163, 28.900000000000126, 17.400000000000027, -129.60000000000093, 35.40000000000023, 30.200000000000163, 50.500000000000476, 35.600000000000236, 27.900000000000105, 57.500000000000476, -63.40000000000002, -65.69999999999978, 49.300000000000466, 27.300000000000107, 38.400000000000276, 33.400000000000205, 68.80000000000001, 41.900000000000325, 27.1000000000001, -124.80000000000048, 96.69999999999986, 33.80000000000021, 58.10000000000049, 26.700000000000085, 30.100000000000144, 26.900000000000087, 32.10000000000018, 33.90000000000021, 38.30000000000027, -119.59999999999997, -98.30000000000007, 37.50000000000026, -30.399999999999665, -94.50000000000033, 2.599999999999953, 36.700000000000244, 34.50000000000022, 22.90000000000002, 42.30000000000033, 22.50000000000001, 59.00000000000047, 37.700000000000266, 15.800000000000004, -50.19999999999993, -4.099999999999689], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-57.69999999999995, 4.99999999999997, -33.399999999999764, 20.000000000000014, -12.099999999999817, -1.9000000000000283, 20.000000000000014, -13.599999999999783, -7.299999999999891, 11.599999999999964, -39.69999999999982, -42.99999999999976, 20.000000000000014, 7.399999999999965, -51.399999999999764, 1.0999999999999865, 20.000000000000014, 9.499999999999964, -194.2000000000005, -204.70000000000041, -45.0999999999998, 20.000000000000014, 13.699999999999964, -13.899999999999796, 15.799999999999963, 7.39999999999997, 15.799999999999963, 20.000000000000014, -101.80000000000027, -175.30000000000052, 15.799999999999963, 20.000000000000014, 13.699999999999964, 3.1999999999999615, 7.399999999999965, -28.29999999999975, -181.6000000000006, 20.000000000000014, 20.90000000000003, -29.799999999999784, 55.10000000000023, -21.099999999999774, 7.399999999999965, -3.099999999999958, 20.000000000000014, -19.29999999999975, 17.899999999999988, 10.69999999999997, -13.599999999999783, 11.599999999999964, 5.299999999999965, 20.000000000000014, 5.299999999999965, 20.000000000000014, 5.299999999999965, -13.599999999999783, -99.69999999999999, -106.00000000000017, -122.80000000000013, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 7.399999999999965, -42.09999999999979, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 5.599999999999981, 15.799999999999962, 7.399999999999965, 20.000000000000014, 13.699999999999964, -24.099999999999746, -26.199999999999747, 20.000000000000014, -3.099999999999958, 20.000000000000014, -154.30000000000064, -106.00000000000077, -1.2999999999999847, 20.000000000000014, -116.50000000000034, -149.50000000000006, 32.60000000000023, 59.0000000000002, -15.699999999999783, -355.89999999999964, -54.99999999999977, 11.599999999999964, 28.100000000000147, -91.3000000000005, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999964, 7.399999999999965, -66.1000000000009, 15.799999999999963, 33.50000000000024, -38.799999999999756, 13.69999999999996, -12.6999999999998, 27.50000000000014, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 2.5999999999999646, -7.299999999999891, -5.1999999999999265, 20.000000000000014, -3.099999999999958, 9.499999999999964, -15.099999999999763, -200.80000000000052, -80.80000000000048, 16.69999999999997, 13.699999999999966, 20.000000000000014, -59.800000000000566, 23.600000000000065, 20.900000000000027, 20.000000000000014, 11.599999999999964, 15.799999999999963, 1.0999999999999865, 24.500000000000092, 20.000000000000014, -173.2000000000004, 15.799999999999963, -181.2000000000006, 9.499999999999982, 25.700000000000113, 11.600000000000005, 20.000000000000014, -15.699999999999747, 7.399999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, -23.20000000000025, 20.000000000000014, 17.899999999999984, 20.000000000000014, -19.899999999999743, 20.000000000000014, -103.90000000000032, -166.90000000000006, 24.200000000000077, 54.50000000000015, -5.1999999999999265, 20.000000000000014, 36.200000000000244, 17.899999999999988, 15.799999999999963, -3.099999999999958, 11.599999999999964, 9.499999999999964, 7.399999999999965, 9.49999999999997, 13.699999999999964, 7.399999999999965, 20.000000000000014, -3.099999999999965, 9.499999999999964, 21.800000000000047, -51.399999999999906, -194.20000000000056, -51.3999999999999, -166.9000000000002, -5.499999999999925, 20.000000000000014, 20.000000000000014, -114.40000000000057, -74.49999999999989, -106.00000000000017, 20.000000000000014, -51.399999999999764, 13.69999999999997, 20.000000000000014, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 1.699999999999971, 17.899999999999988, 19.40000000000001, 6.1999999999999655, 8.299999999999965, -11.499999999999819, 51.50000000000023, 20.000000000000014, 13.699999999999964, -9.399999999999855, 3.1999999999999615, -149.20000000000016, -85.00000000000014, -9.399999999999855, -15.699999999999747], "policy_predator_policy_reward": [7.0, 41.0, 25.0, 5.0, 19.0, 20.0, 5.0, 16.0, 4.0, 13.0, 6.0, 55.0, 2.0, 6.0, 6.0, 34.0, 0.0, 5.0, 115.0, 114.0, 17.0, 17.0, 17.0, 3.0, 6.0, 0.0, 2.0, 0.0, 95.0, 89.0, 0.0, 2.0, 8.0, 0.0, 10.0, 23.0, 44.0, 62.0, 30.0, 4.0, 13.0, 24.0, 11.0, 0.0, 5.0, 20.0, 3.0, 8.0, 4.0, 16.0, 1.0, 7.0, 2.0, 7.0, 16.0, 7.0, 116.0, 2.0, 68.0, 0.0, 1.0, 6.0, 1.0, 6.0, 2.0, 34.0, 9.0, 2.0, 17.0, 15.0, 4.0, 6.0, 18.0, 15.0, 10.0, 16.0, 9.0, 11.0, 91.0, 75.0, 0.0, 11.0, 139.0, 2.0, 5.0, 0.0, 152.0, 160.0, 4.0, 37.0, 2.0, 53.0, 9.0, 0.0, 2.0, 3.0, 0.0, 5.0, 6.0, 41.0, 1.0, 2.0, 30.0, 1.0, 1.0, 16.0, 4.0, 9.0, 13.0, 0.0, 14.0, 2.0, 1.0, 11.0, 5.0, 18.0, 31.0, 121.0, 3.0, 2.0, 38.0, 32.0, 3.0, 3.0, 4.0, 0.0, 2.0, 9.0, 9.0, 4.0, 92.0, 2.0, 5.0, 101.0, 6.0, 6.0, 17.0, 6.0, 6.0, 5.0, 1.0, 5.0, 39.0, 33.0, 4.0, 0.0, 8.0, 19.0, 140.0, 6.0, 1.0, 17.0, 7.0, 12.0, 3.0, 1.0, 3.0, 11.0, 5.0, 4.0, 7.0, 3.0, 6.0, 5.0, 6.0, 11.0, 5.0, 2.0, 10.0, 116.0, 120.0, 0.0, 13.0, 10.0, 64.0, 0.0, 86.0, 0.0, 34.0, 0.0, 0.0, 3.0, 5.0, 0.0, 17.0, 1.0, 5.0, 0.0, 7.0, 1.0, 4.0, 15.0, 1.0, 3.0, 8.0, 14.0, 88.0, 96.0, 4.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8706248672152773, "mean_inference_ms": 2.2504660153241933, "mean_action_processing_ms": 0.355681412730267, "mean_env_wait_ms": 0.28721351785044924, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037522315979003906, "StateBufferConnector_ms": 0.0030622482299804688, "ViewRequirementAgentConnector_ms": 0.16531884670257568}, "num_episodes": 18, "episode_return_max": 96.69999999999986, "episode_return_min": -169.9000000000004, "episode_return_mean": 9.730000000000096, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.65548993996686, "num_env_steps_trained_throughput_per_sec": 343.65548993996686, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 11929.172, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11929.118, "sample_time_ms": 1951.403, "learn_time_ms": 9955.601, "learn_throughput": 401.784, "synch_weights_time_ms": 20.21}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "f0d88_00000", "date": "2024-08-14_11-04-51", "timestamp": 1723647891, "time_this_iter_s": 11.70083212852478, "time_total_s": 1107.1718950271606, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad63f4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1107.1718950271606, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 46.42352941176471, "ram_util_percent": 83.0235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7802388229067363, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.98350282686728, "policy_loss": -0.02402005770573856, "vf_loss": 1.990148649297694, "vf_explained_var": 0.06586868747201546, "kl": 0.011439826157307141, "entropy": 1.2232486688901507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7793682427633377, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 1.4730060704801449, "policy_loss": -0.010188298045026838, "vf_loss": 1.4752441271272285, "vf_explained_var": 0.6745044850167774, "kl": 0.009306178761556223, "entropy": 0.8759219516206671, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 96.69999999999986, "episode_reward_min": -129.60000000000093, "episode_reward_mean": 13.731000000000106, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.89999999999964, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.80000000000018, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -12.384500000000017, "predator_policy": 19.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.60000000000029, 17.99999999999995, 33.3000000000002, 34.30000000000022, 14.699999999999944, -87.70000000000005, -34.7999999999999, 32.30000000000018, 34.40000000000022, 13.899999999999938, 32.10000000000018, 53.400000000000425, 37.40000000000026, 22.600000000000016, 19.79999999999997, 36.900000000000254, -94.30000000000082, 29.70000000000014, -125.0000000000002, 96.59999999999845, -59.599999999999746, -2.400000000000074, -8.199999999999982, 30.100000000000147, 38.70000000000028, 34.50000000000022, -11.699999999999584, 52.30000000000051, 5.9000000000001105, 31.800000000000182, 25.700000000000067, 35.60000000000023, 3.5000000000002163, 28.900000000000126, 17.400000000000027, -129.60000000000093, 35.40000000000023, 30.200000000000163, 50.500000000000476, 35.600000000000236, 27.900000000000105, 57.500000000000476, -63.40000000000002, -65.69999999999978, 49.300000000000466, 27.300000000000107, 38.400000000000276, 33.400000000000205, 68.80000000000001, 41.900000000000325, 27.1000000000001, -124.80000000000048, 96.69999999999986, 33.80000000000021, 58.10000000000049, 26.700000000000085, 30.100000000000144, 26.900000000000087, 32.10000000000018, 33.90000000000021, 38.30000000000027, -119.59999999999997, -98.30000000000007, 37.50000000000026, -30.399999999999665, -94.50000000000033, 2.599999999999953, 36.700000000000244, 34.50000000000022, 22.90000000000002, 42.30000000000033, 22.50000000000001, 59.00000000000047, 37.700000000000266, 15.800000000000004, -50.19999999999993, -4.099999999999689, 1.2000000000001931, 88.79999999999866, 30.50000000000016, 46.0000000000004, 42.70000000000034, 17.199999999999992, 33.2000000000002, -127.40000000000083, -20.499999999999517, -64.50000000000028, 61.50000000000027, 28.400000000000347, 54.90000000000042, 30.100000000000147, -19.599999999999824, 28.10000000000024, 38.400000000000276, 59.4000000000005, 34.200000000000216, 66.60000000000024, 67.20000000000024, -16.099999999999945, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, 10.69999999999997, -13.599999999999783, 11.599999999999964, 5.299999999999965, 20.000000000000014, 5.299999999999965, 20.000000000000014, 5.299999999999965, -13.599999999999783, -99.69999999999999, -106.00000000000017, -122.80000000000013, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 7.399999999999965, -42.09999999999979, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 5.599999999999981, 15.799999999999962, 7.399999999999965, 20.000000000000014, 13.699999999999964, -24.099999999999746, -26.199999999999747, 20.000000000000014, -3.099999999999958, 20.000000000000014, -154.30000000000064, -106.00000000000077, -1.2999999999999847, 20.000000000000014, -116.50000000000034, -149.50000000000006, 32.60000000000023, 59.0000000000002, -15.699999999999783, -355.89999999999964, -54.99999999999977, 11.599999999999964, 28.100000000000147, -91.3000000000005, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999964, 7.399999999999965, -66.1000000000009, 15.799999999999963, 33.50000000000024, -38.799999999999756, 13.69999999999996, -12.6999999999998, 27.50000000000014, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 2.5999999999999646, -7.299999999999891, -5.1999999999999265, 20.000000000000014, -3.099999999999958, 9.499999999999964, -15.099999999999763, -200.80000000000052, -80.80000000000048, 16.69999999999997, 13.699999999999966, 20.000000000000014, -59.800000000000566, 23.600000000000065, 20.900000000000027, 20.000000000000014, 11.599999999999964, 15.799999999999963, 1.0999999999999865, 24.500000000000092, 20.000000000000014, -173.2000000000004, 15.799999999999963, -181.2000000000006, 9.499999999999982, 25.700000000000113, 11.600000000000005, 20.000000000000014, -15.699999999999747, 7.399999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, -23.20000000000025, 20.000000000000014, 17.899999999999984, 20.000000000000014, -19.899999999999743, 20.000000000000014, -103.90000000000032, -166.90000000000006, 24.200000000000077, 54.50000000000015, -5.1999999999999265, 20.000000000000014, 36.200000000000244, 17.899999999999988, 15.799999999999963, -3.099999999999958, 11.599999999999964, 9.499999999999964, 7.399999999999965, 9.49999999999997, 13.699999999999964, 7.399999999999965, 20.000000000000014, -3.099999999999965, 9.499999999999964, 21.800000000000047, -51.399999999999906, -194.20000000000056, -51.3999999999999, -166.9000000000002, -5.499999999999925, 20.000000000000014, 20.000000000000014, -114.40000000000057, -74.49999999999989, -106.00000000000017, 20.000000000000014, -51.399999999999764, 13.69999999999997, 20.000000000000014, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 1.699999999999971, 17.899999999999988, 19.40000000000001, 6.1999999999999655, 8.299999999999965, -11.499999999999819, 51.50000000000023, 20.000000000000014, 13.699999999999964, -9.399999999999855, 3.1999999999999615, -149.20000000000016, -85.00000000000014, -9.399999999999855, -15.699999999999747, 15.799999999999963, -55.60000000000031, 20.000000000000014, 60.80000000000018, 20.000000000000014, -11.499999999999819, 20.000000000000014, 23.000000000000057, 20.000000000000014, 22.700000000000053, 13.699999999999964, -11.499999999999819, 17.899999999999988, 5.299999999999965, -116.50000000000077, -130.90000000000043, -78.70000000000043, 3.1999999999999615, -106.00000000000011, -53.49999999999978, -53.50000000000004, 29.0, 39.80000000000019, -51.399999999999764, 58.400000000000205, -32.49999999999975, 20.000000000000014, 1.0999999999999865, 30.20000000000019, -122.80000000000027, -27.099999999999852, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 15.799999999999963, 41.60000000000025, 20.000000000000014, 3.1999999999999615, 2.299999999999982, 5.299999999999965, 20.000000000000014, 36.20000000000023, -141.70000000000036, 11.599999999999964, 5.299999999999965, 20.000000000000014], "policy_predator_policy_reward": [3.0, 8.0, 4.0, 16.0, 1.0, 7.0, 2.0, 7.0, 16.0, 7.0, 116.0, 2.0, 68.0, 0.0, 1.0, 6.0, 1.0, 6.0, 2.0, 34.0, 9.0, 2.0, 17.0, 15.0, 4.0, 6.0, 18.0, 15.0, 10.0, 16.0, 9.0, 11.0, 91.0, 75.0, 0.0, 11.0, 139.0, 2.0, 5.0, 0.0, 152.0, 160.0, 4.0, 37.0, 2.0, 53.0, 9.0, 0.0, 2.0, 3.0, 0.0, 5.0, 6.0, 41.0, 1.0, 2.0, 30.0, 1.0, 1.0, 16.0, 4.0, 9.0, 13.0, 0.0, 14.0, 2.0, 1.0, 11.0, 5.0, 18.0, 31.0, 121.0, 3.0, 2.0, 38.0, 32.0, 3.0, 3.0, 4.0, 0.0, 2.0, 9.0, 9.0, 4.0, 92.0, 2.0, 5.0, 101.0, 6.0, 6.0, 17.0, 6.0, 6.0, 5.0, 1.0, 5.0, 39.0, 33.0, 4.0, 0.0, 8.0, 19.0, 140.0, 6.0, 1.0, 17.0, 7.0, 12.0, 3.0, 1.0, 3.0, 11.0, 5.0, 4.0, 7.0, 3.0, 6.0, 5.0, 6.0, 11.0, 5.0, 2.0, 10.0, 116.0, 120.0, 0.0, 13.0, 10.0, 64.0, 0.0, 86.0, 0.0, 34.0, 0.0, 0.0, 3.0, 5.0, 0.0, 17.0, 1.0, 5.0, 0.0, 7.0, 1.0, 4.0, 15.0, 1.0, 3.0, 8.0, 14.0, 88.0, 96.0, 4.0, 17.0, 32.0, 9.0, 0.0, 8.0, 15.0, 7.0, 1.0, 2.0, 0.0, 0.0, 0.0, 15.0, 7.0, 3.0, 118.0, 2.0, 8.0, 47.0, 95.0, 0.0, 47.0, 39.0, 34.0, 6.0, 4.0, 25.0, 0.0, 9.0, 5.0, 68.0, 25.0, 27.0, 5.0, 6.0, 0.0, 2.0, 3.0, 8.0, 31.0, 28.0, 5.0, 6.0, 50.0, 64.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.870717362517904, "mean_inference_ms": 2.2493931188758283, "mean_action_processing_ms": 0.3558584298723174, "mean_env_wait_ms": 0.2873425621711895, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004220247268676758, "StateBufferConnector_ms": 0.0030829906463623047, "ViewRequirementAgentConnector_ms": 0.17734193801879883}, "num_episodes": 23, "episode_return_max": 96.69999999999986, "episode_return_min": -129.60000000000093, "episode_return_mean": 13.731000000000106, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.9520988285708, "num_env_steps_trained_throughput_per_sec": 341.9520988285708, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 11809.885, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11809.831, "sample_time_ms": 1899.917, "learn_time_ms": 9887.879, "learn_throughput": 404.536, "synch_weights_time_ms": 20.449}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "f0d88_00000", "date": "2024-08-14_11-05-03", "timestamp": 1723647903, "time_this_iter_s": 11.74446988105774, "time_total_s": 1118.9163649082184, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad63fe50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1118.9163649082184, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 46.16470588235294, "ram_util_percent": 82.72352941176472}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8978598304211147, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.445171628301106, "policy_loss": -0.024504726538040415, "vf_loss": 2.4496691930230963, "vf_explained_var": 0.12025100178819485, "kl": 0.01317344319814601, "entropy": 1.2638547563679003, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0445545865114405, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 1.9294668281519856, "policy_loss": -0.01260630980703152, "vf_loss": 1.9323541529279538, "vf_explained_var": 0.5765933108708216, "kl": 0.011376587911582449, "entropy": 0.8670932190758841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 151.09999999999928, "episode_reward_min": -129.60000000000093, "episode_reward_mean": 16.320000000000096, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.89999999999964, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 110.00000000000009, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -11.99000000000001, "predator_policy": 20.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-125.0000000000002, 96.59999999999845, -59.599999999999746, -2.400000000000074, -8.199999999999982, 30.100000000000147, 38.70000000000028, 34.50000000000022, -11.699999999999584, 52.30000000000051, 5.9000000000001105, 31.800000000000182, 25.700000000000067, 35.60000000000023, 3.5000000000002163, 28.900000000000126, 17.400000000000027, -129.60000000000093, 35.40000000000023, 30.200000000000163, 50.500000000000476, 35.600000000000236, 27.900000000000105, 57.500000000000476, -63.40000000000002, -65.69999999999978, 49.300000000000466, 27.300000000000107, 38.400000000000276, 33.400000000000205, 68.80000000000001, 41.900000000000325, 27.1000000000001, -124.80000000000048, 96.69999999999986, 33.80000000000021, 58.10000000000049, 26.700000000000085, 30.100000000000144, 26.900000000000087, 32.10000000000018, 33.90000000000021, 38.30000000000027, -119.59999999999997, -98.30000000000007, 37.50000000000026, -30.399999999999665, -94.50000000000033, 2.599999999999953, 36.700000000000244, 34.50000000000022, 22.90000000000002, 42.30000000000033, 22.50000000000001, 59.00000000000047, 37.700000000000266, 15.800000000000004, -50.19999999999993, -4.099999999999689, 1.2000000000001931, 88.79999999999866, 30.50000000000016, 46.0000000000004, 42.70000000000034, 17.199999999999992, 33.2000000000002, -127.40000000000083, -20.499999999999517, -64.50000000000028, 61.50000000000027, 28.400000000000347, 54.90000000000042, 30.100000000000147, -19.599999999999824, 28.10000000000024, 38.400000000000276, 59.4000000000005, 34.200000000000216, 66.60000000000024, 67.20000000000024, -16.099999999999945, 32.30000000000018, 42.30000000000033, 17.699999999999932, 20.19999999999997, 6.700000000000136, 6.699999999999926, 31.400000000000304, 26.80000000000009, -97.50000000000117, 14.700000000000022, -31.199999999999548, -39.799999999999706, 3.600000000000202, 118.69999999999989, 97.80000000000003, 32.700000000000195, 151.09999999999928, 52.60000000000031, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-116.50000000000034, -149.50000000000006, 32.60000000000023, 59.0000000000002, -15.699999999999783, -355.89999999999964, -54.99999999999977, 11.599999999999964, 28.100000000000147, -91.3000000000005, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999964, 7.399999999999965, -66.1000000000009, 15.799999999999963, 33.50000000000024, -38.799999999999756, 13.69999999999996, -12.6999999999998, 27.50000000000014, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 2.5999999999999646, -7.299999999999891, -5.1999999999999265, 20.000000000000014, -3.099999999999958, 9.499999999999964, -15.099999999999763, -200.80000000000052, -80.80000000000048, 16.69999999999997, 13.699999999999966, 20.000000000000014, -59.800000000000566, 23.600000000000065, 20.900000000000027, 20.000000000000014, 11.599999999999964, 15.799999999999963, 1.0999999999999865, 24.500000000000092, 20.000000000000014, -173.2000000000004, 15.799999999999963, -181.2000000000006, 9.499999999999982, 25.700000000000113, 11.600000000000005, 20.000000000000014, -15.699999999999747, 7.399999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, -23.20000000000025, 20.000000000000014, 17.899999999999984, 20.000000000000014, -19.899999999999743, 20.000000000000014, -103.90000000000032, -166.90000000000006, 24.200000000000077, 54.50000000000015, -5.1999999999999265, 20.000000000000014, 36.200000000000244, 17.899999999999988, 15.799999999999963, -3.099999999999958, 11.599999999999964, 9.499999999999964, 7.399999999999965, 9.49999999999997, 13.699999999999964, 7.399999999999965, 20.000000000000014, -3.099999999999965, 9.499999999999964, 21.800000000000047, -51.399999999999906, -194.20000000000056, -51.3999999999999, -166.9000000000002, -5.499999999999925, 20.000000000000014, 20.000000000000014, -114.40000000000057, -74.49999999999989, -106.00000000000017, 20.000000000000014, -51.399999999999764, 13.69999999999997, 20.000000000000014, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 1.699999999999971, 17.899999999999988, 19.40000000000001, 6.1999999999999655, 8.299999999999965, -11.499999999999819, 51.50000000000023, 20.000000000000014, 13.699999999999964, -9.399999999999855, 3.1999999999999615, -149.20000000000016, -85.00000000000014, -9.399999999999855, -15.699999999999747, 15.799999999999963, -55.60000000000031, 20.000000000000014, 60.80000000000018, 20.000000000000014, -11.499999999999819, 20.000000000000014, 23.000000000000057, 20.000000000000014, 22.700000000000053, 13.699999999999964, -11.499999999999819, 17.899999999999988, 5.299999999999965, -116.50000000000077, -130.90000000000043, -78.70000000000043, 3.1999999999999615, -106.00000000000011, -53.49999999999978, -53.50000000000004, 29.0, 39.80000000000019, -51.399999999999764, 58.400000000000205, -32.49999999999975, 20.000000000000014, 1.0999999999999865, 30.20000000000019, -122.80000000000027, -27.099999999999852, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 15.799999999999963, 41.60000000000025, 20.000000000000014, 3.1999999999999615, 2.299999999999982, 5.299999999999965, 20.000000000000014, 36.20000000000023, -141.70000000000036, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 23.600000000000065, -36.699999999999754, 7.399999999999965, 7.399999999999965, -5.19999999999993, -13.599999999999783, -3.699999999999962, 20.000000000000014, -49.29999999999989, -46.299999999999855, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -94.30000000000054, -89.20000000000063, -5.1999999999999265, -3.099999999999958, -27.399999999999764, -80.80000000000086, -15.699999999999775, -255.10000000000002, -26.199999999999747, -5.1999999999999265, 94.69999999999999, -15.999999999999774, -47.19999999999986, 110.00000000000009, 7.0999999999999694, 11.599999999999964, 30.80000000000011, 71.2999999999999, 32.60000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [139.0, 2.0, 5.0, 0.0, 152.0, 160.0, 4.0, 37.0, 2.0, 53.0, 9.0, 0.0, 2.0, 3.0, 0.0, 5.0, 6.0, 41.0, 1.0, 2.0, 30.0, 1.0, 1.0, 16.0, 4.0, 9.0, 13.0, 0.0, 14.0, 2.0, 1.0, 11.0, 5.0, 18.0, 31.0, 121.0, 3.0, 2.0, 38.0, 32.0, 3.0, 3.0, 4.0, 0.0, 2.0, 9.0, 9.0, 4.0, 92.0, 2.0, 5.0, 101.0, 6.0, 6.0, 17.0, 6.0, 6.0, 5.0, 1.0, 5.0, 39.0, 33.0, 4.0, 0.0, 8.0, 19.0, 140.0, 6.0, 1.0, 17.0, 7.0, 12.0, 3.0, 1.0, 3.0, 11.0, 5.0, 4.0, 7.0, 3.0, 6.0, 5.0, 6.0, 11.0, 5.0, 2.0, 10.0, 116.0, 120.0, 0.0, 13.0, 10.0, 64.0, 0.0, 86.0, 0.0, 34.0, 0.0, 0.0, 3.0, 5.0, 0.0, 17.0, 1.0, 5.0, 0.0, 7.0, 1.0, 4.0, 15.0, 1.0, 3.0, 8.0, 14.0, 88.0, 96.0, 4.0, 17.0, 32.0, 9.0, 0.0, 8.0, 15.0, 7.0, 1.0, 2.0, 0.0, 0.0, 0.0, 15.0, 7.0, 3.0, 118.0, 2.0, 8.0, 47.0, 95.0, 0.0, 47.0, 39.0, 34.0, 6.0, 4.0, 25.0, 0.0, 9.0, 5.0, 68.0, 25.0, 27.0, 5.0, 6.0, 0.0, 2.0, 3.0, 8.0, 31.0, 28.0, 5.0, 6.0, 50.0, 64.0, 0.0, 7.0, 3.0, 2.0, 25.0, 22.0, 12.0, 6.0, 2.0, 22.0, 31.0, 5.0, 50.0, 14.0, 0.0, 12.0, 6.0, 80.0, 13.0, 10.0, 29.0, 48.0, 113.0, 118.0, 22.0, 13.0, 16.0, 24.0, 32.0, 3.0, 14.0, 0.0, 15.0, 34.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8698653729511281, "mean_inference_ms": 2.249670117834162, "mean_action_processing_ms": 0.3554059029097774, "mean_env_wait_ms": 0.28687289407959066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006248950958251953, "StateBufferConnector_ms": 0.003246784210205078, "ViewRequirementAgentConnector_ms": 0.16080045700073242}, "num_episodes": 18, "episode_return_max": 151.09999999999928, "episode_return_min": -129.60000000000093, "episode_return_mean": 16.320000000000096, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.760742642607, "num_env_steps_trained_throughput_per_sec": 333.760742642607, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 11813.604, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11813.552, "sample_time_ms": 1861.712, "learn_time_ms": 9927.623, "learn_throughput": 402.916, "synch_weights_time_ms": 22.71}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "f0d88_00000", "date": "2024-08-14_11-05-15", "timestamp": 1723647915, "time_this_iter_s": 12.040993928909302, "time_total_s": 1130.9573588371277, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad63f5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1130.9573588371277, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 47.4, "ram_util_percent": 82.78235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6688203267004125, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.962942684485168, "policy_loss": -0.03344161981746318, "vf_loss": 1.9810447707062675, "vf_explained_var": -0.19316714557390363, "kl": 0.010100103368717986, "entropy": 1.2612568534871258, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6992018966132372, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 1.9361634864378228, "policy_loss": -0.010306497944750522, "vf_loss": 1.936544921347704, "vf_explained_var": 0.20706910352227548, "kl": 0.011617817623535528, "entropy": 0.9475913697449618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 151.09999999999928, "episode_reward_min": -127.40000000000083, "episode_reward_mean": 21.710000000000118, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.10000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 110.00000000000009, "predator_policy": 140.0}, "policy_reward_mean": {"prey_policy": -7.880000000000015, "predator_policy": 18.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.40000000000023, 30.200000000000163, 50.500000000000476, 35.600000000000236, 27.900000000000105, 57.500000000000476, -63.40000000000002, -65.69999999999978, 49.300000000000466, 27.300000000000107, 38.400000000000276, 33.400000000000205, 68.80000000000001, 41.900000000000325, 27.1000000000001, -124.80000000000048, 96.69999999999986, 33.80000000000021, 58.10000000000049, 26.700000000000085, 30.100000000000144, 26.900000000000087, 32.10000000000018, 33.90000000000021, 38.30000000000027, -119.59999999999997, -98.30000000000007, 37.50000000000026, -30.399999999999665, -94.50000000000033, 2.599999999999953, 36.700000000000244, 34.50000000000022, 22.90000000000002, 42.30000000000033, 22.50000000000001, 59.00000000000047, 37.700000000000266, 15.800000000000004, -50.19999999999993, -4.099999999999689, 1.2000000000001931, 88.79999999999866, 30.50000000000016, 46.0000000000004, 42.70000000000034, 17.199999999999992, 33.2000000000002, -127.40000000000083, -20.499999999999517, -64.50000000000028, 61.50000000000027, 28.400000000000347, 54.90000000000042, 30.100000000000147, -19.599999999999824, 28.10000000000024, 38.400000000000276, 59.4000000000005, 34.200000000000216, 66.60000000000024, 67.20000000000024, -16.099999999999945, 32.30000000000018, 42.30000000000033, 17.699999999999932, 20.19999999999997, 6.700000000000136, 6.699999999999926, 31.400000000000304, 26.80000000000009, -97.50000000000117, 14.700000000000022, -31.199999999999548, -39.799999999999706, 3.600000000000202, 118.69999999999989, 97.80000000000003, 32.700000000000195, 151.09999999999928, 52.60000000000031, 40.0000000000003, 35.90000000000024, 37.80000000000027, 28.50000000000012, -13.500000000000123, 35.600000000000236, 109.79999999999899, 63.40000000000051, 71.49999999999979, 31.200000000000163, 21.200000000000035, 53.50000000000047, 68.70000000000014, 38.80000000000028, 50.50000000000045, -7.500000000000025, -41.59999999999954, 16.100000000000147, 3.6000000000001204], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [16.69999999999997, 13.699999999999966, 20.000000000000014, -59.800000000000566, 23.600000000000065, 20.900000000000027, 20.000000000000014, 11.599999999999964, 15.799999999999963, 1.0999999999999865, 24.500000000000092, 20.000000000000014, -173.2000000000004, 15.799999999999963, -181.2000000000006, 9.499999999999982, 25.700000000000113, 11.600000000000005, 20.000000000000014, -15.699999999999747, 7.399999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, -23.20000000000025, 20.000000000000014, 17.899999999999984, 20.000000000000014, -19.899999999999743, 20.000000000000014, -103.90000000000032, -166.90000000000006, 24.200000000000077, 54.50000000000015, -5.1999999999999265, 20.000000000000014, 36.200000000000244, 17.899999999999988, 15.799999999999963, -3.099999999999958, 11.599999999999964, 9.499999999999964, 7.399999999999965, 9.49999999999997, 13.699999999999964, 7.399999999999965, 20.000000000000014, -3.099999999999965, 9.499999999999964, 21.800000000000047, -51.399999999999906, -194.20000000000056, -51.3999999999999, -166.9000000000002, -5.499999999999925, 20.000000000000014, 20.000000000000014, -114.40000000000057, -74.49999999999989, -106.00000000000017, 20.000000000000014, -51.399999999999764, 13.69999999999997, 20.000000000000014, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 1.699999999999971, 17.899999999999988, 19.40000000000001, 6.1999999999999655, 8.299999999999965, -11.499999999999819, 51.50000000000023, 20.000000000000014, 13.699999999999964, -9.399999999999855, 3.1999999999999615, -149.20000000000016, -85.00000000000014, -9.399999999999855, -15.699999999999747, 15.799999999999963, -55.60000000000031, 20.000000000000014, 60.80000000000018, 20.000000000000014, -11.499999999999819, 20.000000000000014, 23.000000000000057, 20.000000000000014, 22.700000000000053, 13.699999999999964, -11.499999999999819, 17.899999999999988, 5.299999999999965, -116.50000000000077, -130.90000000000043, -78.70000000000043, 3.1999999999999615, -106.00000000000011, -53.49999999999978, -53.50000000000004, 29.0, 39.80000000000019, -51.399999999999764, 58.400000000000205, -32.49999999999975, 20.000000000000014, 1.0999999999999865, 30.20000000000019, -122.80000000000027, -27.099999999999852, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 15.799999999999963, 41.60000000000025, 20.000000000000014, 3.1999999999999615, 2.299999999999982, 5.299999999999965, 20.000000000000014, 36.20000000000023, -141.70000000000036, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 23.600000000000065, -36.699999999999754, 7.399999999999965, 7.399999999999965, -5.19999999999993, -13.599999999999783, -3.699999999999962, 20.000000000000014, -49.29999999999989, -46.299999999999855, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -94.30000000000054, -89.20000000000063, -5.1999999999999265, -3.099999999999958, -27.399999999999764, -80.80000000000086, -15.699999999999775, -255.10000000000002, -26.199999999999747, -5.1999999999999265, 94.69999999999999, -15.999999999999774, -47.19999999999986, 110.00000000000009, 7.0999999999999694, 11.599999999999964, 30.80000000000011, 71.2999999999999, 32.60000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -11.499999999999819, -148.30000000000032, -26.19999999999977, 17.899999999999988, 13.699999999999964, 84.49999999999955, 5.299999999999965, 43.40000000000025, 20.000000000000014, 39.50000000000013, 20.000000000000014, 7.399999999999965, 15.799999999999963, -5.1999999999999265, -4.599999999999971, 24.500000000000092, 20.000000000000014, -7.299999999999891, 53.00000000000023, 15.799999999999963, 20.000000000000014, 3.799999999999969, 34.70000000000022, 20.000000000000014, -137.50000000000026, -111.40000000000067, -5.1999999999999265, 8.299999999999972, -26.200000000000003, -86.20000000000078, 15.799999999999963], "policy_predator_policy_reward": [3.0, 2.0, 38.0, 32.0, 3.0, 3.0, 4.0, 0.0, 2.0, 9.0, 9.0, 4.0, 92.0, 2.0, 5.0, 101.0, 6.0, 6.0, 17.0, 6.0, 6.0, 5.0, 1.0, 5.0, 39.0, 33.0, 4.0, 0.0, 8.0, 19.0, 140.0, 6.0, 1.0, 17.0, 7.0, 12.0, 3.0, 1.0, 3.0, 11.0, 5.0, 4.0, 7.0, 3.0, 6.0, 5.0, 6.0, 11.0, 5.0, 2.0, 10.0, 116.0, 120.0, 0.0, 13.0, 10.0, 64.0, 0.0, 86.0, 0.0, 34.0, 0.0, 0.0, 3.0, 5.0, 0.0, 17.0, 1.0, 5.0, 0.0, 7.0, 1.0, 4.0, 15.0, 1.0, 3.0, 8.0, 14.0, 88.0, 96.0, 4.0, 17.0, 32.0, 9.0, 0.0, 8.0, 15.0, 7.0, 1.0, 2.0, 0.0, 0.0, 0.0, 15.0, 7.0, 3.0, 118.0, 2.0, 8.0, 47.0, 95.0, 0.0, 47.0, 39.0, 34.0, 6.0, 4.0, 25.0, 0.0, 9.0, 5.0, 68.0, 25.0, 27.0, 5.0, 6.0, 0.0, 2.0, 3.0, 8.0, 31.0, 28.0, 5.0, 6.0, 50.0, 64.0, 0.0, 7.0, 3.0, 2.0, 25.0, 22.0, 12.0, 6.0, 2.0, 22.0, 31.0, 5.0, 50.0, 14.0, 0.0, 12.0, 6.0, 80.0, 13.0, 10.0, 29.0, 48.0, 113.0, 118.0, 22.0, 13.0, 16.0, 24.0, 32.0, 3.0, 14.0, 0.0, 15.0, 34.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 2.0, 15.0, 5.0, 71.0, 90.0, 1.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 7.0, 2.0, 6.0, 12.0, 19.0, 9.0, 0.0, 9.0, 14.0, 1.0, 2.0, 0.0, 12.0, 56.0, 54.0, 17.0, 58.0, 10.0, 24.0, 53.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8690816293460532, "mean_inference_ms": 2.2482145623606837, "mean_action_processing_ms": 0.3552241834083233, "mean_env_wait_ms": 0.2866129122963925, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006764769554138184, "StateBufferConnector_ms": 0.0035032033920288086, "ViewRequirementAgentConnector_ms": 0.14039397239685059}, "num_episodes": 18, "episode_return_max": 151.09999999999928, "episode_return_min": -127.40000000000083, "episode_return_mean": 21.710000000000118, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.386267404928, "num_env_steps_trained_throughput_per_sec": 355.386267404928, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 11765.383, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11765.331, "sample_time_ms": 1797.608, "learn_time_ms": 9943.185, "learn_throughput": 402.286, "synch_weights_time_ms": 23.036}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "f0d88_00000", "date": "2024-08-14_11-05-26", "timestamp": 1723647926, "time_this_iter_s": 11.342948198318481, "time_total_s": 1142.3003070354462, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac0c8af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1142.3003070354462, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 45.7625, "ram_util_percent": 82.97500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8966161954970586, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.3110860805032116, "policy_loss": -0.0324215109418171, "vf_loss": 2.3265673179475086, "vf_explained_var": -0.12843191374546636, "kl": 0.011154093764259049, "entropy": 1.2866517002620395, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9101817373245482, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 2.3819409378621943, "policy_loss": -0.010442587259476856, "vf_loss": 2.383258798513463, "vf_explained_var": 0.26495394277824924, "kl": 0.010680964041916367, "entropy": 0.7705831235994107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 151.09999999999928, "episode_reward_min": -127.40000000000083, "episode_reward_mean": 18.467000000000095, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.10000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 110.00000000000009, "predator_policy": 130.0}, "policy_reward_mean": {"prey_policy": -11.801500000000017, "predator_policy": 21.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.10000000000018, 33.90000000000021, 38.30000000000027, -119.59999999999997, -98.30000000000007, 37.50000000000026, -30.399999999999665, -94.50000000000033, 2.599999999999953, 36.700000000000244, 34.50000000000022, 22.90000000000002, 42.30000000000033, 22.50000000000001, 59.00000000000047, 37.700000000000266, 15.800000000000004, -50.19999999999993, -4.099999999999689, 1.2000000000001931, 88.79999999999866, 30.50000000000016, 46.0000000000004, 42.70000000000034, 17.199999999999992, 33.2000000000002, -127.40000000000083, -20.499999999999517, -64.50000000000028, 61.50000000000027, 28.400000000000347, 54.90000000000042, 30.100000000000147, -19.599999999999824, 28.10000000000024, 38.400000000000276, 59.4000000000005, 34.200000000000216, 66.60000000000024, 67.20000000000024, -16.099999999999945, 32.30000000000018, 42.30000000000033, 17.699999999999932, 20.19999999999997, 6.700000000000136, 6.699999999999926, 31.400000000000304, 26.80000000000009, -97.50000000000117, 14.700000000000022, -31.199999999999548, -39.799999999999706, 3.600000000000202, 118.69999999999989, 97.80000000000003, 32.700000000000195, 151.09999999999928, 52.60000000000031, 40.0000000000003, 35.90000000000024, 37.80000000000027, 28.50000000000012, -13.500000000000123, 35.600000000000236, 109.79999999999899, 63.40000000000051, 71.49999999999979, 31.200000000000163, 21.200000000000035, 53.50000000000047, 68.70000000000014, 38.80000000000028, 50.50000000000045, -7.500000000000025, -41.59999999999954, 16.100000000000147, 3.6000000000001204, -55.39999999999989, -3.1000000000000845, 14.999999999999957, 29.90000000000015, -15.499999999999549, 42.60000000000037, 34.100000000000215, -53.70000000000113, -77.7000000000005, 25.90000000000007, -21.599999999999575, 48.10000000000006, 48.90000000000045, 17.399999999999952, 58.20000000000042, 6.399999999999978, 81.49999999999916, 21.799999999999997, -49.09999999999993, 29.000000000000128, 45.60000000000039, -10.899999999999636], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, 7.399999999999965, 20.000000000000014, -3.099999999999965, 9.499999999999964, 21.800000000000047, -51.399999999999906, -194.20000000000056, -51.3999999999999, -166.9000000000002, -5.499999999999925, 20.000000000000014, 20.000000000000014, -114.40000000000057, -74.49999999999989, -106.00000000000017, 20.000000000000014, -51.399999999999764, 13.69999999999997, 20.000000000000014, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 1.699999999999971, 17.899999999999988, 19.40000000000001, 6.1999999999999655, 8.299999999999965, -11.499999999999819, 51.50000000000023, 20.000000000000014, 13.699999999999964, -9.399999999999855, 3.1999999999999615, -149.20000000000016, -85.00000000000014, -9.399999999999855, -15.699999999999747, 15.799999999999963, -55.60000000000031, 20.000000000000014, 60.80000000000018, 20.000000000000014, -11.499999999999819, 20.000000000000014, 23.000000000000057, 20.000000000000014, 22.700000000000053, 13.699999999999964, -11.499999999999819, 17.899999999999988, 5.299999999999965, -116.50000000000077, -130.90000000000043, -78.70000000000043, 3.1999999999999615, -106.00000000000011, -53.49999999999978, -53.50000000000004, 29.0, 39.80000000000019, -51.399999999999764, 58.400000000000205, -32.49999999999975, 20.000000000000014, 1.0999999999999865, 30.20000000000019, -122.80000000000027, -27.099999999999852, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 15.799999999999963, 41.60000000000025, 20.000000000000014, 3.1999999999999615, 2.299999999999982, 5.299999999999965, 20.000000000000014, 36.20000000000023, -141.70000000000036, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 23.600000000000065, -36.699999999999754, 7.399999999999965, 7.399999999999965, -5.19999999999993, -13.599999999999783, -3.699999999999962, 20.000000000000014, -49.29999999999989, -46.299999999999855, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -94.30000000000054, -89.20000000000063, -5.1999999999999265, -3.099999999999958, -27.399999999999764, -80.80000000000086, -15.699999999999775, -255.10000000000002, -26.199999999999747, -5.1999999999999265, 94.69999999999999, -15.999999999999774, -47.19999999999986, 110.00000000000009, 7.0999999999999694, 11.599999999999964, 30.80000000000011, 71.2999999999999, 32.60000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -11.499999999999819, -148.30000000000032, -26.19999999999977, 17.899999999999988, 13.699999999999964, 84.49999999999955, 5.299999999999965, 43.40000000000025, 20.000000000000014, 39.50000000000013, 20.000000000000014, 7.399999999999965, 15.799999999999963, -5.1999999999999265, -4.599999999999971, 24.500000000000092, 20.000000000000014, -7.299999999999891, 53.00000000000023, 15.799999999999963, 20.000000000000014, 3.799999999999969, 34.70000000000022, 20.000000000000014, -137.50000000000026, -111.40000000000067, -5.1999999999999265, 8.299999999999972, -26.200000000000003, -86.20000000000078, 15.799999999999963, -210.4, 20.000000000000014, 20.90000000000003, -63.99999999999982, -7.8999999999998884, -3.0999999999999934, 20.000000000000014, -33.09999999999985, -91.30000000000084, -26.199999999999747, 10.09999999999998, 9.499999999999964, 1.0999999999999865, 20.000000000000014, -59.80000000000051, -40.89999999999976, -137.50000000000034, -47.19999999999978, 1.0999999999999865, 15.799999999999963, -68.20000000000022, -9.399999999999855, -9.99999999999988, 4.099999999999973, 23.900000000000077, 20.000000000000014, -34.59999999999975, 20.000000000000014, -14.799999999999793, 47.00000000000023, -237.40000000000043, 15.799999999999963, 87.49999999999929, -42.999999999999766, 5.299999999999965, 9.499999999999964, -91.30000000000001, -35.79999999999998, -0.9999999999999846, 20.000000000000014, 28.400000000000155, 3.1999999999999615, -82.9000000000008, 20.000000000000014], "policy_predator_policy_reward": [6.0, 5.0, 6.0, 11.0, 5.0, 2.0, 10.0, 116.0, 120.0, 0.0, 13.0, 10.0, 64.0, 0.0, 86.0, 0.0, 34.0, 0.0, 0.0, 3.0, 5.0, 0.0, 17.0, 1.0, 5.0, 0.0, 7.0, 1.0, 4.0, 15.0, 1.0, 3.0, 8.0, 14.0, 88.0, 96.0, 4.0, 17.0, 32.0, 9.0, 0.0, 8.0, 15.0, 7.0, 1.0, 2.0, 0.0, 0.0, 0.0, 15.0, 7.0, 3.0, 118.0, 2.0, 8.0, 47.0, 95.0, 0.0, 47.0, 39.0, 34.0, 6.0, 4.0, 25.0, 0.0, 9.0, 5.0, 68.0, 25.0, 27.0, 5.0, 6.0, 0.0, 2.0, 3.0, 8.0, 31.0, 28.0, 5.0, 6.0, 50.0, 64.0, 0.0, 7.0, 3.0, 2.0, 25.0, 22.0, 12.0, 6.0, 2.0, 22.0, 31.0, 5.0, 50.0, 14.0, 0.0, 12.0, 6.0, 80.0, 13.0, 10.0, 29.0, 48.0, 113.0, 118.0, 22.0, 13.0, 16.0, 24.0, 32.0, 3.0, 14.0, 0.0, 15.0, 34.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 2.0, 15.0, 5.0, 71.0, 90.0, 1.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 7.0, 2.0, 6.0, 12.0, 19.0, 9.0, 0.0, 9.0, 14.0, 1.0, 2.0, 0.0, 12.0, 56.0, 54.0, 17.0, 58.0, 10.0, 24.0, 53.0, 21.0, 5.0, 130.0, 0.0, 40.0, 15.0, 11.0, 26.0, 17.0, 51.0, 51.0, 18.0, 5.0, 4.0, 9.0, 4.0, 43.0, 103.0, 4.0, 0.0, 9.0, 42.0, 14.0, 18.0, 36.0, 5.0, 0.0, 26.0, 6.0, 23.0, 3.0, 109.0, 119.0, 27.0, 10.0, 7.0, 0.0, 15.0, 63.0, 0.0, 10.0, 4.0, 10.0, 0.0, 52.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8675916224886191, "mean_inference_ms": 2.244488839005864, "mean_action_processing_ms": 0.3547613196738274, "mean_env_wait_ms": 0.286153255206577, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007426261901855469, "StateBufferConnector_ms": 0.0034672021865844727, "ViewRequirementAgentConnector_ms": 0.1272139549255371}, "num_episodes": 22, "episode_return_max": 151.09999999999928, "episode_return_min": -127.40000000000083, "episode_return_mean": 18.467000000000095, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.4539984337774, "num_env_steps_trained_throughput_per_sec": 352.4539984337774, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 11722.101, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11722.043, "sample_time_ms": 1719.942, "learn_time_ms": 9977.812, "learn_throughput": 400.89, "synch_weights_time_ms": 22.847}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "f0d88_00000", "date": "2024-08-14_11-05-37", "timestamp": 1723647937, "time_this_iter_s": 11.384297370910645, "time_total_s": 1153.6846044063568, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4f73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1153.6846044063568, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 45.04375, "ram_util_percent": 82.78125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.940436802433912, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.3562177356904144, "policy_loss": -0.022914727800156152, "vf_loss": 2.361409974224353, "vf_explained_var": 0.05361097142809913, "kl": 0.011669129561805517, "entropy": 1.3051151904479537, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2090517678904154, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 2.3717159903869427, "policy_loss": -0.002570215518285752, "vf_loss": 2.3646125972586334, "vf_explained_var": 0.5531709436701719, "kl": 0.011323484081861223, "entropy": 0.7601422431607726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 151.09999999999928, "episode_reward_min": -255.9999999999998, "episode_reward_mean": 17.963000000000104, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -261.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 110.00000000000009, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -11.358500000000017, "predator_policy": 20.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.099999999999689, 1.2000000000001931, 88.79999999999866, 30.50000000000016, 46.0000000000004, 42.70000000000034, 17.199999999999992, 33.2000000000002, -127.40000000000083, -20.499999999999517, -64.50000000000028, 61.50000000000027, 28.400000000000347, 54.90000000000042, 30.100000000000147, -19.599999999999824, 28.10000000000024, 38.400000000000276, 59.4000000000005, 34.200000000000216, 66.60000000000024, 67.20000000000024, -16.099999999999945, 32.30000000000018, 42.30000000000033, 17.699999999999932, 20.19999999999997, 6.700000000000136, 6.699999999999926, 31.400000000000304, 26.80000000000009, -97.50000000000117, 14.700000000000022, -31.199999999999548, -39.799999999999706, 3.600000000000202, 118.69999999999989, 97.80000000000003, 32.700000000000195, 151.09999999999928, 52.60000000000031, 40.0000000000003, 35.90000000000024, 37.80000000000027, 28.50000000000012, -13.500000000000123, 35.600000000000236, 109.79999999999899, 63.40000000000051, 71.49999999999979, 31.200000000000163, 21.200000000000035, 53.50000000000047, 68.70000000000014, 38.80000000000028, 50.50000000000045, -7.500000000000025, -41.59999999999954, 16.100000000000147, 3.6000000000001204, -55.39999999999989, -3.1000000000000845, 14.999999999999957, 29.90000000000015, -15.499999999999549, 42.60000000000037, 34.100000000000215, -53.70000000000113, -77.7000000000005, 25.90000000000007, -21.599999999999575, 48.10000000000006, 48.90000000000045, 17.399999999999952, 58.20000000000042, 6.399999999999978, 81.49999999999916, 21.799999999999997, -49.09999999999993, 29.000000000000128, 45.60000000000039, -10.899999999999636, 37.700000000000266, 5.900000000000125, 37.80000000000027, -51.299999999999955, -255.9999999999998, -5.0000000000000995, -61.099999999999866, -14.199999999999525, -13.899999999999615, 34.50000000000022, 33.400000000000205, 49.800000000000466, 37.80000000000027, 39.9000000000003, -11.400000000000077, 38.90000000000028, 36.60000000000025, 33.0000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.399999999999855, -15.699999999999747, 15.799999999999963, -55.60000000000031, 20.000000000000014, 60.80000000000018, 20.000000000000014, -11.499999999999819, 20.000000000000014, 23.000000000000057, 20.000000000000014, 22.700000000000053, 13.699999999999964, -11.499999999999819, 17.899999999999988, 5.299999999999965, -116.50000000000077, -130.90000000000043, -78.70000000000043, 3.1999999999999615, -106.00000000000011, -53.49999999999978, -53.50000000000004, 29.0, 39.80000000000019, -51.399999999999764, 58.400000000000205, -32.49999999999975, 20.000000000000014, 1.0999999999999865, 30.20000000000019, -122.80000000000027, -27.099999999999852, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 15.799999999999963, 41.60000000000025, 20.000000000000014, 3.1999999999999615, 2.299999999999982, 5.299999999999965, 20.000000000000014, 36.20000000000023, -141.70000000000036, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 23.600000000000065, -36.699999999999754, 7.399999999999965, 7.399999999999965, -5.19999999999993, -13.599999999999783, -3.699999999999962, 20.000000000000014, -49.29999999999989, -46.299999999999855, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -94.30000000000054, -89.20000000000063, -5.1999999999999265, -3.099999999999958, -27.399999999999764, -80.80000000000086, -15.699999999999775, -255.10000000000002, -26.199999999999747, -5.1999999999999265, 94.69999999999999, -15.999999999999774, -47.19999999999986, 110.00000000000009, 7.0999999999999694, 11.599999999999964, 30.80000000000011, 71.2999999999999, 32.60000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -11.499999999999819, -148.30000000000032, -26.19999999999977, 17.899999999999988, 13.699999999999964, 84.49999999999955, 5.299999999999965, 43.40000000000025, 20.000000000000014, 39.50000000000013, 20.000000000000014, 7.399999999999965, 15.799999999999963, -5.1999999999999265, -4.599999999999971, 24.500000000000092, 20.000000000000014, -7.299999999999891, 53.00000000000023, 15.799999999999963, 20.000000000000014, 3.799999999999969, 34.70000000000022, 20.000000000000014, -137.50000000000026, -111.40000000000067, -5.1999999999999265, 8.299999999999972, -26.200000000000003, -86.20000000000078, 15.799999999999963, -210.4, 20.000000000000014, 20.90000000000003, -63.99999999999982, -7.8999999999998884, -3.0999999999999934, 20.000000000000014, -33.09999999999985, -91.30000000000084, -26.199999999999747, 10.09999999999998, 9.499999999999964, 1.0999999999999865, 20.000000000000014, -59.80000000000051, -40.89999999999976, -137.50000000000034, -47.19999999999978, 1.0999999999999865, 15.799999999999963, -68.20000000000022, -9.399999999999855, -9.99999999999988, 4.099999999999973, 23.900000000000077, 20.000000000000014, -34.59999999999975, 20.000000000000014, -14.799999999999793, 47.00000000000023, -237.40000000000043, 15.799999999999963, 87.49999999999929, -42.999999999999766, 5.299999999999965, 9.499999999999964, -91.30000000000001, -35.79999999999998, -0.9999999999999846, 20.000000000000014, 28.400000000000155, 3.1999999999999615, -82.9000000000008, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -45.09999999999976, 20.000000000000014, 15.799999999999963, -152.2, 17.899999999999988, -261.4000000000001, -147.6000000000001, 20.000000000000014, -85.00000000000054, -74.50000000000014, -76.60000000000035, -36.699999999999754, -11.499999999999819, -78.70000000000081, 15.79999999999996, 11.599999999999964, 17.899999999999988, 7.399999999999965, 20.000000000000014, 35.30000000000026, 9.499999999999964, -3.099999999999958, 29.90000000000018, 17.899999999999988, 20.000000000000014, 23.600000000000065, -85.00000000000026, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, 21.80000000000004, -14.799999999999764], "policy_predator_policy_reward": [4.0, 17.0, 32.0, 9.0, 0.0, 8.0, 15.0, 7.0, 1.0, 2.0, 0.0, 0.0, 0.0, 15.0, 7.0, 3.0, 118.0, 2.0, 8.0, 47.0, 95.0, 0.0, 47.0, 39.0, 34.0, 6.0, 4.0, 25.0, 0.0, 9.0, 5.0, 68.0, 25.0, 27.0, 5.0, 6.0, 0.0, 2.0, 3.0, 8.0, 31.0, 28.0, 5.0, 6.0, 50.0, 64.0, 0.0, 7.0, 3.0, 2.0, 25.0, 22.0, 12.0, 6.0, 2.0, 22.0, 31.0, 5.0, 50.0, 14.0, 0.0, 12.0, 6.0, 80.0, 13.0, 10.0, 29.0, 48.0, 113.0, 118.0, 22.0, 13.0, 16.0, 24.0, 32.0, 3.0, 14.0, 0.0, 15.0, 34.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 2.0, 15.0, 5.0, 71.0, 90.0, 1.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 7.0, 2.0, 6.0, 12.0, 19.0, 9.0, 0.0, 9.0, 14.0, 1.0, 2.0, 0.0, 12.0, 56.0, 54.0, 17.0, 58.0, 10.0, 24.0, 53.0, 21.0, 5.0, 130.0, 0.0, 40.0, 15.0, 11.0, 26.0, 17.0, 51.0, 51.0, 18.0, 5.0, 4.0, 9.0, 4.0, 43.0, 103.0, 4.0, 0.0, 9.0, 42.0, 14.0, 18.0, 36.0, 5.0, 0.0, 26.0, 6.0, 23.0, 3.0, 109.0, 119.0, 27.0, 10.0, 7.0, 0.0, 15.0, 63.0, 0.0, 10.0, 4.0, 10.0, 0.0, 52.0, 1.0, 3.0, 10.0, 21.0, 0.0, 2.0, 82.0, 1.0, 152.0, 1.0, 10.0, 50.0, 60.0, 30.0, 9.0, 25.0, 37.0, 12.0, 4.0, 1.0, 6.0, 0.0, 5.0, 0.0, 11.0, 0.0, 1.0, 1.0, 0.0, 50.0, 1.0, 0.0, 1.0, 4.0, 9.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8658908495096445, "mean_inference_ms": 2.2402905097548818, "mean_action_processing_ms": 0.35414926099173577, "mean_env_wait_ms": 0.28560829718024555, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007959246635437012, "StateBufferConnector_ms": 0.0034694671630859375, "ViewRequirementAgentConnector_ms": 0.1251087188720703}, "num_episodes": 18, "episode_return_max": 151.09999999999928, "episode_return_min": -255.9999999999998, "episode_return_mean": 17.963000000000104, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.6509081380018, "num_env_steps_trained_throughput_per_sec": 350.6509081380018, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 11647.122, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11647.063, "sample_time_ms": 1626.442, "learn_time_ms": 9998.434, "learn_throughput": 400.063, "synch_weights_time_ms": 20.657}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "f0d88_00000", "date": "2024-08-14_11-05-49", "timestamp": 1723647949, "time_this_iter_s": 11.449703216552734, "time_total_s": 1165.1343076229095, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4ebb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1165.1343076229095, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 46.8625, "ram_util_percent": 82.8875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8923709161382503, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.122259171866866, "policy_loss": -0.02768606641637802, "vf_loss": 2.127789666539147, "vf_explained_var": -0.07872925962089862, "kl": 0.01458803110821492, "entropy": 1.2881775639675281, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0877763202266086, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 2.2632950683119435, "policy_loss": -0.010534730157938111, "vf_loss": 2.263423856604036, "vf_explained_var": 0.3741545254906649, "kl": 0.012180708278704577, "entropy": 0.7956738928323069, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 151.09999999999928, "episode_reward_min": -255.9999999999998, "episode_reward_mean": 16.511000000000074, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -261.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 110.00000000000009, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -12.799500000000018, "predator_policy": 21.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, 42.30000000000033, 17.699999999999932, 20.19999999999997, 6.700000000000136, 6.699999999999926, 31.400000000000304, 26.80000000000009, -97.50000000000117, 14.700000000000022, -31.199999999999548, -39.799999999999706, 3.600000000000202, 118.69999999999989, 97.80000000000003, 32.700000000000195, 151.09999999999928, 52.60000000000031, 40.0000000000003, 35.90000000000024, 37.80000000000027, 28.50000000000012, -13.500000000000123, 35.600000000000236, 109.79999999999899, 63.40000000000051, 71.49999999999979, 31.200000000000163, 21.200000000000035, 53.50000000000047, 68.70000000000014, 38.80000000000028, 50.50000000000045, -7.500000000000025, -41.59999999999954, 16.100000000000147, 3.6000000000001204, -55.39999999999989, -3.1000000000000845, 14.999999999999957, 29.90000000000015, -15.499999999999549, 42.60000000000037, 34.100000000000215, -53.70000000000113, -77.7000000000005, 25.90000000000007, -21.599999999999575, 48.10000000000006, 48.90000000000045, 17.399999999999952, 58.20000000000042, 6.399999999999978, 81.49999999999916, 21.799999999999997, -49.09999999999993, 29.000000000000128, 45.60000000000039, -10.899999999999636, 37.700000000000266, 5.900000000000125, 37.80000000000027, -51.299999999999955, -255.9999999999998, -5.0000000000000995, -61.099999999999866, -14.199999999999525, -13.899999999999615, 34.50000000000022, 33.400000000000205, 49.800000000000466, 37.80000000000027, 39.9000000000003, -11.400000000000077, 38.90000000000028, 36.60000000000025, 33.0000000000002, 81.49999999999918, 13.599999999999902, -26.29999999999977, 81.99999999999893, -104.00000000000118, -30.099999999999625, 40.0000000000003, 33.10000000000019, 38.700000000000294, -46.399999999999665, 4.200000000000124, -3.1000000000000245, 13.199999999999957, 63.90000000000013, -89.90000000000018, 20.60000000000006, 33.4000000000002, 49.90000000000045, 68.39999999999995, 35.00000000000023, 19.09999999999999, 8.10000000000006, 26.100000000000072], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, 20.000000000000014, 13.699999999999964, 23.600000000000065, -36.699999999999754, 7.399999999999965, 7.399999999999965, -5.19999999999993, -13.599999999999783, -3.699999999999962, 20.000000000000014, -49.29999999999989, -46.299999999999855, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -94.30000000000054, -89.20000000000063, -5.1999999999999265, -3.099999999999958, -27.399999999999764, -80.80000000000086, -15.699999999999775, -255.10000000000002, -26.199999999999747, -5.1999999999999265, 94.69999999999999, -15.999999999999774, -47.19999999999986, 110.00000000000009, 7.0999999999999694, 11.599999999999964, 30.80000000000011, 71.2999999999999, 32.60000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -11.499999999999819, -148.30000000000032, -26.19999999999977, 17.899999999999988, 13.699999999999964, 84.49999999999955, 5.299999999999965, 43.40000000000025, 20.000000000000014, 39.50000000000013, 20.000000000000014, 7.399999999999965, 15.799999999999963, -5.1999999999999265, -4.599999999999971, 24.500000000000092, 20.000000000000014, -7.299999999999891, 53.00000000000023, 15.799999999999963, 20.000000000000014, 3.799999999999969, 34.70000000000022, 20.000000000000014, -137.50000000000026, -111.40000000000067, -5.1999999999999265, 8.299999999999972, -26.200000000000003, -86.20000000000078, 15.799999999999963, -210.4, 20.000000000000014, 20.90000000000003, -63.99999999999982, -7.8999999999998884, -3.0999999999999934, 20.000000000000014, -33.09999999999985, -91.30000000000084, -26.199999999999747, 10.09999999999998, 9.499999999999964, 1.0999999999999865, 20.000000000000014, -59.80000000000051, -40.89999999999976, -137.50000000000034, -47.19999999999978, 1.0999999999999865, 15.799999999999963, -68.20000000000022, -9.399999999999855, -9.99999999999988, 4.099999999999973, 23.900000000000077, 20.000000000000014, -34.59999999999975, 20.000000000000014, -14.799999999999793, 47.00000000000023, -237.40000000000043, 15.799999999999963, 87.49999999999929, -42.999999999999766, 5.299999999999965, 9.499999999999964, -91.30000000000001, -35.79999999999998, -0.9999999999999846, 20.000000000000014, 28.400000000000155, 3.1999999999999615, -82.9000000000008, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -45.09999999999976, 20.000000000000014, 15.799999999999963, -152.2, 17.899999999999988, -261.4000000000001, -147.6000000000001, 20.000000000000014, -85.00000000000054, -74.50000000000014, -76.60000000000035, -36.699999999999754, -11.499999999999819, -78.70000000000081, 15.79999999999996, 11.599999999999964, 17.899999999999988, 7.399999999999965, 20.000000000000014, 35.30000000000026, 9.499999999999964, -3.099999999999958, 29.90000000000018, 17.899999999999988, 20.000000000000014, 23.600000000000065, -85.00000000000026, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, 21.80000000000004, -14.799999999999764, 1.999999999999991, 66.50000000000001, 11.599999999999966, -21.9999999999998, -30.399999999999885, -61.9, -39.09999999999989, 37.10000000000026, -234.10000000000045, -4.899999999999853, -74.20000000000078, -25.899999999999814, 20.000000000000014, 20.000000000000014, 15.799999999999963, 5.299999999999965, 13.09999999999997, -12.399999999999844, -17.199999999999815, -131.20000000000041, -62.80000000000072, 20.000000000000014, -24.099999999999998, -22.00000000000003, -32.79999999999976, 20.000000000000014, -24.999999999999943, 29.90000000000018, -9.399999999999855, -208.50000000000034, -42.99999999999976, 11.599999999999975, 13.699999999999964, 13.699999999999964, -6.099999999999952, 20.000000000000014, 9.499999999999964, 38.90000000000017, 20.000000000000014, -1.0000000000000275, 11.599999999999964, -11.499999999999819, -34.59999999999978, 13.699999999999966, 9.499999999999964, 11.599999999999964], "policy_predator_policy_reward": [0.0, 7.0, 3.0, 2.0, 25.0, 22.0, 12.0, 6.0, 2.0, 22.0, 31.0, 5.0, 50.0, 14.0, 0.0, 12.0, 6.0, 80.0, 13.0, 10.0, 29.0, 48.0, 113.0, 118.0, 22.0, 13.0, 16.0, 24.0, 32.0, 3.0, 14.0, 0.0, 15.0, 34.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 2.0, 15.0, 5.0, 71.0, 90.0, 1.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 7.0, 2.0, 6.0, 12.0, 19.0, 9.0, 0.0, 9.0, 14.0, 1.0, 2.0, 0.0, 12.0, 56.0, 54.0, 17.0, 58.0, 10.0, 24.0, 53.0, 21.0, 5.0, 130.0, 0.0, 40.0, 15.0, 11.0, 26.0, 17.0, 51.0, 51.0, 18.0, 5.0, 4.0, 9.0, 4.0, 43.0, 103.0, 4.0, 0.0, 9.0, 42.0, 14.0, 18.0, 36.0, 5.0, 0.0, 26.0, 6.0, 23.0, 3.0, 109.0, 119.0, 27.0, 10.0, 7.0, 0.0, 15.0, 63.0, 0.0, 10.0, 4.0, 10.0, 0.0, 52.0, 1.0, 3.0, 10.0, 21.0, 0.0, 2.0, 82.0, 1.0, 152.0, 1.0, 10.0, 50.0, 60.0, 30.0, 9.0, 25.0, 37.0, 12.0, 4.0, 1.0, 6.0, 0.0, 5.0, 0.0, 11.0, 0.0, 1.0, 1.0, 0.0, 50.0, 1.0, 0.0, 1.0, 4.0, 9.0, 17.0, 4.0, 9.0, 20.0, 4.0, 7.0, 59.0, 54.0, 30.0, 121.0, 14.0, 11.0, 59.0, 0.0, 0.0, 7.0, 5.0, 14.0, 24.0, 31.0, 71.0, 2.0, 45.0, 13.0, 30.0, 0.0, 26.0, 34.0, 25.0, 14.0, 114.0, 30.0, 22.0, 3.0, 3.0, 15.0, 21.0, 5.0, 15.0, 10.0, 6.0, 4.0, 15.0, 26.0, 3.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8632725333029692, "mean_inference_ms": 2.233540544734467, "mean_action_processing_ms": 0.35312510054663165, "mean_env_wait_ms": 0.2847888087962527, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007428646087646484, "StateBufferConnector_ms": 0.003398299217224121, "ViewRequirementAgentConnector_ms": 0.10423028469085693}, "num_episodes": 23, "episode_return_max": 151.09999999999928, "episode_return_min": -255.9999999999998, "episode_return_mean": 16.511000000000074, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.2105276381045, "num_env_steps_trained_throughput_per_sec": 354.2105276381045, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 11580.449, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11580.39, "sample_time_ms": 1544.631, "learn_time_ms": 10014.109, "learn_throughput": 399.436, "synch_weights_time_ms": 20.001}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "f0d88_00000", "date": "2024-08-14_11-06-00", "timestamp": 1723647960, "time_this_iter_s": 11.359591007232666, "time_total_s": 1176.4938986301422, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad66f5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1176.4938986301422, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 46.44117647058823, "ram_util_percent": 82.92941176470588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8010838224458947, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.5601475431805567, "policy_loss": -0.02236631717766936, "vf_loss": 2.564155493274568, "vf_explained_var": 0.007396653625700209, "kl": 0.012087811366325524, "entropy": 1.2804030466332006, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1428515200892453, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 2.320545705664095, "policy_loss": -0.009004985528293425, "vf_loss": 2.318244361498999, "vf_explained_var": 0.58550245184747, "kl": 0.01323465601525283, "entropy": 0.7209491784925814, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 109.79999999999899, "episode_reward_min": -255.9999999999998, "episode_reward_mean": 13.668000000000081, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.69999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 87.49999999999929, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -14.691000000000015, "predator_policy": 21.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 35.90000000000024, 37.80000000000027, 28.50000000000012, -13.500000000000123, 35.600000000000236, 109.79999999999899, 63.40000000000051, 71.49999999999979, 31.200000000000163, 21.200000000000035, 53.50000000000047, 68.70000000000014, 38.80000000000028, 50.50000000000045, -7.500000000000025, -41.59999999999954, 16.100000000000147, 3.6000000000001204, -55.39999999999989, -3.1000000000000845, 14.999999999999957, 29.90000000000015, -15.499999999999549, 42.60000000000037, 34.100000000000215, -53.70000000000113, -77.7000000000005, 25.90000000000007, -21.599999999999575, 48.10000000000006, 48.90000000000045, 17.399999999999952, 58.20000000000042, 6.399999999999978, 81.49999999999916, 21.799999999999997, -49.09999999999993, 29.000000000000128, 45.60000000000039, -10.899999999999636, 37.700000000000266, 5.900000000000125, 37.80000000000027, -51.299999999999955, -255.9999999999998, -5.0000000000000995, -61.099999999999866, -14.199999999999525, -13.899999999999615, 34.50000000000022, 33.400000000000205, 49.800000000000466, 37.80000000000027, 39.9000000000003, -11.400000000000077, 38.90000000000028, 36.60000000000025, 33.0000000000002, 81.49999999999918, 13.599999999999902, -26.29999999999977, 81.99999999999893, -104.00000000000118, -30.099999999999625, 40.0000000000003, 33.10000000000019, 38.700000000000294, -46.399999999999665, 4.200000000000124, -3.1000000000000245, 13.199999999999957, 63.90000000000013, -89.90000000000018, 20.60000000000006, 33.4000000000002, 49.90000000000045, 68.39999999999995, 35.00000000000023, 19.09999999999999, 8.10000000000006, 26.100000000000072, 37.80000000000027, -143.70000000000118, 17.999999999999996, -55.899999999999906, -6.600000000000041, -11.999999999999758, 30.800000000000175, 24.90000000000008, 64.30000000000038, 23.500000000000032, 37.600000000000264, 40.400000000000304, 74.19999999999968, 40.70000000000031, 36.80000000000025, 14.89999999999993, 16.800000000000075, -39.99999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -0.9999999999999846, 17.899999999999988, 20.000000000000014, 15.799999999999963, 20.000000000000014, -11.499999999999819, -148.30000000000032, -26.19999999999977, 17.899999999999988, 13.699999999999964, 84.49999999999955, 5.299999999999965, 43.40000000000025, 20.000000000000014, 39.50000000000013, 20.000000000000014, 7.399999999999965, 15.799999999999963, -5.1999999999999265, -4.599999999999971, 24.500000000000092, 20.000000000000014, -7.299999999999891, 53.00000000000023, 15.799999999999963, 20.000000000000014, 3.799999999999969, 34.70000000000022, 20.000000000000014, -137.50000000000026, -111.40000000000067, -5.1999999999999265, 8.299999999999972, -26.200000000000003, -86.20000000000078, 15.799999999999963, -210.4, 20.000000000000014, 20.90000000000003, -63.99999999999982, -7.8999999999998884, -3.0999999999999934, 20.000000000000014, -33.09999999999985, -91.30000000000084, -26.199999999999747, 10.09999999999998, 9.499999999999964, 1.0999999999999865, 20.000000000000014, -59.80000000000051, -40.89999999999976, -137.50000000000034, -47.19999999999978, 1.0999999999999865, 15.799999999999963, -68.20000000000022, -9.399999999999855, -9.99999999999988, 4.099999999999973, 23.900000000000077, 20.000000000000014, -34.59999999999975, 20.000000000000014, -14.799999999999793, 47.00000000000023, -237.40000000000043, 15.799999999999963, 87.49999999999929, -42.999999999999766, 5.299999999999965, 9.499999999999964, -91.30000000000001, -35.79999999999998, -0.9999999999999846, 20.000000000000014, 28.400000000000155, 3.1999999999999615, -82.9000000000008, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -45.09999999999976, 20.000000000000014, 15.799999999999963, -152.2, 17.899999999999988, -261.4000000000001, -147.6000000000001, 20.000000000000014, -85.00000000000054, -74.50000000000014, -76.60000000000035, -36.699999999999754, -11.499999999999819, -78.70000000000081, 15.79999999999996, 11.599999999999964, 17.899999999999988, 7.399999999999965, 20.000000000000014, 35.30000000000026, 9.499999999999964, -3.099999999999958, 29.90000000000018, 17.899999999999988, 20.000000000000014, 23.600000000000065, -85.00000000000026, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, 21.80000000000004, -14.799999999999764, 1.999999999999991, 66.50000000000001, 11.599999999999966, -21.9999999999998, -30.399999999999885, -61.9, -39.09999999999989, 37.10000000000026, -234.10000000000045, -4.899999999999853, -74.20000000000078, -25.899999999999814, 20.000000000000014, 20.000000000000014, 15.799999999999963, 5.299999999999965, 13.09999999999997, -12.399999999999844, -17.199999999999815, -131.20000000000041, -62.80000000000072, 20.000000000000014, -24.099999999999998, -22.00000000000003, -32.79999999999976, 20.000000000000014, -24.999999999999943, 29.90000000000018, -9.399999999999855, -208.50000000000034, -42.99999999999976, 11.599999999999975, 13.699999999999964, 13.699999999999964, -6.099999999999952, 20.000000000000014, 9.499999999999964, 38.90000000000017, 20.000000000000014, -1.0000000000000275, 11.599999999999964, -11.499999999999819, -34.59999999999978, 13.699999999999966, 9.499999999999964, 11.599999999999964, 20.000000000000014, 15.799999999999963, -181.60000000000042, -129.10000000000073, -11.499999999999819, 9.499999999999964, -288.69999999999993, 15.799999999999963, -97.59999999999991, 20.000000000000014, -40.899999999999864, -3.099999999999958, -47.19999999999976, 20.000000000000014, -38.799999999999756, 4.699999999999978, 22.40000000000009, 17.899999999999988, -11.499999999999819, 20.000000000000014, 11.599999999999964, 20.000000000000014, 13.699999999999964, 22.700000000000053, 1.0999999999999865, 64.1000000000002, 17.899999999999988, 21.80000000000004, 26.300000000000118, -32.499999999999766, -46.299999999999805, 15.199999999999962, -6.699999999999861, -11.500000000000025, 9.499999999999964, -137.50000000000006], "policy_predator_policy_reward": [0.0, 0.0, 9.0, 10.0, 0.0, 2.0, 15.0, 5.0, 71.0, 90.0, 1.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 7.0, 2.0, 6.0, 12.0, 19.0, 9.0, 0.0, 9.0, 14.0, 1.0, 2.0, 0.0, 12.0, 56.0, 54.0, 17.0, 58.0, 10.0, 24.0, 53.0, 21.0, 5.0, 130.0, 0.0, 40.0, 15.0, 11.0, 26.0, 17.0, 51.0, 51.0, 18.0, 5.0, 4.0, 9.0, 4.0, 43.0, 103.0, 4.0, 0.0, 9.0, 42.0, 14.0, 18.0, 36.0, 5.0, 0.0, 26.0, 6.0, 23.0, 3.0, 109.0, 119.0, 27.0, 10.0, 7.0, 0.0, 15.0, 63.0, 0.0, 10.0, 4.0, 10.0, 0.0, 52.0, 1.0, 3.0, 10.0, 21.0, 0.0, 2.0, 82.0, 1.0, 152.0, 1.0, 10.0, 50.0, 60.0, 30.0, 9.0, 25.0, 37.0, 12.0, 4.0, 1.0, 6.0, 0.0, 5.0, 0.0, 11.0, 0.0, 1.0, 1.0, 0.0, 50.0, 1.0, 0.0, 1.0, 4.0, 9.0, 17.0, 4.0, 9.0, 20.0, 4.0, 7.0, 59.0, 54.0, 30.0, 121.0, 14.0, 11.0, 59.0, 0.0, 0.0, 7.0, 5.0, 14.0, 24.0, 31.0, 71.0, 2.0, 45.0, 13.0, 30.0, 0.0, 26.0, 34.0, 25.0, 14.0, 114.0, 30.0, 22.0, 3.0, 3.0, 15.0, 21.0, 5.0, 15.0, 10.0, 6.0, 4.0, 15.0, 26.0, 3.0, 0.0, 5.0, 2.0, 0.0, 99.0, 68.0, 15.0, 5.0, 101.0, 116.0, 53.0, 18.0, 32.0, 0.0, 32.0, 26.0, 31.0, 28.0, 19.0, 5.0, 15.0, 0.0, 3.0, 3.0, 3.0, 1.0, 9.0, 0.0, 0.0, 1.0, 28.0, 15.0, 41.0, 5.0, 15.0, 20.0, 15.0, 73.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8609164465668312, "mean_inference_ms": 2.2274564288673497, "mean_action_processing_ms": 0.35218070762521564, "mean_env_wait_ms": 0.2840899604314507, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006595611572265625, "StateBufferConnector_ms": 0.0032428503036499023, "ViewRequirementAgentConnector_ms": 0.10237598419189453}, "num_episodes": 18, "episode_return_max": 109.79999999999899, "episode_return_min": -255.9999999999998, "episode_return_mean": 13.668000000000081, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.9446906186964, "num_env_steps_trained_throughput_per_sec": 344.9446906186964, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 11528.797, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11528.738, "sample_time_ms": 1489.425, "learn_time_ms": 10018.909, "learn_throughput": 399.245, "synch_weights_time_ms": 18.618}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "f0d88_00000", "date": "2024-08-14_11-06-12", "timestamp": 1723647972, "time_this_iter_s": 11.652688980102539, "time_total_s": 1188.1465876102448, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4ebc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1188.1465876102448, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 47.78125, "ram_util_percent": 83.03125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.676596409870834, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 1.6144425247239058, "policy_loss": -0.02488051759837954, "vf_loss": 1.6231793138400588, "vf_explained_var": 0.023075853201447342, "kl": 0.01062961355126714, "entropy": 1.253557836820209, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8448808723971957, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 2.43407636597043, "policy_loss": -0.005961532054084634, "vf_loss": 2.432099974281573, "vf_explained_var": 0.3837733422952985, "kl": 0.009291762796160896, "entropy": 0.6710208410623844, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 81.99999999999893, "episode_reward_min": -255.9999999999998, "episode_reward_mean": 10.522000000000096, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.69999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 87.49999999999929, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -15.954000000000006, "predator_policy": 21.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.90000000000015, -15.499999999999549, 42.60000000000037, 34.100000000000215, -53.70000000000113, -77.7000000000005, 25.90000000000007, -21.599999999999575, 48.10000000000006, 48.90000000000045, 17.399999999999952, 58.20000000000042, 6.399999999999978, 81.49999999999916, 21.799999999999997, -49.09999999999993, 29.000000000000128, 45.60000000000039, -10.899999999999636, 37.700000000000266, 5.900000000000125, 37.80000000000027, -51.299999999999955, -255.9999999999998, -5.0000000000000995, -61.099999999999866, -14.199999999999525, -13.899999999999615, 34.50000000000022, 33.400000000000205, 49.800000000000466, 37.80000000000027, 39.9000000000003, -11.400000000000077, 38.90000000000028, 36.60000000000025, 33.0000000000002, 81.49999999999918, 13.599999999999902, -26.29999999999977, 81.99999999999893, -104.00000000000118, -30.099999999999625, 40.0000000000003, 33.10000000000019, 38.700000000000294, -46.399999999999665, 4.200000000000124, -3.1000000000000245, 13.199999999999957, 63.90000000000013, -89.90000000000018, 20.60000000000006, 33.4000000000002, 49.90000000000045, 68.39999999999995, 35.00000000000023, 19.09999999999999, 8.10000000000006, 26.100000000000072, 37.80000000000027, -143.70000000000118, 17.999999999999996, -55.899999999999906, -6.600000000000041, -11.999999999999758, 30.800000000000175, 24.90000000000008, 64.30000000000038, 23.500000000000032, 37.600000000000264, 40.400000000000304, 74.19999999999968, 40.70000000000031, 36.80000000000025, 14.89999999999993, 16.800000000000075, -39.99999999999983, -58.99999999999958, 5.900000000000125, 23.40000000000003, 31.200000000000163, 1.4999999999999372, 11.300000000000013, 33.4000000000002, 20.099999999999984, -14.799999999999523, 43.100000000000335, 0.3999999999999244, 36.60000000000025, -50.19999999999974, 31.200000000000166, -42.49999999999988, 30.000000000000142, 48.00000000000042, -6.599999999999978, 7.100000000000064, 45.90000000000033, 62.600000000000485, 26.800000000000086], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -33.09999999999985, -91.30000000000084, -26.199999999999747, 10.09999999999998, 9.499999999999964, 1.0999999999999865, 20.000000000000014, -59.80000000000051, -40.89999999999976, -137.50000000000034, -47.19999999999978, 1.0999999999999865, 15.799999999999963, -68.20000000000022, -9.399999999999855, -9.99999999999988, 4.099999999999973, 23.900000000000077, 20.000000000000014, -34.59999999999975, 20.000000000000014, -14.799999999999793, 47.00000000000023, -237.40000000000043, 15.799999999999963, 87.49999999999929, -42.999999999999766, 5.299999999999965, 9.499999999999964, -91.30000000000001, -35.79999999999998, -0.9999999999999846, 20.000000000000014, 28.400000000000155, 3.1999999999999615, -82.9000000000008, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -45.09999999999976, 20.000000000000014, 15.799999999999963, -152.2, 17.899999999999988, -261.4000000000001, -147.6000000000001, 20.000000000000014, -85.00000000000054, -74.50000000000014, -76.60000000000035, -36.699999999999754, -11.499999999999819, -78.70000000000081, 15.79999999999996, 11.599999999999964, 17.899999999999988, 7.399999999999965, 20.000000000000014, 35.30000000000026, 9.499999999999964, -3.099999999999958, 29.90000000000018, 17.899999999999988, 20.000000000000014, 23.600000000000065, -85.00000000000026, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, 21.80000000000004, -14.799999999999764, 1.999999999999991, 66.50000000000001, 11.599999999999966, -21.9999999999998, -30.399999999999885, -61.9, -39.09999999999989, 37.10000000000026, -234.10000000000045, -4.899999999999853, -74.20000000000078, -25.899999999999814, 20.000000000000014, 20.000000000000014, 15.799999999999963, 5.299999999999965, 13.09999999999997, -12.399999999999844, -17.199999999999815, -131.20000000000041, -62.80000000000072, 20.000000000000014, -24.099999999999998, -22.00000000000003, -32.79999999999976, 20.000000000000014, -24.999999999999943, 29.90000000000018, -9.399999999999855, -208.50000000000034, -42.99999999999976, 11.599999999999975, 13.699999999999964, 13.699999999999964, -6.099999999999952, 20.000000000000014, 9.499999999999964, 38.90000000000017, 20.000000000000014, -1.0000000000000275, 11.599999999999964, -11.499999999999819, -34.59999999999978, 13.699999999999966, 9.499999999999964, 11.599999999999964, 20.000000000000014, 15.799999999999963, -181.60000000000042, -129.10000000000073, -11.499999999999819, 9.499999999999964, -288.69999999999993, 15.799999999999963, -97.59999999999991, 20.000000000000014, -40.899999999999864, -3.099999999999958, -47.19999999999976, 20.000000000000014, -38.799999999999756, 4.699999999999978, 22.40000000000009, 17.899999999999988, -11.499999999999819, 20.000000000000014, 11.599999999999964, 20.000000000000014, 13.699999999999964, 22.700000000000053, 1.0999999999999865, 64.1000000000002, 17.899999999999988, 21.80000000000004, 26.300000000000118, -32.499999999999766, -46.299999999999805, 15.199999999999962, -6.699999999999861, -11.500000000000025, 9.499999999999964, -137.50000000000006, -11.499999999999819, -137.50000000000026, 9.499999999999964, -43.59999999999978, 11.599999999999966, -26.199999999999747, 7.399999999999965, 15.799999999999963, 20.000000000000014, -53.49999999999983, -28.29999999999975, 11.599999999999964, 7.3999999999999835, 20.000000000000014, 10.699999999999974, -34.59999999999975, -35.19999999999976, -10.599999999999836, 15.799999999999963, -15.69999999999986, 20.000000000000014, -55.59999999999989, 20.000000000000014, 11.599999999999964, -152.2000000000004, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -135.40000000000006, 17.899999999999988, 5.299999999999965, 13.699999999999964, -24.09999999999979, 40.100000000000236, -2.8000000000000362, -59.79999999999997, 29.000000000000167, -64.90000000000086, 17.899999999999988, 7.999999999999976, 3.1999999999999615, 46.40000000000023, 3.1999999999999615, 11.599999999999964], "policy_predator_policy_reward": [26.0, 17.0, 51.0, 51.0, 18.0, 5.0, 4.0, 9.0, 4.0, 43.0, 103.0, 4.0, 0.0, 9.0, 42.0, 14.0, 18.0, 36.0, 5.0, 0.0, 26.0, 6.0, 23.0, 3.0, 109.0, 119.0, 27.0, 10.0, 7.0, 0.0, 15.0, 63.0, 0.0, 10.0, 4.0, 10.0, 0.0, 52.0, 1.0, 3.0, 10.0, 21.0, 0.0, 2.0, 82.0, 1.0, 152.0, 1.0, 10.0, 50.0, 60.0, 30.0, 9.0, 25.0, 37.0, 12.0, 4.0, 1.0, 6.0, 0.0, 5.0, 0.0, 11.0, 0.0, 1.0, 1.0, 0.0, 50.0, 1.0, 0.0, 1.0, 4.0, 9.0, 17.0, 4.0, 9.0, 20.0, 4.0, 7.0, 59.0, 54.0, 30.0, 121.0, 14.0, 11.0, 59.0, 0.0, 0.0, 7.0, 5.0, 14.0, 24.0, 31.0, 71.0, 2.0, 45.0, 13.0, 30.0, 0.0, 26.0, 34.0, 25.0, 14.0, 114.0, 30.0, 22.0, 3.0, 3.0, 15.0, 21.0, 5.0, 15.0, 10.0, 6.0, 4.0, 15.0, 26.0, 3.0, 0.0, 5.0, 2.0, 0.0, 99.0, 68.0, 15.0, 5.0, 101.0, 116.0, 53.0, 18.0, 32.0, 0.0, 32.0, 26.0, 31.0, 28.0, 19.0, 5.0, 15.0, 0.0, 3.0, 3.0, 3.0, 1.0, 9.0, 0.0, 0.0, 1.0, 28.0, 15.0, 41.0, 5.0, 15.0, 20.0, 15.0, 73.0, 75.0, 15.0, 30.0, 10.0, 22.0, 16.0, 6.0, 2.0, 0.0, 35.0, 8.0, 20.0, 0.0, 6.0, 31.0, 13.0, 3.0, 28.0, 2.0, 41.0, 36.0, 0.0, 4.0, 1.0, 0.0, 82.0, 8.0, 0.0, 74.0, 1.0, 7.0, 4.0, 2.0, 30.0, 18.0, 38.0, 0.0, 43.0, 2.0, 18.0, 5.0, 8.0, 4.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.858007570596734, "mean_inference_ms": 2.221028499408107, "mean_action_processing_ms": 0.3504752505967735, "mean_env_wait_ms": 0.2827760386780171, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004739165306091309, "StateBufferConnector_ms": 0.00293886661529541, "ViewRequirementAgentConnector_ms": 0.10144436359405518}, "num_episodes": 22, "episode_return_max": 81.99999999999893, "episode_return_min": -255.9999999999998, "episode_return_mean": 10.522000000000096, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.9472862358178, "num_env_steps_trained_throughput_per_sec": 354.9472862358178, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 11519.001, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11518.942, "sample_time_ms": 1448.626, "learn_time_ms": 10050.672, "learn_throughput": 397.983, "synch_weights_time_ms": 17.697}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "f0d88_00000", "date": "2024-08-14_11-06-23", "timestamp": 1723647983, "time_this_iter_s": 11.322532892227173, "time_total_s": 1199.469120502472, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad4ebdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1199.469120502472, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 46.14375, "ram_util_percent": 83.08125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7894403379114847, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.147413876321581, "policy_loss": -0.026588467929374287, "vf_loss": 2.1542386095990578, "vf_explained_var": 0.022569331889430052, "kl": 0.013013157697393887, "entropy": 1.25740367710275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2814250362613215, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 2.8160168369611105, "policy_loss": -0.01163807380119112, "vf_loss": 2.8167848361232295, "vf_explained_var": 0.38019355075069206, "kl": 0.012724002940628528, "entropy": 0.6280063029161836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 81.99999999999893, "episode_reward_min": -255.9999999999998, "episode_reward_mean": 13.893000000000109, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.69999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999955, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -12.6385, "predator_policy": 19.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.899999999999636, 37.700000000000266, 5.900000000000125, 37.80000000000027, -51.299999999999955, -255.9999999999998, -5.0000000000000995, -61.099999999999866, -14.199999999999525, -13.899999999999615, 34.50000000000022, 33.400000000000205, 49.800000000000466, 37.80000000000027, 39.9000000000003, -11.400000000000077, 38.90000000000028, 36.60000000000025, 33.0000000000002, 81.49999999999918, 13.599999999999902, -26.29999999999977, 81.99999999999893, -104.00000000000118, -30.099999999999625, 40.0000000000003, 33.10000000000019, 38.700000000000294, -46.399999999999665, 4.200000000000124, -3.1000000000000245, 13.199999999999957, 63.90000000000013, -89.90000000000018, 20.60000000000006, 33.4000000000002, 49.90000000000045, 68.39999999999995, 35.00000000000023, 19.09999999999999, 8.10000000000006, 26.100000000000072, 37.80000000000027, -143.70000000000118, 17.999999999999996, -55.899999999999906, -6.600000000000041, -11.999999999999758, 30.800000000000175, 24.90000000000008, 64.30000000000038, 23.500000000000032, 37.600000000000264, 40.400000000000304, 74.19999999999968, 40.70000000000031, 36.80000000000025, 14.89999999999993, 16.800000000000075, -39.99999999999983, -58.99999999999958, 5.900000000000125, 23.40000000000003, 31.200000000000163, 1.4999999999999372, 11.300000000000013, 33.4000000000002, 20.099999999999984, -14.799999999999523, 43.100000000000335, 0.3999999999999244, 36.60000000000025, -50.19999999999974, 31.200000000000166, -42.49999999999988, 30.000000000000142, 48.00000000000042, -6.599999999999978, 7.100000000000064, 45.90000000000033, 62.600000000000485, 26.800000000000086, 34.70000000000022, 28.300000000000193, 36.70000000000025, 40.400000000000354, 42.000000000000234, 72.19999999999942, 12.400000000000002, 13.599999999999998, -5.200000000000058, 12.30000000000006, 67.80000000000011, 63.3000000000004, 8.999999999999972, 0.4000000000000722, 35.600000000000236, 36.00000000000024, 38.90000000000028, 70.4999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-82.9000000000008, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -45.09999999999976, 20.000000000000014, 15.799999999999963, -152.2, 17.899999999999988, -261.4000000000001, -147.6000000000001, 20.000000000000014, -85.00000000000054, -74.50000000000014, -76.60000000000035, -36.699999999999754, -11.499999999999819, -78.70000000000081, 15.79999999999996, 11.599999999999964, 17.899999999999988, 7.399999999999965, 20.000000000000014, 35.30000000000026, 9.499999999999964, -3.099999999999958, 29.90000000000018, 17.899999999999988, 20.000000000000014, 23.600000000000065, -85.00000000000026, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, 21.80000000000004, -14.799999999999764, 1.999999999999991, 66.50000000000001, 11.599999999999966, -21.9999999999998, -30.399999999999885, -61.9, -39.09999999999989, 37.10000000000026, -234.10000000000045, -4.899999999999853, -74.20000000000078, -25.899999999999814, 20.000000000000014, 20.000000000000014, 15.799999999999963, 5.299999999999965, 13.09999999999997, -12.399999999999844, -17.199999999999815, -131.20000000000041, -62.80000000000072, 20.000000000000014, -24.099999999999998, -22.00000000000003, -32.79999999999976, 20.000000000000014, -24.999999999999943, 29.90000000000018, -9.399999999999855, -208.50000000000034, -42.99999999999976, 11.599999999999975, 13.699999999999964, 13.699999999999964, -6.099999999999952, 20.000000000000014, 9.499999999999964, 38.90000000000017, 20.000000000000014, -1.0000000000000275, 11.599999999999964, -11.499999999999819, -34.59999999999978, 13.699999999999966, 9.499999999999964, 11.599999999999964, 20.000000000000014, 15.799999999999963, -181.60000000000042, -129.10000000000073, -11.499999999999819, 9.499999999999964, -288.69999999999993, 15.799999999999963, -97.59999999999991, 20.000000000000014, -40.899999999999864, -3.099999999999958, -47.19999999999976, 20.000000000000014, -38.799999999999756, 4.699999999999978, 22.40000000000009, 17.899999999999988, -11.499999999999819, 20.000000000000014, 11.599999999999964, 20.000000000000014, 13.699999999999964, 22.700000000000053, 1.0999999999999865, 64.1000000000002, 17.899999999999988, 21.80000000000004, 26.300000000000118, -32.499999999999766, -46.299999999999805, 15.199999999999962, -6.699999999999861, -11.500000000000025, 9.499999999999964, -137.50000000000006, -11.499999999999819, -137.50000000000026, 9.499999999999964, -43.59999999999978, 11.599999999999966, -26.199999999999747, 7.399999999999965, 15.799999999999963, 20.000000000000014, -53.49999999999983, -28.29999999999975, 11.599999999999964, 7.3999999999999835, 20.000000000000014, 10.699999999999974, -34.59999999999975, -35.19999999999976, -10.599999999999836, 15.799999999999963, -15.69999999999986, 20.000000000000014, -55.59999999999989, 20.000000000000014, 11.599999999999964, -152.2000000000004, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -135.40000000000006, 17.899999999999988, 5.299999999999965, 13.699999999999964, -24.09999999999979, 40.100000000000236, -2.8000000000000362, -59.79999999999997, 29.000000000000167, -64.90000000000086, 17.899999999999988, 7.999999999999976, 3.1999999999999615, 46.40000000000023, 3.1999999999999615, 11.599999999999964, -7.299999999999891, 20.000000000000014, -15.399999999999805, 13.699999999999964, 13.699999999999964, 20.000000000000014, -1.00000000000004, 7.399999999999965, 0.8000000000000508, 27.20000000000013, -38.8, 47.00000000000007, -22.899999999999757, 5.299999999999978, -26.199999999999754, 15.799999999999963, -66.09999999999988, -3.099999999999958, 1.099999999999983, -17.79999999999974, -57.299999999999855, 73.09999999999955, 72.1999999999996, -40.89999999999976, -95.50000000000048, 9.499999999999964, -55.60000000000008, 20.000000000000014, 20.000000000000014, 11.599999999999964, 11.299999999999969, 13.699999999999964, 17.899999999999988, 20.000000000000014, 17.899999999999988, 32.60000000000014], "policy_predator_policy_reward": [0.0, 52.0, 1.0, 3.0, 10.0, 21.0, 0.0, 2.0, 82.0, 1.0, 152.0, 1.0, 10.0, 50.0, 60.0, 30.0, 9.0, 25.0, 37.0, 12.0, 4.0, 1.0, 6.0, 0.0, 5.0, 0.0, 11.0, 0.0, 1.0, 1.0, 0.0, 50.0, 1.0, 0.0, 1.0, 4.0, 9.0, 17.0, 4.0, 9.0, 20.0, 4.0, 7.0, 59.0, 54.0, 30.0, 121.0, 14.0, 11.0, 59.0, 0.0, 0.0, 7.0, 5.0, 14.0, 24.0, 31.0, 71.0, 2.0, 45.0, 13.0, 30.0, 0.0, 26.0, 34.0, 25.0, 14.0, 114.0, 30.0, 22.0, 3.0, 3.0, 15.0, 21.0, 5.0, 15.0, 10.0, 6.0, 4.0, 15.0, 26.0, 3.0, 0.0, 5.0, 2.0, 0.0, 99.0, 68.0, 15.0, 5.0, 101.0, 116.0, 53.0, 18.0, 32.0, 0.0, 32.0, 26.0, 31.0, 28.0, 19.0, 5.0, 15.0, 0.0, 3.0, 3.0, 3.0, 1.0, 9.0, 0.0, 0.0, 1.0, 28.0, 15.0, 41.0, 5.0, 15.0, 20.0, 15.0, 73.0, 75.0, 15.0, 30.0, 10.0, 22.0, 16.0, 6.0, 2.0, 0.0, 35.0, 8.0, 20.0, 0.0, 6.0, 31.0, 13.0, 3.0, 28.0, 2.0, 41.0, 36.0, 0.0, 4.0, 1.0, 0.0, 82.0, 8.0, 0.0, 74.0, 1.0, 7.0, 4.0, 2.0, 30.0, 18.0, 38.0, 0.0, 43.0, 2.0, 18.0, 5.0, 8.0, 4.0, 8.0, 9.0, 13.0, 25.0, 5.0, 0.0, 3.0, 11.0, 23.0, 1.0, 13.0, 28.0, 36.0, 7.0, 23.0, 22.0, 2.0, 26.0, 38.0, 18.0, 11.0, 13.0, 39.0, 3.0, 29.0, 40.0, 55.0, 36.0, 0.0, 3.0, 1.0, 8.0, 3.0, 0.0, 1.0, 19.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8557337174257243, "mean_inference_ms": 2.214041611826703, "mean_action_processing_ms": 0.3500789912427912, "mean_env_wait_ms": 0.28256406702788023, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004150748252868652, "StateBufferConnector_ms": 0.0029036998748779297, "ViewRequirementAgentConnector_ms": 0.10012757778167725}, "num_episodes": 18, "episode_return_max": 81.99999999999893, "episode_return_min": -255.9999999999998, "episode_return_mean": 13.893000000000109, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.6574914492064, "num_env_steps_trained_throughput_per_sec": 344.6574914492064, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 11509.732, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11509.673, "sample_time_ms": 1391.159, "learn_time_ms": 10098.974, "learn_throughput": 396.08, "synch_weights_time_ms": 17.616}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "f0d88_00000", "date": "2024-08-14_11-06-35", "timestamp": 1723647995, "time_this_iter_s": 11.642360925674438, "time_total_s": 1211.1114814281464, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad66f5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1211.1114814281464, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 45.94117647058823, "ram_util_percent": 83.07058823529411}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6368145858484602, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.0010000000000000005, "total_loss": 2.724707976850883, "policy_loss": -0.03277797852470367, "vf_loss": 2.739068807180596, "vf_explained_var": 0.026391023113614038, "kl": 0.012126517399707739, "entropy": 1.2746867788531793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0327574317102077, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.0010000000000000005, "total_loss": 2.919664404694996, "policy_loss": -0.01327190962102678, "vf_loss": 2.9215379221729503, "vf_explained_var": 0.3186443158873805, "kl": 0.013342429950425545, "entropy": 0.5796115562556282, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 115.09999999999886, "episode_reward_min": -150.3000000000009, "episode_reward_mean": 13.208000000000066, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.59999999999934, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999955, "predator_policy": 156.0}, "policy_reward_mean": {"prey_policy": -16.751000000000015, "predator_policy": 23.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-104.00000000000118, -30.099999999999625, 40.0000000000003, 33.10000000000019, 38.700000000000294, -46.399999999999665, 4.200000000000124, -3.1000000000000245, 13.199999999999957, 63.90000000000013, -89.90000000000018, 20.60000000000006, 33.4000000000002, 49.90000000000045, 68.39999999999995, 35.00000000000023, 19.09999999999999, 8.10000000000006, 26.100000000000072, 37.80000000000027, -143.70000000000118, 17.999999999999996, -55.899999999999906, -6.600000000000041, -11.999999999999758, 30.800000000000175, 24.90000000000008, 64.30000000000038, 23.500000000000032, 37.600000000000264, 40.400000000000304, 74.19999999999968, 40.70000000000031, 36.80000000000025, 14.89999999999993, 16.800000000000075, -39.99999999999983, -58.99999999999958, 5.900000000000125, 23.40000000000003, 31.200000000000163, 1.4999999999999372, 11.300000000000013, 33.4000000000002, 20.099999999999984, -14.799999999999523, 43.100000000000335, 0.3999999999999244, 36.60000000000025, -50.19999999999974, 31.200000000000166, -42.49999999999988, 30.000000000000142, 48.00000000000042, -6.599999999999978, 7.100000000000064, 45.90000000000033, 62.600000000000485, 26.800000000000086, 34.70000000000022, 28.300000000000193, 36.70000000000025, 40.400000000000354, 42.000000000000234, 72.19999999999942, 12.400000000000002, 13.599999999999998, -5.200000000000058, 12.30000000000006, 67.80000000000011, 63.3000000000004, 8.999999999999972, 0.4000000000000722, 35.600000000000236, 36.00000000000024, 38.90000000000028, 70.4999999999999, 33.4000000000002, 115.09999999999886, 42.30000000000033, 25.000000000000053, 2.799999999999955, -150.3000000000009, -22.699999999999513, 13.800000000000036, 45.60000000000044, -121.80000000000106, -71.4000000000002, -65.1999999999996, 24.300000000000043, 6.999999999999988, 6.600000000000136, 68.40000000000018, 57.10000000000012, -8.199999999999985, 32.30000000000018, -137.30000000000146, 32.20000000000018, 70.7, 44.100000000000364], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-234.10000000000045, -4.899999999999853, -74.20000000000078, -25.899999999999814, 20.000000000000014, 20.000000000000014, 15.799999999999963, 5.299999999999965, 13.09999999999997, -12.399999999999844, -17.199999999999815, -131.20000000000041, -62.80000000000072, 20.000000000000014, -24.099999999999998, -22.00000000000003, -32.79999999999976, 20.000000000000014, -24.999999999999943, 29.90000000000018, -9.399999999999855, -208.50000000000034, -42.99999999999976, 11.599999999999975, 13.699999999999964, 13.699999999999964, -6.099999999999952, 20.000000000000014, 9.499999999999964, 38.90000000000017, 20.000000000000014, -1.0000000000000275, 11.599999999999964, -11.499999999999819, -34.59999999999978, 13.699999999999966, 9.499999999999964, 11.599999999999964, 20.000000000000014, 15.799999999999963, -181.60000000000042, -129.10000000000073, -11.499999999999819, 9.499999999999964, -288.69999999999993, 15.799999999999963, -97.59999999999991, 20.000000000000014, -40.899999999999864, -3.099999999999958, -47.19999999999976, 20.000000000000014, -38.799999999999756, 4.699999999999978, 22.40000000000009, 17.899999999999988, -11.499999999999819, 20.000000000000014, 11.599999999999964, 20.000000000000014, 13.699999999999964, 22.700000000000053, 1.0999999999999865, 64.1000000000002, 17.899999999999988, 21.80000000000004, 26.300000000000118, -32.499999999999766, -46.299999999999805, 15.199999999999962, -6.699999999999861, -11.500000000000025, 9.499999999999964, -137.50000000000006, -11.499999999999819, -137.50000000000026, 9.499999999999964, -43.59999999999978, 11.599999999999966, -26.199999999999747, 7.399999999999965, 15.799999999999963, 20.000000000000014, -53.49999999999983, -28.29999999999975, 11.599999999999964, 7.3999999999999835, 20.000000000000014, 10.699999999999974, -34.59999999999975, -35.19999999999976, -10.599999999999836, 15.799999999999963, -15.69999999999986, 20.000000000000014, -55.59999999999989, 20.000000000000014, 11.599999999999964, -152.2000000000004, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -135.40000000000006, 17.899999999999988, 5.299999999999965, 13.699999999999964, -24.09999999999979, 40.100000000000236, -2.8000000000000362, -59.79999999999997, 29.000000000000167, -64.90000000000086, 17.899999999999988, 7.999999999999976, 3.1999999999999615, 46.40000000000023, 3.1999999999999615, 11.599999999999964, -7.299999999999891, 20.000000000000014, -15.399999999999805, 13.699999999999964, 13.699999999999964, 20.000000000000014, -1.00000000000004, 7.399999999999965, 0.8000000000000508, 27.20000000000013, -38.8, 47.00000000000007, -22.899999999999757, 5.299999999999978, -26.199999999999754, 15.799999999999963, -66.09999999999988, -3.099999999999958, 1.099999999999983, -17.79999999999974, -57.299999999999855, 73.09999999999955, 72.1999999999996, -40.89999999999976, -95.50000000000048, 9.499999999999964, -55.60000000000008, 20.000000000000014, 20.000000000000014, 11.599999999999964, 11.299999999999969, 13.699999999999964, 17.899999999999988, 20.000000000000014, 17.899999999999988, 32.60000000000014, 13.699999999999964, 13.699999999999964, 54.20000000000012, 11.899999999999974, 20.30000000000002, 20.000000000000014, 9.499999999999964, 9.499999999999964, -76.60000000000045, -84.60000000000073, -33.6999999999998, -307.59999999999934, -85.00000000000085, 5.299999999999965, 1.0999999999999865, -91.30000000000067, -7.299999999999891, -78.10000000000073, -131.20000000000056, -139.60000000000053, -1.0000000000000382, -240.40000000000015, -147.99999999999994, -26.199999999999754, 15.799999999999963, -11.499999999999819, -7.299999999999891, -15.699999999999925, -7.299999999999894, -45.09999999999976, 15.799999999999963, 50.600000000000236, 20.000000000000014, -94.90000000000035, -59.19999999999997, -39.999999999999844, 13.699999999999964, 11.599999999999964, -124.90000000000072, -122.40000000000074, 3.1999999999999615, 20.000000000000014, 46.70000000000022, 20.000000000000014, 11.599999999999964, 24.50000000000008], "policy_predator_policy_reward": [121.0, 14.0, 11.0, 59.0, 0.0, 0.0, 7.0, 5.0, 14.0, 24.0, 31.0, 71.0, 2.0, 45.0, 13.0, 30.0, 0.0, 26.0, 34.0, 25.0, 14.0, 114.0, 30.0, 22.0, 3.0, 3.0, 15.0, 21.0, 5.0, 15.0, 10.0, 6.0, 4.0, 15.0, 26.0, 3.0, 0.0, 5.0, 2.0, 0.0, 99.0, 68.0, 15.0, 5.0, 101.0, 116.0, 53.0, 18.0, 32.0, 0.0, 32.0, 26.0, 31.0, 28.0, 19.0, 5.0, 15.0, 0.0, 3.0, 3.0, 3.0, 1.0, 9.0, 0.0, 0.0, 1.0, 28.0, 15.0, 41.0, 5.0, 15.0, 20.0, 15.0, 73.0, 75.0, 15.0, 30.0, 10.0, 22.0, 16.0, 6.0, 2.0, 0.0, 35.0, 8.0, 20.0, 0.0, 6.0, 31.0, 13.0, 3.0, 28.0, 2.0, 41.0, 36.0, 0.0, 4.0, 1.0, 0.0, 82.0, 8.0, 0.0, 74.0, 1.0, 7.0, 4.0, 2.0, 30.0, 18.0, 38.0, 0.0, 43.0, 2.0, 18.0, 5.0, 8.0, 4.0, 8.0, 9.0, 13.0, 25.0, 5.0, 0.0, 3.0, 11.0, 23.0, 1.0, 13.0, 28.0, 36.0, 7.0, 23.0, 22.0, 2.0, 26.0, 38.0, 18.0, 11.0, 13.0, 39.0, 3.0, 29.0, 40.0, 55.0, 36.0, 0.0, 3.0, 1.0, 8.0, 3.0, 0.0, 1.0, 19.0, 1.0, 3.0, 3.0, 27.0, 22.0, 0.0, 2.0, 1.0, 5.0, 91.0, 73.0, 156.0, 35.0, 50.0, 7.0, 45.0, 59.0, 65.0, 66.0, 62.0, 87.0, 89.0, 81.0, 22.0, 87.0, 10.0, 10.0, 17.0, 13.0, 31.0, 28.0, 0.0, 2.0, 57.0, 75.0, 23.0, 68.0, 4.0, 3.0, 83.0, 27.0, 8.0, 1.0, 0.0, 4.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8536237510362561, "mean_inference_ms": 2.205855385712566, "mean_action_processing_ms": 0.3491138652335089, "mean_env_wait_ms": 0.2818951444059922, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035758018493652344, "StateBufferConnector_ms": 0.0028928518295288086, "ViewRequirementAgentConnector_ms": 0.10570907592773438}, "num_episodes": 23, "episode_return_max": 115.09999999999886, "episode_return_min": -150.3000000000009, "episode_return_mean": 13.208000000000066, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 337.0972799752267, "num_env_steps_trained_throughput_per_sec": 337.0972799752267, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 11532.377, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11532.321, "sample_time_ms": 1351.98, "learn_time_ms": 10161.826, "learn_throughput": 393.63, "synch_weights_time_ms": 16.58}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "f0d88_00000", "date": "2024-08-14_11-06-47", "timestamp": 1723648007, "time_this_iter_s": 11.910271167755127, "time_total_s": 1223.0217525959015, "pid": 47002, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ad63ff70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1223.0217525959015, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 49.64117647058823, "ram_util_percent": 83.2}}
