{"num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 4000000, "num_agent_steps_trained": 4000000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 60.1157013665409, "num_env_steps_trained_throughput_per_sec": 60.1157013665409, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 4000000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 4000000, "training_iteration": 100, "timestamp": 1724409313, "time_this_iter_s": 66.60631513595581, "time_total_s": 7200.796705961227, "time_since_restore": 7200.796705961227, "iterations_since_restore": 100, "info/num_env_steps_sampled": 400000, "info/num_env_steps_trained": 400000, "info/num_agent_steps_sampled": 4000000, "info/num_agent_steps_trained": 4000000, "env_runners/episode_reward_max": 1083.8920298905998, "env_runners/episode_reward_min": 576.8932147138976, "env_runners/episode_reward_mean": 809.8202234670597, "env_runners/episode_len_mean": 400.0, "env_runners/episodes_timesteps_total": 40000, "env_runners/num_faulty_episodes": 0, "env_runners/num_episodes": 11, "env_runners/episode_return_max": 1083.8920298905998, "env_runners/episode_return_min": 576.8932147138976, "env_runners/episode_return_mean": 809.8202234670597, "env_runners/episodes_this_iter": 11, "timers/training_iteration_time_ms": 68674.389, "timers/restore_workers_time_ms": 0.019, "timers/training_step_time_ms": 68674.277, "timers/sample_time_ms": 4621.037, "timers/learn_time_ms": 64018.659, "timers/learn_throughput": 62.482, "timers/synch_weights_time_ms": 20.316, "counters/num_env_steps_sampled": 400000, "counters/num_env_steps_trained": 400000, "counters/num_agent_steps_sampled": 4000000, "counters/num_agent_steps_trained": 4000000, "perf/cpu_util_percent": 31.9595744680851, "perf/ram_util_percent": 83.07340425531915, "info/learner/prey_policy/num_agent_steps_trained": 127.38853503184713, "info/learner/prey_policy/num_grad_updates_lifetime": 234323.0, "info/learner/prey_policy/diff_num_grad_updates_vs_sampler_policy": 1177.0, "info/learner/predator_policy/num_agent_steps_trained": 127.38853503184713, "info/learner/predator_policy/num_grad_updates_lifetime": 234323.0, "info/learner/predator_policy/diff_num_grad_updates_vs_sampler_policy": 1177.0, "info/learner/prey_policy/learner_stats/allreduce_latency": 0.0, "info/learner/prey_policy/learner_stats/grad_gnorm": 15.645292149177276, "info/learner/prey_policy/learner_stats/cur_kl_coeff": 0.2, "info/learner/prey_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/prey_policy/learner_stats/total_loss": 7.921135463228651, "info/learner/prey_policy/learner_stats/policy_loss": -0.012258575311140206, "info/learner/prey_policy/learner_stats/vf_loss": 7.931552881293489, "info/learner/prey_policy/learner_stats/vf_explained_var": -0.049477064280499826, "info/learner/prey_policy/learner_stats/kl": 0.009205730143942398, "info/learner/prey_policy/learner_stats/entropy": 0.6299302588475991, "info/learner/prey_policy/learner_stats/entropy_coeff": 0.0, "info/learner/predator_policy/learner_stats/allreduce_latency": 0.0, "info/learner/predator_policy/learner_stats/grad_gnorm": 6.844034971958006, "info/learner/predator_policy/learner_stats/cur_kl_coeff": 0.2, "info/learner/predator_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/predator_policy/learner_stats/total_loss": 6.700954514400215, "info/learner/predator_policy/learner_stats/policy_loss": -0.007154478477373435, "info/learner/predator_policy/learner_stats/vf_loss": 6.70680520590197, "info/learner/predator_policy/learner_stats/vf_explained_var": 0.12996589317443263, "info/learner/predator_policy/learner_stats/kl": 0.006518899888193705, "info/learner/predator_policy/learner_stats/entropy": 0.5050879001617432, "info/learner/predator_policy/learner_stats/entropy_coeff": 0.0, "_timestamp": 1724409313.439138, "_runtime": 7198.571856975555, "_step": 99, "env_runners/policy_reward_min/prey_policy": -454.67499469743075, "env_runners/policy_reward_min/predator_policy": 33.658208743413454, "env_runners/policy_reward_max/prey_policy": 280.3321986378672, "env_runners/policy_reward_max/predator_policy": 403.04135524979023, "env_runners/policy_reward_mean/prey_policy": -51.16140805545941, "env_runners/policy_reward_mean/predator_policy": 213.12545274886966, "env_runners/sampler_perf/mean_raw_obs_processing_ms": 14.705095680075026, "env_runners/sampler_perf/mean_inference_ms": 10.030284436205879, "env_runners/sampler_perf/mean_action_processing_ms": 5.415341388596098, "env_runners/sampler_perf/mean_env_wait_ms": 14.234595856157107, "env_runners/sampler_perf/mean_env_render_ms": 0.0, "env_runners/connector_metrics/ObsPreprocessorConnector_ms": 0.01638197898864746, "env_runners/connector_metrics/StateBufferConnector_ms": 0.011730551719665527, "env_runners/connector_metrics/ViewRequirementAgentConnector_ms": 0.4538315534591675}