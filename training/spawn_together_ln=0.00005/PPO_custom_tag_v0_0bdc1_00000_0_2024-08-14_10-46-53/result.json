{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.168514797296474, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.213288058427276, "policy_loss": 3.095558775519883e-05, "vf_loss": 8.21292551358541, "vf_explained_var": 0.0031049630944691006, "kl": 0.0016580160312182598, "entropy": 1.6077421329008839, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9969315601404382, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.038007971849391, "policy_loss": -0.006142683389655772, "vf_loss": 5.042828711252364, "vf_explained_var": 0.001648904249150917, "kl": 0.006609756181513716, "entropy": 1.6029560499721103, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 126.4999999999998, "episode_reward_min": -139.8000000000006, "episode_reward_mean": -10.861111111111418, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -234.7, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 125.90000000000005, "predator_policy": 138.0}, "policy_reward_mean": {"prey_policy": -62.763888888889056, "predator_policy": 57.333333333333336}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.299999999999905, -67.90000000000092, -59.09999999999991, -65.70000000000147, 72.19999999999997, 126.4999999999998, -16.70000000000052, 98.29999999999976, 48.40000000000017, -78.10000000000151, -34.89999999999956, -82.90000000000092, -112.30000000000021, -139.8000000000006, 1.999999999999938, 94.59999999999987, -8.59999999999963, 78.80000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.89999999999999, -180.40000000000015, 35.300000000000246, -215.20000000000047, 35.600000000000236, -234.7, -77.80000000000081, -82.90000000000066, -85.9, 55.100000000000186, -30.39999999999975, 125.90000000000005, -70.30000000000055, -99.40000000000032, 118.09999999999997, -155.80000000000064, -111.90000000000072, 71.29999999999998, -137.8000000000007, -58.300000000000416, -111.10000000000073, 3.199999999999972, -160.3000000000002, -91.6000000000007, -233.5000000000002, -98.80000000000001, -198.40000000000046, -129.40000000000012, -85.00000000000013, 20.000000000000014, 61.400000000000034, -23.799999999999855, -13.599999999999854, -39.99999999999976, -132.3999999999999, 102.20000000000006], "policy_predator_policy_reward": [95.0, 64.0, 1.0, 111.0, 138.0, 2.0, 33.0, 62.0, 89.0, 14.0, 7.0, 24.0, 66.0, 87.0, 53.0, 83.0, 18.0, 71.0, 76.0, 42.0, 65.0, 8.0, 90.0, 79.0, 101.0, 119.0, 55.0, 133.0, 30.0, 37.0, 28.0, 29.0, 16.0, 29.0, 89.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9803192309702499, "mean_inference_ms": 2.7757995172932226, "mean_action_processing_ms": 0.4091916534076492, "mean_env_wait_ms": 0.34893531409780465, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006451871660020616, "StateBufferConnector_ms": 0.003335873285929362, "ViewRequirementAgentConnector_ms": 0.2515978283352322}, "num_episodes": 18, "episode_return_max": 126.4999999999998, "episode_return_min": -139.8000000000006, "episode_return_mean": -10.861111111111418, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.85987575653127, "num_env_steps_trained_throughput_per_sec": 300.85987575653127, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 13295.236, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13295.183, "sample_time_ms": 2106.408, "learn_time_ms": 11175.419, "learn_throughput": 357.928, "synch_weights_time_ms": 12.207}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-47-20", "timestamp": 1723646840, "time_this_iter_s": 13.334972858428955, "time_total_s": 13.334972858428955, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed408b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 13.334972858428955, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 54.995000000000005, "ram_util_percent": 83.71}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1650408383872772, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.176671391946298, "policy_loss": -0.004665247968363541, "vf_loss": 8.180280386455475, "vf_explained_var": 0.0029990257409514575, "kl": 0.010562684374674614, "entropy": 1.596965946533062, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8444074115109822, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.835545460383098, "policy_loss": -0.004400832401514645, "vf_loss": 5.839041586780043, "vf_explained_var": 0.002036428136169595, "kl": 0.004523395570382134, "entropy": 1.599504823659463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 254.6999999999998, "episode_reward_min": -271.29999999999995, "episode_reward_mean": -15.24722222222242, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -387.3999999999999, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -72.29027777777793, "predator_policy": 64.66666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.299999999999905, -67.90000000000092, -59.09999999999991, -65.70000000000147, 72.19999999999997, 126.4999999999998, -16.70000000000052, 98.29999999999976, 48.40000000000017, -78.10000000000151, -34.89999999999956, -82.90000000000092, -112.30000000000021, -139.8000000000006, 1.999999999999938, 94.59999999999987, -8.59999999999963, 78.80000000000013, 31.100000000000286, -23.999999999999915, 121.09999999999985, -84.00000000000023, -80.10000000000029, -106.00000000000057, 77.7999999999996, -271.29999999999995, -3.3000000000000105, -172.0000000000004, 254.6999999999998, 59.50000000000021, -108.7000000000009, -20.8999999999998, -55.19999999999981, -39.199999999999605, 137.39999999999966, -70.29999999999967], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.89999999999999, -180.40000000000015, 35.300000000000246, -215.20000000000047, 35.600000000000236, -234.7, -77.80000000000081, -82.90000000000066, -85.9, 55.100000000000186, -30.39999999999975, 125.90000000000005, -70.30000000000055, -99.40000000000032, 118.09999999999997, -155.80000000000064, -111.90000000000072, 71.29999999999998, -137.8000000000007, -58.300000000000416, -111.10000000000073, 3.199999999999972, -160.3000000000002, -91.6000000000007, -233.5000000000002, -98.80000000000001, -198.40000000000046, -129.40000000000012, -85.00000000000013, 20.000000000000014, 61.400000000000034, -23.799999999999855, -13.599999999999854, -39.99999999999976, -132.3999999999999, 102.20000000000006, -28.29999999999975, 13.400000000000073, -271.60000000000014, 77.60000000000007, -197.20000000000022, 179.29999999999987, 29.000000000000036, -346.00000000000006, -240.4000000000003, -39.70000000000002, -60.100000000000435, -235.90000000000012, 60.50000000000013, -96.70000000000024, -387.3999999999999, -166.90000000000057, -240.7000000000003, 94.3999999999998, -137.5000000000003, -305.4999999999996, 158.0, 31.699999999999935, 58.70000000000007, -86.20000000000078, -85.90000000000073, -158.80000000000015, -68.49999999999977, -9.400000000000066, -126.7, -119.50000000000054, 17.899999999999988, -129.10000000000068, 197.0, -148.5999999999999, -143.80000000000055, -32.499999999999766], "policy_predator_policy_reward": [95.0, 64.0, 1.0, 111.0, 138.0, 2.0, 33.0, 62.0, 89.0, 14.0, 7.0, 24.0, 66.0, 87.0, 53.0, 83.0, 18.0, 71.0, 76.0, 42.0, 65.0, 8.0, 90.0, 79.0, 101.0, 119.0, 55.0, 133.0, 30.0, 37.0, 28.0, 29.0, 16.0, 29.0, 89.0, 20.0, 14.0, 32.0, 46.0, 124.0, 26.0, 113.0, 126.0, 107.0, 76.0, 124.0, 133.0, 57.0, 79.0, 35.0, 194.0, 89.0, 122.0, 21.0, 103.0, 168.0, 9.0, 56.0, 36.0, 51.0, 23.0, 113.0, 14.0, 43.0, 107.0, 84.0, 1.0, 71.0, 85.0, 4.0, 78.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8982558154902335, "mean_inference_ms": 2.520112188443059, "mean_action_processing_ms": 0.3767956711207656, "mean_env_wait_ms": 0.3155446700795962, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006123714976840549, "StateBufferConnector_ms": 0.003250771098666721, "ViewRequirementAgentConnector_ms": 0.17138984468248156}, "num_episodes": 18, "episode_return_max": 254.6999999999998, "episode_return_min": -271.29999999999995, "episode_return_mean": -15.24722222222242, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.878053971562, "num_env_steps_trained_throughput_per_sec": 346.878053971562, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 12413.353, "restore_workers_time_ms": 0.027, "training_step_time_ms": 12413.276, "sample_time_ms": 1746.822, "learn_time_ms": 10650.247, "learn_throughput": 375.578, "synch_weights_time_ms": 12.605}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-47-34", "timestamp": 1723646854, "time_this_iter_s": 11.568841934204102, "time_total_s": 24.903814792633057, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed25d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 24.903814792633057, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 44.645, "ram_util_percent": 83.58}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3624487293460383, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.323117675730791, "policy_loss": -0.002176650473847985, "vf_loss": 6.324427776235752, "vf_explained_var": 0.006013986200251907, "kl": 0.008665509228328304, "entropy": 1.5878716254991199, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0542197239146662, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9173214175713755, "policy_loss": -0.009349352726959205, "vf_loss": 3.9251992411083645, "vf_explained_var": 0.006240979262760707, "kl": 0.014715269050509227, "entropy": 1.590964136615632, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 269.40000000000003, "episode_reward_min": -271.29999999999995, "episode_reward_mean": -3.1111111111113448, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -387.3999999999999, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -60.25000000000015, "predator_policy": 58.69444444444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.299999999999905, -67.90000000000092, -59.09999999999991, -65.70000000000147, 72.19999999999997, 126.4999999999998, -16.70000000000052, 98.29999999999976, 48.40000000000017, -78.10000000000151, -34.89999999999956, -82.90000000000092, -112.30000000000021, -139.8000000000006, 1.999999999999938, 94.59999999999987, -8.59999999999963, 78.80000000000013, 31.100000000000286, -23.999999999999915, 121.09999999999985, -84.00000000000023, -80.10000000000029, -106.00000000000057, 77.7999999999996, -271.29999999999995, -3.3000000000000105, -172.0000000000004, 254.6999999999998, 59.50000000000021, -108.7000000000009, -20.8999999999998, -55.19999999999981, -39.199999999999605, 137.39999999999966, -70.29999999999967, 119.4999999999992, -23.599999999999937, 19.20000000000009, -90.40000000000134, 269.40000000000003, -18.099999999999802, 89.19999999999864, 47.50000000000021, -10.399999999999894, 166.39999999999932, -2.500000000000036, -90.90000000000141, -48.0000000000004, -29.399999999999995, 52.40000000000021, 14.100000000000074, 24.300000000000193, -107.8000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.89999999999999, -180.40000000000015, 35.300000000000246, -215.20000000000047, 35.600000000000236, -234.7, -77.80000000000081, -82.90000000000066, -85.9, 55.100000000000186, -30.39999999999975, 125.90000000000005, -70.30000000000055, -99.40000000000032, 118.09999999999997, -155.80000000000064, -111.90000000000072, 71.29999999999998, -137.8000000000007, -58.300000000000416, -111.10000000000073, 3.199999999999972, -160.3000000000002, -91.6000000000007, -233.5000000000002, -98.80000000000001, -198.40000000000046, -129.40000000000012, -85.00000000000013, 20.000000000000014, 61.400000000000034, -23.799999999999855, -13.599999999999854, -39.99999999999976, -132.3999999999999, 102.20000000000006, -28.29999999999975, 13.400000000000073, -271.60000000000014, 77.60000000000007, -197.20000000000022, 179.29999999999987, 29.000000000000036, -346.00000000000006, -240.4000000000003, -39.70000000000002, -60.100000000000435, -235.90000000000012, 60.50000000000013, -96.70000000000024, -387.3999999999999, -166.90000000000057, -240.7000000000003, 94.3999999999998, -137.5000000000003, -305.4999999999996, 158.0, 31.699999999999935, 58.70000000000007, -86.20000000000078, -85.90000000000073, -158.80000000000015, -68.49999999999977, -9.400000000000066, -126.7, -119.50000000000054, 17.899999999999988, -129.10000000000068, 197.0, -148.5999999999999, -143.80000000000055, -32.499999999999766, 31.400000000000112, 55.100000000000115, -9.399999999999961, -89.20000000000012, -9.099999999999948, -81.70000000000007, -51.999999999999936, -135.40000000000072, 80.0, 142.3999999999997, -250.89999999999998, 39.80000000000016, 12.499999999999972, 25.700000000000134, 73.1000000000002, -97.60000000000053, -30.999999999999872, -81.40000000000077, 102.49999999999989, 8.899999999999986, 53.9000000000002, -195.40000000000052, -124.90000000000053, -85.0000000000008, -64.00000000000071, -64.00000000000091, -116.20000000000016, -26.199999999999747, 49.69999999999998, -65.30000000000044, -94.60000000000048, 22.70000000000001, 3.7999999999999923, -71.50000000000014, -28.29999999999975, -230.50000000000006], "policy_predator_policy_reward": [95.0, 64.0, 1.0, 111.0, 138.0, 2.0, 33.0, 62.0, 89.0, 14.0, 7.0, 24.0, 66.0, 87.0, 53.0, 83.0, 18.0, 71.0, 76.0, 42.0, 65.0, 8.0, 90.0, 79.0, 101.0, 119.0, 55.0, 133.0, 30.0, 37.0, 28.0, 29.0, 16.0, 29.0, 89.0, 20.0, 14.0, 32.0, 46.0, 124.0, 26.0, 113.0, 126.0, 107.0, 76.0, 124.0, 133.0, 57.0, 79.0, 35.0, 194.0, 89.0, 122.0, 21.0, 103.0, 168.0, 9.0, 56.0, 36.0, 51.0, 23.0, 113.0, 14.0, 43.0, 107.0, 84.0, 1.0, 71.0, 85.0, 4.0, 78.0, 28.0, 11.0, 22.0, 70.0, 5.0, 73.0, 37.0, 89.0, 8.0, 33.0, 14.0, 116.0, 77.0, 24.0, 27.0, 71.0, 1.0, 43.0, 59.0, 27.0, 28.0, 53.0, 86.0, 85.0, 34.0, 12.0, 68.0, 56.0, 57.0, 56.0, 12.0, 71.0, 15.0, 16.0, 76.0, 107.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8469703572656946, "mean_inference_ms": 2.3563698663896937, "mean_action_processing_ms": 0.35454549624376636, "mean_env_wait_ms": 0.29663472243727995, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062648896817807794, "StateBufferConnector_ms": 0.003245362529048213, "ViewRequirementAgentConnector_ms": 0.14582717860186542}, "num_episodes": 18, "episode_return_max": 269.40000000000003, "episode_return_min": -271.29999999999995, "episode_return_mean": -3.1111111111113448, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.00236665409557, "num_env_steps_trained_throughput_per_sec": 352.00236665409557, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 12063.424, "restore_workers_time_ms": 0.022, "training_step_time_ms": 12063.359, "sample_time_ms": 1571.472, "learn_time_ms": 10475.814, "learn_throughput": 381.832, "synch_weights_time_ms": 12.71}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-47-46", "timestamp": 1723646866, "time_this_iter_s": 11.417205095291138, "time_total_s": 36.321019887924194, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed91ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 36.321019887924194, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 47.39375, "ram_util_percent": 83.4625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.021372604575107, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.412169882355544, "policy_loss": -0.0033560522676755983, "vf_loss": 6.414173973931207, "vf_explained_var": -0.0036960715654665833, "kl": 0.013519598014970562, "entropy": 1.5608037020794299, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.245412097548051, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.741599207832699, "policy_loss": -0.007825398321445815, "vf_loss": 5.748497449027168, "vf_explained_var": 0.002569074132455089, "kl": 0.009271523189682957, "entropy": 1.5858708981483702, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 269.40000000000003, "episode_reward_min": -271.29999999999995, "episode_reward_mean": -3.1930555555558087, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -387.3999999999999, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -59.90902777777793, "predator_policy": 58.3125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.299999999999905, -67.90000000000092, -59.09999999999991, -65.70000000000147, 72.19999999999997, 126.4999999999998, -16.70000000000052, 98.29999999999976, 48.40000000000017, -78.10000000000151, -34.89999999999956, -82.90000000000092, -112.30000000000021, -139.8000000000006, 1.999999999999938, 94.59999999999987, -8.59999999999963, 78.80000000000013, 31.100000000000286, -23.999999999999915, 121.09999999999985, -84.00000000000023, -80.10000000000029, -106.00000000000057, 77.7999999999996, -271.29999999999995, -3.3000000000000105, -172.0000000000004, 254.6999999999998, 59.50000000000021, -108.7000000000009, -20.8999999999998, -55.19999999999981, -39.199999999999605, 137.39999999999966, -70.29999999999967, 119.4999999999992, -23.599999999999937, 19.20000000000009, -90.40000000000134, 269.40000000000003, -18.099999999999802, 89.19999999999864, 47.50000000000021, -10.399999999999894, 166.39999999999932, -2.500000000000036, -90.90000000000141, -48.0000000000004, -29.399999999999995, 52.40000000000021, 14.100000000000074, 24.300000000000193, -107.8000000000005, -194.10000000000085, -134.10000000000142, -8.400000000000004, -119.500000000001, -9.200000000000115, -97.60000000000102, 122.39999999999961, -42.19999999999978, 248.3999999999999, 22.400000000000034, 1.2000000000001647, -3.3999999999999453, 65.20000000000022, 63.299999999998974, 62.500000000000114, -102.00000000000097, 26.90000000000013, 36.30000000000029], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.89999999999999, -180.40000000000015, 35.300000000000246, -215.20000000000047, 35.600000000000236, -234.7, -77.80000000000081, -82.90000000000066, -85.9, 55.100000000000186, -30.39999999999975, 125.90000000000005, -70.30000000000055, -99.40000000000032, 118.09999999999997, -155.80000000000064, -111.90000000000072, 71.29999999999998, -137.8000000000007, -58.300000000000416, -111.10000000000073, 3.199999999999972, -160.3000000000002, -91.6000000000007, -233.5000000000002, -98.80000000000001, -198.40000000000046, -129.40000000000012, -85.00000000000013, 20.000000000000014, 61.400000000000034, -23.799999999999855, -13.599999999999854, -39.99999999999976, -132.3999999999999, 102.20000000000006, -28.29999999999975, 13.400000000000073, -271.60000000000014, 77.60000000000007, -197.20000000000022, 179.29999999999987, 29.000000000000036, -346.00000000000006, -240.4000000000003, -39.70000000000002, -60.100000000000435, -235.90000000000012, 60.50000000000013, -96.70000000000024, -387.3999999999999, -166.90000000000057, -240.7000000000003, 94.3999999999998, -137.5000000000003, -305.4999999999996, 158.0, 31.699999999999935, 58.70000000000007, -86.20000000000078, -85.90000000000073, -158.80000000000015, -68.49999999999977, -9.400000000000066, -126.7, -119.50000000000054, 17.899999999999988, -129.10000000000068, 197.0, -148.5999999999999, -143.80000000000055, -32.499999999999766, 31.400000000000112, 55.100000000000115, -9.399999999999961, -89.20000000000012, -9.099999999999948, -81.70000000000007, -51.999999999999936, -135.40000000000072, 80.0, 142.3999999999997, -250.89999999999998, 39.80000000000016, 12.499999999999972, 25.700000000000134, 73.1000000000002, -97.60000000000053, -30.999999999999872, -81.40000000000077, 102.49999999999989, 8.899999999999986, 53.9000000000002, -195.40000000000052, -124.90000000000053, -85.0000000000008, -64.00000000000071, -64.00000000000091, -116.20000000000016, -26.199999999999747, 49.69999999999998, -65.30000000000044, -94.60000000000048, 22.70000000000001, 3.7999999999999923, -71.50000000000014, -28.29999999999975, -230.50000000000006, -227.80000000000047, -142.30000000000038, -187.90000000000057, -89.20000000000084, -135.40000000000023, 20.000000000000014, -117.4000000000002, -171.1000000000006, -116.50000000000077, 14.300000000000038, -237.90000000000043, 5.299999999999965, -40.6, 31.999999999999936, 30.500000000000174, -351.6999999999987, 153.8, 41.59999999999985, -146.80000000000052, 12.20000000000003, 25.4000000000001, -68.20000000000087, -31.899999999999935, -128.50000000000037, 62.900000000000134, -57.700000000000024, 19.999999999999964, -33.69999999999991, 63.80000000000003, -28.299999999999763, -22.599999999999774, -227.4000000000005, -63.100000000000556, 20.000000000000014, -21.99999999999978, 26.30000000000016], "policy_predator_policy_reward": [95.0, 64.0, 1.0, 111.0, 138.0, 2.0, 33.0, 62.0, 89.0, 14.0, 7.0, 24.0, 66.0, 87.0, 53.0, 83.0, 18.0, 71.0, 76.0, 42.0, 65.0, 8.0, 90.0, 79.0, 101.0, 119.0, 55.0, 133.0, 30.0, 37.0, 28.0, 29.0, 16.0, 29.0, 89.0, 20.0, 14.0, 32.0, 46.0, 124.0, 26.0, 113.0, 126.0, 107.0, 76.0, 124.0, 133.0, 57.0, 79.0, 35.0, 194.0, 89.0, 122.0, 21.0, 103.0, 168.0, 9.0, 56.0, 36.0, 51.0, 23.0, 113.0, 14.0, 43.0, 107.0, 84.0, 1.0, 71.0, 85.0, 4.0, 78.0, 28.0, 11.0, 22.0, 70.0, 5.0, 73.0, 37.0, 89.0, 8.0, 33.0, 14.0, 116.0, 77.0, 24.0, 27.0, 71.0, 1.0, 43.0, 59.0, 27.0, 28.0, 53.0, 86.0, 85.0, 34.0, 12.0, 68.0, 56.0, 57.0, 56.0, 12.0, 71.0, 15.0, 16.0, 76.0, 107.0, 44.0, 66.0, 110.0, 97.0, 46.0, 71.0, 36.0, 127.0, 42.0, 28.0, 65.0, 106.0, 29.0, 38.0, 93.0, 228.0, 51.0, 17.0, 36.0, 55.0, 102.0, 42.0, 2.0, 76.0, 81.0, 37.0, 23.0, 29.0, 48.0, 14.0, 13.0, 123.0, 25.0, 51.0, 19.0, 19.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8133975670836732, "mean_inference_ms": 2.249154902957714, "mean_action_processing_ms": 0.33962520200982854, "mean_env_wait_ms": 0.28418100993993856, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006360477871365017, "StateBufferConnector_ms": 0.0031982858975728354, "ViewRequirementAgentConnector_ms": 0.13375828663508096}, "num_episodes": 18, "episode_return_max": 269.40000000000003, "episode_return_min": -271.29999999999995, "episode_return_mean": -3.1930555555558087, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.3521129106818, "num_env_steps_trained_throughput_per_sec": 349.3521129106818, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 11910.012, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11909.952, "sample_time_ms": 1500.864, "learn_time_ms": 10393.819, "learn_throughput": 384.844, "synch_weights_time_ms": 12.44}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-47-57", "timestamp": 1723646877, "time_this_iter_s": 11.474011898040771, "time_total_s": 47.795031785964966, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed91f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 47.795031785964966, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 47.025, "ram_util_percent": 83.58125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6302225922465956, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.296053283681315, "policy_loss": -0.002489249523058928, "vf_loss": 7.297344212809568, "vf_explained_var": 0.0033479065176040407, "kl": 0.01198301385451553, "entropy": 1.5626704990548432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1990996375285758, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.979785224621889, "policy_loss": -0.012099159250489225, "vf_loss": 5.99024933204449, "vf_explained_var": 0.02120911056402499, "kl": 0.01635043343292665, "entropy": 1.5552184065813741, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 269.40000000000003, "episode_reward_min": -271.29999999999995, "episode_reward_mean": -21.606060606060854, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -387.3999999999999, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -72.27272727272742, "predator_policy": 61.46969696969697}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.299999999999905, -67.90000000000092, -59.09999999999991, -65.70000000000147, 72.19999999999997, 126.4999999999998, -16.70000000000052, 98.29999999999976, 48.40000000000017, -78.10000000000151, -34.89999999999956, -82.90000000000092, -112.30000000000021, -139.8000000000006, 1.999999999999938, 94.59999999999987, -8.59999999999963, 78.80000000000013, 31.100000000000286, -23.999999999999915, 121.09999999999985, -84.00000000000023, -80.10000000000029, -106.00000000000057, 77.7999999999996, -271.29999999999995, -3.3000000000000105, -172.0000000000004, 254.6999999999998, 59.50000000000021, -108.7000000000009, -20.8999999999998, -55.19999999999981, -39.199999999999605, 137.39999999999966, -70.29999999999967, 119.4999999999992, -23.599999999999937, 19.20000000000009, -90.40000000000134, 269.40000000000003, -18.099999999999802, 89.19999999999864, 47.50000000000021, -10.399999999999894, 166.39999999999932, -2.500000000000036, -90.90000000000141, -48.0000000000004, -29.399999999999995, 52.40000000000021, 14.100000000000074, 24.300000000000193, -107.8000000000005, -194.10000000000085, -134.10000000000142, -8.400000000000004, -119.500000000001, -9.200000000000115, -97.60000000000102, 122.39999999999961, -42.19999999999978, 248.3999999999999, 22.400000000000034, 1.2000000000001647, -3.3999999999999453, 65.20000000000022, 63.299999999998974, 62.500000000000114, -102.00000000000097, 26.90000000000013, 36.30000000000029, 3.0000000000000715, -187.40000000000072, 77.69999999999943, -63.09999999999994, -100.90000000000109, -38.799999999999685, -177.40000000000074, -7.899999999999881, -5.999999999999972, -109.6000000000004, -163.8000000000006, -242.90000000000094, -2.499999999999794, -6.199999999999688, -63.899999999999835, 83.49999999999889, 3.2000000000000832, -119.39999999999995, -66.39999999999972, -128.40000000000038, 124.19999999999987, -39.299999999999926, -144.19999999999993, -31.800000000000033, -190.20000000000127, -214.8000000000002, -95.79999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.89999999999999, -180.40000000000015, 35.300000000000246, -215.20000000000047, 35.600000000000236, -234.7, -77.80000000000081, -82.90000000000066, -85.9, 55.100000000000186, -30.39999999999975, 125.90000000000005, -70.30000000000055, -99.40000000000032, 118.09999999999997, -155.80000000000064, -111.90000000000072, 71.29999999999998, -137.8000000000007, -58.300000000000416, -111.10000000000073, 3.199999999999972, -160.3000000000002, -91.6000000000007, -233.5000000000002, -98.80000000000001, -198.40000000000046, -129.40000000000012, -85.00000000000013, 20.000000000000014, 61.400000000000034, -23.799999999999855, -13.599999999999854, -39.99999999999976, -132.3999999999999, 102.20000000000006, -28.29999999999975, 13.400000000000073, -271.60000000000014, 77.60000000000007, -197.20000000000022, 179.29999999999987, 29.000000000000036, -346.00000000000006, -240.4000000000003, -39.70000000000002, -60.100000000000435, -235.90000000000012, 60.50000000000013, -96.70000000000024, -387.3999999999999, -166.90000000000057, -240.7000000000003, 94.3999999999998, -137.5000000000003, -305.4999999999996, 158.0, 31.699999999999935, 58.70000000000007, -86.20000000000078, -85.90000000000073, -158.80000000000015, -68.49999999999977, -9.400000000000066, -126.7, -119.50000000000054, 17.899999999999988, -129.10000000000068, 197.0, -148.5999999999999, -143.80000000000055, -32.499999999999766, 31.400000000000112, 55.100000000000115, -9.399999999999961, -89.20000000000012, -9.099999999999948, -81.70000000000007, -51.999999999999936, -135.40000000000072, 80.0, 142.3999999999997, -250.89999999999998, 39.80000000000016, 12.499999999999972, 25.700000000000134, 73.1000000000002, -97.60000000000053, -30.999999999999872, -81.40000000000077, 102.49999999999989, 8.899999999999986, 53.9000000000002, -195.40000000000052, -124.90000000000053, -85.0000000000008, -64.00000000000071, -64.00000000000091, -116.20000000000016, -26.199999999999747, 49.69999999999998, -65.30000000000044, -94.60000000000048, 22.70000000000001, 3.7999999999999923, -71.50000000000014, -28.29999999999975, -230.50000000000006, -227.80000000000047, -142.30000000000038, -187.90000000000057, -89.20000000000084, -135.40000000000023, 20.000000000000014, -117.4000000000002, -171.1000000000006, -116.50000000000077, 14.300000000000038, -237.90000000000043, 5.299999999999965, -40.6, 31.999999999999936, 30.500000000000174, -351.6999999999987, 153.8, 41.59999999999985, -146.80000000000052, 12.20000000000003, 25.4000000000001, -68.20000000000087, -31.899999999999935, -128.50000000000037, 62.900000000000134, -57.700000000000024, 19.999999999999964, -33.69999999999991, 63.80000000000003, -28.299999999999763, -22.599999999999774, -227.4000000000005, -63.100000000000556, 20.000000000000014, -21.99999999999978, 26.30000000000016, -196.89999999999998, 20.90000000000003, -263.50000000000034, -124.90000000000018, 56.900000000000226, -62.2000000000006, -271.10000000000036, 38.00000000000018, -225.70000000000044, 0.7999999999999741, -206.2000000000005, 43.400000000000226, -154.3000000000005, -207.1000000000003, -84.69999999999989, -56.19999999999992, 20.000000000000014, -87.9999999999998, -44.49999999999998, -210.10000000000028, -200.20000000000033, -202.60000000000053, -279.39999999999964, -166.5, 20.90000000000003, -108.40000000000077, 3.199999999999965, -51.39999999999995, 28.10000000000015, -235.00000000000017, 61.40000000000016, -55.899999999999885, -92.80000000000072, 20.000000000000014, -240.40000000000032, -7.0000000000001705, -125.8000000000007, -115.60000000000004, -303.39999999999986, -115.00000000000036, 148.69999999999982, -74.49999999999986, 17.899999999999988, -161.19999999999996, -317.70000000000016, 3.5000000000001337, -1.0000000000000515, -101.79999999999995, -133.30000000000064, -145.90000000000063, -149.80000000000018, -358.0000000000001, -66.1, -162.70000000000059], "policy_predator_policy_reward": [95.0, 64.0, 1.0, 111.0, 138.0, 2.0, 33.0, 62.0, 89.0, 14.0, 7.0, 24.0, 66.0, 87.0, 53.0, 83.0, 18.0, 71.0, 76.0, 42.0, 65.0, 8.0, 90.0, 79.0, 101.0, 119.0, 55.0, 133.0, 30.0, 37.0, 28.0, 29.0, 16.0, 29.0, 89.0, 20.0, 14.0, 32.0, 46.0, 124.0, 26.0, 113.0, 126.0, 107.0, 76.0, 124.0, 133.0, 57.0, 79.0, 35.0, 194.0, 89.0, 122.0, 21.0, 103.0, 168.0, 9.0, 56.0, 36.0, 51.0, 23.0, 113.0, 14.0, 43.0, 107.0, 84.0, 1.0, 71.0, 85.0, 4.0, 78.0, 28.0, 11.0, 22.0, 70.0, 5.0, 73.0, 37.0, 89.0, 8.0, 33.0, 14.0, 116.0, 77.0, 24.0, 27.0, 71.0, 1.0, 43.0, 59.0, 27.0, 28.0, 53.0, 86.0, 85.0, 34.0, 12.0, 68.0, 56.0, 57.0, 56.0, 12.0, 71.0, 15.0, 16.0, 76.0, 107.0, 44.0, 66.0, 110.0, 97.0, 46.0, 71.0, 36.0, 127.0, 42.0, 28.0, 65.0, 106.0, 29.0, 38.0, 93.0, 228.0, 51.0, 17.0, 36.0, 55.0, 102.0, 42.0, 2.0, 76.0, 81.0, 37.0, 23.0, 29.0, 48.0, 14.0, 13.0, 123.0, 25.0, 51.0, 19.0, 19.0, 13.0, 99.0, 80.0, 166.0, 35.0, 34.0, 49.0, 143.0, 27.0, 117.0, 7.0, 43.0, 81.0, 58.0, 126.0, 60.0, 73.0, 46.0, 16.0, 113.0, 32.0, 129.0, 110.0, 57.0, 146.0, 52.0, 33.0, 34.0, 8.0, 125.0, 18.0, 34.0, 44.0, 46.0, 30.0, 126.0, 2.0, 73.0, 102.0, 118.0, 172.0, 39.0, 11.0, 38.0, 66.0, 164.0, 6.0, 19.0, 52.0, 80.0, 9.0, 119.0, 174.0, 88.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7803343485418232, "mean_inference_ms": 2.1396209588722086, "mean_action_processing_ms": 0.3250648275212256, "mean_env_wait_ms": 0.2715999759198559, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00901956750889017, "StateBufferConnector_ms": 0.003521731405547171, "ViewRequirementAgentConnector_ms": 0.12371251077362985}, "num_episodes": 27, "episode_return_max": 269.40000000000003, "episode_return_min": -271.29999999999995, "episode_return_mean": -21.606060606060854, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.5490829327427, "num_env_steps_trained_throughput_per_sec": 355.5490829327427, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 11778.052, "restore_workers_time_ms": 0.019, "training_step_time_ms": 11777.995, "sample_time_ms": 1442.317, "learn_time_ms": 10320.465, "learn_throughput": 387.579, "synch_weights_time_ms": 12.679}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-48-08", "timestamp": 1723646888, "time_this_iter_s": 11.289463996887207, "time_total_s": 59.08449578285217, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d3a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 59.08449578285217, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 45.49375, "ram_util_percent": 83.49375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5371679720266787, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.512782613562528, "policy_loss": -0.0022551492212596475, "vf_loss": 8.514476302313426, "vf_explained_var": 0.0077910798882681225, "kl": 0.0056145128787313545, "entropy": 1.5738293603614524, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.297461267249294, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.592601191051423, "policy_loss": -0.008862473756547959, "vf_loss": 7.599824901611086, "vf_explained_var": 0.018005306758577862, "kl": 0.016387521463627604, "entropy": 1.5502318770797163, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 269.40000000000003, "episode_reward_min": -354.599999999999, "episode_reward_mean": -39.47500000000022, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -533.9, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 417.0}, "policy_reward_mean": {"prey_policy": -91.70750000000015, "predator_policy": 71.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [78.80000000000013, 31.100000000000286, -23.999999999999915, 121.09999999999985, -84.00000000000023, -80.10000000000029, -106.00000000000057, 77.7999999999996, -271.29999999999995, -3.3000000000000105, -172.0000000000004, 254.6999999999998, 59.50000000000021, -108.7000000000009, -20.8999999999998, -55.19999999999981, -39.199999999999605, 137.39999999999966, -70.29999999999967, 119.4999999999992, -23.599999999999937, 19.20000000000009, -90.40000000000134, 269.40000000000003, -18.099999999999802, 89.19999999999864, 47.50000000000021, -10.399999999999894, 166.39999999999932, -2.500000000000036, -90.90000000000141, -48.0000000000004, -29.399999999999995, 52.40000000000021, 14.100000000000074, 24.300000000000193, -107.8000000000005, -194.10000000000085, -134.10000000000142, -8.400000000000004, -119.500000000001, -9.200000000000115, -97.60000000000102, 122.39999999999961, -42.19999999999978, 248.3999999999999, 22.400000000000034, 1.2000000000001647, -3.3999999999999453, 65.20000000000022, 63.299999999998974, 62.500000000000114, -102.00000000000097, 26.90000000000013, 36.30000000000029, 3.0000000000000715, -187.40000000000072, 77.69999999999943, -63.09999999999994, -100.90000000000109, -38.799999999999685, -177.40000000000074, -7.899999999999881, -5.999999999999972, -109.6000000000004, -163.8000000000006, -242.90000000000094, -2.499999999999794, -6.199999999999688, -63.899999999999835, 83.49999999999889, 3.2000000000000832, -119.39999999999995, -66.39999999999972, -128.40000000000038, 124.19999999999987, -39.299999999999926, -144.19999999999993, -31.800000000000033, -190.20000000000127, -214.8000000000002, -95.79999999999998, -256.30000000000075, -189.20000000000064, -121.90000000000035, -154.00000000000037, -124.90000000000018, -76.20000000000071, -345.00000000000006, 147.2999999999998, -62.299999999999756, 146.4999999999996, -354.599999999999, -180.8000000000008, -311.2000000000003, 26.000000000000224, -145.70000000000016, -3.0000000000000657, 93.40000000000012, -170.9000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-132.3999999999999, 102.20000000000006, -28.29999999999975, 13.400000000000073, -271.60000000000014, 77.60000000000007, -197.20000000000022, 179.29999999999987, 29.000000000000036, -346.00000000000006, -240.4000000000003, -39.70000000000002, -60.100000000000435, -235.90000000000012, 60.50000000000013, -96.70000000000024, -387.3999999999999, -166.90000000000057, -240.7000000000003, 94.3999999999998, -137.5000000000003, -305.4999999999996, 158.0, 31.699999999999935, 58.70000000000007, -86.20000000000078, -85.90000000000073, -158.80000000000015, -68.49999999999977, -9.400000000000066, -126.7, -119.50000000000054, 17.899999999999988, -129.10000000000068, 197.0, -148.5999999999999, -143.80000000000055, -32.499999999999766, 31.400000000000112, 55.100000000000115, -9.399999999999961, -89.20000000000012, -9.099999999999948, -81.70000000000007, -51.999999999999936, -135.40000000000072, 80.0, 142.3999999999997, -250.89999999999998, 39.80000000000016, 12.499999999999972, 25.700000000000134, 73.1000000000002, -97.60000000000053, -30.999999999999872, -81.40000000000077, 102.49999999999989, 8.899999999999986, 53.9000000000002, -195.40000000000052, -124.90000000000053, -85.0000000000008, -64.00000000000071, -64.00000000000091, -116.20000000000016, -26.199999999999747, 49.69999999999998, -65.30000000000044, -94.60000000000048, 22.70000000000001, 3.7999999999999923, -71.50000000000014, -28.29999999999975, -230.50000000000006, -227.80000000000047, -142.30000000000038, -187.90000000000057, -89.20000000000084, -135.40000000000023, 20.000000000000014, -117.4000000000002, -171.1000000000006, -116.50000000000077, 14.300000000000038, -237.90000000000043, 5.299999999999965, -40.6, 31.999999999999936, 30.500000000000174, -351.6999999999987, 153.8, 41.59999999999985, -146.80000000000052, 12.20000000000003, 25.4000000000001, -68.20000000000087, -31.899999999999935, -128.50000000000037, 62.900000000000134, -57.700000000000024, 19.999999999999964, -33.69999999999991, 63.80000000000003, -28.299999999999763, -22.599999999999774, -227.4000000000005, -63.100000000000556, 20.000000000000014, -21.99999999999978, 26.30000000000016, -196.89999999999998, 20.90000000000003, -263.50000000000034, -124.90000000000018, 56.900000000000226, -62.2000000000006, -271.10000000000036, 38.00000000000018, -225.70000000000044, 0.7999999999999741, -206.2000000000005, 43.400000000000226, -154.3000000000005, -207.1000000000003, -84.69999999999989, -56.19999999999992, 20.000000000000014, -87.9999999999998, -44.49999999999998, -210.10000000000028, -200.20000000000033, -202.60000000000053, -279.39999999999964, -166.5, 20.90000000000003, -108.40000000000077, 3.199999999999965, -51.39999999999995, 28.10000000000015, -235.00000000000017, 61.40000000000016, -55.899999999999885, -92.80000000000072, 20.000000000000014, -240.40000000000032, -7.0000000000001705, -125.8000000000007, -115.60000000000004, -303.39999999999986, -115.00000000000036, 148.69999999999982, -74.49999999999986, 17.899999999999988, -161.19999999999996, -317.70000000000016, 3.5000000000001337, -1.0000000000000515, -101.79999999999995, -133.30000000000064, -145.90000000000063, -149.80000000000018, -358.0000000000001, -66.1, -162.70000000000059, -305.5000000000002, -206.80000000000052, -286.6000000000001, -160.60000000000065, 20.000000000000014, -298.90000000000003, -332.79999999999995, -139.20000000000016, -206.90000000000015, -145.00000000000028, -80.7999999999999, -153.40000000000015, -451.09999999999934, -533.9, 137.89999999999995, -136.6000000000003, 20.000000000000014, -322.30000000000007, 86.60000000000002, 20.900000000000038, -206.80000000000024, -377.79999999999995, -293.80000000000035, -148.0000000000005, -204.0999999999999, -376.09999999999985, -54.399999999999885, 13.399999999999997, -15.699999999999797, -366.0, -274.0, 20.000000000000014, 126.19999999999999, -214.79999999999987, -212.80000000000013, -201.10000000000016], "policy_predator_policy_reward": [89.0, 20.0, 14.0, 32.0, 46.0, 124.0, 26.0, 113.0, 126.0, 107.0, 76.0, 124.0, 133.0, 57.0, 79.0, 35.0, 194.0, 89.0, 122.0, 21.0, 103.0, 168.0, 9.0, 56.0, 36.0, 51.0, 23.0, 113.0, 14.0, 43.0, 107.0, 84.0, 1.0, 71.0, 85.0, 4.0, 78.0, 28.0, 11.0, 22.0, 70.0, 5.0, 73.0, 37.0, 89.0, 8.0, 33.0, 14.0, 116.0, 77.0, 24.0, 27.0, 71.0, 1.0, 43.0, 59.0, 27.0, 28.0, 53.0, 86.0, 85.0, 34.0, 12.0, 68.0, 56.0, 57.0, 56.0, 12.0, 71.0, 15.0, 16.0, 76.0, 107.0, 44.0, 66.0, 110.0, 97.0, 46.0, 71.0, 36.0, 127.0, 42.0, 28.0, 65.0, 106.0, 29.0, 38.0, 93.0, 228.0, 51.0, 17.0, 36.0, 55.0, 102.0, 42.0, 2.0, 76.0, 81.0, 37.0, 23.0, 29.0, 48.0, 14.0, 13.0, 123.0, 25.0, 51.0, 19.0, 19.0, 13.0, 99.0, 80.0, 166.0, 35.0, 34.0, 49.0, 143.0, 27.0, 117.0, 7.0, 43.0, 81.0, 58.0, 126.0, 60.0, 73.0, 46.0, 16.0, 113.0, 32.0, 129.0, 110.0, 57.0, 146.0, 52.0, 33.0, 34.0, 8.0, 125.0, 18.0, 34.0, 44.0, 46.0, 30.0, 126.0, 2.0, 73.0, 102.0, 118.0, 172.0, 39.0, 11.0, 38.0, 66.0, 164.0, 6.0, 19.0, 52.0, 80.0, 9.0, 119.0, 174.0, 88.0, 45.0, 101.0, 155.0, 127.0, 131.0, 87.0, 70.0, 174.0, 144.0, 165.0, 62.0, 31.0, 127.0, 223.0, 417.0, 55.0, 91.0, 157.0, 83.0, 20.0, 19.0, 160.0, 70.0, 83.0, 178.0, 119.0, 150.0, 63.0, 4.0, 184.0, 52.0, 149.0, 102.0, 105.0, 77.0, 149.0, 94.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7300580756266885, "mean_inference_ms": 1.9779782805827273, "mean_action_processing_ms": 0.30282215362476417, "mean_env_wait_ms": 0.2520953256919314, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008563756942749023, "StateBufferConnector_ms": 0.0035325288772583008, "ViewRequirementAgentConnector_ms": 0.09717845916748047}, "num_episodes": 18, "episode_return_max": 269.40000000000003, "episode_return_min": -354.599999999999, "episode_return_mean": -39.47500000000022, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.549040210266, "num_env_steps_trained_throughput_per_sec": 348.549040210266, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 11727.736, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11727.681, "sample_time_ms": 1432.428, "learn_time_ms": 10280.398, "learn_throughput": 389.09, "synch_weights_time_ms": 12.466}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-48-20", "timestamp": 1723646900, "time_this_iter_s": 11.530386924743652, "time_total_s": 70.61488270759583, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede9280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 70.61488270759583, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 45.411764705882355, "ram_util_percent": 83.59411764705882}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6058211253118262, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.858720294003763, "policy_loss": -0.0047937391870334824, "vf_loss": 8.862100589843024, "vf_explained_var": 0.03477992109520726, "kl": 0.014134197882523177, "entropy": 1.5827479722007873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4429249210017068, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.249928254172915, "policy_loss": -0.007119802528469966, "vf_loss": 7.255995548843707, "vf_explained_var": -0.0036577993284457573, "kl": 0.010525069772342412, "entropy": 1.566843384346634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 269.40000000000003, "episode_reward_min": -354.599999999999, "episode_reward_mean": -43.04800000000021, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -533.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.9, "predator_policy": 417.0}, "policy_reward_mean": {"prey_policy": -96.40900000000012, "predator_policy": 74.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-70.29999999999967, 119.4999999999992, -23.599999999999937, 19.20000000000009, -90.40000000000134, 269.40000000000003, -18.099999999999802, 89.19999999999864, 47.50000000000021, -10.399999999999894, 166.39999999999932, -2.500000000000036, -90.90000000000141, -48.0000000000004, -29.399999999999995, 52.40000000000021, 14.100000000000074, 24.300000000000193, -107.8000000000005, -194.10000000000085, -134.10000000000142, -8.400000000000004, -119.500000000001, -9.200000000000115, -97.60000000000102, 122.39999999999961, -42.19999999999978, 248.3999999999999, 22.400000000000034, 1.2000000000001647, -3.3999999999999453, 65.20000000000022, 63.299999999998974, 62.500000000000114, -102.00000000000097, 26.90000000000013, 36.30000000000029, 3.0000000000000715, -187.40000000000072, 77.69999999999943, -63.09999999999994, -100.90000000000109, -38.799999999999685, -177.40000000000074, -7.899999999999881, -5.999999999999972, -109.6000000000004, -163.8000000000006, -242.90000000000094, -2.499999999999794, -6.199999999999688, -63.899999999999835, 83.49999999999889, 3.2000000000000832, -119.39999999999995, -66.39999999999972, -128.40000000000038, 124.19999999999987, -39.299999999999926, -144.19999999999993, -31.800000000000033, -190.20000000000127, -214.8000000000002, -95.79999999999998, -256.30000000000075, -189.20000000000064, -121.90000000000035, -154.00000000000037, -124.90000000000018, -76.20000000000071, -345.00000000000006, 147.2999999999998, -62.299999999999756, 146.4999999999996, -354.599999999999, -180.8000000000008, -311.2000000000003, 26.000000000000224, -145.70000000000016, -3.0000000000000657, 93.40000000000012, -170.9000000000003, 32.00000000000028, -319.99999999999886, 83.89999999999989, -166.40000000000003, 15.100000000000144, 113.09999999999985, -257.89999999999986, 71.9, 5.300000000000327, 163.79999999999953, -24.49999999999995, 144.0, -8.899999999999984, 105.49999999999935, -214.2, -218.90000000000094, -213.7000000000005, 128.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-143.80000000000055, -32.499999999999766, 31.400000000000112, 55.100000000000115, -9.399999999999961, -89.20000000000012, -9.099999999999948, -81.70000000000007, -51.999999999999936, -135.40000000000072, 80.0, 142.3999999999997, -250.89999999999998, 39.80000000000016, 12.499999999999972, 25.700000000000134, 73.1000000000002, -97.60000000000053, -30.999999999999872, -81.40000000000077, 102.49999999999989, 8.899999999999986, 53.9000000000002, -195.40000000000052, -124.90000000000053, -85.0000000000008, -64.00000000000071, -64.00000000000091, -116.20000000000016, -26.199999999999747, 49.69999999999998, -65.30000000000044, -94.60000000000048, 22.70000000000001, 3.7999999999999923, -71.50000000000014, -28.29999999999975, -230.50000000000006, -227.80000000000047, -142.30000000000038, -187.90000000000057, -89.20000000000084, -135.40000000000023, 20.000000000000014, -117.4000000000002, -171.1000000000006, -116.50000000000077, 14.300000000000038, -237.90000000000043, 5.299999999999965, -40.6, 31.999999999999936, 30.500000000000174, -351.6999999999987, 153.8, 41.59999999999985, -146.80000000000052, 12.20000000000003, 25.4000000000001, -68.20000000000087, -31.899999999999935, -128.50000000000037, 62.900000000000134, -57.700000000000024, 19.999999999999964, -33.69999999999991, 63.80000000000003, -28.299999999999763, -22.599999999999774, -227.4000000000005, -63.100000000000556, 20.000000000000014, -21.99999999999978, 26.30000000000016, -196.89999999999998, 20.90000000000003, -263.50000000000034, -124.90000000000018, 56.900000000000226, -62.2000000000006, -271.10000000000036, 38.00000000000018, -225.70000000000044, 0.7999999999999741, -206.2000000000005, 43.400000000000226, -154.3000000000005, -207.1000000000003, -84.69999999999989, -56.19999999999992, 20.000000000000014, -87.9999999999998, -44.49999999999998, -210.10000000000028, -200.20000000000033, -202.60000000000053, -279.39999999999964, -166.5, 20.90000000000003, -108.40000000000077, 3.199999999999965, -51.39999999999995, 28.10000000000015, -235.00000000000017, 61.40000000000016, -55.899999999999885, -92.80000000000072, 20.000000000000014, -240.40000000000032, -7.0000000000001705, -125.8000000000007, -115.60000000000004, -303.39999999999986, -115.00000000000036, 148.69999999999982, -74.49999999999986, 17.899999999999988, -161.19999999999996, -317.70000000000016, 3.5000000000001337, -1.0000000000000515, -101.79999999999995, -133.30000000000064, -145.90000000000063, -149.80000000000018, -358.0000000000001, -66.1, -162.70000000000059, -305.5000000000002, -206.80000000000052, -286.6000000000001, -160.60000000000065, 20.000000000000014, -298.90000000000003, -332.79999999999995, -139.20000000000016, -206.90000000000015, -145.00000000000028, -80.7999999999999, -153.40000000000015, -451.09999999999934, -533.9, 137.89999999999995, -136.6000000000003, 20.000000000000014, -322.30000000000007, 86.60000000000002, 20.900000000000038, -206.80000000000024, -377.79999999999995, -293.80000000000035, -148.0000000000005, -204.0999999999999, -376.09999999999985, -54.399999999999885, 13.399999999999997, -15.699999999999797, -366.0, -274.0, 20.000000000000014, 126.19999999999999, -214.79999999999987, -212.80000000000013, -201.10000000000016, -124.00000000000031, 23.000000000000192, -265.0000000000002, -295.0000000000001, -198.40000000000032, 161.29999999999998, -153.09999999999994, -253.3000000000001, -86.80000000000001, -24.099999999999746, -223.2000000000005, 179.30000000000004, -301.29999999999893, -160.60000000000065, -504.0, 110.89999999999992, -40.300000000000075, -24.399999999999856, 182.9, -57.10000000000006, -98.00000000000003, -56.50000000000028, 104.9, -70.9, -17.499999999999893, -151.39999999999992, -7.600000000000032, 52.10000000000007, -103.59999999999997, -284.5999999999999, -215.2000000000005, -273.69999999999925, -237.90000000000043, -251.80000000000007, -138.50000000000003, 63.8], "policy_predator_policy_reward": [78.0, 28.0, 11.0, 22.0, 70.0, 5.0, 73.0, 37.0, 89.0, 8.0, 33.0, 14.0, 116.0, 77.0, 24.0, 27.0, 71.0, 1.0, 43.0, 59.0, 27.0, 28.0, 53.0, 86.0, 85.0, 34.0, 12.0, 68.0, 56.0, 57.0, 56.0, 12.0, 71.0, 15.0, 16.0, 76.0, 107.0, 44.0, 66.0, 110.0, 97.0, 46.0, 71.0, 36.0, 127.0, 42.0, 28.0, 65.0, 106.0, 29.0, 38.0, 93.0, 228.0, 51.0, 17.0, 36.0, 55.0, 102.0, 42.0, 2.0, 76.0, 81.0, 37.0, 23.0, 29.0, 48.0, 14.0, 13.0, 123.0, 25.0, 51.0, 19.0, 19.0, 13.0, 99.0, 80.0, 166.0, 35.0, 34.0, 49.0, 143.0, 27.0, 117.0, 7.0, 43.0, 81.0, 58.0, 126.0, 60.0, 73.0, 46.0, 16.0, 113.0, 32.0, 129.0, 110.0, 57.0, 146.0, 52.0, 33.0, 34.0, 8.0, 125.0, 18.0, 34.0, 44.0, 46.0, 30.0, 126.0, 2.0, 73.0, 102.0, 118.0, 172.0, 39.0, 11.0, 38.0, 66.0, 164.0, 6.0, 19.0, 52.0, 80.0, 9.0, 119.0, 174.0, 88.0, 45.0, 101.0, 155.0, 127.0, 131.0, 87.0, 70.0, 174.0, 144.0, 165.0, 62.0, 31.0, 127.0, 223.0, 417.0, 55.0, 91.0, 157.0, 83.0, 20.0, 19.0, 160.0, 70.0, 83.0, 178.0, 119.0, 150.0, 63.0, 4.0, 184.0, 52.0, 149.0, 102.0, 105.0, 77.0, 149.0, 94.0, 81.0, 52.0, 138.0, 102.0, 19.0, 102.0, 146.0, 94.0, 15.0, 111.0, 36.0, 121.0, 35.0, 169.0, 188.0, 277.0, 36.0, 34.0, 0.0, 38.0, 101.0, 29.0, 29.0, 81.0, 34.0, 126.0, 15.0, 46.0, 174.0, 0.0, 79.0, 191.0, 109.0, 167.0, 92.0, 111.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7045156240299221, "mean_inference_ms": 1.891549958842205, "mean_action_processing_ms": 0.2897745958400766, "mean_env_wait_ms": 0.24248806737306033, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008226394653320312, "StateBufferConnector_ms": 0.0035399198532104492, "ViewRequirementAgentConnector_ms": 0.10624217987060547}, "num_episodes": 18, "episode_return_max": 269.40000000000003, "episode_return_min": -354.599999999999, "episode_return_mean": -43.04800000000021, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.75950597568215, "num_env_steps_trained_throughput_per_sec": 352.75950597568215, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 11672.227, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11672.174, "sample_time_ms": 1411.553, "learn_time_ms": 10245.984, "learn_throughput": 390.397, "synch_weights_time_ms": 12.432}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-48-31", "timestamp": 1723646911, "time_this_iter_s": 11.392730951309204, "time_total_s": 82.00761365890503, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32eddb0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 82.00761365890503, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 45.15625, "ram_util_percent": 83.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9162250997055144, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.551655830908074, "policy_loss": -0.009358255830519493, "vf_loss": 7.558854384397073, "vf_explained_var": 0.05876583409687829, "kl": 0.02159716189911027, "entropy": 1.5873336012401278, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2643484453517924, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.330107181917422, "policy_loss": -0.00514322198316376, "vf_loss": 5.334249955888779, "vf_explained_var": 0.005201264380147217, "kl": 0.010004670831023967, "entropy": 1.5369445521995504, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 248.3999999999999, "episode_reward_min": -354.599999999999, "episode_reward_mean": -41.772000000000226, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -533.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.9, "predator_policy": 417.0}, "policy_reward_mean": {"prey_policy": -104.4760000000001, "predator_policy": 83.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-107.8000000000005, -194.10000000000085, -134.10000000000142, -8.400000000000004, -119.500000000001, -9.200000000000115, -97.60000000000102, 122.39999999999961, -42.19999999999978, 248.3999999999999, 22.400000000000034, 1.2000000000001647, -3.3999999999999453, 65.20000000000022, 63.299999999998974, 62.500000000000114, -102.00000000000097, 26.90000000000013, 36.30000000000029, 3.0000000000000715, -187.40000000000072, 77.69999999999943, -63.09999999999994, -100.90000000000109, -38.799999999999685, -177.40000000000074, -7.899999999999881, -5.999999999999972, -109.6000000000004, -163.8000000000006, -242.90000000000094, -2.499999999999794, -6.199999999999688, -63.899999999999835, 83.49999999999889, 3.2000000000000832, -119.39999999999995, -66.39999999999972, -128.40000000000038, 124.19999999999987, -39.299999999999926, -144.19999999999993, -31.800000000000033, -190.20000000000127, -214.8000000000002, -95.79999999999998, -256.30000000000075, -189.20000000000064, -121.90000000000035, -154.00000000000037, -124.90000000000018, -76.20000000000071, -345.00000000000006, 147.2999999999998, -62.299999999999756, 146.4999999999996, -354.599999999999, -180.8000000000008, -311.2000000000003, 26.000000000000224, -145.70000000000016, -3.0000000000000657, 93.40000000000012, -170.9000000000003, 32.00000000000028, -319.99999999999886, 83.89999999999989, -166.40000000000003, 15.100000000000144, 113.09999999999985, -257.89999999999986, 71.9, 5.300000000000327, 163.79999999999953, -24.49999999999995, 144.0, -8.899999999999984, 105.49999999999935, -214.2, -218.90000000000094, -213.7000000000005, 128.29999999999995, 79.10000000000004, -89.00000000000043, 73.09999999999982, -95.80000000000045, -71.00000000000063, 40.1000000000001, 54.800000000000054, 154.89999999999864, 16.800000000000068, 150.29999999999944, -92.70000000000113, -60.899999999999864, 94.79999999999961, 6.900000000000192, -7.4999999999998295, 147.4999999999999, 3.399999999999629, 141.1999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.29999999999975, -230.50000000000006, -227.80000000000047, -142.30000000000038, -187.90000000000057, -89.20000000000084, -135.40000000000023, 20.000000000000014, -117.4000000000002, -171.1000000000006, -116.50000000000077, 14.300000000000038, -237.90000000000043, 5.299999999999965, -40.6, 31.999999999999936, 30.500000000000174, -351.6999999999987, 153.8, 41.59999999999985, -146.80000000000052, 12.20000000000003, 25.4000000000001, -68.20000000000087, -31.899999999999935, -128.50000000000037, 62.900000000000134, -57.700000000000024, 19.999999999999964, -33.69999999999991, 63.80000000000003, -28.299999999999763, -22.599999999999774, -227.4000000000005, -63.100000000000556, 20.000000000000014, -21.99999999999978, 26.30000000000016, -196.89999999999998, 20.90000000000003, -263.50000000000034, -124.90000000000018, 56.900000000000226, -62.2000000000006, -271.10000000000036, 38.00000000000018, -225.70000000000044, 0.7999999999999741, -206.2000000000005, 43.400000000000226, -154.3000000000005, -207.1000000000003, -84.69999999999989, -56.19999999999992, 20.000000000000014, -87.9999999999998, -44.49999999999998, -210.10000000000028, -200.20000000000033, -202.60000000000053, -279.39999999999964, -166.5, 20.90000000000003, -108.40000000000077, 3.199999999999965, -51.39999999999995, 28.10000000000015, -235.00000000000017, 61.40000000000016, -55.899999999999885, -92.80000000000072, 20.000000000000014, -240.40000000000032, -7.0000000000001705, -125.8000000000007, -115.60000000000004, -303.39999999999986, -115.00000000000036, 148.69999999999982, -74.49999999999986, 17.899999999999988, -161.19999999999996, -317.70000000000016, 3.5000000000001337, -1.0000000000000515, -101.79999999999995, -133.30000000000064, -145.90000000000063, -149.80000000000018, -358.0000000000001, -66.1, -162.70000000000059, -305.5000000000002, -206.80000000000052, -286.6000000000001, -160.60000000000065, 20.000000000000014, -298.90000000000003, -332.79999999999995, -139.20000000000016, -206.90000000000015, -145.00000000000028, -80.7999999999999, -153.40000000000015, -451.09999999999934, -533.9, 137.89999999999995, -136.6000000000003, 20.000000000000014, -322.30000000000007, 86.60000000000002, 20.900000000000038, -206.80000000000024, -377.79999999999995, -293.80000000000035, -148.0000000000005, -204.0999999999999, -376.09999999999985, -54.399999999999885, 13.399999999999997, -15.699999999999797, -366.0, -274.0, 20.000000000000014, 126.19999999999999, -214.79999999999987, -212.80000000000013, -201.10000000000016, -124.00000000000031, 23.000000000000192, -265.0000000000002, -295.0000000000001, -198.40000000000032, 161.29999999999998, -153.09999999999994, -253.3000000000001, -86.80000000000001, -24.099999999999746, -223.2000000000005, 179.30000000000004, -301.29999999999893, -160.60000000000065, -504.0, 110.89999999999992, -40.300000000000075, -24.399999999999856, 182.9, -57.10000000000006, -98.00000000000003, -56.50000000000028, 104.9, -70.9, -17.499999999999893, -151.39999999999992, -7.600000000000032, 52.10000000000007, -103.59999999999997, -284.5999999999999, -215.2000000000005, -273.69999999999925, -237.90000000000043, -251.80000000000007, -138.50000000000003, 63.8, -373.3999999999993, 147.49999999999977, -82.90000000000012, -183.10000000000034, -182.19999999999996, 116.2999999999999, -280.29999999999984, -29.499999999999766, -60.1000000000001, -208.90000000000052, -67.60000000000076, 7.699999999999989, 158.59999999999994, -332.7999999999995, 46.400000000000055, 84.50000000000017, 171.79999999999984, -315.9999999999997, 140.5999999999999, -28.29999999999975, -38.799999999999756, -401.9, -225.3000000000002, -31.599999999999838, -147.70000000000053, 96.49999999999997, -7.299999999999891, -119.79999999999997, -434.59999999999997, 52.099999999999966, 5.299999999999885, 87.19999999999985, 52.700000000000124, -441.30000000000007, 118.10000000000002, -124.90000000000052], "policy_predator_policy_reward": [107.0, 44.0, 66.0, 110.0, 97.0, 46.0, 71.0, 36.0, 127.0, 42.0, 28.0, 65.0, 106.0, 29.0, 38.0, 93.0, 228.0, 51.0, 17.0, 36.0, 55.0, 102.0, 42.0, 2.0, 76.0, 81.0, 37.0, 23.0, 29.0, 48.0, 14.0, 13.0, 123.0, 25.0, 51.0, 19.0, 19.0, 13.0, 99.0, 80.0, 166.0, 35.0, 34.0, 49.0, 143.0, 27.0, 117.0, 7.0, 43.0, 81.0, 58.0, 126.0, 60.0, 73.0, 46.0, 16.0, 113.0, 32.0, 129.0, 110.0, 57.0, 146.0, 52.0, 33.0, 34.0, 8.0, 125.0, 18.0, 34.0, 44.0, 46.0, 30.0, 126.0, 2.0, 73.0, 102.0, 118.0, 172.0, 39.0, 11.0, 38.0, 66.0, 164.0, 6.0, 19.0, 52.0, 80.0, 9.0, 119.0, 174.0, 88.0, 45.0, 101.0, 155.0, 127.0, 131.0, 87.0, 70.0, 174.0, 144.0, 165.0, 62.0, 31.0, 127.0, 223.0, 417.0, 55.0, 91.0, 157.0, 83.0, 20.0, 19.0, 160.0, 70.0, 83.0, 178.0, 119.0, 150.0, 63.0, 4.0, 184.0, 52.0, 149.0, 102.0, 105.0, 77.0, 149.0, 94.0, 81.0, 52.0, 138.0, 102.0, 19.0, 102.0, 146.0, 94.0, 15.0, 111.0, 36.0, 121.0, 35.0, 169.0, 188.0, 277.0, 36.0, 34.0, 0.0, 38.0, 101.0, 29.0, 29.0, 81.0, 34.0, 126.0, 15.0, 46.0, 174.0, 0.0, 79.0, 191.0, 109.0, 167.0, 92.0, 111.0, 248.0, 57.0, 123.0, 54.0, 3.0, 136.0, 141.0, 73.0, 100.0, 98.0, 32.0, 68.0, 89.0, 140.0, 10.0, 14.0, 160.0, 1.0, 15.0, 23.0, 203.0, 145.0, 34.0, 162.0, 87.0, 59.0, 64.0, 70.0, 195.0, 180.0, 25.0, 30.0, 189.0, 203.0, 70.0, 78.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6913807145089343, "mean_inference_ms": 1.842224793848259, "mean_action_processing_ms": 0.2824469158815099, "mean_env_wait_ms": 0.2363689064604101, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007672905921936035, "StateBufferConnector_ms": 0.003527522087097168, "ViewRequirementAgentConnector_ms": 0.1083458662033081}, "num_episodes": 18, "episode_return_max": 248.3999999999999, "episode_return_min": -354.599999999999, "episode_return_mean": -41.772000000000226, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.43824313119626, "num_env_steps_trained_throughput_per_sec": 349.43824313119626, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 11644.068, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11644.016, "sample_time_ms": 1382.05, "learn_time_ms": 10247.125, "learn_throughput": 390.353, "synch_weights_time_ms": 12.399}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-48-43", "timestamp": 1723646923, "time_this_iter_s": 11.494084119796753, "time_total_s": 93.50169777870178, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d3dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 93.50169777870178, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 47.0, "ram_util_percent": 83.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0179498600896704, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.928465340629456, "policy_loss": -0.006156695053528344, "vf_loss": 6.932870439499143, "vf_explained_var": 0.07422193348723113, "kl": 0.011677327797471408, "entropy": 1.574893392141534, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1811906723276018, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.091203683141678, "policy_loss": -0.009373622136831126, "vf_loss": 3.099290698419803, "vf_explained_var": -0.005256976747008228, "kl": 0.01286609896852186, "entropy": 1.5505935995036333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 171.7999999999994, "episode_reward_min": -354.599999999999, "episode_reward_mean": -29.572000000000177, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -533.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.9, "predator_policy": 417.0}, "policy_reward_mean": {"prey_policy": -95.02100000000007, "predator_policy": 80.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.09999999999994, -100.90000000000109, -38.799999999999685, -177.40000000000074, -7.899999999999881, -5.999999999999972, -109.6000000000004, -163.8000000000006, -242.90000000000094, -2.499999999999794, -6.199999999999688, -63.899999999999835, 83.49999999999889, 3.2000000000000832, -119.39999999999995, -66.39999999999972, -128.40000000000038, 124.19999999999987, -39.299999999999926, -144.19999999999993, -31.800000000000033, -190.20000000000127, -214.8000000000002, -95.79999999999998, -256.30000000000075, -189.20000000000064, -121.90000000000035, -154.00000000000037, -124.90000000000018, -76.20000000000071, -345.00000000000006, 147.2999999999998, -62.299999999999756, 146.4999999999996, -354.599999999999, -180.8000000000008, -311.2000000000003, 26.000000000000224, -145.70000000000016, -3.0000000000000657, 93.40000000000012, -170.9000000000003, 32.00000000000028, -319.99999999999886, 83.89999999999989, -166.40000000000003, 15.100000000000144, 113.09999999999985, -257.89999999999986, 71.9, 5.300000000000327, 163.79999999999953, -24.49999999999995, 144.0, -8.899999999999984, 105.49999999999935, -214.2, -218.90000000000094, -213.7000000000005, 128.29999999999995, 79.10000000000004, -89.00000000000043, 73.09999999999982, -95.80000000000045, -71.00000000000063, 40.1000000000001, 54.800000000000054, 154.89999999999864, 16.800000000000068, 150.29999999999944, -92.70000000000113, -60.899999999999864, 94.79999999999961, 6.900000000000192, -7.4999999999998295, 147.4999999999999, 3.399999999999629, 141.1999999999995, -54.39999999999983, 60.200000000000294, 49.10000000000006, 45.10000000000012, 51.10000000000009, 145.09999999999928, 4.900000000000128, 141.9999999999997, 0.4000000000002356, 154.3999999999995, 171.7999999999994, -52.800000000000026, -40.0000000000004, 90.80000000000015, 37.100000000000094, 56.90000000000027, -46.799999999999805, -58.500000000000945, 123.69999999999894, 51.40000000000034, -21.800000000000345, 33.90000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-271.10000000000036, 38.00000000000018, -225.70000000000044, 0.7999999999999741, -206.2000000000005, 43.400000000000226, -154.3000000000005, -207.1000000000003, -84.69999999999989, -56.19999999999992, 20.000000000000014, -87.9999999999998, -44.49999999999998, -210.10000000000028, -200.20000000000033, -202.60000000000053, -279.39999999999964, -166.5, 20.90000000000003, -108.40000000000077, 3.199999999999965, -51.39999999999995, 28.10000000000015, -235.00000000000017, 61.40000000000016, -55.899999999999885, -92.80000000000072, 20.000000000000014, -240.40000000000032, -7.0000000000001705, -125.8000000000007, -115.60000000000004, -303.39999999999986, -115.00000000000036, 148.69999999999982, -74.49999999999986, 17.899999999999988, -161.19999999999996, -317.70000000000016, 3.5000000000001337, -1.0000000000000515, -101.79999999999995, -133.30000000000064, -145.90000000000063, -149.80000000000018, -358.0000000000001, -66.1, -162.70000000000059, -305.5000000000002, -206.80000000000052, -286.6000000000001, -160.60000000000065, 20.000000000000014, -298.90000000000003, -332.79999999999995, -139.20000000000016, -206.90000000000015, -145.00000000000028, -80.7999999999999, -153.40000000000015, -451.09999999999934, -533.9, 137.89999999999995, -136.6000000000003, 20.000000000000014, -322.30000000000007, 86.60000000000002, 20.900000000000038, -206.80000000000024, -377.79999999999995, -293.80000000000035, -148.0000000000005, -204.0999999999999, -376.09999999999985, -54.399999999999885, 13.399999999999997, -15.699999999999797, -366.0, -274.0, 20.000000000000014, 126.19999999999999, -214.79999999999987, -212.80000000000013, -201.10000000000016, -124.00000000000031, 23.000000000000192, -265.0000000000002, -295.0000000000001, -198.40000000000032, 161.29999999999998, -153.09999999999994, -253.3000000000001, -86.80000000000001, -24.099999999999746, -223.2000000000005, 179.30000000000004, -301.29999999999893, -160.60000000000065, -504.0, 110.89999999999992, -40.300000000000075, -24.399999999999856, 182.9, -57.10000000000006, -98.00000000000003, -56.50000000000028, 104.9, -70.9, -17.499999999999893, -151.39999999999992, -7.600000000000032, 52.10000000000007, -103.59999999999997, -284.5999999999999, -215.2000000000005, -273.69999999999925, -237.90000000000043, -251.80000000000007, -138.50000000000003, 63.8, -373.3999999999993, 147.49999999999977, -82.90000000000012, -183.10000000000034, -182.19999999999996, 116.2999999999999, -280.29999999999984, -29.499999999999766, -60.1000000000001, -208.90000000000052, -67.60000000000076, 7.699999999999989, 158.59999999999994, -332.7999999999995, 46.400000000000055, 84.50000000000017, 171.79999999999984, -315.9999999999997, 140.5999999999999, -28.29999999999975, -38.799999999999756, -401.9, -225.3000000000002, -31.599999999999838, -147.70000000000053, 96.49999999999997, -7.299999999999891, -119.79999999999997, -434.59999999999997, 52.099999999999966, 5.299999999999885, 87.19999999999985, 52.700000000000124, -441.30000000000007, 118.10000000000002, -124.90000000000052, -63.399999999999984, -64.00000000000004, 117.19999999999956, -127.0000000000006, -49.0, -25.8999999999999, -22.299999999999763, 31.400000000000034, 28.700000000000088, -139.6000000000001, 5.900000000000041, 78.19999999999982, -5.1999999999999265, -34.899999999999785, 64.70000000000013, 20.30000000000002, -32.49999999999975, -3.099999999999965, 76.09999999999954, 29.300000000000097, 19.70000000000006, 109.09999999999991, 82.09999999999964, -308.8999999999996, -234.09999999999974, 64.10000000000011, -36.699999999999754, 93.50000000000009, -219.40000000000015, 84.49999999999989, -89.20000000000078, 79.09999999999957, -370.79999999999995, 44.000000000000064, -51.399999999999906, -183.10000000000056, 20.000000000000014, 91.69999999999958, 16.40000000000002, 20.000000000000014, 12.499999999999968, -136.30000000000027, 25.39999999999999, -74.50000000000088], "policy_predator_policy_reward": [143.0, 27.0, 117.0, 7.0, 43.0, 81.0, 58.0, 126.0, 60.0, 73.0, 46.0, 16.0, 113.0, 32.0, 129.0, 110.0, 57.0, 146.0, 52.0, 33.0, 34.0, 8.0, 125.0, 18.0, 34.0, 44.0, 46.0, 30.0, 126.0, 2.0, 73.0, 102.0, 118.0, 172.0, 39.0, 11.0, 38.0, 66.0, 164.0, 6.0, 19.0, 52.0, 80.0, 9.0, 119.0, 174.0, 88.0, 45.0, 101.0, 155.0, 127.0, 131.0, 87.0, 70.0, 174.0, 144.0, 165.0, 62.0, 31.0, 127.0, 223.0, 417.0, 55.0, 91.0, 157.0, 83.0, 20.0, 19.0, 160.0, 70.0, 83.0, 178.0, 119.0, 150.0, 63.0, 4.0, 184.0, 52.0, 149.0, 102.0, 105.0, 77.0, 149.0, 94.0, 81.0, 52.0, 138.0, 102.0, 19.0, 102.0, 146.0, 94.0, 15.0, 111.0, 36.0, 121.0, 35.0, 169.0, 188.0, 277.0, 36.0, 34.0, 0.0, 38.0, 101.0, 29.0, 29.0, 81.0, 34.0, 126.0, 15.0, 46.0, 174.0, 0.0, 79.0, 191.0, 109.0, 167.0, 92.0, 111.0, 248.0, 57.0, 123.0, 54.0, 3.0, 136.0, 141.0, 73.0, 100.0, 98.0, 32.0, 68.0, 89.0, 140.0, 10.0, 14.0, 160.0, 1.0, 15.0, 23.0, 203.0, 145.0, 34.0, 162.0, 87.0, 59.0, 64.0, 70.0, 195.0, 180.0, 25.0, 30.0, 189.0, 203.0, 70.0, 78.0, 73.0, 0.0, 68.0, 2.0, 49.0, 75.0, 3.0, 33.0, 68.0, 94.0, 25.0, 36.0, 12.0, 33.0, 38.0, 19.0, 25.0, 11.0, 38.0, 11.0, 24.0, 19.0, 17.0, 157.0, 0.0, 130.0, 7.0, 27.0, 72.0, 100.0, 48.0, 19.0, 229.0, 51.0, 83.0, 93.0, 7.0, 5.0, 12.0, 3.0, 4.0, 98.0, 19.0, 64.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.683190777003529, "mean_inference_ms": 1.8029539897006719, "mean_action_processing_ms": 0.2757749024985297, "mean_env_wait_ms": 0.23123943940708663, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005525827407836914, "StateBufferConnector_ms": 0.0035398006439208984, "ViewRequirementAgentConnector_ms": 0.11113440990447998}, "num_episodes": 22, "episode_return_max": 171.7999999999994, "episode_return_min": -354.599999999999, "episode_return_mean": -29.572000000000177, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.70947132695954, "num_env_steps_trained_throughput_per_sec": 347.70947132695954, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 11628.49, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11628.439, "sample_time_ms": 1364.426, "learn_time_ms": 10249.223, "learn_throughput": 390.273, "synch_weights_time_ms": 12.458}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-48-55", "timestamp": 1723646935, "time_this_iter_s": 11.54997706413269, "time_total_s": 105.05167484283447, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed91b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 105.05167484283447, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 46.023529411764706, "ram_util_percent": 83.3235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9592919805062512, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.66929665797602, "policy_loss": -0.0072579650338936265, "vf_loss": 7.67487765544306, "vf_explained_var": 0.14424551094650592, "kl": 0.011179745414523578, "entropy": 1.5803878171734078, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.300429170346134, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.888030696356738, "policy_loss": -0.007998214493796387, "vf_loss": 2.895081860552389, "vf_explained_var": 0.022387225854964485, "kl": 0.009470427477162235, "entropy": 1.5631775806820583, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 292.90000000000055, "episode_reward_min": -354.599999999999, "episode_reward_mean": 13.442999999999829, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -533.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.9, "predator_policy": 417.0}, "policy_reward_mean": {"prey_policy": -64.98850000000006, "predator_policy": 71.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-95.79999999999998, -256.30000000000075, -189.20000000000064, -121.90000000000035, -154.00000000000037, -124.90000000000018, -76.20000000000071, -345.00000000000006, 147.2999999999998, -62.299999999999756, 146.4999999999996, -354.599999999999, -180.8000000000008, -311.2000000000003, 26.000000000000224, -145.70000000000016, -3.0000000000000657, 93.40000000000012, -170.9000000000003, 32.00000000000028, -319.99999999999886, 83.89999999999989, -166.40000000000003, 15.100000000000144, 113.09999999999985, -257.89999999999986, 71.9, 5.300000000000327, 163.79999999999953, -24.49999999999995, 144.0, -8.899999999999984, 105.49999999999935, -214.2, -218.90000000000094, -213.7000000000005, 128.29999999999995, 79.10000000000004, -89.00000000000043, 73.09999999999982, -95.80000000000045, -71.00000000000063, 40.1000000000001, 54.800000000000054, 154.89999999999864, 16.800000000000068, 150.29999999999944, -92.70000000000113, -60.899999999999864, 94.79999999999961, 6.900000000000192, -7.4999999999998295, 147.4999999999999, 3.399999999999629, 141.1999999999995, -54.39999999999983, 60.200000000000294, 49.10000000000006, 45.10000000000012, 51.10000000000009, 145.09999999999928, 4.900000000000128, 141.9999999999997, 0.4000000000002356, 154.3999999999995, 171.7999999999994, -52.800000000000026, -40.0000000000004, 90.80000000000015, 37.100000000000094, 56.90000000000027, -46.799999999999805, -58.500000000000945, 123.69999999999894, 51.40000000000034, -21.800000000000345, 33.90000000000024, 162.99999999999957, -121.40000000000151, 100.79999999999892, -14.299999999999793, 280.8999999999999, 124.9, 285.6, 82.6, 262.0, 285.5000000000003, 76.5999999999999, -144.3000000000012, 6.700000000000197, 41.60000000000036, 91.89999999999935, -21.700000000000117, 124.09999999999931, 254.49999999999966, 89.30000000000013, -8.69999999999987, 123.89999999999957, 218.4999999999999, 292.90000000000055], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-66.1, -162.70000000000059, -305.5000000000002, -206.80000000000052, -286.6000000000001, -160.60000000000065, 20.000000000000014, -298.90000000000003, -332.79999999999995, -139.20000000000016, -206.90000000000015, -145.00000000000028, -80.7999999999999, -153.40000000000015, -451.09999999999934, -533.9, 137.89999999999995, -136.6000000000003, 20.000000000000014, -322.30000000000007, 86.60000000000002, 20.900000000000038, -206.80000000000024, -377.79999999999995, -293.80000000000035, -148.0000000000005, -204.0999999999999, -376.09999999999985, -54.399999999999885, 13.399999999999997, -15.699999999999797, -366.0, -274.0, 20.000000000000014, 126.19999999999999, -214.79999999999987, -212.80000000000013, -201.10000000000016, -124.00000000000031, 23.000000000000192, -265.0000000000002, -295.0000000000001, -198.40000000000032, 161.29999999999998, -153.09999999999994, -253.3000000000001, -86.80000000000001, -24.099999999999746, -223.2000000000005, 179.30000000000004, -301.29999999999893, -160.60000000000065, -504.0, 110.89999999999992, -40.300000000000075, -24.399999999999856, 182.9, -57.10000000000006, -98.00000000000003, -56.50000000000028, 104.9, -70.9, -17.499999999999893, -151.39999999999992, -7.600000000000032, 52.10000000000007, -103.59999999999997, -284.5999999999999, -215.2000000000005, -273.69999999999925, -237.90000000000043, -251.80000000000007, -138.50000000000003, 63.8, -373.3999999999993, 147.49999999999977, -82.90000000000012, -183.10000000000034, -182.19999999999996, 116.2999999999999, -280.29999999999984, -29.499999999999766, -60.1000000000001, -208.90000000000052, -67.60000000000076, 7.699999999999989, 158.59999999999994, -332.7999999999995, 46.400000000000055, 84.50000000000017, 171.79999999999984, -315.9999999999997, 140.5999999999999, -28.29999999999975, -38.799999999999756, -401.9, -225.3000000000002, -31.599999999999838, -147.70000000000053, 96.49999999999997, -7.299999999999891, -119.79999999999997, -434.59999999999997, 52.099999999999966, 5.299999999999885, 87.19999999999985, 52.700000000000124, -441.30000000000007, 118.10000000000002, -124.90000000000052, -63.399999999999984, -64.00000000000004, 117.19999999999956, -127.0000000000006, -49.0, -25.8999999999999, -22.299999999999763, 31.400000000000034, 28.700000000000088, -139.6000000000001, 5.900000000000041, 78.19999999999982, -5.1999999999999265, -34.899999999999785, 64.70000000000013, 20.30000000000002, -32.49999999999975, -3.099999999999965, 76.09999999999954, 29.300000000000097, 19.70000000000006, 109.09999999999991, 82.09999999999964, -308.8999999999996, -234.09999999999974, 64.10000000000011, -36.699999999999754, 93.50000000000009, -219.40000000000015, 84.49999999999989, -89.20000000000078, 79.09999999999957, -370.79999999999995, 44.000000000000064, -51.399999999999906, -183.10000000000056, 20.000000000000014, 91.69999999999958, 16.40000000000002, 20.000000000000014, 12.499999999999968, -136.30000000000027, 25.39999999999999, -74.50000000000088, 127.99999999999997, 14.000000000000073, -148.00000000000063, -72.40000000000089, 20.000000000000014, 66.79999999999997, -141.7000000000007, 19.399999999999995, 152.8999999999999, 104.00000000000006, 1.0999999999999943, 57.800000000000104, 163.10000000000002, 111.49999999999957, -2.1999999999999176, -77.2000000000001, 145.1, 86.90000000000003, 153.19999999999976, 104.30000000000001, 32.900000000000034, -28.299999999999834, -116.50000000000068, -197.80000000000052, -11.19999999999987, -54.09999999999985, 8.599999999999978, -21.999999999999744, 72.1999999999997, -10.299999999999798, -53.50000000000016, -65.20000000000033, 4.399999999999997, 64.70000000000005, 99.20000000000013, 128.29999999999998, 66.80000000000001, -11.499999999999844, 20.000000000000014, -96.70000000000019, -73.00000000000011, 77.8999999999995, 113.30000000000001, 30.19999999999999, 111.4999999999998, 145.4], "policy_predator_policy_reward": [88.0, 45.0, 101.0, 155.0, 127.0, 131.0, 87.0, 70.0, 174.0, 144.0, 165.0, 62.0, 31.0, 127.0, 223.0, 417.0, 55.0, 91.0, 157.0, 83.0, 20.0, 19.0, 160.0, 70.0, 83.0, 178.0, 119.0, 150.0, 63.0, 4.0, 184.0, 52.0, 149.0, 102.0, 105.0, 77.0, 149.0, 94.0, 81.0, 52.0, 138.0, 102.0, 19.0, 102.0, 146.0, 94.0, 15.0, 111.0, 36.0, 121.0, 35.0, 169.0, 188.0, 277.0, 36.0, 34.0, 0.0, 38.0, 101.0, 29.0, 29.0, 81.0, 34.0, 126.0, 15.0, 46.0, 174.0, 0.0, 79.0, 191.0, 109.0, 167.0, 92.0, 111.0, 248.0, 57.0, 123.0, 54.0, 3.0, 136.0, 141.0, 73.0, 100.0, 98.0, 32.0, 68.0, 89.0, 140.0, 10.0, 14.0, 160.0, 1.0, 15.0, 23.0, 203.0, 145.0, 34.0, 162.0, 87.0, 59.0, 64.0, 70.0, 195.0, 180.0, 25.0, 30.0, 189.0, 203.0, 70.0, 78.0, 73.0, 0.0, 68.0, 2.0, 49.0, 75.0, 3.0, 33.0, 68.0, 94.0, 25.0, 36.0, 12.0, 33.0, 38.0, 19.0, 25.0, 11.0, 38.0, 11.0, 24.0, 19.0, 17.0, 157.0, 0.0, 130.0, 7.0, 27.0, 72.0, 100.0, 48.0, 19.0, 229.0, 51.0, 83.0, 93.0, 7.0, 5.0, 12.0, 3.0, 4.0, 98.0, 19.0, 64.0, 17.0, 4.0, 49.0, 50.0, 5.0, 9.0, 11.0, 97.0, 1.0, 23.0, 0.0, 66.0, 4.0, 7.0, 99.0, 63.0, 29.0, 1.0, 0.0, 28.0, 15.0, 57.0, 105.0, 65.0, 55.0, 17.0, 4.0, 51.0, 22.0, 8.0, 35.0, 62.0, 27.0, 28.0, 12.0, 15.0, 33.0, 1.0, 57.0, 11.0, 49.0, 70.0, 30.0, 45.0, 19.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6743794016625162, "mean_inference_ms": 1.7732928535257773, "mean_action_processing_ms": 0.2716289518081008, "mean_env_wait_ms": 0.2266158600676215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004062294960021973, "StateBufferConnector_ms": 0.00335085391998291, "ViewRequirementAgentConnector_ms": 0.11329805850982666}, "num_episodes": 23, "episode_return_max": 292.90000000000055, "episode_return_min": -354.599999999999, "episode_return_mean": 13.442999999999829, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.2459785331127, "num_env_steps_trained_throughput_per_sec": 352.2459785331127, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 11601.212, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11601.161, "sample_time_ms": 1345.651, "learn_time_ms": 10239.769, "learn_throughput": 390.634, "synch_weights_time_ms": 13.534}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-49-06", "timestamp": 1723646946, "time_this_iter_s": 11.399357080459595, "time_total_s": 116.45103192329407, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed8c0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 116.45103192329407, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 45.00625, "ram_util_percent": 83.36874999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.068278400134788, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.210892555953334, "policy_loss": -0.0042750149203967, "vf_loss": 8.213274606068929, "vf_explained_var": 0.118077054540947, "kl": 0.01261948310596289, "entropy": 1.5686507192238297, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3769696134108085, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.204206691847907, "policy_loss": -0.010087377357015771, "vf_loss": 3.2130009103704382, "vf_explained_var": 0.022504541640559202, "kl": 0.012931542578849918, "entropy": 1.5633985879559997, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 292.90000000000055, "episode_reward_min": -319.99999999999886, "episode_reward_mean": 54.23499999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -504.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 277.0}, "policy_reward_mean": {"prey_policy": -31.122500000000063, "predator_policy": 58.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.9000000000003, 32.00000000000028, -319.99999999999886, 83.89999999999989, -166.40000000000003, 15.100000000000144, 113.09999999999985, -257.89999999999986, 71.9, 5.300000000000327, 163.79999999999953, -24.49999999999995, 144.0, -8.899999999999984, 105.49999999999935, -214.2, -218.90000000000094, -213.7000000000005, 128.29999999999995, 79.10000000000004, -89.00000000000043, 73.09999999999982, -95.80000000000045, -71.00000000000063, 40.1000000000001, 54.800000000000054, 154.89999999999864, 16.800000000000068, 150.29999999999944, -92.70000000000113, -60.899999999999864, 94.79999999999961, 6.900000000000192, -7.4999999999998295, 147.4999999999999, 3.399999999999629, 141.1999999999995, -54.39999999999983, 60.200000000000294, 49.10000000000006, 45.10000000000012, 51.10000000000009, 145.09999999999928, 4.900000000000128, 141.9999999999997, 0.4000000000002356, 154.3999999999995, 171.7999999999994, -52.800000000000026, -40.0000000000004, 90.80000000000015, 37.100000000000094, 56.90000000000027, -46.799999999999805, -58.500000000000945, 123.69999999999894, 51.40000000000034, -21.800000000000345, 33.90000000000024, 162.99999999999957, -121.40000000000151, 100.79999999999892, -14.299999999999793, 280.8999999999999, 124.9, 285.6, 82.6, 262.0, 285.5000000000003, 76.5999999999999, -144.3000000000012, 6.700000000000197, 41.60000000000036, 91.89999999999935, -21.700000000000117, 124.09999999999931, 254.49999999999966, 89.30000000000013, -8.69999999999987, 123.89999999999957, 218.4999999999999, 292.90000000000055, 176.7, 81.9, 221.39999999999972, 150.79999999999916, 290.0, 104.20000000000005, -192.90000000000038, 85.50000000000001, 231.5, 251.99999999999957, 221.09999999999982, 33.800000000000374, 98.59999999999991, 229.49999999999983, 2.5000000000002154, 189.4999999999999, 140.19999999999922, -244.80000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-212.80000000000013, -201.10000000000016, -124.00000000000031, 23.000000000000192, -265.0000000000002, -295.0000000000001, -198.40000000000032, 161.29999999999998, -153.09999999999994, -253.3000000000001, -86.80000000000001, -24.099999999999746, -223.2000000000005, 179.30000000000004, -301.29999999999893, -160.60000000000065, -504.0, 110.89999999999992, -40.300000000000075, -24.399999999999856, 182.9, -57.10000000000006, -98.00000000000003, -56.50000000000028, 104.9, -70.9, -17.499999999999893, -151.39999999999992, -7.600000000000032, 52.10000000000007, -103.59999999999997, -284.5999999999999, -215.2000000000005, -273.69999999999925, -237.90000000000043, -251.80000000000007, -138.50000000000003, 63.8, -373.3999999999993, 147.49999999999977, -82.90000000000012, -183.10000000000034, -182.19999999999996, 116.2999999999999, -280.29999999999984, -29.499999999999766, -60.1000000000001, -208.90000000000052, -67.60000000000076, 7.699999999999989, 158.59999999999994, -332.7999999999995, 46.400000000000055, 84.50000000000017, 171.79999999999984, -315.9999999999997, 140.5999999999999, -28.29999999999975, -38.799999999999756, -401.9, -225.3000000000002, -31.599999999999838, -147.70000000000053, 96.49999999999997, -7.299999999999891, -119.79999999999997, -434.59999999999997, 52.099999999999966, 5.299999999999885, 87.19999999999985, 52.700000000000124, -441.30000000000007, 118.10000000000002, -124.90000000000052, -63.399999999999984, -64.00000000000004, 117.19999999999956, -127.0000000000006, -49.0, -25.8999999999999, -22.299999999999763, 31.400000000000034, 28.700000000000088, -139.6000000000001, 5.900000000000041, 78.19999999999982, -5.1999999999999265, -34.899999999999785, 64.70000000000013, 20.30000000000002, -32.49999999999975, -3.099999999999965, 76.09999999999954, 29.300000000000097, 19.70000000000006, 109.09999999999991, 82.09999999999964, -308.8999999999996, -234.09999999999974, 64.10000000000011, -36.699999999999754, 93.50000000000009, -219.40000000000015, 84.49999999999989, -89.20000000000078, 79.09999999999957, -370.79999999999995, 44.000000000000064, -51.399999999999906, -183.10000000000056, 20.000000000000014, 91.69999999999958, 16.40000000000002, 20.000000000000014, 12.499999999999968, -136.30000000000027, 25.39999999999999, -74.50000000000088, 127.99999999999997, 14.000000000000073, -148.00000000000063, -72.40000000000089, 20.000000000000014, 66.79999999999997, -141.7000000000007, 19.399999999999995, 152.8999999999999, 104.00000000000006, 1.0999999999999943, 57.800000000000104, 163.10000000000002, 111.49999999999957, -2.1999999999999176, -77.2000000000001, 145.1, 86.90000000000003, 153.19999999999976, 104.30000000000001, 32.900000000000034, -28.299999999999834, -116.50000000000068, -197.80000000000052, -11.19999999999987, -54.09999999999985, 8.599999999999978, -21.999999999999744, 72.1999999999997, -10.299999999999798, -53.50000000000016, -65.20000000000033, 4.399999999999997, 64.70000000000005, 99.20000000000013, 128.29999999999998, 66.80000000000001, -11.499999999999844, 20.000000000000014, -96.70000000000019, -73.00000000000011, 77.8999999999995, 113.30000000000001, 30.19999999999999, 111.4999999999998, 145.4, 41.0, 58.69999999999999, -153.40000000000046, 146.29999999999976, 10.399999999999977, 139.99999999999974, 15.500000000000064, 89.29999999999964, 185.3, 43.700000000000024, 23.300000000000047, -0.09999999999996234, -232.30000000000038, -205.6, 74.00000000000001, -98.50000000000054, 153.2, 14.29999999999994, 172.99999999999991, 50.0000000000001, 197.29999999999998, -56.19999999999997, -61.90000000000064, 52.69999999999996, 35.3, 5.299999999999965, 103.39999999999998, 115.0999999999998, -32.49999999999975, -0.9999999999999846, 149.6, 11.90000000000014, -24.099999999999746, 134.29999999999976, -130.90000000000046, -328.9], "policy_predator_policy_reward": [149.0, 94.0, 81.0, 52.0, 138.0, 102.0, 19.0, 102.0, 146.0, 94.0, 15.0, 111.0, 36.0, 121.0, 35.0, 169.0, 188.0, 277.0, 36.0, 34.0, 0.0, 38.0, 101.0, 29.0, 29.0, 81.0, 34.0, 126.0, 15.0, 46.0, 174.0, 0.0, 79.0, 191.0, 109.0, 167.0, 92.0, 111.0, 248.0, 57.0, 123.0, 54.0, 3.0, 136.0, 141.0, 73.0, 100.0, 98.0, 32.0, 68.0, 89.0, 140.0, 10.0, 14.0, 160.0, 1.0, 15.0, 23.0, 203.0, 145.0, 34.0, 162.0, 87.0, 59.0, 64.0, 70.0, 195.0, 180.0, 25.0, 30.0, 189.0, 203.0, 70.0, 78.0, 73.0, 0.0, 68.0, 2.0, 49.0, 75.0, 3.0, 33.0, 68.0, 94.0, 25.0, 36.0, 12.0, 33.0, 38.0, 19.0, 25.0, 11.0, 38.0, 11.0, 24.0, 19.0, 17.0, 157.0, 0.0, 130.0, 7.0, 27.0, 72.0, 100.0, 48.0, 19.0, 229.0, 51.0, 83.0, 93.0, 7.0, 5.0, 12.0, 3.0, 4.0, 98.0, 19.0, 64.0, 17.0, 4.0, 49.0, 50.0, 5.0, 9.0, 11.0, 97.0, 1.0, 23.0, 0.0, 66.0, 4.0, 7.0, 99.0, 63.0, 29.0, 1.0, 0.0, 28.0, 15.0, 57.0, 105.0, 65.0, 55.0, 17.0, 4.0, 51.0, 22.0, 8.0, 35.0, 62.0, 27.0, 28.0, 12.0, 15.0, 33.0, 1.0, 57.0, 11.0, 49.0, 70.0, 30.0, 45.0, 19.0, 17.0, 70.0, 7.0, 83.0, 6.0, 9.0, 62.0, 31.0, 15.0, 26.0, 35.0, 80.0, 1.0, 187.0, 58.0, 39.0, 71.0, 59.0, 5.0, 4.0, 25.0, 77.0, 3.0, 39.0, 4.0, 7.0, 51.0, 3.0, 8.0, 24.0, 12.0, 22.0, 6.0, 21.0, 9.0, 105.0, 110.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6689520317914288, "mean_inference_ms": 1.7472058120436074, "mean_action_processing_ms": 0.26831132825283716, "mean_env_wait_ms": 0.2227914483148341, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004036664962768555, "StateBufferConnector_ms": 0.0033140182495117188, "ViewRequirementAgentConnector_ms": 0.11132931709289551}, "num_episodes": 18, "episode_return_max": 292.90000000000055, "episode_return_min": -319.99999999999886, "episode_return_mean": 54.23499999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.52653696558605, "num_env_steps_trained_throughput_per_sec": 343.52653696558605, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 11436.082, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11436.033, "sample_time_ms": 1259.648, "learn_time_ms": 10160.417, "learn_throughput": 393.685, "synch_weights_time_ms": 13.693}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-49-18", "timestamp": 1723646958, "time_this_iter_s": 11.6992769241333, "time_total_s": 128.15030884742737, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29ee550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 128.15030884742737, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 46.52499999999999, "ram_util_percent": 83.56875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0377835134034434, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.009173460612222, "policy_loss": -0.0022194223256693, "vf_loss": 7.0103571543617855, "vf_explained_var": 0.2093946102434996, "kl": 0.006904856173341776, "entropy": 1.55910656862158, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3888835455690112, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.322522604150116, "policy_loss": -0.01098543345957758, "vf_loss": 4.331988020044156, "vf_explained_var": 0.00935804979511039, "kl": 0.015200297312879316, "entropy": 1.540226253189107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 314.5000000000008, "episode_reward_min": -244.80000000000047, "episode_reward_mean": 78.4529999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -441.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 248.0}, "policy_reward_mean": {"prey_policy": -11.223500000000085, "predator_policy": 50.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [128.29999999999995, 79.10000000000004, -89.00000000000043, 73.09999999999982, -95.80000000000045, -71.00000000000063, 40.1000000000001, 54.800000000000054, 154.89999999999864, 16.800000000000068, 150.29999999999944, -92.70000000000113, -60.899999999999864, 94.79999999999961, 6.900000000000192, -7.4999999999998295, 147.4999999999999, 3.399999999999629, 141.1999999999995, -54.39999999999983, 60.200000000000294, 49.10000000000006, 45.10000000000012, 51.10000000000009, 145.09999999999928, 4.900000000000128, 141.9999999999997, 0.4000000000002356, 154.3999999999995, 171.7999999999994, -52.800000000000026, -40.0000000000004, 90.80000000000015, 37.100000000000094, 56.90000000000027, -46.799999999999805, -58.500000000000945, 123.69999999999894, 51.40000000000034, -21.800000000000345, 33.90000000000024, 162.99999999999957, -121.40000000000151, 100.79999999999892, -14.299999999999793, 280.8999999999999, 124.9, 285.6, 82.6, 262.0, 285.5000000000003, 76.5999999999999, -144.3000000000012, 6.700000000000197, 41.60000000000036, 91.89999999999935, -21.700000000000117, 124.09999999999931, 254.49999999999966, 89.30000000000013, -8.69999999999987, 123.89999999999957, 218.4999999999999, 292.90000000000055, 176.7, 81.9, 221.39999999999972, 150.79999999999916, 290.0, 104.20000000000005, -192.90000000000038, 85.50000000000001, 231.5, 251.99999999999957, 221.09999999999982, 33.800000000000374, 98.59999999999991, 229.49999999999983, 2.5000000000002154, 189.4999999999999, 140.19999999999922, -244.80000000000047, 70.70000000000007, 88.1999999999996, 6.300000000000162, -78.70000000000044, 314.5000000000008, -55.299999999999734, 275.6000000000005, 155.49999999999937, 79.80000000000015, 21.500000000000185, -154.20000000000118, 3.0999999999997603, 195.19999999999993, 126.39999999999972, 231.3999999999993, 73.20000000000002, 181.69999999999933, 26.100000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-138.50000000000003, 63.8, -373.3999999999993, 147.49999999999977, -82.90000000000012, -183.10000000000034, -182.19999999999996, 116.2999999999999, -280.29999999999984, -29.499999999999766, -60.1000000000001, -208.90000000000052, -67.60000000000076, 7.699999999999989, 158.59999999999994, -332.7999999999995, 46.400000000000055, 84.50000000000017, 171.79999999999984, -315.9999999999997, 140.5999999999999, -28.29999999999975, -38.799999999999756, -401.9, -225.3000000000002, -31.599999999999838, -147.70000000000053, 96.49999999999997, -7.299999999999891, -119.79999999999997, -434.59999999999997, 52.099999999999966, 5.299999999999885, 87.19999999999985, 52.700000000000124, -441.30000000000007, 118.10000000000002, -124.90000000000052, -63.399999999999984, -64.00000000000004, 117.19999999999956, -127.0000000000006, -49.0, -25.8999999999999, -22.299999999999763, 31.400000000000034, 28.700000000000088, -139.6000000000001, 5.900000000000041, 78.19999999999982, -5.1999999999999265, -34.899999999999785, 64.70000000000013, 20.30000000000002, -32.49999999999975, -3.099999999999965, 76.09999999999954, 29.300000000000097, 19.70000000000006, 109.09999999999991, 82.09999999999964, -308.8999999999996, -234.09999999999974, 64.10000000000011, -36.699999999999754, 93.50000000000009, -219.40000000000015, 84.49999999999989, -89.20000000000078, 79.09999999999957, -370.79999999999995, 44.000000000000064, -51.399999999999906, -183.10000000000056, 20.000000000000014, 91.69999999999958, 16.40000000000002, 20.000000000000014, 12.499999999999968, -136.30000000000027, 25.39999999999999, -74.50000000000088, 127.99999999999997, 14.000000000000073, -148.00000000000063, -72.40000000000089, 20.000000000000014, 66.79999999999997, -141.7000000000007, 19.399999999999995, 152.8999999999999, 104.00000000000006, 1.0999999999999943, 57.800000000000104, 163.10000000000002, 111.49999999999957, -2.1999999999999176, -77.2000000000001, 145.1, 86.90000000000003, 153.19999999999976, 104.30000000000001, 32.900000000000034, -28.299999999999834, -116.50000000000068, -197.80000000000052, -11.19999999999987, -54.09999999999985, 8.599999999999978, -21.999999999999744, 72.1999999999997, -10.299999999999798, -53.50000000000016, -65.20000000000033, 4.399999999999997, 64.70000000000005, 99.20000000000013, 128.29999999999998, 66.80000000000001, -11.499999999999844, 20.000000000000014, -96.70000000000019, -73.00000000000011, 77.8999999999995, 113.30000000000001, 30.19999999999999, 111.4999999999998, 145.4, 41.0, 58.69999999999999, -153.40000000000046, 146.29999999999976, 10.399999999999977, 139.99999999999974, 15.500000000000064, 89.29999999999964, 185.3, 43.700000000000024, 23.300000000000047, -0.09999999999996234, -232.30000000000038, -205.6, 74.00000000000001, -98.50000000000054, 153.2, 14.29999999999994, 172.99999999999991, 50.0000000000001, 197.29999999999998, -56.19999999999997, -61.90000000000064, 52.69999999999996, 35.3, 5.299999999999965, 103.39999999999998, 115.0999999999998, -32.49999999999975, -0.9999999999999846, 149.6, 11.90000000000014, -24.099999999999746, 134.29999999999976, -130.90000000000046, -328.9, 19.40000000000002, -33.6999999999998, -0.4000000000000188, 50.60000000000021, -73.0, -57.70000000000004, -193.90000000000023, 3.1999999999999615, 84.1999999999999, 170.29999999999984, -137.50000000000045, -17.800000000000026, 169.39999999999986, 75.19999999999973, 127.1, -34.59999999999975, 131.60000000000005, -149.80000000000055, -187.90000000000057, 94.39999999999968, -160.60000000000042, -139.60000000000068, -2.4999999999999343, -111.4000000000002, 55.1, 67.10000000000002, 28.10000000000001, 44.30000000000021, 95.89999999999989, 81.4999999999994, 20.000000000000014, -83.80000000000001, 118.09999999999948, -57.40000000000015, 20.000000000000014, -112.89999999999998], "policy_predator_policy_reward": [92.0, 111.0, 248.0, 57.0, 123.0, 54.0, 3.0, 136.0, 141.0, 73.0, 100.0, 98.0, 32.0, 68.0, 89.0, 140.0, 10.0, 14.0, 160.0, 1.0, 15.0, 23.0, 203.0, 145.0, 34.0, 162.0, 87.0, 59.0, 64.0, 70.0, 195.0, 180.0, 25.0, 30.0, 189.0, 203.0, 70.0, 78.0, 73.0, 0.0, 68.0, 2.0, 49.0, 75.0, 3.0, 33.0, 68.0, 94.0, 25.0, 36.0, 12.0, 33.0, 38.0, 19.0, 25.0, 11.0, 38.0, 11.0, 24.0, 19.0, 17.0, 157.0, 0.0, 130.0, 7.0, 27.0, 72.0, 100.0, 48.0, 19.0, 229.0, 51.0, 83.0, 93.0, 7.0, 5.0, 12.0, 3.0, 4.0, 98.0, 19.0, 64.0, 17.0, 4.0, 49.0, 50.0, 5.0, 9.0, 11.0, 97.0, 1.0, 23.0, 0.0, 66.0, 4.0, 7.0, 99.0, 63.0, 29.0, 1.0, 0.0, 28.0, 15.0, 57.0, 105.0, 65.0, 55.0, 17.0, 4.0, 51.0, 22.0, 8.0, 35.0, 62.0, 27.0, 28.0, 12.0, 15.0, 33.0, 1.0, 57.0, 11.0, 49.0, 70.0, 30.0, 45.0, 19.0, 17.0, 70.0, 7.0, 83.0, 6.0, 9.0, 62.0, 31.0, 15.0, 26.0, 35.0, 80.0, 1.0, 187.0, 58.0, 39.0, 71.0, 59.0, 5.0, 4.0, 25.0, 77.0, 3.0, 39.0, 4.0, 7.0, 51.0, 3.0, 8.0, 24.0, 12.0, 22.0, 6.0, 21.0, 9.0, 105.0, 110.0, 70.0, 15.0, 32.0, 6.0, 21.0, 116.0, 8.0, 104.0, 28.0, 32.0, 50.0, 50.0, 5.0, 26.0, 18.0, 45.0, 86.0, 12.0, 13.0, 102.0, 60.0, 86.0, 93.0, 24.0, 1.0, 72.0, 54.0, 0.0, 25.0, 29.0, 66.0, 71.0, 59.0, 62.0, 65.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6625377521673573, "mean_inference_ms": 1.7247797399371025, "mean_action_processing_ms": 0.26570791832243856, "mean_env_wait_ms": 0.2197145292455146, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004024505615234375, "StateBufferConnector_ms": 0.00328981876373291, "ViewRequirementAgentConnector_ms": 0.10342729091644287}, "num_episodes": 18, "episode_return_max": 314.5000000000008, "episode_return_min": -244.80000000000047, "episode_return_mean": 78.4529999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.3690454070615, "num_env_steps_trained_throughput_per_sec": 346.3690454070615, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 11437.774, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11437.73, "sample_time_ms": 1250.244, "learn_time_ms": 10171.578, "learn_throughput": 393.253, "synch_weights_time_ms": 14.084}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-49-29", "timestamp": 1723646969, "time_this_iter_s": 11.595363855361938, "time_total_s": 139.7456727027893, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede2160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 139.7456727027893, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 44.61764705882353, "ram_util_percent": 83.55882352941177}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9035436986615417, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.052805342749943, "policy_loss": -0.006178208662778455, "vf_loss": 8.057069138622788, "vf_explained_var": 0.08087071949842746, "kl": 0.012762686173989662, "entropy": 1.5643893745841173, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1500869200973916, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.696093960413857, "policy_loss": -0.012592780846787036, "vf_loss": 5.707356659823625, "vf_explained_var": 0.021384544788845, "kl": 0.013300865614401521, "entropy": 1.5442659829659438, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 314.5000000000008, "episode_reward_min": -244.80000000000047, "episode_reward_mean": 81.07799999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -422.7999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 229.0}, "policy_reward_mean": {"prey_policy": -4.456000000000092, "predator_policy": 44.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [141.1999999999995, -54.39999999999983, 60.200000000000294, 49.10000000000006, 45.10000000000012, 51.10000000000009, 145.09999999999928, 4.900000000000128, 141.9999999999997, 0.4000000000002356, 154.3999999999995, 171.7999999999994, -52.800000000000026, -40.0000000000004, 90.80000000000015, 37.100000000000094, 56.90000000000027, -46.799999999999805, -58.500000000000945, 123.69999999999894, 51.40000000000034, -21.800000000000345, 33.90000000000024, 162.99999999999957, -121.40000000000151, 100.79999999999892, -14.299999999999793, 280.8999999999999, 124.9, 285.6, 82.6, 262.0, 285.5000000000003, 76.5999999999999, -144.3000000000012, 6.700000000000197, 41.60000000000036, 91.89999999999935, -21.700000000000117, 124.09999999999931, 254.49999999999966, 89.30000000000013, -8.69999999999987, 123.89999999999957, 218.4999999999999, 292.90000000000055, 176.7, 81.9, 221.39999999999972, 150.79999999999916, 290.0, 104.20000000000005, -192.90000000000038, 85.50000000000001, 231.5, 251.99999999999957, 221.09999999999982, 33.800000000000374, 98.59999999999991, 229.49999999999983, 2.5000000000002154, 189.4999999999999, 140.19999999999922, -244.80000000000047, 70.70000000000007, 88.1999999999996, 6.300000000000162, -78.70000000000044, 314.5000000000008, -55.299999999999734, 275.6000000000005, 155.49999999999937, 79.80000000000015, 21.500000000000185, -154.20000000000118, 3.0999999999997603, 195.19999999999993, 126.39999999999972, 231.3999999999993, 73.20000000000002, 181.69999999999933, 26.100000000000083, -50.799999999999656, 31.000000000000227, 54.40000000000006, 195.29999999999947, 101.79999999999977, -109.10000000000005, 0.6000000000001672, -41.4, 250.5999999999998, -75.90000000000067, 100.8999999999998, -221.70000000000041, 116.6999999999998, 96.79999999999943, 273.10000000000076, 149.69999999999993, 80.99999999999997, -157.4000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [118.10000000000002, -124.90000000000052, -63.399999999999984, -64.00000000000004, 117.19999999999956, -127.0000000000006, -49.0, -25.8999999999999, -22.299999999999763, 31.400000000000034, 28.700000000000088, -139.6000000000001, 5.900000000000041, 78.19999999999982, -5.1999999999999265, -34.899999999999785, 64.70000000000013, 20.30000000000002, -32.49999999999975, -3.099999999999965, 76.09999999999954, 29.300000000000097, 19.70000000000006, 109.09999999999991, 82.09999999999964, -308.8999999999996, -234.09999999999974, 64.10000000000011, -36.699999999999754, 93.50000000000009, -219.40000000000015, 84.49999999999989, -89.20000000000078, 79.09999999999957, -370.79999999999995, 44.000000000000064, -51.399999999999906, -183.10000000000056, 20.000000000000014, 91.69999999999958, 16.40000000000002, 20.000000000000014, 12.499999999999968, -136.30000000000027, 25.39999999999999, -74.50000000000088, 127.99999999999997, 14.000000000000073, -148.00000000000063, -72.40000000000089, 20.000000000000014, 66.79999999999997, -141.7000000000007, 19.399999999999995, 152.8999999999999, 104.00000000000006, 1.0999999999999943, 57.800000000000104, 163.10000000000002, 111.49999999999957, -2.1999999999999176, -77.2000000000001, 145.1, 86.90000000000003, 153.19999999999976, 104.30000000000001, 32.900000000000034, -28.299999999999834, -116.50000000000068, -197.80000000000052, -11.19999999999987, -54.09999999999985, 8.599999999999978, -21.999999999999744, 72.1999999999997, -10.299999999999798, -53.50000000000016, -65.20000000000033, 4.399999999999997, 64.70000000000005, 99.20000000000013, 128.29999999999998, 66.80000000000001, -11.499999999999844, 20.000000000000014, -96.70000000000019, -73.00000000000011, 77.8999999999995, 113.30000000000001, 30.19999999999999, 111.4999999999998, 145.4, 41.0, 58.69999999999999, -153.40000000000046, 146.29999999999976, 10.399999999999977, 139.99999999999974, 15.500000000000064, 89.29999999999964, 185.3, 43.700000000000024, 23.300000000000047, -0.09999999999996234, -232.30000000000038, -205.6, 74.00000000000001, -98.50000000000054, 153.2, 14.29999999999994, 172.99999999999991, 50.0000000000001, 197.29999999999998, -56.19999999999997, -61.90000000000064, 52.69999999999996, 35.3, 5.299999999999965, 103.39999999999998, 115.0999999999998, -32.49999999999975, -0.9999999999999846, 149.6, 11.90000000000014, -24.099999999999746, 134.29999999999976, -130.90000000000046, -328.9, 19.40000000000002, -33.6999999999998, -0.4000000000000188, 50.60000000000021, -73.0, -57.70000000000004, -193.90000000000023, 3.1999999999999615, 84.1999999999999, 170.29999999999984, -137.50000000000045, -17.800000000000026, 169.39999999999986, 75.19999999999973, 127.1, -34.59999999999975, 131.60000000000005, -149.80000000000055, -187.90000000000057, 94.39999999999968, -160.60000000000042, -139.60000000000068, -2.4999999999999343, -111.4000000000002, 55.1, 67.10000000000002, 28.10000000000001, 44.30000000000021, 95.89999999999989, 81.4999999999994, 20.000000000000014, -83.80000000000001, 118.09999999999948, -57.40000000000015, 20.000000000000014, -112.89999999999998, -166.90000000000063, 1.0999999999999688, -15.999999999999867, -60.99999999999993, 20.000000000000014, 10.40000000000019, 194.6, -88.29999999999997, -97.60000000000082, 82.4, -381.09999999999997, -33.999999999999986, -114.40000000000003, -0.9999999999999846, -199.9, -62.5, 147.79999999999998, 45.80000000000007, -133.90000000000023, -105.99999999999986, -23.800000000000097, 16.699999999999996, -162.70000000000041, -223.0, 85.99999999999982, -28.299999999999883, -3.6999999999999975, 15.499999999999993, 123.49999999999963, 125.59999999999988, 126.19999999999993, -56.49999999999998, 192.8, -422.7999999999997, -151.60000000000025, -200.80000000000024], "policy_predator_policy_reward": [70.0, 78.0, 73.0, 0.0, 68.0, 2.0, 49.0, 75.0, 3.0, 33.0, 68.0, 94.0, 25.0, 36.0, 12.0, 33.0, 38.0, 19.0, 25.0, 11.0, 38.0, 11.0, 24.0, 19.0, 17.0, 157.0, 0.0, 130.0, 7.0, 27.0, 72.0, 100.0, 48.0, 19.0, 229.0, 51.0, 83.0, 93.0, 7.0, 5.0, 12.0, 3.0, 4.0, 98.0, 19.0, 64.0, 17.0, 4.0, 49.0, 50.0, 5.0, 9.0, 11.0, 97.0, 1.0, 23.0, 0.0, 66.0, 4.0, 7.0, 99.0, 63.0, 29.0, 1.0, 0.0, 28.0, 15.0, 57.0, 105.0, 65.0, 55.0, 17.0, 4.0, 51.0, 22.0, 8.0, 35.0, 62.0, 27.0, 28.0, 12.0, 15.0, 33.0, 1.0, 57.0, 11.0, 49.0, 70.0, 30.0, 45.0, 19.0, 17.0, 70.0, 7.0, 83.0, 6.0, 9.0, 62.0, 31.0, 15.0, 26.0, 35.0, 80.0, 1.0, 187.0, 58.0, 39.0, 71.0, 59.0, 5.0, 4.0, 25.0, 77.0, 3.0, 39.0, 4.0, 7.0, 51.0, 3.0, 8.0, 24.0, 12.0, 22.0, 6.0, 21.0, 9.0, 105.0, 110.0, 70.0, 15.0, 32.0, 6.0, 21.0, 116.0, 8.0, 104.0, 28.0, 32.0, 50.0, 50.0, 5.0, 26.0, 18.0, 45.0, 86.0, 12.0, 13.0, 102.0, 60.0, 86.0, 93.0, 24.0, 1.0, 72.0, 54.0, 0.0, 25.0, 29.0, 66.0, 71.0, 59.0, 62.0, 65.0, 54.0, 85.0, 30.0, 69.0, 39.0, 23.0, 1.0, 50.0, 39.0, 82.0, 35.0, 173.0, 133.0, 98.0, 18.0, 123.0, 98.0, 14.0, 43.0, 94.0, 70.0, 26.0, 82.0, 147.0, 17.0, 23.0, 36.0, 45.0, 40.0, 13.0, 11.0, 39.0, 41.0, 225.0, 86.0, 98.0, 97.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6575095139168481, "mean_inference_ms": 1.70862049157924, "mean_action_processing_ms": 0.2637629123317893, "mean_env_wait_ms": 0.21749329684335483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004076719284057617, "StateBufferConnector_ms": 0.003298640251159668, "ViewRequirementAgentConnector_ms": 0.10792016983032227}, "num_episodes": 18, "episode_return_max": 314.5000000000008, "episode_return_min": -244.80000000000047, "episode_return_mean": 81.07799999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.55508875523685, "num_env_steps_trained_throughput_per_sec": 354.55508875523685, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 11429.592, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11429.547, "sample_time_ms": 1259.03, "learn_time_ms": 10152.931, "learn_throughput": 393.975, "synch_weights_time_ms": 15.697}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-49-41", "timestamp": 1723646981, "time_this_iter_s": 11.340635299682617, "time_total_s": 151.08630800247192, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede2ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 151.08630800247192, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 41.78750000000001, "ram_util_percent": 83.61249999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.066064170144853, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.267023754119872, "policy_loss": -0.011855583747223059, "vf_loss": 9.275784771530716, "vf_explained_var": 0.0580781724087145, "kl": 0.02063043043362944, "entropy": 1.547708026568095, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4541546080478285, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.999762893606115, "policy_loss": -0.012414407438879449, "vf_loss": 7.010505292024562, "vf_explained_var": 0.04627045929116547, "kl": 0.016720235321589425, "entropy": 1.5266292818639644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 314.5000000000008, "episode_reward_min": -250.89999999999884, "episode_reward_mean": 71.36799999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -422.7999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 225.0}, "policy_reward_mean": {"prey_policy": -16.066000000000077, "predator_policy": 51.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [280.8999999999999, 124.9, 285.6, 82.6, 262.0, 285.5000000000003, 76.5999999999999, -144.3000000000012, 6.700000000000197, 41.60000000000036, 91.89999999999935, -21.700000000000117, 124.09999999999931, 254.49999999999966, 89.30000000000013, -8.69999999999987, 123.89999999999957, 218.4999999999999, 292.90000000000055, 176.7, 81.9, 221.39999999999972, 150.79999999999916, 290.0, 104.20000000000005, -192.90000000000038, 85.50000000000001, 231.5, 251.99999999999957, 221.09999999999982, 33.800000000000374, 98.59999999999991, 229.49999999999983, 2.5000000000002154, 189.4999999999999, 140.19999999999922, -244.80000000000047, 70.70000000000007, 88.1999999999996, 6.300000000000162, -78.70000000000044, 314.5000000000008, -55.299999999999734, 275.6000000000005, 155.49999999999937, 79.80000000000015, 21.500000000000185, -154.20000000000118, 3.0999999999997603, 195.19999999999993, 126.39999999999972, 231.3999999999993, 73.20000000000002, 181.69999999999933, 26.100000000000083, -50.799999999999656, 31.000000000000227, 54.40000000000006, 195.29999999999947, 101.79999999999977, -109.10000000000005, 0.6000000000001672, -41.4, 250.5999999999998, -75.90000000000067, 100.8999999999998, -221.70000000000041, 116.6999999999998, 96.79999999999943, 273.10000000000076, 149.69999999999993, 80.99999999999997, -157.4000000000005, 119.89999999999904, 228.99999999999991, 19.600000000000126, 27.0000000000002, 86.49999999999994, -46.0000000000002, -69.30000000000001, 267.79999999999995, 131.90000000000003, -187.29999999999993, -117.20000000000053, 71.40000000000003, -197.30000000000032, -250.89999999999884, 152.69999999999987, 112.79999999999959, -209.70000000000007, 252.69999999999987, -192.19999999999993, 55.4999999999999, 22.79999999999999, -190.10000000000045, 1.2612133559741778e-13, -66.60000000000039, 59.999999999999766, -68.59999999999997, 227.49999999999915], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [152.8999999999999, 104.00000000000006, 1.0999999999999943, 57.800000000000104, 163.10000000000002, 111.49999999999957, -2.1999999999999176, -77.2000000000001, 145.1, 86.90000000000003, 153.19999999999976, 104.30000000000001, 32.900000000000034, -28.299999999999834, -116.50000000000068, -197.80000000000052, -11.19999999999987, -54.09999999999985, 8.599999999999978, -21.999999999999744, 72.1999999999997, -10.299999999999798, -53.50000000000016, -65.20000000000033, 4.399999999999997, 64.70000000000005, 99.20000000000013, 128.29999999999998, 66.80000000000001, -11.499999999999844, 20.000000000000014, -96.70000000000019, -73.00000000000011, 77.8999999999995, 113.30000000000001, 30.19999999999999, 111.4999999999998, 145.4, 41.0, 58.69999999999999, -153.40000000000046, 146.29999999999976, 10.399999999999977, 139.99999999999974, 15.500000000000064, 89.29999999999964, 185.3, 43.700000000000024, 23.300000000000047, -0.09999999999996234, -232.30000000000038, -205.6, 74.00000000000001, -98.50000000000054, 153.2, 14.29999999999994, 172.99999999999991, 50.0000000000001, 197.29999999999998, -56.19999999999997, -61.90000000000064, 52.69999999999996, 35.3, 5.299999999999965, 103.39999999999998, 115.0999999999998, -32.49999999999975, -0.9999999999999846, 149.6, 11.90000000000014, -24.099999999999746, 134.29999999999976, -130.90000000000046, -328.9, 19.40000000000002, -33.6999999999998, -0.4000000000000188, 50.60000000000021, -73.0, -57.70000000000004, -193.90000000000023, 3.1999999999999615, 84.1999999999999, 170.29999999999984, -137.50000000000045, -17.800000000000026, 169.39999999999986, 75.19999999999973, 127.1, -34.59999999999975, 131.60000000000005, -149.80000000000055, -187.90000000000057, 94.39999999999968, -160.60000000000042, -139.60000000000068, -2.4999999999999343, -111.4000000000002, 55.1, 67.10000000000002, 28.10000000000001, 44.30000000000021, 95.89999999999989, 81.4999999999994, 20.000000000000014, -83.80000000000001, 118.09999999999948, -57.40000000000015, 20.000000000000014, -112.89999999999998, -166.90000000000063, 1.0999999999999688, -15.999999999999867, -60.99999999999993, 20.000000000000014, 10.40000000000019, 194.6, -88.29999999999997, -97.60000000000082, 82.4, -381.09999999999997, -33.999999999999986, -114.40000000000003, -0.9999999999999846, -199.9, -62.5, 147.79999999999998, 45.80000000000007, -133.90000000000023, -105.99999999999986, -23.800000000000097, 16.699999999999996, -162.70000000000041, -223.0, 85.99999999999982, -28.299999999999883, -3.6999999999999975, 15.499999999999993, 123.49999999999963, 125.59999999999988, 126.19999999999993, -56.49999999999998, 192.8, -422.7999999999997, -151.60000000000025, -200.80000000000024, -39.09999999999993, 88.99999999999935, 156.19999999999993, -62.2000000000001, -161.20000000000007, 60.80000000000007, -1.900000000000016, -45.099999999999945, 26.599999999999994, -42.10000000000006, -97.3, -114.69999999999996, 4.699999999999989, -205.0, 103.7, 88.09999999999997, 43.69999999999999, 9.200000000000095, -320.19999999999993, -72.1, -111.40000000000012, -149.8000000000004, -73.30000000000003, -40.300000000000026, -230.20000000000033, -135.10000000000002, -273.3999999999989, -224.50000000000009, 76.99999999999999, 4.700000000000017, 45.80000000000003, -36.99999999999993, -159.4, -307.30000000000007, 176.8999999999999, 12.80000000000011, -142.29999999999995, -184.90000000000003, -46.29999999999999, -8.199999999999985, -133.9000000000001, -10.299999999999976, -301.59999999999997, -56.49999999999995, -173.2000000000006, -2.7999999999999687, -187.60000000000053, -85.0, -197.50000000000045, 135.49999999999986, -157.90000000000006, -126.7, 70.70000000000007, 111.79999999999953], "policy_predator_policy_reward": [1.0, 23.0, 0.0, 66.0, 4.0, 7.0, 99.0, 63.0, 29.0, 1.0, 0.0, 28.0, 15.0, 57.0, 105.0, 65.0, 55.0, 17.0, 4.0, 51.0, 22.0, 8.0, 35.0, 62.0, 27.0, 28.0, 12.0, 15.0, 33.0, 1.0, 57.0, 11.0, 49.0, 70.0, 30.0, 45.0, 19.0, 17.0, 70.0, 7.0, 83.0, 6.0, 9.0, 62.0, 31.0, 15.0, 26.0, 35.0, 80.0, 1.0, 187.0, 58.0, 39.0, 71.0, 59.0, 5.0, 4.0, 25.0, 77.0, 3.0, 39.0, 4.0, 7.0, 51.0, 3.0, 8.0, 24.0, 12.0, 22.0, 6.0, 21.0, 9.0, 105.0, 110.0, 70.0, 15.0, 32.0, 6.0, 21.0, 116.0, 8.0, 104.0, 28.0, 32.0, 50.0, 50.0, 5.0, 26.0, 18.0, 45.0, 86.0, 12.0, 13.0, 102.0, 60.0, 86.0, 93.0, 24.0, 1.0, 72.0, 54.0, 0.0, 25.0, 29.0, 66.0, 71.0, 59.0, 62.0, 65.0, 54.0, 85.0, 30.0, 69.0, 39.0, 23.0, 1.0, 50.0, 39.0, 82.0, 35.0, 173.0, 133.0, 98.0, 18.0, 123.0, 98.0, 14.0, 43.0, 94.0, 70.0, 26.0, 82.0, 147.0, 17.0, 23.0, 36.0, 45.0, 40.0, 13.0, 11.0, 39.0, 41.0, 225.0, 86.0, 98.0, 97.0, 14.0, 56.0, 74.0, 61.0, 96.0, 24.0, 56.0, 18.0, 69.0, 33.0, 53.0, 113.0, 35.0, 96.0, 47.0, 29.0, 35.0, 44.0, 162.0, 43.0, 101.0, 43.0, 125.0, 60.0, 32.0, 136.0, 100.0, 147.0, 69.0, 2.0, 31.0, 73.0, 157.0, 100.0, 35.0, 28.0, 36.0, 99.0, 66.0, 44.0, 102.0, 65.0, 21.0, 147.0, 94.0, 82.0, 148.0, 58.0, 92.0, 30.0, 53.0, 163.0, 26.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6530549400908613, "mean_inference_ms": 1.6963183832150666, "mean_action_processing_ms": 0.2622692802688855, "mean_env_wait_ms": 0.21565778813886535, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004049420356750488, "StateBufferConnector_ms": 0.003285527229309082, "ViewRequirementAgentConnector_ms": 0.11598145961761475}, "num_episodes": 27, "episode_return_max": 314.5000000000008, "episode_return_min": -250.89999999999884, "episode_return_mean": 71.36799999999988, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.59165399798627, "num_env_steps_trained_throughput_per_sec": 352.59165399798627, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 11419.073, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11419.024, "sample_time_ms": 1274.77, "learn_time_ms": 10126.205, "learn_throughput": 395.015, "synch_weights_time_ms": 16.201}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-49-52", "timestamp": 1723646992, "time_this_iter_s": 11.448132753372192, "time_total_s": 162.53444075584412, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29eeee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 162.53444075584412, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 42.96875, "ram_util_percent": 83.47500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.957998705225647, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.41669523324916, "policy_loss": -0.0112638015440473, "vf_loss": 8.424792690630312, "vf_explained_var": -0.047526018297861496, "kl": 0.014072618687459843, "entropy": 1.5530207364647477, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.648760070624175, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.54747371623125, "policy_loss": -0.014828056353021157, "vf_loss": 7.560313216971342, "vf_explained_var": 0.006994355891747449, "kl": 0.019885469428248648, "entropy": 1.5295926850308816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 314.5000000000008, "episode_reward_min": -250.89999999999884, "episode_reward_mean": 57.76899999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -422.7999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 225.0}, "policy_reward_mean": {"prey_policy": -31.790500000000065, "predator_policy": 60.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [292.90000000000055, 176.7, 81.9, 221.39999999999972, 150.79999999999916, 290.0, 104.20000000000005, -192.90000000000038, 85.50000000000001, 231.5, 251.99999999999957, 221.09999999999982, 33.800000000000374, 98.59999999999991, 229.49999999999983, 2.5000000000002154, 189.4999999999999, 140.19999999999922, -244.80000000000047, 70.70000000000007, 88.1999999999996, 6.300000000000162, -78.70000000000044, 314.5000000000008, -55.299999999999734, 275.6000000000005, 155.49999999999937, 79.80000000000015, 21.500000000000185, -154.20000000000118, 3.0999999999997603, 195.19999999999993, 126.39999999999972, 231.3999999999993, 73.20000000000002, 181.69999999999933, 26.100000000000083, -50.799999999999656, 31.000000000000227, 54.40000000000006, 195.29999999999947, 101.79999999999977, -109.10000000000005, 0.6000000000001672, -41.4, 250.5999999999998, -75.90000000000067, 100.8999999999998, -221.70000000000041, 116.6999999999998, 96.79999999999943, 273.10000000000076, 149.69999999999993, 80.99999999999997, -157.4000000000005, 119.89999999999904, 228.99999999999991, 19.600000000000126, 27.0000000000002, 86.49999999999994, -46.0000000000002, -69.30000000000001, 267.79999999999995, 131.90000000000003, -187.29999999999993, -117.20000000000053, 71.40000000000003, -197.30000000000032, -250.89999999999884, 152.69999999999987, 112.79999999999959, -209.70000000000007, 252.69999999999987, -192.19999999999993, 55.4999999999999, 22.79999999999999, -190.10000000000045, 1.2612133559741778e-13, -66.60000000000039, 59.999999999999766, -68.59999999999997, 227.49999999999915, -72.69999999999999, 216.0, -53.8, 203.09999999999988, -99.70000000000033, 192.59999999999994, 24.0, 185.6999999999996, 77.29999999999998, 162.4, -22.80000000000004, 32.599999999999994, -95.00000000000068, 44.900000000000205, 38.2, -17.0, -55.79999999999983, 54.00000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [111.4999999999998, 145.4, 41.0, 58.69999999999999, -153.40000000000046, 146.29999999999976, 10.399999999999977, 139.99999999999974, 15.500000000000064, 89.29999999999964, 185.3, 43.700000000000024, 23.300000000000047, -0.09999999999996234, -232.30000000000038, -205.6, 74.00000000000001, -98.50000000000054, 153.2, 14.29999999999994, 172.99999999999991, 50.0000000000001, 197.29999999999998, -56.19999999999997, -61.90000000000064, 52.69999999999996, 35.3, 5.299999999999965, 103.39999999999998, 115.0999999999998, -32.49999999999975, -0.9999999999999846, 149.6, 11.90000000000014, -24.099999999999746, 134.29999999999976, -130.90000000000046, -328.9, 19.40000000000002, -33.6999999999998, -0.4000000000000188, 50.60000000000021, -73.0, -57.70000000000004, -193.90000000000023, 3.1999999999999615, 84.1999999999999, 170.29999999999984, -137.50000000000045, -17.800000000000026, 169.39999999999986, 75.19999999999973, 127.1, -34.59999999999975, 131.60000000000005, -149.80000000000055, -187.90000000000057, 94.39999999999968, -160.60000000000042, -139.60000000000068, -2.4999999999999343, -111.4000000000002, 55.1, 67.10000000000002, 28.10000000000001, 44.30000000000021, 95.89999999999989, 81.4999999999994, 20.000000000000014, -83.80000000000001, 118.09999999999948, -57.40000000000015, 20.000000000000014, -112.89999999999998, -166.90000000000063, 1.0999999999999688, -15.999999999999867, -60.99999999999993, 20.000000000000014, 10.40000000000019, 194.6, -88.29999999999997, -97.60000000000082, 82.4, -381.09999999999997, -33.999999999999986, -114.40000000000003, -0.9999999999999846, -199.9, -62.5, 147.79999999999998, 45.80000000000007, -133.90000000000023, -105.99999999999986, -23.800000000000097, 16.699999999999996, -162.70000000000041, -223.0, 85.99999999999982, -28.299999999999883, -3.6999999999999975, 15.499999999999993, 123.49999999999963, 125.59999999999988, 126.19999999999993, -56.49999999999998, 192.8, -422.7999999999997, -151.60000000000025, -200.80000000000024, -39.09999999999993, 88.99999999999935, 156.19999999999993, -62.2000000000001, -161.20000000000007, 60.80000000000007, -1.900000000000016, -45.099999999999945, 26.599999999999994, -42.10000000000006, -97.3, -114.69999999999996, 4.699999999999989, -205.0, 103.7, 88.09999999999997, 43.69999999999999, 9.200000000000095, -320.19999999999993, -72.1, -111.40000000000012, -149.8000000000004, -73.30000000000003, -40.300000000000026, -230.20000000000033, -135.10000000000002, -273.3999999999989, -224.50000000000009, 76.99999999999999, 4.700000000000017, 45.80000000000003, -36.99999999999993, -159.4, -307.30000000000007, 176.8999999999999, 12.80000000000011, -142.29999999999995, -184.90000000000003, -46.29999999999999, -8.199999999999985, -133.9000000000001, -10.299999999999976, -301.59999999999997, -56.49999999999995, -173.2000000000006, -2.7999999999999687, -187.60000000000053, -85.0, -197.50000000000045, 135.49999999999986, -157.90000000000006, -126.7, 70.70000000000007, 111.79999999999953, -67.0, -177.70000000000007, 137.89999999999998, -46.89999999999999, -131.8, -106.0, -48.99999999999997, 181.09999999999997, 17.899999999999988, -361.6, -45.09999999999999, 172.69999999999987, -133.0, -22.0, 45.8, 59.90000000000011, -370.0, 155.2999999999999, 29.600000000000037, 30.799999999999997, -2.799999999999997, -178.0, -199.0, -0.3999999999999915, -92.2000000000007, -179.8, 11.899999999999977, 20.000000000000014, -247.0, 45.2, -244.0, -10.0, -259.3, -11.499999999999819, -160.0, 20.000000000000014], "policy_predator_policy_reward": [19.0, 17.0, 70.0, 7.0, 83.0, 6.0, 9.0, 62.0, 31.0, 15.0, 26.0, 35.0, 80.0, 1.0, 187.0, 58.0, 39.0, 71.0, 59.0, 5.0, 4.0, 25.0, 77.0, 3.0, 39.0, 4.0, 7.0, 51.0, 3.0, 8.0, 24.0, 12.0, 22.0, 6.0, 21.0, 9.0, 105.0, 110.0, 70.0, 15.0, 32.0, 6.0, 21.0, 116.0, 8.0, 104.0, 28.0, 32.0, 50.0, 50.0, 5.0, 26.0, 18.0, 45.0, 86.0, 12.0, 13.0, 102.0, 60.0, 86.0, 93.0, 24.0, 1.0, 72.0, 54.0, 0.0, 25.0, 29.0, 66.0, 71.0, 59.0, 62.0, 65.0, 54.0, 85.0, 30.0, 69.0, 39.0, 23.0, 1.0, 50.0, 39.0, 82.0, 35.0, 173.0, 133.0, 98.0, 18.0, 123.0, 98.0, 14.0, 43.0, 94.0, 70.0, 26.0, 82.0, 147.0, 17.0, 23.0, 36.0, 45.0, 40.0, 13.0, 11.0, 39.0, 41.0, 225.0, 86.0, 98.0, 97.0, 14.0, 56.0, 74.0, 61.0, 96.0, 24.0, 56.0, 18.0, 69.0, 33.0, 53.0, 113.0, 35.0, 96.0, 47.0, 29.0, 35.0, 44.0, 162.0, 43.0, 101.0, 43.0, 125.0, 60.0, 32.0, 136.0, 100.0, 147.0, 69.0, 2.0, 31.0, 73.0, 157.0, 100.0, 35.0, 28.0, 36.0, 99.0, 66.0, 44.0, 102.0, 65.0, 21.0, 147.0, 94.0, 82.0, 148.0, 58.0, 92.0, 30.0, 53.0, 163.0, 26.0, 19.0, 40.0, 132.0, 63.0, 62.0, 160.0, 24.0, 0.0, 71.0, 156.0, 88.0, 7.0, 58.0, 121.0, 58.0, 29.0, 51.0, 138.0, 154.0, 17.0, 85.0, 59.0, 99.0, 123.0, 109.0, 48.0, 129.0, 9.0, 4.0, 102.0, 138.0, 147.0, 90.0, 137.0, 78.0, 97.0, 97.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6549000592183138, "mean_inference_ms": 1.7011916493715955, "mean_action_processing_ms": 0.26402170093307187, "mean_env_wait_ms": 0.21620463256103115, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003790140151977539, "StateBufferConnector_ms": 0.0031241178512573242, "ViewRequirementAgentConnector_ms": 0.12831687927246094}, "num_episodes": 18, "episode_return_max": 314.5000000000008, "episode_return_min": -250.89999999999884, "episode_return_mean": 57.76899999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.1202295442423, "num_env_steps_trained_throughput_per_sec": 340.1202295442423, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 11470.108, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11470.054, "sample_time_ms": 1346.312, "learn_time_ms": 10105.576, "learn_throughput": 395.821, "synch_weights_time_ms": 16.284}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-50-04", "timestamp": 1723647004, "time_this_iter_s": 11.810137271881104, "time_total_s": 174.34457802772522, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29eef70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 174.34457802772522, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 42.60588235294118, "ram_util_percent": 83.12941176470588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.428569165108696, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.271782958066022, "policy_loss": -0.006738445671428015, "vf_loss": 7.276055853455155, "vf_explained_var": 0.0021011519053625682, "kl": 0.01095809930782619, "entropy": 1.569753392095919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8644511958909413, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.0486957469314495, "policy_loss": -0.01195511641473603, "vf_loss": 6.0593384914297275, "vf_explained_var": 0.016465668104313037, "kl": 0.013123724319406574, "entropy": 1.5355355338444785, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 314.5000000000008, "episode_reward_min": -250.89999999999884, "episode_reward_mean": 38.340999999999894, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -422.7999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.6, "predator_policy": 225.0}, "policy_reward_mean": {"prey_policy": -47.06950000000006, "predator_policy": 66.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-244.80000000000047, 70.70000000000007, 88.1999999999996, 6.300000000000162, -78.70000000000044, 314.5000000000008, -55.299999999999734, 275.6000000000005, 155.49999999999937, 79.80000000000015, 21.500000000000185, -154.20000000000118, 3.0999999999997603, 195.19999999999993, 126.39999999999972, 231.3999999999993, 73.20000000000002, 181.69999999999933, 26.100000000000083, -50.799999999999656, 31.000000000000227, 54.40000000000006, 195.29999999999947, 101.79999999999977, -109.10000000000005, 0.6000000000001672, -41.4, 250.5999999999998, -75.90000000000067, 100.8999999999998, -221.70000000000041, 116.6999999999998, 96.79999999999943, 273.10000000000076, 149.69999999999993, 80.99999999999997, -157.4000000000005, 119.89999999999904, 228.99999999999991, 19.600000000000126, 27.0000000000002, 86.49999999999994, -46.0000000000002, -69.30000000000001, 267.79999999999995, 131.90000000000003, -187.29999999999993, -117.20000000000053, 71.40000000000003, -197.30000000000032, -250.89999999999884, 152.69999999999987, 112.79999999999959, -209.70000000000007, 252.69999999999987, -192.19999999999993, 55.4999999999999, 22.79999999999999, -190.10000000000045, 1.2612133559741778e-13, -66.60000000000039, 59.999999999999766, -68.59999999999997, 227.49999999999915, -72.69999999999999, 216.0, -53.8, 203.09999999999988, -99.70000000000033, 192.59999999999994, 24.0, 185.6999999999996, 77.29999999999998, 162.4, -22.80000000000004, 32.599999999999994, -95.00000000000068, 44.900000000000205, 38.2, -17.0, -55.79999999999983, 54.00000000000013, -54.600000000000634, -138.40000000000026, 230.39999999999984, -12.899999999999684, -50.4000000000002, 57.20000000000019, 248.1999999999999, 46.70000000000014, 36.99999999999985, 65.00000000000006, 52.40000000000008, 34.699999999999854, 3.8000000000000043, 51.800000000000004, -52.10000000000103, 39.90000000000032, 55.20000000000004, 52.50000000000021], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-130.90000000000046, -328.9, 19.40000000000002, -33.6999999999998, -0.4000000000000188, 50.60000000000021, -73.0, -57.70000000000004, -193.90000000000023, 3.1999999999999615, 84.1999999999999, 170.29999999999984, -137.50000000000045, -17.800000000000026, 169.39999999999986, 75.19999999999973, 127.1, -34.59999999999975, 131.60000000000005, -149.80000000000055, -187.90000000000057, 94.39999999999968, -160.60000000000042, -139.60000000000068, -2.4999999999999343, -111.4000000000002, 55.1, 67.10000000000002, 28.10000000000001, 44.30000000000021, 95.89999999999989, 81.4999999999994, 20.000000000000014, -83.80000000000001, 118.09999999999948, -57.40000000000015, 20.000000000000014, -112.89999999999998, -166.90000000000063, 1.0999999999999688, -15.999999999999867, -60.99999999999993, 20.000000000000014, 10.40000000000019, 194.6, -88.29999999999997, -97.60000000000082, 82.4, -381.09999999999997, -33.999999999999986, -114.40000000000003, -0.9999999999999846, -199.9, -62.5, 147.79999999999998, 45.80000000000007, -133.90000000000023, -105.99999999999986, -23.800000000000097, 16.699999999999996, -162.70000000000041, -223.0, 85.99999999999982, -28.299999999999883, -3.6999999999999975, 15.499999999999993, 123.49999999999963, 125.59999999999988, 126.19999999999993, -56.49999999999998, 192.8, -422.7999999999997, -151.60000000000025, -200.80000000000024, -39.09999999999993, 88.99999999999935, 156.19999999999993, -62.2000000000001, -161.20000000000007, 60.80000000000007, -1.900000000000016, -45.099999999999945, 26.599999999999994, -42.10000000000006, -97.3, -114.69999999999996, 4.699999999999989, -205.0, 103.7, 88.09999999999997, 43.69999999999999, 9.200000000000095, -320.19999999999993, -72.1, -111.40000000000012, -149.8000000000004, -73.30000000000003, -40.300000000000026, -230.20000000000033, -135.10000000000002, -273.3999999999989, -224.50000000000009, 76.99999999999999, 4.700000000000017, 45.80000000000003, -36.99999999999993, -159.4, -307.30000000000007, 176.8999999999999, 12.80000000000011, -142.29999999999995, -184.90000000000003, -46.29999999999999, -8.199999999999985, -133.9000000000001, -10.299999999999976, -301.59999999999997, -56.49999999999995, -173.2000000000006, -2.7999999999999687, -187.60000000000053, -85.0, -197.50000000000045, 135.49999999999986, -157.90000000000006, -126.7, 70.70000000000007, 111.79999999999953, -67.0, -177.70000000000007, 137.89999999999998, -46.89999999999999, -131.8, -106.0, -48.99999999999997, 181.09999999999997, 17.899999999999988, -361.6, -45.09999999999999, 172.69999999999987, -133.0, -22.0, 45.8, 59.90000000000011, -370.0, 155.2999999999999, 29.600000000000037, 30.799999999999997, -2.799999999999997, -178.0, -199.0, -0.3999999999999915, -92.2000000000007, -179.8, 11.899999999999977, 20.000000000000014, -247.0, 45.2, -244.0, -10.0, -259.3, -11.499999999999819, -160.0, 20.000000000000014, -53.49999999999983, -87.10000000000085, -67.30000000000007, -334.09999999999957, -67.00000000000014, 178.39999999999998, -149.20000000000022, 5.299999999999965, -15.699999999999747, -177.70000000000005, 25.400000000000006, -92.2000000000001, 47.0, 132.2, 0.20000000000010942, -116.5000000000002, -81.39999999999998, 4.40000000000006, 168.79999999999998, -235.80000000000047, 58.69999999999996, -91.3000000000003, -139.3000000000002, 47.000000000000036, -56.80000000000015, -204.4, 13.699999999999966, -10.900000000000006, -15.699999999999761, -180.40000000000032, 1.0999999999999865, -68.20000000000056, -3.699999999999939, -30.099999999999987, 27.50000000000012, -73.00000000000034], "policy_predator_policy_reward": [105.0, 110.0, 70.0, 15.0, 32.0, 6.0, 21.0, 116.0, 8.0, 104.0, 28.0, 32.0, 50.0, 50.0, 5.0, 26.0, 18.0, 45.0, 86.0, 12.0, 13.0, 102.0, 60.0, 86.0, 93.0, 24.0, 1.0, 72.0, 54.0, 0.0, 25.0, 29.0, 66.0, 71.0, 59.0, 62.0, 65.0, 54.0, 85.0, 30.0, 69.0, 39.0, 23.0, 1.0, 50.0, 39.0, 82.0, 35.0, 173.0, 133.0, 98.0, 18.0, 123.0, 98.0, 14.0, 43.0, 94.0, 70.0, 26.0, 82.0, 147.0, 17.0, 23.0, 36.0, 45.0, 40.0, 13.0, 11.0, 39.0, 41.0, 225.0, 86.0, 98.0, 97.0, 14.0, 56.0, 74.0, 61.0, 96.0, 24.0, 56.0, 18.0, 69.0, 33.0, 53.0, 113.0, 35.0, 96.0, 47.0, 29.0, 35.0, 44.0, 162.0, 43.0, 101.0, 43.0, 125.0, 60.0, 32.0, 136.0, 100.0, 147.0, 69.0, 2.0, 31.0, 73.0, 157.0, 100.0, 35.0, 28.0, 36.0, 99.0, 66.0, 44.0, 102.0, 65.0, 21.0, 147.0, 94.0, 82.0, 148.0, 58.0, 92.0, 30.0, 53.0, 163.0, 26.0, 19.0, 40.0, 132.0, 63.0, 62.0, 160.0, 24.0, 0.0, 71.0, 156.0, 88.0, 7.0, 58.0, 121.0, 58.0, 29.0, 51.0, 138.0, 154.0, 17.0, 85.0, 59.0, 99.0, 123.0, 109.0, 48.0, 129.0, 9.0, 4.0, 102.0, 138.0, 147.0, 90.0, 137.0, 78.0, 97.0, 97.0, 12.0, 74.0, 180.0, 83.0, 53.0, 66.0, 86.0, 45.0, 67.0, 76.0, 81.0, 43.0, 48.0, 21.0, 87.0, 76.0, 16.0, 98.0, 5.0, 127.0, 40.0, 45.0, 19.0, 108.0, 114.0, 151.0, 5.0, 44.0, 105.0, 39.0, 54.0, 53.0, 74.0, 15.0, 27.0, 71.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6619894730870872, "mean_inference_ms": 1.720036836809549, "mean_action_processing_ms": 0.2671994753203192, "mean_env_wait_ms": 0.21847322227139876, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007602691650390625, "StateBufferConnector_ms": 0.012574434280395508, "ViewRequirementAgentConnector_ms": 0.1524571180343628}, "num_episodes": 18, "episode_return_max": 314.5000000000008, "episode_return_min": -250.89999999999884, "episode_return_mean": 38.340999999999894, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.58417255694775, "num_env_steps_trained_throughput_per_sec": 329.58417255694775, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 11536.144, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11536.09, "sample_time_ms": 1419.154, "learn_time_ms": 10098.367, "learn_throughput": 396.104, "synch_weights_time_ms": 16.443}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-50-16", "timestamp": 1723647016, "time_this_iter_s": 12.189280033111572, "time_total_s": 186.5338580608368, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d3d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 186.5338580608368, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 44.57647058823529, "ram_util_percent": 83.34117647058824}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8035395833234937, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.915528955661431, "policy_loss": -0.00597439550661615, "vf_loss": 8.919039676302955, "vf_explained_var": -0.050824393387194036, "kl": 0.010949671590393702, "entropy": 1.5586710177401386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7282204628936828, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.551329981082331, "policy_loss": -0.011526039627346175, "vf_loss": 6.561393644443895, "vf_explained_var": 0.0015935807001023065, "kl": 0.014623639830880573, "entropy": 1.5184210419654847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 273.10000000000076, "episode_reward_min": -324.2999999999998, "episode_reward_mean": 22.344999999999928, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -477.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.6, "predator_policy": 241.0}, "policy_reward_mean": {"prey_policy": -62.922500000000056, "predator_policy": 74.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.100000000000083, -50.799999999999656, 31.000000000000227, 54.40000000000006, 195.29999999999947, 101.79999999999977, -109.10000000000005, 0.6000000000001672, -41.4, 250.5999999999998, -75.90000000000067, 100.8999999999998, -221.70000000000041, 116.6999999999998, 96.79999999999943, 273.10000000000076, 149.69999999999993, 80.99999999999997, -157.4000000000005, 119.89999999999904, 228.99999999999991, 19.600000000000126, 27.0000000000002, 86.49999999999994, -46.0000000000002, -69.30000000000001, 267.79999999999995, 131.90000000000003, -187.29999999999993, -117.20000000000053, 71.40000000000003, -197.30000000000032, -250.89999999999884, 152.69999999999987, 112.79999999999959, -209.70000000000007, 252.69999999999987, -192.19999999999993, 55.4999999999999, 22.79999999999999, -190.10000000000045, 1.2612133559741778e-13, -66.60000000000039, 59.999999999999766, -68.59999999999997, 227.49999999999915, -72.69999999999999, 216.0, -53.8, 203.09999999999988, -99.70000000000033, 192.59999999999994, 24.0, 185.6999999999996, 77.29999999999998, 162.4, -22.80000000000004, 32.599999999999994, -95.00000000000068, 44.900000000000205, 38.2, -17.0, -55.79999999999983, 54.00000000000013, -54.600000000000634, -138.40000000000026, 230.39999999999984, -12.899999999999684, -50.4000000000002, 57.20000000000019, 248.1999999999999, 46.70000000000014, 36.99999999999985, 65.00000000000006, 52.40000000000008, 34.699999999999854, 3.8000000000000043, 51.800000000000004, -52.10000000000103, 39.90000000000032, 55.20000000000004, 52.50000000000021, 74.60000000000004, -162.90000000000012, -98.69999999999993, -120.2000000000003, 59.90000000000008, 88.70000000000006, 42.80000000000021, 47.20000000000017, 139.79999999999984, -56.70000000000001, 85.7999999999999, -30.699999999999882, 26.100000000000165, 268.4000000000001, -324.2999999999998, -87.30000000000074, -194.20000000000013, -67.79999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -112.89999999999998, -166.90000000000063, 1.0999999999999688, -15.999999999999867, -60.99999999999993, 20.000000000000014, 10.40000000000019, 194.6, -88.29999999999997, -97.60000000000082, 82.4, -381.09999999999997, -33.999999999999986, -114.40000000000003, -0.9999999999999846, -199.9, -62.5, 147.79999999999998, 45.80000000000007, -133.90000000000023, -105.99999999999986, -23.800000000000097, 16.699999999999996, -162.70000000000041, -223.0, 85.99999999999982, -28.299999999999883, -3.6999999999999975, 15.499999999999993, 123.49999999999963, 125.59999999999988, 126.19999999999993, -56.49999999999998, 192.8, -422.7999999999997, -151.60000000000025, -200.80000000000024, -39.09999999999993, 88.99999999999935, 156.19999999999993, -62.2000000000001, -161.20000000000007, 60.80000000000007, -1.900000000000016, -45.099999999999945, 26.599999999999994, -42.10000000000006, -97.3, -114.69999999999996, 4.699999999999989, -205.0, 103.7, 88.09999999999997, 43.69999999999999, 9.200000000000095, -320.19999999999993, -72.1, -111.40000000000012, -149.8000000000004, -73.30000000000003, -40.300000000000026, -230.20000000000033, -135.10000000000002, -273.3999999999989, -224.50000000000009, 76.99999999999999, 4.700000000000017, 45.80000000000003, -36.99999999999993, -159.4, -307.30000000000007, 176.8999999999999, 12.80000000000011, -142.29999999999995, -184.90000000000003, -46.29999999999999, -8.199999999999985, -133.9000000000001, -10.299999999999976, -301.59999999999997, -56.49999999999995, -173.2000000000006, -2.7999999999999687, -187.60000000000053, -85.0, -197.50000000000045, 135.49999999999986, -157.90000000000006, -126.7, 70.70000000000007, 111.79999999999953, -67.0, -177.70000000000007, 137.89999999999998, -46.89999999999999, -131.8, -106.0, -48.99999999999997, 181.09999999999997, 17.899999999999988, -361.6, -45.09999999999999, 172.69999999999987, -133.0, -22.0, 45.8, 59.90000000000011, -370.0, 155.2999999999999, 29.600000000000037, 30.799999999999997, -2.799999999999997, -178.0, -199.0, -0.3999999999999915, -92.2000000000007, -179.8, 11.899999999999977, 20.000000000000014, -247.0, 45.2, -244.0, -10.0, -259.3, -11.499999999999819, -160.0, 20.000000000000014, -53.49999999999983, -87.10000000000085, -67.30000000000007, -334.09999999999957, -67.00000000000014, 178.39999999999998, -149.20000000000022, 5.299999999999965, -15.699999999999747, -177.70000000000005, 25.400000000000006, -92.2000000000001, 47.0, 132.2, 0.20000000000010942, -116.5000000000002, -81.39999999999998, 4.40000000000006, 168.79999999999998, -235.80000000000047, 58.69999999999996, -91.3000000000003, -139.3000000000002, 47.000000000000036, -56.80000000000015, -204.4, 13.699999999999966, -10.900000000000006, -15.699999999999761, -180.40000000000032, 1.0999999999999865, -68.20000000000056, -3.699999999999939, -30.099999999999987, 27.50000000000012, -73.00000000000034, 41.89999999999998, -64.30000000000008, -327.4, -95.49999999999997, -241.30000000000004, -120.39999999999995, -298.29999999999916, -70.90000000000013, 50.30000000000005, -102.40000000000032, -477.9, 95.60000000000005, -103.90000000000009, 52.69999999999997, 53.900000000000134, -108.70000000000016, -45.99999999999997, 96.79999999999998, 5.000000000000087, -279.7000000000002, 34.70000000000001, 1.0999999999999865, -277.3000000000002, 32.59999999999998, 20.000000000000014, -79.90000000000025, 79.3999999999998, 160.9999999999999, -364.30000000000007, -193.00000000000003, -116.20000000000029, -150.10000000000045, -240.40000000000006, -266.8000000000001, -279.99999999999983, -56.80000000000004], "policy_predator_policy_reward": [65.0, 54.0, 85.0, 30.0, 69.0, 39.0, 23.0, 1.0, 50.0, 39.0, 82.0, 35.0, 173.0, 133.0, 98.0, 18.0, 123.0, 98.0, 14.0, 43.0, 94.0, 70.0, 26.0, 82.0, 147.0, 17.0, 23.0, 36.0, 45.0, 40.0, 13.0, 11.0, 39.0, 41.0, 225.0, 86.0, 98.0, 97.0, 14.0, 56.0, 74.0, 61.0, 96.0, 24.0, 56.0, 18.0, 69.0, 33.0, 53.0, 113.0, 35.0, 96.0, 47.0, 29.0, 35.0, 44.0, 162.0, 43.0, 101.0, 43.0, 125.0, 60.0, 32.0, 136.0, 100.0, 147.0, 69.0, 2.0, 31.0, 73.0, 157.0, 100.0, 35.0, 28.0, 36.0, 99.0, 66.0, 44.0, 102.0, 65.0, 21.0, 147.0, 94.0, 82.0, 148.0, 58.0, 92.0, 30.0, 53.0, 163.0, 26.0, 19.0, 40.0, 132.0, 63.0, 62.0, 160.0, 24.0, 0.0, 71.0, 156.0, 88.0, 7.0, 58.0, 121.0, 58.0, 29.0, 51.0, 138.0, 154.0, 17.0, 85.0, 59.0, 99.0, 123.0, 109.0, 48.0, 129.0, 9.0, 4.0, 102.0, 138.0, 147.0, 90.0, 137.0, 78.0, 97.0, 97.0, 12.0, 74.0, 180.0, 83.0, 53.0, 66.0, 86.0, 45.0, 67.0, 76.0, 81.0, 43.0, 48.0, 21.0, 87.0, 76.0, 16.0, 98.0, 5.0, 127.0, 40.0, 45.0, 19.0, 108.0, 114.0, 151.0, 5.0, 44.0, 105.0, 39.0, 54.0, 53.0, 74.0, 15.0, 27.0, 71.0, 63.0, 34.0, 171.0, 89.0, 165.0, 98.0, 157.0, 92.0, 43.0, 69.0, 230.0, 241.0, 18.0, 76.0, 2.0, 100.0, 34.0, 55.0, 139.0, 79.0, 34.0, 16.0, 148.0, 66.0, 61.0, 25.0, 17.0, 11.0, 169.0, 64.0, 111.0, 68.0, 190.0, 123.0, 111.0, 158.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6733263898654053, "mean_inference_ms": 1.7483260817228652, "mean_action_processing_ms": 0.2716169733556303, "mean_env_wait_ms": 0.2218926964806635, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0076084136962890625, "StateBufferConnector_ms": 0.012575268745422363, "ViewRequirementAgentConnector_ms": 0.1558753252029419}, "num_episodes": 18, "episode_return_max": 273.10000000000076, "episode_return_min": -324.2999999999998, "episode_return_mean": 22.344999999999928, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 337.29315125996783, "num_env_steps_trained_throughput_per_sec": 337.29315125996783, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 11588.139, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11588.085, "sample_time_ms": 1485.014, "learn_time_ms": 10084.411, "learn_throughput": 396.652, "synch_weights_time_ms": 16.517}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-50-28", "timestamp": 1723647028, "time_this_iter_s": 11.907530069351196, "time_total_s": 198.441388130188, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede9430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 198.441388130188, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 44.099999999999994, "ram_util_percent": 83.5470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6807563860895773, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.650227660224552, "policy_loss": -0.005533558610462086, "vf_loss": 7.653530707182708, "vf_explained_var": -0.1659147135164372, "kl": 0.009913353553545293, "entropy": 1.5640916892460415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5420048961563715, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.937598088178685, "policy_loss": -0.015699587020254323, "vf_loss": 7.951182169636722, "vf_explained_var": 0.007599635351271857, "kl": 0.021154911939694612, "entropy": 1.5164384641975321, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 268.4000000000001, "episode_reward_min": -324.2999999999998, "episode_reward_mean": 2.6609999999999188, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -477.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999997, "predator_policy": 241.0}, "policy_reward_mean": {"prey_policy": -74.70450000000005, "predator_policy": 76.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.0000000000002, 86.49999999999994, -46.0000000000002, -69.30000000000001, 267.79999999999995, 131.90000000000003, -187.29999999999993, -117.20000000000053, 71.40000000000003, -197.30000000000032, -250.89999999999884, 152.69999999999987, 112.79999999999959, -209.70000000000007, 252.69999999999987, -192.19999999999993, 55.4999999999999, 22.79999999999999, -190.10000000000045, 1.2612133559741778e-13, -66.60000000000039, 59.999999999999766, -68.59999999999997, 227.49999999999915, -72.69999999999999, 216.0, -53.8, 203.09999999999988, -99.70000000000033, 192.59999999999994, 24.0, 185.6999999999996, 77.29999999999998, 162.4, -22.80000000000004, 32.599999999999994, -95.00000000000068, 44.900000000000205, 38.2, -17.0, -55.79999999999983, 54.00000000000013, -54.600000000000634, -138.40000000000026, 230.39999999999984, -12.899999999999684, -50.4000000000002, 57.20000000000019, 248.1999999999999, 46.70000000000014, 36.99999999999985, 65.00000000000006, 52.40000000000008, 34.699999999999854, 3.8000000000000043, 51.800000000000004, -52.10000000000103, 39.90000000000032, 55.20000000000004, 52.50000000000021, 74.60000000000004, -162.90000000000012, -98.69999999999993, -120.2000000000003, 59.90000000000008, 88.70000000000006, 42.80000000000021, 47.20000000000017, 139.79999999999984, -56.70000000000001, 85.7999999999999, -30.699999999999882, 26.100000000000165, 268.4000000000001, -324.2999999999998, -87.30000000000074, -194.20000000000013, -67.79999999999993, -57.59999999999999, 65.70000000000014, -107.70000000000061, 205.99999999999935, -19.999999999999844, -130.6000000000014, 129.59999999999903, 37.500000000000206, -7.399999999999972, -201.70000000000007, 44.50000000000027, -58.99999999999985, -85.4000000000004, 34.800000000000125, -252.30000000000055, -9.899999999999865, 7.500000000000034, -8.100000000000028, -6.899999999999898, -68.6999999999999, -68.79999999999981, -219.70000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1.900000000000016, -45.099999999999945, 26.599999999999994, -42.10000000000006, -97.3, -114.69999999999996, 4.699999999999989, -205.0, 103.7, 88.09999999999997, 43.69999999999999, 9.200000000000095, -320.19999999999993, -72.1, -111.40000000000012, -149.8000000000004, -73.30000000000003, -40.300000000000026, -230.20000000000033, -135.10000000000002, -273.3999999999989, -224.50000000000009, 76.99999999999999, 4.700000000000017, 45.80000000000003, -36.99999999999993, -159.4, -307.30000000000007, 176.8999999999999, 12.80000000000011, -142.29999999999995, -184.90000000000003, -46.29999999999999, -8.199999999999985, -133.9000000000001, -10.299999999999976, -301.59999999999997, -56.49999999999995, -173.2000000000006, -2.7999999999999687, -187.60000000000053, -85.0, -197.50000000000045, 135.49999999999986, -157.90000000000006, -126.7, 70.70000000000007, 111.79999999999953, -67.0, -177.70000000000007, 137.89999999999998, -46.89999999999999, -131.8, -106.0, -48.99999999999997, 181.09999999999997, 17.899999999999988, -361.6, -45.09999999999999, 172.69999999999987, -133.0, -22.0, 45.8, 59.90000000000011, -370.0, 155.2999999999999, 29.600000000000037, 30.799999999999997, -2.799999999999997, -178.0, -199.0, -0.3999999999999915, -92.2000000000007, -179.8, 11.899999999999977, 20.000000000000014, -247.0, 45.2, -244.0, -10.0, -259.3, -11.499999999999819, -160.0, 20.000000000000014, -53.49999999999983, -87.10000000000085, -67.30000000000007, -334.09999999999957, -67.00000000000014, 178.39999999999998, -149.20000000000022, 5.299999999999965, -15.699999999999747, -177.70000000000005, 25.400000000000006, -92.2000000000001, 47.0, 132.2, 0.20000000000010942, -116.5000000000002, -81.39999999999998, 4.40000000000006, 168.79999999999998, -235.80000000000047, 58.69999999999996, -91.3000000000003, -139.3000000000002, 47.000000000000036, -56.80000000000015, -204.4, 13.699999999999966, -10.900000000000006, -15.699999999999761, -180.40000000000032, 1.0999999999999865, -68.20000000000056, -3.699999999999939, -30.099999999999987, 27.50000000000012, -73.00000000000034, 41.89999999999998, -64.30000000000008, -327.4, -95.49999999999997, -241.30000000000004, -120.39999999999995, -298.29999999999916, -70.90000000000013, 50.30000000000005, -102.40000000000032, -477.9, 95.60000000000005, -103.90000000000009, 52.69999999999997, 53.900000000000134, -108.70000000000016, -45.99999999999997, 96.79999999999998, 5.000000000000087, -279.7000000000002, 34.70000000000001, 1.0999999999999865, -277.3000000000002, 32.59999999999998, 20.000000000000014, -79.90000000000025, 79.3999999999998, 160.9999999999999, -364.30000000000007, -193.00000000000003, -116.20000000000029, -150.10000000000045, -240.40000000000006, -266.8000000000001, -279.99999999999983, -56.80000000000004, -108.3999999999998, -26.199999999999974, -14.19999999999993, -33.1, 38.599999999999966, -331.3000000000002, 107.29999999999984, 73.69999999999993, -124.00000000000017, 20.000000000000014, -55.60000000000032, -205.00000000000045, -28.59999999999978, 99.19999999999973, -33.699999999999754, -5.800000000000001, 20.000000000000014, -240.40000000000003, -144.10000000000002, -229.60000000000008, -75.40000000000026, 26.899999999999974, -116.50000000000065, -242.49999999999997, 27.19999999999998, -294.60000000000025, 20.000000000000014, -95.1999999999999, -186.10000000000045, -278.20000000000005, -210.70000000000036, 30.799999999999997, -27.099999999999888, -39.399999999999885, -172.60000000000014, -14.499999999999822, -185.80000000000047, 38.89999999999997, -59.80000000000045, -151.89999999999986, -2.1999999999999535, -211.6000000000001, -313.5999999999999, -198.1000000000002], "policy_predator_policy_reward": [56.0, 18.0, 69.0, 33.0, 53.0, 113.0, 35.0, 96.0, 47.0, 29.0, 35.0, 44.0, 162.0, 43.0, 101.0, 43.0, 125.0, 60.0, 32.0, 136.0, 100.0, 147.0, 69.0, 2.0, 31.0, 73.0, 157.0, 100.0, 35.0, 28.0, 36.0, 99.0, 66.0, 44.0, 102.0, 65.0, 21.0, 147.0, 94.0, 82.0, 148.0, 58.0, 92.0, 30.0, 53.0, 163.0, 26.0, 19.0, 40.0, 132.0, 63.0, 62.0, 160.0, 24.0, 0.0, 71.0, 156.0, 88.0, 7.0, 58.0, 121.0, 58.0, 29.0, 51.0, 138.0, 154.0, 17.0, 85.0, 59.0, 99.0, 123.0, 109.0, 48.0, 129.0, 9.0, 4.0, 102.0, 138.0, 147.0, 90.0, 137.0, 78.0, 97.0, 97.0, 12.0, 74.0, 180.0, 83.0, 53.0, 66.0, 86.0, 45.0, 67.0, 76.0, 81.0, 43.0, 48.0, 21.0, 87.0, 76.0, 16.0, 98.0, 5.0, 127.0, 40.0, 45.0, 19.0, 108.0, 114.0, 151.0, 5.0, 44.0, 105.0, 39.0, 54.0, 53.0, 74.0, 15.0, 27.0, 71.0, 63.0, 34.0, 171.0, 89.0, 165.0, 98.0, 157.0, 92.0, 43.0, 69.0, 230.0, 241.0, 18.0, 76.0, 2.0, 100.0, 34.0, 55.0, 139.0, 79.0, 34.0, 16.0, 148.0, 66.0, 61.0, 25.0, 17.0, 11.0, 169.0, 64.0, 111.0, 68.0, 190.0, 123.0, 111.0, 158.0, 68.0, 9.0, 56.0, 57.0, 169.0, 16.0, 18.0, 7.0, 31.0, 53.0, 37.0, 93.0, 28.0, 31.0, 58.0, 19.0, 89.0, 124.0, 14.0, 158.0, 54.0, 39.0, 163.0, 137.0, 155.0, 27.0, 54.0, 56.0, 104.0, 108.0, 98.0, 72.0, 56.0, 18.0, 89.0, 90.0, 85.0, 55.0, 83.0, 60.0, 15.0, 130.0, 168.0, 124.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.689577852344399, "mean_inference_ms": 1.7865687848906844, "mean_action_processing_ms": 0.27708134083196695, "mean_env_wait_ms": 0.22643598309427668, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007584929466247559, "StateBufferConnector_ms": 0.013784170150756836, "ViewRequirementAgentConnector_ms": 0.16795217990875244}, "num_episodes": 22, "episode_return_max": 268.4000000000001, "episode_return_min": -324.2999999999998, "episode_return_mean": 2.6609999999999188, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.5013185785218, "num_env_steps_trained_throughput_per_sec": 338.5013185785218, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 11625.124, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11625.069, "sample_time_ms": 1545.505, "learn_time_ms": 10061.097, "learn_throughput": 397.571, "synch_weights_time_ms": 16.614}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-50-40", "timestamp": 1723647040, "time_this_iter_s": 11.864071130752563, "time_total_s": 210.30545926094055, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee119d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 210.30545926094055, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 44.023529411764706, "ram_util_percent": 83.41176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.414062815210807, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.06409248775906, "policy_loss": -0.009778610109499404, "vf_loss": 8.07095088201856, "vf_explained_var": -0.09710986759296801, "kl": 0.012978724190789269, "entropy": 1.5602723314648583, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.640744099131337, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.110867294937215, "policy_loss": -0.011534450086395419, "vf_loss": 8.12019270538653, "vf_explained_var": 0.010205184372644576, "kl": 0.01472673450790069, "entropy": 1.4972968207465278, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 268.4000000000001, "episode_reward_min": -324.2999999999998, "episode_reward_mean": -8.538000000000086, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -477.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999997, "predator_policy": 241.0}, "policy_reward_mean": {"prey_policy": -86.89900000000007, "predator_policy": 82.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [227.49999999999915, -72.69999999999999, 216.0, -53.8, 203.09999999999988, -99.70000000000033, 192.59999999999994, 24.0, 185.6999999999996, 77.29999999999998, 162.4, -22.80000000000004, 32.599999999999994, -95.00000000000068, 44.900000000000205, 38.2, -17.0, -55.79999999999983, 54.00000000000013, -54.600000000000634, -138.40000000000026, 230.39999999999984, -12.899999999999684, -50.4000000000002, 57.20000000000019, 248.1999999999999, 46.70000000000014, 36.99999999999985, 65.00000000000006, 52.40000000000008, 34.699999999999854, 3.8000000000000043, 51.800000000000004, -52.10000000000103, 39.90000000000032, 55.20000000000004, 52.50000000000021, 74.60000000000004, -162.90000000000012, -98.69999999999993, -120.2000000000003, 59.90000000000008, 88.70000000000006, 42.80000000000021, 47.20000000000017, 139.79999999999984, -56.70000000000001, 85.7999999999999, -30.699999999999882, 26.100000000000165, 268.4000000000001, -324.2999999999998, -87.30000000000074, -194.20000000000013, -67.79999999999993, -57.59999999999999, 65.70000000000014, -107.70000000000061, 205.99999999999935, -19.999999999999844, -130.6000000000014, 129.59999999999903, 37.500000000000206, -7.399999999999972, -201.70000000000007, 44.50000000000027, -58.99999999999985, -85.4000000000004, 34.800000000000125, -252.30000000000055, -9.899999999999865, 7.500000000000034, -8.100000000000028, -6.899999999999898, -68.6999999999999, -68.79999999999981, -219.70000000000022, -170.40000000000015, 24.30000000000021, -3.5000000000000053, 15.700000000000134, 40.9000000000002, -51.5000000000008, -90.49999999999999, -171.80000000000024, -19.399999999999846, -95.80000000000035, -90.80000000000038, -56.89999999999998, -5.1000000000000565, -2.999999999999886, -249.40000000000032, 14.599999999999941, -209.50000000000043, 0.7000000000001231, -23.39999999999994, -62.99999999999986, -33.60000000000001, 15.19999999999999, -247.80000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [70.70000000000007, 111.79999999999953, -67.0, -177.70000000000007, 137.89999999999998, -46.89999999999999, -131.8, -106.0, -48.99999999999997, 181.09999999999997, 17.899999999999988, -361.6, -45.09999999999999, 172.69999999999987, -133.0, -22.0, 45.8, 59.90000000000011, -370.0, 155.2999999999999, 29.600000000000037, 30.799999999999997, -2.799999999999997, -178.0, -199.0, -0.3999999999999915, -92.2000000000007, -179.8, 11.899999999999977, 20.000000000000014, -247.0, 45.2, -244.0, -10.0, -259.3, -11.499999999999819, -160.0, 20.000000000000014, -53.49999999999983, -87.10000000000085, -67.30000000000007, -334.09999999999957, -67.00000000000014, 178.39999999999998, -149.20000000000022, 5.299999999999965, -15.699999999999747, -177.70000000000005, 25.400000000000006, -92.2000000000001, 47.0, 132.2, 0.20000000000010942, -116.5000000000002, -81.39999999999998, 4.40000000000006, 168.79999999999998, -235.80000000000047, 58.69999999999996, -91.3000000000003, -139.3000000000002, 47.000000000000036, -56.80000000000015, -204.4, 13.699999999999966, -10.900000000000006, -15.699999999999761, -180.40000000000032, 1.0999999999999865, -68.20000000000056, -3.699999999999939, -30.099999999999987, 27.50000000000012, -73.00000000000034, 41.89999999999998, -64.30000000000008, -327.4, -95.49999999999997, -241.30000000000004, -120.39999999999995, -298.29999999999916, -70.90000000000013, 50.30000000000005, -102.40000000000032, -477.9, 95.60000000000005, -103.90000000000009, 52.69999999999997, 53.900000000000134, -108.70000000000016, -45.99999999999997, 96.79999999999998, 5.000000000000087, -279.7000000000002, 34.70000000000001, 1.0999999999999865, -277.3000000000002, 32.59999999999998, 20.000000000000014, -79.90000000000025, 79.3999999999998, 160.9999999999999, -364.30000000000007, -193.00000000000003, -116.20000000000029, -150.10000000000045, -240.40000000000006, -266.8000000000001, -279.99999999999983, -56.80000000000004, -108.3999999999998, -26.199999999999974, -14.19999999999993, -33.1, 38.599999999999966, -331.3000000000002, 107.29999999999984, 73.69999999999993, -124.00000000000017, 20.000000000000014, -55.60000000000032, -205.00000000000045, -28.59999999999978, 99.19999999999973, -33.699999999999754, -5.800000000000001, 20.000000000000014, -240.40000000000003, -144.10000000000002, -229.60000000000008, -75.40000000000026, 26.899999999999974, -116.50000000000065, -242.49999999999997, 27.19999999999998, -294.60000000000025, 20.000000000000014, -95.1999999999999, -186.10000000000045, -278.20000000000005, -210.70000000000036, 30.799999999999997, -27.099999999999888, -39.399999999999885, -172.60000000000014, -14.499999999999822, -185.80000000000047, 38.89999999999997, -59.80000000000045, -151.89999999999986, -2.1999999999999535, -211.6000000000001, -313.5999999999999, -198.1000000000002, -336.4, -118.00000000000011, -12.100000000000385, -61.59999999999988, -388.0, 54.500000000000064, -157.3, 20.000000000000014, -51.10000000000008, -18.999999999999993, -47.19999999999976, -88.30000000000078, -163.6, -241.90000000000012, -228.40000000000012, -213.40000000000015, -155.2000000000003, 21.80000000000003, -372.70000000000005, -3.0999999999999615, -134.2000000000003, -139.60000000000008, -202.90000000000015, -45.99999999999995, -123.10000000000005, -55.000000000000284, -73.00000000000011, -18.99999999999993, -214.0000000000002, -255.40000000000015, 20.000000000000014, -51.399999999999764, -295.9000000000001, -145.60000000000034, -20.19999999999989, -132.10000000000002, -342.1, 76.6999999999995, -263.20000000000005, -17.800000000000026, -249.0000000000004, -58.59999999999999, -230.50000000000014, -13.299999999999983, -233.50000000000003, -385.30000000000007], "policy_predator_policy_reward": [26.0, 19.0, 40.0, 132.0, 63.0, 62.0, 160.0, 24.0, 0.0, 71.0, 156.0, 88.0, 7.0, 58.0, 121.0, 58.0, 29.0, 51.0, 138.0, 154.0, 17.0, 85.0, 59.0, 99.0, 123.0, 109.0, 48.0, 129.0, 9.0, 4.0, 102.0, 138.0, 147.0, 90.0, 137.0, 78.0, 97.0, 97.0, 12.0, 74.0, 180.0, 83.0, 53.0, 66.0, 86.0, 45.0, 67.0, 76.0, 81.0, 43.0, 48.0, 21.0, 87.0, 76.0, 16.0, 98.0, 5.0, 127.0, 40.0, 45.0, 19.0, 108.0, 114.0, 151.0, 5.0, 44.0, 105.0, 39.0, 54.0, 53.0, 74.0, 15.0, 27.0, 71.0, 63.0, 34.0, 171.0, 89.0, 165.0, 98.0, 157.0, 92.0, 43.0, 69.0, 230.0, 241.0, 18.0, 76.0, 2.0, 100.0, 34.0, 55.0, 139.0, 79.0, 34.0, 16.0, 148.0, 66.0, 61.0, 25.0, 17.0, 11.0, 169.0, 64.0, 111.0, 68.0, 190.0, 123.0, 111.0, 158.0, 68.0, 9.0, 56.0, 57.0, 169.0, 16.0, 18.0, 7.0, 31.0, 53.0, 37.0, 93.0, 28.0, 31.0, 58.0, 19.0, 89.0, 124.0, 14.0, 158.0, 54.0, 39.0, 163.0, 137.0, 155.0, 27.0, 54.0, 56.0, 104.0, 108.0, 98.0, 72.0, 56.0, 18.0, 89.0, 90.0, 85.0, 55.0, 83.0, 60.0, 15.0, 130.0, 168.0, 124.0, 117.0, 167.0, 32.0, 66.0, 183.0, 147.0, 75.0, 78.0, 50.0, 61.0, 32.0, 52.0, 163.0, 152.0, 154.0, 116.0, 38.0, 76.0, 135.0, 145.0, 114.0, 69.0, 61.0, 131.0, 119.0, 54.0, 89.0, 0.0, 103.0, 117.0, 31.0, 15.0, 79.0, 153.0, 36.0, 117.0, 174.0, 68.0, 148.0, 70.0, 123.0, 151.0, 135.0, 124.0, 190.0, 181.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7054805164494579, "mean_inference_ms": 1.8283784829404426, "mean_action_processing_ms": 0.2847075362421329, "mean_env_wait_ms": 0.23109524804213558, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008202075958251953, "StateBufferConnector_ms": 0.01401221752166748, "ViewRequirementAgentConnector_ms": 0.16845738887786865}, "num_episodes": 23, "episode_return_max": 268.4000000000001, "episode_return_min": -324.2999999999998, "episode_return_mean": -8.538000000000086, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.6005215353678, "num_env_steps_trained_throughput_per_sec": 338.6005215353678, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 11656.071, "restore_workers_time_ms": 0.019, "training_step_time_ms": 11656.017, "sample_time_ms": 1593.781, "learn_time_ms": 10043.762, "learn_throughput": 398.257, "synch_weights_time_ms": 16.651}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-50-52", "timestamp": 1723647052, "time_this_iter_s": 11.834731101989746, "time_total_s": 222.1401903629303, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32edda0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 222.1401903629303, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 44.576470588235296, "ram_util_percent": 83.2764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7706841324056897, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.0707566074593355, "policy_loss": -0.010834746349051043, "vf_loss": 7.079248089260525, "vf_explained_var": -0.07120563621243471, "kl": 0.010414513841312464, "entropy": 1.5431763441474349, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.914675537335179, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.910595851474338, "policy_loss": -0.006166839492433364, "vf_loss": 5.915567858256991, "vf_explained_var": 0.004172826160198797, "kl": 0.007965582500038744, "entropy": 1.5160707385451706, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 268.4000000000001, "episode_reward_min": -324.2999999999998, "episode_reward_mean": -15.946000000000078, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -477.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.39999999999998, "predator_policy": 241.0}, "policy_reward_mean": {"prey_policy": -87.50300000000007, "predator_policy": 79.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.00000000000013, -54.600000000000634, -138.40000000000026, 230.39999999999984, -12.899999999999684, -50.4000000000002, 57.20000000000019, 248.1999999999999, 46.70000000000014, 36.99999999999985, 65.00000000000006, 52.40000000000008, 34.699999999999854, 3.8000000000000043, 51.800000000000004, -52.10000000000103, 39.90000000000032, 55.20000000000004, 52.50000000000021, 74.60000000000004, -162.90000000000012, -98.69999999999993, -120.2000000000003, 59.90000000000008, 88.70000000000006, 42.80000000000021, 47.20000000000017, 139.79999999999984, -56.70000000000001, 85.7999999999999, -30.699999999999882, 26.100000000000165, 268.4000000000001, -324.2999999999998, -87.30000000000074, -194.20000000000013, -67.79999999999993, -57.59999999999999, 65.70000000000014, -107.70000000000061, 205.99999999999935, -19.999999999999844, -130.6000000000014, 129.59999999999903, 37.500000000000206, -7.399999999999972, -201.70000000000007, 44.50000000000027, -58.99999999999985, -85.4000000000004, 34.800000000000125, -252.30000000000055, -9.899999999999865, 7.500000000000034, -8.100000000000028, -6.899999999999898, -68.6999999999999, -68.79999999999981, -219.70000000000022, -170.40000000000015, 24.30000000000021, -3.5000000000000053, 15.700000000000134, 40.9000000000002, -51.5000000000008, -90.49999999999999, -171.80000000000024, -19.399999999999846, -95.80000000000035, -90.80000000000038, -56.89999999999998, -5.1000000000000565, -2.999999999999886, -249.40000000000032, 14.599999999999941, -209.50000000000043, 0.7000000000001231, -23.39999999999994, -62.99999999999986, -33.60000000000001, 15.19999999999999, -247.80000000000007, -24.49999999999971, 94.5999999999994, 45.80000000000012, 122.69999999999956, -1.400000000000241, 83.49999999999986, 53.300000000000296, -58.40000000000025, 32.70000000000023, 45.40000000000034, 123.59999999999982, -235.7000000000007, 84.19999999999997, 2.400000000000169, 11.500000000000407, -121.30000000000047, -42.4000000000006, 30.700000000000074], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-160.0, 20.000000000000014, -53.49999999999983, -87.10000000000085, -67.30000000000007, -334.09999999999957, -67.00000000000014, 178.39999999999998, -149.20000000000022, 5.299999999999965, -15.699999999999747, -177.70000000000005, 25.400000000000006, -92.2000000000001, 47.0, 132.2, 0.20000000000010942, -116.5000000000002, -81.39999999999998, 4.40000000000006, 168.79999999999998, -235.80000000000047, 58.69999999999996, -91.3000000000003, -139.3000000000002, 47.000000000000036, -56.80000000000015, -204.4, 13.699999999999966, -10.900000000000006, -15.699999999999761, -180.40000000000032, 1.0999999999999865, -68.20000000000056, -3.699999999999939, -30.099999999999987, 27.50000000000012, -73.00000000000034, 41.89999999999998, -64.30000000000008, -327.4, -95.49999999999997, -241.30000000000004, -120.39999999999995, -298.29999999999916, -70.90000000000013, 50.30000000000005, -102.40000000000032, -477.9, 95.60000000000005, -103.90000000000009, 52.69999999999997, 53.900000000000134, -108.70000000000016, -45.99999999999997, 96.79999999999998, 5.000000000000087, -279.7000000000002, 34.70000000000001, 1.0999999999999865, -277.3000000000002, 32.59999999999998, 20.000000000000014, -79.90000000000025, 79.3999999999998, 160.9999999999999, -364.30000000000007, -193.00000000000003, -116.20000000000029, -150.10000000000045, -240.40000000000006, -266.8000000000001, -279.99999999999983, -56.80000000000004, -108.3999999999998, -26.199999999999974, -14.19999999999993, -33.1, 38.599999999999966, -331.3000000000002, 107.29999999999984, 73.69999999999993, -124.00000000000017, 20.000000000000014, -55.60000000000032, -205.00000000000045, -28.59999999999978, 99.19999999999973, -33.699999999999754, -5.800000000000001, 20.000000000000014, -240.40000000000003, -144.10000000000002, -229.60000000000008, -75.40000000000026, 26.899999999999974, -116.50000000000065, -242.49999999999997, 27.19999999999998, -294.60000000000025, 20.000000000000014, -95.1999999999999, -186.10000000000045, -278.20000000000005, -210.70000000000036, 30.799999999999997, -27.099999999999888, -39.399999999999885, -172.60000000000014, -14.499999999999822, -185.80000000000047, 38.89999999999997, -59.80000000000045, -151.89999999999986, -2.1999999999999535, -211.6000000000001, -313.5999999999999, -198.1000000000002, -336.4, -118.00000000000011, -12.100000000000385, -61.59999999999988, -388.0, 54.500000000000064, -157.3, 20.000000000000014, -51.10000000000008, -18.999999999999993, -47.19999999999976, -88.30000000000078, -163.6, -241.90000000000012, -228.40000000000012, -213.40000000000015, -155.2000000000003, 21.80000000000003, -372.70000000000005, -3.0999999999999615, -134.2000000000003, -139.60000000000008, -202.90000000000015, -45.99999999999995, -123.10000000000005, -55.000000000000284, -73.00000000000011, -18.99999999999993, -214.0000000000002, -255.40000000000015, 20.000000000000014, -51.399999999999764, -295.9000000000001, -145.60000000000034, -20.19999999999989, -132.10000000000002, -342.1, 76.6999999999995, -263.20000000000005, -17.800000000000026, -249.0000000000004, -58.59999999999999, -230.50000000000014, -13.299999999999983, -233.50000000000003, -385.30000000000007, -45.100000000000065, -99.40000000000049, 35.000000000000064, 44.60000000000018, -68.20000000000043, 8.0, 38.90000000000006, 15.799999999999962, -89.20000000000084, -11.200000000000102, 17.00000000000001, -50.50000000000031, -43.300000000000054, -0.3999999999998738, -59.79999999999979, -147.6000000000006, -13.599999999999783, -93.70000000000019, -31.599999999999902, 20.000000000000014, -17.5000000000001, 28.100000000000087, -276.1000000000002, -217.60000000000036, -13.299999999999855, -17.499999999999936, -199.60000000000036, 5.000000000000156, -34.59999999999975, 4.1000000000002, -213.1000000000002, -161.20000000000056, -162.7000000000003, -12.69999999999993, -67.00000000000003, -34.29999999999993], "policy_predator_policy_reward": [97.0, 97.0, 12.0, 74.0, 180.0, 83.0, 53.0, 66.0, 86.0, 45.0, 67.0, 76.0, 81.0, 43.0, 48.0, 21.0, 87.0, 76.0, 16.0, 98.0, 5.0, 127.0, 40.0, 45.0, 19.0, 108.0, 114.0, 151.0, 5.0, 44.0, 105.0, 39.0, 54.0, 53.0, 74.0, 15.0, 27.0, 71.0, 63.0, 34.0, 171.0, 89.0, 165.0, 98.0, 157.0, 92.0, 43.0, 69.0, 230.0, 241.0, 18.0, 76.0, 2.0, 100.0, 34.0, 55.0, 139.0, 79.0, 34.0, 16.0, 148.0, 66.0, 61.0, 25.0, 17.0, 11.0, 169.0, 64.0, 111.0, 68.0, 190.0, 123.0, 111.0, 158.0, 68.0, 9.0, 56.0, 57.0, 169.0, 16.0, 18.0, 7.0, 31.0, 53.0, 37.0, 93.0, 28.0, 31.0, 58.0, 19.0, 89.0, 124.0, 14.0, 158.0, 54.0, 39.0, 163.0, 137.0, 155.0, 27.0, 54.0, 56.0, 104.0, 108.0, 98.0, 72.0, 56.0, 18.0, 89.0, 90.0, 85.0, 55.0, 83.0, 60.0, 15.0, 130.0, 168.0, 124.0, 117.0, 167.0, 32.0, 66.0, 183.0, 147.0, 75.0, 78.0, 50.0, 61.0, 32.0, 52.0, 163.0, 152.0, 154.0, 116.0, 38.0, 76.0, 135.0, 145.0, 114.0, 69.0, 61.0, 131.0, 119.0, 54.0, 89.0, 0.0, 103.0, 117.0, 31.0, 15.0, 79.0, 153.0, 36.0, 117.0, 174.0, 68.0, 148.0, 70.0, 123.0, 151.0, 135.0, 124.0, 190.0, 181.0, 82.0, 38.0, 3.0, 12.0, 49.0, 57.0, 39.0, 29.0, 47.0, 52.0, 39.0, 78.0, 35.0, 62.0, 76.0, 73.0, 70.0, 70.0, 39.0, 18.0, 54.0, 59.0, 117.0, 141.0, 60.0, 55.0, 91.0, 106.0, 17.0, 25.0, 119.0, 134.0, 87.0, 46.0, 67.0, 65.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7160232035715164, "mean_inference_ms": 1.8511165945180608, "mean_action_processing_ms": 0.28861804129529844, "mean_env_wait_ms": 0.23374646603658356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01034080982208252, "StateBufferConnector_ms": 0.013991832733154297, "ViewRequirementAgentConnector_ms": 0.16175031661987305}, "num_episodes": 18, "episode_return_max": 268.4000000000001, "episode_return_min": -324.2999999999998, "episode_return_mean": -15.946000000000078, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.289241807343, "num_env_steps_trained_throughput_per_sec": 341.289241807343, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 11692.528, "restore_workers_time_ms": 0.019, "training_step_time_ms": 11692.472, "sample_time_ms": 1628.837, "learn_time_ms": 10045.569, "learn_throughput": 398.185, "synch_weights_time_ms": 15.633}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-51-04", "timestamp": 1723647064, "time_this_iter_s": 11.745868921279907, "time_total_s": 233.8860592842102, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32eddbe50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 233.8860592842102, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 44.637499999999996, "ram_util_percent": 83.3125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.795551498226388, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.866561804372798, "policy_loss": -0.006030694898415022, "vf_loss": 5.870750402016615, "vf_explained_var": 0.06419354809655084, "kl": 0.008187164096194771, "entropy": 1.5688598958272784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0613424078812677, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.252777589818157, "policy_loss": -0.0122625816502564, "vf_loss": 4.26274142063484, "vf_explained_var": -0.004438317705083777, "kl": 0.015324995004653822, "entropy": 1.491389773825489, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 268.4000000000001, "episode_reward_min": -324.2999999999998, "episode_reward_mean": -16.01000000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -477.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 160.9999999999999, "predator_policy": 241.0}, "policy_reward_mean": {"prey_policy": -84.44000000000007, "predator_policy": 76.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [52.50000000000021, 74.60000000000004, -162.90000000000012, -98.69999999999993, -120.2000000000003, 59.90000000000008, 88.70000000000006, 42.80000000000021, 47.20000000000017, 139.79999999999984, -56.70000000000001, 85.7999999999999, -30.699999999999882, 26.100000000000165, 268.4000000000001, -324.2999999999998, -87.30000000000074, -194.20000000000013, -67.79999999999993, -57.59999999999999, 65.70000000000014, -107.70000000000061, 205.99999999999935, -19.999999999999844, -130.6000000000014, 129.59999999999903, 37.500000000000206, -7.399999999999972, -201.70000000000007, 44.50000000000027, -58.99999999999985, -85.4000000000004, 34.800000000000125, -252.30000000000055, -9.899999999999865, 7.500000000000034, -8.100000000000028, -6.899999999999898, -68.6999999999999, -68.79999999999981, -219.70000000000022, -170.40000000000015, 24.30000000000021, -3.5000000000000053, 15.700000000000134, 40.9000000000002, -51.5000000000008, -90.49999999999999, -171.80000000000024, -19.399999999999846, -95.80000000000035, -90.80000000000038, -56.89999999999998, -5.1000000000000565, -2.999999999999886, -249.40000000000032, 14.599999999999941, -209.50000000000043, 0.7000000000001231, -23.39999999999994, -62.99999999999986, -33.60000000000001, 15.19999999999999, -247.80000000000007, -24.49999999999971, 94.5999999999994, 45.80000000000012, 122.69999999999956, -1.400000000000241, 83.49999999999986, 53.300000000000296, -58.40000000000025, 32.70000000000023, 45.40000000000034, 123.59999999999982, -235.7000000000007, 84.19999999999997, 2.400000000000169, 11.500000000000407, -121.30000000000047, -42.4000000000006, 30.700000000000074, 57.100000000000236, 14.199999999999934, -8.899999999999704, 41.30000000000033, 35.400000000000205, 111.1999999999997, -256.8999999999969, 76.10000000000002, 76.40000000000022, 59.00000000000022, 57.600000000000286, 40.80000000000033, -65.99999999999984, 165.59999999999968, -1.0000000000003433, 10.100000000000064, 116.20000000000005, 133.29999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [27.50000000000012, -73.00000000000034, 41.89999999999998, -64.30000000000008, -327.4, -95.49999999999997, -241.30000000000004, -120.39999999999995, -298.29999999999916, -70.90000000000013, 50.30000000000005, -102.40000000000032, -477.9, 95.60000000000005, -103.90000000000009, 52.69999999999997, 53.900000000000134, -108.70000000000016, -45.99999999999997, 96.79999999999998, 5.000000000000087, -279.7000000000002, 34.70000000000001, 1.0999999999999865, -277.3000000000002, 32.59999999999998, 20.000000000000014, -79.90000000000025, 79.3999999999998, 160.9999999999999, -364.30000000000007, -193.00000000000003, -116.20000000000029, -150.10000000000045, -240.40000000000006, -266.8000000000001, -279.99999999999983, -56.80000000000004, -108.3999999999998, -26.199999999999974, -14.19999999999993, -33.1, 38.599999999999966, -331.3000000000002, 107.29999999999984, 73.69999999999993, -124.00000000000017, 20.000000000000014, -55.60000000000032, -205.00000000000045, -28.59999999999978, 99.19999999999973, -33.699999999999754, -5.800000000000001, 20.000000000000014, -240.40000000000003, -144.10000000000002, -229.60000000000008, -75.40000000000026, 26.899999999999974, -116.50000000000065, -242.49999999999997, 27.19999999999998, -294.60000000000025, 20.000000000000014, -95.1999999999999, -186.10000000000045, -278.20000000000005, -210.70000000000036, 30.799999999999997, -27.099999999999888, -39.399999999999885, -172.60000000000014, -14.499999999999822, -185.80000000000047, 38.89999999999997, -59.80000000000045, -151.89999999999986, -2.1999999999999535, -211.6000000000001, -313.5999999999999, -198.1000000000002, -336.4, -118.00000000000011, -12.100000000000385, -61.59999999999988, -388.0, 54.500000000000064, -157.3, 20.000000000000014, -51.10000000000008, -18.999999999999993, -47.19999999999976, -88.30000000000078, -163.6, -241.90000000000012, -228.40000000000012, -213.40000000000015, -155.2000000000003, 21.80000000000003, -372.70000000000005, -3.0999999999999615, -134.2000000000003, -139.60000000000008, -202.90000000000015, -45.99999999999995, -123.10000000000005, -55.000000000000284, -73.00000000000011, -18.99999999999993, -214.0000000000002, -255.40000000000015, 20.000000000000014, -51.399999999999764, -295.9000000000001, -145.60000000000034, -20.19999999999989, -132.10000000000002, -342.1, 76.6999999999995, -263.20000000000005, -17.800000000000026, -249.0000000000004, -58.59999999999999, -230.50000000000014, -13.299999999999983, -233.50000000000003, -385.30000000000007, -45.100000000000065, -99.40000000000049, 35.000000000000064, 44.60000000000018, -68.20000000000043, 8.0, 38.90000000000006, 15.799999999999962, -89.20000000000084, -11.200000000000102, 17.00000000000001, -50.50000000000031, -43.300000000000054, -0.3999999999998738, -59.79999999999979, -147.6000000000006, -13.599999999999783, -93.70000000000019, -31.599999999999902, 20.000000000000014, -17.5000000000001, 28.100000000000087, -276.1000000000002, -217.60000000000036, -13.299999999999855, -17.499999999999936, -199.60000000000036, 5.000000000000156, -34.59999999999975, 4.1000000000002, -213.1000000000002, -161.20000000000056, -162.7000000000003, -12.69999999999993, -67.00000000000003, -34.29999999999993, -86.50000000000017, 14.600000000000042, 43.40000000000021, -110.20000000000078, -173.19999999999985, 59.3000000000002, -12.699999999999857, 20.000000000000014, -71.50000000000082, -54.1, 54.200000000000074, 8.000000000000039, -241.60000000000036, -208.3000000000005, -59.80000000000062, 80.90000000000002, 23.6000000000001, 3.799999999999976, 21.50000000000003, -8.499999999999854, -201.7000000000003, 41.30000000000021, -67.00000000000077, 30.800000000000196, -378.9999999999999, 20.000000000000014, 28.700000000000003, 83.89999999999975, 3.500000000000192, -101.50000000000045, 7.399999999999965, -25.29999999999977, 54.20000000000013, 2.000000000000168, 20.000000000000014, 56.30000000000001], "policy_predator_policy_reward": [27.0, 71.0, 63.0, 34.0, 171.0, 89.0, 165.0, 98.0, 157.0, 92.0, 43.0, 69.0, 230.0, 241.0, 18.0, 76.0, 2.0, 100.0, 34.0, 55.0, 139.0, 79.0, 34.0, 16.0, 148.0, 66.0, 61.0, 25.0, 17.0, 11.0, 169.0, 64.0, 111.0, 68.0, 190.0, 123.0, 111.0, 158.0, 68.0, 9.0, 56.0, 57.0, 169.0, 16.0, 18.0, 7.0, 31.0, 53.0, 37.0, 93.0, 28.0, 31.0, 58.0, 19.0, 89.0, 124.0, 14.0, 158.0, 54.0, 39.0, 163.0, 137.0, 155.0, 27.0, 54.0, 56.0, 104.0, 108.0, 98.0, 72.0, 56.0, 18.0, 89.0, 90.0, 85.0, 55.0, 83.0, 60.0, 15.0, 130.0, 168.0, 124.0, 117.0, 167.0, 32.0, 66.0, 183.0, 147.0, 75.0, 78.0, 50.0, 61.0, 32.0, 52.0, 163.0, 152.0, 154.0, 116.0, 38.0, 76.0, 135.0, 145.0, 114.0, 69.0, 61.0, 131.0, 119.0, 54.0, 89.0, 0.0, 103.0, 117.0, 31.0, 15.0, 79.0, 153.0, 36.0, 117.0, 174.0, 68.0, 148.0, 70.0, 123.0, 151.0, 135.0, 124.0, 190.0, 181.0, 82.0, 38.0, 3.0, 12.0, 49.0, 57.0, 39.0, 29.0, 47.0, 52.0, 39.0, 78.0, 35.0, 62.0, 76.0, 73.0, 70.0, 70.0, 39.0, 18.0, 54.0, 59.0, 117.0, 141.0, 60.0, 55.0, 91.0, 106.0, 17.0, 25.0, 119.0, 134.0, 87.0, 46.0, 67.0, 65.0, 63.0, 66.0, 19.0, 62.0, 75.0, 30.0, 28.0, 6.0, 74.0, 87.0, 42.0, 7.0, 66.0, 127.0, 12.0, 43.0, 21.0, 28.0, 23.0, 23.0, 108.0, 110.0, 39.0, 38.0, 134.0, 159.0, 46.0, 7.0, 75.0, 22.0, 6.0, 22.0, 43.0, 17.0, 41.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7228181021418189, "mean_inference_ms": 1.8653008422019854, "mean_action_processing_ms": 0.2914211464208403, "mean_env_wait_ms": 0.23573734871424817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007002115249633789, "StateBufferConnector_ms": 0.004527449607849121, "ViewRequirementAgentConnector_ms": 0.1436384916305542}, "num_episodes": 18, "episode_return_max": 268.4000000000001, "episode_return_min": -324.2999999999998, "episode_return_mean": -16.01000000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 337.6570400999051, "num_env_steps_trained_throughput_per_sec": 337.6570400999051, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 11712.768, "restore_workers_time_ms": 0.022, "training_step_time_ms": 11712.709, "sample_time_ms": 1676.776, "learn_time_ms": 10017.997, "learn_throughput": 399.281, "synch_weights_time_ms": 15.412}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-51-16", "timestamp": 1723647076, "time_this_iter_s": 11.888646125793457, "time_total_s": 245.77470541000366, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed405e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 245.77470541000366, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 44.48823529411764, "ram_util_percent": 83.27058823529411}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9223366530168624, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.342815925204564, "policy_loss": -0.008980812179417442, "vf_loss": 7.348826926599735, "vf_explained_var": 0.01024771909865122, "kl": 0.013199095106354546, "entropy": 1.5368884164820273, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.028333354973919, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.344461655490613, "policy_loss": -0.014028983008086918, "vf_loss": 4.356146209706705, "vf_explained_var": 0.0013779548740891553, "kl": 0.0156295336343271, "entropy": 1.4704249168199206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 238.09999999999945, "episode_reward_min": -256.8999999999969, "episode_reward_mean": -2.8810000000000513, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -388.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.3999999999998, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -69.97550000000007, "predator_policy": 68.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-67.79999999999993, -57.59999999999999, 65.70000000000014, -107.70000000000061, 205.99999999999935, -19.999999999999844, -130.6000000000014, 129.59999999999903, 37.500000000000206, -7.399999999999972, -201.70000000000007, 44.50000000000027, -58.99999999999985, -85.4000000000004, 34.800000000000125, -252.30000000000055, -9.899999999999865, 7.500000000000034, -8.100000000000028, -6.899999999999898, -68.6999999999999, -68.79999999999981, -219.70000000000022, -170.40000000000015, 24.30000000000021, -3.5000000000000053, 15.700000000000134, 40.9000000000002, -51.5000000000008, -90.49999999999999, -171.80000000000024, -19.399999999999846, -95.80000000000035, -90.80000000000038, -56.89999999999998, -5.1000000000000565, -2.999999999999886, -249.40000000000032, 14.599999999999941, -209.50000000000043, 0.7000000000001231, -23.39999999999994, -62.99999999999986, -33.60000000000001, 15.19999999999999, -247.80000000000007, -24.49999999999971, 94.5999999999994, 45.80000000000012, 122.69999999999956, -1.400000000000241, 83.49999999999986, 53.300000000000296, -58.40000000000025, 32.70000000000023, 45.40000000000034, 123.59999999999982, -235.7000000000007, 84.19999999999997, 2.400000000000169, 11.500000000000407, -121.30000000000047, -42.4000000000006, 30.700000000000074, 57.100000000000236, 14.199999999999934, -8.899999999999704, 41.30000000000033, 35.400000000000205, 111.1999999999997, -256.8999999999969, 76.10000000000002, 76.40000000000022, 59.00000000000022, 57.600000000000286, 40.80000000000033, -65.99999999999984, 165.59999999999968, -1.0000000000003433, 10.100000000000064, 116.20000000000005, 133.29999999999956, 75.19999999999958, 106.50000000000004, 147.69999999999897, 130.2999999999999, 60.300000000000146, 27.200000000000166, -138.5, 5.300000000000335, 113.50000000000004, 102.99999999999905, 238.09999999999945, -64.5, -17.599999999999866, 125.39999999999954, 30.900000000000166, 49.79999999999978, -16.699999999999868, 147.79999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-279.99999999999983, -56.80000000000004, -108.3999999999998, -26.199999999999974, -14.19999999999993, -33.1, 38.599999999999966, -331.3000000000002, 107.29999999999984, 73.69999999999993, -124.00000000000017, 20.000000000000014, -55.60000000000032, -205.00000000000045, -28.59999999999978, 99.19999999999973, -33.699999999999754, -5.800000000000001, 20.000000000000014, -240.40000000000003, -144.10000000000002, -229.60000000000008, -75.40000000000026, 26.899999999999974, -116.50000000000065, -242.49999999999997, 27.19999999999998, -294.60000000000025, 20.000000000000014, -95.1999999999999, -186.10000000000045, -278.20000000000005, -210.70000000000036, 30.799999999999997, -27.099999999999888, -39.399999999999885, -172.60000000000014, -14.499999999999822, -185.80000000000047, 38.89999999999997, -59.80000000000045, -151.89999999999986, -2.1999999999999535, -211.6000000000001, -313.5999999999999, -198.1000000000002, -336.4, -118.00000000000011, -12.100000000000385, -61.59999999999988, -388.0, 54.500000000000064, -157.3, 20.000000000000014, -51.10000000000008, -18.999999999999993, -47.19999999999976, -88.30000000000078, -163.6, -241.90000000000012, -228.40000000000012, -213.40000000000015, -155.2000000000003, 21.80000000000003, -372.70000000000005, -3.0999999999999615, -134.2000000000003, -139.60000000000008, -202.90000000000015, -45.99999999999995, -123.10000000000005, -55.000000000000284, -73.00000000000011, -18.99999999999993, -214.0000000000002, -255.40000000000015, 20.000000000000014, -51.399999999999764, -295.9000000000001, -145.60000000000034, -20.19999999999989, -132.10000000000002, -342.1, 76.6999999999995, -263.20000000000005, -17.800000000000026, -249.0000000000004, -58.59999999999999, -230.50000000000014, -13.299999999999983, -233.50000000000003, -385.30000000000007, -45.100000000000065, -99.40000000000049, 35.000000000000064, 44.60000000000018, -68.20000000000043, 8.0, 38.90000000000006, 15.799999999999962, -89.20000000000084, -11.200000000000102, 17.00000000000001, -50.50000000000031, -43.300000000000054, -0.3999999999998738, -59.79999999999979, -147.6000000000006, -13.599999999999783, -93.70000000000019, -31.599999999999902, 20.000000000000014, -17.5000000000001, 28.100000000000087, -276.1000000000002, -217.60000000000036, -13.299999999999855, -17.499999999999936, -199.60000000000036, 5.000000000000156, -34.59999999999975, 4.1000000000002, -213.1000000000002, -161.20000000000056, -162.7000000000003, -12.69999999999993, -67.00000000000003, -34.29999999999993, -86.50000000000017, 14.600000000000042, 43.40000000000021, -110.20000000000078, -173.19999999999985, 59.3000000000002, -12.699999999999857, 20.000000000000014, -71.50000000000082, -54.1, 54.200000000000074, 8.000000000000039, -241.60000000000036, -208.3000000000005, -59.80000000000062, 80.90000000000002, 23.6000000000001, 3.799999999999976, 21.50000000000003, -8.499999999999854, -201.7000000000003, 41.30000000000021, -67.00000000000077, 30.800000000000196, -378.9999999999999, 20.000000000000014, 28.700000000000003, 83.89999999999975, 3.500000000000192, -101.50000000000045, 7.399999999999965, -25.29999999999977, 54.20000000000013, 2.000000000000168, 20.000000000000014, 56.30000000000001, -0.4000000000000188, 23.60000000000007, 26.300000000000033, -14.800000000000182, 94.70000000000013, 38.00000000000022, 28.69999999999997, 56.60000000000006, -21.99999999999986, -0.7000000000000071, -56.799999999999784, 20.000000000000014, -115.30000000000041, -223.2, -6.39999999999986, -70.30000000000072, 73.09999999999992, -61.60000000000042, -24.099999999999746, 100.09999999999954, 88.7000000000001, 121.3999999999998, 20.000000000000014, -179.50000000000057, -158.8000000000003, 21.200000000000117, -52.00000000000004, 70.39999999999986, 11.599999999999977, -84.7000000000007, -18.10000000000015, -18.09999999999978, -322.29999999999944, 113.59999999999945, 62.60000000000011, 6.200000000000081], "policy_predator_policy_reward": [111.0, 158.0, 68.0, 9.0, 56.0, 57.0, 169.0, 16.0, 18.0, 7.0, 31.0, 53.0, 37.0, 93.0, 28.0, 31.0, 58.0, 19.0, 89.0, 124.0, 14.0, 158.0, 54.0, 39.0, 163.0, 137.0, 155.0, 27.0, 54.0, 56.0, 104.0, 108.0, 98.0, 72.0, 56.0, 18.0, 89.0, 90.0, 85.0, 55.0, 83.0, 60.0, 15.0, 130.0, 168.0, 124.0, 117.0, 167.0, 32.0, 66.0, 183.0, 147.0, 75.0, 78.0, 50.0, 61.0, 32.0, 52.0, 163.0, 152.0, 154.0, 116.0, 38.0, 76.0, 135.0, 145.0, 114.0, 69.0, 61.0, 131.0, 119.0, 54.0, 89.0, 0.0, 103.0, 117.0, 31.0, 15.0, 79.0, 153.0, 36.0, 117.0, 174.0, 68.0, 148.0, 70.0, 123.0, 151.0, 135.0, 124.0, 190.0, 181.0, 82.0, 38.0, 3.0, 12.0, 49.0, 57.0, 39.0, 29.0, 47.0, 52.0, 39.0, 78.0, 35.0, 62.0, 76.0, 73.0, 70.0, 70.0, 39.0, 18.0, 54.0, 59.0, 117.0, 141.0, 60.0, 55.0, 91.0, 106.0, 17.0, 25.0, 119.0, 134.0, 87.0, 46.0, 67.0, 65.0, 63.0, 66.0, 19.0, 62.0, 75.0, 30.0, 28.0, 6.0, 74.0, 87.0, 42.0, 7.0, 66.0, 127.0, 12.0, 43.0, 21.0, 28.0, 23.0, 23.0, 108.0, 110.0, 39.0, 38.0, 134.0, 159.0, 46.0, 7.0, 75.0, 22.0, 6.0, 22.0, 43.0, 17.0, 41.0, 16.0, 31.0, 21.0, 36.0, 59.0, 3.0, 12.0, 22.0, 23.0, 29.0, 54.0, 33.0, 31.0, 162.0, 38.0, 39.0, 43.0, 31.0, 71.0, 6.0, 21.0, 20.0, 8.0, 0.0, 95.0, 54.0, 66.0, 55.0, 52.0, 57.0, 47.0, 25.0, 61.0, 127.0, 65.0, 31.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7271593398642157, "mean_inference_ms": 1.876253622072172, "mean_action_processing_ms": 0.2935228111208603, "mean_env_wait_ms": 0.23738465609616533, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0070574283599853516, "StateBufferConnector_ms": 0.004511237144470215, "ViewRequirementAgentConnector_ms": 0.13339531421661377}, "num_episodes": 18, "episode_return_max": 238.09999999999945, "episode_return_min": -256.8999999999969, "episode_return_mean": -2.8810000000000513, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.26150526365643, "num_env_steps_trained_throughput_per_sec": 336.26150526365643, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 11747.481, "restore_workers_time_ms": 0.022, "training_step_time_ms": 11747.422, "sample_time_ms": 1722.558, "learn_time_ms": 10007.387, "learn_throughput": 399.705, "synch_weights_time_ms": 14.994}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-51-28", "timestamp": 1723647088, "time_this_iter_s": 11.931739091873169, "time_total_s": 257.70644450187683, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29eeee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 257.70644450187683, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 45.33529411764706, "ram_util_percent": 83.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7560304625009104, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.516792273395277, "policy_loss": -0.007798358691343791, "vf_loss": 8.521146560850598, "vf_explained_var": 0.0008993014141365334, "kl": 0.015306903715558986, "entropy": 1.5252588332645476, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9112472326351853, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.7102887395828485, "policy_loss": -0.014696098209442522, "vf_loss": 7.7226559366498675, "vf_explained_var": 0.039234974554606845, "kl": 0.015525901957443763, "entropy": 1.4635651672958696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 238.09999999999945, "episode_reward_min": -256.8999999999969, "episode_reward_mean": 14.335999999999958, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -385.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.3999999999998, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -57.20200000000008, "predator_policy": 64.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.9000000000002, -51.5000000000008, -90.49999999999999, -171.80000000000024, -19.399999999999846, -95.80000000000035, -90.80000000000038, -56.89999999999998, -5.1000000000000565, -2.999999999999886, -249.40000000000032, 14.599999999999941, -209.50000000000043, 0.7000000000001231, -23.39999999999994, -62.99999999999986, -33.60000000000001, 15.19999999999999, -247.80000000000007, -24.49999999999971, 94.5999999999994, 45.80000000000012, 122.69999999999956, -1.400000000000241, 83.49999999999986, 53.300000000000296, -58.40000000000025, 32.70000000000023, 45.40000000000034, 123.59999999999982, -235.7000000000007, 84.19999999999997, 2.400000000000169, 11.500000000000407, -121.30000000000047, -42.4000000000006, 30.700000000000074, 57.100000000000236, 14.199999999999934, -8.899999999999704, 41.30000000000033, 35.400000000000205, 111.1999999999997, -256.8999999999969, 76.10000000000002, 76.40000000000022, 59.00000000000022, 57.600000000000286, 40.80000000000033, -65.99999999999984, 165.59999999999968, -1.0000000000003433, 10.100000000000064, 116.20000000000005, 133.29999999999956, 75.19999999999958, 106.50000000000004, 147.69999999999897, 130.2999999999999, 60.300000000000146, 27.200000000000166, -138.5, 5.300000000000335, 113.50000000000004, 102.99999999999905, 238.09999999999945, -64.5, -17.599999999999866, 125.39999999999954, 30.900000000000166, 49.79999999999978, -16.699999999999868, 147.79999999999993, -17.100000000000513, -31.20000000000001, 179.9999999999999, 85.69999999999996, 143.2999999999999, 74.19999999999996, 114.10000000000002, 37.100000000000115, 9.200000000000298, 100.69999999999995, 50.099999999999696, -72.60000000000002, 87.99999999999983, 66.20000000000005, -59.600000000000186, 60.199999999999875, -20.70000000000013, 13.400000000000091, -99.60000000000042, -16.600000000000023, 24.100000000000072, 78.80000000000001, 59.90000000000014, 5.6000000000001755, 134.99999999999972, -164.20000000000024, -102.20000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-51.10000000000008, -18.999999999999993, -47.19999999999976, -88.30000000000078, -163.6, -241.90000000000012, -228.40000000000012, -213.40000000000015, -155.2000000000003, 21.80000000000003, -372.70000000000005, -3.0999999999999615, -134.2000000000003, -139.60000000000008, -202.90000000000015, -45.99999999999995, -123.10000000000005, -55.000000000000284, -73.00000000000011, -18.99999999999993, -214.0000000000002, -255.40000000000015, 20.000000000000014, -51.399999999999764, -295.9000000000001, -145.60000000000034, -20.19999999999989, -132.10000000000002, -342.1, 76.6999999999995, -263.20000000000005, -17.800000000000026, -249.0000000000004, -58.59999999999999, -230.50000000000014, -13.299999999999983, -233.50000000000003, -385.30000000000007, -45.100000000000065, -99.40000000000049, 35.000000000000064, 44.60000000000018, -68.20000000000043, 8.0, 38.90000000000006, 15.799999999999962, -89.20000000000084, -11.200000000000102, 17.00000000000001, -50.50000000000031, -43.300000000000054, -0.3999999999998738, -59.79999999999979, -147.6000000000006, -13.599999999999783, -93.70000000000019, -31.599999999999902, 20.000000000000014, -17.5000000000001, 28.100000000000087, -276.1000000000002, -217.60000000000036, -13.299999999999855, -17.499999999999936, -199.60000000000036, 5.000000000000156, -34.59999999999975, 4.1000000000002, -213.1000000000002, -161.20000000000056, -162.7000000000003, -12.69999999999993, -67.00000000000003, -34.29999999999993, -86.50000000000017, 14.600000000000042, 43.40000000000021, -110.20000000000078, -173.19999999999985, 59.3000000000002, -12.699999999999857, 20.000000000000014, -71.50000000000082, -54.1, 54.200000000000074, 8.000000000000039, -241.60000000000036, -208.3000000000005, -59.80000000000062, 80.90000000000002, 23.6000000000001, 3.799999999999976, 21.50000000000003, -8.499999999999854, -201.7000000000003, 41.30000000000021, -67.00000000000077, 30.800000000000196, -378.9999999999999, 20.000000000000014, 28.700000000000003, 83.89999999999975, 3.500000000000192, -101.50000000000045, 7.399999999999965, -25.29999999999977, 54.20000000000013, 2.000000000000168, 20.000000000000014, 56.30000000000001, -0.4000000000000188, 23.60000000000007, 26.300000000000033, -14.800000000000182, 94.70000000000013, 38.00000000000022, 28.69999999999997, 56.60000000000006, -21.99999999999986, -0.7000000000000071, -56.799999999999784, 20.000000000000014, -115.30000000000041, -223.2, -6.39999999999986, -70.30000000000072, 73.09999999999992, -61.60000000000042, -24.099999999999746, 100.09999999999954, 88.7000000000001, 121.3999999999998, 20.000000000000014, -179.50000000000057, -158.8000000000003, 21.200000000000117, -52.00000000000004, 70.39999999999986, 11.599999999999977, -84.7000000000007, -18.10000000000015, -18.09999999999978, -322.29999999999944, 113.59999999999945, 62.60000000000011, 6.200000000000081, -100.00000000000057, -69.10000000000012, -37.6, -124.60000000000011, 45.800000000000026, 51.2, -28.300000000000196, 20.000000000000014, 50.00000000000006, 2.3000000000000327, -47.79999999999992, -3.999999999999943, -66.10000000000068, 114.19999999999979, -42.99999999999999, -19.899999999999785, -51.40000000000005, -48.40000000000012, 36.20000000000005, -53.500000000000085, -15.399999999999991, -50.499999999999915, -145.6, -109.0, 36.500000000000036, -29.499999999999808, -118.30000000000007, 3.499999999999991, -91.30000000000015, -109.30000000000004, -13.000000000000227, -41.80000000000001, -44.50000000000014, -113.20000000000005, -25.599999999999945, -85.0, -121.60000000000042, -109.00000000000006, -53.19999999999996, -120.40000000000015, -70.00000000000007, -58.89999999999996, -1.8999999999998067, 10.700000000000122, -45.40000000000002, -30.699999999999967, -129.40000000000038, 20.000000000000014, 56.90000000000006, -70.90000000000035, -279.10000000000014, -123.10000000000018, -175.60000000000008, -106.60000000000002], "policy_predator_policy_reward": [50.0, 61.0, 32.0, 52.0, 163.0, 152.0, 154.0, 116.0, 38.0, 76.0, 135.0, 145.0, 114.0, 69.0, 61.0, 131.0, 119.0, 54.0, 89.0, 0.0, 103.0, 117.0, 31.0, 15.0, 79.0, 153.0, 36.0, 117.0, 174.0, 68.0, 148.0, 70.0, 123.0, 151.0, 135.0, 124.0, 190.0, 181.0, 82.0, 38.0, 3.0, 12.0, 49.0, 57.0, 39.0, 29.0, 47.0, 52.0, 39.0, 78.0, 35.0, 62.0, 76.0, 73.0, 70.0, 70.0, 39.0, 18.0, 54.0, 59.0, 117.0, 141.0, 60.0, 55.0, 91.0, 106.0, 17.0, 25.0, 119.0, 134.0, 87.0, 46.0, 67.0, 65.0, 63.0, 66.0, 19.0, 62.0, 75.0, 30.0, 28.0, 6.0, 74.0, 87.0, 42.0, 7.0, 66.0, 127.0, 12.0, 43.0, 21.0, 28.0, 23.0, 23.0, 108.0, 110.0, 39.0, 38.0, 134.0, 159.0, 46.0, 7.0, 75.0, 22.0, 6.0, 22.0, 43.0, 17.0, 41.0, 16.0, 31.0, 21.0, 36.0, 59.0, 3.0, 12.0, 22.0, 23.0, 29.0, 54.0, 33.0, 31.0, 162.0, 38.0, 39.0, 43.0, 31.0, 71.0, 6.0, 21.0, 20.0, 8.0, 0.0, 95.0, 54.0, 66.0, 55.0, 52.0, 57.0, 47.0, 25.0, 61.0, 127.0, 65.0, 31.0, 48.0, 75.0, 77.0, 63.0, 68.0, 39.0, 44.0, 56.0, 38.0, 26.0, 65.0, 61.0, 65.0, 48.0, 18.0, 31.0, 69.0, 61.0, 48.0, 81.0, 37.0, 69.0, 47.0, 71.0, 111.0, 48.0, 33.0, 91.0, 90.0, 62.0, 79.0, 44.0, 71.0, 100.0, 37.0, 84.0, 40.0, 30.0, 101.0, 63.0, 94.0, 56.0, 97.0, 25.0, 45.0, 69.0, 67.0, 67.0, 48.0, 80.0, 69.0, 117.0, 121.0, 79.0, 101.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7318791488224007, "mean_inference_ms": 1.8895967781286622, "mean_action_processing_ms": 0.2958299704114853, "mean_env_wait_ms": 0.23944157356329676, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00754237174987793, "StateBufferConnector_ms": 0.0047855377197265625, "ViewRequirementAgentConnector_ms": 0.14252889156341553}, "num_episodes": 27, "episode_return_max": 238.09999999999945, "episode_return_min": -256.8999999999969, "episode_return_mean": 14.335999999999958, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.2646067304069, "num_env_steps_trained_throughput_per_sec": 340.2646067304069, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 11794.862, "restore_workers_time_ms": 0.022, "training_step_time_ms": 11794.805, "sample_time_ms": 1753.47, "learn_time_ms": 10025.76, "learn_throughput": 398.972, "synch_weights_time_ms": 13.333}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-51-39", "timestamp": 1723647099, "time_this_iter_s": 11.771653890609741, "time_total_s": 269.4780983924866, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede2f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 269.4780983924866, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 44.470588235294116, "ram_util_percent": 83.45882352941176}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1546354478629177, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.812852944520415, "policy_loss": -0.004679116128485591, "vf_loss": 8.815708072854097, "vf_explained_var": -0.0855303722083884, "kl": 0.008106641843137327, "entropy": 1.5081252661331621, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6706031824230516, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.400273378059348, "policy_loss": -0.012427586164428956, "vf_loss": 8.410255304972331, "vf_explained_var": -0.011095239497997143, "kl": 0.016304500122991613, "entropy": 1.4159773783078269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 238.09999999999945, "episode_reward_min": -338.70000000000005, "episode_reward_mean": 6.155999999999961, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -385.30000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.3999999999998, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -61.67700000000006, "predator_policy": 64.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-247.80000000000007, -24.49999999999971, 94.5999999999994, 45.80000000000012, 122.69999999999956, -1.400000000000241, 83.49999999999986, 53.300000000000296, -58.40000000000025, 32.70000000000023, 45.40000000000034, 123.59999999999982, -235.7000000000007, 84.19999999999997, 2.400000000000169, 11.500000000000407, -121.30000000000047, -42.4000000000006, 30.700000000000074, 57.100000000000236, 14.199999999999934, -8.899999999999704, 41.30000000000033, 35.400000000000205, 111.1999999999997, -256.8999999999969, 76.10000000000002, 76.40000000000022, 59.00000000000022, 57.600000000000286, 40.80000000000033, -65.99999999999984, 165.59999999999968, -1.0000000000003433, 10.100000000000064, 116.20000000000005, 133.29999999999956, 75.19999999999958, 106.50000000000004, 147.69999999999897, 130.2999999999999, 60.300000000000146, 27.200000000000166, -138.5, 5.300000000000335, 113.50000000000004, 102.99999999999905, 238.09999999999945, -64.5, -17.599999999999866, 125.39999999999954, 30.900000000000166, 49.79999999999978, -16.699999999999868, 147.79999999999993, -17.100000000000513, -31.20000000000001, 179.9999999999999, 85.69999999999996, 143.2999999999999, 74.19999999999996, 114.10000000000002, 37.100000000000115, 9.200000000000298, 100.69999999999995, 50.099999999999696, -72.60000000000002, 87.99999999999983, 66.20000000000005, -59.600000000000186, 60.199999999999875, -20.70000000000013, 13.400000000000091, -99.60000000000042, -16.600000000000023, 24.100000000000072, 78.80000000000001, 59.90000000000014, 5.6000000000001755, 134.99999999999972, -164.20000000000024, -102.20000000000016, 58.00000000000028, -45.600000000000094, -160.80000000000004, -73.80000000000183, 61.69999999999975, -278.8999999999996, -329.0999999999999, -338.70000000000005, -274.0999999999998, -73.89999999999996, -76.80000000000001, -245.70000000000024, 76.50000000000009, -22.699999999999882, -258.8, 44.70000000000003, -59.79999999999987, 87.49999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-233.50000000000003, -385.30000000000007, -45.100000000000065, -99.40000000000049, 35.000000000000064, 44.60000000000018, -68.20000000000043, 8.0, 38.90000000000006, 15.799999999999962, -89.20000000000084, -11.200000000000102, 17.00000000000001, -50.50000000000031, -43.300000000000054, -0.3999999999998738, -59.79999999999979, -147.6000000000006, -13.599999999999783, -93.70000000000019, -31.599999999999902, 20.000000000000014, -17.5000000000001, 28.100000000000087, -276.1000000000002, -217.60000000000036, -13.299999999999855, -17.499999999999936, -199.60000000000036, 5.000000000000156, -34.59999999999975, 4.1000000000002, -213.1000000000002, -161.20000000000056, -162.7000000000003, -12.69999999999993, -67.00000000000003, -34.29999999999993, -86.50000000000017, 14.600000000000042, 43.40000000000021, -110.20000000000078, -173.19999999999985, 59.3000000000002, -12.699999999999857, 20.000000000000014, -71.50000000000082, -54.1, 54.200000000000074, 8.000000000000039, -241.60000000000036, -208.3000000000005, -59.80000000000062, 80.90000000000002, 23.6000000000001, 3.799999999999976, 21.50000000000003, -8.499999999999854, -201.7000000000003, 41.30000000000021, -67.00000000000077, 30.800000000000196, -378.9999999999999, 20.000000000000014, 28.700000000000003, 83.89999999999975, 3.500000000000192, -101.50000000000045, 7.399999999999965, -25.29999999999977, 54.20000000000013, 2.000000000000168, 20.000000000000014, 56.30000000000001, -0.4000000000000188, 23.60000000000007, 26.300000000000033, -14.800000000000182, 94.70000000000013, 38.00000000000022, 28.69999999999997, 56.60000000000006, -21.99999999999986, -0.7000000000000071, -56.799999999999784, 20.000000000000014, -115.30000000000041, -223.2, -6.39999999999986, -70.30000000000072, 73.09999999999992, -61.60000000000042, -24.099999999999746, 100.09999999999954, 88.7000000000001, 121.3999999999998, 20.000000000000014, -179.50000000000057, -158.8000000000003, 21.200000000000117, -52.00000000000004, 70.39999999999986, 11.599999999999977, -84.7000000000007, -18.10000000000015, -18.09999999999978, -322.29999999999944, 113.59999999999945, 62.60000000000011, 6.200000000000081, -100.00000000000057, -69.10000000000012, -37.6, -124.60000000000011, 45.800000000000026, 51.2, -28.300000000000196, 20.000000000000014, 50.00000000000006, 2.3000000000000327, -47.79999999999992, -3.999999999999943, -66.10000000000068, 114.19999999999979, -42.99999999999999, -19.899999999999785, -51.40000000000005, -48.40000000000012, 36.20000000000005, -53.500000000000085, -15.399999999999991, -50.499999999999915, -145.6, -109.0, 36.500000000000036, -29.499999999999808, -118.30000000000007, 3.499999999999991, -91.30000000000015, -109.30000000000004, -13.000000000000227, -41.80000000000001, -44.50000000000014, -113.20000000000005, -25.599999999999945, -85.0, -121.60000000000042, -109.00000000000006, -53.19999999999996, -120.40000000000015, -70.00000000000007, -58.89999999999996, -1.8999999999998067, 10.700000000000122, -45.40000000000002, -30.699999999999967, -129.40000000000038, 20.000000000000014, 56.90000000000006, -70.90000000000035, -279.10000000000014, -123.10000000000018, -175.60000000000008, -106.60000000000002, -30.39999999999975, -7.6000000000000085, -105.09999999999998, -125.5000000000002, -129.70000000000007, -216.0999999999999, -59.80000000000062, -58.00000000000048, -32.49999999999975, 27.20000000000006, -216.1000000000001, -302.8, -328.9, -344.2, -262.0, -354.70000000000005, -248.4999999999999, -316.6, -98.19999999999999, -192.7, -197.8, -106.0, -234.1000000000001, -283.5999999999996, -25.90000000000031, -52.60000000000002, -155.50000000000006, -17.199999999999847, -313.0, -245.8, -138.1, 21.800000000000026, -280.0, 42.199999999999974, -29.19999999999999, -25.299999999999997], "policy_predator_policy_reward": [190.0, 181.0, 82.0, 38.0, 3.0, 12.0, 49.0, 57.0, 39.0, 29.0, 47.0, 52.0, 39.0, 78.0, 35.0, 62.0, 76.0, 73.0, 70.0, 70.0, 39.0, 18.0, 54.0, 59.0, 117.0, 141.0, 60.0, 55.0, 91.0, 106.0, 17.0, 25.0, 119.0, 134.0, 87.0, 46.0, 67.0, 65.0, 63.0, 66.0, 19.0, 62.0, 75.0, 30.0, 28.0, 6.0, 74.0, 87.0, 42.0, 7.0, 66.0, 127.0, 12.0, 43.0, 21.0, 28.0, 23.0, 23.0, 108.0, 110.0, 39.0, 38.0, 134.0, 159.0, 46.0, 7.0, 75.0, 22.0, 6.0, 22.0, 43.0, 17.0, 41.0, 16.0, 31.0, 21.0, 36.0, 59.0, 3.0, 12.0, 22.0, 23.0, 29.0, 54.0, 33.0, 31.0, 162.0, 38.0, 39.0, 43.0, 31.0, 71.0, 6.0, 21.0, 20.0, 8.0, 0.0, 95.0, 54.0, 66.0, 55.0, 52.0, 57.0, 47.0, 25.0, 61.0, 127.0, 65.0, 31.0, 48.0, 75.0, 77.0, 63.0, 68.0, 39.0, 44.0, 56.0, 38.0, 26.0, 65.0, 61.0, 65.0, 48.0, 18.0, 31.0, 69.0, 61.0, 48.0, 81.0, 37.0, 69.0, 47.0, 71.0, 111.0, 48.0, 33.0, 91.0, 90.0, 62.0, 79.0, 44.0, 71.0, 100.0, 37.0, 84.0, 40.0, 30.0, 101.0, 63.0, 94.0, 56.0, 97.0, 25.0, 45.0, 69.0, 67.0, 67.0, 48.0, 80.0, 69.0, 117.0, 121.0, 79.0, 101.0, 43.0, 53.0, 67.0, 118.0, 118.0, 67.0, 38.0, 6.0, 0.0, 67.0, 107.0, 133.0, 169.0, 175.0, 89.0, 189.0, 165.0, 126.0, 136.0, 81.0, 116.0, 111.0, 138.0, 134.0, 72.0, 83.0, 101.0, 49.0, 142.0, 158.0, 79.0, 82.0, 75.0, 103.0, 62.0, 80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7347908232186992, "mean_inference_ms": 1.8968880711696396, "mean_action_processing_ms": 0.2966031557280952, "mean_env_wait_ms": 0.24075984419235866, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007505536079406738, "StateBufferConnector_ms": 0.004641890525817871, "ViewRequirementAgentConnector_ms": 0.13810622692108154}, "num_episodes": 18, "episode_return_max": 238.09999999999945, "episode_return_min": -338.70000000000005, "episode_return_mean": 6.155999999999961, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.11563128802135, "num_env_steps_trained_throughput_per_sec": 332.11563128802135, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 11864.805, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11864.75, "sample_time_ms": 1779.03, "learn_time_ms": 10070.17, "learn_throughput": 397.213, "synch_weights_time_ms": 12.96}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-51-52", "timestamp": 1723647112, "time_this_iter_s": 12.088112115859985, "time_total_s": 281.56621050834656, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32eddaa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 281.56621050834656, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 47.28235294117647, "ram_util_percent": 83.21176470588236}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9510448763767878, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.244450432156759, "policy_loss": -0.012332793712744086, "vf_loss": 9.253136036383411, "vf_explained_var": -0.040431770351197986, "kl": 0.016209722874035142, "entropy": 1.4806012644969597, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5372340413313064, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.122878046893568, "policy_loss": -0.009222881652281753, "vf_loss": 9.130567288777184, "vf_explained_var": 0.029929461081822713, "kl": 0.01022423485074801, "entropy": 1.417654382677936, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 238.09999999999945, "episode_reward_min": -340.9, "episode_reward_mean": -27.991000000000028, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.3999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -91.56050000000005, "predator_policy": 77.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.700000000000074, 57.100000000000236, 14.199999999999934, -8.899999999999704, 41.30000000000033, 35.400000000000205, 111.1999999999997, -256.8999999999969, 76.10000000000002, 76.40000000000022, 59.00000000000022, 57.600000000000286, 40.80000000000033, -65.99999999999984, 165.59999999999968, -1.0000000000003433, 10.100000000000064, 116.20000000000005, 133.29999999999956, 75.19999999999958, 106.50000000000004, 147.69999999999897, 130.2999999999999, 60.300000000000146, 27.200000000000166, -138.5, 5.300000000000335, 113.50000000000004, 102.99999999999905, 238.09999999999945, -64.5, -17.599999999999866, 125.39999999999954, 30.900000000000166, 49.79999999999978, -16.699999999999868, 147.79999999999993, -17.100000000000513, -31.20000000000001, 179.9999999999999, 85.69999999999996, 143.2999999999999, 74.19999999999996, 114.10000000000002, 37.100000000000115, 9.200000000000298, 100.69999999999995, 50.099999999999696, -72.60000000000002, 87.99999999999983, 66.20000000000005, -59.600000000000186, 60.199999999999875, -20.70000000000013, 13.400000000000091, -99.60000000000042, -16.600000000000023, 24.100000000000072, 78.80000000000001, 59.90000000000014, 5.6000000000001755, 134.99999999999972, -164.20000000000024, -102.20000000000016, 58.00000000000028, -45.600000000000094, -160.80000000000004, -73.80000000000183, 61.69999999999975, -278.8999999999996, -329.0999999999999, -338.70000000000005, -274.0999999999998, -73.89999999999996, -76.80000000000001, -245.70000000000024, 76.50000000000009, -22.699999999999882, -258.8, 44.70000000000003, -59.79999999999987, 87.49999999999991, -191.4000000000001, -145.90000000000018, 86.0, -314.3, -335.69999999999993, -280.6, -182.2, -251.20000000000005, -229.70000000000002, 8.599999999999957, -284.30000000000007, -38.099999999999966, -132.79999999999995, -111.19999999999999, -223.90000000000003, -285.8000000000002, -340.9, -193.1000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-67.00000000000003, -34.29999999999993, -86.50000000000017, 14.600000000000042, 43.40000000000021, -110.20000000000078, -173.19999999999985, 59.3000000000002, -12.699999999999857, 20.000000000000014, -71.50000000000082, -54.1, 54.200000000000074, 8.000000000000039, -241.60000000000036, -208.3000000000005, -59.80000000000062, 80.90000000000002, 23.6000000000001, 3.799999999999976, 21.50000000000003, -8.499999999999854, -201.7000000000003, 41.30000000000021, -67.00000000000077, 30.800000000000196, -378.9999999999999, 20.000000000000014, 28.700000000000003, 83.89999999999975, 3.500000000000192, -101.50000000000045, 7.399999999999965, -25.29999999999977, 54.20000000000013, 2.000000000000168, 20.000000000000014, 56.30000000000001, -0.4000000000000188, 23.60000000000007, 26.300000000000033, -14.800000000000182, 94.70000000000013, 38.00000000000022, 28.69999999999997, 56.60000000000006, -21.99999999999986, -0.7000000000000071, -56.799999999999784, 20.000000000000014, -115.30000000000041, -223.2, -6.39999999999986, -70.30000000000072, 73.09999999999992, -61.60000000000042, -24.099999999999746, 100.09999999999954, 88.7000000000001, 121.3999999999998, 20.000000000000014, -179.50000000000057, -158.8000000000003, 21.200000000000117, -52.00000000000004, 70.39999999999986, 11.599999999999977, -84.7000000000007, -18.10000000000015, -18.09999999999978, -322.29999999999944, 113.59999999999945, 62.60000000000011, 6.200000000000081, -100.00000000000057, -69.10000000000012, -37.6, -124.60000000000011, 45.800000000000026, 51.2, -28.300000000000196, 20.000000000000014, 50.00000000000006, 2.3000000000000327, -47.79999999999992, -3.999999999999943, -66.10000000000068, 114.19999999999979, -42.99999999999999, -19.899999999999785, -51.40000000000005, -48.40000000000012, 36.20000000000005, -53.500000000000085, -15.399999999999991, -50.499999999999915, -145.6, -109.0, 36.500000000000036, -29.499999999999808, -118.30000000000007, 3.499999999999991, -91.30000000000015, -109.30000000000004, -13.000000000000227, -41.80000000000001, -44.50000000000014, -113.20000000000005, -25.599999999999945, -85.0, -121.60000000000042, -109.00000000000006, -53.19999999999996, -120.40000000000015, -70.00000000000007, -58.89999999999996, -1.8999999999998067, 10.700000000000122, -45.40000000000002, -30.699999999999967, -129.40000000000038, 20.000000000000014, 56.90000000000006, -70.90000000000035, -279.10000000000014, -123.10000000000018, -175.60000000000008, -106.60000000000002, -30.39999999999975, -7.6000000000000085, -105.09999999999998, -125.5000000000002, -129.70000000000007, -216.0999999999999, -59.80000000000062, -58.00000000000048, -32.49999999999975, 27.20000000000006, -216.1000000000001, -302.8, -328.9, -344.2, -262.0, -354.70000000000005, -248.4999999999999, -316.6, -98.19999999999999, -192.7, -197.8, -106.0, -234.1000000000001, -283.5999999999996, -25.90000000000031, -52.60000000000002, -155.50000000000006, -17.199999999999847, -313.0, -245.8, -138.1, 21.800000000000026, -280.0, 42.199999999999974, -29.19999999999999, -25.299999999999997, -330.40000000000003, -163.00000000000006, -317.4999999999999, -105.39999999999984, 41.600000000000094, -58.6, -391.0, -310.3, -313.9, -347.79999999999995, -367.6, -277.0, -259.30000000000007, -214.89999999999998, -257.8, -270.4, -238.0, -267.70000000000005, -53.50000000000005, -94.9, -322.9, -297.40000000000003, -286.0, -24.099999999999746, -181.30000000000004, -71.50000000000003, -235.6, -160.60000000000008, -400.0, -202.90000000000003, -254.80000000000018, -328.0, -277.9, -358.0, -179.50000000000009, -280.6], "policy_predator_policy_reward": [67.0, 65.0, 63.0, 66.0, 19.0, 62.0, 75.0, 30.0, 28.0, 6.0, 74.0, 87.0, 42.0, 7.0, 66.0, 127.0, 12.0, 43.0, 21.0, 28.0, 23.0, 23.0, 108.0, 110.0, 39.0, 38.0, 134.0, 159.0, 46.0, 7.0, 75.0, 22.0, 6.0, 22.0, 43.0, 17.0, 41.0, 16.0, 31.0, 21.0, 36.0, 59.0, 3.0, 12.0, 22.0, 23.0, 29.0, 54.0, 33.0, 31.0, 162.0, 38.0, 39.0, 43.0, 31.0, 71.0, 6.0, 21.0, 20.0, 8.0, 0.0, 95.0, 54.0, 66.0, 55.0, 52.0, 57.0, 47.0, 25.0, 61.0, 127.0, 65.0, 31.0, 48.0, 75.0, 77.0, 63.0, 68.0, 39.0, 44.0, 56.0, 38.0, 26.0, 65.0, 61.0, 65.0, 48.0, 18.0, 31.0, 69.0, 61.0, 48.0, 81.0, 37.0, 69.0, 47.0, 71.0, 111.0, 48.0, 33.0, 91.0, 90.0, 62.0, 79.0, 44.0, 71.0, 100.0, 37.0, 84.0, 40.0, 30.0, 101.0, 63.0, 94.0, 56.0, 97.0, 25.0, 45.0, 69.0, 67.0, 67.0, 48.0, 80.0, 69.0, 117.0, 121.0, 79.0, 101.0, 43.0, 53.0, 67.0, 118.0, 118.0, 67.0, 38.0, 6.0, 0.0, 67.0, 107.0, 133.0, 169.0, 175.0, 89.0, 189.0, 165.0, 126.0, 136.0, 81.0, 116.0, 111.0, 138.0, 134.0, 72.0, 83.0, 101.0, 49.0, 142.0, 158.0, 79.0, 82.0, 75.0, 103.0, 62.0, 80.0, 140.0, 162.0, 161.0, 116.0, 82.0, 21.0, 199.0, 188.0, 186.0, 140.0, 194.0, 170.0, 156.0, 136.0, 175.0, 102.0, 98.0, 178.0, 96.0, 61.0, 185.0, 151.0, 131.0, 141.0, 31.0, 89.0, 128.0, 157.0, 183.0, 196.0, 116.0, 181.0, 138.0, 157.0, 137.0, 130.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7390231977807872, "mean_inference_ms": 1.9078458535067617, "mean_action_processing_ms": 0.29804805497260917, "mean_env_wait_ms": 0.24235625894286264, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005718350410461426, "StateBufferConnector_ms": 0.004647731781005859, "ViewRequirementAgentConnector_ms": 0.13274216651916504}, "num_episodes": 18, "episode_return_max": 238.09999999999945, "episode_return_min": -340.9, "episode_return_mean": -27.991000000000028, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 308.6297843646158, "num_env_steps_trained_throughput_per_sec": 308.6297843646158, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 11984.8, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11984.75, "sample_time_ms": 1790.06, "learn_time_ms": 10179.417, "learn_throughput": 392.95, "synch_weights_time_ms": 12.66}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-52-05", "timestamp": 1723647125, "time_this_iter_s": 13.008453845977783, "time_total_s": 294.57466435432434, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32eddaf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 294.57466435432434, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 51.98421052631578, "ram_util_percent": 83.50526315789475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.143112339166106, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.424760572494023, "policy_loss": -0.012798780738499271, "vf_loss": 8.433837881542388, "vf_explained_var": -0.04618508513011629, "kl": 0.016539947833395175, "entropy": 1.4566655970755078, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8737751170125587, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.540484291157394, "policy_loss": -0.007409064792264154, "vf_loss": 8.546520274026053, "vf_explained_var": 0.0635288295922456, "kl": 0.009153806475768371, "entropy": 1.4015028196667867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 238.09999999999945, "episode_reward_min": -340.9, "episode_reward_mean": -49.22900000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 121.3999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -114.74450000000004, "predator_policy": 90.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [133.29999999999956, 75.19999999999958, 106.50000000000004, 147.69999999999897, 130.2999999999999, 60.300000000000146, 27.200000000000166, -138.5, 5.300000000000335, 113.50000000000004, 102.99999999999905, 238.09999999999945, -64.5, -17.599999999999866, 125.39999999999954, 30.900000000000166, 49.79999999999978, -16.699999999999868, 147.79999999999993, -17.100000000000513, -31.20000000000001, 179.9999999999999, 85.69999999999996, 143.2999999999999, 74.19999999999996, 114.10000000000002, 37.100000000000115, 9.200000000000298, 100.69999999999995, 50.099999999999696, -72.60000000000002, 87.99999999999983, 66.20000000000005, -59.600000000000186, 60.199999999999875, -20.70000000000013, 13.400000000000091, -99.60000000000042, -16.600000000000023, 24.100000000000072, 78.80000000000001, 59.90000000000014, 5.6000000000001755, 134.99999999999972, -164.20000000000024, -102.20000000000016, 58.00000000000028, -45.600000000000094, -160.80000000000004, -73.80000000000183, 61.69999999999975, -278.8999999999996, -329.0999999999999, -338.70000000000005, -274.0999999999998, -73.89999999999996, -76.80000000000001, -245.70000000000024, 76.50000000000009, -22.699999999999882, -258.8, 44.70000000000003, -59.79999999999987, 87.49999999999991, -191.4000000000001, -145.90000000000018, 86.0, -314.3, -335.69999999999993, -280.6, -182.2, -251.20000000000005, -229.70000000000002, 8.599999999999957, -284.30000000000007, -38.099999999999966, -132.79999999999995, -111.19999999999999, -223.90000000000003, -285.8000000000002, -340.9, -193.1000000000001, -54.099999999999724, -107.4, -275.40000000000003, -56.80000000000012, -62.5, -32.89999999999998, -42.49999999999998, 6.7999999999999865, -203.30000000000013, 37.600000000000136, -108.80000000000044, 71.69999999999996, -50.100000000000136, -138.80000000000007, -159.8000000000002, -91.20000000000022, -143.70000000000024, -153.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 56.30000000000001, -0.4000000000000188, 23.60000000000007, 26.300000000000033, -14.800000000000182, 94.70000000000013, 38.00000000000022, 28.69999999999997, 56.60000000000006, -21.99999999999986, -0.7000000000000071, -56.799999999999784, 20.000000000000014, -115.30000000000041, -223.2, -6.39999999999986, -70.30000000000072, 73.09999999999992, -61.60000000000042, -24.099999999999746, 100.09999999999954, 88.7000000000001, 121.3999999999998, 20.000000000000014, -179.50000000000057, -158.8000000000003, 21.200000000000117, -52.00000000000004, 70.39999999999986, 11.599999999999977, -84.7000000000007, -18.10000000000015, -18.09999999999978, -322.29999999999944, 113.59999999999945, 62.60000000000011, 6.200000000000081, -100.00000000000057, -69.10000000000012, -37.6, -124.60000000000011, 45.800000000000026, 51.2, -28.300000000000196, 20.000000000000014, 50.00000000000006, 2.3000000000000327, -47.79999999999992, -3.999999999999943, -66.10000000000068, 114.19999999999979, -42.99999999999999, -19.899999999999785, -51.40000000000005, -48.40000000000012, 36.20000000000005, -53.500000000000085, -15.399999999999991, -50.499999999999915, -145.6, -109.0, 36.500000000000036, -29.499999999999808, -118.30000000000007, 3.499999999999991, -91.30000000000015, -109.30000000000004, -13.000000000000227, -41.80000000000001, -44.50000000000014, -113.20000000000005, -25.599999999999945, -85.0, -121.60000000000042, -109.00000000000006, -53.19999999999996, -120.40000000000015, -70.00000000000007, -58.89999999999996, -1.8999999999998067, 10.700000000000122, -45.40000000000002, -30.699999999999967, -129.40000000000038, 20.000000000000014, 56.90000000000006, -70.90000000000035, -279.10000000000014, -123.10000000000018, -175.60000000000008, -106.60000000000002, -30.39999999999975, -7.6000000000000085, -105.09999999999998, -125.5000000000002, -129.70000000000007, -216.0999999999999, -59.80000000000062, -58.00000000000048, -32.49999999999975, 27.20000000000006, -216.1000000000001, -302.8, -328.9, -344.2, -262.0, -354.70000000000005, -248.4999999999999, -316.6, -98.19999999999999, -192.7, -197.8, -106.0, -234.1000000000001, -283.5999999999996, -25.90000000000031, -52.60000000000002, -155.50000000000006, -17.199999999999847, -313.0, -245.8, -138.1, 21.800000000000026, -280.0, 42.199999999999974, -29.19999999999999, -25.299999999999997, -330.40000000000003, -163.00000000000006, -317.4999999999999, -105.39999999999984, 41.600000000000094, -58.6, -391.0, -310.3, -313.9, -347.79999999999995, -367.6, -277.0, -259.30000000000007, -214.89999999999998, -257.8, -270.4, -238.0, -267.70000000000005, -53.50000000000005, -94.9, -322.9, -297.40000000000003, -286.0, -24.099999999999746, -181.30000000000004, -71.50000000000003, -235.6, -160.60000000000008, -400.0, -202.90000000000003, -254.80000000000018, -328.0, -277.9, -358.0, -179.50000000000009, -280.6, -363.0999999999999, -0.9999999999999846, -225.4, -178.0, -199.0, -327.40000000000003, -118.9, -181.90000000000012, -269.5, -70.0, 20.000000000000014, -286.9, -194.8, -114.70000000000007, -53.50000000000005, -141.7, -196.30000000000007, -315.9999999999998, -65.80000000000001, -34.59999999999975, -25.29999999999984, -260.5, -59.5, -2.7999999999999687, -65.20000000000007, -139.90000000000012, -253.00000000000003, -182.80000000000013, -211.00000000000014, -140.8, -83.2000000000002, -331.0, -208.3, -246.40000000000026, -144.7, -265.0], "policy_predator_policy_reward": [41.0, 16.0, 31.0, 21.0, 36.0, 59.0, 3.0, 12.0, 22.0, 23.0, 29.0, 54.0, 33.0, 31.0, 162.0, 38.0, 39.0, 43.0, 31.0, 71.0, 6.0, 21.0, 20.0, 8.0, 0.0, 95.0, 54.0, 66.0, 55.0, 52.0, 57.0, 47.0, 25.0, 61.0, 127.0, 65.0, 31.0, 48.0, 75.0, 77.0, 63.0, 68.0, 39.0, 44.0, 56.0, 38.0, 26.0, 65.0, 61.0, 65.0, 48.0, 18.0, 31.0, 69.0, 61.0, 48.0, 81.0, 37.0, 69.0, 47.0, 71.0, 111.0, 48.0, 33.0, 91.0, 90.0, 62.0, 79.0, 44.0, 71.0, 100.0, 37.0, 84.0, 40.0, 30.0, 101.0, 63.0, 94.0, 56.0, 97.0, 25.0, 45.0, 69.0, 67.0, 67.0, 48.0, 80.0, 69.0, 117.0, 121.0, 79.0, 101.0, 43.0, 53.0, 67.0, 118.0, 118.0, 67.0, 38.0, 6.0, 0.0, 67.0, 107.0, 133.0, 169.0, 175.0, 89.0, 189.0, 165.0, 126.0, 136.0, 81.0, 116.0, 111.0, 138.0, 134.0, 72.0, 83.0, 101.0, 49.0, 142.0, 158.0, 79.0, 82.0, 75.0, 103.0, 62.0, 80.0, 140.0, 162.0, 161.0, 116.0, 82.0, 21.0, 199.0, 188.0, 186.0, 140.0, 194.0, 170.0, 156.0, 136.0, 175.0, 102.0, 98.0, 178.0, 96.0, 61.0, 185.0, 151.0, 131.0, 141.0, 31.0, 89.0, 128.0, 157.0, 183.0, 196.0, 116.0, 181.0, 138.0, 157.0, 137.0, 130.0, 161.0, 149.0, 135.0, 161.0, 90.0, 161.0, 148.0, 96.0, 121.0, 156.0, 141.0, 93.0, 138.0, 129.0, 119.0, 83.0, 172.0, 137.0, 81.0, 57.0, 153.0, 24.0, 32.0, 102.0, 69.0, 86.0, 138.0, 159.0, 33.0, 159.0, 151.0, 172.0, 155.0, 156.0, 129.0, 127.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7419744616348156, "mean_inference_ms": 1.916990963239928, "mean_action_processing_ms": 0.2993086753907472, "mean_env_wait_ms": 0.24344894886384907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005668759346008301, "StateBufferConnector_ms": 0.004625916481018066, "ViewRequirementAgentConnector_ms": 0.13102853298187256}, "num_episodes": 18, "episode_return_max": 238.09999999999945, "episode_return_min": -340.9, "episode_return_mean": -49.22900000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.60011715493516, "num_env_steps_trained_throughput_per_sec": 332.60011715493516, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 11973.795, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11973.746, "sample_time_ms": 1742.82, "learn_time_ms": 10215.996, "learn_throughput": 391.543, "synch_weights_time_ms": 12.614}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-52-17", "timestamp": 1723647137, "time_this_iter_s": 12.053393840789795, "time_total_s": 306.62805819511414, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede2af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 306.62805819511414, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 47.0, "ram_util_percent": 83.38823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.063492639039559, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.2496938102459785, "policy_loss": -0.007326716479042141, "vf_loss": 7.254324476554911, "vf_explained_var": -0.07813738792661637, "kl": 0.011982524304535034, "entropy": 1.4432141510267107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.156916612670535, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.383404185532262, "policy_loss": -0.01463179581345271, "vf_loss": 8.395420358799122, "vf_explained_var": -0.020987614216627898, "kl": 0.01743757848939943, "entropy": 1.3548189103287995, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 191.3, "episode_reward_min": -340.9, "episode_reward_mean": -63.68700000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 114.19999999999979, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -131.72350000000003, "predator_policy": 99.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.69999999999996, 143.2999999999999, 74.19999999999996, 114.10000000000002, 37.100000000000115, 9.200000000000298, 100.69999999999995, 50.099999999999696, -72.60000000000002, 87.99999999999983, 66.20000000000005, -59.600000000000186, 60.199999999999875, -20.70000000000013, 13.400000000000091, -99.60000000000042, -16.600000000000023, 24.100000000000072, 78.80000000000001, 59.90000000000014, 5.6000000000001755, 134.99999999999972, -164.20000000000024, -102.20000000000016, 58.00000000000028, -45.600000000000094, -160.80000000000004, -73.80000000000183, 61.69999999999975, -278.8999999999996, -329.0999999999999, -338.70000000000005, -274.0999999999998, -73.89999999999996, -76.80000000000001, -245.70000000000024, 76.50000000000009, -22.699999999999882, -258.8, 44.70000000000003, -59.79999999999987, 87.49999999999991, -191.4000000000001, -145.90000000000018, 86.0, -314.3, -335.69999999999993, -280.6, -182.2, -251.20000000000005, -229.70000000000002, 8.599999999999957, -284.30000000000007, -38.099999999999966, -132.79999999999995, -111.19999999999999, -223.90000000000003, -285.8000000000002, -340.9, -193.1000000000001, -54.099999999999724, -107.4, -275.40000000000003, -56.80000000000012, -62.5, -32.89999999999998, -42.49999999999998, 6.7999999999999865, -203.30000000000013, 37.600000000000136, -108.80000000000044, 71.69999999999996, -50.100000000000136, -138.80000000000007, -159.8000000000002, -91.20000000000022, -143.70000000000024, -153.7, -11.799999999999933, -85.89999999999998, 7.400000000000082, -8.199999999999939, 12.30000000000014, 13.700000000000113, 87.29999999999998, 5.400000000000071, 162.0, -16.199999999999676, -71.60000000000079, -103.50000000000001, -113.6999999999999, -141.90000000000032, 63.30000000000001, 32.30000000000018, -185.29999999999998, 49.400000000000134, -18.69999999999986, 34.40000000000003, 40.90000000000015, 191.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.300000000000196, 20.000000000000014, 50.00000000000006, 2.3000000000000327, -47.79999999999992, -3.999999999999943, -66.10000000000068, 114.19999999999979, -42.99999999999999, -19.899999999999785, -51.40000000000005, -48.40000000000012, 36.20000000000005, -53.500000000000085, -15.399999999999991, -50.499999999999915, -145.6, -109.0, 36.500000000000036, -29.499999999999808, -118.30000000000007, 3.499999999999991, -91.30000000000015, -109.30000000000004, -13.000000000000227, -41.80000000000001, -44.50000000000014, -113.20000000000005, -25.599999999999945, -85.0, -121.60000000000042, -109.00000000000006, -53.19999999999996, -120.40000000000015, -70.00000000000007, -58.89999999999996, -1.8999999999998067, 10.700000000000122, -45.40000000000002, -30.699999999999967, -129.40000000000038, 20.000000000000014, 56.90000000000006, -70.90000000000035, -279.10000000000014, -123.10000000000018, -175.60000000000008, -106.60000000000002, -30.39999999999975, -7.6000000000000085, -105.09999999999998, -125.5000000000002, -129.70000000000007, -216.0999999999999, -59.80000000000062, -58.00000000000048, -32.49999999999975, 27.20000000000006, -216.1000000000001, -302.8, -328.9, -344.2, -262.0, -354.70000000000005, -248.4999999999999, -316.6, -98.19999999999999, -192.7, -197.8, -106.0, -234.1000000000001, -283.5999999999996, -25.90000000000031, -52.60000000000002, -155.50000000000006, -17.199999999999847, -313.0, -245.8, -138.1, 21.800000000000026, -280.0, 42.199999999999974, -29.19999999999999, -25.299999999999997, -330.40000000000003, -163.00000000000006, -317.4999999999999, -105.39999999999984, 41.600000000000094, -58.6, -391.0, -310.3, -313.9, -347.79999999999995, -367.6, -277.0, -259.30000000000007, -214.89999999999998, -257.8, -270.4, -238.0, -267.70000000000005, -53.50000000000005, -94.9, -322.9, -297.40000000000003, -286.0, -24.099999999999746, -181.30000000000004, -71.50000000000003, -235.6, -160.60000000000008, -400.0, -202.90000000000003, -254.80000000000018, -328.0, -277.9, -358.0, -179.50000000000009, -280.6, -363.0999999999999, -0.9999999999999846, -225.4, -178.0, -199.0, -327.40000000000003, -118.9, -181.90000000000012, -269.5, -70.0, 20.000000000000014, -286.9, -194.8, -114.70000000000007, -53.50000000000005, -141.7, -196.30000000000007, -315.9999999999998, -65.80000000000001, -34.59999999999975, -25.29999999999984, -260.5, -59.5, -2.7999999999999687, -65.20000000000007, -139.90000000000012, -253.00000000000003, -182.80000000000013, -211.00000000000014, -140.8, -83.2000000000002, -331.0, -208.3, -246.40000000000026, -144.7, -265.0, -275.20000000000005, -55.59999999999994, 1.0999999999999865, -271.00000000000006, 38.00000000000004, -226.60000000000016, -112.30000000000007, -25.899999999999974, -45.09999999999976, -37.59999999999997, -14.199999999999918, -66.1000000000009, -123.70000000000002, -19.0, -116.80000000000018, -17.79999999999974, 26.0, 5.0, -11.499999999999751, -183.69999999999993, -106.0000000000008, -109.60000000000036, -205.00000000000026, -176.5, -253.9, -134.8, -192.4000000000002, -119.50000000000011, -10.599999999999994, -126.10000000000016, 5.299999999999965, 20.000000000000014, -301.0, -148.3, -115.30000000000007, 13.699999999999967, 5.299999999999965, -247.0, -70.89999999999995, -39.69999999999998, -256.2999999999997, 63.199999999999974, -0.7000000000001876, 32.0], "policy_predator_policy_reward": [56.0, 38.0, 26.0, 65.0, 61.0, 65.0, 48.0, 18.0, 31.0, 69.0, 61.0, 48.0, 81.0, 37.0, 69.0, 47.0, 71.0, 111.0, 48.0, 33.0, 91.0, 90.0, 62.0, 79.0, 44.0, 71.0, 100.0, 37.0, 84.0, 40.0, 30.0, 101.0, 63.0, 94.0, 56.0, 97.0, 25.0, 45.0, 69.0, 67.0, 67.0, 48.0, 80.0, 69.0, 117.0, 121.0, 79.0, 101.0, 43.0, 53.0, 67.0, 118.0, 118.0, 67.0, 38.0, 6.0, 0.0, 67.0, 107.0, 133.0, 169.0, 175.0, 89.0, 189.0, 165.0, 126.0, 136.0, 81.0, 116.0, 111.0, 138.0, 134.0, 72.0, 83.0, 101.0, 49.0, 142.0, 158.0, 79.0, 82.0, 75.0, 103.0, 62.0, 80.0, 140.0, 162.0, 161.0, 116.0, 82.0, 21.0, 199.0, 188.0, 186.0, 140.0, 194.0, 170.0, 156.0, 136.0, 175.0, 102.0, 98.0, 178.0, 96.0, 61.0, 185.0, 151.0, 131.0, 141.0, 31.0, 89.0, 128.0, 157.0, 183.0, 196.0, 116.0, 181.0, 138.0, 157.0, 137.0, 130.0, 161.0, 149.0, 135.0, 161.0, 90.0, 161.0, 148.0, 96.0, 121.0, 156.0, 141.0, 93.0, 138.0, 129.0, 119.0, 83.0, 172.0, 137.0, 81.0, 57.0, 153.0, 24.0, 32.0, 102.0, 69.0, 86.0, 138.0, 159.0, 33.0, 159.0, 151.0, 172.0, 155.0, 156.0, 129.0, 127.0, 160.0, 159.0, 119.0, 65.0, 118.0, 78.0, 4.0, 126.0, 52.0, 43.0, 56.0, 38.0, 118.0, 112.0, 79.0, 61.0, 55.0, 76.0, 89.0, 90.0, 61.0, 83.0, 141.0, 137.0, 137.0, 138.0, 108.0, 62.0, 98.0, 102.0, 0.0, 7.0, 185.0, 79.0, 75.0, 76.0, 136.0, 87.0, 64.0, 81.0, 145.0, 89.0, 81.0, 79.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.745621003687479, "mean_inference_ms": 1.9244724378925775, "mean_action_processing_ms": 0.29979853992985733, "mean_env_wait_ms": 0.24396972055690525, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006526947021484375, "StateBufferConnector_ms": 0.003222227096557617, "ViewRequirementAgentConnector_ms": 0.11749660968780518}, "num_episodes": 22, "episode_return_max": 191.3, "episode_return_min": -340.9, "episode_return_mean": -63.68700000000003, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.77736107367673, "num_env_steps_trained_throughput_per_sec": 342.77736107367673, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 11954.821, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11954.771, "sample_time_ms": 1714.155, "learn_time_ms": 10225.001, "learn_throughput": 391.198, "synch_weights_time_ms": 13.213}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-52-28", "timestamp": 1723647148, "time_this_iter_s": 11.711461067199707, "time_total_s": 318.33951926231384, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede2160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 318.33951926231384, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 44.849999999999994, "ram_util_percent": 83.4875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.070981339109007, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.2715426432392585, "policy_loss": -0.012850159178019831, "vf_loss": 6.2803758507683165, "vf_explained_var": -0.17668033157076155, "kl": 0.017853107890847895, "entropy": 1.4075303844673923, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.579897456982779, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.795813620279706, "policy_loss": -0.012955198673009084, "vf_loss": 7.806470993586949, "vf_explained_var": -0.0009861991519019718, "kl": 0.015318704247178369, "entropy": 1.3438072544557076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 191.3, "episode_reward_min": -340.9, "episode_reward_mean": -82.33800000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.199999999999974, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -145.95400000000006, "predator_policy": 104.785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-102.20000000000016, 58.00000000000028, -45.600000000000094, -160.80000000000004, -73.80000000000183, 61.69999999999975, -278.8999999999996, -329.0999999999999, -338.70000000000005, -274.0999999999998, -73.89999999999996, -76.80000000000001, -245.70000000000024, 76.50000000000009, -22.699999999999882, -258.8, 44.70000000000003, -59.79999999999987, 87.49999999999991, -191.4000000000001, -145.90000000000018, 86.0, -314.3, -335.69999999999993, -280.6, -182.2, -251.20000000000005, -229.70000000000002, 8.599999999999957, -284.30000000000007, -38.099999999999966, -132.79999999999995, -111.19999999999999, -223.90000000000003, -285.8000000000002, -340.9, -193.1000000000001, -54.099999999999724, -107.4, -275.40000000000003, -56.80000000000012, -62.5, -32.89999999999998, -42.49999999999998, 6.7999999999999865, -203.30000000000013, 37.600000000000136, -108.80000000000044, 71.69999999999996, -50.100000000000136, -138.80000000000007, -159.8000000000002, -91.20000000000022, -143.70000000000024, -153.7, -11.799999999999933, -85.89999999999998, 7.400000000000082, -8.199999999999939, 12.30000000000014, 13.700000000000113, 87.29999999999998, 5.400000000000071, 162.0, -16.199999999999676, -71.60000000000079, -103.50000000000001, -113.6999999999999, -141.90000000000032, 63.30000000000001, 32.30000000000018, -185.29999999999998, 49.400000000000134, -18.69999999999986, 34.40000000000003, 40.90000000000015, 191.3, -22.999999999999666, 40.0000000000003, -164.00000000000003, -25.399999999999892, -54.00000000000108, -109.80000000000052, -338.6999999999998, -213.90000000000006, 75.6999999999997, -57.400000000000006, -150.30000000000058, 101.79999999999981, -55.999999999999915, -30.399999999999906, -22.79999999999982, 14.299999999999986, -78.30000000000044, -106.30000000000001, 111.19999999999986, 14.399999999999965, -4.400000000000006, -40.59999999999968, -34.899999999999835], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.60000000000008, -106.60000000000002, -30.39999999999975, -7.6000000000000085, -105.09999999999998, -125.5000000000002, -129.70000000000007, -216.0999999999999, -59.80000000000062, -58.00000000000048, -32.49999999999975, 27.20000000000006, -216.1000000000001, -302.8, -328.9, -344.2, -262.0, -354.70000000000005, -248.4999999999999, -316.6, -98.19999999999999, -192.7, -197.8, -106.0, -234.1000000000001, -283.5999999999996, -25.90000000000031, -52.60000000000002, -155.50000000000006, -17.199999999999847, -313.0, -245.8, -138.1, 21.800000000000026, -280.0, 42.199999999999974, -29.19999999999999, -25.299999999999997, -330.40000000000003, -163.00000000000006, -317.4999999999999, -105.39999999999984, 41.600000000000094, -58.6, -391.0, -310.3, -313.9, -347.79999999999995, -367.6, -277.0, -259.30000000000007, -214.89999999999998, -257.8, -270.4, -238.0, -267.70000000000005, -53.50000000000005, -94.9, -322.9, -297.40000000000003, -286.0, -24.099999999999746, -181.30000000000004, -71.50000000000003, -235.6, -160.60000000000008, -400.0, -202.90000000000003, -254.80000000000018, -328.0, -277.9, -358.0, -179.50000000000009, -280.6, -363.0999999999999, -0.9999999999999846, -225.4, -178.0, -199.0, -327.40000000000003, -118.9, -181.90000000000012, -269.5, -70.0, 20.000000000000014, -286.9, -194.8, -114.70000000000007, -53.50000000000005, -141.7, -196.30000000000007, -315.9999999999998, -65.80000000000001, -34.59999999999975, -25.29999999999984, -260.5, -59.5, -2.7999999999999687, -65.20000000000007, -139.90000000000012, -253.00000000000003, -182.80000000000013, -211.00000000000014, -140.8, -83.2000000000002, -331.0, -208.3, -246.40000000000026, -144.7, -265.0, -275.20000000000005, -55.59999999999994, 1.0999999999999865, -271.00000000000006, 38.00000000000004, -226.60000000000016, -112.30000000000007, -25.899999999999974, -45.09999999999976, -37.59999999999997, -14.199999999999918, -66.1000000000009, -123.70000000000002, -19.0, -116.80000000000018, -17.79999999999974, 26.0, 5.0, -11.499999999999751, -183.69999999999993, -106.0000000000008, -109.60000000000036, -205.00000000000026, -176.5, -253.9, -134.8, -192.4000000000002, -119.50000000000011, -10.599999999999994, -126.10000000000016, 5.299999999999965, 20.000000000000014, -301.0, -148.3, -115.30000000000007, 13.699999999999967, 5.299999999999965, -247.0, -70.89999999999995, -39.69999999999998, -256.2999999999997, 63.199999999999974, -0.7000000000001876, 32.0, -153.70000000000053, 13.699999999999964, 20.000000000000014, 20.000000000000014, -238.0, -217.00000000000003, -90.39999999999993, -118.00000000000063, -66.10000000000088, -61.900000000000766, -197.8, -145.0000000000005, -322.29999999999984, -264.4, -196.00000000000006, -244.9, -50.79999999999998, 9.499999999999964, -50.79999999999998, -205.6, -194.50000000000028, -197.8000000000003, -5.500000000000018, -27.700000000000003, -57.999999999999964, -244.0, -104.2000000000006, -5.19999999999999, -17.79999999999974, -166.00000000000006, -130.90000000000055, 3.1999999999999615, -0.9999999999999846, -310.30000000000007, -170.8, -152.5, -27.700000000000003, 2.900000000000012, 15.799999999999963, -30.39999999999975, -242.2000000000001, 12.799999999999983, 20.000000000000014, -199.60000000000048, -51.70000000000001, -221.20000000000044], "policy_predator_policy_reward": [79.0, 101.0, 43.0, 53.0, 67.0, 118.0, 118.0, 67.0, 38.0, 6.0, 0.0, 67.0, 107.0, 133.0, 169.0, 175.0, 89.0, 189.0, 165.0, 126.0, 136.0, 81.0, 116.0, 111.0, 138.0, 134.0, 72.0, 83.0, 101.0, 49.0, 142.0, 158.0, 79.0, 82.0, 75.0, 103.0, 62.0, 80.0, 140.0, 162.0, 161.0, 116.0, 82.0, 21.0, 199.0, 188.0, 186.0, 140.0, 194.0, 170.0, 156.0, 136.0, 175.0, 102.0, 98.0, 178.0, 96.0, 61.0, 185.0, 151.0, 131.0, 141.0, 31.0, 89.0, 128.0, 157.0, 183.0, 196.0, 116.0, 181.0, 138.0, 157.0, 137.0, 130.0, 161.0, 149.0, 135.0, 161.0, 90.0, 161.0, 148.0, 96.0, 121.0, 156.0, 141.0, 93.0, 138.0, 129.0, 119.0, 83.0, 172.0, 137.0, 81.0, 57.0, 153.0, 24.0, 32.0, 102.0, 69.0, 86.0, 138.0, 159.0, 33.0, 159.0, 151.0, 172.0, 155.0, 156.0, 129.0, 127.0, 160.0, 159.0, 119.0, 65.0, 118.0, 78.0, 4.0, 126.0, 52.0, 43.0, 56.0, 38.0, 118.0, 112.0, 79.0, 61.0, 55.0, 76.0, 89.0, 90.0, 61.0, 83.0, 141.0, 137.0, 137.0, 138.0, 108.0, 62.0, 98.0, 102.0, 0.0, 7.0, 185.0, 79.0, 75.0, 76.0, 136.0, 87.0, 64.0, 81.0, 145.0, 89.0, 81.0, 79.0, 34.0, 83.0, 0.0, 0.0, 165.0, 126.0, 75.0, 108.0, 30.0, 44.0, 132.0, 101.0, 159.0, 89.0, 132.0, 95.0, 45.0, 72.0, 115.0, 84.0, 151.0, 91.0, 91.0, 44.0, 98.0, 148.0, 65.0, 14.0, 87.0, 74.0, 69.0, 73.0, 86.0, 147.0, 123.0, 94.0, 80.0, 56.0, 6.0, 23.0, 104.0, 121.0, 104.0, 35.0, 79.0, 159.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7490914642680343, "mean_inference_ms": 1.9353125065137247, "mean_action_processing_ms": 0.30715908546765536, "mean_env_wait_ms": 0.24503864573428152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008656024932861328, "StateBufferConnector_ms": 0.003481268882751465, "ViewRequirementAgentConnector_ms": 0.11015117168426514}, "num_episodes": 23, "episode_return_max": 191.3, "episode_return_min": -340.9, "episode_return_mean": -82.33800000000005, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.33826431211884, "num_env_steps_trained_throughput_per_sec": 324.33826431211884, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 12006.422, "restore_workers_time_ms": 0.018, "training_step_time_ms": 12006.372, "sample_time_ms": 1753.355, "learn_time_ms": 10237.388, "learn_throughput": 390.725, "synch_weights_time_ms": 13.175}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-52-41", "timestamp": 1723647161, "time_this_iter_s": 12.348803997039795, "time_total_s": 330.68832325935364, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed91940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 330.68832325935364, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 45.49444444444444, "ram_util_percent": 83.28333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3666268241153192, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.25137475205477, "policy_loss": -0.010125916070925693, "vf_loss": 4.2575414132819605, "vf_explained_var": -0.06171845509892418, "kl": 0.017596702092192384, "entropy": 1.3422099140586046, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.599808230854216, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.38917301445411, "policy_loss": -0.005567576607600564, "vf_loss": 6.3932243740747845, "vf_explained_var": -0.0012680416069333516, "kl": 0.010108104667937243, "entropy": 1.3366431110119694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 191.3, "episode_reward_min": -340.9, "episode_reward_mean": -67.32000000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.199999999999974, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -132.44000000000003, "predator_policy": 98.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [87.49999999999991, -191.4000000000001, -145.90000000000018, 86.0, -314.3, -335.69999999999993, -280.6, -182.2, -251.20000000000005, -229.70000000000002, 8.599999999999957, -284.30000000000007, -38.099999999999966, -132.79999999999995, -111.19999999999999, -223.90000000000003, -285.8000000000002, -340.9, -193.1000000000001, -54.099999999999724, -107.4, -275.40000000000003, -56.80000000000012, -62.5, -32.89999999999998, -42.49999999999998, 6.7999999999999865, -203.30000000000013, 37.600000000000136, -108.80000000000044, 71.69999999999996, -50.100000000000136, -138.80000000000007, -159.8000000000002, -91.20000000000022, -143.70000000000024, -153.7, -11.799999999999933, -85.89999999999998, 7.400000000000082, -8.199999999999939, 12.30000000000014, 13.700000000000113, 87.29999999999998, 5.400000000000071, 162.0, -16.199999999999676, -71.60000000000079, -103.50000000000001, -113.6999999999999, -141.90000000000032, 63.30000000000001, 32.30000000000018, -185.29999999999998, 49.400000000000134, -18.69999999999986, 34.40000000000003, 40.90000000000015, 191.3, -22.999999999999666, 40.0000000000003, -164.00000000000003, -25.399999999999892, -54.00000000000108, -109.80000000000052, -338.6999999999998, -213.90000000000006, 75.6999999999997, -57.400000000000006, -150.30000000000058, 101.79999999999981, -55.999999999999915, -30.399999999999906, -22.79999999999982, 14.299999999999986, -78.30000000000044, -106.30000000000001, 111.19999999999986, 14.399999999999965, -4.400000000000006, -40.59999999999968, -34.899999999999835, -40.09999999999966, 4.600000000000012, 14.89999999999998, -209.9000000000008, -209.80000000000047, 26.50000000000008, -29.799999999999734, -174.50000000000026, 26.800000000000104, -22.700000000000014, 0.9000000000002142, -26.699999999999758, 32.800000000000196, 16.499999999999993, 33.4000000000002, -26.799999999999933, -45.49999999999958, 31.200000000000166], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.19999999999999, -25.299999999999997, -330.40000000000003, -163.00000000000006, -317.4999999999999, -105.39999999999984, 41.600000000000094, -58.6, -391.0, -310.3, -313.9, -347.79999999999995, -367.6, -277.0, -259.30000000000007, -214.89999999999998, -257.8, -270.4, -238.0, -267.70000000000005, -53.50000000000005, -94.9, -322.9, -297.40000000000003, -286.0, -24.099999999999746, -181.30000000000004, -71.50000000000003, -235.6, -160.60000000000008, -400.0, -202.90000000000003, -254.80000000000018, -328.0, -277.9, -358.0, -179.50000000000009, -280.6, -363.0999999999999, -0.9999999999999846, -225.4, -178.0, -199.0, -327.40000000000003, -118.9, -181.90000000000012, -269.5, -70.0, 20.000000000000014, -286.9, -194.8, -114.70000000000007, -53.50000000000005, -141.7, -196.30000000000007, -315.9999999999998, -65.80000000000001, -34.59999999999975, -25.29999999999984, -260.5, -59.5, -2.7999999999999687, -65.20000000000007, -139.90000000000012, -253.00000000000003, -182.80000000000013, -211.00000000000014, -140.8, -83.2000000000002, -331.0, -208.3, -246.40000000000026, -144.7, -265.0, -275.20000000000005, -55.59999999999994, 1.0999999999999865, -271.00000000000006, 38.00000000000004, -226.60000000000016, -112.30000000000007, -25.899999999999974, -45.09999999999976, -37.59999999999997, -14.199999999999918, -66.1000000000009, -123.70000000000002, -19.0, -116.80000000000018, -17.79999999999974, 26.0, 5.0, -11.499999999999751, -183.69999999999993, -106.0000000000008, -109.60000000000036, -205.00000000000026, -176.5, -253.9, -134.8, -192.4000000000002, -119.50000000000011, -10.599999999999994, -126.10000000000016, 5.299999999999965, 20.000000000000014, -301.0, -148.3, -115.30000000000007, 13.699999999999967, 5.299999999999965, -247.0, -70.89999999999995, -39.69999999999998, -256.2999999999997, 63.199999999999974, -0.7000000000001876, 32.0, -153.70000000000053, 13.699999999999964, 20.000000000000014, 20.000000000000014, -238.0, -217.00000000000003, -90.39999999999993, -118.00000000000063, -66.10000000000088, -61.900000000000766, -197.8, -145.0000000000005, -322.29999999999984, -264.4, -196.00000000000006, -244.9, -50.79999999999998, 9.499999999999964, -50.79999999999998, -205.6, -194.50000000000028, -197.8000000000003, -5.500000000000018, -27.700000000000003, -57.999999999999964, -244.0, -104.2000000000006, -5.19999999999999, -17.79999999999974, -166.00000000000006, -130.90000000000055, 3.1999999999999615, -0.9999999999999846, -310.30000000000007, -170.8, -152.5, -27.700000000000003, 2.900000000000012, 15.799999999999963, -30.39999999999975, -242.2000000000001, 12.799999999999983, 20.000000000000014, -199.60000000000048, -51.70000000000001, -221.20000000000044, -53.79999999999991, -160.30000000000058, -92.80000000000001, 7.399999999999979, -111.10000000000056, -39.999999999999886, -273.60000000000025, -175.30000000000052, -226.30000000000027, -272.4999999999992, 15.799999999999963, -7.299999999999891, -124.90000000000046, 1.0999999999999652, -167.20000000000002, -256.2999999999986, -25.8999999999998, -7.299999999999891, -136.60000000000005, -24.099999999999746, 1.0999999999999865, -68.20000000000087, -373.0, 5.299999999999965, 7.399999999999965, 7.399999999999981, -77.50000000000065, 20.000000000000014, 13.699999999999964, 13.699999999999964, -9.399999999999855, -228.4000000000001, -168.4000000000006, -3.099999999999958, 13.699999999999966, 9.499999999999964], "policy_predator_policy_reward": [62.0, 80.0, 140.0, 162.0, 161.0, 116.0, 82.0, 21.0, 199.0, 188.0, 186.0, 140.0, 194.0, 170.0, 156.0, 136.0, 175.0, 102.0, 98.0, 178.0, 96.0, 61.0, 185.0, 151.0, 131.0, 141.0, 31.0, 89.0, 128.0, 157.0, 183.0, 196.0, 116.0, 181.0, 138.0, 157.0, 137.0, 130.0, 161.0, 149.0, 135.0, 161.0, 90.0, 161.0, 148.0, 96.0, 121.0, 156.0, 141.0, 93.0, 138.0, 129.0, 119.0, 83.0, 172.0, 137.0, 81.0, 57.0, 153.0, 24.0, 32.0, 102.0, 69.0, 86.0, 138.0, 159.0, 33.0, 159.0, 151.0, 172.0, 155.0, 156.0, 129.0, 127.0, 160.0, 159.0, 119.0, 65.0, 118.0, 78.0, 4.0, 126.0, 52.0, 43.0, 56.0, 38.0, 118.0, 112.0, 79.0, 61.0, 55.0, 76.0, 89.0, 90.0, 61.0, 83.0, 141.0, 137.0, 137.0, 138.0, 108.0, 62.0, 98.0, 102.0, 0.0, 7.0, 185.0, 79.0, 75.0, 76.0, 136.0, 87.0, 64.0, 81.0, 145.0, 89.0, 81.0, 79.0, 34.0, 83.0, 0.0, 0.0, 165.0, 126.0, 75.0, 108.0, 30.0, 44.0, 132.0, 101.0, 159.0, 89.0, 132.0, 95.0, 45.0, 72.0, 115.0, 84.0, 151.0, 91.0, 91.0, 44.0, 98.0, 148.0, 65.0, 14.0, 87.0, 74.0, 69.0, 73.0, 86.0, 147.0, 123.0, 94.0, 80.0, 56.0, 6.0, 23.0, 104.0, 121.0, 104.0, 35.0, 79.0, 159.0, 111.0, 63.0, 44.0, 46.0, 96.0, 70.0, 87.0, 152.0, 167.0, 122.0, 5.0, 13.0, 76.0, 18.0, 188.0, 61.0, 36.0, 24.0, 92.0, 46.0, 32.0, 36.0, 161.0, 180.0, 12.0, 6.0, 56.0, 18.0, 3.0, 3.0, 89.0, 122.0, 40.0, 86.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7509761988610983, "mean_inference_ms": 1.9411010221163771, "mean_action_processing_ms": 0.31127467354305294, "mean_env_wait_ms": 0.24539378032425646, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008074045181274414, "StateBufferConnector_ms": 0.003496885299682617, "ViewRequirementAgentConnector_ms": 0.10537374019622803}, "num_episodes": 18, "episode_return_max": 191.3, "episode_return_min": -340.9, "episode_return_mean": -67.32000000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.9170691143885, "num_env_steps_trained_throughput_per_sec": 348.9170691143885, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 11971.494, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11971.443, "sample_time_ms": 1723.244, "learn_time_ms": 10232.479, "learn_throughput": 390.912, "synch_weights_time_ms": 13.091}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-52-52", "timestamp": 1723647172, "time_this_iter_s": 11.509667873382568, "time_total_s": 342.1979911327362, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee11dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 342.1979911327362, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 45.33125, "ram_util_percent": 83.3875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.525845036084059, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5279463888160767, "policy_loss": -0.01190452448119503, "vf_loss": 2.5378266644856287, "vf_explained_var": -0.07662464266731625, "kl": 0.008996666104947692, "entropy": 1.3311945090218196, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.095630910566875, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2063442260499984, "policy_loss": -0.007688053225773195, "vf_loss": 3.212435657826681, "vf_explained_var": -0.0038091453610273897, "kl": 0.01064411106712247, "entropy": 1.3101101199785867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 191.3, "episode_reward_min": -550.7999999999995, "episode_reward_mean": -40.164000000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -419.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.199999999999974, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -104.06700000000008, "predator_policy": 83.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-193.1000000000001, -54.099999999999724, -107.4, -275.40000000000003, -56.80000000000012, -62.5, -32.89999999999998, -42.49999999999998, 6.7999999999999865, -203.30000000000013, 37.600000000000136, -108.80000000000044, 71.69999999999996, -50.100000000000136, -138.80000000000007, -159.8000000000002, -91.20000000000022, -143.70000000000024, -153.7, -11.799999999999933, -85.89999999999998, 7.400000000000082, -8.199999999999939, 12.30000000000014, 13.700000000000113, 87.29999999999998, 5.400000000000071, 162.0, -16.199999999999676, -71.60000000000079, -103.50000000000001, -113.6999999999999, -141.90000000000032, 63.30000000000001, 32.30000000000018, -185.29999999999998, 49.400000000000134, -18.69999999999986, 34.40000000000003, 40.90000000000015, 191.3, -22.999999999999666, 40.0000000000003, -164.00000000000003, -25.399999999999892, -54.00000000000108, -109.80000000000052, -338.6999999999998, -213.90000000000006, 75.6999999999997, -57.400000000000006, -150.30000000000058, 101.79999999999981, -55.999999999999915, -30.399999999999906, -22.79999999999982, 14.299999999999986, -78.30000000000044, -106.30000000000001, 111.19999999999986, 14.399999999999965, -4.400000000000006, -40.59999999999968, -34.899999999999835, -40.09999999999966, 4.600000000000012, 14.89999999999998, -209.9000000000008, -209.80000000000047, 26.50000000000008, -29.799999999999734, -174.50000000000026, 26.800000000000104, -22.700000000000014, 0.9000000000002142, -26.699999999999758, 32.800000000000196, 16.499999999999993, 33.4000000000002, -26.799999999999933, -45.49999999999958, 31.200000000000166, -550.7999999999995, -35.699999999999584, 10.199999999999985, 32.20000000000018, -7.699999999999804, -17.49999999999966, 32.50000000000021, 25.700000000000067, -93.60000000000139, 9.199999999999928, -36.9999999999996, 86.59999999999886, -1.3000000000000722, 37.700000000000266, 11.099999999999952, 17.699999999999957, 25.200000000000074, 5.200000000000127], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-179.50000000000009, -280.6, -363.0999999999999, -0.9999999999999846, -225.4, -178.0, -199.0, -327.40000000000003, -118.9, -181.90000000000012, -269.5, -70.0, 20.000000000000014, -286.9, -194.8, -114.70000000000007, -53.50000000000005, -141.7, -196.30000000000007, -315.9999999999998, -65.80000000000001, -34.59999999999975, -25.29999999999984, -260.5, -59.5, -2.7999999999999687, -65.20000000000007, -139.90000000000012, -253.00000000000003, -182.80000000000013, -211.00000000000014, -140.8, -83.2000000000002, -331.0, -208.3, -246.40000000000026, -144.7, -265.0, -275.20000000000005, -55.59999999999994, 1.0999999999999865, -271.00000000000006, 38.00000000000004, -226.60000000000016, -112.30000000000007, -25.899999999999974, -45.09999999999976, -37.59999999999997, -14.199999999999918, -66.1000000000009, -123.70000000000002, -19.0, -116.80000000000018, -17.79999999999974, 26.0, 5.0, -11.499999999999751, -183.69999999999993, -106.0000000000008, -109.60000000000036, -205.00000000000026, -176.5, -253.9, -134.8, -192.4000000000002, -119.50000000000011, -10.599999999999994, -126.10000000000016, 5.299999999999965, 20.000000000000014, -301.0, -148.3, -115.30000000000007, 13.699999999999967, 5.299999999999965, -247.0, -70.89999999999995, -39.69999999999998, -256.2999999999997, 63.199999999999974, -0.7000000000001876, 32.0, -153.70000000000053, 13.699999999999964, 20.000000000000014, 20.000000000000014, -238.0, -217.00000000000003, -90.39999999999993, -118.00000000000063, -66.10000000000088, -61.900000000000766, -197.8, -145.0000000000005, -322.29999999999984, -264.4, -196.00000000000006, -244.9, -50.79999999999998, 9.499999999999964, -50.79999999999998, -205.6, -194.50000000000028, -197.8000000000003, -5.500000000000018, -27.700000000000003, -57.999999999999964, -244.0, -104.2000000000006, -5.19999999999999, -17.79999999999974, -166.00000000000006, -130.90000000000055, 3.1999999999999615, -0.9999999999999846, -310.30000000000007, -170.8, -152.5, -27.700000000000003, 2.900000000000012, 15.799999999999963, -30.39999999999975, -242.2000000000001, 12.799999999999983, 20.000000000000014, -199.60000000000048, -51.70000000000001, -221.20000000000044, -53.79999999999991, -160.30000000000058, -92.80000000000001, 7.399999999999979, -111.10000000000056, -39.999999999999886, -273.60000000000025, -175.30000000000052, -226.30000000000027, -272.4999999999992, 15.799999999999963, -7.299999999999891, -124.90000000000046, 1.0999999999999652, -167.20000000000002, -256.2999999999986, -25.8999999999998, -7.299999999999891, -136.60000000000005, -24.099999999999746, 1.0999999999999865, -68.20000000000087, -373.0, 5.299999999999965, 7.399999999999965, 7.399999999999981, -77.50000000000065, 20.000000000000014, 13.699999999999964, 13.699999999999964, -9.399999999999855, -228.4000000000001, -168.4000000000006, -3.099999999999958, 13.699999999999966, 9.499999999999964, -419.39999999999986, -366.39999999999975, -32.49999999999975, -152.20000000000067, -51.40000000000005, -96.40000000000023, 3.1999999999999615, 20.000000000000014, -204.70000000000053, 20.000000000000014, -61.600000000000634, -79.90000000000059, -0.9999999999999846, -5.4999999999999964, -5.1999999999999265, 17.899999999999988, -82.0000000000008, -181.6000000000006, -62.80000000000062, -0.9999999999999881, -23.799999999999756, -125.20000000000061, 31.100000000000207, 45.50000000000022, -86.80000000000054, 9.499999999999964, -47.19999999999979, 17.899999999999984, 15.799999999999963, -315.7, 20.000000000000014, -103.30000000000072, -33.99999999999977, 3.1999999999999615, 10.699999999999989, -53.50000000000016], "policy_predator_policy_reward": [137.0, 130.0, 161.0, 149.0, 135.0, 161.0, 90.0, 161.0, 148.0, 96.0, 121.0, 156.0, 141.0, 93.0, 138.0, 129.0, 119.0, 83.0, 172.0, 137.0, 81.0, 57.0, 153.0, 24.0, 32.0, 102.0, 69.0, 86.0, 138.0, 159.0, 33.0, 159.0, 151.0, 172.0, 155.0, 156.0, 129.0, 127.0, 160.0, 159.0, 119.0, 65.0, 118.0, 78.0, 4.0, 126.0, 52.0, 43.0, 56.0, 38.0, 118.0, 112.0, 79.0, 61.0, 55.0, 76.0, 89.0, 90.0, 61.0, 83.0, 141.0, 137.0, 137.0, 138.0, 108.0, 62.0, 98.0, 102.0, 0.0, 7.0, 185.0, 79.0, 75.0, 76.0, 136.0, 87.0, 64.0, 81.0, 145.0, 89.0, 81.0, 79.0, 34.0, 83.0, 0.0, 0.0, 165.0, 126.0, 75.0, 108.0, 30.0, 44.0, 132.0, 101.0, 159.0, 89.0, 132.0, 95.0, 45.0, 72.0, 115.0, 84.0, 151.0, 91.0, 91.0, 44.0, 98.0, 148.0, 65.0, 14.0, 87.0, 74.0, 69.0, 73.0, 86.0, 147.0, 123.0, 94.0, 80.0, 56.0, 6.0, 23.0, 104.0, 121.0, 104.0, 35.0, 79.0, 159.0, 111.0, 63.0, 44.0, 46.0, 96.0, 70.0, 87.0, 152.0, 167.0, 122.0, 5.0, 13.0, 76.0, 18.0, 188.0, 61.0, 36.0, 24.0, 92.0, 46.0, 32.0, 36.0, 161.0, 180.0, 12.0, 6.0, 56.0, 18.0, 3.0, 3.0, 89.0, 122.0, 40.0, 86.0, 5.0, 3.0, 235.0, 0.0, 72.0, 77.0, 56.0, 102.0, 8.0, 1.0, 95.0, 82.0, 83.0, 41.0, 30.0, 9.0, 12.0, 1.0, 96.0, 74.0, 30.0, 43.0, 66.0, 46.0, 5.0, 5.0, 25.0, 51.0, 38.0, 29.0, 171.0, 140.0, 41.0, 60.0, 24.0, 32.0, 13.0, 35.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7503864965112176, "mean_inference_ms": 1.941484386834908, "mean_action_processing_ms": 0.3144011342906049, "mean_env_wait_ms": 0.24495356108228716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00764918327331543, "StateBufferConnector_ms": 0.0035049915313720703, "ViewRequirementAgentConnector_ms": 0.10735630989074707}, "num_episodes": 18, "episode_return_max": 191.3, "episode_return_min": -550.7999999999995, "episode_return_mean": -40.164000000000016, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.646352298395, "num_env_steps_trained_throughput_per_sec": 348.646352298395, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 11946.762, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11946.712, "sample_time_ms": 1691.082, "learn_time_ms": 10240.594, "learn_throughput": 390.602, "synch_weights_time_ms": 13.017}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-53-04", "timestamp": 1723647184, "time_this_iter_s": 11.522769927978516, "time_total_s": 353.7207610607147, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee0d670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 353.7207610607147, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 46.63529411764706, "ram_util_percent": 83.48235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3950682603335254, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.326944390869645, "policy_loss": -0.004422033755921774, "vf_loss": 2.3300473577761776, "vf_explained_var": -0.006212101316956616, "kl": 0.0058625001311620175, "entropy": 1.33702393499001, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.505250857620643, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.251420525268272, "policy_loss": -0.006386357745421785, "vf_loss": 3.257074627485225, "vf_explained_var": 0.013281561363311042, "kl": 0.004881723938958352, "entropy": 1.321836034456889, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 191.3, "episode_reward_min": -550.7999999999995, "episode_reward_mean": -27.253000000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -419.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.199999999999974, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -84.99650000000013, "predator_policy": 71.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-153.7, -11.799999999999933, -85.89999999999998, 7.400000000000082, -8.199999999999939, 12.30000000000014, 13.700000000000113, 87.29999999999998, 5.400000000000071, 162.0, -16.199999999999676, -71.60000000000079, -103.50000000000001, -113.6999999999999, -141.90000000000032, 63.30000000000001, 32.30000000000018, -185.29999999999998, 49.400000000000134, -18.69999999999986, 34.40000000000003, 40.90000000000015, 191.3, -22.999999999999666, 40.0000000000003, -164.00000000000003, -25.399999999999892, -54.00000000000108, -109.80000000000052, -338.6999999999998, -213.90000000000006, 75.6999999999997, -57.400000000000006, -150.30000000000058, 101.79999999999981, -55.999999999999915, -30.399999999999906, -22.79999999999982, 14.299999999999986, -78.30000000000044, -106.30000000000001, 111.19999999999986, 14.399999999999965, -4.400000000000006, -40.59999999999968, -34.899999999999835, -40.09999999999966, 4.600000000000012, 14.89999999999998, -209.9000000000008, -209.80000000000047, 26.50000000000008, -29.799999999999734, -174.50000000000026, 26.800000000000104, -22.700000000000014, 0.9000000000002142, -26.699999999999758, 32.800000000000196, 16.499999999999993, 33.4000000000002, -26.799999999999933, -45.49999999999958, 31.200000000000166, -550.7999999999995, -35.699999999999584, 10.199999999999985, 32.20000000000018, -7.699999999999804, -17.49999999999966, 32.50000000000021, 25.700000000000067, -93.60000000000139, 9.199999999999928, -36.9999999999996, 86.59999999999886, -1.3000000000000722, 37.700000000000266, 11.099999999999952, 17.699999999999957, 25.200000000000074, 5.200000000000127, 1.2000000000000652, -136.9000000000009, 9.90000000000011, 22.000000000000046, 21.70000000000003, 29.200000000000326, 4.999999999999934, 74.2999999999997, 28.200000000000138, 14.099999999999946, -89.8000000000012, 28.40000000000014, 21.20000000000001, 16.399999999999956, -387.29999999999995, -19.599999999999547, 48.50000000000045, 0.2999999999999901], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-144.7, -265.0, -275.20000000000005, -55.59999999999994, 1.0999999999999865, -271.00000000000006, 38.00000000000004, -226.60000000000016, -112.30000000000007, -25.899999999999974, -45.09999999999976, -37.59999999999997, -14.199999999999918, -66.1000000000009, -123.70000000000002, -19.0, -116.80000000000018, -17.79999999999974, 26.0, 5.0, -11.499999999999751, -183.69999999999993, -106.0000000000008, -109.60000000000036, -205.00000000000026, -176.5, -253.9, -134.8, -192.4000000000002, -119.50000000000011, -10.599999999999994, -126.10000000000016, 5.299999999999965, 20.000000000000014, -301.0, -148.3, -115.30000000000007, 13.699999999999967, 5.299999999999965, -247.0, -70.89999999999995, -39.69999999999998, -256.2999999999997, 63.199999999999974, -0.7000000000001876, 32.0, -153.70000000000053, 13.699999999999964, 20.000000000000014, 20.000000000000014, -238.0, -217.00000000000003, -90.39999999999993, -118.00000000000063, -66.10000000000088, -61.900000000000766, -197.8, -145.0000000000005, -322.29999999999984, -264.4, -196.00000000000006, -244.9, -50.79999999999998, 9.499999999999964, -50.79999999999998, -205.6, -194.50000000000028, -197.8000000000003, -5.500000000000018, -27.700000000000003, -57.999999999999964, -244.0, -104.2000000000006, -5.19999999999999, -17.79999999999974, -166.00000000000006, -130.90000000000055, 3.1999999999999615, -0.9999999999999846, -310.30000000000007, -170.8, -152.5, -27.700000000000003, 2.900000000000012, 15.799999999999963, -30.39999999999975, -242.2000000000001, 12.799999999999983, 20.000000000000014, -199.60000000000048, -51.70000000000001, -221.20000000000044, -53.79999999999991, -160.30000000000058, -92.80000000000001, 7.399999999999979, -111.10000000000056, -39.999999999999886, -273.60000000000025, -175.30000000000052, -226.30000000000027, -272.4999999999992, 15.799999999999963, -7.299999999999891, -124.90000000000046, 1.0999999999999652, -167.20000000000002, -256.2999999999986, -25.8999999999998, -7.299999999999891, -136.60000000000005, -24.099999999999746, 1.0999999999999865, -68.20000000000087, -373.0, 5.299999999999965, 7.399999999999965, 7.399999999999981, -77.50000000000065, 20.000000000000014, 13.699999999999964, 13.699999999999964, -9.399999999999855, -228.4000000000001, -168.4000000000006, -3.099999999999958, 13.699999999999966, 9.499999999999964, -419.39999999999986, -366.39999999999975, -32.49999999999975, -152.20000000000067, -51.40000000000005, -96.40000000000023, 3.1999999999999615, 20.000000000000014, -204.70000000000053, 20.000000000000014, -61.600000000000634, -79.90000000000059, -0.9999999999999846, -5.4999999999999964, -5.1999999999999265, 17.899999999999988, -82.0000000000008, -181.6000000000006, -62.80000000000062, -0.9999999999999881, -23.799999999999756, -125.20000000000061, 31.100000000000207, 45.50000000000022, -86.80000000000054, 9.499999999999964, -47.19999999999979, 17.899999999999984, 15.799999999999963, -315.7, 20.000000000000014, -103.30000000000072, -33.99999999999977, 3.1999999999999615, 10.699999999999989, -53.50000000000016, -0.9999999999999846, -137.80000000000064, -319.09999999999866, -62.80000000000044, 1.0999999999999865, -5.1999999999999265, -94.0000000000008, 20.000000000000014, -0.4000000000000259, -61.900000000000766, -41.79999999999987, -1.0000000000000062, -121.0000000000006, 20.000000000000014, 26.600000000000158, 13.699999999999964, -72.40000000000089, 32.60000000000023, -61.90000000000051, 20.000000000000014, -229.90000000000046, -85.90000000000074, -34.89999999999982, 5.299999999999965, -116.80000000000075, 20.000000000000014, -24.099999999999746, 15.499999999999964, -249.40000000000038, -397.9, 5.299999999999965, -121.90000000000074, 20.000000000000014, 12.499999999999972, -76.90000000000086, -68.80000000000047], "policy_predator_policy_reward": [129.0, 127.0, 160.0, 159.0, 119.0, 65.0, 118.0, 78.0, 4.0, 126.0, 52.0, 43.0, 56.0, 38.0, 118.0, 112.0, 79.0, 61.0, 55.0, 76.0, 89.0, 90.0, 61.0, 83.0, 141.0, 137.0, 137.0, 138.0, 108.0, 62.0, 98.0, 102.0, 0.0, 7.0, 185.0, 79.0, 75.0, 76.0, 136.0, 87.0, 64.0, 81.0, 145.0, 89.0, 81.0, 79.0, 34.0, 83.0, 0.0, 0.0, 165.0, 126.0, 75.0, 108.0, 30.0, 44.0, 132.0, 101.0, 159.0, 89.0, 132.0, 95.0, 45.0, 72.0, 115.0, 84.0, 151.0, 91.0, 91.0, 44.0, 98.0, 148.0, 65.0, 14.0, 87.0, 74.0, 69.0, 73.0, 86.0, 147.0, 123.0, 94.0, 80.0, 56.0, 6.0, 23.0, 104.0, 121.0, 104.0, 35.0, 79.0, 159.0, 111.0, 63.0, 44.0, 46.0, 96.0, 70.0, 87.0, 152.0, 167.0, 122.0, 5.0, 13.0, 76.0, 18.0, 188.0, 61.0, 36.0, 24.0, 92.0, 46.0, 32.0, 36.0, 161.0, 180.0, 12.0, 6.0, 56.0, 18.0, 3.0, 3.0, 89.0, 122.0, 40.0, 86.0, 5.0, 3.0, 235.0, 0.0, 72.0, 77.0, 56.0, 102.0, 8.0, 1.0, 95.0, 82.0, 83.0, 41.0, 30.0, 9.0, 12.0, 1.0, 96.0, 74.0, 30.0, 43.0, 66.0, 46.0, 5.0, 5.0, 25.0, 51.0, 38.0, 29.0, 171.0, 140.0, 41.0, 60.0, 24.0, 32.0, 13.0, 35.0, 66.0, 74.0, 42.0, 203.0, 2.0, 12.0, 53.0, 43.0, 64.0, 20.0, 41.0, 31.0, 44.0, 62.0, 13.0, 21.0, 27.0, 41.0, 33.0, 23.0, 108.0, 118.0, 31.0, 27.0, 61.0, 57.0, 21.0, 4.0, 61.0, 199.0, 39.0, 58.0, 8.0, 8.0, 57.0, 89.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7489186692444477, "mean_inference_ms": 1.9395462026611359, "mean_action_processing_ms": 0.3169606193214321, "mean_env_wait_ms": 0.24415671515918386, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00708925724029541, "StateBufferConnector_ms": 0.003461122512817383, "ViewRequirementAgentConnector_ms": 0.10568106174468994}, "num_episodes": 18, "episode_return_max": 191.3, "episode_return_min": -550.7999999999995, "episode_return_mean": -27.253000000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.2110157053818, "num_env_steps_trained_throughput_per_sec": 352.2110157053818, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 11897.811, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11897.765, "sample_time_ms": 1644.739, "learn_time_ms": 10238.036, "learn_throughput": 390.7, "synch_weights_time_ms": 13.105}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-53-15", "timestamp": 1723647195, "time_this_iter_s": 11.41583800315857, "time_total_s": 365.1365990638733, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee0dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 365.1365990638733, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 45.6125, "ram_util_percent": 83.10625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.450297751833522, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1199466496863693, "policy_loss": -0.0038153162708988897, "vf_loss": 2.1225211699172934, "vf_explained_var": 0.0231252011798677, "kl": 0.005514662257568545, "entropy": 1.3671611846439422, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4136364705348141, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5624485050559676, "policy_loss": -0.011411619686679274, "vf_loss": 2.5726583302336397, "vf_explained_var": 0.02757564101900373, "kl": 0.01602405333461508, "entropy": 1.2543647944611847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 111.19999999999986, "episode_reward_min": -550.7999999999995, "episode_reward_mean": -23.456999999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -419.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.00000000000024, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -69.74850000000013, "predator_policy": 58.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-54.00000000000108, -109.80000000000052, -338.6999999999998, -213.90000000000006, 75.6999999999997, -57.400000000000006, -150.30000000000058, 101.79999999999981, -55.999999999999915, -30.399999999999906, -22.79999999999982, 14.299999999999986, -78.30000000000044, -106.30000000000001, 111.19999999999986, 14.399999999999965, -4.400000000000006, -40.59999999999968, -34.899999999999835, -40.09999999999966, 4.600000000000012, 14.89999999999998, -209.9000000000008, -209.80000000000047, 26.50000000000008, -29.799999999999734, -174.50000000000026, 26.800000000000104, -22.700000000000014, 0.9000000000002142, -26.699999999999758, 32.800000000000196, 16.499999999999993, 33.4000000000002, -26.799999999999933, -45.49999999999958, 31.200000000000166, -550.7999999999995, -35.699999999999584, 10.199999999999985, 32.20000000000018, -7.699999999999804, -17.49999999999966, 32.50000000000021, 25.700000000000067, -93.60000000000139, 9.199999999999928, -36.9999999999996, 86.59999999999886, -1.3000000000000722, 37.700000000000266, 11.099999999999952, 17.699999999999957, 25.200000000000074, 5.200000000000127, 1.2000000000000652, -136.9000000000009, 9.90000000000011, 22.000000000000046, 21.70000000000003, 29.200000000000326, 4.999999999999934, 74.2999999999997, 28.200000000000138, 14.099999999999946, -89.8000000000012, 28.40000000000014, 21.20000000000001, 16.399999999999956, -387.29999999999995, -19.599999999999547, 48.50000000000045, 0.2999999999999901, 7.399999999999977, 8.60000000000013, -4.099999999999753, 9.200000000000074, -1.8999999999998716, 35.50000000000031, 25.800000000000214, -260.09999999999815, 31.500000000000178, 21.300000000000008, -88.90000000000155, 13.599999999999937, -32.79999999999956, 17.199999999999935, 27.100000000000286, 16.799999999999947, 14.100000000000003, -9.89999999999964, 13.200000000000056, 24.000000000000046, -15.599999999999605, 14.499999999999988, 24.700000000000053, 3.500000000000053, 33.400000000000205, 40.20000000000032, 28.100000000000108], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-66.10000000000088, -61.900000000000766, -197.8, -145.0000000000005, -322.29999999999984, -264.4, -196.00000000000006, -244.9, -50.79999999999998, 9.499999999999964, -50.79999999999998, -205.6, -194.50000000000028, -197.8000000000003, -5.500000000000018, -27.700000000000003, -57.999999999999964, -244.0, -104.2000000000006, -5.19999999999999, -17.79999999999974, -166.00000000000006, -130.90000000000055, 3.1999999999999615, -0.9999999999999846, -310.30000000000007, -170.8, -152.5, -27.700000000000003, 2.900000000000012, 15.799999999999963, -30.39999999999975, -242.2000000000001, 12.799999999999983, 20.000000000000014, -199.60000000000048, -51.70000000000001, -221.20000000000044, -53.79999999999991, -160.30000000000058, -92.80000000000001, 7.399999999999979, -111.10000000000056, -39.999999999999886, -273.60000000000025, -175.30000000000052, -226.30000000000027, -272.4999999999992, 15.799999999999963, -7.299999999999891, -124.90000000000046, 1.0999999999999652, -167.20000000000002, -256.2999999999986, -25.8999999999998, -7.299999999999891, -136.60000000000005, -24.099999999999746, 1.0999999999999865, -68.20000000000087, -373.0, 5.299999999999965, 7.399999999999965, 7.399999999999981, -77.50000000000065, 20.000000000000014, 13.699999999999964, 13.699999999999964, -9.399999999999855, -228.4000000000001, -168.4000000000006, -3.099999999999958, 13.699999999999966, 9.499999999999964, -419.39999999999986, -366.39999999999975, -32.49999999999975, -152.20000000000067, -51.40000000000005, -96.40000000000023, 3.1999999999999615, 20.000000000000014, -204.70000000000053, 20.000000000000014, -61.600000000000634, -79.90000000000059, -0.9999999999999846, -5.4999999999999964, -5.1999999999999265, 17.899999999999988, -82.0000000000008, -181.6000000000006, -62.80000000000062, -0.9999999999999881, -23.799999999999756, -125.20000000000061, 31.100000000000207, 45.50000000000022, -86.80000000000054, 9.499999999999964, -47.19999999999979, 17.899999999999984, 15.799999999999963, -315.7, 20.000000000000014, -103.30000000000072, -33.99999999999977, 3.1999999999999615, 10.699999999999989, -53.50000000000016, -0.9999999999999846, -137.80000000000064, -319.09999999999866, -62.80000000000044, 1.0999999999999865, -5.1999999999999265, -94.0000000000008, 20.000000000000014, -0.4000000000000259, -61.900000000000766, -41.79999999999987, -1.0000000000000062, -121.0000000000006, 20.000000000000014, 26.600000000000158, 13.699999999999964, -72.40000000000089, 32.60000000000023, -61.90000000000051, 20.000000000000014, -229.90000000000046, -85.90000000000074, -34.89999999999982, 5.299999999999965, -116.80000000000075, 20.000000000000014, -24.099999999999746, 15.499999999999964, -249.40000000000038, -397.9, 5.299999999999965, -121.90000000000074, 20.000000000000014, 12.499999999999972, -76.90000000000086, -68.80000000000047, -86.20000000000066, 11.599999999999964, -5.1999999999999265, -5.1999999999999265, -52.59999999999992, -2.4999999999999822, -47.199999999999775, -13.599999999999783, 3.1999999999999615, -126.10000000000068, -24.099999999999746, -0.40000000000002944, -107.80000000000052, 11.599999999999975, -273.19999999999914, -161.9000000000006, 20.000000000000014, -74.50000000000088, 20.000000000000014, -69.70000000000087, -114.40000000000074, -92.50000000000082, -24.099999999999824, 13.699999999999964, -36.699999999999754, -87.10000000000076, -51.69999999999994, 17.899999999999988, -334.8999999999993, 47.00000000000024, 20.000000000000014, -107.20000000000078, 9.49999999999997, -24.39999999999975, -92.20000000000076, 5.299999999999965, 5.299999999999965, -3.099999999999958, 20.000000000000014, -42.99999999999976, -59.80000000000062, -92.8000000000007, -55.600000000000335, -1.9000000000000212, -9.399999999999855, 16.099999999999962, 1.0999999999999865, -94.60000000000075, 20.000000000000014, 7.399999999999965, 5.299999999999965, -30.099999999999774, 7.399999999999965, 13.699999999999964], "policy_predator_policy_reward": [30.0, 44.0, 132.0, 101.0, 159.0, 89.0, 132.0, 95.0, 45.0, 72.0, 115.0, 84.0, 151.0, 91.0, 91.0, 44.0, 98.0, 148.0, 65.0, 14.0, 87.0, 74.0, 69.0, 73.0, 86.0, 147.0, 123.0, 94.0, 80.0, 56.0, 6.0, 23.0, 104.0, 121.0, 104.0, 35.0, 79.0, 159.0, 111.0, 63.0, 44.0, 46.0, 96.0, 70.0, 87.0, 152.0, 167.0, 122.0, 5.0, 13.0, 76.0, 18.0, 188.0, 61.0, 36.0, 24.0, 92.0, 46.0, 32.0, 36.0, 161.0, 180.0, 12.0, 6.0, 56.0, 18.0, 3.0, 3.0, 89.0, 122.0, 40.0, 86.0, 5.0, 3.0, 235.0, 0.0, 72.0, 77.0, 56.0, 102.0, 8.0, 1.0, 95.0, 82.0, 83.0, 41.0, 30.0, 9.0, 12.0, 1.0, 96.0, 74.0, 30.0, 43.0, 66.0, 46.0, 5.0, 5.0, 25.0, 51.0, 38.0, 29.0, 171.0, 140.0, 41.0, 60.0, 24.0, 32.0, 13.0, 35.0, 66.0, 74.0, 42.0, 203.0, 2.0, 12.0, 53.0, 43.0, 64.0, 20.0, 41.0, 31.0, 44.0, 62.0, 13.0, 21.0, 27.0, 41.0, 33.0, 23.0, 108.0, 118.0, 31.0, 27.0, 61.0, 57.0, 21.0, 4.0, 61.0, 199.0, 39.0, 58.0, 8.0, 8.0, 57.0, 89.0, 30.0, 52.0, 12.0, 7.0, 18.0, 33.0, 35.0, 35.0, 53.0, 68.0, 39.0, 21.0, 60.0, 62.0, 175.0, 0.0, 41.0, 45.0, 32.0, 39.0, 54.0, 64.0, 3.0, 21.0, 54.0, 37.0, 38.0, 13.0, 155.0, 160.0, 48.0, 56.0, 14.0, 15.0, 31.0, 46.0, 0.0, 11.0, 23.0, 24.0, 64.0, 73.0, 55.0, 17.0, 14.0, 4.0, 56.0, 41.0, 6.0, 0.0, 33.0, 32.0, 1.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7447271992312643, "mean_inference_ms": 1.9310223301045226, "mean_action_processing_ms": 0.31963117584772827, "mean_env_wait_ms": 0.24244499633924652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00603485107421875, "StateBufferConnector_ms": 0.0035628080368041992, "ViewRequirementAgentConnector_ms": 0.1081160306930542}, "num_episodes": 27, "episode_return_max": 111.19999999999986, "episode_return_min": -550.7999999999995, "episode_return_mean": -23.456999999999994, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.1638198211413, "num_env_steps_trained_throughput_per_sec": 351.1638198211413, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 11847.33, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11847.283, "sample_time_ms": 1588.604, "learn_time_ms": 10242.537, "learn_throughput": 390.528, "synch_weights_time_ms": 14.249}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-53-27", "timestamp": 1723647207, "time_this_iter_s": 11.433356046676636, "time_total_s": 376.5699551105499, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee11f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 376.5699551105499, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 45.64375, "ram_util_percent": 83.2625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5766837405306953, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3032840955194342, "policy_loss": -0.00646846968281482, "vf_loss": 2.308102588489573, "vf_explained_var": 0.03429522208435826, "kl": 0.0073332299490023916, "entropy": 1.3946322672581546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7373906957724738, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.103603247612242, "policy_loss": -0.0072404749942795625, "vf_loss": 3.1101433102415985, "vf_explained_var": 0.0035681548572721934, "kl": 0.009338958902385388, "entropy": 1.1293308602439032, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 86.59999999999886, "episode_reward_min": -550.7999999999995, "episode_reward_mean": -14.024999999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -449.499999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.00000000000024, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -56.58250000000012, "predator_policy": 49.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.899999999999835, -40.09999999999966, 4.600000000000012, 14.89999999999998, -209.9000000000008, -209.80000000000047, 26.50000000000008, -29.799999999999734, -174.50000000000026, 26.800000000000104, -22.700000000000014, 0.9000000000002142, -26.699999999999758, 32.800000000000196, 16.499999999999993, 33.4000000000002, -26.799999999999933, -45.49999999999958, 31.200000000000166, -550.7999999999995, -35.699999999999584, 10.199999999999985, 32.20000000000018, -7.699999999999804, -17.49999999999966, 32.50000000000021, 25.700000000000067, -93.60000000000139, 9.199999999999928, -36.9999999999996, 86.59999999999886, -1.3000000000000722, 37.700000000000266, 11.099999999999952, 17.699999999999957, 25.200000000000074, 5.200000000000127, 1.2000000000000652, -136.9000000000009, 9.90000000000011, 22.000000000000046, 21.70000000000003, 29.200000000000326, 4.999999999999934, 74.2999999999997, 28.200000000000138, 14.099999999999946, -89.8000000000012, 28.40000000000014, 21.20000000000001, 16.399999999999956, -387.29999999999995, -19.599999999999547, 48.50000000000045, 0.2999999999999901, 7.399999999999977, 8.60000000000013, -4.099999999999753, 9.200000000000074, -1.8999999999998716, 35.50000000000031, 25.800000000000214, -260.09999999999815, 31.500000000000178, 21.300000000000008, -88.90000000000155, 13.599999999999937, -32.79999999999956, 17.199999999999935, 27.100000000000286, 16.799999999999947, 14.100000000000003, -9.89999999999964, 13.200000000000056, 24.000000000000046, -15.599999999999605, 14.499999999999988, 24.700000000000053, 3.500000000000053, 33.400000000000205, 40.20000000000032, 28.100000000000108, 13.999999999999972, -19.499999999999922, -86.30000000000135, -4.599999999999985, 24.50000000000005, -50.599999999999696, 23.300000000000026, -79.70000000000084, 10.60000000000008, 29.600000000000165, 1.1000000000001895, 24.600000000000048, 27.80000000000017, 6.499999999999936, 12.800000000000058, 17.799999999999947, 36.300000000000274, 9.499999999999917], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-51.70000000000001, -221.20000000000044, -53.79999999999991, -160.30000000000058, -92.80000000000001, 7.399999999999979, -111.10000000000056, -39.999999999999886, -273.60000000000025, -175.30000000000052, -226.30000000000027, -272.4999999999992, 15.799999999999963, -7.299999999999891, -124.90000000000046, 1.0999999999999652, -167.20000000000002, -256.2999999999986, -25.8999999999998, -7.299999999999891, -136.60000000000005, -24.099999999999746, 1.0999999999999865, -68.20000000000087, -373.0, 5.299999999999965, 7.399999999999965, 7.399999999999981, -77.50000000000065, 20.000000000000014, 13.699999999999964, 13.699999999999964, -9.399999999999855, -228.4000000000001, -168.4000000000006, -3.099999999999958, 13.699999999999966, 9.499999999999964, -419.39999999999986, -366.39999999999975, -32.49999999999975, -152.20000000000067, -51.40000000000005, -96.40000000000023, 3.1999999999999615, 20.000000000000014, -204.70000000000053, 20.000000000000014, -61.600000000000634, -79.90000000000059, -0.9999999999999846, -5.4999999999999964, -5.1999999999999265, 17.899999999999988, -82.0000000000008, -181.6000000000006, -62.80000000000062, -0.9999999999999881, -23.799999999999756, -125.20000000000061, 31.100000000000207, 45.50000000000022, -86.80000000000054, 9.499999999999964, -47.19999999999979, 17.899999999999984, 15.799999999999963, -315.7, 20.000000000000014, -103.30000000000072, -33.99999999999977, 3.1999999999999615, 10.699999999999989, -53.50000000000016, -0.9999999999999846, -137.80000000000064, -319.09999999999866, -62.80000000000044, 1.0999999999999865, -5.1999999999999265, -94.0000000000008, 20.000000000000014, -0.4000000000000259, -61.900000000000766, -41.79999999999987, -1.0000000000000062, -121.0000000000006, 20.000000000000014, 26.600000000000158, 13.699999999999964, -72.40000000000089, 32.60000000000023, -61.90000000000051, 20.000000000000014, -229.90000000000046, -85.90000000000074, -34.89999999999982, 5.299999999999965, -116.80000000000075, 20.000000000000014, -24.099999999999746, 15.499999999999964, -249.40000000000038, -397.9, 5.299999999999965, -121.90000000000074, 20.000000000000014, 12.499999999999972, -76.90000000000086, -68.80000000000047, -86.20000000000066, 11.599999999999964, -5.1999999999999265, -5.1999999999999265, -52.59999999999992, -2.4999999999999822, -47.199999999999775, -13.599999999999783, 3.1999999999999615, -126.10000000000068, -24.099999999999746, -0.40000000000002944, -107.80000000000052, 11.599999999999975, -273.19999999999914, -161.9000000000006, 20.000000000000014, -74.50000000000088, 20.000000000000014, -69.70000000000087, -114.40000000000074, -92.50000000000082, -24.099999999999824, 13.699999999999964, -36.699999999999754, -87.10000000000076, -51.69999999999994, 17.899999999999988, -334.8999999999993, 47.00000000000024, 20.000000000000014, -107.20000000000078, 9.49999999999997, -24.39999999999975, -92.20000000000076, 5.299999999999965, 5.299999999999965, -3.099999999999958, 20.000000000000014, -42.99999999999976, -59.80000000000062, -92.8000000000007, -55.600000000000335, -1.9000000000000212, -9.399999999999855, 16.099999999999962, 1.0999999999999865, -94.60000000000075, 20.000000000000014, 7.399999999999965, 5.299999999999965, -30.099999999999774, 7.399999999999965, 13.699999999999964, 15.799999999999963, -38.799999999999756, -164.2000000000006, 13.699999999999969, -53.499999999999766, -137.8000000000007, 24.800000000000093, -132.40000000000043, -11.499999999999826, 20.000000000000014, 11.599999999999968, -160.20000000000047, 8.299999999999965, -0.9999999999999846, -47.19999999999979, -449.499999999999, -17.79999999999974, -1.599999999999985, -9.399999999999922, 20.000000000000014, 11.599999999999964, -74.50000000000082, -3.099999999999958, 13.699999999999964, -31.299999999999876, 1.0999999999999865, 7.399999999999965, -58.900000000000226, -7.299999999999891, 1.0999999999999865, -62.20000000000077, 20.000000000000014, 27.80000000000017, -32.49999999999975, -110.20000000000078, 13.699999999999964], "policy_predator_policy_reward": [79.0, 159.0, 111.0, 63.0, 44.0, 46.0, 96.0, 70.0, 87.0, 152.0, 167.0, 122.0, 5.0, 13.0, 76.0, 18.0, 188.0, 61.0, 36.0, 24.0, 92.0, 46.0, 32.0, 36.0, 161.0, 180.0, 12.0, 6.0, 56.0, 18.0, 3.0, 3.0, 89.0, 122.0, 40.0, 86.0, 5.0, 3.0, 235.0, 0.0, 72.0, 77.0, 56.0, 102.0, 8.0, 1.0, 95.0, 82.0, 83.0, 41.0, 30.0, 9.0, 12.0, 1.0, 96.0, 74.0, 30.0, 43.0, 66.0, 46.0, 5.0, 5.0, 25.0, 51.0, 38.0, 29.0, 171.0, 140.0, 41.0, 60.0, 24.0, 32.0, 13.0, 35.0, 66.0, 74.0, 42.0, 203.0, 2.0, 12.0, 53.0, 43.0, 64.0, 20.0, 41.0, 31.0, 44.0, 62.0, 13.0, 21.0, 27.0, 41.0, 33.0, 23.0, 108.0, 118.0, 31.0, 27.0, 61.0, 57.0, 21.0, 4.0, 61.0, 199.0, 39.0, 58.0, 8.0, 8.0, 57.0, 89.0, 30.0, 52.0, 12.0, 7.0, 18.0, 33.0, 35.0, 35.0, 53.0, 68.0, 39.0, 21.0, 60.0, 62.0, 175.0, 0.0, 41.0, 45.0, 32.0, 39.0, 54.0, 64.0, 3.0, 21.0, 54.0, 37.0, 38.0, 13.0, 155.0, 160.0, 48.0, 56.0, 14.0, 15.0, 31.0, 46.0, 0.0, 11.0, 23.0, 24.0, 64.0, 73.0, 55.0, 17.0, 14.0, 4.0, 56.0, 41.0, 6.0, 0.0, 33.0, 32.0, 1.0, 6.0, 27.0, 10.0, 46.0, 85.0, 22.0, 83.0, 31.0, 72.0, 11.0, 5.0, 16.0, 82.0, 10.0, 6.0, 220.0, 197.0, 16.0, 14.0, 14.0, 5.0, 27.0, 37.0, 11.0, 3.0, 34.0, 24.0, 34.0, 24.0, 13.0, 6.0, 40.0, 20.0, 39.0, 2.0, 58.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7405066896324027, "mean_inference_ms": 1.9206237244542907, "mean_action_processing_ms": 0.31645811286098935, "mean_env_wait_ms": 0.24077026735317417, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004159688949584961, "StateBufferConnector_ms": 0.0031810998916625977, "ViewRequirementAgentConnector_ms": 0.09934556484222412}, "num_episodes": 18, "episode_return_max": 86.59999999999886, "episode_return_min": -550.7999999999995, "episode_return_mean": -14.024999999999972, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.79609861366185, "num_env_steps_trained_throughput_per_sec": 352.79609861366185, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 11805.574, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11805.527, "sample_time_ms": 1539.711, "learn_time_ms": 10249.673, "learn_throughput": 390.256, "synch_weights_time_ms": 14.27}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-53-38", "timestamp": 1723647218, "time_this_iter_s": 11.373539924621582, "time_total_s": 387.9434950351715, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32eddbd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 387.9434950351715, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 45.1875, "ram_util_percent": 83.1375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2829223293476004, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9413185669631554, "policy_loss": -0.010158251619173421, "vf_loss": 1.9496927931825951, "vf_explained_var": 0.03109546937639751, "kl": 0.007929032843969648, "entropy": 1.4099307497342428, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3606366781015244, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2427270279359566, "policy_loss": -0.010360413059966747, "vf_loss": 2.252031228971229, "vf_explained_var": 0.006455615998575927, "kl": 0.014082836083626175, "entropy": 1.0430466003203518, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 86.59999999999886, "episode_reward_min": -550.7999999999995, "episode_reward_mean": -6.286999999999955, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -449.499999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.00000000000024, "predator_policy": 235.0}, "policy_reward_mean": {"prey_policy": -44.84850000000014, "predator_policy": 41.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.200000000000166, -550.7999999999995, -35.699999999999584, 10.199999999999985, 32.20000000000018, -7.699999999999804, -17.49999999999966, 32.50000000000021, 25.700000000000067, -93.60000000000139, 9.199999999999928, -36.9999999999996, 86.59999999999886, -1.3000000000000722, 37.700000000000266, 11.099999999999952, 17.699999999999957, 25.200000000000074, 5.200000000000127, 1.2000000000000652, -136.9000000000009, 9.90000000000011, 22.000000000000046, 21.70000000000003, 29.200000000000326, 4.999999999999934, 74.2999999999997, 28.200000000000138, 14.099999999999946, -89.8000000000012, 28.40000000000014, 21.20000000000001, 16.399999999999956, -387.29999999999995, -19.599999999999547, 48.50000000000045, 0.2999999999999901, 7.399999999999977, 8.60000000000013, -4.099999999999753, 9.200000000000074, -1.8999999999998716, 35.50000000000031, 25.800000000000214, -260.09999999999815, 31.500000000000178, 21.300000000000008, -88.90000000000155, 13.599999999999937, -32.79999999999956, 17.199999999999935, 27.100000000000286, 16.799999999999947, 14.100000000000003, -9.89999999999964, 13.200000000000056, 24.000000000000046, -15.599999999999605, 14.499999999999988, 24.700000000000053, 3.500000000000053, 33.400000000000205, 40.20000000000032, 28.100000000000108, 13.999999999999972, -19.499999999999922, -86.30000000000135, -4.599999999999985, 24.50000000000005, -50.599999999999696, 23.300000000000026, -79.70000000000084, 10.60000000000008, 29.600000000000165, 1.1000000000001895, 24.600000000000048, 27.80000000000017, 6.499999999999936, 12.800000000000058, 17.799999999999947, 36.300000000000274, 9.499999999999917, 5.70000000000009, -54.300000000001, 10.099999999999927, 7.300000000000148, 4.800000000000146, 23.200000000000063, -39.59999999999955, 20.50000000000013, 35.40000000000023, 26.500000000000114, -30.399999999999537, 32.10000000000017, 30.100000000000147, -31.39999999999973, -32.599999999999625, 57.9000000000005, 38.50000000000028, 5.700000000000076], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999966, 9.499999999999964, -419.39999999999986, -366.39999999999975, -32.49999999999975, -152.20000000000067, -51.40000000000005, -96.40000000000023, 3.1999999999999615, 20.000000000000014, -204.70000000000053, 20.000000000000014, -61.600000000000634, -79.90000000000059, -0.9999999999999846, -5.4999999999999964, -5.1999999999999265, 17.899999999999988, -82.0000000000008, -181.6000000000006, -62.80000000000062, -0.9999999999999881, -23.799999999999756, -125.20000000000061, 31.100000000000207, 45.50000000000022, -86.80000000000054, 9.499999999999964, -47.19999999999979, 17.899999999999984, 15.799999999999963, -315.7, 20.000000000000014, -103.30000000000072, -33.99999999999977, 3.1999999999999615, 10.699999999999989, -53.50000000000016, -0.9999999999999846, -137.80000000000064, -319.09999999999866, -62.80000000000044, 1.0999999999999865, -5.1999999999999265, -94.0000000000008, 20.000000000000014, -0.4000000000000259, -61.900000000000766, -41.79999999999987, -1.0000000000000062, -121.0000000000006, 20.000000000000014, 26.600000000000158, 13.699999999999964, -72.40000000000089, 32.60000000000023, -61.90000000000051, 20.000000000000014, -229.90000000000046, -85.90000000000074, -34.89999999999982, 5.299999999999965, -116.80000000000075, 20.000000000000014, -24.099999999999746, 15.499999999999964, -249.40000000000038, -397.9, 5.299999999999965, -121.90000000000074, 20.000000000000014, 12.499999999999972, -76.90000000000086, -68.80000000000047, -86.20000000000066, 11.599999999999964, -5.1999999999999265, -5.1999999999999265, -52.59999999999992, -2.4999999999999822, -47.199999999999775, -13.599999999999783, 3.1999999999999615, -126.10000000000068, -24.099999999999746, -0.40000000000002944, -107.80000000000052, 11.599999999999975, -273.19999999999914, -161.9000000000006, 20.000000000000014, -74.50000000000088, 20.000000000000014, -69.70000000000087, -114.40000000000074, -92.50000000000082, -24.099999999999824, 13.699999999999964, -36.699999999999754, -87.10000000000076, -51.69999999999994, 17.899999999999988, -334.8999999999993, 47.00000000000024, 20.000000000000014, -107.20000000000078, 9.49999999999997, -24.39999999999975, -92.20000000000076, 5.299999999999965, 5.299999999999965, -3.099999999999958, 20.000000000000014, -42.99999999999976, -59.80000000000062, -92.8000000000007, -55.600000000000335, -1.9000000000000212, -9.399999999999855, 16.099999999999962, 1.0999999999999865, -94.60000000000075, 20.000000000000014, 7.399999999999965, 5.299999999999965, -30.099999999999774, 7.399999999999965, 13.699999999999964, 15.799999999999963, -38.799999999999756, -164.2000000000006, 13.699999999999969, -53.499999999999766, -137.8000000000007, 24.800000000000093, -132.40000000000043, -11.499999999999826, 20.000000000000014, 11.599999999999968, -160.20000000000047, 8.299999999999965, -0.9999999999999846, -47.19999999999979, -449.499999999999, -17.79999999999974, -1.599999999999985, -9.399999999999922, 20.000000000000014, 11.599999999999964, -74.50000000000082, -3.099999999999958, 13.699999999999964, -31.299999999999876, 1.0999999999999865, 7.399999999999965, -58.900000000000226, -7.299999999999891, 1.0999999999999865, -62.20000000000077, 20.000000000000014, 27.80000000000017, -32.49999999999975, -110.20000000000078, 13.699999999999964, 15.799999999999963, -84.10000000000085, -42.99999999999976, -133.30000000000072, -106.90000000000069, 20.000000000000014, -3.099999999999958, -13.599999999999783, -48.399999999999764, 3.1999999999999615, -80.80000000000086, 20.000000000000014, -127.00000000000054, 7.399999999999965, -86.20000000000081, 31.700000000000095, 7.399999999999965, 20.000000000000014, -74.50000000000088, 20.000000000000014, -99.70000000000077, 5.299999999999965, 11.599999999999971, 9.499999999999964, 5.299999999999967, 15.799999999999963, 1.0999999999999865, -137.50000000000045, 11.599999999999964, -110.20000000000064, 7.399999999999965, 39.50000000000025, 9.499999999999964, 20.000000000000014, 20.000000000000014, -70.30000000000085], "policy_predator_policy_reward": [5.0, 3.0, 235.0, 0.0, 72.0, 77.0, 56.0, 102.0, 8.0, 1.0, 95.0, 82.0, 83.0, 41.0, 30.0, 9.0, 12.0, 1.0, 96.0, 74.0, 30.0, 43.0, 66.0, 46.0, 5.0, 5.0, 25.0, 51.0, 38.0, 29.0, 171.0, 140.0, 41.0, 60.0, 24.0, 32.0, 13.0, 35.0, 66.0, 74.0, 42.0, 203.0, 2.0, 12.0, 53.0, 43.0, 64.0, 20.0, 41.0, 31.0, 44.0, 62.0, 13.0, 21.0, 27.0, 41.0, 33.0, 23.0, 108.0, 118.0, 31.0, 27.0, 61.0, 57.0, 21.0, 4.0, 61.0, 199.0, 39.0, 58.0, 8.0, 8.0, 57.0, 89.0, 30.0, 52.0, 12.0, 7.0, 18.0, 33.0, 35.0, 35.0, 53.0, 68.0, 39.0, 21.0, 60.0, 62.0, 175.0, 0.0, 41.0, 45.0, 32.0, 39.0, 54.0, 64.0, 3.0, 21.0, 54.0, 37.0, 38.0, 13.0, 155.0, 160.0, 48.0, 56.0, 14.0, 15.0, 31.0, 46.0, 0.0, 11.0, 23.0, 24.0, 64.0, 73.0, 55.0, 17.0, 14.0, 4.0, 56.0, 41.0, 6.0, 0.0, 33.0, 32.0, 1.0, 6.0, 27.0, 10.0, 46.0, 85.0, 22.0, 83.0, 31.0, 72.0, 11.0, 5.0, 16.0, 82.0, 10.0, 6.0, 220.0, 197.0, 16.0, 14.0, 14.0, 5.0, 27.0, 37.0, 11.0, 3.0, 34.0, 24.0, 34.0, 24.0, 13.0, 6.0, 40.0, 20.0, 39.0, 2.0, 58.0, 48.0, 40.0, 34.0, 57.0, 65.0, 36.0, 61.0, 8.0, 16.0, 17.0, 33.0, 46.0, 38.0, 69.0, 11.0, 24.0, 51.0, 6.0, 2.0, 43.0, 38.0, 57.0, 7.0, 3.0, 8.0, 7.0, 2.0, 72.0, 33.0, 21.0, 45.0, 5.0, 6.0, 4.0, 5.0, 13.0, 43.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7361550045426308, "mean_inference_ms": 1.9089909735245851, "mean_action_processing_ms": 0.3143590554092321, "mean_env_wait_ms": 0.23933631393910418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004174351692199707, "StateBufferConnector_ms": 0.003088235855102539, "ViewRequirementAgentConnector_ms": 0.10005605220794678}, "num_episodes": 18, "episode_return_max": 86.59999999999886, "episode_return_min": -550.7999999999995, "episode_return_mean": -6.286999999999955, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.97989159128076, "num_env_steps_trained_throughput_per_sec": 349.97989159128076, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 11744.096, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11744.051, "sample_time_ms": 1490.964, "learn_time_ms": 10237.291, "learn_throughput": 390.728, "synch_weights_time_ms": 14.259}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-53-50", "timestamp": 1723647230, "time_this_iter_s": 11.470954895019531, "time_total_s": 399.41444993019104, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29eee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 399.41444993019104, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 44.83529411764705, "ram_util_percent": 83.36470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4962402095239629, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.387723909799384, "policy_loss": -0.006180829638073211, "vf_loss": 2.3916998921878756, "vf_explained_var": -0.018314151379166456, "kl": 0.009799326672516035, "entropy": 1.447359290703264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4206655788358558, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.251929493808242, "policy_loss": -0.007368505808460728, "vf_loss": 2.2587456788335527, "vf_explained_var": 0.015788372546907455, "kl": 0.007364291973768828, "entropy": 0.9578240563314427, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 74.2999999999997, "episode_reward_min": -387.29999999999995, "episode_reward_mean": -2.702999999999955, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -449.499999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.00000000000024, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -38.586500000000136, "predator_policy": 37.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.200000000000127, 1.2000000000000652, -136.9000000000009, 9.90000000000011, 22.000000000000046, 21.70000000000003, 29.200000000000326, 4.999999999999934, 74.2999999999997, 28.200000000000138, 14.099999999999946, -89.8000000000012, 28.40000000000014, 21.20000000000001, 16.399999999999956, -387.29999999999995, -19.599999999999547, 48.50000000000045, 0.2999999999999901, 7.399999999999977, 8.60000000000013, -4.099999999999753, 9.200000000000074, -1.8999999999998716, 35.50000000000031, 25.800000000000214, -260.09999999999815, 31.500000000000178, 21.300000000000008, -88.90000000000155, 13.599999999999937, -32.79999999999956, 17.199999999999935, 27.100000000000286, 16.799999999999947, 14.100000000000003, -9.89999999999964, 13.200000000000056, 24.000000000000046, -15.599999999999605, 14.499999999999988, 24.700000000000053, 3.500000000000053, 33.400000000000205, 40.20000000000032, 28.100000000000108, 13.999999999999972, -19.499999999999922, -86.30000000000135, -4.599999999999985, 24.50000000000005, -50.599999999999696, 23.300000000000026, -79.70000000000084, 10.60000000000008, 29.600000000000165, 1.1000000000001895, 24.600000000000048, 27.80000000000017, 6.499999999999936, 12.800000000000058, 17.799999999999947, 36.300000000000274, 9.499999999999917, 5.70000000000009, -54.300000000001, 10.099999999999927, 7.300000000000148, 4.800000000000146, 23.200000000000063, -39.59999999999955, 20.50000000000013, 35.40000000000023, 26.500000000000114, -30.399999999999537, 32.10000000000017, 30.100000000000147, -31.39999999999973, -32.599999999999625, 57.9000000000005, 38.50000000000028, 5.700000000000076, 15.69999999999994, 32.80000000000019, -114.5000000000015, -31.799999999999585, 29.200000000000127, 27.200000000000244, -39.19999999999957, 35.90000000000024, -66.50000000000185, -8.59999999999963, -18.699999999999513, 0.5000000000001894, 34.30000000000022, -2.0999999999998646, -50.400000000000716, 59.80000000000038, 34.30000000000022, -3.7999999999998093], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [10.699999999999989, -53.50000000000016, -0.9999999999999846, -137.80000000000064, -319.09999999999866, -62.80000000000044, 1.0999999999999865, -5.1999999999999265, -94.0000000000008, 20.000000000000014, -0.4000000000000259, -61.900000000000766, -41.79999999999987, -1.0000000000000062, -121.0000000000006, 20.000000000000014, 26.600000000000158, 13.699999999999964, -72.40000000000089, 32.60000000000023, -61.90000000000051, 20.000000000000014, -229.90000000000046, -85.90000000000074, -34.89999999999982, 5.299999999999965, -116.80000000000075, 20.000000000000014, -24.099999999999746, 15.499999999999964, -249.40000000000038, -397.9, 5.299999999999965, -121.90000000000074, 20.000000000000014, 12.499999999999972, -76.90000000000086, -68.80000000000047, -86.20000000000066, 11.599999999999964, -5.1999999999999265, -5.1999999999999265, -52.59999999999992, -2.4999999999999822, -47.199999999999775, -13.599999999999783, 3.1999999999999615, -126.10000000000068, -24.099999999999746, -0.40000000000002944, -107.80000000000052, 11.599999999999975, -273.19999999999914, -161.9000000000006, 20.000000000000014, -74.50000000000088, 20.000000000000014, -69.70000000000087, -114.40000000000074, -92.50000000000082, -24.099999999999824, 13.699999999999964, -36.699999999999754, -87.10000000000076, -51.69999999999994, 17.899999999999988, -334.8999999999993, 47.00000000000024, 20.000000000000014, -107.20000000000078, 9.49999999999997, -24.39999999999975, -92.20000000000076, 5.299999999999965, 5.299999999999965, -3.099999999999958, 20.000000000000014, -42.99999999999976, -59.80000000000062, -92.8000000000007, -55.600000000000335, -1.9000000000000212, -9.399999999999855, 16.099999999999962, 1.0999999999999865, -94.60000000000075, 20.000000000000014, 7.399999999999965, 5.299999999999965, -30.099999999999774, 7.399999999999965, 13.699999999999964, 15.799999999999963, -38.799999999999756, -164.2000000000006, 13.699999999999969, -53.499999999999766, -137.8000000000007, 24.800000000000093, -132.40000000000043, -11.499999999999826, 20.000000000000014, 11.599999999999968, -160.20000000000047, 8.299999999999965, -0.9999999999999846, -47.19999999999979, -449.499999999999, -17.79999999999974, -1.599999999999985, -9.399999999999922, 20.000000000000014, 11.599999999999964, -74.50000000000082, -3.099999999999958, 13.699999999999964, -31.299999999999876, 1.0999999999999865, 7.399999999999965, -58.900000000000226, -7.299999999999891, 1.0999999999999865, -62.20000000000077, 20.000000000000014, 27.80000000000017, -32.49999999999975, -110.20000000000078, 13.699999999999964, 15.799999999999963, -84.10000000000085, -42.99999999999976, -133.30000000000072, -106.90000000000069, 20.000000000000014, -3.099999999999958, -13.599999999999783, -48.399999999999764, 3.1999999999999615, -80.80000000000086, 20.000000000000014, -127.00000000000054, 7.399999999999965, -86.20000000000081, 31.700000000000095, 7.399999999999965, 20.000000000000014, -74.50000000000088, 20.000000000000014, -99.70000000000077, 5.299999999999965, 11.599999999999971, 9.499999999999964, 5.299999999999967, 15.799999999999963, 1.0999999999999865, -137.50000000000045, 11.599999999999964, -110.20000000000064, 7.399999999999965, 39.50000000000025, 9.499999999999964, 20.000000000000014, 20.000000000000014, -70.30000000000085, -55.60000000000028, -3.6999999999999584, 13.699999999999964, 10.099999999999962, -116.50000000000077, -127.00000000000074, -162.4000000000004, 11.599999999999964, 11.599999999999964, 11.599999999999964, -4.599999999999806, -5.1999999999999265, 20.000000000000014, -131.20000000000067, -21.099999999999746, 20.000000000000014, -68.2000000000009, -49.299999999999905, -10.599999999999836, -42.99999999999976, -19.89999999999975, -59.80000000000062, -36.69999999999977, -35.79999999999977, 5.299999999999965, 20.000000000000014, -82.0000000000006, -24.099999999999746, -76.60000000000085, -56.80000000000027, 0.19999999999997767, 41.60000000000016, 11.59999999999998, -7.299999999999891, -38.79999999999977, -1.000000000000047], "policy_predator_policy_reward": [13.0, 35.0, 66.0, 74.0, 42.0, 203.0, 2.0, 12.0, 53.0, 43.0, 64.0, 20.0, 41.0, 31.0, 44.0, 62.0, 13.0, 21.0, 27.0, 41.0, 33.0, 23.0, 108.0, 118.0, 31.0, 27.0, 61.0, 57.0, 21.0, 4.0, 61.0, 199.0, 39.0, 58.0, 8.0, 8.0, 57.0, 89.0, 30.0, 52.0, 12.0, 7.0, 18.0, 33.0, 35.0, 35.0, 53.0, 68.0, 39.0, 21.0, 60.0, 62.0, 175.0, 0.0, 41.0, 45.0, 32.0, 39.0, 54.0, 64.0, 3.0, 21.0, 54.0, 37.0, 38.0, 13.0, 155.0, 160.0, 48.0, 56.0, 14.0, 15.0, 31.0, 46.0, 0.0, 11.0, 23.0, 24.0, 64.0, 73.0, 55.0, 17.0, 14.0, 4.0, 56.0, 41.0, 6.0, 0.0, 33.0, 32.0, 1.0, 6.0, 27.0, 10.0, 46.0, 85.0, 22.0, 83.0, 31.0, 72.0, 11.0, 5.0, 16.0, 82.0, 10.0, 6.0, 220.0, 197.0, 16.0, 14.0, 14.0, 5.0, 27.0, 37.0, 11.0, 3.0, 34.0, 24.0, 34.0, 24.0, 13.0, 6.0, 40.0, 20.0, 39.0, 2.0, 58.0, 48.0, 40.0, 34.0, 57.0, 65.0, 36.0, 61.0, 8.0, 16.0, 17.0, 33.0, 46.0, 38.0, 69.0, 11.0, 24.0, 51.0, 6.0, 2.0, 43.0, 38.0, 57.0, 7.0, 3.0, 8.0, 7.0, 2.0, 72.0, 33.0, 21.0, 45.0, 5.0, 6.0, 4.0, 5.0, 13.0, 43.0, 34.0, 41.0, 4.0, 5.0, 60.0, 69.0, 48.0, 71.0, 5.0, 1.0, 25.0, 12.0, 20.0, 52.0, 18.0, 19.0, 9.0, 42.0, 15.0, 30.0, 23.0, 38.0, 38.0, 35.0, 2.0, 7.0, 48.0, 56.0, 44.0, 39.0, 12.0, 6.0, 17.0, 13.0, 19.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7319467482519323, "mean_inference_ms": 1.8977937839081918, "mean_action_processing_ms": 0.31232807829522996, "mean_env_wait_ms": 0.23799926648853265, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004329085350036621, "StateBufferConnector_ms": 0.003255486488342285, "ViewRequirementAgentConnector_ms": 0.10068929195404053}, "num_episodes": 18, "episode_return_max": 74.2999999999997, "episode_return_min": -387.29999999999995, "episode_return_mean": -2.702999999999955, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.2193751459798, "num_env_steps_trained_throughput_per_sec": 353.2193751459798, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 11580.486, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11580.441, "sample_time_ms": 1405.357, "learn_time_ms": 10158.725, "learn_throughput": 393.75, "synch_weights_time_ms": 14.493}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-54-01", "timestamp": 1723647241, "time_this_iter_s": 11.364022731781006, "time_total_s": 410.77847266197205, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32eddad30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 410.77847266197205, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 44.95625, "ram_util_percent": 83.22500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8217079758013368, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7225987124064612, "policy_loss": -0.004750755613684536, "vf_loss": 1.7265365037653182, "vf_explained_var": -0.03353336712039968, "kl": 0.003613183225060033, "entropy": 1.471624646174214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3825400936540473, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2686101181166514, "policy_loss": -0.007569759975497922, "vf_loss": 1.275471412630939, "vf_explained_var": 0.03897680037866825, "kl": 0.00944618346915108, "entropy": 1.0192965237867264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 100.19999999999973, "episode_reward_min": -260.09999999999815, "episode_reward_mean": 5.072000000000055, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -449.499999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.8, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -29.014000000000095, "predator_policy": 31.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.200000000000074, -1.8999999999998716, 35.50000000000031, 25.800000000000214, -260.09999999999815, 31.500000000000178, 21.300000000000008, -88.90000000000155, 13.599999999999937, -32.79999999999956, 17.199999999999935, 27.100000000000286, 16.799999999999947, 14.100000000000003, -9.89999999999964, 13.200000000000056, 24.000000000000046, -15.599999999999605, 14.499999999999988, 24.700000000000053, 3.500000000000053, 33.400000000000205, 40.20000000000032, 28.100000000000108, 13.999999999999972, -19.499999999999922, -86.30000000000135, -4.599999999999985, 24.50000000000005, -50.599999999999696, 23.300000000000026, -79.70000000000084, 10.60000000000008, 29.600000000000165, 1.1000000000001895, 24.600000000000048, 27.80000000000017, 6.499999999999936, 12.800000000000058, 17.799999999999947, 36.300000000000274, 9.499999999999917, 5.70000000000009, -54.300000000001, 10.099999999999927, 7.300000000000148, 4.800000000000146, 23.200000000000063, -39.59999999999955, 20.50000000000013, 35.40000000000023, 26.500000000000114, -30.399999999999537, 32.10000000000017, 30.100000000000147, -31.39999999999973, -32.599999999999625, 57.9000000000005, 38.50000000000028, 5.700000000000076, 15.69999999999994, 32.80000000000019, -114.5000000000015, -31.799999999999585, 29.200000000000127, 27.200000000000244, -39.19999999999957, 35.90000000000024, -66.50000000000185, -8.59999999999963, -18.699999999999513, 0.5000000000001894, 34.30000000000022, -2.0999999999998646, -50.400000000000716, 59.80000000000038, 34.30000000000022, -3.7999999999998093, 14.199999999999974, 2.4000000000002153, 22.20000000000001, 3.7999999999999816, 6.300000000000152, 71.79999999999984, 35.50000000000034, 16.50000000000001, -34.29999999999958, 4.200000000000017, 21.8, 19.099999999999984, 5.700000000000125, -41.500000000000135, 38.70000000000028, 43.800000000000246, -39.59999999999961, 35.600000000000215, 33.000000000000185, 26.400000000000084, 95.59999999999884, 100.19999999999973], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-47.199999999999775, -13.599999999999783, 3.1999999999999615, -126.10000000000068, -24.099999999999746, -0.40000000000002944, -107.80000000000052, 11.599999999999975, -273.19999999999914, -161.9000000000006, 20.000000000000014, -74.50000000000088, 20.000000000000014, -69.70000000000087, -114.40000000000074, -92.50000000000082, -24.099999999999824, 13.699999999999964, -36.699999999999754, -87.10000000000076, -51.69999999999994, 17.899999999999988, -334.8999999999993, 47.00000000000024, 20.000000000000014, -107.20000000000078, 9.49999999999997, -24.39999999999975, -92.20000000000076, 5.299999999999965, 5.299999999999965, -3.099999999999958, 20.000000000000014, -42.99999999999976, -59.80000000000062, -92.8000000000007, -55.600000000000335, -1.9000000000000212, -9.399999999999855, 16.099999999999962, 1.0999999999999865, -94.60000000000075, 20.000000000000014, 7.399999999999965, 5.299999999999965, -30.099999999999774, 7.399999999999965, 13.699999999999964, 15.799999999999963, -38.799999999999756, -164.2000000000006, 13.699999999999969, -53.499999999999766, -137.8000000000007, 24.800000000000093, -132.40000000000043, -11.499999999999826, 20.000000000000014, 11.599999999999968, -160.20000000000047, 8.299999999999965, -0.9999999999999846, -47.19999999999979, -449.499999999999, -17.79999999999974, -1.599999999999985, -9.399999999999922, 20.000000000000014, 11.599999999999964, -74.50000000000082, -3.099999999999958, 13.699999999999964, -31.299999999999876, 1.0999999999999865, 7.399999999999965, -58.900000000000226, -7.299999999999891, 1.0999999999999865, -62.20000000000077, 20.000000000000014, 27.80000000000017, -32.49999999999975, -110.20000000000078, 13.699999999999964, 15.799999999999963, -84.10000000000085, -42.99999999999976, -133.30000000000072, -106.90000000000069, 20.000000000000014, -3.099999999999958, -13.599999999999783, -48.399999999999764, 3.1999999999999615, -80.80000000000086, 20.000000000000014, -127.00000000000054, 7.399999999999965, -86.20000000000081, 31.700000000000095, 7.399999999999965, 20.000000000000014, -74.50000000000088, 20.000000000000014, -99.70000000000077, 5.299999999999965, 11.599999999999971, 9.499999999999964, 5.299999999999967, 15.799999999999963, 1.0999999999999865, -137.50000000000045, 11.599999999999964, -110.20000000000064, 7.399999999999965, 39.50000000000025, 9.499999999999964, 20.000000000000014, 20.000000000000014, -70.30000000000085, -55.60000000000028, -3.6999999999999584, 13.699999999999964, 10.099999999999962, -116.50000000000077, -127.00000000000074, -162.4000000000004, 11.599999999999964, 11.599999999999964, 11.599999999999964, -4.599999999999806, -5.1999999999999265, 20.000000000000014, -131.20000000000067, -21.099999999999746, 20.000000000000014, -68.2000000000009, -49.299999999999905, -10.599999999999836, -42.99999999999976, -19.89999999999975, -59.80000000000062, -36.69999999999977, -35.79999999999977, 5.299999999999965, 20.000000000000014, -82.0000000000006, -24.099999999999746, -76.60000000000085, -56.80000000000027, 0.19999999999997767, 41.60000000000016, 11.59999999999998, -7.299999999999891, -38.79999999999977, -1.000000000000047, -8.499999999999893, -7.299999999999891, -21.999999999999744, -10.599999999999836, 20.000000000000014, -14.799999999999764, -24.699999999999825, -20.499999999999865, -5.199999999999944, -32.49999999999975, 20.000000000000014, 27.800000000000175, -3.999999999999948, -47.49999999999981, 15.499999999999957, -21.999999999999744, -59.80000000000062, -50.49999999999981, -118.60000000000076, 15.799999999999963, -17.79999999999974, 11.599999999999964, -15.699999999999747, 15.799999999999963, -49.29999999999989, 20.000000000000014, -32.49999999999975, -93.00000000000085, 20.000000000000014, 13.699999999999964, 29.000000000000064, 6.799999999999967, -106.0000000000008, -85.6000000000002, 4.699999999999992, 20.90000000000003, 11.599999999999977, 7.399999999999965, 20.000000000000014, -13.599999999999783, 59.60000000000015, 20.000000000000014, -13.599999999999783, 72.8], "policy_predator_policy_reward": [35.0, 35.0, 53.0, 68.0, 39.0, 21.0, 60.0, 62.0, 175.0, 0.0, 41.0, 45.0, 32.0, 39.0, 54.0, 64.0, 3.0, 21.0, 54.0, 37.0, 38.0, 13.0, 155.0, 160.0, 48.0, 56.0, 14.0, 15.0, 31.0, 46.0, 0.0, 11.0, 23.0, 24.0, 64.0, 73.0, 55.0, 17.0, 14.0, 4.0, 56.0, 41.0, 6.0, 0.0, 33.0, 32.0, 1.0, 6.0, 27.0, 10.0, 46.0, 85.0, 22.0, 83.0, 31.0, 72.0, 11.0, 5.0, 16.0, 82.0, 10.0, 6.0, 220.0, 197.0, 16.0, 14.0, 14.0, 5.0, 27.0, 37.0, 11.0, 3.0, 34.0, 24.0, 34.0, 24.0, 13.0, 6.0, 40.0, 20.0, 39.0, 2.0, 58.0, 48.0, 40.0, 34.0, 57.0, 65.0, 36.0, 61.0, 8.0, 16.0, 17.0, 33.0, 46.0, 38.0, 69.0, 11.0, 24.0, 51.0, 6.0, 2.0, 43.0, 38.0, 57.0, 7.0, 3.0, 8.0, 7.0, 2.0, 72.0, 33.0, 21.0, 45.0, 5.0, 6.0, 4.0, 5.0, 13.0, 43.0, 34.0, 41.0, 4.0, 5.0, 60.0, 69.0, 48.0, 71.0, 5.0, 1.0, 25.0, 12.0, 20.0, 52.0, 18.0, 19.0, 9.0, 42.0, 15.0, 30.0, 23.0, 38.0, 38.0, 35.0, 2.0, 7.0, 48.0, 56.0, 44.0, 39.0, 12.0, 6.0, 17.0, 13.0, 19.0, 17.0, 11.0, 19.0, 15.0, 20.0, 4.0, 13.0, 36.0, 13.0, 22.0, 22.0, 9.0, 15.0, 21.0, 66.0, 20.0, 3.0, 43.0, 33.0, 54.0, 53.0, 19.0, 9.0, 2.0, 17.0, 3.0, 32.0, 25.0, 59.0, 3.0, 2.0, 0.0, 8.0, 57.0, 95.0, 1.0, 9.0, 6.0, 8.0, 4.0, 16.0, 12.0, 4.0, 24.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7271981678545089, "mean_inference_ms": 1.8853309248996357, "mean_action_processing_ms": 0.3087844048617556, "mean_env_wait_ms": 0.23639027257134146, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004398465156555176, "StateBufferConnector_ms": 0.00590825080871582, "ViewRequirementAgentConnector_ms": 0.10126519203186035}, "num_episodes": 22, "episode_return_max": 100.19999999999973, "episode_return_min": -260.09999999999815, "episode_return_mean": 5.072000000000055, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.3763108327822, "num_env_steps_trained_throughput_per_sec": 346.3763108327822, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 11532.654, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11532.609, "sample_time_ms": 1360.229, "learn_time_ms": 10156.154, "learn_throughput": 393.85, "synch_weights_time_ms": 14.373}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-54-13", "timestamp": 1723647253, "time_this_iter_s": 11.592747926712036, "time_total_s": 422.3712205886841, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee2daf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 422.3712205886841, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 45.83125, "ram_util_percent": 83.19375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9158029730988557, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5675251027263664, "policy_loss": -0.006854490584708632, "vf_loss": 2.5736423704990004, "vf_explained_var": -0.0484036662906566, "kl": 0.006553102038488817, "entropy": 1.487521411943688, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3205860777979805, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8640980788008876, "policy_loss": -0.008594189591646668, "vf_loss": 1.871977575304647, "vf_explained_var": 0.012224754833039784, "kl": 0.009529228100027981, "entropy": 1.0337375907986253, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 101.89999999999911, "episode_reward_min": -114.5000000000015, "episode_reward_mean": 11.618000000000025, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -449.499999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.8, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -21.246000000000066, "predator_policy": 27.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.100000000000108, 13.999999999999972, -19.499999999999922, -86.30000000000135, -4.599999999999985, 24.50000000000005, -50.599999999999696, 23.300000000000026, -79.70000000000084, 10.60000000000008, 29.600000000000165, 1.1000000000001895, 24.600000000000048, 27.80000000000017, 6.499999999999936, 12.800000000000058, 17.799999999999947, 36.300000000000274, 9.499999999999917, 5.70000000000009, -54.300000000001, 10.099999999999927, 7.300000000000148, 4.800000000000146, 23.200000000000063, -39.59999999999955, 20.50000000000013, 35.40000000000023, 26.500000000000114, -30.399999999999537, 32.10000000000017, 30.100000000000147, -31.39999999999973, -32.599999999999625, 57.9000000000005, 38.50000000000028, 5.700000000000076, 15.69999999999994, 32.80000000000019, -114.5000000000015, -31.799999999999585, 29.200000000000127, 27.200000000000244, -39.19999999999957, 35.90000000000024, -66.50000000000185, -8.59999999999963, -18.699999999999513, 0.5000000000001894, 34.30000000000022, -2.0999999999998646, -50.400000000000716, 59.80000000000038, 34.30000000000022, -3.7999999999998093, 14.199999999999974, 2.4000000000002153, 22.20000000000001, 3.7999999999999816, 6.300000000000152, 71.79999999999984, 35.50000000000034, 16.50000000000001, -34.29999999999958, 4.200000000000017, 21.8, 19.099999999999984, 5.700000000000125, -41.500000000000135, 38.70000000000028, 43.800000000000246, -39.59999999999961, 35.600000000000215, 33.000000000000185, 26.400000000000084, 95.59999999999884, 100.19999999999973, 28.700000000000138, 5.400000000000095, 55.80000000000036, -6.399999999999666, 15.900000000000004, -36.79999999999957, 28.300000000000022, 30.40000000000016, 35.80000000000023, 32.60000000000019, 101.89999999999911, 13.599999999999921, 22.40000000000001, 2.50000000000013, 15.599999999999962, 72.19999999999969, 31.700000000000173, -50.90000000000084, 33.50000000000021, 24.700000000000074, 46.30000000000036, 84.09999999999953, 23.70000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 13.699999999999964, 15.799999999999963, -38.799999999999756, -164.2000000000006, 13.699999999999969, -53.499999999999766, -137.8000000000007, 24.800000000000093, -132.40000000000043, -11.499999999999826, 20.000000000000014, 11.599999999999968, -160.20000000000047, 8.299999999999965, -0.9999999999999846, -47.19999999999979, -449.499999999999, -17.79999999999974, -1.599999999999985, -9.399999999999922, 20.000000000000014, 11.599999999999964, -74.50000000000082, -3.099999999999958, 13.699999999999964, -31.299999999999876, 1.0999999999999865, 7.399999999999965, -58.900000000000226, -7.299999999999891, 1.0999999999999865, -62.20000000000077, 20.000000000000014, 27.80000000000017, -32.49999999999975, -110.20000000000078, 13.699999999999964, 15.799999999999963, -84.10000000000085, -42.99999999999976, -133.30000000000072, -106.90000000000069, 20.000000000000014, -3.099999999999958, -13.599999999999783, -48.399999999999764, 3.1999999999999615, -80.80000000000086, 20.000000000000014, -127.00000000000054, 7.399999999999965, -86.20000000000081, 31.700000000000095, 7.399999999999965, 20.000000000000014, -74.50000000000088, 20.000000000000014, -99.70000000000077, 5.299999999999965, 11.599999999999971, 9.499999999999964, 5.299999999999967, 15.799999999999963, 1.0999999999999865, -137.50000000000045, 11.599999999999964, -110.20000000000064, 7.399999999999965, 39.50000000000025, 9.499999999999964, 20.000000000000014, 20.000000000000014, -70.30000000000085, -55.60000000000028, -3.6999999999999584, 13.699999999999964, 10.099999999999962, -116.50000000000077, -127.00000000000074, -162.4000000000004, 11.599999999999964, 11.599999999999964, 11.599999999999964, -4.599999999999806, -5.1999999999999265, 20.000000000000014, -131.20000000000067, -21.099999999999746, 20.000000000000014, -68.2000000000009, -49.299999999999905, -10.599999999999836, -42.99999999999976, -19.89999999999975, -59.80000000000062, -36.69999999999977, -35.79999999999977, 5.299999999999965, 20.000000000000014, -82.0000000000006, -24.099999999999746, -76.60000000000085, -56.80000000000027, 0.19999999999997767, 41.60000000000016, 11.59999999999998, -7.299999999999891, -38.79999999999977, -1.000000000000047, -8.499999999999893, -7.299999999999891, -21.999999999999744, -10.599999999999836, 20.000000000000014, -14.799999999999764, -24.699999999999825, -20.499999999999865, -5.199999999999944, -32.49999999999975, 20.000000000000014, 27.800000000000175, -3.999999999999948, -47.49999999999981, 15.499999999999957, -21.999999999999744, -59.80000000000062, -50.49999999999981, -118.60000000000076, 15.799999999999963, -17.79999999999974, 11.599999999999964, -15.699999999999747, 15.799999999999963, -49.29999999999989, 20.000000000000014, -32.49999999999975, -93.00000000000085, 20.000000000000014, 13.699999999999964, 29.000000000000064, 6.799999999999967, -106.0000000000008, -85.6000000000002, 4.699999999999992, 20.90000000000003, 11.599999999999977, 7.399999999999965, 20.000000000000014, -13.599999999999783, 59.60000000000015, 20.000000000000014, -13.599999999999783, 72.8, -28.29999999999975, 32.00000000000002, -15.699999999999747, -76.90000000000023, 33.800000000000026, -45.99999999999984, -45.09999999999976, -7.299999999999891, 3.1999999999999615, -7.299999999999891, -143.8000000000007, -21.999999999999744, -132.10000000000036, 64.40000000000003, 20.000000000000014, -13.599999999999783, 1.0999999999999865, -73.30000000000078, -6.399999999999908, 20.000000000000014, 22.700000000000053, 30.200000000000106, -3.099999999999958, -7.299999999999937, -5.1999999999999265, 11.599999999999964, 22.700000000000053, -89.20000000000084, -15.699999999999761, 5.299999999999965, 2.8999999999999737, 32.30000000000011, -3.7000000000000015, 7.399999999999965, -78.70000000000087, -26.199999999999754, 20.000000000000014, -11.499999999999819, 9.499999999999964, -2.799999999999972, 29.900000000000173, 7.399999999999965, 18.200000000000006, 8.900000000000004, -12.999999999999813, 13.699999999999964], "policy_predator_policy_reward": [1.0, 6.0, 27.0, 10.0, 46.0, 85.0, 22.0, 83.0, 31.0, 72.0, 11.0, 5.0, 16.0, 82.0, 10.0, 6.0, 220.0, 197.0, 16.0, 14.0, 14.0, 5.0, 27.0, 37.0, 11.0, 3.0, 34.0, 24.0, 34.0, 24.0, 13.0, 6.0, 40.0, 20.0, 39.0, 2.0, 58.0, 48.0, 40.0, 34.0, 57.0, 65.0, 36.0, 61.0, 8.0, 16.0, 17.0, 33.0, 46.0, 38.0, 69.0, 11.0, 24.0, 51.0, 6.0, 2.0, 43.0, 38.0, 57.0, 7.0, 3.0, 8.0, 7.0, 2.0, 72.0, 33.0, 21.0, 45.0, 5.0, 6.0, 4.0, 5.0, 13.0, 43.0, 34.0, 41.0, 4.0, 5.0, 60.0, 69.0, 48.0, 71.0, 5.0, 1.0, 25.0, 12.0, 20.0, 52.0, 18.0, 19.0, 9.0, 42.0, 15.0, 30.0, 23.0, 38.0, 38.0, 35.0, 2.0, 7.0, 48.0, 56.0, 44.0, 39.0, 12.0, 6.0, 17.0, 13.0, 19.0, 17.0, 11.0, 19.0, 15.0, 20.0, 4.0, 13.0, 36.0, 13.0, 22.0, 22.0, 9.0, 15.0, 21.0, 66.0, 20.0, 3.0, 43.0, 33.0, 54.0, 53.0, 19.0, 9.0, 2.0, 17.0, 3.0, 32.0, 25.0, 59.0, 3.0, 2.0, 0.0, 8.0, 57.0, 95.0, 1.0, 9.0, 6.0, 8.0, 4.0, 16.0, 12.0, 4.0, 24.0, 17.0, 2.0, 23.0, 46.0, 52.0, 38.0, 30.0, 31.0, 15.0, 7.0, 13.0, 55.0, 74.0, 87.0, 9.0, 16.0, 8.0, 57.0, 51.0, 7.0, 12.0, 31.0, 18.0, 13.0, 11.0, 12.0, 4.0, 19.0, 50.0, 11.0, 15.0, 4.0, 33.0, 6.0, 22.0, 42.0, 12.0, 15.0, 10.0, 5.0, 13.0, 6.0, 3.0, 19.0, 38.0, 4.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7222176547690495, "mean_inference_ms": 1.8719173813497696, "mean_action_processing_ms": 0.3076144375903019, "mean_env_wait_ms": 0.23503583837254868, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004159212112426758, "StateBufferConnector_ms": 0.0057604312896728516, "ViewRequirementAgentConnector_ms": 0.0961378812789917}, "num_episodes": 23, "episode_return_max": 101.89999999999911, "episode_return_min": -114.5000000000015, "episode_return_mean": 11.618000000000025, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.39465881508846, "num_env_steps_trained_throughput_per_sec": 353.39465881508846, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 11497.595, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11497.55, "sample_time_ms": 1308.708, "learn_time_ms": 10172.942, "learn_throughput": 393.2, "synch_weights_time_ms": 14.16}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-54-24", "timestamp": 1723647264, "time_this_iter_s": 11.350262880325317, "time_total_s": 433.7214834690094, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee10a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 433.7214834690094, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 45.91875, "ram_util_percent": 83.33125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.186352633483826, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.176907951459683, "policy_loss": -0.005103643210456958, "vf_loss": 2.1816024855961875, "vf_explained_var": 0.026723234836386625, "kl": 0.003636498327298644, "entropy": 1.5013137142494242, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2665603630284152, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1144247847574729, "policy_loss": -0.00921422328772861, "vf_loss": 1.1229280803254043, "vf_explained_var": 0.02460320475240233, "kl": 0.009479042384980096, "entropy": 1.0604049763351522, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 101.89999999999911, "episode_reward_min": -114.5000000000015, "episode_reward_mean": 17.596000000000057, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -162.4000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.8, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -14.642000000000053, "predator_policy": 23.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.499999999999917, 5.70000000000009, -54.300000000001, 10.099999999999927, 7.300000000000148, 4.800000000000146, 23.200000000000063, -39.59999999999955, 20.50000000000013, 35.40000000000023, 26.500000000000114, -30.399999999999537, 32.10000000000017, 30.100000000000147, -31.39999999999973, -32.599999999999625, 57.9000000000005, 38.50000000000028, 5.700000000000076, 15.69999999999994, 32.80000000000019, -114.5000000000015, -31.799999999999585, 29.200000000000127, 27.200000000000244, -39.19999999999957, 35.90000000000024, -66.50000000000185, -8.59999999999963, -18.699999999999513, 0.5000000000001894, 34.30000000000022, -2.0999999999998646, -50.400000000000716, 59.80000000000038, 34.30000000000022, -3.7999999999998093, 14.199999999999974, 2.4000000000002153, 22.20000000000001, 3.7999999999999816, 6.300000000000152, 71.79999999999984, 35.50000000000034, 16.50000000000001, -34.29999999999958, 4.200000000000017, 21.8, 19.099999999999984, 5.700000000000125, -41.500000000000135, 38.70000000000028, 43.800000000000246, -39.59999999999961, 35.600000000000215, 33.000000000000185, 26.400000000000084, 95.59999999999884, 100.19999999999973, 28.700000000000138, 5.400000000000095, 55.80000000000036, -6.399999999999666, 15.900000000000004, -36.79999999999957, 28.300000000000022, 30.40000000000016, 35.80000000000023, 32.60000000000019, 101.89999999999911, 13.599999999999921, 22.40000000000001, 2.50000000000013, 15.599999999999962, 72.19999999999969, 31.700000000000173, -50.90000000000084, 33.50000000000021, 24.700000000000074, 46.30000000000036, 84.09999999999953, 23.70000000000006, 29.70000000000016, 22.100000000000012, 36.80000000000026, 49.800000000000374, 15.400000000000006, 21.299999999999994, 32.200000000000195, 30.100000000000147, 24.00000000000005, 7.899999999999951, 34.9000000000001, 57.4000000000002, 67.50000000000017, 38.80000000000028, 27.30000000000012, 39.80000000000028, 40.0000000000003, 39.10000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-110.20000000000078, 13.699999999999964, 15.799999999999963, -84.10000000000085, -42.99999999999976, -133.30000000000072, -106.90000000000069, 20.000000000000014, -3.099999999999958, -13.599999999999783, -48.399999999999764, 3.1999999999999615, -80.80000000000086, 20.000000000000014, -127.00000000000054, 7.399999999999965, -86.20000000000081, 31.700000000000095, 7.399999999999965, 20.000000000000014, -74.50000000000088, 20.000000000000014, -99.70000000000077, 5.299999999999965, 11.599999999999971, 9.499999999999964, 5.299999999999967, 15.799999999999963, 1.0999999999999865, -137.50000000000045, 11.599999999999964, -110.20000000000064, 7.399999999999965, 39.50000000000025, 9.499999999999964, 20.000000000000014, 20.000000000000014, -70.30000000000085, -55.60000000000028, -3.6999999999999584, 13.699999999999964, 10.099999999999962, -116.50000000000077, -127.00000000000074, -162.4000000000004, 11.599999999999964, 11.599999999999964, 11.599999999999964, -4.599999999999806, -5.1999999999999265, 20.000000000000014, -131.20000000000067, -21.099999999999746, 20.000000000000014, -68.2000000000009, -49.299999999999905, -10.599999999999836, -42.99999999999976, -19.89999999999975, -59.80000000000062, -36.69999999999977, -35.79999999999977, 5.299999999999965, 20.000000000000014, -82.0000000000006, -24.099999999999746, -76.60000000000085, -56.80000000000027, 0.19999999999997767, 41.60000000000016, 11.59999999999998, -7.299999999999891, -38.79999999999977, -1.000000000000047, -8.499999999999893, -7.299999999999891, -21.999999999999744, -10.599999999999836, 20.000000000000014, -14.799999999999764, -24.699999999999825, -20.499999999999865, -5.199999999999944, -32.49999999999975, 20.000000000000014, 27.800000000000175, -3.999999999999948, -47.49999999999981, 15.499999999999957, -21.999999999999744, -59.80000000000062, -50.49999999999981, -118.60000000000076, 15.799999999999963, -17.79999999999974, 11.599999999999964, -15.699999999999747, 15.799999999999963, -49.29999999999989, 20.000000000000014, -32.49999999999975, -93.00000000000085, 20.000000000000014, 13.699999999999964, 29.000000000000064, 6.799999999999967, -106.0000000000008, -85.6000000000002, 4.699999999999992, 20.90000000000003, 11.599999999999977, 7.399999999999965, 20.000000000000014, -13.599999999999783, 59.60000000000015, 20.000000000000014, -13.599999999999783, 72.8, -28.29999999999975, 32.00000000000002, -15.699999999999747, -76.90000000000023, 33.800000000000026, -45.99999999999984, -45.09999999999976, -7.299999999999891, 3.1999999999999615, -7.299999999999891, -143.8000000000007, -21.999999999999744, -132.10000000000036, 64.40000000000003, 20.000000000000014, -13.599999999999783, 1.0999999999999865, -73.30000000000078, -6.399999999999908, 20.000000000000014, 22.700000000000053, 30.200000000000106, -3.099999999999958, -7.299999999999937, -5.1999999999999265, 11.599999999999964, 22.700000000000053, -89.20000000000084, -15.699999999999761, 5.299999999999965, 2.8999999999999737, 32.30000000000011, -3.7000000000000015, 7.399999999999965, -78.70000000000087, -26.199999999999754, 20.000000000000014, -11.499999999999819, 9.499999999999964, -2.799999999999972, 29.900000000000173, 7.399999999999965, 18.200000000000006, 8.900000000000004, -12.999999999999813, 13.699999999999964, -49.299999999999905, 20.000000000000014, 3.1999999999999615, -3.1000000000000294, 31.700000000000212, -16.899999999999743, 22.100000000000062, -16.29999999999977, -17.79999999999974, 3.1999999999999615, -5.19999999999993, 9.499999999999964, -4.89999999999997, 10.099999999999953, 1.0999999999999865, 20.000000000000014, -24.99999999999976, 20.000000000000014, -39.99999999999984, -24.099999999999746, 13.99999999999997, -0.09999999999988213, 49.70000000000009, -7.299999999999933, 23.600000000000083, 20.90000000000003, 0.7999999999999723, 20.000000000000014, -15.099999999999792, 7.399999999999965, 18.800000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.499999999999986, -105.40000000000055], "policy_predator_policy_reward": [58.0, 48.0, 40.0, 34.0, 57.0, 65.0, 36.0, 61.0, 8.0, 16.0, 17.0, 33.0, 46.0, 38.0, 69.0, 11.0, 24.0, 51.0, 6.0, 2.0, 43.0, 38.0, 57.0, 7.0, 3.0, 8.0, 7.0, 2.0, 72.0, 33.0, 21.0, 45.0, 5.0, 6.0, 4.0, 5.0, 13.0, 43.0, 34.0, 41.0, 4.0, 5.0, 60.0, 69.0, 48.0, 71.0, 5.0, 1.0, 25.0, 12.0, 20.0, 52.0, 18.0, 19.0, 9.0, 42.0, 15.0, 30.0, 23.0, 38.0, 38.0, 35.0, 2.0, 7.0, 48.0, 56.0, 44.0, 39.0, 12.0, 6.0, 17.0, 13.0, 19.0, 17.0, 11.0, 19.0, 15.0, 20.0, 4.0, 13.0, 36.0, 13.0, 22.0, 22.0, 9.0, 15.0, 21.0, 66.0, 20.0, 3.0, 43.0, 33.0, 54.0, 53.0, 19.0, 9.0, 2.0, 17.0, 3.0, 32.0, 25.0, 59.0, 3.0, 2.0, 0.0, 8.0, 57.0, 95.0, 1.0, 9.0, 6.0, 8.0, 4.0, 16.0, 12.0, 4.0, 24.0, 17.0, 2.0, 23.0, 46.0, 52.0, 38.0, 30.0, 31.0, 15.0, 7.0, 13.0, 55.0, 74.0, 87.0, 9.0, 16.0, 8.0, 57.0, 51.0, 7.0, 12.0, 31.0, 18.0, 13.0, 11.0, 12.0, 4.0, 19.0, 50.0, 11.0, 15.0, 4.0, 33.0, 6.0, 22.0, 42.0, 12.0, 15.0, 10.0, 5.0, 13.0, 6.0, 3.0, 19.0, 38.0, 4.0, 19.0, 33.0, 26.0, 9.0, 13.0, 8.0, 14.0, 22.0, 22.0, 12.0, 18.0, 12.0, 5.0, 26.0, 1.0, 9.0, 0.0, 24.0, 5.0, 22.0, 50.0, 8.0, 13.0, 13.0, 2.0, 8.0, 15.0, 13.0, 5.0, 11.0, 24.0, 0.0, 1.0, 0.0, 0.0, 63.0, 63.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7187738769366142, "mean_inference_ms": 1.862692116871, "mean_action_processing_ms": 0.3060026923544115, "mean_env_wait_ms": 0.23402202217190202, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004185080528259277, "StateBufferConnector_ms": 0.005767464637756348, "ViewRequirementAgentConnector_ms": 0.09501612186431885}, "num_episodes": 18, "episode_return_max": 101.89999999999911, "episode_return_min": -114.5000000000015, "episode_return_mean": 17.596000000000057, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.15215778867025, "num_env_steps_trained_throughput_per_sec": 347.15215778867025, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 11416.547, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11416.502, "sample_time_ms": 1213.314, "learn_time_ms": 10187.261, "learn_throughput": 392.647, "synch_weights_time_ms": 14.047}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-54-36", "timestamp": 1723647276, "time_this_iter_s": 11.56502890586853, "time_total_s": 445.28651237487793, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32eddaf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 445.28651237487793, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 44.688235294117646, "ram_util_percent": 83.52352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0159993396864997, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2462525834482183, "policy_loss": -0.0113535773127325, "vf_loss": 3.2564650607487513, "vf_explained_var": 0.0794954607095668, "kl": 0.020286250596988593, "entropy": 1.4437727991866056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7350648396229618, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7480268259527822, "policy_loss": -0.010345847528703787, "vf_loss": 1.7577115028308181, "vf_explained_var": 0.024071380101814473, "kl": 0.008815570930018815, "entropy": 1.0132292540931198, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 144.39999999999927, "episode_reward_min": -114.5000000000015, "episode_reward_mean": 22.431000000000044, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -162.4000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999975, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -9.459500000000014, "predator_policy": 20.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.700000000000076, 15.69999999999994, 32.80000000000019, -114.5000000000015, -31.799999999999585, 29.200000000000127, 27.200000000000244, -39.19999999999957, 35.90000000000024, -66.50000000000185, -8.59999999999963, -18.699999999999513, 0.5000000000001894, 34.30000000000022, -2.0999999999998646, -50.400000000000716, 59.80000000000038, 34.30000000000022, -3.7999999999998093, 14.199999999999974, 2.4000000000002153, 22.20000000000001, 3.7999999999999816, 6.300000000000152, 71.79999999999984, 35.50000000000034, 16.50000000000001, -34.29999999999958, 4.200000000000017, 21.8, 19.099999999999984, 5.700000000000125, -41.500000000000135, 38.70000000000028, 43.800000000000246, -39.59999999999961, 35.600000000000215, 33.000000000000185, 26.400000000000084, 95.59999999999884, 100.19999999999973, 28.700000000000138, 5.400000000000095, 55.80000000000036, -6.399999999999666, 15.900000000000004, -36.79999999999957, 28.300000000000022, 30.40000000000016, 35.80000000000023, 32.60000000000019, 101.89999999999911, 13.599999999999921, 22.40000000000001, 2.50000000000013, 15.599999999999962, 72.19999999999969, 31.700000000000173, -50.90000000000084, 33.50000000000021, 24.700000000000074, 46.30000000000036, 84.09999999999953, 23.70000000000006, 29.70000000000016, 22.100000000000012, 36.80000000000026, 49.800000000000374, 15.400000000000006, 21.299999999999994, 32.200000000000195, 30.100000000000147, 24.00000000000005, 7.899999999999951, 34.9000000000001, 57.4000000000002, 67.50000000000017, 38.80000000000028, 27.30000000000012, 39.80000000000028, 40.0000000000003, 39.10000000000023, 53.00000000000039, 61.50000000000021, 28.600000000000126, 33.0000000000002, 20.699999999999985, 27.700000000000102, 20.300000000000143, 20.799999999999986, 19.399999999999963, 34.00000000000021, 144.39999999999927, 29.000000000000284, 15.500000000000068, -29.699999999999648, 90.39999999999903, -12.799999999999622, 8.699999999999942, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -70.30000000000085, -55.60000000000028, -3.6999999999999584, 13.699999999999964, 10.099999999999962, -116.50000000000077, -127.00000000000074, -162.4000000000004, 11.599999999999964, 11.599999999999964, 11.599999999999964, -4.599999999999806, -5.1999999999999265, 20.000000000000014, -131.20000000000067, -21.099999999999746, 20.000000000000014, -68.2000000000009, -49.299999999999905, -10.599999999999836, -42.99999999999976, -19.89999999999975, -59.80000000000062, -36.69999999999977, -35.79999999999977, 5.299999999999965, 20.000000000000014, -82.0000000000006, -24.099999999999746, -76.60000000000085, -56.80000000000027, 0.19999999999997767, 41.60000000000016, 11.59999999999998, -7.299999999999891, -38.79999999999977, -1.000000000000047, -8.499999999999893, -7.299999999999891, -21.999999999999744, -10.599999999999836, 20.000000000000014, -14.799999999999764, -24.699999999999825, -20.499999999999865, -5.199999999999944, -32.49999999999975, 20.000000000000014, 27.800000000000175, -3.999999999999948, -47.49999999999981, 15.499999999999957, -21.999999999999744, -59.80000000000062, -50.49999999999981, -118.60000000000076, 15.799999999999963, -17.79999999999974, 11.599999999999964, -15.699999999999747, 15.799999999999963, -49.29999999999989, 20.000000000000014, -32.49999999999975, -93.00000000000085, 20.000000000000014, 13.699999999999964, 29.000000000000064, 6.799999999999967, -106.0000000000008, -85.6000000000002, 4.699999999999992, 20.90000000000003, 11.599999999999977, 7.399999999999965, 20.000000000000014, -13.599999999999783, 59.60000000000015, 20.000000000000014, -13.599999999999783, 72.8, -28.29999999999975, 32.00000000000002, -15.699999999999747, -76.90000000000023, 33.800000000000026, -45.99999999999984, -45.09999999999976, -7.299999999999891, 3.1999999999999615, -7.299999999999891, -143.8000000000007, -21.999999999999744, -132.10000000000036, 64.40000000000003, 20.000000000000014, -13.599999999999783, 1.0999999999999865, -73.30000000000078, -6.399999999999908, 20.000000000000014, 22.700000000000053, 30.200000000000106, -3.099999999999958, -7.299999999999937, -5.1999999999999265, 11.599999999999964, 22.700000000000053, -89.20000000000084, -15.699999999999761, 5.299999999999965, 2.8999999999999737, 32.30000000000011, -3.7000000000000015, 7.399999999999965, -78.70000000000087, -26.199999999999754, 20.000000000000014, -11.499999999999819, 9.499999999999964, -2.799999999999972, 29.900000000000173, 7.399999999999965, 18.200000000000006, 8.900000000000004, -12.999999999999813, 13.699999999999964, -49.299999999999905, 20.000000000000014, 3.1999999999999615, -3.1000000000000294, 31.700000000000212, -16.899999999999743, 22.100000000000062, -16.29999999999977, -17.79999999999974, 3.1999999999999615, -5.19999999999993, 9.499999999999964, -4.89999999999997, 10.099999999999953, 1.0999999999999865, 20.000000000000014, -24.99999999999976, 20.000000000000014, -39.99999999999984, -24.099999999999746, 13.99999999999997, -0.09999999999988213, 49.70000000000009, -7.299999999999933, 23.600000000000083, 20.90000000000003, 0.7999999999999723, 20.000000000000014, -15.099999999999792, 7.399999999999965, 18.800000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.499999999999986, -105.40000000000055, -32.49999999999975, 51.50000000000019, 38.90000000000009, 17.59999999999999, 19.700000000000006, -3.099999999999958, -17.79999999999974, 15.799999999999963, 7.399999999999965, -36.699999999999754, 7.3999999999999755, 5.2999999999999785, 22.40000000000006, -24.099999999999994, 14.599999999999968, -14.799999999999764, -5.1999999999999265, -12.399999999999816, -7.299999999999891, 17.299999999999976, 59.300000000000175, 58.100000000000094, 20.000000000000014, -1.0000000000000373, -9.399999999999855, -24.099999999999966, 2.2999999999999803, -85.00000000000053, 73.09999999999975, 5.299999999999965, -3.100000000000024, -57.700000000000436, -57.70000000000028, 4.399999999999996, 5.299999999999965, 20.000000000000014], "policy_predator_policy_reward": [13.0, 43.0, 34.0, 41.0, 4.0, 5.0, 60.0, 69.0, 48.0, 71.0, 5.0, 1.0, 25.0, 12.0, 20.0, 52.0, 18.0, 19.0, 9.0, 42.0, 15.0, 30.0, 23.0, 38.0, 38.0, 35.0, 2.0, 7.0, 48.0, 56.0, 44.0, 39.0, 12.0, 6.0, 17.0, 13.0, 19.0, 17.0, 11.0, 19.0, 15.0, 20.0, 4.0, 13.0, 36.0, 13.0, 22.0, 22.0, 9.0, 15.0, 21.0, 66.0, 20.0, 3.0, 43.0, 33.0, 54.0, 53.0, 19.0, 9.0, 2.0, 17.0, 3.0, 32.0, 25.0, 59.0, 3.0, 2.0, 0.0, 8.0, 57.0, 95.0, 1.0, 9.0, 6.0, 8.0, 4.0, 16.0, 12.0, 4.0, 24.0, 17.0, 2.0, 23.0, 46.0, 52.0, 38.0, 30.0, 31.0, 15.0, 7.0, 13.0, 55.0, 74.0, 87.0, 9.0, 16.0, 8.0, 57.0, 51.0, 7.0, 12.0, 31.0, 18.0, 13.0, 11.0, 12.0, 4.0, 19.0, 50.0, 11.0, 15.0, 4.0, 33.0, 6.0, 22.0, 42.0, 12.0, 15.0, 10.0, 5.0, 13.0, 6.0, 3.0, 19.0, 38.0, 4.0, 19.0, 33.0, 26.0, 9.0, 13.0, 8.0, 14.0, 22.0, 22.0, 12.0, 18.0, 12.0, 5.0, 26.0, 1.0, 9.0, 0.0, 24.0, 5.0, 22.0, 50.0, 8.0, 13.0, 13.0, 2.0, 8.0, 15.0, 13.0, 5.0, 11.0, 24.0, 0.0, 1.0, 0.0, 0.0, 63.0, 63.0, 24.0, 10.0, 3.0, 2.0, 1.0, 11.0, 17.0, 18.0, 25.0, 25.0, 11.0, 4.0, 13.0, 9.0, 17.0, 4.0, 15.0, 22.0, 11.0, 13.0, 20.0, 7.0, 0.0, 10.0, 35.0, 14.0, 28.0, 25.0, 7.0, 5.0, 37.0, 11.0, 20.0, 42.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7153637831346, "mean_inference_ms": 1.853555436707508, "mean_action_processing_ms": 0.30434315854670885, "mean_env_wait_ms": 0.23296897441959838, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003705739974975586, "StateBufferConnector_ms": 0.005766034126281738, "ViewRequirementAgentConnector_ms": 0.09474408626556396}, "num_episodes": 18, "episode_return_max": 144.39999999999927, "episode_return_min": -114.5000000000015, "episode_return_mean": 22.431000000000044, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.5041353208456, "num_env_steps_trained_throughput_per_sec": 344.5041353208456, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 11431.231, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11431.187, "sample_time_ms": 1198.373, "learn_time_ms": 10217.051, "learn_throughput": 391.502, "synch_weights_time_ms": 14.023}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-54-47", "timestamp": 1723647287, "time_this_iter_s": 11.656255960464478, "time_total_s": 456.9427683353424, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d3d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 456.9427683353424, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 45.8125, "ram_util_percent": 83.50625000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3588612348945053, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.804453849918628, "policy_loss": -0.009254493059284946, "vf_loss": 3.8122412887199846, "vf_explained_var": 0.0984251342122517, "kl": 0.017387340612445817, "entropy": 1.3407327411036012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7778332835152035, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8873263518646282, "policy_loss": -0.011866406237869154, "vf_loss": 1.8983789739470003, "vf_explained_var": 0.039318402198256636, "kl": 0.010850437617178089, "entropy": 0.9983350613445201, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 144.39999999999927, "episode_reward_min": -50.90000000000084, "episode_reward_mean": 30.480000000000064, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -143.8000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.39999999999975, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -3.679999999999991, "predator_policy": 18.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.7999999999999816, 6.300000000000152, 71.79999999999984, 35.50000000000034, 16.50000000000001, -34.29999999999958, 4.200000000000017, 21.8, 19.099999999999984, 5.700000000000125, -41.500000000000135, 38.70000000000028, 43.800000000000246, -39.59999999999961, 35.600000000000215, 33.000000000000185, 26.400000000000084, 95.59999999999884, 100.19999999999973, 28.700000000000138, 5.400000000000095, 55.80000000000036, -6.399999999999666, 15.900000000000004, -36.79999999999957, 28.300000000000022, 30.40000000000016, 35.80000000000023, 32.60000000000019, 101.89999999999911, 13.599999999999921, 22.40000000000001, 2.50000000000013, 15.599999999999962, 72.19999999999969, 31.700000000000173, -50.90000000000084, 33.50000000000021, 24.700000000000074, 46.30000000000036, 84.09999999999953, 23.70000000000006, 29.70000000000016, 22.100000000000012, 36.80000000000026, 49.800000000000374, 15.400000000000006, 21.299999999999994, 32.200000000000195, 30.100000000000147, 24.00000000000005, 7.899999999999951, 34.9000000000001, 57.4000000000002, 67.50000000000017, 38.80000000000028, 27.30000000000012, 39.80000000000028, 40.0000000000003, 39.10000000000023, 53.00000000000039, 61.50000000000021, 28.600000000000126, 33.0000000000002, 20.699999999999985, 27.700000000000102, 20.300000000000143, 20.799999999999986, 19.399999999999963, 34.00000000000021, 144.39999999999927, 29.000000000000284, 15.500000000000068, -29.699999999999648, 90.39999999999903, -12.799999999999622, 8.699999999999942, 32.30000000000018, -16.099999999999504, 28.60000000000013, 33.400000000000205, 109.69999999999938, 24.200000000000077, 36.80000000000025, -49.49999999999988, -44.59999999999956, 2.6999999999999504, 97.3999999999998, 7.000000000000107, 37.30000000000026, 31.0000000000001, 12.299999999999967, 48.60000000000027, 116.69999999999987, 58.70000000000015, 32.60000000000024, 56.10000000000004, 73.5999999999996, 62.400000000000354, 24.600000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.699999999999825, -20.499999999999865, -5.199999999999944, -32.49999999999975, 20.000000000000014, 27.800000000000175, -3.999999999999948, -47.49999999999981, 15.499999999999957, -21.999999999999744, -59.80000000000062, -50.49999999999981, -118.60000000000076, 15.799999999999963, -17.79999999999974, 11.599999999999964, -15.699999999999747, 15.799999999999963, -49.29999999999989, 20.000000000000014, -32.49999999999975, -93.00000000000085, 20.000000000000014, 13.699999999999964, 29.000000000000064, 6.799999999999967, -106.0000000000008, -85.6000000000002, 4.699999999999992, 20.90000000000003, 11.599999999999977, 7.399999999999965, 20.000000000000014, -13.599999999999783, 59.60000000000015, 20.000000000000014, -13.599999999999783, 72.8, -28.29999999999975, 32.00000000000002, -15.699999999999747, -76.90000000000023, 33.800000000000026, -45.99999999999984, -45.09999999999976, -7.299999999999891, 3.1999999999999615, -7.299999999999891, -143.8000000000007, -21.999999999999744, -132.10000000000036, 64.40000000000003, 20.000000000000014, -13.599999999999783, 1.0999999999999865, -73.30000000000078, -6.399999999999908, 20.000000000000014, 22.700000000000053, 30.200000000000106, -3.099999999999958, -7.299999999999937, -5.1999999999999265, 11.599999999999964, 22.700000000000053, -89.20000000000084, -15.699999999999761, 5.299999999999965, 2.8999999999999737, 32.30000000000011, -3.7000000000000015, 7.399999999999965, -78.70000000000087, -26.199999999999754, 20.000000000000014, -11.499999999999819, 9.499999999999964, -2.799999999999972, 29.900000000000173, 7.399999999999965, 18.200000000000006, 8.900000000000004, -12.999999999999813, 13.699999999999964, -49.299999999999905, 20.000000000000014, 3.1999999999999615, -3.1000000000000294, 31.700000000000212, -16.899999999999743, 22.100000000000062, -16.29999999999977, -17.79999999999974, 3.1999999999999615, -5.19999999999993, 9.499999999999964, -4.89999999999997, 10.099999999999953, 1.0999999999999865, 20.000000000000014, -24.99999999999976, 20.000000000000014, -39.99999999999984, -24.099999999999746, 13.99999999999997, -0.09999999999988213, 49.70000000000009, -7.299999999999933, 23.600000000000083, 20.90000000000003, 0.7999999999999723, 20.000000000000014, -15.099999999999792, 7.399999999999965, 18.800000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.499999999999986, -105.40000000000055, -32.49999999999975, 51.50000000000019, 38.90000000000009, 17.59999999999999, 19.700000000000006, -3.099999999999958, -17.79999999999974, 15.799999999999963, 7.399999999999965, -36.699999999999754, 7.3999999999999755, 5.2999999999999785, 22.40000000000006, -24.099999999999994, 14.599999999999968, -14.799999999999764, -5.1999999999999265, -12.399999999999816, -7.299999999999891, 17.299999999999976, 59.300000000000175, 58.100000000000094, 20.000000000000014, -1.0000000000000373, -9.399999999999855, -24.099999999999966, 2.2999999999999803, -85.00000000000053, 73.09999999999975, 5.299999999999965, -3.100000000000024, -57.700000000000436, -57.70000000000028, 4.399999999999996, 5.299999999999965, 20.000000000000014, -13.599999999999786, -53.50000000000016, 5.299999999999973, -33.69999999999977, 7.399999999999965, 20.000000000000014, 133.39999999999975, -99.70000000000081, 13.099999999999971, -19.899999999999743, 20.000000000000014, -26.199999999999747, -55.5999999999998, -52.89999999999989, -17.800000000000033, -101.80000000000081, -36.699999999999754, -13.599999999999843, 4.0999999999999615, 80.30000000000004, -38.79999999999976, 15.799999999999963, -15.699999999999747, 29.000000000000114, -7.900000000000039, 14.900000000000045, -7.29999999999993, -9.400000000000004, -0.7000000000000308, -15.699999999999747, 61.09999999999999, 38.60000000000017, 28.09999999999998, 20.600000000000026, 41.300000000000125, -36.699999999999996, 38.89999999999998, 3.1999999999999615, -11.499999999999819, 55.1000000000001, 69.19999999999979, -38.799999999999756, -5.1999999999999265, 15.799999999999963], "policy_predator_policy_reward": [36.0, 13.0, 22.0, 22.0, 9.0, 15.0, 21.0, 66.0, 20.0, 3.0, 43.0, 33.0, 54.0, 53.0, 19.0, 9.0, 2.0, 17.0, 3.0, 32.0, 25.0, 59.0, 3.0, 2.0, 0.0, 8.0, 57.0, 95.0, 1.0, 9.0, 6.0, 8.0, 4.0, 16.0, 12.0, 4.0, 24.0, 17.0, 2.0, 23.0, 46.0, 52.0, 38.0, 30.0, 31.0, 15.0, 7.0, 13.0, 55.0, 74.0, 87.0, 9.0, 16.0, 8.0, 57.0, 51.0, 7.0, 12.0, 31.0, 18.0, 13.0, 11.0, 12.0, 4.0, 19.0, 50.0, 11.0, 15.0, 4.0, 33.0, 6.0, 22.0, 42.0, 12.0, 15.0, 10.0, 5.0, 13.0, 6.0, 3.0, 19.0, 38.0, 4.0, 19.0, 33.0, 26.0, 9.0, 13.0, 8.0, 14.0, 22.0, 22.0, 12.0, 18.0, 12.0, 5.0, 26.0, 1.0, 9.0, 0.0, 24.0, 5.0, 22.0, 50.0, 8.0, 13.0, 13.0, 2.0, 8.0, 15.0, 13.0, 5.0, 11.0, 24.0, 0.0, 1.0, 0.0, 0.0, 63.0, 63.0, 24.0, 10.0, 3.0, 2.0, 1.0, 11.0, 17.0, 18.0, 25.0, 25.0, 11.0, 4.0, 13.0, 9.0, 17.0, 4.0, 15.0, 22.0, 11.0, 13.0, 20.0, 7.0, 0.0, 10.0, 35.0, 14.0, 28.0, 25.0, 7.0, 5.0, 37.0, 11.0, 20.0, 42.0, 7.0, 0.0, 16.0, 35.0, 28.0, 29.0, 0.0, 6.0, 40.0, 36.0, 9.0, 22.0, 22.0, 21.0, 3.0, 56.0, 22.0, 53.0, 29.0, 24.0, 8.0, 5.0, 2.0, 28.0, 17.0, 7.0, 23.0, 1.0, 10.0, 19.0, 36.0, 29.0, 1.0, 16.0, 1.0, 9.0, 27.0, 1.0, 10.0, 4.0, 15.0, 15.0, 24.0, 8.0, 2.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7114126400427156, "mean_inference_ms": 1.8431038460160414, "mean_action_processing_ms": 0.3013467682716224, "mean_env_wait_ms": 0.231562241985563, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005203723907470703, "StateBufferConnector_ms": 0.0055522918701171875, "ViewRequirementAgentConnector_ms": 0.0894244909286499}, "num_episodes": 22, "episode_return_max": 144.39999999999927, "episode_return_min": -50.90000000000084, "episode_return_mean": 30.480000000000064, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.43975929150093, "num_env_steps_trained_throughput_per_sec": 324.43975929150093, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 11516.831, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11516.786, "sample_time_ms": 1192.404, "learn_time_ms": 10308.608, "learn_throughput": 388.025, "synch_weights_time_ms": 14.018}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-55-00", "timestamp": 1723647300, "time_this_iter_s": 12.365179777145386, "time_total_s": 469.3079481124878, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32eddbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 469.3079481124878, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 53.06666666666667, "ram_util_percent": 83.52222222222221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4351453451252487, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.055179807118007, "policy_loss": -0.003696529349193923, "vf_loss": 8.058186224276426, "vf_explained_var": 0.10665612082002024, "kl": 0.00817928826846925, "entropy": 1.3776080916798303, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8778764878946637, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0710648404227365, "policy_loss": -0.012501158817823996, "vf_loss": 4.082656897186602, "vf_explained_var": 0.00505778433153869, "kl": 0.012121230438795406, "entropy": 1.0013769161133539, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 147.09999999999968, "episode_reward_min": -421.19999999999965, "episode_reward_mean": 23.67400000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.29999999999984, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.39999999999975, "predator_policy": 230.0}, "policy_reward_mean": {"prey_policy": -10.272999999999998, "predator_policy": 22.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.900000000000004, -36.79999999999957, 28.300000000000022, 30.40000000000016, 35.80000000000023, 32.60000000000019, 101.89999999999911, 13.599999999999921, 22.40000000000001, 2.50000000000013, 15.599999999999962, 72.19999999999969, 31.700000000000173, -50.90000000000084, 33.50000000000021, 24.700000000000074, 46.30000000000036, 84.09999999999953, 23.70000000000006, 29.70000000000016, 22.100000000000012, 36.80000000000026, 49.800000000000374, 15.400000000000006, 21.299999999999994, 32.200000000000195, 30.100000000000147, 24.00000000000005, 7.899999999999951, 34.9000000000001, 57.4000000000002, 67.50000000000017, 38.80000000000028, 27.30000000000012, 39.80000000000028, 40.0000000000003, 39.10000000000023, 53.00000000000039, 61.50000000000021, 28.600000000000126, 33.0000000000002, 20.699999999999985, 27.700000000000102, 20.300000000000143, 20.799999999999986, 19.399999999999963, 34.00000000000021, 144.39999999999927, 29.000000000000284, 15.500000000000068, -29.699999999999648, 90.39999999999903, -12.799999999999622, 8.699999999999942, 32.30000000000018, -16.099999999999504, 28.60000000000013, 33.400000000000205, 109.69999999999938, 24.200000000000077, 36.80000000000025, -49.49999999999988, -44.59999999999956, 2.6999999999999504, 97.3999999999998, 7.000000000000107, 37.30000000000026, 31.0000000000001, 12.299999999999967, 48.60000000000027, 116.69999999999987, 58.70000000000015, 32.60000000000024, 56.10000000000004, 73.5999999999996, 62.400000000000354, 24.600000000000048, -38.599999999999675, -43.09999999999972, -34.09999999999995, -166.79999999999978, 86.6999999999995, -421.19999999999965, -247.9000000000002, 127.59999999999928, 56.60000000000037, 18.40000000000033, -101.80000000000058, 52.20000000000038, 137.99999999999994, -16.29999999999975, 28.500000000000156, 34.90000000000011, 80.10000000000005, 12.500000000000016, 110.59999999999982, 147.09999999999968, -8.899999999999947, 59.70000000000016, -28.69999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, -7.299999999999891, -143.8000000000007, -21.999999999999744, -132.10000000000036, 64.40000000000003, 20.000000000000014, -13.599999999999783, 1.0999999999999865, -73.30000000000078, -6.399999999999908, 20.000000000000014, 22.700000000000053, 30.200000000000106, -3.099999999999958, -7.299999999999937, -5.1999999999999265, 11.599999999999964, 22.700000000000053, -89.20000000000084, -15.699999999999761, 5.299999999999965, 2.8999999999999737, 32.30000000000011, -3.7000000000000015, 7.399999999999965, -78.70000000000087, -26.199999999999754, 20.000000000000014, -11.499999999999819, 9.499999999999964, -2.799999999999972, 29.900000000000173, 7.399999999999965, 18.200000000000006, 8.900000000000004, -12.999999999999813, 13.699999999999964, -49.299999999999905, 20.000000000000014, 3.1999999999999615, -3.1000000000000294, 31.700000000000212, -16.899999999999743, 22.100000000000062, -16.29999999999977, -17.79999999999974, 3.1999999999999615, -5.19999999999993, 9.499999999999964, -4.89999999999997, 10.099999999999953, 1.0999999999999865, 20.000000000000014, -24.99999999999976, 20.000000000000014, -39.99999999999984, -24.099999999999746, 13.99999999999997, -0.09999999999988213, 49.70000000000009, -7.299999999999933, 23.600000000000083, 20.90000000000003, 0.7999999999999723, 20.000000000000014, -15.099999999999792, 7.399999999999965, 18.800000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.499999999999986, -105.40000000000055, -32.49999999999975, 51.50000000000019, 38.90000000000009, 17.59999999999999, 19.700000000000006, -3.099999999999958, -17.79999999999974, 15.799999999999963, 7.399999999999965, -36.699999999999754, 7.3999999999999755, 5.2999999999999785, 22.40000000000006, -24.099999999999994, 14.599999999999968, -14.799999999999764, -5.1999999999999265, -12.399999999999816, -7.299999999999891, 17.299999999999976, 59.300000000000175, 58.100000000000094, 20.000000000000014, -1.0000000000000373, -9.399999999999855, -24.099999999999966, 2.2999999999999803, -85.00000000000053, 73.09999999999975, 5.299999999999965, -3.100000000000024, -57.700000000000436, -57.70000000000028, 4.399999999999996, 5.299999999999965, 20.000000000000014, -13.599999999999786, -53.50000000000016, 5.299999999999973, -33.69999999999977, 7.399999999999965, 20.000000000000014, 133.39999999999975, -99.70000000000081, 13.099999999999971, -19.899999999999743, 20.000000000000014, -26.199999999999747, -55.5999999999998, -52.89999999999989, -17.800000000000033, -101.80000000000081, -36.699999999999754, -13.599999999999843, 4.0999999999999615, 80.30000000000004, -38.79999999999976, 15.799999999999963, -15.699999999999747, 29.000000000000114, -7.900000000000039, 14.900000000000045, -7.29999999999993, -9.400000000000004, -0.7000000000000308, -15.699999999999747, 61.09999999999999, 38.60000000000017, 28.09999999999998, 20.600000000000026, 41.300000000000125, -36.699999999999996, 38.89999999999998, 3.1999999999999615, -11.499999999999819, 55.1000000000001, 69.19999999999979, -38.799999999999756, -5.1999999999999265, 15.799999999999963, -38.79999999999998, -44.799999999999955, -13.300000000000084, -101.79999999999994, -201.80000000000013, 43.70000000000005, -167.8999999999999, -274.9, 56.00000000000012, -28.29999999999987, -324.89999999999975, -336.29999999999984, -209.39999999999995, -174.50000000000009, 64.10000000000008, 9.499999999999961, -57.10000000000033, 40.70000000000016, -19.89999999999992, -15.700000000000008, -131.2000000000007, -76.60000000000002, 75.8, -76.60000000000086, 51.50000000000011, 48.500000000000036, -11.499999999999996, -38.79999999999989, -15.999999999999803, 9.499999999999964, 50.30000000000012, -72.4000000000002, 9.499999999999947, 20.599999999999966, 11.599999999999964, -24.099999999999753, 20.000000000000014, 74.60000000000002, 4.700000000000122, 97.39999999999998, 44.00000000000023, -124.90000000000074, -9.400000000000059, 46.100000000000044, -30.399999999999956, -28.30000000000003], "policy_predator_policy_reward": [7.0, 13.0, 55.0, 74.0, 87.0, 9.0, 16.0, 8.0, 57.0, 51.0, 7.0, 12.0, 31.0, 18.0, 13.0, 11.0, 12.0, 4.0, 19.0, 50.0, 11.0, 15.0, 4.0, 33.0, 6.0, 22.0, 42.0, 12.0, 15.0, 10.0, 5.0, 13.0, 6.0, 3.0, 19.0, 38.0, 4.0, 19.0, 33.0, 26.0, 9.0, 13.0, 8.0, 14.0, 22.0, 22.0, 12.0, 18.0, 12.0, 5.0, 26.0, 1.0, 9.0, 0.0, 24.0, 5.0, 22.0, 50.0, 8.0, 13.0, 13.0, 2.0, 8.0, 15.0, 13.0, 5.0, 11.0, 24.0, 0.0, 1.0, 0.0, 0.0, 63.0, 63.0, 24.0, 10.0, 3.0, 2.0, 1.0, 11.0, 17.0, 18.0, 25.0, 25.0, 11.0, 4.0, 13.0, 9.0, 17.0, 4.0, 15.0, 22.0, 11.0, 13.0, 20.0, 7.0, 0.0, 10.0, 35.0, 14.0, 28.0, 25.0, 7.0, 5.0, 37.0, 11.0, 20.0, 42.0, 7.0, 0.0, 16.0, 35.0, 28.0, 29.0, 0.0, 6.0, 40.0, 36.0, 9.0, 22.0, 22.0, 21.0, 3.0, 56.0, 22.0, 53.0, 29.0, 24.0, 8.0, 5.0, 2.0, 28.0, 17.0, 7.0, 23.0, 1.0, 10.0, 19.0, 36.0, 29.0, 1.0, 16.0, 1.0, 9.0, 27.0, 1.0, 10.0, 4.0, 15.0, 15.0, 24.0, 8.0, 2.0, 12.0, 6.0, 39.0, 65.0, 7.0, 8.0, 116.0, 181.0, 95.0, 17.0, 42.0, 10.0, 230.0, 118.0, 18.0, 28.0, 26.0, 36.0, 37.0, 20.0, 34.0, 35.0, 71.0, 46.0, 7.0, 7.0, 31.0, 15.0, 19.0, 16.0, 19.0, 44.0, 13.0, 2.0, 48.0, 21.0, 4.0, 10.0, 6.0, 9.0, 36.0, 8.0, 64.0, 15.0, 8.0, 3.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7085792942698874, "mean_inference_ms": 1.8347780404299496, "mean_action_processing_ms": 0.3019001976005454, "mean_env_wait_ms": 0.23102155539343097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005850434303283691, "StateBufferConnector_ms": 0.0030707120895385742, "ViewRequirementAgentConnector_ms": 0.09557926654815674}, "num_episodes": 23, "episode_return_max": 147.09999999999968, "episode_return_min": -421.19999999999965, "episode_return_mean": 23.67400000000006, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.6964823036503, "num_env_steps_trained_throughput_per_sec": 305.6964823036503, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 11689.636, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11689.59, "sample_time_ms": 1223.275, "learn_time_ms": 10449.496, "learn_throughput": 382.794, "synch_weights_time_ms": 14.739}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-55-13", "timestamp": 1723647313, "time_this_iter_s": 13.140517950057983, "time_total_s": 482.4484660625458, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee0d5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 482.4484660625458, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 60.46666666666666, "ram_util_percent": 83.41666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8981446048885426, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.934440794192925, "policy_loss": -0.006981383626984935, "vf_loss": 8.939699368754392, "vf_explained_var": 0.13519099629114545, "kl": 0.020418513313249308, "entropy": 1.4564572672364573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.394258593976813, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.957580317643584, "policy_loss": -0.011472745357751453, "vf_loss": 6.968207706723894, "vf_explained_var": -0.0010943017624042652, "kl": 0.011271779520726898, "entropy": 0.9649478620637661, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 166.39999999999947, "episode_reward_min": -421.19999999999965, "episode_reward_mean": 6.415000000000046, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -696.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.39999999999975, "predator_policy": 475.0}, "policy_reward_mean": {"prey_policy": -37.6025, "predator_policy": 40.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.70000000000006, 29.70000000000016, 22.100000000000012, 36.80000000000026, 49.800000000000374, 15.400000000000006, 21.299999999999994, 32.200000000000195, 30.100000000000147, 24.00000000000005, 7.899999999999951, 34.9000000000001, 57.4000000000002, 67.50000000000017, 38.80000000000028, 27.30000000000012, 39.80000000000028, 40.0000000000003, 39.10000000000023, 53.00000000000039, 61.50000000000021, 28.600000000000126, 33.0000000000002, 20.699999999999985, 27.700000000000102, 20.300000000000143, 20.799999999999986, 19.399999999999963, 34.00000000000021, 144.39999999999927, 29.000000000000284, 15.500000000000068, -29.699999999999648, 90.39999999999903, -12.799999999999622, 8.699999999999942, 32.30000000000018, -16.099999999999504, 28.60000000000013, 33.400000000000205, 109.69999999999938, 24.200000000000077, 36.80000000000025, -49.49999999999988, -44.59999999999956, 2.6999999999999504, 97.3999999999998, 7.000000000000107, 37.30000000000026, 31.0000000000001, 12.299999999999967, 48.60000000000027, 116.69999999999987, 58.70000000000015, 32.60000000000024, 56.10000000000004, 73.5999999999996, 62.400000000000354, 24.600000000000048, -38.599999999999675, -43.09999999999972, -34.09999999999995, -166.79999999999978, 86.6999999999995, -421.19999999999965, -247.9000000000002, 127.59999999999928, 56.60000000000037, 18.40000000000033, -101.80000000000058, 52.20000000000038, 137.99999999999994, -16.29999999999975, 28.500000000000156, 34.90000000000011, 80.10000000000005, 12.500000000000016, 110.59999999999982, 147.09999999999968, -8.899999999999947, 59.70000000000016, -28.69999999999991, -45.90000000000117, 41.600000000000136, -414.9, -386.5999999999983, -8.999999999999956, -178.60000000000002, -10.799999999999994, -35.999999999999815, -202.0, 10.100000000000062, 6.000000000000033, 166.39999999999947, 5.799999999999985, 31.600000000000158, -357.0, 162.79999999999896, -114.1000000000008, 108.49999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-12.999999999999813, 13.699999999999964, -49.299999999999905, 20.000000000000014, 3.1999999999999615, -3.1000000000000294, 31.700000000000212, -16.899999999999743, 22.100000000000062, -16.29999999999977, -17.79999999999974, 3.1999999999999615, -5.19999999999993, 9.499999999999964, -4.89999999999997, 10.099999999999953, 1.0999999999999865, 20.000000000000014, -24.99999999999976, 20.000000000000014, -39.99999999999984, -24.099999999999746, 13.99999999999997, -0.09999999999988213, 49.70000000000009, -7.299999999999933, 23.600000000000083, 20.90000000000003, 0.7999999999999723, 20.000000000000014, -15.099999999999792, 7.399999999999965, 18.800000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.499999999999986, -105.40000000000055, -32.49999999999975, 51.50000000000019, 38.90000000000009, 17.59999999999999, 19.700000000000006, -3.099999999999958, -17.79999999999974, 15.799999999999963, 7.399999999999965, -36.699999999999754, 7.3999999999999755, 5.2999999999999785, 22.40000000000006, -24.099999999999994, 14.599999999999968, -14.799999999999764, -5.1999999999999265, -12.399999999999816, -7.299999999999891, 17.299999999999976, 59.300000000000175, 58.100000000000094, 20.000000000000014, -1.0000000000000373, -9.399999999999855, -24.099999999999966, 2.2999999999999803, -85.00000000000053, 73.09999999999975, 5.299999999999965, -3.100000000000024, -57.700000000000436, -57.70000000000028, 4.399999999999996, 5.299999999999965, 20.000000000000014, -13.599999999999786, -53.50000000000016, 5.299999999999973, -33.69999999999977, 7.399999999999965, 20.000000000000014, 133.39999999999975, -99.70000000000081, 13.099999999999971, -19.899999999999743, 20.000000000000014, -26.199999999999747, -55.5999999999998, -52.89999999999989, -17.800000000000033, -101.80000000000081, -36.699999999999754, -13.599999999999843, 4.0999999999999615, 80.30000000000004, -38.79999999999976, 15.799999999999963, -15.699999999999747, 29.000000000000114, -7.900000000000039, 14.900000000000045, -7.29999999999993, -9.400000000000004, -0.7000000000000308, -15.699999999999747, 61.09999999999999, 38.60000000000017, 28.09999999999998, 20.600000000000026, 41.300000000000125, -36.699999999999996, 38.89999999999998, 3.1999999999999615, -11.499999999999819, 55.1000000000001, 69.19999999999979, -38.799999999999756, -5.1999999999999265, 15.799999999999963, -38.79999999999998, -44.799999999999955, -13.300000000000084, -101.79999999999994, -201.80000000000013, 43.70000000000005, -167.8999999999999, -274.9, 56.00000000000012, -28.29999999999987, -324.89999999999975, -336.29999999999984, -209.39999999999995, -174.50000000000009, 64.10000000000008, 9.499999999999961, -57.10000000000033, 40.70000000000016, -19.89999999999992, -15.700000000000008, -131.2000000000007, -76.60000000000002, 75.8, -76.60000000000086, 51.50000000000011, 48.500000000000036, -11.499999999999996, -38.79999999999989, -15.999999999999803, 9.499999999999964, 50.30000000000012, -72.4000000000002, 9.499999999999947, 20.599999999999966, 11.599999999999964, -24.099999999999753, 20.000000000000014, 74.60000000000002, 4.700000000000122, 97.39999999999998, 44.00000000000023, -124.90000000000074, -9.400000000000059, 46.100000000000044, -30.399999999999956, -28.30000000000003, -55.90000000000047, -40.000000000000476, -116.2000000000005, 69.79999999999959, -398.39999999999986, -359.5, -290.3999999999991, -328.19999999999914, -293.50000000000006, 78.5, -267.9, -292.7, -314.0, 99.1999999999999, 56.300000000000075, -259.30000000000007, -255.70000000000002, -295.29999999999995, -53.80000000000046, -237.10000000000002, -181.2, -14.79999999999994, 110.89999999999972, -8.500000000000197, 126.19999999999985, -433.40000000000003, 84.4999999999994, -358.89999999999975, -696.0, -536.0, 50.00000000000016, 81.8000000000001, -100.90000000000042, -89.2000000000003, 52.40000000000014, -302.9], "policy_predator_policy_reward": [4.0, 19.0, 33.0, 26.0, 9.0, 13.0, 8.0, 14.0, 22.0, 22.0, 12.0, 18.0, 12.0, 5.0, 26.0, 1.0, 9.0, 0.0, 24.0, 5.0, 22.0, 50.0, 8.0, 13.0, 13.0, 2.0, 8.0, 15.0, 13.0, 5.0, 11.0, 24.0, 0.0, 1.0, 0.0, 0.0, 63.0, 63.0, 24.0, 10.0, 3.0, 2.0, 1.0, 11.0, 17.0, 18.0, 25.0, 25.0, 11.0, 4.0, 13.0, 9.0, 17.0, 4.0, 15.0, 22.0, 11.0, 13.0, 20.0, 7.0, 0.0, 10.0, 35.0, 14.0, 28.0, 25.0, 7.0, 5.0, 37.0, 11.0, 20.0, 42.0, 7.0, 0.0, 16.0, 35.0, 28.0, 29.0, 0.0, 6.0, 40.0, 36.0, 9.0, 22.0, 22.0, 21.0, 3.0, 56.0, 22.0, 53.0, 29.0, 24.0, 8.0, 5.0, 2.0, 28.0, 17.0, 7.0, 23.0, 1.0, 10.0, 19.0, 36.0, 29.0, 1.0, 16.0, 1.0, 9.0, 27.0, 1.0, 10.0, 4.0, 15.0, 15.0, 24.0, 8.0, 2.0, 12.0, 6.0, 39.0, 65.0, 7.0, 8.0, 116.0, 181.0, 95.0, 17.0, 42.0, 10.0, 230.0, 118.0, 18.0, 28.0, 26.0, 36.0, 37.0, 20.0, 34.0, 35.0, 71.0, 46.0, 7.0, 7.0, 31.0, 15.0, 19.0, 16.0, 19.0, 44.0, 13.0, 2.0, 48.0, 21.0, 4.0, 10.0, 6.0, 9.0, 36.0, 8.0, 64.0, 15.0, 8.0, 3.0, 27.0, 45.0, 5.0, 0.0, 88.0, 94.0, 249.0, 171.0, 61.0, 8.0, 198.0, 189.0, 193.0, 2.0, 202.0, 120.0, 47.0, 194.0, 155.0, 141.0, 160.0, 105.0, 97.0, 41.0, 23.0, 107.0, 206.0, 110.0, 196.0, 400.0, 475.0, 17.0, 14.0, 32.0, 44.0, 156.0, 203.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7069587874672252, "mean_inference_ms": 1.8319935410593158, "mean_action_processing_ms": 0.30040382927627407, "mean_env_wait_ms": 0.23073557399159433, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007649064064025879, "StateBufferConnector_ms": 0.004453301429748535, "ViewRequirementAgentConnector_ms": 0.10026383399963379}, "num_episodes": 18, "episode_return_max": 166.39999999999947, "episode_return_min": -421.19999999999965, "episode_return_mean": 6.415000000000046, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.94126999147403, "num_env_steps_trained_throughput_per_sec": 315.94126999147403, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 11816.624, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11816.58, "sample_time_ms": 1261.915, "learn_time_ms": 10538.989, "learn_throughput": 379.543, "synch_weights_time_ms": 13.609}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-55-26", "timestamp": 1723647326, "time_this_iter_s": 12.715466976165771, "time_total_s": 495.16393303871155, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee101f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 495.16393303871155, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 53.51666666666667, "ram_util_percent": 83.41666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7501582252916204, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.356660283053364, "policy_loss": -0.006381332600198528, "vf_loss": 8.36163836913134, "vf_explained_var": 0.1391450702828705, "kl": 0.011087200821256268, "entropy": 1.4687916635836242, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3129300612305839, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.327699149096453, "policy_loss": -0.009590627511756288, "vf_loss": 6.336291865696983, "vf_explained_var": 0.0006887562060482287, "kl": 0.013305345092046263, "entropy": 0.9248652670749281, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 196.99999999999895, "episode_reward_min": -421.19999999999965, "episode_reward_mean": 1.1100000000000037, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.39999999999975, "predator_policy": 544.0}, "policy_reward_mean": {"prey_policy": -60.150000000000034, "predator_policy": 60.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.10000000000023, 53.00000000000039, 61.50000000000021, 28.600000000000126, 33.0000000000002, 20.699999999999985, 27.700000000000102, 20.300000000000143, 20.799999999999986, 19.399999999999963, 34.00000000000021, 144.39999999999927, 29.000000000000284, 15.500000000000068, -29.699999999999648, 90.39999999999903, -12.799999999999622, 8.699999999999942, 32.30000000000018, -16.099999999999504, 28.60000000000013, 33.400000000000205, 109.69999999999938, 24.200000000000077, 36.80000000000025, -49.49999999999988, -44.59999999999956, 2.6999999999999504, 97.3999999999998, 7.000000000000107, 37.30000000000026, 31.0000000000001, 12.299999999999967, 48.60000000000027, 116.69999999999987, 58.70000000000015, 32.60000000000024, 56.10000000000004, 73.5999999999996, 62.400000000000354, 24.600000000000048, -38.599999999999675, -43.09999999999972, -34.09999999999995, -166.79999999999978, 86.6999999999995, -421.19999999999965, -247.9000000000002, 127.59999999999928, 56.60000000000037, 18.40000000000033, -101.80000000000058, 52.20000000000038, 137.99999999999994, -16.29999999999975, 28.500000000000156, 34.90000000000011, 80.10000000000005, 12.500000000000016, 110.59999999999982, 147.09999999999968, -8.899999999999947, 59.70000000000016, -28.69999999999991, -45.90000000000117, 41.600000000000136, -414.9, -386.5999999999983, -8.999999999999956, -178.60000000000002, -10.799999999999994, -35.999999999999815, -202.0, 10.100000000000062, 6.000000000000033, 166.39999999999947, 5.799999999999985, 31.600000000000158, -357.0, 162.79999999999896, -114.1000000000008, 108.49999999999997, -318.2, 156.59999999999962, 68.7999999999999, 9.900000000000306, -92.29999999999993, -57.100000000000215, 196.99999999999895, -65.00000000000009, 18.50000000000015, 125.09999999999945, 60.00000000000024, -104.60000000000002, 11.900000000000048, 64.60000000000028, -2.999999999999858, -7.89999999999975, 191.69999999999897, -187.80000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [18.499999999999986, -105.40000000000055, -32.49999999999975, 51.50000000000019, 38.90000000000009, 17.59999999999999, 19.700000000000006, -3.099999999999958, -17.79999999999974, 15.799999999999963, 7.399999999999965, -36.699999999999754, 7.3999999999999755, 5.2999999999999785, 22.40000000000006, -24.099999999999994, 14.599999999999968, -14.799999999999764, -5.1999999999999265, -12.399999999999816, -7.299999999999891, 17.299999999999976, 59.300000000000175, 58.100000000000094, 20.000000000000014, -1.0000000000000373, -9.399999999999855, -24.099999999999966, 2.2999999999999803, -85.00000000000053, 73.09999999999975, 5.299999999999965, -3.100000000000024, -57.700000000000436, -57.70000000000028, 4.399999999999996, 5.299999999999965, 20.000000000000014, -13.599999999999786, -53.50000000000016, 5.299999999999973, -33.69999999999977, 7.399999999999965, 20.000000000000014, 133.39999999999975, -99.70000000000081, 13.099999999999971, -19.899999999999743, 20.000000000000014, -26.199999999999747, -55.5999999999998, -52.89999999999989, -17.800000000000033, -101.80000000000081, -36.699999999999754, -13.599999999999843, 4.0999999999999615, 80.30000000000004, -38.79999999999976, 15.799999999999963, -15.699999999999747, 29.000000000000114, -7.900000000000039, 14.900000000000045, -7.29999999999993, -9.400000000000004, -0.7000000000000308, -15.699999999999747, 61.09999999999999, 38.60000000000017, 28.09999999999998, 20.600000000000026, 41.300000000000125, -36.699999999999996, 38.89999999999998, 3.1999999999999615, -11.499999999999819, 55.1000000000001, 69.19999999999979, -38.799999999999756, -5.1999999999999265, 15.799999999999963, -38.79999999999998, -44.799999999999955, -13.300000000000084, -101.79999999999994, -201.80000000000013, 43.70000000000005, -167.8999999999999, -274.9, 56.00000000000012, -28.29999999999987, -324.89999999999975, -336.29999999999984, -209.39999999999995, -174.50000000000009, 64.10000000000008, 9.499999999999961, -57.10000000000033, 40.70000000000016, -19.89999999999992, -15.700000000000008, -131.2000000000007, -76.60000000000002, 75.8, -76.60000000000086, 51.50000000000011, 48.500000000000036, -11.499999999999996, -38.79999999999989, -15.999999999999803, 9.499999999999964, 50.30000000000012, -72.4000000000002, 9.499999999999947, 20.599999999999966, 11.599999999999964, -24.099999999999753, 20.000000000000014, 74.60000000000002, 4.700000000000122, 97.39999999999998, 44.00000000000023, -124.90000000000074, -9.400000000000059, 46.100000000000044, -30.399999999999956, -28.30000000000003, -55.90000000000047, -40.000000000000476, -116.2000000000005, 69.79999999999959, -398.39999999999986, -359.5, -290.3999999999991, -328.19999999999914, -293.50000000000006, 78.5, -267.9, -292.7, -314.0, 99.1999999999999, 56.300000000000075, -259.30000000000007, -255.70000000000002, -295.29999999999995, -53.80000000000046, -237.10000000000002, -181.2, -14.79999999999994, 110.89999999999972, -8.500000000000197, 126.19999999999985, -433.40000000000003, 84.4999999999994, -358.89999999999975, -696.0, -536.0, 50.00000000000016, 81.8000000000001, -100.90000000000042, -89.2000000000003, 52.40000000000014, -302.9, -784.0, -528.2, 17.300000000000125, 89.29999999999974, -343.09999999999997, 29.900000000000105, -276.29999999999984, 81.19999999999982, -151.4, -94.90000000000067, -451.4, 44.30000000000016, 83.8999999999998, 100.09999999999968, 72.20000000000016, -538.2, -90.10000000000062, -63.400000000000034, 74.00000000000007, 43.100000000000094, -173.7999999999999, -62.2000000000007, -106.00000000000001, -103.60000000000002, -89.80000000000055, -99.30000000000001, -144.39999999999986, 5.000000000000121, -325.3, 80.30000000000015, 13.699999999999946, -103.60000000000076, 115.39999999999964, 65.30000000000017, -377.3, -386.5], "policy_predator_policy_reward": [63.0, 63.0, 24.0, 10.0, 3.0, 2.0, 1.0, 11.0, 17.0, 18.0, 25.0, 25.0, 11.0, 4.0, 13.0, 9.0, 17.0, 4.0, 15.0, 22.0, 11.0, 13.0, 20.0, 7.0, 0.0, 10.0, 35.0, 14.0, 28.0, 25.0, 7.0, 5.0, 37.0, 11.0, 20.0, 42.0, 7.0, 0.0, 16.0, 35.0, 28.0, 29.0, 0.0, 6.0, 40.0, 36.0, 9.0, 22.0, 22.0, 21.0, 3.0, 56.0, 22.0, 53.0, 29.0, 24.0, 8.0, 5.0, 2.0, 28.0, 17.0, 7.0, 23.0, 1.0, 10.0, 19.0, 36.0, 29.0, 1.0, 16.0, 1.0, 9.0, 27.0, 1.0, 10.0, 4.0, 15.0, 15.0, 24.0, 8.0, 2.0, 12.0, 6.0, 39.0, 65.0, 7.0, 8.0, 116.0, 181.0, 95.0, 17.0, 42.0, 10.0, 230.0, 118.0, 18.0, 28.0, 26.0, 36.0, 37.0, 20.0, 34.0, 35.0, 71.0, 46.0, 7.0, 7.0, 31.0, 15.0, 19.0, 16.0, 19.0, 44.0, 13.0, 2.0, 48.0, 21.0, 4.0, 10.0, 6.0, 9.0, 36.0, 8.0, 64.0, 15.0, 8.0, 3.0, 27.0, 45.0, 5.0, 0.0, 88.0, 94.0, 249.0, 171.0, 61.0, 8.0, 198.0, 189.0, 193.0, 2.0, 202.0, 120.0, 47.0, 194.0, 155.0, 141.0, 160.0, 105.0, 97.0, 41.0, 23.0, 107.0, 206.0, 110.0, 196.0, 400.0, 475.0, 17.0, 14.0, 32.0, 44.0, 156.0, 203.0, 544.0, 450.0, 31.0, 19.0, 221.0, 161.0, 193.0, 12.0, 92.0, 62.0, 168.0, 182.0, 4.0, 9.0, 22.0, 379.0, 70.0, 102.0, 4.0, 4.0, 220.0, 76.0, 65.0, 40.0, 93.0, 108.0, 114.0, 90.0, 182.0, 60.0, 62.0, 20.0, 8.0, 3.0, 232.0, 344.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7054173424067344, "mean_inference_ms": 1.8287226964998748, "mean_action_processing_ms": 0.29972841917509224, "mean_env_wait_ms": 0.2306119184947528, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00814509391784668, "StateBufferConnector_ms": 0.0045108795166015625, "ViewRequirementAgentConnector_ms": 0.10335981845855713}, "num_episodes": 18, "episode_return_max": 196.99999999999895, "episode_return_min": -421.19999999999965, "episode_return_mean": 1.1100000000000037, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.36704878768245, "num_env_steps_trained_throughput_per_sec": 340.36704878768245, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 11858.027, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11857.982, "sample_time_ms": 1277.733, "learn_time_ms": 10564.561, "learn_throughput": 378.624, "synch_weights_time_ms": 13.571}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-55-37", "timestamp": 1723647337, "time_this_iter_s": 11.812623262405396, "time_total_s": 506.97655630111694, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee07b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 506.97655630111694, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 47.017647058823535, "ram_util_percent": 82.82941176470588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1648262616187806, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.865401106536703, "policy_loss": -0.007097310437599109, "vf_loss": 7.870729503177461, "vf_explained_var": 0.10812195022270163, "kl": 0.013976793548801011, "entropy": 1.4734957111575615, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.511637610701657, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.533768813572233, "policy_loss": -0.007265521644580143, "vf_loss": 5.5403947529969395, "vf_explained_var": -0.001477765406250323, "kl": 0.008527760130813713, "entropy": 0.9127108311842358, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 196.99999999999895, "episode_reward_min": -421.19999999999965, "episode_reward_mean": -13.645000000000046, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 147.79999999999998, "predator_policy": 605.0}, "policy_reward_mean": {"prey_policy": -87.94750000000003, "predator_policy": 81.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, -16.099999999999504, 28.60000000000013, 33.400000000000205, 109.69999999999938, 24.200000000000077, 36.80000000000025, -49.49999999999988, -44.59999999999956, 2.6999999999999504, 97.3999999999998, 7.000000000000107, 37.30000000000026, 31.0000000000001, 12.299999999999967, 48.60000000000027, 116.69999999999987, 58.70000000000015, 32.60000000000024, 56.10000000000004, 73.5999999999996, 62.400000000000354, 24.600000000000048, -38.599999999999675, -43.09999999999972, -34.09999999999995, -166.79999999999978, 86.6999999999995, -421.19999999999965, -247.9000000000002, 127.59999999999928, 56.60000000000037, 18.40000000000033, -101.80000000000058, 52.20000000000038, 137.99999999999994, -16.29999999999975, 28.500000000000156, 34.90000000000011, 80.10000000000005, 12.500000000000016, 110.59999999999982, 147.09999999999968, -8.899999999999947, 59.70000000000016, -28.69999999999991, -45.90000000000117, 41.600000000000136, -414.9, -386.5999999999983, -8.999999999999956, -178.60000000000002, -10.799999999999994, -35.999999999999815, -202.0, 10.100000000000062, 6.000000000000033, 166.39999999999947, 5.799999999999985, 31.600000000000158, -357.0, 162.79999999999896, -114.1000000000008, 108.49999999999997, -318.2, 156.59999999999962, 68.7999999999999, 9.900000000000306, -92.29999999999993, -57.100000000000215, 196.99999999999895, -65.00000000000009, 18.50000000000015, 125.09999999999945, 60.00000000000024, -104.60000000000002, 11.900000000000048, 64.60000000000028, -2.999999999999858, -7.89999999999975, 191.69999999999897, -187.80000000000004, 118.29999999999893, -49.90000000000071, -98.20000000000002, 182.09999999999997, 44.2000000000003, 128.9999999999988, -401.3, -115.9000000000016, -10.799999999999926, -125.80000000000001, -401.59999999999957, 134.49999999999966, 17.000000000000277, 16.700000000000216, -15.599999999999824, -317.4000000000003, -97.9, 120.69999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, 20.000000000000014, -13.599999999999786, -53.50000000000016, 5.299999999999973, -33.69999999999977, 7.399999999999965, 20.000000000000014, 133.39999999999975, -99.70000000000081, 13.099999999999971, -19.899999999999743, 20.000000000000014, -26.199999999999747, -55.5999999999998, -52.89999999999989, -17.800000000000033, -101.80000000000081, -36.699999999999754, -13.599999999999843, 4.0999999999999615, 80.30000000000004, -38.79999999999976, 15.799999999999963, -15.699999999999747, 29.000000000000114, -7.900000000000039, 14.900000000000045, -7.29999999999993, -9.400000000000004, -0.7000000000000308, -15.699999999999747, 61.09999999999999, 38.60000000000017, 28.09999999999998, 20.600000000000026, 41.300000000000125, -36.699999999999996, 38.89999999999998, 3.1999999999999615, -11.499999999999819, 55.1000000000001, 69.19999999999979, -38.799999999999756, -5.1999999999999265, 15.799999999999963, -38.79999999999998, -44.799999999999955, -13.300000000000084, -101.79999999999994, -201.80000000000013, 43.70000000000005, -167.8999999999999, -274.9, 56.00000000000012, -28.29999999999987, -324.89999999999975, -336.29999999999984, -209.39999999999995, -174.50000000000009, 64.10000000000008, 9.499999999999961, -57.10000000000033, 40.70000000000016, -19.89999999999992, -15.700000000000008, -131.2000000000007, -76.60000000000002, 75.8, -76.60000000000086, 51.50000000000011, 48.500000000000036, -11.499999999999996, -38.79999999999989, -15.999999999999803, 9.499999999999964, 50.30000000000012, -72.4000000000002, 9.499999999999947, 20.599999999999966, 11.599999999999964, -24.099999999999753, 20.000000000000014, 74.60000000000002, 4.700000000000122, 97.39999999999998, 44.00000000000023, -124.90000000000074, -9.400000000000059, 46.100000000000044, -30.399999999999956, -28.30000000000003, -55.90000000000047, -40.000000000000476, -116.2000000000005, 69.79999999999959, -398.39999999999986, -359.5, -290.3999999999991, -328.19999999999914, -293.50000000000006, 78.5, -267.9, -292.7, -314.0, 99.1999999999999, 56.300000000000075, -259.30000000000007, -255.70000000000002, -295.29999999999995, -53.80000000000046, -237.10000000000002, -181.2, -14.79999999999994, 110.89999999999972, -8.500000000000197, 126.19999999999985, -433.40000000000003, 84.4999999999994, -358.89999999999975, -696.0, -536.0, 50.00000000000016, 81.8000000000001, -100.90000000000042, -89.2000000000003, 52.40000000000014, -302.9, -784.0, -528.2, 17.300000000000125, 89.29999999999974, -343.09999999999997, 29.900000000000105, -276.29999999999984, 81.19999999999982, -151.4, -94.90000000000067, -451.4, 44.30000000000016, 83.8999999999998, 100.09999999999968, 72.20000000000016, -538.2, -90.10000000000062, -63.400000000000034, 74.00000000000007, 43.100000000000094, -173.7999999999999, -62.2000000000007, -106.00000000000001, -103.60000000000002, -89.80000000000055, -99.30000000000001, -144.39999999999986, 5.000000000000121, -325.3, 80.30000000000015, 13.699999999999946, -103.60000000000076, 115.39999999999964, 65.30000000000017, -377.3, -386.5, -18.70000000000001, 94.99999999999991, -75.10000000000073, -38.799999999999756, -132.70000000000005, -395.4999999999999, -649.6999999999999, 147.79999999999998, 5.299999999999965, 26.90000000000006, 106.09999999999951, 17.899999999999984, -483.4, -469.9, -80.20000000000081, -99.70000000000076, -418.8999999999997, 46.10000000000012, -515.1000000000001, -141.70000000000005, -423.7999999999996, -659.8, 55.699999999999974, 33.80000000000005, 12.800000000000132, -129.7999999999999, -11.199999999999863, -24.10000000000003, -85.90000000000069, -284.69999999999993, -427.9000000000001, -187.5, -193.20000000000002, -216.7, -84.10000000000045, 102.80000000000001], "policy_predator_policy_reward": [7.0, 0.0, 16.0, 35.0, 28.0, 29.0, 0.0, 6.0, 40.0, 36.0, 9.0, 22.0, 22.0, 21.0, 3.0, 56.0, 22.0, 53.0, 29.0, 24.0, 8.0, 5.0, 2.0, 28.0, 17.0, 7.0, 23.0, 1.0, 10.0, 19.0, 36.0, 29.0, 1.0, 16.0, 1.0, 9.0, 27.0, 1.0, 10.0, 4.0, 15.0, 15.0, 24.0, 8.0, 2.0, 12.0, 6.0, 39.0, 65.0, 7.0, 8.0, 116.0, 181.0, 95.0, 17.0, 42.0, 10.0, 230.0, 118.0, 18.0, 28.0, 26.0, 36.0, 37.0, 20.0, 34.0, 35.0, 71.0, 46.0, 7.0, 7.0, 31.0, 15.0, 19.0, 16.0, 19.0, 44.0, 13.0, 2.0, 48.0, 21.0, 4.0, 10.0, 6.0, 9.0, 36.0, 8.0, 64.0, 15.0, 8.0, 3.0, 27.0, 45.0, 5.0, 0.0, 88.0, 94.0, 249.0, 171.0, 61.0, 8.0, 198.0, 189.0, 193.0, 2.0, 202.0, 120.0, 47.0, 194.0, 155.0, 141.0, 160.0, 105.0, 97.0, 41.0, 23.0, 107.0, 206.0, 110.0, 196.0, 400.0, 475.0, 17.0, 14.0, 32.0, 44.0, 156.0, 203.0, 544.0, 450.0, 31.0, 19.0, 221.0, 161.0, 193.0, 12.0, 92.0, 62.0, 168.0, 182.0, 4.0, 9.0, 22.0, 379.0, 70.0, 102.0, 4.0, 4.0, 220.0, 76.0, 65.0, 40.0, 93.0, 108.0, 114.0, 90.0, 182.0, 60.0, 62.0, 20.0, 8.0, 3.0, 232.0, 344.0, 15.0, 27.0, 55.0, 9.0, 256.0, 174.0, 354.0, 330.0, 6.0, 6.0, 4.0, 1.0, 310.0, 242.0, 0.0, 64.0, 268.0, 94.0, 285.0, 246.0, 605.0, 77.0, 20.0, 25.0, 21.0, 113.0, 23.0, 29.0, 59.0, 296.0, 18.0, 280.0, 109.0, 203.0, 39.0, 63.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.704629886074439, "mean_inference_ms": 1.8272785198964845, "mean_action_processing_ms": 0.2995254266767516, "mean_env_wait_ms": 0.23077150824369536, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008195877075195312, "StateBufferConnector_ms": 0.004526734352111816, "ViewRequirementAgentConnector_ms": 0.1032860279083252}, "num_episodes": 18, "episode_return_max": 196.99999999999895, "episode_return_min": -421.19999999999965, "episode_return_mean": -13.645000000000046, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 337.77372793649926, "num_env_steps_trained_throughput_per_sec": 337.77372793649926, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 11899.329, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11899.283, "sample_time_ms": 1315.177, "learn_time_ms": 10568.339, "learn_throughput": 378.489, "synch_weights_time_ms": 13.617}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-55-49", "timestamp": 1723647349, "time_this_iter_s": 11.890519857406616, "time_total_s": 518.8670761585236, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee0ddc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 518.8670761585236, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 47.870588235294115, "ram_util_percent": 82.87058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.722965945295556, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.461011362075806, "policy_loss": -0.00807976097043446, "vf_loss": 7.466911873489461, "vf_explained_var": 0.14670509837922596, "kl": 0.017219014381091653, "entropy": 1.5070409062047485, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2586744083613945, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.350280881306482, "policy_loss": -0.0049860467570070075, "vf_loss": 5.354863266591672, "vf_explained_var": -0.0012284931051668036, "kl": 0.005382361443484631, "entropy": 0.8726749716297029, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 236.89999999999935, "episode_reward_min": -421.19999999999965, "episode_reward_mean": -7.171000000000143, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 147.79999999999998, "predator_policy": 605.0}, "policy_reward_mean": {"prey_policy": -112.74050000000007, "predator_policy": 109.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.600000000000048, -38.599999999999675, -43.09999999999972, -34.09999999999995, -166.79999999999978, 86.6999999999995, -421.19999999999965, -247.9000000000002, 127.59999999999928, 56.60000000000037, 18.40000000000033, -101.80000000000058, 52.20000000000038, 137.99999999999994, -16.29999999999975, 28.500000000000156, 34.90000000000011, 80.10000000000005, 12.500000000000016, 110.59999999999982, 147.09999999999968, -8.899999999999947, 59.70000000000016, -28.69999999999991, -45.90000000000117, 41.600000000000136, -414.9, -386.5999999999983, -8.999999999999956, -178.60000000000002, -10.799999999999994, -35.999999999999815, -202.0, 10.100000000000062, 6.000000000000033, 166.39999999999947, 5.799999999999985, 31.600000000000158, -357.0, 162.79999999999896, -114.1000000000008, 108.49999999999997, -318.2, 156.59999999999962, 68.7999999999999, 9.900000000000306, -92.29999999999993, -57.100000000000215, 196.99999999999895, -65.00000000000009, 18.50000000000015, 125.09999999999945, 60.00000000000024, -104.60000000000002, 11.900000000000048, 64.60000000000028, -2.999999999999858, -7.89999999999975, 191.69999999999897, -187.80000000000004, 118.29999999999893, -49.90000000000071, -98.20000000000002, 182.09999999999997, 44.2000000000003, 128.9999999999988, -401.3, -115.9000000000016, -10.799999999999926, -125.80000000000001, -401.59999999999957, 134.49999999999966, 17.000000000000277, 16.700000000000216, -15.599999999999824, -317.4000000000003, -97.9, 120.69999999999976, 145.29999999999885, 171.6999999999988, 169.6999999999991, 207.1999999999997, 70.30000000000024, -19.99999999999988, -12.799999999999585, 236.89999999999935, 23.700000000000223, 147.79999999999956, 79.9999999999998, 131.79999999999993, -5.500000000000554, 201.9999999999989, -121.40000000000057, -9.000000000000554, 133.89999999999975, 50.400000000000276, 3.5000000000000995, -208.90000000000012, 183.8999999999996, -141.90000000000074], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.1999999999999265, 15.799999999999963, -38.79999999999998, -44.799999999999955, -13.300000000000084, -101.79999999999994, -201.80000000000013, 43.70000000000005, -167.8999999999999, -274.9, 56.00000000000012, -28.29999999999987, -324.89999999999975, -336.29999999999984, -209.39999999999995, -174.50000000000009, 64.10000000000008, 9.499999999999961, -57.10000000000033, 40.70000000000016, -19.89999999999992, -15.700000000000008, -131.2000000000007, -76.60000000000002, 75.8, -76.60000000000086, 51.50000000000011, 48.500000000000036, -11.499999999999996, -38.79999999999989, -15.999999999999803, 9.499999999999964, 50.30000000000012, -72.4000000000002, 9.499999999999947, 20.599999999999966, 11.599999999999964, -24.099999999999753, 20.000000000000014, 74.60000000000002, 4.700000000000122, 97.39999999999998, 44.00000000000023, -124.90000000000074, -9.400000000000059, 46.100000000000044, -30.399999999999956, -28.30000000000003, -55.90000000000047, -40.000000000000476, -116.2000000000005, 69.79999999999959, -398.39999999999986, -359.5, -290.3999999999991, -328.19999999999914, -293.50000000000006, 78.5, -267.9, -292.7, -314.0, 99.1999999999999, 56.300000000000075, -259.30000000000007, -255.70000000000002, -295.29999999999995, -53.80000000000046, -237.10000000000002, -181.2, -14.79999999999994, 110.89999999999972, -8.500000000000197, 126.19999999999985, -433.40000000000003, 84.4999999999994, -358.89999999999975, -696.0, -536.0, 50.00000000000016, 81.8000000000001, -100.90000000000042, -89.2000000000003, 52.40000000000014, -302.9, -784.0, -528.2, 17.300000000000125, 89.29999999999974, -343.09999999999997, 29.900000000000105, -276.29999999999984, 81.19999999999982, -151.4, -94.90000000000067, -451.4, 44.30000000000016, 83.8999999999998, 100.09999999999968, 72.20000000000016, -538.2, -90.10000000000062, -63.400000000000034, 74.00000000000007, 43.100000000000094, -173.7999999999999, -62.2000000000007, -106.00000000000001, -103.60000000000002, -89.80000000000055, -99.30000000000001, -144.39999999999986, 5.000000000000121, -325.3, 80.30000000000015, 13.699999999999946, -103.60000000000076, 115.39999999999964, 65.30000000000017, -377.3, -386.5, -18.70000000000001, 94.99999999999991, -75.10000000000073, -38.799999999999756, -132.70000000000005, -395.4999999999999, -649.6999999999999, 147.79999999999998, 5.299999999999965, 26.90000000000006, 106.09999999999951, 17.899999999999984, -483.4, -469.9, -80.20000000000081, -99.70000000000076, -418.8999999999997, 46.10000000000012, -515.1000000000001, -141.70000000000005, -423.7999999999996, -659.8, 55.699999999999974, 33.80000000000005, 12.800000000000132, -129.7999999999999, -11.199999999999863, -24.10000000000003, -85.90000000000069, -284.69999999999993, -427.9000000000001, -187.5, -193.20000000000002, -216.7, -84.10000000000045, 102.80000000000001, 56.60000000000014, 79.69999999999982, 76.39999999999944, 83.29999999999967, 15.8, 137.89999999999978, 75.79999999999974, -511.6, 3.5000000000000933, 27.800000000000153, 97.99999999999997, -411.99999999999955, 9.499999999999966, -88.30000000000067, 128.60000000000002, 98.29999999999998, -474.1, 15.8, -731.3999999999999, 72.2000000000001, 7.399999999999965, -15.400000000000137, 138.79999999999967, -467.0, -698.2, -7.2999999999999154, 138.79999999999973, 51.20000000000021, -245.90000000000015, -98.5000000000006, 20.000000000000014, -696.0, 72.5, 52.40000000000016, 3.1999999999999615, 18.200000000000102, -423.8999999999994, -116.60000000000004, -505.6, -396.29999999999995, 79.10000000000014, 102.79999999999993, -150.10000000000062, -566.8], "policy_predator_policy_reward": [2.0, 12.0, 6.0, 39.0, 65.0, 7.0, 8.0, 116.0, 181.0, 95.0, 17.0, 42.0, 10.0, 230.0, 118.0, 18.0, 28.0, 26.0, 36.0, 37.0, 20.0, 34.0, 35.0, 71.0, 46.0, 7.0, 7.0, 31.0, 15.0, 19.0, 16.0, 19.0, 44.0, 13.0, 2.0, 48.0, 21.0, 4.0, 10.0, 6.0, 9.0, 36.0, 8.0, 64.0, 15.0, 8.0, 3.0, 27.0, 45.0, 5.0, 0.0, 88.0, 94.0, 249.0, 171.0, 61.0, 8.0, 198.0, 189.0, 193.0, 2.0, 202.0, 120.0, 47.0, 194.0, 155.0, 141.0, 160.0, 105.0, 97.0, 41.0, 23.0, 107.0, 206.0, 110.0, 196.0, 400.0, 475.0, 17.0, 14.0, 32.0, 44.0, 156.0, 203.0, 544.0, 450.0, 31.0, 19.0, 221.0, 161.0, 193.0, 12.0, 92.0, 62.0, 168.0, 182.0, 4.0, 9.0, 22.0, 379.0, 70.0, 102.0, 4.0, 4.0, 220.0, 76.0, 65.0, 40.0, 93.0, 108.0, 114.0, 90.0, 182.0, 60.0, 62.0, 20.0, 8.0, 3.0, 232.0, 344.0, 15.0, 27.0, 55.0, 9.0, 256.0, 174.0, 354.0, 330.0, 6.0, 6.0, 4.0, 1.0, 310.0, 242.0, 0.0, 64.0, 268.0, 94.0, 285.0, 246.0, 605.0, 77.0, 20.0, 25.0, 21.0, 113.0, 23.0, 29.0, 59.0, 296.0, 18.0, 280.0, 109.0, 203.0, 39.0, 63.0, 4.0, 5.0, 4.0, 8.0, 10.0, 6.0, 347.0, 296.0, 10.0, 29.0, 258.0, 36.0, 5.0, 61.0, 0.0, 10.0, 353.0, 129.0, 475.0, 332.0, 59.0, 29.0, 225.0, 235.0, 506.0, 194.0, 3.0, 9.0, 125.0, 98.0, 172.0, 495.0, 1.0, 8.0, 21.0, 8.0, 323.0, 221.0, 315.0, 378.0, 1.0, 1.0, 262.0, 313.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7049994751826847, "mean_inference_ms": 1.829117847258388, "mean_action_processing_ms": 0.299739210098664, "mean_env_wait_ms": 0.23143936122357853, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0065343379974365234, "StateBufferConnector_ms": 0.012209415435791016, "ViewRequirementAgentConnector_ms": 0.1031261682510376}, "num_episodes": 22, "episode_return_max": 236.89999999999935, "episode_return_min": -421.19999999999965, "episode_return_mean": -7.171000000000143, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.0554083889453, "num_env_steps_trained_throughput_per_sec": 343.0554083889453, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 11932.88, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11932.835, "sample_time_ms": 1379.823, "learn_time_ms": 10537.444, "learn_throughput": 379.599, "synch_weights_time_ms": 13.558}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-56-01", "timestamp": 1723647361, "time_this_iter_s": 11.697820901870728, "time_total_s": 530.5648970603943, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee0d8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 530.5648970603943, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 44.582352941176474, "ram_util_percent": 82.56470588235295}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.523048185261469, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.661281651794595, "policy_loss": -0.01190699634706434, "vf_loss": 5.671264273779733, "vf_explained_var": 0.3947305025247039, "kl": 0.015205010389060124, "entropy": 1.4905415173560854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4884553063168098, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0528464543125615, "policy_loss": -0.007003158504123647, "vf_loss": 2.059411835071271, "vf_explained_var": 0.009715691382292087, "kl": 0.005837070359367508, "entropy": 0.9116994935999472, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 312.2000000000006, "episode_reward_min": -414.9, "episode_reward_mean": 19.4839999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.79999999999973, "predator_policy": 605.0}, "policy_reward_mean": {"prey_policy": -101.82800000000006, "predator_policy": 111.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.69999999999991, -45.90000000000117, 41.600000000000136, -414.9, -386.5999999999983, -8.999999999999956, -178.60000000000002, -10.799999999999994, -35.999999999999815, -202.0, 10.100000000000062, 6.000000000000033, 166.39999999999947, 5.799999999999985, 31.600000000000158, -357.0, 162.79999999999896, -114.1000000000008, 108.49999999999997, -318.2, 156.59999999999962, 68.7999999999999, 9.900000000000306, -92.29999999999993, -57.100000000000215, 196.99999999999895, -65.00000000000009, 18.50000000000015, 125.09999999999945, 60.00000000000024, -104.60000000000002, 11.900000000000048, 64.60000000000028, -2.999999999999858, -7.89999999999975, 191.69999999999897, -187.80000000000004, 118.29999999999893, -49.90000000000071, -98.20000000000002, 182.09999999999997, 44.2000000000003, 128.9999999999988, -401.3, -115.9000000000016, -10.799999999999926, -125.80000000000001, -401.59999999999957, 134.49999999999966, 17.000000000000277, 16.700000000000216, -15.599999999999824, -317.4000000000003, -97.9, 120.69999999999976, 145.29999999999885, 171.6999999999988, 169.6999999999991, 207.1999999999997, 70.30000000000024, -19.99999999999988, -12.799999999999585, 236.89999999999935, 23.700000000000223, 147.79999999999956, 79.9999999999998, 131.79999999999993, -5.500000000000554, 201.9999999999989, -121.40000000000057, -9.000000000000554, 133.89999999999975, 50.400000000000276, 3.5000000000000995, -208.90000000000012, 183.8999999999996, -141.90000000000074, 143.29999999999941, 22.700000000000017, 259.40000000000003, 34.50000000000022, 101.0999999999993, 18.299999999999983, 57.60000000000024, 128.99999999999957, 312.2000000000006, 120.09999999999903, 111.49999999999916, -17.99999999999983, 133.4999999999994, 286.89999999999986, -35.0999999999997, 120.8999999999989, 61.60000000000025, 192.3999999999996, 163.89999999999995, 129.89999999999958, -83.79999999999993, 157.99999999999943, 144.3999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-30.399999999999956, -28.30000000000003, -55.90000000000047, -40.000000000000476, -116.2000000000005, 69.79999999999959, -398.39999999999986, -359.5, -290.3999999999991, -328.19999999999914, -293.50000000000006, 78.5, -267.9, -292.7, -314.0, 99.1999999999999, 56.300000000000075, -259.30000000000007, -255.70000000000002, -295.29999999999995, -53.80000000000046, -237.10000000000002, -181.2, -14.79999999999994, 110.89999999999972, -8.500000000000197, 126.19999999999985, -433.40000000000003, 84.4999999999994, -358.89999999999975, -696.0, -536.0, 50.00000000000016, 81.8000000000001, -100.90000000000042, -89.2000000000003, 52.40000000000014, -302.9, -784.0, -528.2, 17.300000000000125, 89.29999999999974, -343.09999999999997, 29.900000000000105, -276.29999999999984, 81.19999999999982, -151.4, -94.90000000000067, -451.4, 44.30000000000016, 83.8999999999998, 100.09999999999968, 72.20000000000016, -538.2, -90.10000000000062, -63.400000000000034, 74.00000000000007, 43.100000000000094, -173.7999999999999, -62.2000000000007, -106.00000000000001, -103.60000000000002, -89.80000000000055, -99.30000000000001, -144.39999999999986, 5.000000000000121, -325.3, 80.30000000000015, 13.699999999999946, -103.60000000000076, 115.39999999999964, 65.30000000000017, -377.3, -386.5, -18.70000000000001, 94.99999999999991, -75.10000000000073, -38.799999999999756, -132.70000000000005, -395.4999999999999, -649.6999999999999, 147.79999999999998, 5.299999999999965, 26.90000000000006, 106.09999999999951, 17.899999999999984, -483.4, -469.9, -80.20000000000081, -99.70000000000076, -418.8999999999997, 46.10000000000012, -515.1000000000001, -141.70000000000005, -423.7999999999996, -659.8, 55.699999999999974, 33.80000000000005, 12.800000000000132, -129.7999999999999, -11.199999999999863, -24.10000000000003, -85.90000000000069, -284.69999999999993, -427.9000000000001, -187.5, -193.20000000000002, -216.7, -84.10000000000045, 102.80000000000001, 56.60000000000014, 79.69999999999982, 76.39999999999944, 83.29999999999967, 15.8, 137.89999999999978, 75.79999999999974, -511.6, 3.5000000000000933, 27.800000000000153, 97.99999999999997, -411.99999999999955, 9.499999999999966, -88.30000000000067, 128.60000000000002, 98.29999999999998, -474.1, 15.8, -731.3999999999999, 72.2000000000001, 7.399999999999965, -15.400000000000137, 138.79999999999967, -467.0, -698.2, -7.2999999999999154, 138.79999999999973, 51.20000000000021, -245.90000000000015, -98.5000000000006, 20.000000000000014, -696.0, 72.5, 52.40000000000016, 3.1999999999999615, 18.200000000000102, -423.8999999999994, -116.60000000000004, -505.6, -396.29999999999995, 79.10000000000014, 102.79999999999993, -150.10000000000062, -566.8, 86.89999999999984, 19.4, -0.9999999999999846, 13.699999999999964, 134.89999999999984, 114.49999999999957, 17.899999999999988, 11.599999999999964, 20.000000000000014, 37.10000000000007, -156.40000000000066, 28.70000000000004, -91.30000000000075, 89.89999999999958, 152.5999999999999, -97.60000000000082, 156.79999999999973, 148.39999999999984, -24.099999999999753, 117.19999999999959, 81.79999999999976, 13.699999999999964, -456.69999999999993, 64.6999999999997, 9.499999999999964, 94.99999999999997, 119.89999999999978, 154.99999999999997, -353.099999999999, 20.000000000000014, 24.50000000000009, 82.39999999999962, 13.699999999999964, -18.099999999999994, 81.79999999999974, 41.6, 61.999999999999964, 11.899999999999894, 103.4, 3.4999999999999725, -269.5, -395.30000000000035, 151.09999999999994, -108.10000000000062, 53.60000000000009, 12.79999999999999], "policy_predator_policy_reward": [3.0, 27.0, 45.0, 5.0, 0.0, 88.0, 94.0, 249.0, 171.0, 61.0, 8.0, 198.0, 189.0, 193.0, 2.0, 202.0, 120.0, 47.0, 194.0, 155.0, 141.0, 160.0, 105.0, 97.0, 41.0, 23.0, 107.0, 206.0, 110.0, 196.0, 400.0, 475.0, 17.0, 14.0, 32.0, 44.0, 156.0, 203.0, 544.0, 450.0, 31.0, 19.0, 221.0, 161.0, 193.0, 12.0, 92.0, 62.0, 168.0, 182.0, 4.0, 9.0, 22.0, 379.0, 70.0, 102.0, 4.0, 4.0, 220.0, 76.0, 65.0, 40.0, 93.0, 108.0, 114.0, 90.0, 182.0, 60.0, 62.0, 20.0, 8.0, 3.0, 232.0, 344.0, 15.0, 27.0, 55.0, 9.0, 256.0, 174.0, 354.0, 330.0, 6.0, 6.0, 4.0, 1.0, 310.0, 242.0, 0.0, 64.0, 268.0, 94.0, 285.0, 246.0, 605.0, 77.0, 20.0, 25.0, 21.0, 113.0, 23.0, 29.0, 59.0, 296.0, 18.0, 280.0, 109.0, 203.0, 39.0, 63.0, 4.0, 5.0, 4.0, 8.0, 10.0, 6.0, 347.0, 296.0, 10.0, 29.0, 258.0, 36.0, 5.0, 61.0, 0.0, 10.0, 353.0, 129.0, 475.0, 332.0, 59.0, 29.0, 225.0, 235.0, 506.0, 194.0, 3.0, 9.0, 125.0, 98.0, 172.0, 495.0, 1.0, 8.0, 21.0, 8.0, 323.0, 221.0, 315.0, 378.0, 1.0, 1.0, 262.0, 313.0, 13.0, 24.0, 1.0, 9.0, 0.0, 10.0, 4.0, 1.0, 30.0, 14.0, 71.0, 75.0, 13.0, 46.0, 53.0, 21.0, 7.0, 0.0, 6.0, 21.0, 13.0, 3.0, 46.0, 328.0, 5.0, 24.0, 12.0, 0.0, 197.0, 101.0, 7.0, 7.0, 29.0, 37.0, 47.0, 22.0, 38.0, 52.0, 16.0, 7.0, 315.0, 266.0, 53.0, 62.0, 27.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7056706432318994, "mean_inference_ms": 1.8321187325763555, "mean_action_processing_ms": 0.29994086190395886, "mean_env_wait_ms": 0.2320515170915869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006460428237915039, "StateBufferConnector_ms": 0.012144207954406738, "ViewRequirementAgentConnector_ms": 0.11112415790557861}, "num_episodes": 23, "episode_return_max": 312.2000000000006, "episode_return_min": -414.9, "episode_return_mean": 19.4839999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.69941453477674, "num_env_steps_trained_throughput_per_sec": 339.69941453477674, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 11955.579, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11955.533, "sample_time_ms": 1440.833, "learn_time_ms": 10498.66, "learn_throughput": 381.001, "synch_weights_time_ms": 13.809}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-56-13", "timestamp": 1723647373, "time_this_iter_s": 11.802826166152954, "time_total_s": 542.3677232265472, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ed40f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 542.3677232265472, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 45.6, "ram_util_percent": 82.65294117647058}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1015228266438477, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.480949460387861, "policy_loss": -0.005678847973806557, "vf_loss": 5.4849009609727, "vf_explained_var": 0.42043602476044306, "kl": 0.013648042831638752, "entropy": 1.4850413611326267, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2313381758001116, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6958529133645315, "policy_loss": -0.010414547687667426, "vf_loss": 1.705600109869841, "vf_explained_var": 0.00888620791611848, "kl": 0.008897984754014187, "entropy": 0.9128453963017338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 339.90000000000015, "episode_reward_min": -401.59999999999957, "episode_reward_mean": 62.070999999999785, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.0, "predator_policy": 605.0}, "policy_reward_mean": {"prey_policy": -63.27450000000008, "predator_policy": 94.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [108.49999999999997, -318.2, 156.59999999999962, 68.7999999999999, 9.900000000000306, -92.29999999999993, -57.100000000000215, 196.99999999999895, -65.00000000000009, 18.50000000000015, 125.09999999999945, 60.00000000000024, -104.60000000000002, 11.900000000000048, 64.60000000000028, -2.999999999999858, -7.89999999999975, 191.69999999999897, -187.80000000000004, 118.29999999999893, -49.90000000000071, -98.20000000000002, 182.09999999999997, 44.2000000000003, 128.9999999999988, -401.3, -115.9000000000016, -10.799999999999926, -125.80000000000001, -401.59999999999957, 134.49999999999966, 17.000000000000277, 16.700000000000216, -15.599999999999824, -317.4000000000003, -97.9, 120.69999999999976, 145.29999999999885, 171.6999999999988, 169.6999999999991, 207.1999999999997, 70.30000000000024, -19.99999999999988, -12.799999999999585, 236.89999999999935, 23.700000000000223, 147.79999999999956, 79.9999999999998, 131.79999999999993, -5.500000000000554, 201.9999999999989, -121.40000000000057, -9.000000000000554, 133.89999999999975, 50.400000000000276, 3.5000000000000995, -208.90000000000012, 183.8999999999996, -141.90000000000074, 143.29999999999941, 22.700000000000017, 259.40000000000003, 34.50000000000022, 101.0999999999993, 18.299999999999983, 57.60000000000024, 128.99999999999957, 312.2000000000006, 120.09999999999903, 111.49999999999916, -17.99999999999983, 133.4999999999994, 286.89999999999986, -35.0999999999997, 120.8999999999989, 61.60000000000025, 192.3999999999996, 163.89999999999995, 129.89999999999958, -83.79999999999993, 157.99999999999943, 144.3999999999996, 231.29999999999933, 285.79999999999995, 277.00000000000034, 34.30000000000022, 103.69999999999929, 339.90000000000015, -50.70000000000007, 152.2, 98.59999999999854, 162.29999999999964, 47.200000000000394, 24.600000000000048, 259.3, 313.10000000000036, 25.600000000000065, 146.79999999999967, 315.79999999999995, 132.5999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [52.40000000000014, -302.9, -784.0, -528.2, 17.300000000000125, 89.29999999999974, -343.09999999999997, 29.900000000000105, -276.29999999999984, 81.19999999999982, -151.4, -94.90000000000067, -451.4, 44.30000000000016, 83.8999999999998, 100.09999999999968, 72.20000000000016, -538.2, -90.10000000000062, -63.400000000000034, 74.00000000000007, 43.100000000000094, -173.7999999999999, -62.2000000000007, -106.00000000000001, -103.60000000000002, -89.80000000000055, -99.30000000000001, -144.39999999999986, 5.000000000000121, -325.3, 80.30000000000015, 13.699999999999946, -103.60000000000076, 115.39999999999964, 65.30000000000017, -377.3, -386.5, -18.70000000000001, 94.99999999999991, -75.10000000000073, -38.799999999999756, -132.70000000000005, -395.4999999999999, -649.6999999999999, 147.79999999999998, 5.299999999999965, 26.90000000000006, 106.09999999999951, 17.899999999999984, -483.4, -469.9, -80.20000000000081, -99.70000000000076, -418.8999999999997, 46.10000000000012, -515.1000000000001, -141.70000000000005, -423.7999999999996, -659.8, 55.699999999999974, 33.80000000000005, 12.800000000000132, -129.7999999999999, -11.199999999999863, -24.10000000000003, -85.90000000000069, -284.69999999999993, -427.9000000000001, -187.5, -193.20000000000002, -216.7, -84.10000000000045, 102.80000000000001, 56.60000000000014, 79.69999999999982, 76.39999999999944, 83.29999999999967, 15.8, 137.89999999999978, 75.79999999999974, -511.6, 3.5000000000000933, 27.800000000000153, 97.99999999999997, -411.99999999999955, 9.499999999999966, -88.30000000000067, 128.60000000000002, 98.29999999999998, -474.1, 15.8, -731.3999999999999, 72.2000000000001, 7.399999999999965, -15.400000000000137, 138.79999999999967, -467.0, -698.2, -7.2999999999999154, 138.79999999999973, 51.20000000000021, -245.90000000000015, -98.5000000000006, 20.000000000000014, -696.0, 72.5, 52.40000000000016, 3.1999999999999615, 18.200000000000102, -423.8999999999994, -116.60000000000004, -505.6, -396.29999999999995, 79.10000000000014, 102.79999999999993, -150.10000000000062, -566.8, 86.89999999999984, 19.4, -0.9999999999999846, 13.699999999999964, 134.89999999999984, 114.49999999999957, 17.899999999999988, 11.599999999999964, 20.000000000000014, 37.10000000000007, -156.40000000000066, 28.70000000000004, -91.30000000000075, 89.89999999999958, 152.5999999999999, -97.60000000000082, 156.79999999999973, 148.39999999999984, -24.099999999999753, 117.19999999999959, 81.79999999999976, 13.699999999999964, -456.69999999999993, 64.6999999999997, 9.499999999999964, 94.99999999999997, 119.89999999999978, 154.99999999999997, -353.099999999999, 20.000000000000014, 24.50000000000009, 82.39999999999962, 13.699999999999964, -18.099999999999994, 81.79999999999974, 41.6, 61.999999999999964, 11.899999999999894, 103.4, 3.4999999999999725, -269.5, -395.30000000000035, 151.09999999999994, -108.10000000000062, 53.60000000000009, 12.79999999999999, 118.4, 74.8999999999994, 110.30000000000001, 141.49999999999997, 84.79999999999984, 162.19999999999985, 20.000000000000014, 5.299999999999965, -141.7000000000007, 151.3999999999997, 146.89999999999995, 188.0, -5.1999999999999265, -137.5000000000007, 150.2, -133.0, 82.99999999999926, 11.599999999999964, 166.4, -66.10000000000015, 0.4999999999999901, 13.699999999999964, -5.1999999999999265, 15.799999999999963, 109.1, 105.2, 151.39999999999986, 148.69999999999987, 9.499999999999964, 1.099999999999983, -13.299999999999855, 94.1, 152.29999999999995, 126.5, 84.2, 7.399999999999965], "policy_predator_policy_reward": [156.0, 203.0, 544.0, 450.0, 31.0, 19.0, 221.0, 161.0, 193.0, 12.0, 92.0, 62.0, 168.0, 182.0, 4.0, 9.0, 22.0, 379.0, 70.0, 102.0, 4.0, 4.0, 220.0, 76.0, 65.0, 40.0, 93.0, 108.0, 114.0, 90.0, 182.0, 60.0, 62.0, 20.0, 8.0, 3.0, 232.0, 344.0, 15.0, 27.0, 55.0, 9.0, 256.0, 174.0, 354.0, 330.0, 6.0, 6.0, 4.0, 1.0, 310.0, 242.0, 0.0, 64.0, 268.0, 94.0, 285.0, 246.0, 605.0, 77.0, 20.0, 25.0, 21.0, 113.0, 23.0, 29.0, 59.0, 296.0, 18.0, 280.0, 109.0, 203.0, 39.0, 63.0, 4.0, 5.0, 4.0, 8.0, 10.0, 6.0, 347.0, 296.0, 10.0, 29.0, 258.0, 36.0, 5.0, 61.0, 0.0, 10.0, 353.0, 129.0, 475.0, 332.0, 59.0, 29.0, 225.0, 235.0, 506.0, 194.0, 3.0, 9.0, 125.0, 98.0, 172.0, 495.0, 1.0, 8.0, 21.0, 8.0, 323.0, 221.0, 315.0, 378.0, 1.0, 1.0, 262.0, 313.0, 13.0, 24.0, 1.0, 9.0, 0.0, 10.0, 4.0, 1.0, 30.0, 14.0, 71.0, 75.0, 13.0, 46.0, 53.0, 21.0, 7.0, 0.0, 6.0, 21.0, 13.0, 3.0, 46.0, 328.0, 5.0, 24.0, 12.0, 0.0, 197.0, 101.0, 7.0, 7.0, 29.0, 37.0, 47.0, 22.0, 38.0, 52.0, 16.0, 7.0, 315.0, 266.0, 53.0, 62.0, 27.0, 51.0, 22.0, 16.0, 4.0, 30.0, 0.0, 30.0, 2.0, 7.0, 20.0, 74.0, 1.0, 4.0, 22.0, 70.0, 37.0, 98.0, 4.0, 0.0, 32.0, 30.0, 29.0, 4.0, 2.0, 12.0, 17.0, 28.0, 13.0, 0.0, 7.0, 8.0, 30.0, 36.0, 18.0, 19.0, 5.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7066059039705723, "mean_inference_ms": 1.8349270716375452, "mean_action_processing_ms": 0.30017691239119926, "mean_env_wait_ms": 0.23270972791874903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005617856979370117, "StateBufferConnector_ms": 0.010845661163330078, "ViewRequirementAgentConnector_ms": 0.13601291179656982}, "num_episodes": 18, "episode_return_max": 339.90000000000015, "episode_return_min": -401.59999999999957, "episode_return_mean": 62.070999999999785, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.84164965831326, "num_env_steps_trained_throughput_per_sec": 342.84164965831326, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 11990.419, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11990.373, "sample_time_ms": 1501.827, "learn_time_ms": 10472.652, "learn_throughput": 381.947, "synch_weights_time_ms": 13.628}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-56-25", "timestamp": 1723647385, "time_this_iter_s": 11.7085599899292, "time_total_s": 554.0762832164764, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee2daf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 554.0762832164764, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 45.28125, "ram_util_percent": 82.76875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.038553898769712, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.008093082589447, "policy_loss": -0.0003637718995195375, "vf_loss": 6.006475447851514, "vf_explained_var": 0.46307995227909593, "kl": 0.01565556047625237, "entropy": 1.5381137474504099, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1392112347814771, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2638593659829842, "policy_loss": -0.012301456489447485, "vf_loss": 1.275346762730331, "vf_explained_var": 0.01617214739638031, "kl": 0.010854105158059924, "entropy": 0.9316450871487774, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 364.4000000000001, "episode_reward_min": -401.59999999999957, "episode_reward_mean": 89.0819999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -731.3999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 605.0}, "policy_reward_mean": {"prey_policy": -32.80400000000007, "predator_policy": 77.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-187.80000000000004, 118.29999999999893, -49.90000000000071, -98.20000000000002, 182.09999999999997, 44.2000000000003, 128.9999999999988, -401.3, -115.9000000000016, -10.799999999999926, -125.80000000000001, -401.59999999999957, 134.49999999999966, 17.000000000000277, 16.700000000000216, -15.599999999999824, -317.4000000000003, -97.9, 120.69999999999976, 145.29999999999885, 171.6999999999988, 169.6999999999991, 207.1999999999997, 70.30000000000024, -19.99999999999988, -12.799999999999585, 236.89999999999935, 23.700000000000223, 147.79999999999956, 79.9999999999998, 131.79999999999993, -5.500000000000554, 201.9999999999989, -121.40000000000057, -9.000000000000554, 133.89999999999975, 50.400000000000276, 3.5000000000000995, -208.90000000000012, 183.8999999999996, -141.90000000000074, 143.29999999999941, 22.700000000000017, 259.40000000000003, 34.50000000000022, 101.0999999999993, 18.299999999999983, 57.60000000000024, 128.99999999999957, 312.2000000000006, 120.09999999999903, 111.49999999999916, -17.99999999999983, 133.4999999999994, 286.89999999999986, -35.0999999999997, 120.8999999999989, 61.60000000000025, 192.3999999999996, 163.89999999999995, 129.89999999999958, -83.79999999999993, 157.99999999999943, 144.3999999999996, 231.29999999999933, 285.79999999999995, 277.00000000000034, 34.30000000000022, 103.69999999999929, 339.90000000000015, -50.70000000000007, 152.2, 98.59999999999854, 162.29999999999964, 47.200000000000394, 24.600000000000048, 259.3, 313.10000000000036, 25.600000000000065, 146.79999999999967, 315.79999999999995, 132.5999999999997, 106.49999999999986, 35.0, 37.40000000000026, 296.0, 26.00000000000007, 128.0999999999997, 194.09999999999937, 249.1, 189.19999999999933, 364.4000000000001, 116.3999999999998, 230.99999999999997, 318.0000000000001, 20.800000000000015, 54.800000000000054, 139.0999999999997, 214.69999999999925, 345.0000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-377.3, -386.5, -18.70000000000001, 94.99999999999991, -75.10000000000073, -38.799999999999756, -132.70000000000005, -395.4999999999999, -649.6999999999999, 147.79999999999998, 5.299999999999965, 26.90000000000006, 106.09999999999951, 17.899999999999984, -483.4, -469.9, -80.20000000000081, -99.70000000000076, -418.8999999999997, 46.10000000000012, -515.1000000000001, -141.70000000000005, -423.7999999999996, -659.8, 55.699999999999974, 33.80000000000005, 12.800000000000132, -129.7999999999999, -11.199999999999863, -24.10000000000003, -85.90000000000069, -284.69999999999993, -427.9000000000001, -187.5, -193.20000000000002, -216.7, -84.10000000000045, 102.80000000000001, 56.60000000000014, 79.69999999999982, 76.39999999999944, 83.29999999999967, 15.8, 137.89999999999978, 75.79999999999974, -511.6, 3.5000000000000933, 27.800000000000153, 97.99999999999997, -411.99999999999955, 9.499999999999966, -88.30000000000067, 128.60000000000002, 98.29999999999998, -474.1, 15.8, -731.3999999999999, 72.2000000000001, 7.399999999999965, -15.400000000000137, 138.79999999999967, -467.0, -698.2, -7.2999999999999154, 138.79999999999973, 51.20000000000021, -245.90000000000015, -98.5000000000006, 20.000000000000014, -696.0, 72.5, 52.40000000000016, 3.1999999999999615, 18.200000000000102, -423.8999999999994, -116.60000000000004, -505.6, -396.29999999999995, 79.10000000000014, 102.79999999999993, -150.10000000000062, -566.8, 86.89999999999984, 19.4, -0.9999999999999846, 13.699999999999964, 134.89999999999984, 114.49999999999957, 17.899999999999988, 11.599999999999964, 20.000000000000014, 37.10000000000007, -156.40000000000066, 28.70000000000004, -91.30000000000075, 89.89999999999958, 152.5999999999999, -97.60000000000082, 156.79999999999973, 148.39999999999984, -24.099999999999753, 117.19999999999959, 81.79999999999976, 13.699999999999964, -456.69999999999993, 64.6999999999997, 9.499999999999964, 94.99999999999997, 119.89999999999978, 154.99999999999997, -353.099999999999, 20.000000000000014, 24.50000000000009, 82.39999999999962, 13.699999999999964, -18.099999999999994, 81.79999999999974, 41.6, 61.999999999999964, 11.899999999999894, 103.4, 3.4999999999999725, -269.5, -395.30000000000035, 151.09999999999994, -108.10000000000062, 53.60000000000009, 12.79999999999999, 118.4, 74.8999999999994, 110.30000000000001, 141.49999999999997, 84.79999999999984, 162.19999999999985, 20.000000000000014, 5.299999999999965, -141.7000000000007, 151.3999999999997, 146.89999999999995, 188.0, -5.1999999999999265, -137.5000000000007, 150.2, -133.0, 82.99999999999926, 11.599999999999964, 166.4, -66.10000000000015, 0.4999999999999901, 13.699999999999964, -5.1999999999999265, 15.799999999999963, 109.1, 105.2, 151.39999999999986, 148.69999999999987, 9.499999999999964, 1.099999999999983, -13.299999999999855, 94.1, 152.29999999999995, 126.5, 84.2, 7.399999999999965, 7.399999999999965, 40.1, -151.0, 44.0, 20.000000000000014, 7.399999999999965, 111.5, 141.50000000000003, 7.399999999999965, 11.599999999999964, 77.30000000000001, -5.1999999999999265, 195.2, -24.099999999999746, 176.0, -1.9000000000000004, -76.60000000000088, 192.79999999999995, 164.3, 181.09999999999997, -24.099999999999746, 66.50000000000001, 72.80000000000001, 93.20000000000002, 131.0, 151.99999999999994, 7.399999999999965, 7.399999999999965, 3.1999999999999615, -36.400000000000034, 103.10000000000001, 20.000000000000014, 197.29999999999998, -13.599999999999783, 196.4, 134.6], "policy_predator_policy_reward": [232.0, 344.0, 15.0, 27.0, 55.0, 9.0, 256.0, 174.0, 354.0, 330.0, 6.0, 6.0, 4.0, 1.0, 310.0, 242.0, 0.0, 64.0, 268.0, 94.0, 285.0, 246.0, 605.0, 77.0, 20.0, 25.0, 21.0, 113.0, 23.0, 29.0, 59.0, 296.0, 18.0, 280.0, 109.0, 203.0, 39.0, 63.0, 4.0, 5.0, 4.0, 8.0, 10.0, 6.0, 347.0, 296.0, 10.0, 29.0, 258.0, 36.0, 5.0, 61.0, 0.0, 10.0, 353.0, 129.0, 475.0, 332.0, 59.0, 29.0, 225.0, 235.0, 506.0, 194.0, 3.0, 9.0, 125.0, 98.0, 172.0, 495.0, 1.0, 8.0, 21.0, 8.0, 323.0, 221.0, 315.0, 378.0, 1.0, 1.0, 262.0, 313.0, 13.0, 24.0, 1.0, 9.0, 0.0, 10.0, 4.0, 1.0, 30.0, 14.0, 71.0, 75.0, 13.0, 46.0, 53.0, 21.0, 7.0, 0.0, 6.0, 21.0, 13.0, 3.0, 46.0, 328.0, 5.0, 24.0, 12.0, 0.0, 197.0, 101.0, 7.0, 7.0, 29.0, 37.0, 47.0, 22.0, 38.0, 52.0, 16.0, 7.0, 315.0, 266.0, 53.0, 62.0, 27.0, 51.0, 22.0, 16.0, 4.0, 30.0, 0.0, 30.0, 2.0, 7.0, 20.0, 74.0, 1.0, 4.0, 22.0, 70.0, 37.0, 98.0, 4.0, 0.0, 32.0, 30.0, 29.0, 4.0, 2.0, 12.0, 17.0, 28.0, 13.0, 0.0, 7.0, 8.0, 30.0, 36.0, 18.0, 19.0, 5.0, 36.0, 52.0, 7.0, 18.0, 124.0, 6.0, 4.0, 19.0, 24.0, 6.0, 1.0, 12.0, 44.0, 1.0, 22.0, 13.0, 62.0, 33.0, 40.0, 8.0, 11.0, 30.0, 44.0, 32.0, 33.0, 23.0, 12.0, 6.0, 0.0, 11.0, 77.0, 11.0, 5.0, 16.0, 15.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7089998541359124, "mean_inference_ms": 1.8404818948762514, "mean_action_processing_ms": 0.3007980551211511, "mean_env_wait_ms": 0.2336378966039591, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00564122200012207, "StateBufferConnector_ms": 0.011222243309020996, "ViewRequirementAgentConnector_ms": 0.13639485836029053}, "num_episodes": 18, "episode_return_max": 364.4000000000001, "episode_return_min": -401.59999999999957, "episode_return_mean": 89.0819999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.39446511538335, "num_env_steps_trained_throughput_per_sec": 339.39446511538335, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 12016.756, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12016.71, "sample_time_ms": 1567.371, "learn_time_ms": 10433.448, "learn_throughput": 383.382, "synch_weights_time_ms": 13.853}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-56-37", "timestamp": 1723647397, "time_this_iter_s": 11.858490943908691, "time_total_s": 565.9347741603851, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee0d8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 565.9347741603851, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 45.9470588235294, "ram_util_percent": 82.7470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4102793886863365, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.428191184997559, "policy_loss": -0.008206471541364278, "vf_loss": 7.4345470733743495, "vf_explained_var": 0.1446763205780554, "kl": 0.014621989918740688, "entropy": 1.5175909157783265, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6583730515979584, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.081607188244976, "policy_loss": -0.012631809615613844, "vf_loss": 3.093234036082313, "vf_explained_var": 0.02585869623870446, "kl": 0.013399419556908806, "entropy": 1.0216881719846573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 368.7, "episode_reward_min": -281.59999999999997, "episode_reward_mean": 130.37399999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -731.3999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 506.0}, "policy_reward_mean": {"prey_policy": 7.8919999999999435, "predator_policy": 57.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [207.1999999999997, 70.30000000000024, -19.99999999999988, -12.799999999999585, 236.89999999999935, 23.700000000000223, 147.79999999999956, 79.9999999999998, 131.79999999999993, -5.500000000000554, 201.9999999999989, -121.40000000000057, -9.000000000000554, 133.89999999999975, 50.400000000000276, 3.5000000000000995, -208.90000000000012, 183.8999999999996, -141.90000000000074, 143.29999999999941, 22.700000000000017, 259.40000000000003, 34.50000000000022, 101.0999999999993, 18.299999999999983, 57.60000000000024, 128.99999999999957, 312.2000000000006, 120.09999999999903, 111.49999999999916, -17.99999999999983, 133.4999999999994, 286.89999999999986, -35.0999999999997, 120.8999999999989, 61.60000000000025, 192.3999999999996, 163.89999999999995, 129.89999999999958, -83.79999999999993, 157.99999999999943, 144.3999999999996, 231.29999999999933, 285.79999999999995, 277.00000000000034, 34.30000000000022, 103.69999999999929, 339.90000000000015, -50.70000000000007, 152.2, 98.59999999999854, 162.29999999999964, 47.200000000000394, 24.600000000000048, 259.3, 313.10000000000036, 25.600000000000065, 146.79999999999967, 315.79999999999995, 132.5999999999997, 106.49999999999986, 35.0, 37.40000000000026, 296.0, 26.00000000000007, 128.0999999999997, 194.09999999999937, 249.1, 189.19999999999933, 364.4000000000001, 116.3999999999998, 230.99999999999997, 318.0000000000001, 20.800000000000015, 54.800000000000054, 139.0999999999997, 214.69999999999925, 345.0000000000001, 37.80000000000027, 277.6, 156.09999999999997, 106.89999999999858, 331.40000000000003, 368.7, 245.79999999999998, -281.59999999999997, 152.09999999999962, 20.900000000000013, 165.2, 32.30000000000004, 163.99999999999895, 183.3999999999997, 193.29999999999973, 191.2999999999997, 119.3999999999994, 343.1, 239.89999999999992, 194.3, 157.5, 156.79999999999953], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [75.79999999999974, -511.6, 3.5000000000000933, 27.800000000000153, 97.99999999999997, -411.99999999999955, 9.499999999999966, -88.30000000000067, 128.60000000000002, 98.29999999999998, -474.1, 15.8, -731.3999999999999, 72.2000000000001, 7.399999999999965, -15.400000000000137, 138.79999999999967, -467.0, -698.2, -7.2999999999999154, 138.79999999999973, 51.20000000000021, -245.90000000000015, -98.5000000000006, 20.000000000000014, -696.0, 72.5, 52.40000000000016, 3.1999999999999615, 18.200000000000102, -423.8999999999994, -116.60000000000004, -505.6, -396.29999999999995, 79.10000000000014, 102.79999999999993, -150.10000000000062, -566.8, 86.89999999999984, 19.4, -0.9999999999999846, 13.699999999999964, 134.89999999999984, 114.49999999999957, 17.899999999999988, 11.599999999999964, 20.000000000000014, 37.10000000000007, -156.40000000000066, 28.70000000000004, -91.30000000000075, 89.89999999999958, 152.5999999999999, -97.60000000000082, 156.79999999999973, 148.39999999999984, -24.099999999999753, 117.19999999999959, 81.79999999999976, 13.699999999999964, -456.69999999999993, 64.6999999999997, 9.499999999999964, 94.99999999999997, 119.89999999999978, 154.99999999999997, -353.099999999999, 20.000000000000014, 24.50000000000009, 82.39999999999962, 13.699999999999964, -18.099999999999994, 81.79999999999974, 41.6, 61.999999999999964, 11.899999999999894, 103.4, 3.4999999999999725, -269.5, -395.30000000000035, 151.09999999999994, -108.10000000000062, 53.60000000000009, 12.79999999999999, 118.4, 74.8999999999994, 110.30000000000001, 141.49999999999997, 84.79999999999984, 162.19999999999985, 20.000000000000014, 5.299999999999965, -141.7000000000007, 151.3999999999997, 146.89999999999995, 188.0, -5.1999999999999265, -137.5000000000007, 150.2, -133.0, 82.99999999999926, 11.599999999999964, 166.4, -66.10000000000015, 0.4999999999999901, 13.699999999999964, -5.1999999999999265, 15.799999999999963, 109.1, 105.2, 151.39999999999986, 148.69999999999987, 9.499999999999964, 1.099999999999983, -13.299999999999855, 94.1, 152.29999999999995, 126.5, 84.2, 7.399999999999965, 7.399999999999965, 40.1, -151.0, 44.0, 20.000000000000014, 7.399999999999965, 111.5, 141.50000000000003, 7.399999999999965, 11.599999999999964, 77.30000000000001, -5.1999999999999265, 195.2, -24.099999999999746, 176.0, -1.9000000000000004, -76.60000000000088, 192.79999999999995, 164.3, 181.09999999999997, -24.099999999999746, 66.50000000000001, 72.80000000000001, 93.20000000000002, 131.0, 151.99999999999994, 7.399999999999965, 7.399999999999965, 3.1999999999999615, -36.400000000000034, 103.10000000000001, 20.000000000000014, 197.29999999999998, -13.599999999999783, 196.4, 134.6, 15.799999999999962, 20.000000000000014, 47.60000000000001, 164.0, 38.900000000000006, 9.199999999999989, -7.299999999999891, 90.1999999999993, 143.3, 169.1, 151.70000000000002, 200.0, 117.20000000000002, 83.60000000000002, -145.60000000000002, -316.0, -21.99999999999975, 139.1, 10.099999999999968, -2.1999999999999713, 65.6, 20.60000000000001, -36.699999999999754, -40.0, 141.49999999999966, -51.50000000000016, 94.39999999999985, -7.0, 38.899999999999984, 124.39999999999992, -28.300000000000153, 146.59999999999974, 22.400000000000052, 35.0, 163.1, 152.0, 43.1, 129.7999999999999, 11.0, 101.29999999999998, -4.89999999999997, 43.400000000000006, 20.000000000000014, 135.79999999999998], "policy_predator_policy_reward": [347.0, 296.0, 10.0, 29.0, 258.0, 36.0, 5.0, 61.0, 0.0, 10.0, 353.0, 129.0, 475.0, 332.0, 59.0, 29.0, 225.0, 235.0, 506.0, 194.0, 3.0, 9.0, 125.0, 98.0, 172.0, 495.0, 1.0, 8.0, 21.0, 8.0, 323.0, 221.0, 315.0, 378.0, 1.0, 1.0, 262.0, 313.0, 13.0, 24.0, 1.0, 9.0, 0.0, 10.0, 4.0, 1.0, 30.0, 14.0, 71.0, 75.0, 13.0, 46.0, 53.0, 21.0, 7.0, 0.0, 6.0, 21.0, 13.0, 3.0, 46.0, 328.0, 5.0, 24.0, 12.0, 0.0, 197.0, 101.0, 7.0, 7.0, 29.0, 37.0, 47.0, 22.0, 38.0, 52.0, 16.0, 7.0, 315.0, 266.0, 53.0, 62.0, 27.0, 51.0, 22.0, 16.0, 4.0, 30.0, 0.0, 30.0, 2.0, 7.0, 20.0, 74.0, 1.0, 4.0, 22.0, 70.0, 37.0, 98.0, 4.0, 0.0, 32.0, 30.0, 29.0, 4.0, 2.0, 12.0, 17.0, 28.0, 13.0, 0.0, 7.0, 8.0, 30.0, 36.0, 18.0, 19.0, 5.0, 36.0, 52.0, 7.0, 18.0, 124.0, 6.0, 4.0, 19.0, 24.0, 6.0, 1.0, 12.0, 44.0, 1.0, 22.0, 13.0, 62.0, 33.0, 40.0, 8.0, 11.0, 30.0, 44.0, 32.0, 33.0, 23.0, 12.0, 6.0, 0.0, 11.0, 77.0, 11.0, 5.0, 16.0, 15.0, 0.0, 14.0, 2.0, 0.0, 19.0, 47.0, 72.0, 36.0, 11.0, 13.0, 10.0, 9.0, 10.0, 7.0, 28.0, 17.0, 4.0, 176.0, 11.0, 24.0, 13.0, 0.0, 74.0, 5.0, 38.0, 71.0, 41.0, 33.0, 67.0, 29.0, 21.0, 9.0, 11.0, 62.0, 8.0, 54.0, 12.0, 16.0, 29.0, 38.0, 77.0, 5.0, 46.0, 73.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7122269735243109, "mean_inference_ms": 1.8489961791632026, "mean_action_processing_ms": 0.30041080086930705, "mean_env_wait_ms": 0.23452495095105128, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006308197975158691, "StateBufferConnector_ms": 0.01127767562866211, "ViewRequirementAgentConnector_ms": 0.14342761039733887}, "num_episodes": 22, "episode_return_max": 368.7, "episode_return_min": -281.59999999999997, "episode_return_mean": 130.37399999999977, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.14365856246087, "num_env_steps_trained_throughput_per_sec": 316.14365856246087, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 12120.914, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12120.869, "sample_time_ms": 1613.808, "learn_time_ms": 10490.437, "learn_throughput": 381.3, "synch_weights_time_ms": 14.522}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-56-49", "timestamp": 1723647409, "time_this_iter_s": 12.711504220962524, "time_total_s": 578.6462783813477, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d4820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 578.6462783813477, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 54.36666666666667, "ram_util_percent": 83.03888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5931214945026175, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.103960133860351, "policy_loss": -0.008989037517162542, "vf_loss": 7.111498540292972, "vf_explained_var": -0.01910831508813081, "kl": 0.011461676137413359, "entropy": 1.48646350531351, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7499384341101167, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.348129329605708, "policy_loss": -0.013520437514251738, "vf_loss": 4.360750119648283, "vf_explained_var": 0.039321764089443066, "kl": 0.011995230665332769, "entropy": 0.9510224498768963, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -281.59999999999997, "episode_reward_mean": 141.88899999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.69999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 328.0}, "policy_reward_mean": {"prey_policy": 35.674499999999945, "predator_policy": 35.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [101.0999999999993, 18.299999999999983, 57.60000000000024, 128.99999999999957, 312.2000000000006, 120.09999999999903, 111.49999999999916, -17.99999999999983, 133.4999999999994, 286.89999999999986, -35.0999999999997, 120.8999999999989, 61.60000000000025, 192.3999999999996, 163.89999999999995, 129.89999999999958, -83.79999999999993, 157.99999999999943, 144.3999999999996, 231.29999999999933, 285.79999999999995, 277.00000000000034, 34.30000000000022, 103.69999999999929, 339.90000000000015, -50.70000000000007, 152.2, 98.59999999999854, 162.29999999999964, 47.200000000000394, 24.600000000000048, 259.3, 313.10000000000036, 25.600000000000065, 146.79999999999967, 315.79999999999995, 132.5999999999997, 106.49999999999986, 35.0, 37.40000000000026, 296.0, 26.00000000000007, 128.0999999999997, 194.09999999999937, 249.1, 189.19999999999933, 364.4000000000001, 116.3999999999998, 230.99999999999997, 318.0000000000001, 20.800000000000015, 54.800000000000054, 139.0999999999997, 214.69999999999925, 345.0000000000001, 37.80000000000027, 277.6, 156.09999999999997, 106.89999999999858, 331.40000000000003, 368.7, 245.79999999999998, -281.59999999999997, 152.09999999999962, 20.900000000000013, 165.2, 32.30000000000004, 163.99999999999895, 183.3999999999997, 193.29999999999973, 191.2999999999997, 119.3999999999994, 343.1, 239.89999999999992, 194.3, 157.5, 156.79999999999953, 396.0, 94.99999999999937, 56.400000000000006, 97.59999999999951, 44.5, 5.900000000000146, 61.60000000000015, 262.79999999999984, 262.99999999999994, 55.00000000000007, 185.0, 173.39999999999952, 343.5, 138.79999999999947, 116.59999999999988, 78.0999999999999, -37.700000000000024, 117.89999999999941, -54.0, 3.000000000000107, 58.59999999999996, -10.799999999999883, 113.09999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 37.10000000000007, -156.40000000000066, 28.70000000000004, -91.30000000000075, 89.89999999999958, 152.5999999999999, -97.60000000000082, 156.79999999999973, 148.39999999999984, -24.099999999999753, 117.19999999999959, 81.79999999999976, 13.699999999999964, -456.69999999999993, 64.6999999999997, 9.499999999999964, 94.99999999999997, 119.89999999999978, 154.99999999999997, -353.099999999999, 20.000000000000014, 24.50000000000009, 82.39999999999962, 13.699999999999964, -18.099999999999994, 81.79999999999974, 41.6, 61.999999999999964, 11.899999999999894, 103.4, 3.4999999999999725, -269.5, -395.30000000000035, 151.09999999999994, -108.10000000000062, 53.60000000000009, 12.79999999999999, 118.4, 74.8999999999994, 110.30000000000001, 141.49999999999997, 84.79999999999984, 162.19999999999985, 20.000000000000014, 5.299999999999965, -141.7000000000007, 151.3999999999997, 146.89999999999995, 188.0, -5.1999999999999265, -137.5000000000007, 150.2, -133.0, 82.99999999999926, 11.599999999999964, 166.4, -66.10000000000015, 0.4999999999999901, 13.699999999999964, -5.1999999999999265, 15.799999999999963, 109.1, 105.2, 151.39999999999986, 148.69999999999987, 9.499999999999964, 1.099999999999983, -13.299999999999855, 94.1, 152.29999999999995, 126.5, 84.2, 7.399999999999965, 7.399999999999965, 40.1, -151.0, 44.0, 20.000000000000014, 7.399999999999965, 111.5, 141.50000000000003, 7.399999999999965, 11.599999999999964, 77.30000000000001, -5.1999999999999265, 195.2, -24.099999999999746, 176.0, -1.9000000000000004, -76.60000000000088, 192.79999999999995, 164.3, 181.09999999999997, -24.099999999999746, 66.50000000000001, 72.80000000000001, 93.20000000000002, 131.0, 151.99999999999994, 7.399999999999965, 7.399999999999965, 3.1999999999999615, -36.400000000000034, 103.10000000000001, 20.000000000000014, 197.29999999999998, -13.599999999999783, 196.4, 134.6, 15.799999999999962, 20.000000000000014, 47.60000000000001, 164.0, 38.900000000000006, 9.199999999999989, -7.299999999999891, 90.1999999999993, 143.3, 169.1, 151.70000000000002, 200.0, 117.20000000000002, 83.60000000000002, -145.60000000000002, -316.0, -21.99999999999975, 139.1, 10.099999999999968, -2.1999999999999713, 65.6, 20.60000000000001, -36.699999999999754, -40.0, 141.49999999999966, -51.50000000000016, 94.39999999999985, -7.0, 38.899999999999984, 124.39999999999992, -28.300000000000153, 146.59999999999974, 22.400000000000052, 35.0, 163.1, 152.0, 43.1, 129.7999999999999, 11.0, 101.29999999999998, -4.89999999999997, 43.400000000000006, 20.000000000000014, 135.79999999999998, 191.0, 200.0, -4.899999999999999, 17.899999999999988, -62.79999999999998, -20.799999999999997, 20.0, 2.5999999999999712, 48.5, -163.0, 13.699999999999964, -38.799999999999756, 27.800000000000196, 9.800000000000011, 156.50000000000003, 50.3, 63.2, 117.80000000000001, -103.0, 20.000000000000014, 8.0, 41.0, 7.399999999999965, 140.0, 170.0, 159.5, 15.799999999999963, 59.0, 7.399999999999965, 30.20000000000003, -4.0, 7.099999999999966, 20.000000000000014, -174.69999999999996, 47.0, 17.89999999999998, -112.0, -61.0, 20.000000000000014, -163.0, -58.0, 11.599999999999964, 20.000000000000014, -197.80000000000004, -1.0, 7.099999999999996], "policy_predator_policy_reward": [30.0, 14.0, 71.0, 75.0, 13.0, 46.0, 53.0, 21.0, 7.0, 0.0, 6.0, 21.0, 13.0, 3.0, 46.0, 328.0, 5.0, 24.0, 12.0, 0.0, 197.0, 101.0, 7.0, 7.0, 29.0, 37.0, 47.0, 22.0, 38.0, 52.0, 16.0, 7.0, 315.0, 266.0, 53.0, 62.0, 27.0, 51.0, 22.0, 16.0, 4.0, 30.0, 0.0, 30.0, 2.0, 7.0, 20.0, 74.0, 1.0, 4.0, 22.0, 70.0, 37.0, 98.0, 4.0, 0.0, 32.0, 30.0, 29.0, 4.0, 2.0, 12.0, 17.0, 28.0, 13.0, 0.0, 7.0, 8.0, 30.0, 36.0, 18.0, 19.0, 5.0, 36.0, 52.0, 7.0, 18.0, 124.0, 6.0, 4.0, 19.0, 24.0, 6.0, 1.0, 12.0, 44.0, 1.0, 22.0, 13.0, 62.0, 33.0, 40.0, 8.0, 11.0, 30.0, 44.0, 32.0, 33.0, 23.0, 12.0, 6.0, 0.0, 11.0, 77.0, 11.0, 5.0, 16.0, 15.0, 0.0, 14.0, 2.0, 0.0, 19.0, 47.0, 72.0, 36.0, 11.0, 13.0, 10.0, 9.0, 10.0, 7.0, 28.0, 17.0, 4.0, 176.0, 11.0, 24.0, 13.0, 0.0, 74.0, 5.0, 38.0, 71.0, 41.0, 33.0, 67.0, 29.0, 21.0, 9.0, 11.0, 62.0, 8.0, 54.0, 12.0, 16.0, 29.0, 38.0, 77.0, 5.0, 46.0, 73.0, 0.0, 1.0, 3.0, 2.0, 68.0, 14.0, 40.0, 100.0, 59.0, 16.0, 88.0, 71.0, 3.0, 28.0, 16.0, 8.0, 46.0, 10.0, 42.0, 40.0, 84.0, 54.0, 43.0, 93.0, 16.0, 10.0, 4.0, 10.0, 47.0, 17.0, 40.0, 39.0, 26.0, 49.0, 110.0, 7.0, 34.0, 19.0, 10.0, 109.0, 119.0, 27.0, 86.0, 19.0, 43.0, 124.0, 86.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.71983624428335, "mean_inference_ms": 1.868089717487694, "mean_action_processing_ms": 0.3050978112674476, "mean_env_wait_ms": 0.23716624009820614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007982492446899414, "StateBufferConnector_ms": 0.004420280456542969, "ViewRequirementAgentConnector_ms": 0.20081138610839844}, "num_episodes": 23, "episode_return_max": 396.0, "episode_return_min": -281.59999999999997, "episode_return_mean": 141.88899999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 255.13234137396145, "num_env_steps_trained_throughput_per_sec": 255.13234137396145, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 12455.834, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12455.783, "sample_time_ms": 1904.064, "learn_time_ms": 10534.339, "learn_throughput": 379.711, "synch_weights_time_ms": 14.85}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-57-05", "timestamp": 1723647425, "time_this_iter_s": 15.743121862411499, "time_total_s": 594.3894002437592, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee2d160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 594.3894002437592, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 74.4304347826087, "ram_util_percent": 83.08260869565217}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6297863500143484, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.020915049346036, "policy_loss": -0.00842769943835539, "vf_loss": 6.027702496291468, "vf_explained_var": 0.16129341399858868, "kl": 0.012959919796036268, "entropy": 1.4801603179129343, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8285765821656221, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.00503020097339, "policy_loss": -0.010196703501173823, "vf_loss": 4.014523427322428, "vf_explained_var": 0.038348582528886344, "kl": 0.009379715583523386, "entropy": 0.928178184625333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -281.59999999999997, "episode_reward_mean": 141.84599999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -316.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 176.0}, "policy_reward_mean": {"prey_policy": 40.27799999999998, "predator_policy": 30.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [144.3999999999996, 231.29999999999933, 285.79999999999995, 277.00000000000034, 34.30000000000022, 103.69999999999929, 339.90000000000015, -50.70000000000007, 152.2, 98.59999999999854, 162.29999999999964, 47.200000000000394, 24.600000000000048, 259.3, 313.10000000000036, 25.600000000000065, 146.79999999999967, 315.79999999999995, 132.5999999999997, 106.49999999999986, 35.0, 37.40000000000026, 296.0, 26.00000000000007, 128.0999999999997, 194.09999999999937, 249.1, 189.19999999999933, 364.4000000000001, 116.3999999999998, 230.99999999999997, 318.0000000000001, 20.800000000000015, 54.800000000000054, 139.0999999999997, 214.69999999999925, 345.0000000000001, 37.80000000000027, 277.6, 156.09999999999997, 106.89999999999858, 331.40000000000003, 368.7, 245.79999999999998, -281.59999999999997, 152.09999999999962, 20.900000000000013, 165.2, 32.30000000000004, 163.99999999999895, 183.3999999999997, 193.29999999999973, 191.2999999999997, 119.3999999999994, 343.1, 239.89999999999992, 194.3, 157.5, 156.79999999999953, 396.0, 94.99999999999937, 56.400000000000006, 97.59999999999951, 44.5, 5.900000000000146, 61.60000000000015, 262.79999999999984, 262.99999999999994, 55.00000000000007, 185.0, 173.39999999999952, 343.5, 138.79999999999947, 116.59999999999988, 78.0999999999999, -37.700000000000024, 117.89999999999941, -54.0, 3.000000000000107, 58.59999999999996, -10.799999999999883, 113.09999999999994, 97.49999999999986, 200.0, 165.60000000000002, 128.19999999999973, 88.499999999999, 221.19999999999945, 194.29999999999995, 12.899999999999986, 193.0999999999994, 182.99999999999946, 30.900000000000112, 107.19999999999999, 25.900000000000084, 67.50000000000014, 30.100000000000144, 38.400000000000276, 93.59999999999997, 77.80000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [53.60000000000009, 12.79999999999999, 118.4, 74.8999999999994, 110.30000000000001, 141.49999999999997, 84.79999999999984, 162.19999999999985, 20.000000000000014, 5.299999999999965, -141.7000000000007, 151.3999999999997, 146.89999999999995, 188.0, -5.1999999999999265, -137.5000000000007, 150.2, -133.0, 82.99999999999926, 11.599999999999964, 166.4, -66.10000000000015, 0.4999999999999901, 13.699999999999964, -5.1999999999999265, 15.799999999999963, 109.1, 105.2, 151.39999999999986, 148.69999999999987, 9.499999999999964, 1.099999999999983, -13.299999999999855, 94.1, 152.29999999999995, 126.5, 84.2, 7.399999999999965, 7.399999999999965, 40.1, -151.0, 44.0, 20.000000000000014, 7.399999999999965, 111.5, 141.50000000000003, 7.399999999999965, 11.599999999999964, 77.30000000000001, -5.1999999999999265, 195.2, -24.099999999999746, 176.0, -1.9000000000000004, -76.60000000000088, 192.79999999999995, 164.3, 181.09999999999997, -24.099999999999746, 66.50000000000001, 72.80000000000001, 93.20000000000002, 131.0, 151.99999999999994, 7.399999999999965, 7.399999999999965, 3.1999999999999615, -36.400000000000034, 103.10000000000001, 20.000000000000014, 197.29999999999998, -13.599999999999783, 196.4, 134.6, 15.799999999999962, 20.000000000000014, 47.60000000000001, 164.0, 38.900000000000006, 9.199999999999989, -7.299999999999891, 90.1999999999993, 143.3, 169.1, 151.70000000000002, 200.0, 117.20000000000002, 83.60000000000002, -145.60000000000002, -316.0, -21.99999999999975, 139.1, 10.099999999999968, -2.1999999999999713, 65.6, 20.60000000000001, -36.699999999999754, -40.0, 141.49999999999966, -51.50000000000016, 94.39999999999985, -7.0, 38.899999999999984, 124.39999999999992, -28.300000000000153, 146.59999999999974, 22.400000000000052, 35.0, 163.1, 152.0, 43.1, 129.7999999999999, 11.0, 101.29999999999998, -4.89999999999997, 43.400000000000006, 20.000000000000014, 135.79999999999998, 191.0, 200.0, -4.899999999999999, 17.899999999999988, -62.79999999999998, -20.799999999999997, 20.0, 2.5999999999999712, 48.5, -163.0, 13.699999999999964, -38.799999999999756, 27.800000000000196, 9.800000000000011, 156.50000000000003, 50.3, 63.2, 117.80000000000001, -103.0, 20.000000000000014, 8.0, 41.0, 7.399999999999965, 140.0, 170.0, 159.5, 15.799999999999963, 59.0, 7.399999999999965, 30.20000000000003, -4.0, 7.099999999999966, 20.000000000000014, -174.69999999999996, 47.0, 17.89999999999998, -112.0, -61.0, 20.000000000000014, -163.0, -58.0, 11.599999999999964, 20.000000000000014, -197.80000000000004, -1.0, 7.099999999999996, -97.3, 27.80000000000001, 131.0, -13.0, 91.40000000000006, 9.200000000000017, -26.199999999999747, 100.39999999999999, 33.500000000000135, 20.000000000000014, 93.19999999999959, 97.99999999999997, 115.10000000000001, 9.200000000000003, -3.099999999999958, -15.999999999999774, 20.000000000000014, 160.1, 20.000000000000014, 125.0, 17.899999999999988, -94.0, -19.0, 18.19999999999999, 20.000000000000014, -24.099999999999746, 70.70000000000002, -86.20000000000056, 5.299999999999965, 15.799999999999963, 20.000000000000014, 7.399999999999965, 68.59999999999988, -67.0, -55.00000000000003, 39.79999999999998], "policy_predator_policy_reward": [27.0, 51.0, 22.0, 16.0, 4.0, 30.0, 0.0, 30.0, 2.0, 7.0, 20.0, 74.0, 1.0, 4.0, 22.0, 70.0, 37.0, 98.0, 4.0, 0.0, 32.0, 30.0, 29.0, 4.0, 2.0, 12.0, 17.0, 28.0, 13.0, 0.0, 7.0, 8.0, 30.0, 36.0, 18.0, 19.0, 5.0, 36.0, 52.0, 7.0, 18.0, 124.0, 6.0, 4.0, 19.0, 24.0, 6.0, 1.0, 12.0, 44.0, 1.0, 22.0, 13.0, 62.0, 33.0, 40.0, 8.0, 11.0, 30.0, 44.0, 32.0, 33.0, 23.0, 12.0, 6.0, 0.0, 11.0, 77.0, 11.0, 5.0, 16.0, 15.0, 0.0, 14.0, 2.0, 0.0, 19.0, 47.0, 72.0, 36.0, 11.0, 13.0, 10.0, 9.0, 10.0, 7.0, 28.0, 17.0, 4.0, 176.0, 11.0, 24.0, 13.0, 0.0, 74.0, 5.0, 38.0, 71.0, 41.0, 33.0, 67.0, 29.0, 21.0, 9.0, 11.0, 62.0, 8.0, 54.0, 12.0, 16.0, 29.0, 38.0, 77.0, 5.0, 46.0, 73.0, 0.0, 1.0, 3.0, 2.0, 68.0, 14.0, 40.0, 100.0, 59.0, 16.0, 88.0, 71.0, 3.0, 28.0, 16.0, 8.0, 46.0, 10.0, 42.0, 40.0, 84.0, 54.0, 43.0, 93.0, 16.0, 10.0, 4.0, 10.0, 47.0, 17.0, 40.0, 39.0, 26.0, 49.0, 110.0, 7.0, 34.0, 19.0, 10.0, 109.0, 119.0, 27.0, 86.0, 19.0, 43.0, 124.0, 86.0, 21.0, 64.0, 103.0, 16.0, 66.0, 26.0, 39.0, 28.0, 26.0, 14.0, 21.0, 1.0, 29.0, 24.0, 46.0, 21.0, 11.0, 12.0, 1.0, 17.0, 21.0, 91.0, 16.0, 69.0, 39.0, 9.0, 21.0, 32.0, 51.0, 7.0, 2.0, 6.0, 5.0, 89.0, 3.0, 39.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7265390053110989, "mean_inference_ms": 1.8853693782832601, "mean_action_processing_ms": 0.3073303425334542, "mean_env_wait_ms": 0.23917343939758828, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007588624954223633, "StateBufferConnector_ms": 0.004365444183349609, "ViewRequirementAgentConnector_ms": 0.2050929069519043}, "num_episodes": 18, "episode_return_max": 396.0, "episode_return_min": -281.59999999999997, "episode_return_mean": 141.84599999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.16525172210487, "num_env_steps_trained_throughput_per_sec": 304.16525172210487, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 12462.421, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12462.37, "sample_time_ms": 1969.354, "learn_time_ms": 10473.556, "learn_throughput": 381.914, "synch_weights_time_ms": 17.253}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-57-19", "timestamp": 1723647439, "time_this_iter_s": 13.335958003997803, "time_total_s": 607.725358247757, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d3f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 607.725358247757, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 57.9736842105263, "ram_util_percent": 83.72631578947369}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.274141665173586, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.04189874734828, "policy_loss": -0.002531902914344476, "vf_loss": 8.041764094842174, "vf_explained_var": 0.16361168058460981, "kl": 0.02106897783282122, "entropy": 1.4845526802476752, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1589974270611214, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.896638543265206, "policy_loss": -0.009185031284799888, "vf_loss": 4.905026614855206, "vf_explained_var": 0.009958682930658734, "kl": 0.010626032738863556, "entropy": 0.897764589862218, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -281.59999999999997, "episode_reward_mean": 141.10099999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -316.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 176.0}, "policy_reward_mean": {"prey_policy": 37.930499999999995, "predator_policy": 32.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [132.5999999999997, 106.49999999999986, 35.0, 37.40000000000026, 296.0, 26.00000000000007, 128.0999999999997, 194.09999999999937, 249.1, 189.19999999999933, 364.4000000000001, 116.3999999999998, 230.99999999999997, 318.0000000000001, 20.800000000000015, 54.800000000000054, 139.0999999999997, 214.69999999999925, 345.0000000000001, 37.80000000000027, 277.6, 156.09999999999997, 106.89999999999858, 331.40000000000003, 368.7, 245.79999999999998, -281.59999999999997, 152.09999999999962, 20.900000000000013, 165.2, 32.30000000000004, 163.99999999999895, 183.3999999999997, 193.29999999999973, 191.2999999999997, 119.3999999999994, 343.1, 239.89999999999992, 194.3, 157.5, 156.79999999999953, 396.0, 94.99999999999937, 56.400000000000006, 97.59999999999951, 44.5, 5.900000000000146, 61.60000000000015, 262.79999999999984, 262.99999999999994, 55.00000000000007, 185.0, 173.39999999999952, 343.5, 138.79999999999947, 116.59999999999988, 78.0999999999999, -37.700000000000024, 117.89999999999941, -54.0, 3.000000000000107, 58.59999999999996, -10.799999999999883, 113.09999999999994, 97.49999999999986, 200.0, 165.60000000000002, 128.19999999999973, 88.499999999999, 221.19999999999945, 194.29999999999995, 12.899999999999986, 193.0999999999994, 182.99999999999946, 30.900000000000112, 107.19999999999999, 25.900000000000084, 67.50000000000014, 30.100000000000144, 38.400000000000276, 93.59999999999997, 77.80000000000014, 213.7999999999995, 232.49999999999966, 198.4999999999999, 247.19999999999982, 142.69999999999908, 184.59999999999994, 120.6999999999999, 261.59999999999957, 125.09999999999997, 121.4000000000001, 273.5, 262.3999999999998, -52.3000000000005, 117.39999999999985, 160.09999999999954, 91.99999999999991, 20.400000000000162, 115.09999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [84.2, 7.399999999999965, 7.399999999999965, 40.1, -151.0, 44.0, 20.000000000000014, 7.399999999999965, 111.5, 141.50000000000003, 7.399999999999965, 11.599999999999964, 77.30000000000001, -5.1999999999999265, 195.2, -24.099999999999746, 176.0, -1.9000000000000004, -76.60000000000088, 192.79999999999995, 164.3, 181.09999999999997, -24.099999999999746, 66.50000000000001, 72.80000000000001, 93.20000000000002, 131.0, 151.99999999999994, 7.399999999999965, 7.399999999999965, 3.1999999999999615, -36.400000000000034, 103.10000000000001, 20.000000000000014, 197.29999999999998, -13.599999999999783, 196.4, 134.6, 15.799999999999962, 20.000000000000014, 47.60000000000001, 164.0, 38.900000000000006, 9.199999999999989, -7.299999999999891, 90.1999999999993, 143.3, 169.1, 151.70000000000002, 200.0, 117.20000000000002, 83.60000000000002, -145.60000000000002, -316.0, -21.99999999999975, 139.1, 10.099999999999968, -2.1999999999999713, 65.6, 20.60000000000001, -36.699999999999754, -40.0, 141.49999999999966, -51.50000000000016, 94.39999999999985, -7.0, 38.899999999999984, 124.39999999999992, -28.300000000000153, 146.59999999999974, 22.400000000000052, 35.0, 163.1, 152.0, 43.1, 129.7999999999999, 11.0, 101.29999999999998, -4.89999999999997, 43.400000000000006, 20.000000000000014, 135.79999999999998, 191.0, 200.0, -4.899999999999999, 17.899999999999988, -62.79999999999998, -20.799999999999997, 20.0, 2.5999999999999712, 48.5, -163.0, 13.699999999999964, -38.799999999999756, 27.800000000000196, 9.800000000000011, 156.50000000000003, 50.3, 63.2, 117.80000000000001, -103.0, 20.000000000000014, 8.0, 41.0, 7.399999999999965, 140.0, 170.0, 159.5, 15.799999999999963, 59.0, 7.399999999999965, 30.20000000000003, -4.0, 7.099999999999966, 20.000000000000014, -174.69999999999996, 47.0, 17.89999999999998, -112.0, -61.0, 20.000000000000014, -163.0, -58.0, 11.599999999999964, 20.000000000000014, -197.80000000000004, -1.0, 7.099999999999996, -97.3, 27.80000000000001, 131.0, -13.0, 91.40000000000006, 9.200000000000017, -26.199999999999747, 100.39999999999999, 33.500000000000135, 20.000000000000014, 93.19999999999959, 97.99999999999997, 115.10000000000001, 9.200000000000003, -3.099999999999958, -15.999999999999774, 20.000000000000014, 160.1, 20.000000000000014, 125.0, 17.899999999999988, -94.0, -19.0, 18.19999999999999, 20.000000000000014, -24.099999999999746, 70.70000000000002, -86.20000000000056, 5.299999999999965, 15.799999999999963, 20.000000000000014, 7.399999999999965, 68.59999999999988, -67.0, -55.00000000000003, 39.79999999999998, 36.79999999999998, 163.99999999999994, 199.1, -37.60000000000001, -49.0, 141.49999999999994, 29.000000000000128, 189.2, 118.10000000000008, 11.599999999999964, 83.59999999999992, 70.99999999999997, 33.19999999999996, 6.500000000000007, 94.69999999999997, 125.8999999999999, 48.80000000000001, -12.70000000000001, 1.0999999999999854, 65.30000000000007, 121.10000000000004, 127.39999999999998, 122.29999999999995, 127.09999999999981, -82.60000000000002, -141.70000000000064, -36.700000000000024, 67.10000000000002, 132.79999999999995, -15.699999999999747, 55.69999999999999, 5.299999999999965, -142.30000000000015, -7.299999999999905, -68.50000000000006, 53.60000000000001], "policy_predator_policy_reward": [5.0, 36.0, 52.0, 7.0, 18.0, 124.0, 6.0, 4.0, 19.0, 24.0, 6.0, 1.0, 12.0, 44.0, 1.0, 22.0, 13.0, 62.0, 33.0, 40.0, 8.0, 11.0, 30.0, 44.0, 32.0, 33.0, 23.0, 12.0, 6.0, 0.0, 11.0, 77.0, 11.0, 5.0, 16.0, 15.0, 0.0, 14.0, 2.0, 0.0, 19.0, 47.0, 72.0, 36.0, 11.0, 13.0, 10.0, 9.0, 10.0, 7.0, 28.0, 17.0, 4.0, 176.0, 11.0, 24.0, 13.0, 0.0, 74.0, 5.0, 38.0, 71.0, 41.0, 33.0, 67.0, 29.0, 21.0, 9.0, 11.0, 62.0, 8.0, 54.0, 12.0, 16.0, 29.0, 38.0, 77.0, 5.0, 46.0, 73.0, 0.0, 1.0, 3.0, 2.0, 68.0, 14.0, 40.0, 100.0, 59.0, 16.0, 88.0, 71.0, 3.0, 28.0, 16.0, 8.0, 46.0, 10.0, 42.0, 40.0, 84.0, 54.0, 43.0, 93.0, 16.0, 10.0, 4.0, 10.0, 47.0, 17.0, 40.0, 39.0, 26.0, 49.0, 110.0, 7.0, 34.0, 19.0, 10.0, 109.0, 119.0, 27.0, 86.0, 19.0, 43.0, 124.0, 86.0, 21.0, 64.0, 103.0, 16.0, 66.0, 26.0, 39.0, 28.0, 26.0, 14.0, 21.0, 1.0, 29.0, 24.0, 46.0, 21.0, 11.0, 12.0, 1.0, 17.0, 21.0, 91.0, 16.0, 69.0, 39.0, 9.0, 21.0, 32.0, 51.0, 7.0, 2.0, 6.0, 5.0, 89.0, 3.0, 39.0, 54.0, 6.0, 7.0, 29.0, 42.0, 37.0, 69.0, 27.0, 2.0, 9.0, 4.0, 10.0, 20.0, 63.0, 18.0, 23.0, 18.0, 42.0, 47.0, 46.0, 9.0, 3.0, 22.0, 13.0, 0.0, 93.0, 79.0, 24.0, 63.0, 26.0, 17.0, 24.0, 7.0, 70.0, 100.0, 44.0, 86.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.734242098125784, "mean_inference_ms": 1.9058343461311826, "mean_action_processing_ms": 0.31068748512849026, "mean_env_wait_ms": 0.24143805128629148, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0066683292388916016, "StateBufferConnector_ms": 0.004290342330932617, "ViewRequirementAgentConnector_ms": 0.19364464282989502}, "num_episodes": 18, "episode_return_max": 396.0, "episode_return_min": -281.59999999999997, "episode_return_mean": 141.10099999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.32932750355167, "num_env_steps_trained_throughput_per_sec": 321.32932750355167, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 12441.192, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12441.138, "sample_time_ms": 2053.287, "learn_time_ms": 10366.714, "learn_throughput": 385.85, "synch_weights_time_ms": 18.928}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-57-31", "timestamp": 1723647451, "time_this_iter_s": 12.579782962799072, "time_total_s": 620.305141210556, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee11ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 620.305141210556, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 48.81666666666667, "ram_util_percent": 83.69999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.101011991027802, "cur_kl_coeff": 0.18984375000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.728391552980614, "policy_loss": -0.006047678973141408, "vf_loss": 7.732396866783263, "vf_explained_var": 0.20670616916878515, "kl": 0.010758119791247012, "entropy": 1.4786778680861943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.102765614992727, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9874826036433064, "policy_loss": -0.007393685645773691, "vf_loss": 2.994197098855619, "vf_explained_var": 0.006274731764717708, "kl": 0.009055750669023605, "entropy": 0.8325443794172277, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -281.59999999999997, "episode_reward_mean": 139.23199999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -316.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 176.0}, "policy_reward_mean": {"prey_policy": 33.71099999999998, "predator_policy": 35.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [345.0000000000001, 37.80000000000027, 277.6, 156.09999999999997, 106.89999999999858, 331.40000000000003, 368.7, 245.79999999999998, -281.59999999999997, 152.09999999999962, 20.900000000000013, 165.2, 32.30000000000004, 163.99999999999895, 183.3999999999997, 193.29999999999973, 191.2999999999997, 119.3999999999994, 343.1, 239.89999999999992, 194.3, 157.5, 156.79999999999953, 396.0, 94.99999999999937, 56.400000000000006, 97.59999999999951, 44.5, 5.900000000000146, 61.60000000000015, 262.79999999999984, 262.99999999999994, 55.00000000000007, 185.0, 173.39999999999952, 343.5, 138.79999999999947, 116.59999999999988, 78.0999999999999, -37.700000000000024, 117.89999999999941, -54.0, 3.000000000000107, 58.59999999999996, -10.799999999999883, 113.09999999999994, 97.49999999999986, 200.0, 165.60000000000002, 128.19999999999973, 88.499999999999, 221.19999999999945, 194.29999999999995, 12.899999999999986, 193.0999999999994, 182.99999999999946, 30.900000000000112, 107.19999999999999, 25.900000000000084, 67.50000000000014, 30.100000000000144, 38.400000000000276, 93.59999999999997, 77.80000000000014, 213.7999999999995, 232.49999999999966, 198.4999999999999, 247.19999999999982, 142.69999999999908, 184.59999999999994, 120.6999999999999, 261.59999999999957, 125.09999999999997, 121.4000000000001, 273.5, 262.3999999999998, -52.3000000000005, 117.39999999999985, 160.09999999999954, 91.99999999999991, 20.400000000000162, 115.09999999999991, 138.79999999999933, -66.00000000000057, 211.59999999999965, 18.700000000000344, 175.2, 118.49999999999994, 75.59999999999994, 251.0999999999999, 247.39999999999978, 94.29999999999991, 109.59999999999984, 243.2, 70.20000000000012, 186.59999999999928, 168.1999999999998, 253.19999999999928, 253.9999999999998, 116.09999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [196.4, 134.6, 15.799999999999962, 20.000000000000014, 47.60000000000001, 164.0, 38.900000000000006, 9.199999999999989, -7.299999999999891, 90.1999999999993, 143.3, 169.1, 151.70000000000002, 200.0, 117.20000000000002, 83.60000000000002, -145.60000000000002, -316.0, -21.99999999999975, 139.1, 10.099999999999968, -2.1999999999999713, 65.6, 20.60000000000001, -36.699999999999754, -40.0, 141.49999999999966, -51.50000000000016, 94.39999999999985, -7.0, 38.899999999999984, 124.39999999999992, -28.300000000000153, 146.59999999999974, 22.400000000000052, 35.0, 163.1, 152.0, 43.1, 129.7999999999999, 11.0, 101.29999999999998, -4.89999999999997, 43.400000000000006, 20.000000000000014, 135.79999999999998, 191.0, 200.0, -4.899999999999999, 17.899999999999988, -62.79999999999998, -20.799999999999997, 20.0, 2.5999999999999712, 48.5, -163.0, 13.699999999999964, -38.799999999999756, 27.800000000000196, 9.800000000000011, 156.50000000000003, 50.3, 63.2, 117.80000000000001, -103.0, 20.000000000000014, 8.0, 41.0, 7.399999999999965, 140.0, 170.0, 159.5, 15.799999999999963, 59.0, 7.399999999999965, 30.20000000000003, -4.0, 7.099999999999966, 20.000000000000014, -174.69999999999996, 47.0, 17.89999999999998, -112.0, -61.0, 20.000000000000014, -163.0, -58.0, 11.599999999999964, 20.000000000000014, -197.80000000000004, -1.0, 7.099999999999996, -97.3, 27.80000000000001, 131.0, -13.0, 91.40000000000006, 9.200000000000017, -26.199999999999747, 100.39999999999999, 33.500000000000135, 20.000000000000014, 93.19999999999959, 97.99999999999997, 115.10000000000001, 9.200000000000003, -3.099999999999958, -15.999999999999774, 20.000000000000014, 160.1, 20.000000000000014, 125.0, 17.899999999999988, -94.0, -19.0, 18.19999999999999, 20.000000000000014, -24.099999999999746, 70.70000000000002, -86.20000000000056, 5.299999999999965, 15.799999999999963, 20.000000000000014, 7.399999999999965, 68.59999999999988, -67.0, -55.00000000000003, 39.79999999999998, 36.79999999999998, 163.99999999999994, 199.1, -37.60000000000001, -49.0, 141.49999999999994, 29.000000000000128, 189.2, 118.10000000000008, 11.599999999999964, 83.59999999999992, 70.99999999999997, 33.19999999999996, 6.500000000000007, 94.69999999999997, 125.8999999999999, 48.80000000000001, -12.70000000000001, 1.0999999999999854, 65.30000000000007, 121.10000000000004, 127.39999999999998, 122.29999999999995, 127.09999999999981, -82.60000000000002, -141.70000000000064, -36.700000000000024, 67.10000000000002, 132.79999999999995, -15.699999999999747, 55.69999999999999, 5.299999999999965, -142.30000000000015, -7.299999999999905, -68.50000000000006, 53.60000000000001, 15.799999999999963, 79.99999999999991, -63.70000000000023, -151.30000000000035, 59.6, 118.9999999999996, -48.400000000000084, 1.0999999999999865, 35.0000000000001, 72.19999999999999, -106.0, 57.50000000000009, 89.59999999999988, -232.0, 144.7999999999999, -0.7000000000001236, 41.0, 154.39999999999998, -20.500000000000036, -5.1999999999999265, -53.50000000000003, 55.10000000000013, 112.70000000000002, 42.49999999999995, 1.0999999999999865, 25.099999999999998, 30.199999999999967, 145.39999999999975, 111.49999999999977, -22.300000000000097, 130.6999999999997, 108.49999999999993, 51.19999999999992, 156.7999999999998, 151.9999999999999, -142.90000000000018], "policy_predator_policy_reward": [0.0, 14.0, 2.0, 0.0, 19.0, 47.0, 72.0, 36.0, 11.0, 13.0, 10.0, 9.0, 10.0, 7.0, 28.0, 17.0, 4.0, 176.0, 11.0, 24.0, 13.0, 0.0, 74.0, 5.0, 38.0, 71.0, 41.0, 33.0, 67.0, 29.0, 21.0, 9.0, 11.0, 62.0, 8.0, 54.0, 12.0, 16.0, 29.0, 38.0, 77.0, 5.0, 46.0, 73.0, 0.0, 1.0, 3.0, 2.0, 68.0, 14.0, 40.0, 100.0, 59.0, 16.0, 88.0, 71.0, 3.0, 28.0, 16.0, 8.0, 46.0, 10.0, 42.0, 40.0, 84.0, 54.0, 43.0, 93.0, 16.0, 10.0, 4.0, 10.0, 47.0, 17.0, 40.0, 39.0, 26.0, 49.0, 110.0, 7.0, 34.0, 19.0, 10.0, 109.0, 119.0, 27.0, 86.0, 19.0, 43.0, 124.0, 86.0, 21.0, 64.0, 103.0, 16.0, 66.0, 26.0, 39.0, 28.0, 26.0, 14.0, 21.0, 1.0, 29.0, 24.0, 46.0, 21.0, 11.0, 12.0, 1.0, 17.0, 21.0, 91.0, 16.0, 69.0, 39.0, 9.0, 21.0, 32.0, 51.0, 7.0, 2.0, 6.0, 5.0, 89.0, 3.0, 39.0, 54.0, 6.0, 7.0, 29.0, 42.0, 37.0, 69.0, 27.0, 2.0, 9.0, 4.0, 10.0, 20.0, 63.0, 18.0, 23.0, 18.0, 42.0, 47.0, 46.0, 9.0, 3.0, 22.0, 13.0, 0.0, 93.0, 79.0, 24.0, 63.0, 26.0, 17.0, 24.0, 7.0, 70.0, 100.0, 44.0, 86.0, 11.0, 32.0, 96.0, 53.0, 29.0, 4.0, 14.0, 52.0, 52.0, 16.0, 86.0, 81.0, 103.0, 115.0, 44.0, 63.0, 44.0, 8.0, 62.0, 58.0, 67.0, 41.0, 40.0, 48.0, 23.0, 21.0, 8.0, 3.0, 6.0, 73.0, 11.0, 3.0, 3.0, 43.0, 105.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7418469731007469, "mean_inference_ms": 1.927433840719288, "mean_action_processing_ms": 0.3143775441062385, "mean_env_wait_ms": 0.24389935895294798, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062406063079833984, "StateBufferConnector_ms": 0.003900289535522461, "ViewRequirementAgentConnector_ms": 0.21921169757843018}, "num_episodes": 18, "episode_return_max": 396.0, "episode_return_min": -281.59999999999997, "episode_return_mean": 139.23199999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.28502769281585, "num_env_steps_trained_throughput_per_sec": 306.28502769281585, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 12571.963, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12571.908, "sample_time_ms": 2138.242, "learn_time_ms": 10411.694, "learn_throughput": 384.183, "synch_weights_time_ms": 19.792}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-57-44", "timestamp": 1723647464, "time_this_iter_s": 13.146405220031738, "time_total_s": 633.4515464305878, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee10940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 633.4515464305878, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 52.88333333333333, "ram_util_percent": 83.68333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8429160793622335, "cur_kl_coeff": 0.18984375000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.670755297797067, "policy_loss": 0.0011292664874985657, "vf_loss": 7.666441956272831, "vf_explained_var": 0.38048082448187326, "kl": 0.016771979056331855, "entropy": 1.476902117489507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.98964433679505, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.54798492704119, "policy_loss": -0.006942570413383976, "vf_loss": 2.554288820047227, "vf_explained_var": -0.003647524843770991, "kl": 0.008515710573117858, "entropy": 0.788243004348543, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -66.00000000000057, "episode_reward_mean": 150.83999999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -232.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 124.0}, "policy_reward_mean": {"prey_policy": 40.86499999999998, "predator_policy": 34.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [156.79999999999953, 396.0, 94.99999999999937, 56.400000000000006, 97.59999999999951, 44.5, 5.900000000000146, 61.60000000000015, 262.79999999999984, 262.99999999999994, 55.00000000000007, 185.0, 173.39999999999952, 343.5, 138.79999999999947, 116.59999999999988, 78.0999999999999, -37.700000000000024, 117.89999999999941, -54.0, 3.000000000000107, 58.59999999999996, -10.799999999999883, 113.09999999999994, 97.49999999999986, 200.0, 165.60000000000002, 128.19999999999973, 88.499999999999, 221.19999999999945, 194.29999999999995, 12.899999999999986, 193.0999999999994, 182.99999999999946, 30.900000000000112, 107.19999999999999, 25.900000000000084, 67.50000000000014, 30.100000000000144, 38.400000000000276, 93.59999999999997, 77.80000000000014, 213.7999999999995, 232.49999999999966, 198.4999999999999, 247.19999999999982, 142.69999999999908, 184.59999999999994, 120.6999999999999, 261.59999999999957, 125.09999999999997, 121.4000000000001, 273.5, 262.3999999999998, -52.3000000000005, 117.39999999999985, 160.09999999999954, 91.99999999999991, 20.400000000000162, 115.09999999999991, 138.79999999999933, -66.00000000000057, 211.59999999999965, 18.700000000000344, 175.2, 118.49999999999994, 75.59999999999994, 251.0999999999999, 247.39999999999978, 94.29999999999991, 109.59999999999984, 243.2, 70.20000000000012, 186.59999999999928, 168.1999999999998, 253.19999999999928, 253.9999999999998, 116.09999999999997, 220.69999999999976, 298.6, 361.80000000000007, 239.1999999999996, 276.09999999999974, 276.5999999999999, 240.39999999999955, 207.19999999999987, 27.000000000000036, 159.79999999999941, 152.09999999999937, -60.10000000000008, 268.6, 349.9, 240.49999999999997, 186.59999999999917, 196.89999999999984, 190.1999999999998, 263.39999999999986, 213.19999999999996, 280.29999999999984, 316.20000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 135.79999999999998, 191.0, 200.0, -4.899999999999999, 17.899999999999988, -62.79999999999998, -20.799999999999997, 20.0, 2.5999999999999712, 48.5, -163.0, 13.699999999999964, -38.799999999999756, 27.800000000000196, 9.800000000000011, 156.50000000000003, 50.3, 63.2, 117.80000000000001, -103.0, 20.000000000000014, 8.0, 41.0, 7.399999999999965, 140.0, 170.0, 159.5, 15.799999999999963, 59.0, 7.399999999999965, 30.20000000000003, -4.0, 7.099999999999966, 20.000000000000014, -174.69999999999996, 47.0, 17.89999999999998, -112.0, -61.0, 20.000000000000014, -163.0, -58.0, 11.599999999999964, 20.000000000000014, -197.80000000000004, -1.0, 7.099999999999996, -97.3, 27.80000000000001, 131.0, -13.0, 91.40000000000006, 9.200000000000017, -26.199999999999747, 100.39999999999999, 33.500000000000135, 20.000000000000014, 93.19999999999959, 97.99999999999997, 115.10000000000001, 9.200000000000003, -3.099999999999958, -15.999999999999774, 20.000000000000014, 160.1, 20.000000000000014, 125.0, 17.899999999999988, -94.0, -19.0, 18.19999999999999, 20.000000000000014, -24.099999999999746, 70.70000000000002, -86.20000000000056, 5.299999999999965, 15.799999999999963, 20.000000000000014, 7.399999999999965, 68.59999999999988, -67.0, -55.00000000000003, 39.79999999999998, 36.79999999999998, 163.99999999999994, 199.1, -37.60000000000001, -49.0, 141.49999999999994, 29.000000000000128, 189.2, 118.10000000000008, 11.599999999999964, 83.59999999999992, 70.99999999999997, 33.19999999999996, 6.500000000000007, 94.69999999999997, 125.8999999999999, 48.80000000000001, -12.70000000000001, 1.0999999999999854, 65.30000000000007, 121.10000000000004, 127.39999999999998, 122.29999999999995, 127.09999999999981, -82.60000000000002, -141.70000000000064, -36.700000000000024, 67.10000000000002, 132.79999999999995, -15.699999999999747, 55.69999999999999, 5.299999999999965, -142.30000000000015, -7.299999999999905, -68.50000000000006, 53.60000000000001, 15.799999999999963, 79.99999999999991, -63.70000000000023, -151.30000000000035, 59.6, 118.9999999999996, -48.400000000000084, 1.0999999999999865, 35.0000000000001, 72.19999999999999, -106.0, 57.50000000000009, 89.59999999999988, -232.0, 144.7999999999999, -0.7000000000001236, 41.0, 154.39999999999998, -20.500000000000036, -5.1999999999999265, -53.50000000000003, 55.10000000000013, 112.70000000000002, 42.49999999999995, 1.0999999999999865, 25.099999999999998, 30.199999999999967, 145.39999999999975, 111.49999999999977, -22.300000000000097, 130.6999999999997, 108.49999999999993, 51.19999999999992, 156.7999999999998, 151.9999999999999, -142.90000000000018, 118.09999999999995, 38.6, 140.59999999999988, 148.9999999999999, 167.29999999999998, 186.49999999999997, 104.8999999999999, 95.29999999999997, 99.1999999999999, 125.89999999999999, 98.00000000000001, 95.60000000000004, 102.1999999999999, 66.19999999999997, 30.800000000000026, 115.39999999999998, -67.60000000000014, -51.399999999999906, 136.09999999999994, 13.699999999999964, 95.29999999999998, 15.799999999999963, -78.70000000000007, -93.4, 89.00000000000006, 146.6, 178.69999999999996, 162.20000000000005, 112.09999999999997, 94.39999999999999, 167.89999999999986, 13.699999999999964, 33.500000000000114, 124.39999999999992, -23.80000000000014, 121.99999999999994, 109.39999999999999, 124.99999999999997, 112.7, 27.499999999999996, 117.19999999999999, 154.09999999999988, 140.9, 122.29999999999995], "policy_predator_policy_reward": [0.0, 1.0, 3.0, 2.0, 68.0, 14.0, 40.0, 100.0, 59.0, 16.0, 88.0, 71.0, 3.0, 28.0, 16.0, 8.0, 46.0, 10.0, 42.0, 40.0, 84.0, 54.0, 43.0, 93.0, 16.0, 10.0, 4.0, 10.0, 47.0, 17.0, 40.0, 39.0, 26.0, 49.0, 110.0, 7.0, 34.0, 19.0, 10.0, 109.0, 119.0, 27.0, 86.0, 19.0, 43.0, 124.0, 86.0, 21.0, 64.0, 103.0, 16.0, 66.0, 26.0, 39.0, 28.0, 26.0, 14.0, 21.0, 1.0, 29.0, 24.0, 46.0, 21.0, 11.0, 12.0, 1.0, 17.0, 21.0, 91.0, 16.0, 69.0, 39.0, 9.0, 21.0, 32.0, 51.0, 7.0, 2.0, 6.0, 5.0, 89.0, 3.0, 39.0, 54.0, 6.0, 7.0, 29.0, 42.0, 37.0, 69.0, 27.0, 2.0, 9.0, 4.0, 10.0, 20.0, 63.0, 18.0, 23.0, 18.0, 42.0, 47.0, 46.0, 9.0, 3.0, 22.0, 13.0, 0.0, 93.0, 79.0, 24.0, 63.0, 26.0, 17.0, 24.0, 7.0, 70.0, 100.0, 44.0, 86.0, 11.0, 32.0, 96.0, 53.0, 29.0, 4.0, 14.0, 52.0, 52.0, 16.0, 86.0, 81.0, 103.0, 115.0, 44.0, 63.0, 44.0, 8.0, 62.0, 58.0, 67.0, 41.0, 40.0, 48.0, 23.0, 21.0, 8.0, 3.0, 6.0, 73.0, 11.0, 3.0, 3.0, 43.0, 105.0, 2.0, 46.0, 18.0, 8.0, 1.0, 4.0, 4.0, 31.0, 8.0, 22.0, 29.0, 34.0, 49.0, 32.0, 40.0, 17.0, 44.0, 68.0, 78.0, 4.0, 6.0, 20.0, 21.0, 96.0, 16.0, 17.0, 16.0, 5.0, 4.0, 8.0, 26.0, 3.0, 2.0, 30.0, 9.0, 57.0, 35.0, 22.0, 7.0, 46.0, 27.0, 3.0, 6.0, 23.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7523451118746217, "mean_inference_ms": 1.956493775947697, "mean_action_processing_ms": 0.31988905337067025, "mean_env_wait_ms": 0.24745989514484748, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005676388740539551, "StateBufferConnector_ms": 0.004523634910583496, "ViewRequirementAgentConnector_ms": 0.24002671241760254}, "num_episodes": 22, "episode_return_max": 396.0, "episode_return_min": -66.00000000000057, "episode_return_mean": 150.83999999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.30558917524104, "num_env_steps_trained_throughput_per_sec": 306.30558917524104, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 12693.624, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12693.569, "sample_time_ms": 2217.057, "learn_time_ms": 10452.299, "learn_throughput": 382.691, "synch_weights_time_ms": 21.529}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-57-58", "timestamp": 1723647478, "time_this_iter_s": 13.189555883407593, "time_total_s": 646.6411023139954, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee181f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 646.6411023139954, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 52.784210526315796, "ram_util_percent": 83.49999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4994028988023285, "cur_kl_coeff": 0.18984375000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.036908942934066, "policy_loss": -0.0030382827419551117, "vf_loss": 7.036577287805144, "vf_explained_var": 0.3854905108610789, "kl": 0.01775104421537231, "entropy": 1.4795443257326801, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6038379380627283, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.489673403709654, "policy_loss": -0.007852306358624625, "vf_loss": 4.4967086051506975, "vf_explained_var": 0.019933204329203046, "kl": 0.010894559781438787, "entropy": 0.7780501128504516, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 376.2, "episode_reward_min": -66.00000000000057, "episode_reward_mean": 171.07099999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -232.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 134.0}, "policy_reward_mean": {"prey_policy": 52.78549999999998, "predator_policy": 32.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [113.09999999999994, 97.49999999999986, 200.0, 165.60000000000002, 128.19999999999973, 88.499999999999, 221.19999999999945, 194.29999999999995, 12.899999999999986, 193.0999999999994, 182.99999999999946, 30.900000000000112, 107.19999999999999, 25.900000000000084, 67.50000000000014, 30.100000000000144, 38.400000000000276, 93.59999999999997, 77.80000000000014, 213.7999999999995, 232.49999999999966, 198.4999999999999, 247.19999999999982, 142.69999999999908, 184.59999999999994, 120.6999999999999, 261.59999999999957, 125.09999999999997, 121.4000000000001, 273.5, 262.3999999999998, -52.3000000000005, 117.39999999999985, 160.09999999999954, 91.99999999999991, 20.400000000000162, 115.09999999999991, 138.79999999999933, -66.00000000000057, 211.59999999999965, 18.700000000000344, 175.2, 118.49999999999994, 75.59999999999994, 251.0999999999999, 247.39999999999978, 94.29999999999991, 109.59999999999984, 243.2, 70.20000000000012, 186.59999999999928, 168.1999999999998, 253.19999999999928, 253.9999999999998, 116.09999999999997, 220.69999999999976, 298.6, 361.80000000000007, 239.1999999999996, 276.09999999999974, 276.5999999999999, 240.39999999999955, 207.19999999999987, 27.000000000000036, 159.79999999999941, 152.09999999999937, -60.10000000000008, 268.6, 349.9, 240.49999999999997, 186.59999999999917, 196.89999999999984, 190.1999999999998, 263.39999999999986, 213.19999999999996, 280.29999999999984, 316.20000000000016, 322.90000000000003, 241.59999999999985, 185.1, 114.7999999999997, 18.300000000000008, 190.1999999999993, 376.2, 267.4999999999999, 275.49999999999983, 101.0999999999997, 139.9999999999996, 195.3, 174.9999999999994, 259.39999999999975, 50.29999999999997, 345.9, 176.99999999999997, 205.89999999999927, 272.0999999999998, 121.89999999999985, 143.70000000000007, 188.49999999999997, 261.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1.0, 7.099999999999996, -97.3, 27.80000000000001, 131.0, -13.0, 91.40000000000006, 9.200000000000017, -26.199999999999747, 100.39999999999999, 33.500000000000135, 20.000000000000014, 93.19999999999959, 97.99999999999997, 115.10000000000001, 9.200000000000003, -3.099999999999958, -15.999999999999774, 20.000000000000014, 160.1, 20.000000000000014, 125.0, 17.899999999999988, -94.0, -19.0, 18.19999999999999, 20.000000000000014, -24.099999999999746, 70.70000000000002, -86.20000000000056, 5.299999999999965, 15.799999999999963, 20.000000000000014, 7.399999999999965, 68.59999999999988, -67.0, -55.00000000000003, 39.79999999999998, 36.79999999999998, 163.99999999999994, 199.1, -37.60000000000001, -49.0, 141.49999999999994, 29.000000000000128, 189.2, 118.10000000000008, 11.599999999999964, 83.59999999999992, 70.99999999999997, 33.19999999999996, 6.500000000000007, 94.69999999999997, 125.8999999999999, 48.80000000000001, -12.70000000000001, 1.0999999999999854, 65.30000000000007, 121.10000000000004, 127.39999999999998, 122.29999999999995, 127.09999999999981, -82.60000000000002, -141.70000000000064, -36.700000000000024, 67.10000000000002, 132.79999999999995, -15.699999999999747, 55.69999999999999, 5.299999999999965, -142.30000000000015, -7.299999999999905, -68.50000000000006, 53.60000000000001, 15.799999999999963, 79.99999999999991, -63.70000000000023, -151.30000000000035, 59.6, 118.9999999999996, -48.400000000000084, 1.0999999999999865, 35.0000000000001, 72.19999999999999, -106.0, 57.50000000000009, 89.59999999999988, -232.0, 144.7999999999999, -0.7000000000001236, 41.0, 154.39999999999998, -20.500000000000036, -5.1999999999999265, -53.50000000000003, 55.10000000000013, 112.70000000000002, 42.49999999999995, 1.0999999999999865, 25.099999999999998, 30.199999999999967, 145.39999999999975, 111.49999999999977, -22.300000000000097, 130.6999999999997, 108.49999999999993, 51.19999999999992, 156.7999999999998, 151.9999999999999, -142.90000000000018, 118.09999999999995, 38.6, 140.59999999999988, 148.9999999999999, 167.29999999999998, 186.49999999999997, 104.8999999999999, 95.29999999999997, 99.1999999999999, 125.89999999999999, 98.00000000000001, 95.60000000000004, 102.1999999999999, 66.19999999999997, 30.800000000000026, 115.39999999999998, -67.60000000000014, -51.399999999999906, 136.09999999999994, 13.699999999999964, 95.29999999999998, 15.799999999999963, -78.70000000000007, -93.4, 89.00000000000006, 146.6, 178.69999999999996, 162.20000000000005, 112.09999999999997, 94.39999999999999, 167.89999999999986, 13.699999999999964, 33.500000000000114, 124.39999999999992, -23.80000000000014, 121.99999999999994, 109.39999999999999, 124.99999999999997, 112.7, 27.499999999999996, 117.19999999999999, 154.09999999999988, 140.9, 122.29999999999995, 151.7, 135.20000000000002, 74.0, 98.59999999999997, 77.29999999999998, 66.80000000000001, 27.79999999999998, 20.000000000000014, 7.399999999999965, -3.099999999999958, 20.000000000000014, 147.20000000000002, 189.2, 185.0, 107.29999999999998, 108.2, 101.29999999999998, 126.19999999999997, 22.700000000000056, -4.59999999999998, 71.89999999999998, 31.09999999999997, 34.70000000000009, 116.59999999999997, 20.000000000000014, 122.0, 119.89999999999989, 9.500000000000018, -48.700000000000074, 20.000000000000014, 173.89999999999998, 149.0, -76.00000000000006, -4.000000000000107, 36.200000000000145, 121.69999999999987, 66.5, 155.5999999999999, -3.099999999999958, 80.00000000000001, 136.99999999999994, -79.30000000000032, -156.70000000000002, 135.2, 54.20000000000001, 151.69999999999996], "policy_predator_policy_reward": [86.0, 21.0, 64.0, 103.0, 16.0, 66.0, 26.0, 39.0, 28.0, 26.0, 14.0, 21.0, 1.0, 29.0, 24.0, 46.0, 21.0, 11.0, 12.0, 1.0, 17.0, 21.0, 91.0, 16.0, 69.0, 39.0, 9.0, 21.0, 32.0, 51.0, 7.0, 2.0, 6.0, 5.0, 89.0, 3.0, 39.0, 54.0, 6.0, 7.0, 29.0, 42.0, 37.0, 69.0, 27.0, 2.0, 9.0, 4.0, 10.0, 20.0, 63.0, 18.0, 23.0, 18.0, 42.0, 47.0, 46.0, 9.0, 3.0, 22.0, 13.0, 0.0, 93.0, 79.0, 24.0, 63.0, 26.0, 17.0, 24.0, 7.0, 70.0, 100.0, 44.0, 86.0, 11.0, 32.0, 96.0, 53.0, 29.0, 4.0, 14.0, 52.0, 52.0, 16.0, 86.0, 81.0, 103.0, 115.0, 44.0, 63.0, 44.0, 8.0, 62.0, 58.0, 67.0, 41.0, 40.0, 48.0, 23.0, 21.0, 8.0, 3.0, 6.0, 73.0, 11.0, 3.0, 3.0, 43.0, 105.0, 2.0, 46.0, 18.0, 8.0, 1.0, 4.0, 4.0, 31.0, 8.0, 22.0, 29.0, 34.0, 49.0, 32.0, 40.0, 17.0, 44.0, 68.0, 78.0, 4.0, 6.0, 20.0, 21.0, 96.0, 16.0, 17.0, 16.0, 5.0, 4.0, 8.0, 26.0, 3.0, 2.0, 30.0, 9.0, 57.0, 35.0, 22.0, 7.0, 46.0, 27.0, 3.0, 6.0, 23.0, 30.0, 23.0, 13.0, 7.0, 62.0, 2.0, 39.0, 52.0, 15.0, 11.0, 3.0, 13.0, 10.0, 2.0, 0.0, 20.0, 32.0, 23.0, 25.0, 57.0, 26.0, 7.0, 30.0, 24.0, 20.0, 23.0, 10.0, 61.0, 69.0, 0.0, 79.0, 5.0, 18.0, 134.0, 123.0, 27.0, 21.0, 20.0, 30.0, 24.0, 21.0, 11.0, 75.0, 102.0, 108.0, 19.0, 37.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7595527185193117, "mean_inference_ms": 1.9778850219191988, "mean_action_processing_ms": 0.3231868918312386, "mean_env_wait_ms": 0.250428435665753, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005428433418273926, "StateBufferConnector_ms": 0.00378572940826416, "ViewRequirementAgentConnector_ms": 0.2188655138015747}, "num_episodes": 23, "episode_return_max": 376.2, "episode_return_min": -66.00000000000057, "episode_return_mean": 171.07099999999988, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.7869986820905, "num_env_steps_trained_throughput_per_sec": 300.7869986820905, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 12857.477, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12857.419, "sample_time_ms": 2243.055, "learn_time_ms": 10589.672, "learn_throughput": 377.727, "synch_weights_time_ms": 22.086}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-58-11", "timestamp": 1723647491, "time_this_iter_s": 13.347658157348633, "time_total_s": 659.988760471344, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee18430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 659.988760471344, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 55.43684210526315, "ram_util_percent": 83.21578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.19501358242262, "cur_kl_coeff": 0.18984375000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.790209945547518, "policy_loss": 0.004081612428904033, "vf_loss": 7.780777258090872, "vf_explained_var": 0.4004349884848115, "kl": 0.028186609772941577, "entropy": 1.5006770264534723, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1679256299185377, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5875000813650706, "policy_loss": -0.004003780060226009, "vf_loss": 2.591033663699236, "vf_explained_var": -0.0008569598513305502, "kl": 0.006269409752164631, "entropy": 0.7042425840304642, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 376.2, "episode_reward_min": -66.00000000000057, "episode_reward_mean": 189.37699999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -232.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 134.0}, "policy_reward_mean": {"prey_policy": 62.028499999999966, "predator_policy": 32.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [77.80000000000014, 213.7999999999995, 232.49999999999966, 198.4999999999999, 247.19999999999982, 142.69999999999908, 184.59999999999994, 120.6999999999999, 261.59999999999957, 125.09999999999997, 121.4000000000001, 273.5, 262.3999999999998, -52.3000000000005, 117.39999999999985, 160.09999999999954, 91.99999999999991, 20.400000000000162, 115.09999999999991, 138.79999999999933, -66.00000000000057, 211.59999999999965, 18.700000000000344, 175.2, 118.49999999999994, 75.59999999999994, 251.0999999999999, 247.39999999999978, 94.29999999999991, 109.59999999999984, 243.2, 70.20000000000012, 186.59999999999928, 168.1999999999998, 253.19999999999928, 253.9999999999998, 116.09999999999997, 220.69999999999976, 298.6, 361.80000000000007, 239.1999999999996, 276.09999999999974, 276.5999999999999, 240.39999999999955, 207.19999999999987, 27.000000000000036, 159.79999999999941, 152.09999999999937, -60.10000000000008, 268.6, 349.9, 240.49999999999997, 186.59999999999917, 196.89999999999984, 190.1999999999998, 263.39999999999986, 213.19999999999996, 280.29999999999984, 316.20000000000016, 322.90000000000003, 241.59999999999985, 185.1, 114.7999999999997, 18.300000000000008, 190.1999999999993, 376.2, 267.4999999999999, 275.49999999999983, 101.0999999999997, 139.9999999999996, 195.3, 174.9999999999994, 259.39999999999975, 50.29999999999997, 345.9, 176.99999999999997, 205.89999999999927, 272.0999999999998, 121.89999999999985, 143.70000000000007, 188.49999999999997, 261.9, 266.19999999999993, 261.9, 273.90000000000003, 229.5999999999998, 258.9999999999998, 237.79999999999941, 70.89999999999998, 291.39999999999986, 168.89999999999952, 237.0999999999998, 239.1999999999997, 167.9, 159.29999999999959, 250.1999999999996, 245.5999999999997, 244.5999999999998, 163.29999999999953, 54.799999999999876], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-55.00000000000003, 39.79999999999998, 36.79999999999998, 163.99999999999994, 199.1, -37.60000000000001, -49.0, 141.49999999999994, 29.000000000000128, 189.2, 118.10000000000008, 11.599999999999964, 83.59999999999992, 70.99999999999997, 33.19999999999996, 6.500000000000007, 94.69999999999997, 125.8999999999999, 48.80000000000001, -12.70000000000001, 1.0999999999999854, 65.30000000000007, 121.10000000000004, 127.39999999999998, 122.29999999999995, 127.09999999999981, -82.60000000000002, -141.70000000000064, -36.700000000000024, 67.10000000000002, 132.79999999999995, -15.699999999999747, 55.69999999999999, 5.299999999999965, -142.30000000000015, -7.299999999999905, -68.50000000000006, 53.60000000000001, 15.799999999999963, 79.99999999999991, -63.70000000000023, -151.30000000000035, 59.6, 118.9999999999996, -48.400000000000084, 1.0999999999999865, 35.0000000000001, 72.19999999999999, -106.0, 57.50000000000009, 89.59999999999988, -232.0, 144.7999999999999, -0.7000000000001236, 41.0, 154.39999999999998, -20.500000000000036, -5.1999999999999265, -53.50000000000003, 55.10000000000013, 112.70000000000002, 42.49999999999995, 1.0999999999999865, 25.099999999999998, 30.199999999999967, 145.39999999999975, 111.49999999999977, -22.300000000000097, 130.6999999999997, 108.49999999999993, 51.19999999999992, 156.7999999999998, 151.9999999999999, -142.90000000000018, 118.09999999999995, 38.6, 140.59999999999988, 148.9999999999999, 167.29999999999998, 186.49999999999997, 104.8999999999999, 95.29999999999997, 99.1999999999999, 125.89999999999999, 98.00000000000001, 95.60000000000004, 102.1999999999999, 66.19999999999997, 30.800000000000026, 115.39999999999998, -67.60000000000014, -51.399999999999906, 136.09999999999994, 13.699999999999964, 95.29999999999998, 15.799999999999963, -78.70000000000007, -93.4, 89.00000000000006, 146.6, 178.69999999999996, 162.20000000000005, 112.09999999999997, 94.39999999999999, 167.89999999999986, 13.699999999999964, 33.500000000000114, 124.39999999999992, -23.80000000000014, 121.99999999999994, 109.39999999999999, 124.99999999999997, 112.7, 27.499999999999996, 117.19999999999999, 154.09999999999988, 140.9, 122.29999999999995, 151.7, 135.20000000000002, 74.0, 98.59999999999997, 77.29999999999998, 66.80000000000001, 27.79999999999998, 20.000000000000014, 7.399999999999965, -3.099999999999958, 20.000000000000014, 147.20000000000002, 189.2, 185.0, 107.29999999999998, 108.2, 101.29999999999998, 126.19999999999997, 22.700000000000056, -4.59999999999998, 71.89999999999998, 31.09999999999997, 34.70000000000009, 116.59999999999997, 20.000000000000014, 122.0, 119.89999999999989, 9.500000000000018, -48.700000000000074, 20.000000000000014, 173.89999999999998, 149.0, -76.00000000000006, -4.000000000000107, 36.200000000000145, 121.69999999999987, 66.5, 155.5999999999999, -3.099999999999958, 80.00000000000001, 136.99999999999994, -79.30000000000032, -156.70000000000002, 135.2, 54.20000000000001, 151.69999999999996, 145.6999999999999, 30.499999999999996, 89.90000000000003, 134.0, 146.59999999999982, 83.30000000000001, 48.80000000000001, 108.79999999999995, 173.29999999999987, 37.70000000000002, 145.99999999999991, 90.79999999999997, -34.59999999999999, 78.49999999999997, 93.80000000000004, 140.59999999999997, 134.9, 20.000000000000014, 75.80000000000001, 104.29999999999995, 164.29999999999993, 26.89999999999994, -82.60000000000028, 159.5, -65.8000000000003, 61.10000000000008, -2.7999999999999474, 163.99999999999986, 71.00000000000003, 131.59999999999994, 128.00000000000003, 29.599999999999973, 103.4, 17.899999999999988, 18.7999999999999, -67.00000000000018], "policy_predator_policy_reward": [39.0, 54.0, 6.0, 7.0, 29.0, 42.0, 37.0, 69.0, 27.0, 2.0, 9.0, 4.0, 10.0, 20.0, 63.0, 18.0, 23.0, 18.0, 42.0, 47.0, 46.0, 9.0, 3.0, 22.0, 13.0, 0.0, 93.0, 79.0, 24.0, 63.0, 26.0, 17.0, 24.0, 7.0, 70.0, 100.0, 44.0, 86.0, 11.0, 32.0, 96.0, 53.0, 29.0, 4.0, 14.0, 52.0, 52.0, 16.0, 86.0, 81.0, 103.0, 115.0, 44.0, 63.0, 44.0, 8.0, 62.0, 58.0, 67.0, 41.0, 40.0, 48.0, 23.0, 21.0, 8.0, 3.0, 6.0, 73.0, 11.0, 3.0, 3.0, 43.0, 105.0, 2.0, 46.0, 18.0, 8.0, 1.0, 4.0, 4.0, 31.0, 8.0, 22.0, 29.0, 34.0, 49.0, 32.0, 40.0, 17.0, 44.0, 68.0, 78.0, 4.0, 6.0, 20.0, 21.0, 96.0, 16.0, 17.0, 16.0, 5.0, 4.0, 8.0, 26.0, 3.0, 2.0, 30.0, 9.0, 57.0, 35.0, 22.0, 7.0, 46.0, 27.0, 3.0, 6.0, 23.0, 30.0, 23.0, 13.0, 7.0, 62.0, 2.0, 39.0, 52.0, 15.0, 11.0, 3.0, 13.0, 10.0, 2.0, 0.0, 20.0, 32.0, 23.0, 25.0, 57.0, 26.0, 7.0, 30.0, 24.0, 20.0, 23.0, 10.0, 61.0, 69.0, 0.0, 79.0, 5.0, 18.0, 134.0, 123.0, 27.0, 21.0, 20.0, 30.0, 24.0, 21.0, 11.0, 75.0, 102.0, 108.0, 19.0, 37.0, 50.0, 40.0, 22.0, 16.0, 32.0, 12.0, 29.0, 43.0, 46.0, 2.0, 0.0, 1.0, 11.0, 16.0, 30.0, 27.0, 13.0, 1.0, 24.0, 33.0, 37.0, 11.0, 8.0, 83.0, 81.0, 83.0, 37.0, 52.0, 20.0, 23.0, 42.0, 45.0, 24.0, 18.0, 92.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7645449492215681, "mean_inference_ms": 1.9925479855591295, "mean_action_processing_ms": 0.32543403090525386, "mean_env_wait_ms": 0.25238434662890546, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005579471588134766, "StateBufferConnector_ms": 0.003874540328979492, "ViewRequirementAgentConnector_ms": 0.18293380737304688}, "num_episodes": 18, "episode_return_max": 376.2, "episode_return_min": -66.00000000000057, "episode_return_mean": 189.37699999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.7251255573811, "num_env_steps_trained_throughput_per_sec": 321.7251255573811, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 12923.263, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12923.205, "sample_time_ms": 2254.82, "learn_time_ms": 10642.333, "learn_throughput": 375.857, "synch_weights_time_ms": 23.631}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-58-24", "timestamp": 1723647504, "time_this_iter_s": 12.478655815124512, "time_total_s": 672.4674162864685, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee18ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 672.4674162864685, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 51.68333333333333, "ram_util_percent": 81.72777777777779}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.96476608502171, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.121560410090856, "policy_loss": -0.005732073369756262, "vf_loss": 8.123337785529081, "vf_explained_var": 0.2367102025047181, "kl": 0.013887495834244513, "entropy": 1.4654257476014434, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4025723392370515, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2596552274845263, "policy_loss": -0.0069226680850738255, "vf_loss": 3.2660655942543473, "vf_explained_var": 0.01483080995776666, "kl": 0.006830700634569821, "entropy": 0.6797502504770088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 376.2, "episode_reward_min": -66.00000000000057, "episode_reward_mean": 196.8059999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -232.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.2, "predator_policy": 134.0}, "policy_reward_mean": {"prey_policy": 65.88799999999996, "predator_policy": 32.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [115.09999999999991, 138.79999999999933, -66.00000000000057, 211.59999999999965, 18.700000000000344, 175.2, 118.49999999999994, 75.59999999999994, 251.0999999999999, 247.39999999999978, 94.29999999999991, 109.59999999999984, 243.2, 70.20000000000012, 186.59999999999928, 168.1999999999998, 253.19999999999928, 253.9999999999998, 116.09999999999997, 220.69999999999976, 298.6, 361.80000000000007, 239.1999999999996, 276.09999999999974, 276.5999999999999, 240.39999999999955, 207.19999999999987, 27.000000000000036, 159.79999999999941, 152.09999999999937, -60.10000000000008, 268.6, 349.9, 240.49999999999997, 186.59999999999917, 196.89999999999984, 190.1999999999998, 263.39999999999986, 213.19999999999996, 280.29999999999984, 316.20000000000016, 322.90000000000003, 241.59999999999985, 185.1, 114.7999999999997, 18.300000000000008, 190.1999999999993, 376.2, 267.4999999999999, 275.49999999999983, 101.0999999999997, 139.9999999999996, 195.3, 174.9999999999994, 259.39999999999975, 50.29999999999997, 345.9, 176.99999999999997, 205.89999999999927, 272.0999999999998, 121.89999999999985, 143.70000000000007, 188.49999999999997, 261.9, 266.19999999999993, 261.9, 273.90000000000003, 229.5999999999998, 258.9999999999998, 237.79999999999941, 70.89999999999998, 291.39999999999986, 168.89999999999952, 237.0999999999998, 239.1999999999997, 167.9, 159.29999999999959, 250.1999999999996, 245.5999999999997, 244.5999999999998, 163.29999999999953, 54.799999999999876, 88.5999999999997, 240.9999999999996, 264.59999999999974, -17.30000000000009, 275.8999999999999, 129.3999999999996, 213.79999999999953, 293.8000000000008, 239.49999999999997, 172.69999999999968, 269.6999999999997, 123.79999999999939, 228.89999999999972, 176.69999999999985, 310.9000000000001, 204.1999999999997, 50.2999999999999, 275.7999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-68.50000000000006, 53.60000000000001, 15.799999999999963, 79.99999999999991, -63.70000000000023, -151.30000000000035, 59.6, 118.9999999999996, -48.400000000000084, 1.0999999999999865, 35.0000000000001, 72.19999999999999, -106.0, 57.50000000000009, 89.59999999999988, -232.0, 144.7999999999999, -0.7000000000001236, 41.0, 154.39999999999998, -20.500000000000036, -5.1999999999999265, -53.50000000000003, 55.10000000000013, 112.70000000000002, 42.49999999999995, 1.0999999999999865, 25.099999999999998, 30.199999999999967, 145.39999999999975, 111.49999999999977, -22.300000000000097, 130.6999999999997, 108.49999999999993, 51.19999999999992, 156.7999999999998, 151.9999999999999, -142.90000000000018, 118.09999999999995, 38.6, 140.59999999999988, 148.9999999999999, 167.29999999999998, 186.49999999999997, 104.8999999999999, 95.29999999999997, 99.1999999999999, 125.89999999999999, 98.00000000000001, 95.60000000000004, 102.1999999999999, 66.19999999999997, 30.800000000000026, 115.39999999999998, -67.60000000000014, -51.399999999999906, 136.09999999999994, 13.699999999999964, 95.29999999999998, 15.799999999999963, -78.70000000000007, -93.4, 89.00000000000006, 146.6, 178.69999999999996, 162.20000000000005, 112.09999999999997, 94.39999999999999, 167.89999999999986, 13.699999999999964, 33.500000000000114, 124.39999999999992, -23.80000000000014, 121.99999999999994, 109.39999999999999, 124.99999999999997, 112.7, 27.499999999999996, 117.19999999999999, 154.09999999999988, 140.9, 122.29999999999995, 151.7, 135.20000000000002, 74.0, 98.59999999999997, 77.29999999999998, 66.80000000000001, 27.79999999999998, 20.000000000000014, 7.399999999999965, -3.099999999999958, 20.000000000000014, 147.20000000000002, 189.2, 185.0, 107.29999999999998, 108.2, 101.29999999999998, 126.19999999999997, 22.700000000000056, -4.59999999999998, 71.89999999999998, 31.09999999999997, 34.70000000000009, 116.59999999999997, 20.000000000000014, 122.0, 119.89999999999989, 9.500000000000018, -48.700000000000074, 20.000000000000014, 173.89999999999998, 149.0, -76.00000000000006, -4.000000000000107, 36.200000000000145, 121.69999999999987, 66.5, 155.5999999999999, -3.099999999999958, 80.00000000000001, 136.99999999999994, -79.30000000000032, -156.70000000000002, 135.2, 54.20000000000001, 151.69999999999996, 145.6999999999999, 30.499999999999996, 89.90000000000003, 134.0, 146.59999999999982, 83.30000000000001, 48.80000000000001, 108.79999999999995, 173.29999999999987, 37.70000000000002, 145.99999999999991, 90.79999999999997, -34.59999999999999, 78.49999999999997, 93.80000000000004, 140.59999999999997, 134.9, 20.000000000000014, 75.80000000000001, 104.29999999999995, 164.29999999999993, 26.89999999999994, -82.60000000000028, 159.5, -65.8000000000003, 61.10000000000008, -2.7999999999999474, 163.99999999999986, 71.00000000000003, 131.59999999999994, 128.00000000000003, 29.599999999999973, 103.4, 17.899999999999988, 18.7999999999999, -67.00000000000018, -28.299999999999763, 56.90000000000003, 119.89999999999986, 61.10000000000006, 36.800000000000054, 165.79999999999993, -196.60000000000025, 29.30000000000002, 20.299999999999955, 158.59999999999985, 48.2000000000001, 33.200000000000074, 94.6999999999999, 79.10000000000001, 139.39999999999966, 142.39999999999984, 66.8, 112.69999999999999, 39.50000000000008, 60.20000000000002, 69.20000000000006, 141.49999999999994, 38.000000000000064, 45.800000000000104, 94.69999999999985, 84.20000000000005, 74.00000000000007, 85.69999999999982, 166.6999999999998, 96.20000000000002, 71.30000000000004, 68.89999999999989, -145.90000000000012, 60.20000000000003, 127.99999999999997, 90.79999999999994], "policy_predator_policy_reward": [44.0, 86.0, 11.0, 32.0, 96.0, 53.0, 29.0, 4.0, 14.0, 52.0, 52.0, 16.0, 86.0, 81.0, 103.0, 115.0, 44.0, 63.0, 44.0, 8.0, 62.0, 58.0, 67.0, 41.0, 40.0, 48.0, 23.0, 21.0, 8.0, 3.0, 6.0, 73.0, 11.0, 3.0, 3.0, 43.0, 105.0, 2.0, 46.0, 18.0, 8.0, 1.0, 4.0, 4.0, 31.0, 8.0, 22.0, 29.0, 34.0, 49.0, 32.0, 40.0, 17.0, 44.0, 68.0, 78.0, 4.0, 6.0, 20.0, 21.0, 96.0, 16.0, 17.0, 16.0, 5.0, 4.0, 8.0, 26.0, 3.0, 2.0, 30.0, 9.0, 57.0, 35.0, 22.0, 7.0, 46.0, 27.0, 3.0, 6.0, 23.0, 30.0, 23.0, 13.0, 7.0, 62.0, 2.0, 39.0, 52.0, 15.0, 11.0, 3.0, 13.0, 10.0, 2.0, 0.0, 20.0, 32.0, 23.0, 25.0, 57.0, 26.0, 7.0, 30.0, 24.0, 20.0, 23.0, 10.0, 61.0, 69.0, 0.0, 79.0, 5.0, 18.0, 134.0, 123.0, 27.0, 21.0, 20.0, 30.0, 24.0, 21.0, 11.0, 75.0, 102.0, 108.0, 19.0, 37.0, 50.0, 40.0, 22.0, 16.0, 32.0, 12.0, 29.0, 43.0, 46.0, 2.0, 0.0, 1.0, 11.0, 16.0, 30.0, 27.0, 13.0, 1.0, 24.0, 33.0, 37.0, 11.0, 8.0, 83.0, 81.0, 83.0, 37.0, 52.0, 20.0, 23.0, 42.0, 45.0, 24.0, 18.0, 92.0, 11.0, 18.0, 42.0, 30.0, 30.0, 36.0, 26.0, 31.0, 119.0, 49.0, 48.0, 38.0, 10.0, 24.0, 16.0, 6.0, 6.0, 19.0, 41.0, 29.0, 44.0, 31.0, 28.0, 40.0, 0.0, 29.0, 21.0, 12.0, 5.0, 21.0, 27.0, 36.0, 28.0, 106.0, 30.0, 27.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7683336119160262, "mean_inference_ms": 2.004029105121982, "mean_action_processing_ms": 0.3271962139071565, "mean_env_wait_ms": 0.2539287339365418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005606532096862793, "StateBufferConnector_ms": 0.003908634185791016, "ViewRequirementAgentConnector_ms": 0.16779685020446777}, "num_episodes": 18, "episode_return_max": 376.2, "episode_return_min": -66.00000000000057, "episode_return_mean": 196.8059999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.7141471793522, "num_env_steps_trained_throughput_per_sec": 319.7141471793522, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 13007.661, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13007.604, "sample_time_ms": 2262.276, "learn_time_ms": 10718.374, "learn_throughput": 373.191, "synch_weights_time_ms": 24.598}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-58-36", "timestamp": 1723647516, "time_this_iter_s": 12.526607036590576, "time_total_s": 684.9940233230591, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d4f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 684.9940233230591, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 46.9, "ram_util_percent": 81.50588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5857766610604744, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.719701097125099, "policy_loss": 0.004228285244769521, "vf_loss": 7.711952240504916, "vf_explained_var": 0.2992920935784698, "kl": 0.012363063696786244, "entropy": 1.4995438513301669, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.481896371879275, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.317417980754186, "policy_loss": -0.004706522269499681, "vf_loss": 2.321656172868436, "vf_explained_var": 0.002015817449206398, "kl": 0.006244317969665994, "entropy": 0.7034681514142052, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 376.2, "episode_reward_min": -60.10000000000008, "episode_reward_mean": 208.75199999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -196.60000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.2, "predator_policy": 134.0}, "policy_reward_mean": {"prey_policy": 74.35599999999998, "predator_policy": 30.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [239.1999999999996, 276.09999999999974, 276.5999999999999, 240.39999999999955, 207.19999999999987, 27.000000000000036, 159.79999999999941, 152.09999999999937, -60.10000000000008, 268.6, 349.9, 240.49999999999997, 186.59999999999917, 196.89999999999984, 190.1999999999998, 263.39999999999986, 213.19999999999996, 280.29999999999984, 316.20000000000016, 322.90000000000003, 241.59999999999985, 185.1, 114.7999999999997, 18.300000000000008, 190.1999999999993, 376.2, 267.4999999999999, 275.49999999999983, 101.0999999999997, 139.9999999999996, 195.3, 174.9999999999994, 259.39999999999975, 50.29999999999997, 345.9, 176.99999999999997, 205.89999999999927, 272.0999999999998, 121.89999999999985, 143.70000000000007, 188.49999999999997, 261.9, 266.19999999999993, 261.9, 273.90000000000003, 229.5999999999998, 258.9999999999998, 237.79999999999941, 70.89999999999998, 291.39999999999986, 168.89999999999952, 237.0999999999998, 239.1999999999997, 167.9, 159.29999999999959, 250.1999999999996, 245.5999999999997, 244.5999999999998, 163.29999999999953, 54.799999999999876, 88.5999999999997, 240.9999999999996, 264.59999999999974, -17.30000000000009, 275.8999999999999, 129.3999999999996, 213.79999999999953, 293.8000000000008, 239.49999999999997, 172.69999999999968, 269.6999999999997, 123.79999999999939, 228.89999999999972, 176.69999999999985, 310.9000000000001, 204.1999999999997, 50.2999999999999, 275.7999999999996, 192.19999999999948, 272.0999999999997, 297.99999999999983, 196.39999999999984, 156.69999999999987, 235.09999999999985, 151.6999999999999, 257.29999999999984, 290.79999999999984, 166.59999999999965, 193.49999999999963, 243.9999999999997, 153.8999999999997, 181.5999999999999, 135.3, 255.59999999999948, 234.09999999999994, 277.80000000000007, 96.09999999999988, 286.69999999999993, 257.19999999999993, 324.40000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [104.8999999999999, 95.29999999999997, 99.1999999999999, 125.89999999999999, 98.00000000000001, 95.60000000000004, 102.1999999999999, 66.19999999999997, 30.800000000000026, 115.39999999999998, -67.60000000000014, -51.399999999999906, 136.09999999999994, 13.699999999999964, 95.29999999999998, 15.799999999999963, -78.70000000000007, -93.4, 89.00000000000006, 146.6, 178.69999999999996, 162.20000000000005, 112.09999999999997, 94.39999999999999, 167.89999999999986, 13.699999999999964, 33.500000000000114, 124.39999999999992, -23.80000000000014, 121.99999999999994, 109.39999999999999, 124.99999999999997, 112.7, 27.499999999999996, 117.19999999999999, 154.09999999999988, 140.9, 122.29999999999995, 151.7, 135.20000000000002, 74.0, 98.59999999999997, 77.29999999999998, 66.80000000000001, 27.79999999999998, 20.000000000000014, 7.399999999999965, -3.099999999999958, 20.000000000000014, 147.20000000000002, 189.2, 185.0, 107.29999999999998, 108.2, 101.29999999999998, 126.19999999999997, 22.700000000000056, -4.59999999999998, 71.89999999999998, 31.09999999999997, 34.70000000000009, 116.59999999999997, 20.000000000000014, 122.0, 119.89999999999989, 9.500000000000018, -48.700000000000074, 20.000000000000014, 173.89999999999998, 149.0, -76.00000000000006, -4.000000000000107, 36.200000000000145, 121.69999999999987, 66.5, 155.5999999999999, -3.099999999999958, 80.00000000000001, 136.99999999999994, -79.30000000000032, -156.70000000000002, 135.2, 54.20000000000001, 151.69999999999996, 145.6999999999999, 30.499999999999996, 89.90000000000003, 134.0, 146.59999999999982, 83.30000000000001, 48.80000000000001, 108.79999999999995, 173.29999999999987, 37.70000000000002, 145.99999999999991, 90.79999999999997, -34.59999999999999, 78.49999999999997, 93.80000000000004, 140.59999999999997, 134.9, 20.000000000000014, 75.80000000000001, 104.29999999999995, 164.29999999999993, 26.89999999999994, -82.60000000000028, 159.5, -65.8000000000003, 61.10000000000008, -2.7999999999999474, 163.99999999999986, 71.00000000000003, 131.59999999999994, 128.00000000000003, 29.599999999999973, 103.4, 17.899999999999988, 18.7999999999999, -67.00000000000018, -28.299999999999763, 56.90000000000003, 119.89999999999986, 61.10000000000006, 36.800000000000054, 165.79999999999993, -196.60000000000025, 29.30000000000002, 20.299999999999955, 158.59999999999985, 48.2000000000001, 33.200000000000074, 94.6999999999999, 79.10000000000001, 139.39999999999966, 142.39999999999984, 66.8, 112.69999999999999, 39.50000000000008, 60.20000000000002, 69.20000000000006, 141.49999999999994, 38.000000000000064, 45.800000000000104, 94.69999999999985, 84.20000000000005, 74.00000000000007, 85.69999999999982, 166.6999999999998, 96.20000000000002, 71.30000000000004, 68.89999999999989, -145.90000000000012, 60.20000000000003, 127.99999999999997, 90.79999999999994, 97.3999999999997, 45.8, 105.80000000000005, 128.3, 143.29999999999998, 139.69999999999993, 73.70000000000002, -4.299999999999995, 38.3, 46.40000000000002, 68.29999999999998, 129.8, 41.30000000000001, 4.400000000000055, 132.79999999999995, 99.50000000000001, 129.5, 146.2999999999999, 84.19999999999996, 43.39999999999998, 40.10000000000008, 106.40000000000003, 101.29999999999995, 97.69999999999995, 79.09999999999997, 30.799999999999997, -63.400000000000034, 160.99999999999994, 128.29999999999998, -138.00000000000003, 61.70000000000004, 140.8999999999997, 129.49999999999994, 11.600000000000005, 133.9999999999998, 108.79999999999995, -47.20000000000003, 62.30000000000004, 144.79999999999998, 86.90000000000003, 110.59999999999997, 131.6, 156.79999999999995, 155.5999999999999], "policy_predator_policy_reward": [31.0, 8.0, 22.0, 29.0, 34.0, 49.0, 32.0, 40.0, 17.0, 44.0, 68.0, 78.0, 4.0, 6.0, 20.0, 21.0, 96.0, 16.0, 17.0, 16.0, 5.0, 4.0, 8.0, 26.0, 3.0, 2.0, 30.0, 9.0, 57.0, 35.0, 22.0, 7.0, 46.0, 27.0, 3.0, 6.0, 23.0, 30.0, 23.0, 13.0, 7.0, 62.0, 2.0, 39.0, 52.0, 15.0, 11.0, 3.0, 13.0, 10.0, 2.0, 0.0, 20.0, 32.0, 23.0, 25.0, 57.0, 26.0, 7.0, 30.0, 24.0, 20.0, 23.0, 10.0, 61.0, 69.0, 0.0, 79.0, 5.0, 18.0, 134.0, 123.0, 27.0, 21.0, 20.0, 30.0, 24.0, 21.0, 11.0, 75.0, 102.0, 108.0, 19.0, 37.0, 50.0, 40.0, 22.0, 16.0, 32.0, 12.0, 29.0, 43.0, 46.0, 2.0, 0.0, 1.0, 11.0, 16.0, 30.0, 27.0, 13.0, 1.0, 24.0, 33.0, 37.0, 11.0, 8.0, 83.0, 81.0, 83.0, 37.0, 52.0, 20.0, 23.0, 42.0, 45.0, 24.0, 18.0, 92.0, 11.0, 18.0, 42.0, 30.0, 30.0, 36.0, 26.0, 31.0, 119.0, 49.0, 48.0, 38.0, 10.0, 24.0, 16.0, 6.0, 6.0, 19.0, 41.0, 29.0, 44.0, 31.0, 28.0, 40.0, 0.0, 29.0, 21.0, 12.0, 5.0, 21.0, 27.0, 36.0, 28.0, 106.0, 30.0, 27.0, 30.0, 43.0, 6.0, 13.0, 25.0, 6.0, 9.0, 61.0, 66.0, 7.0, 65.0, 27.0, 10.0, 36.0, 70.0, 16.0, 9.0, 5.0, 10.0, 21.0, 18.0, 47.0, 0.0, 14.0, 31.0, 37.0, 7.0, 10.0, 74.0, 73.0, 72.0, 28.0, 25.0, 57.0, 36.0, 14.0, 21.0, 45.0, 36.0, 22.0, 33.0, 6.0, 9.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7710864583594426, "mean_inference_ms": 2.0144821393666423, "mean_action_processing_ms": 0.3276973674013807, "mean_env_wait_ms": 0.2551912683396562, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009000182151794434, "StateBufferConnector_ms": 0.003823399543762207, "ViewRequirementAgentConnector_ms": 0.1501082181930542}, "num_episodes": 22, "episode_return_max": 376.2, "episode_return_min": -60.10000000000008, "episode_return_mean": 208.75199999999984, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.33414283067657, "num_env_steps_trained_throughput_per_sec": 323.33414283067657, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 13066.203, "restore_workers_time_ms": 0.022, "training_step_time_ms": 13066.138, "sample_time_ms": 2232.117, "learn_time_ms": 10798.854, "learn_throughput": 370.41, "synch_weights_time_ms": 30.701}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-58-49", "timestamp": 1723647529, "time_this_iter_s": 12.434197902679443, "time_total_s": 697.4282212257385, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d3d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 697.4282212257385, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 54.16111111111112, "ram_util_percent": 81.79444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7310094946591312, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.105170851914341, "policy_loss": -0.0041815268650660835, "vf_loss": 8.106574530071683, "vf_explained_var": 0.030049852687845786, "kl": 0.009754876311871006, "entropy": 1.46553421859388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.331911184390386, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.916451649060325, "policy_loss": -0.004494422556655038, "vf_loss": 3.920412217750751, "vf_explained_var": 0.09965774590376193, "kl": 0.007118191607146119, "entropy": 0.7104562006299457, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 376.2, "episode_reward_min": -17.30000000000009, "episode_reward_mean": 212.2739999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -196.60000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.2, "predator_policy": 134.0}, "policy_reward_mean": {"prey_policy": 74.70699999999997, "predator_policy": 31.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [316.20000000000016, 322.90000000000003, 241.59999999999985, 185.1, 114.7999999999997, 18.300000000000008, 190.1999999999993, 376.2, 267.4999999999999, 275.49999999999983, 101.0999999999997, 139.9999999999996, 195.3, 174.9999999999994, 259.39999999999975, 50.29999999999997, 345.9, 176.99999999999997, 205.89999999999927, 272.0999999999998, 121.89999999999985, 143.70000000000007, 188.49999999999997, 261.9, 266.19999999999993, 261.9, 273.90000000000003, 229.5999999999998, 258.9999999999998, 237.79999999999941, 70.89999999999998, 291.39999999999986, 168.89999999999952, 237.0999999999998, 239.1999999999997, 167.9, 159.29999999999959, 250.1999999999996, 245.5999999999997, 244.5999999999998, 163.29999999999953, 54.799999999999876, 88.5999999999997, 240.9999999999996, 264.59999999999974, -17.30000000000009, 275.8999999999999, 129.3999999999996, 213.79999999999953, 293.8000000000008, 239.49999999999997, 172.69999999999968, 269.6999999999997, 123.79999999999939, 228.89999999999972, 176.69999999999985, 310.9000000000001, 204.1999999999997, 50.2999999999999, 275.7999999999996, 192.19999999999948, 272.0999999999997, 297.99999999999983, 196.39999999999984, 156.69999999999987, 235.09999999999985, 151.6999999999999, 257.29999999999984, 290.79999999999984, 166.59999999999965, 193.49999999999963, 243.9999999999997, 153.8999999999997, 181.5999999999999, 135.3, 255.59999999999948, 234.09999999999994, 277.80000000000007, 96.09999999999988, 286.69999999999993, 257.19999999999993, 324.40000000000043, 232.99999999999935, 266.7999999999994, 222.09999999999985, 235.49999999999997, 243.09999999999954, 290.10000000000014, 26.499999999999744, 154.59999999999962, 230.59999999999968, 189.09999999999997, 253.09999999999985, 312.40000000000003, 239.69999999999956, 246.69999999999973, 303.3000000000003, 202.99999999999974, 217.19999999999956, 193.2999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [140.9, 122.29999999999995, 151.7, 135.20000000000002, 74.0, 98.59999999999997, 77.29999999999998, 66.80000000000001, 27.79999999999998, 20.000000000000014, 7.399999999999965, -3.099999999999958, 20.000000000000014, 147.20000000000002, 189.2, 185.0, 107.29999999999998, 108.2, 101.29999999999998, 126.19999999999997, 22.700000000000056, -4.59999999999998, 71.89999999999998, 31.09999999999997, 34.70000000000009, 116.59999999999997, 20.000000000000014, 122.0, 119.89999999999989, 9.500000000000018, -48.700000000000074, 20.000000000000014, 173.89999999999998, 149.0, -76.00000000000006, -4.000000000000107, 36.200000000000145, 121.69999999999987, 66.5, 155.5999999999999, -3.099999999999958, 80.00000000000001, 136.99999999999994, -79.30000000000032, -156.70000000000002, 135.2, 54.20000000000001, 151.69999999999996, 145.6999999999999, 30.499999999999996, 89.90000000000003, 134.0, 146.59999999999982, 83.30000000000001, 48.80000000000001, 108.79999999999995, 173.29999999999987, 37.70000000000002, 145.99999999999991, 90.79999999999997, -34.59999999999999, 78.49999999999997, 93.80000000000004, 140.59999999999997, 134.9, 20.000000000000014, 75.80000000000001, 104.29999999999995, 164.29999999999993, 26.89999999999994, -82.60000000000028, 159.5, -65.8000000000003, 61.10000000000008, -2.7999999999999474, 163.99999999999986, 71.00000000000003, 131.59999999999994, 128.00000000000003, 29.599999999999973, 103.4, 17.899999999999988, 18.7999999999999, -67.00000000000018, -28.299999999999763, 56.90000000000003, 119.89999999999986, 61.10000000000006, 36.800000000000054, 165.79999999999993, -196.60000000000025, 29.30000000000002, 20.299999999999955, 158.59999999999985, 48.2000000000001, 33.200000000000074, 94.6999999999999, 79.10000000000001, 139.39999999999966, 142.39999999999984, 66.8, 112.69999999999999, 39.50000000000008, 60.20000000000002, 69.20000000000006, 141.49999999999994, 38.000000000000064, 45.800000000000104, 94.69999999999985, 84.20000000000005, 74.00000000000007, 85.69999999999982, 166.6999999999998, 96.20000000000002, 71.30000000000004, 68.89999999999989, -145.90000000000012, 60.20000000000003, 127.99999999999997, 90.79999999999994, 97.3999999999997, 45.8, 105.80000000000005, 128.3, 143.29999999999998, 139.69999999999993, 73.70000000000002, -4.299999999999995, 38.3, 46.40000000000002, 68.29999999999998, 129.8, 41.30000000000001, 4.400000000000055, 132.79999999999995, 99.50000000000001, 129.5, 146.2999999999999, 84.19999999999996, 43.39999999999998, 40.10000000000008, 106.40000000000003, 101.29999999999995, 97.69999999999995, 79.09999999999997, 30.799999999999997, -63.400000000000034, 160.99999999999994, 128.29999999999998, -138.00000000000003, 61.70000000000004, 140.8999999999997, 129.49999999999994, 11.600000000000005, 133.9999999999998, 108.79999999999995, -47.20000000000003, 62.30000000000004, 144.79999999999998, 86.90000000000003, 110.59999999999997, 131.6, 156.79999999999995, 155.5999999999999, 6.499999999999973, 180.49999999999997, 110.89999999999992, 128.89999999999978, -140.80000000000007, 152.89999999999992, 115.1, 40.39999999999999, 7.399999999999984, 145.69999999999996, 80.89999999999999, 162.19999999999987, 19.700000000000045, -155.2000000000001, 60.49999999999996, 46.100000000000094, 117.4999999999998, 67.10000000000005, -67.90000000000003, 163.99999999999997, 91.99999999999997, 115.10000000000002, 163.99999999999997, 121.39999999999993, 104.59999999999974, 76.10000000000002, 167.59999999999994, 55.10000000000002, 142.9999999999999, 146.29999999999998, -11.79999999999999, 120.79999999999981, 84.49999999999972, 82.69999999999996, 157.9999999999999, -21.700000000000003], "policy_predator_policy_reward": [23.0, 30.0, 23.0, 13.0, 7.0, 62.0, 2.0, 39.0, 52.0, 15.0, 11.0, 3.0, 13.0, 10.0, 2.0, 0.0, 20.0, 32.0, 23.0, 25.0, 57.0, 26.0, 7.0, 30.0, 24.0, 20.0, 23.0, 10.0, 61.0, 69.0, 0.0, 79.0, 5.0, 18.0, 134.0, 123.0, 27.0, 21.0, 20.0, 30.0, 24.0, 21.0, 11.0, 75.0, 102.0, 108.0, 19.0, 37.0, 50.0, 40.0, 22.0, 16.0, 32.0, 12.0, 29.0, 43.0, 46.0, 2.0, 0.0, 1.0, 11.0, 16.0, 30.0, 27.0, 13.0, 1.0, 24.0, 33.0, 37.0, 11.0, 8.0, 83.0, 81.0, 83.0, 37.0, 52.0, 20.0, 23.0, 42.0, 45.0, 24.0, 18.0, 92.0, 11.0, 18.0, 42.0, 30.0, 30.0, 36.0, 26.0, 31.0, 119.0, 49.0, 48.0, 38.0, 10.0, 24.0, 16.0, 6.0, 6.0, 19.0, 41.0, 29.0, 44.0, 31.0, 28.0, 40.0, 0.0, 29.0, 21.0, 12.0, 5.0, 21.0, 27.0, 36.0, 28.0, 106.0, 30.0, 27.0, 30.0, 43.0, 6.0, 13.0, 25.0, 6.0, 9.0, 61.0, 66.0, 7.0, 65.0, 27.0, 10.0, 36.0, 70.0, 16.0, 9.0, 5.0, 10.0, 21.0, 18.0, 47.0, 0.0, 14.0, 31.0, 37.0, 7.0, 10.0, 74.0, 73.0, 72.0, 28.0, 25.0, 57.0, 36.0, 14.0, 21.0, 45.0, 36.0, 22.0, 33.0, 6.0, 9.0, 2.0, 10.0, 17.0, 29.0, 18.0, 9.0, 107.0, 103.0, 28.0, 52.0, 47.0, 43.0, 27.0, 20.0, 49.0, 113.0, 23.0, 25.0, 32.0, 14.0, 15.0, 78.0, 26.0, 20.0, 5.0, 22.0, 24.0, 35.0, 24.0, 0.0, 13.0, 1.0, 42.0, 52.0, 27.0, 23.0, 17.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7729990173128385, "mean_inference_ms": 2.019696102365256, "mean_action_processing_ms": 0.32896276869332736, "mean_env_wait_ms": 0.25605235838309925, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00895678997039795, "StateBufferConnector_ms": 0.003935098648071289, "ViewRequirementAgentConnector_ms": 0.13950598239898682}, "num_episodes": 18, "episode_return_max": 376.2, "episode_return_min": -17.30000000000009, "episode_return_mean": 212.2739999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.09585389912064, "num_env_steps_trained_throughput_per_sec": 320.09585389912064, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 13050.582, "restore_workers_time_ms": 0.022, "training_step_time_ms": 13050.516, "sample_time_ms": 2246.598, "learn_time_ms": 10768.3, "learn_throughput": 371.461, "synch_weights_time_ms": 31.242}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-59-01", "timestamp": 1723647541, "time_this_iter_s": 12.51077914237976, "time_total_s": 709.9390003681183, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede2f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 709.9390003681183, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 50.205555555555556, "ram_util_percent": 82.26111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6516761855473594, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.720647515443267, "policy_loss": -0.00651465847893623, "vf_loss": 7.723467919687746, "vf_explained_var": -0.00727129821424131, "kl": 0.012972887511884298, "entropy": 1.4260699352890096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8629150849486154, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.872387629022043, "policy_loss": -0.008160631050030509, "vf_loss": 2.8797831184649594, "vf_explained_var": 0.06975645416628116, "kl": 0.010201832162357956, "entropy": 0.7549795679629795, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 355.69999999999993, "episode_reward_min": -17.30000000000009, "episode_reward_mean": 218.38399999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -196.60000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.29999999999998, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": 78.92199999999997, "predator_policy": 30.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [261.9, 266.19999999999993, 261.9, 273.90000000000003, 229.5999999999998, 258.9999999999998, 237.79999999999941, 70.89999999999998, 291.39999999999986, 168.89999999999952, 237.0999999999998, 239.1999999999997, 167.9, 159.29999999999959, 250.1999999999996, 245.5999999999997, 244.5999999999998, 163.29999999999953, 54.799999999999876, 88.5999999999997, 240.9999999999996, 264.59999999999974, -17.30000000000009, 275.8999999999999, 129.3999999999996, 213.79999999999953, 293.8000000000008, 239.49999999999997, 172.69999999999968, 269.6999999999997, 123.79999999999939, 228.89999999999972, 176.69999999999985, 310.9000000000001, 204.1999999999997, 50.2999999999999, 275.7999999999996, 192.19999999999948, 272.0999999999997, 297.99999999999983, 196.39999999999984, 156.69999999999987, 235.09999999999985, 151.6999999999999, 257.29999999999984, 290.79999999999984, 166.59999999999965, 193.49999999999963, 243.9999999999997, 153.8999999999997, 181.5999999999999, 135.3, 255.59999999999948, 234.09999999999994, 277.80000000000007, 96.09999999999988, 286.69999999999993, 257.19999999999993, 324.40000000000043, 232.99999999999935, 266.7999999999994, 222.09999999999985, 235.49999999999997, 243.09999999999954, 290.10000000000014, 26.499999999999744, 154.59999999999962, 230.59999999999968, 189.09999999999997, 253.09999999999985, 312.40000000000003, 239.69999999999956, 246.69999999999973, 303.3000000000003, 202.99999999999974, 217.19999999999956, 193.2999999999998, 216.39999999999935, 245.2999999999997, 226.9999999999999, 355.69999999999993, 261.6999999999999, 248.09999999999945, 88.19999999999993, 308.2999999999996, 310.09999999999974, 212.89999999999975, 220.19999999999987, 206.99999999999983, 244.89999999999975, 239.09999999999968, 253.39999999999966, 130.1999999999999, 242.8999999999997, 174.09999999999965, 252.4999999999999, 235.5999999999999, 74.10000000000011, 270.4, 277.29999999999984], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [54.20000000000001, 151.69999999999996, 145.6999999999999, 30.499999999999996, 89.90000000000003, 134.0, 146.59999999999982, 83.30000000000001, 48.80000000000001, 108.79999999999995, 173.29999999999987, 37.70000000000002, 145.99999999999991, 90.79999999999997, -34.59999999999999, 78.49999999999997, 93.80000000000004, 140.59999999999997, 134.9, 20.000000000000014, 75.80000000000001, 104.29999999999995, 164.29999999999993, 26.89999999999994, -82.60000000000028, 159.5, -65.8000000000003, 61.10000000000008, -2.7999999999999474, 163.99999999999986, 71.00000000000003, 131.59999999999994, 128.00000000000003, 29.599999999999973, 103.4, 17.899999999999988, 18.7999999999999, -67.00000000000018, -28.299999999999763, 56.90000000000003, 119.89999999999986, 61.10000000000006, 36.800000000000054, 165.79999999999993, -196.60000000000025, 29.30000000000002, 20.299999999999955, 158.59999999999985, 48.2000000000001, 33.200000000000074, 94.6999999999999, 79.10000000000001, 139.39999999999966, 142.39999999999984, 66.8, 112.69999999999999, 39.50000000000008, 60.20000000000002, 69.20000000000006, 141.49999999999994, 38.000000000000064, 45.800000000000104, 94.69999999999985, 84.20000000000005, 74.00000000000007, 85.69999999999982, 166.6999999999998, 96.20000000000002, 71.30000000000004, 68.89999999999989, -145.90000000000012, 60.20000000000003, 127.99999999999997, 90.79999999999994, 97.3999999999997, 45.8, 105.80000000000005, 128.3, 143.29999999999998, 139.69999999999993, 73.70000000000002, -4.299999999999995, 38.3, 46.40000000000002, 68.29999999999998, 129.8, 41.30000000000001, 4.400000000000055, 132.79999999999995, 99.50000000000001, 129.5, 146.2999999999999, 84.19999999999996, 43.39999999999998, 40.10000000000008, 106.40000000000003, 101.29999999999995, 97.69999999999995, 79.09999999999997, 30.799999999999997, -63.400000000000034, 160.99999999999994, 128.29999999999998, -138.00000000000003, 61.70000000000004, 140.8999999999997, 129.49999999999994, 11.600000000000005, 133.9999999999998, 108.79999999999995, -47.20000000000003, 62.30000000000004, 144.79999999999998, 86.90000000000003, 110.59999999999997, 131.6, 156.79999999999995, 155.5999999999999, 6.499999999999973, 180.49999999999997, 110.89999999999992, 128.89999999999978, -140.80000000000007, 152.89999999999992, 115.1, 40.39999999999999, 7.399999999999984, 145.69999999999996, 80.89999999999999, 162.19999999999987, 19.700000000000045, -155.2000000000001, 60.49999999999996, 46.100000000000094, 117.4999999999998, 67.10000000000005, -67.90000000000003, 163.99999999999997, 91.99999999999997, 115.10000000000002, 163.99999999999997, 121.39999999999993, 104.59999999999974, 76.10000000000002, 167.59999999999994, 55.10000000000002, 142.9999999999999, 146.29999999999998, -11.79999999999999, 120.79999999999981, 84.49999999999972, 82.69999999999996, 157.9999999999999, -21.700000000000003, 128.8999999999998, 45.50000000000009, 63.500000000000014, 108.79999999999976, 52.39999999999999, 95.60000000000004, 169.39999999999998, 185.29999999999998, 81.49999999999989, 135.19999999999987, 25.700000000000077, 160.39999999999995, -7.9000000000000625, -7.900000000000015, 167.2999999999999, 136.9999999999998, 121.40000000000003, 166.69999999999996, 120.79999999999994, 76.10000000000011, 32.6, 107.60000000000002, 60.200000000000024, 87.80000000000001, 26.600000000000037, 155.29999999999987, 38.89999999999999, 120.19999999999992, 94.99999999999969, 118.39999999999998, 89.29999999999997, -102.10000000000011, 138.7999999999999, 82.09999999999988, 81.50000000000001, 44.600000000000065, 67.39999999999996, 127.09999999999994, 55.4, 129.19999999999996, 69.8000000000001, -90.70000000000007, 129.79999999999978, 62.600000000000016, 141.2, 103.10000000000002], "policy_predator_policy_reward": [19.0, 37.0, 50.0, 40.0, 22.0, 16.0, 32.0, 12.0, 29.0, 43.0, 46.0, 2.0, 0.0, 1.0, 11.0, 16.0, 30.0, 27.0, 13.0, 1.0, 24.0, 33.0, 37.0, 11.0, 8.0, 83.0, 81.0, 83.0, 37.0, 52.0, 20.0, 23.0, 42.0, 45.0, 24.0, 18.0, 92.0, 11.0, 18.0, 42.0, 30.0, 30.0, 36.0, 26.0, 31.0, 119.0, 49.0, 48.0, 38.0, 10.0, 24.0, 16.0, 6.0, 6.0, 19.0, 41.0, 29.0, 44.0, 31.0, 28.0, 40.0, 0.0, 29.0, 21.0, 12.0, 5.0, 21.0, 27.0, 36.0, 28.0, 106.0, 30.0, 27.0, 30.0, 43.0, 6.0, 13.0, 25.0, 6.0, 9.0, 61.0, 66.0, 7.0, 65.0, 27.0, 10.0, 36.0, 70.0, 16.0, 9.0, 5.0, 10.0, 21.0, 18.0, 47.0, 0.0, 14.0, 31.0, 37.0, 7.0, 10.0, 74.0, 73.0, 72.0, 28.0, 25.0, 57.0, 36.0, 14.0, 21.0, 45.0, 36.0, 22.0, 33.0, 6.0, 9.0, 2.0, 10.0, 17.0, 29.0, 18.0, 9.0, 107.0, 103.0, 28.0, 52.0, 47.0, 43.0, 27.0, 20.0, 49.0, 113.0, 23.0, 25.0, 32.0, 14.0, 15.0, 78.0, 26.0, 20.0, 5.0, 22.0, 24.0, 35.0, 24.0, 0.0, 13.0, 1.0, 42.0, 52.0, 27.0, 23.0, 17.0, 40.0, 13.0, 29.0, 50.0, 23.0, 30.0, 49.0, 1.0, 0.0, 24.0, 21.0, 34.0, 28.0, 12.0, 92.0, 0.0, 4.0, 16.0, 6.0, 2.0, 14.0, 34.0, 46.0, 57.0, 2.0, 37.0, 26.0, 32.0, 48.0, 8.0, 32.0, 65.0, 78.0, 18.0, 4.0, 38.0, 10.0, 21.0, 37.0, 36.0, 15.0, 0.0, 95.0, 39.0, 39.0, 32.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7743446164189548, "mean_inference_ms": 2.025341623254297, "mean_action_processing_ms": 0.3292300485484852, "mean_env_wait_ms": 0.2566997504179253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007604479789733887, "StateBufferConnector_ms": 0.004118919372558594, "ViewRequirementAgentConnector_ms": 0.16283190250396729}, "num_episodes": 23, "episode_return_max": 355.69999999999993, "episode_return_min": -17.30000000000009, "episode_return_mean": 218.38399999999976, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.37300457076674, "num_env_steps_trained_throughput_per_sec": 321.37300457076674, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 12727.427, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12727.367, "sample_time_ms": 2020.031, "learn_time_ms": 10671.303, "learn_throughput": 374.837, "synch_weights_time_ms": 32.051}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-59-14", "timestamp": 1723647554, "time_this_iter_s": 12.502018928527832, "time_total_s": 722.4410192966461, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee07280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 722.4410192966461, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 49.80555555555556, "ram_util_percent": 81.8888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6671014187197204, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.298432397085523, "policy_loss": -0.0010447373837922458, "vf_loss": 7.297013904682543, "vf_explained_var": 0.028987364289621828, "kl": 0.008650035972110537, "entropy": 1.4731561828542639, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0348276570991235, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.818772454520382, "policy_loss": -0.0034006513354600107, "vf_loss": 1.821529433020839, "vf_explained_var": 0.05267586244477166, "kl": 0.008582235871148494, "entropy": 0.71030896034821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 355.69999999999993, "episode_reward_min": -17.30000000000009, "episode_reward_mean": 224.35499999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -196.60000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.29999999999998, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": 83.62749999999997, "predator_policy": 28.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.799999999999876, 88.5999999999997, 240.9999999999996, 264.59999999999974, -17.30000000000009, 275.8999999999999, 129.3999999999996, 213.79999999999953, 293.8000000000008, 239.49999999999997, 172.69999999999968, 269.6999999999997, 123.79999999999939, 228.89999999999972, 176.69999999999985, 310.9000000000001, 204.1999999999997, 50.2999999999999, 275.7999999999996, 192.19999999999948, 272.0999999999997, 297.99999999999983, 196.39999999999984, 156.69999999999987, 235.09999999999985, 151.6999999999999, 257.29999999999984, 290.79999999999984, 166.59999999999965, 193.49999999999963, 243.9999999999997, 153.8999999999997, 181.5999999999999, 135.3, 255.59999999999948, 234.09999999999994, 277.80000000000007, 96.09999999999988, 286.69999999999993, 257.19999999999993, 324.40000000000043, 232.99999999999935, 266.7999999999994, 222.09999999999985, 235.49999999999997, 243.09999999999954, 290.10000000000014, 26.499999999999744, 154.59999999999962, 230.59999999999968, 189.09999999999997, 253.09999999999985, 312.40000000000003, 239.69999999999956, 246.69999999999973, 303.3000000000003, 202.99999999999974, 217.19999999999956, 193.2999999999998, 216.39999999999935, 245.2999999999997, 226.9999999999999, 355.69999999999993, 261.6999999999999, 248.09999999999945, 88.19999999999993, 308.2999999999996, 310.09999999999974, 212.89999999999975, 220.19999999999987, 206.99999999999983, 244.89999999999975, 239.09999999999968, 253.39999999999966, 130.1999999999999, 242.8999999999997, 174.09999999999965, 252.4999999999999, 235.5999999999999, 74.10000000000011, 270.4, 277.29999999999984, 303.4999999999999, 320.5000000000002, 272.39999999999986, 63.499999999999886, 234.19999999999962, 194.6, 311.6999999999998, 222.70000000000005, 299.6999999999998, 320.40000000000043, 119.89999999999964, 250.89999999999975, 336.0000000000003, 305.9000000000001, 264.5999999999998, 164.19999999999962, 328.7000000000001, 312.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [18.7999999999999, -67.00000000000018, -28.299999999999763, 56.90000000000003, 119.89999999999986, 61.10000000000006, 36.800000000000054, 165.79999999999993, -196.60000000000025, 29.30000000000002, 20.299999999999955, 158.59999999999985, 48.2000000000001, 33.200000000000074, 94.6999999999999, 79.10000000000001, 139.39999999999966, 142.39999999999984, 66.8, 112.69999999999999, 39.50000000000008, 60.20000000000002, 69.20000000000006, 141.49999999999994, 38.000000000000064, 45.800000000000104, 94.69999999999985, 84.20000000000005, 74.00000000000007, 85.69999999999982, 166.6999999999998, 96.20000000000002, 71.30000000000004, 68.89999999999989, -145.90000000000012, 60.20000000000003, 127.99999999999997, 90.79999999999994, 97.3999999999997, 45.8, 105.80000000000005, 128.3, 143.29999999999998, 139.69999999999993, 73.70000000000002, -4.299999999999995, 38.3, 46.40000000000002, 68.29999999999998, 129.8, 41.30000000000001, 4.400000000000055, 132.79999999999995, 99.50000000000001, 129.5, 146.2999999999999, 84.19999999999996, 43.39999999999998, 40.10000000000008, 106.40000000000003, 101.29999999999995, 97.69999999999995, 79.09999999999997, 30.799999999999997, -63.400000000000034, 160.99999999999994, 128.29999999999998, -138.00000000000003, 61.70000000000004, 140.8999999999997, 129.49999999999994, 11.600000000000005, 133.9999999999998, 108.79999999999995, -47.20000000000003, 62.30000000000004, 144.79999999999998, 86.90000000000003, 110.59999999999997, 131.6, 156.79999999999995, 155.5999999999999, 6.499999999999973, 180.49999999999997, 110.89999999999992, 128.89999999999978, -140.80000000000007, 152.89999999999992, 115.1, 40.39999999999999, 7.399999999999984, 145.69999999999996, 80.89999999999999, 162.19999999999987, 19.700000000000045, -155.2000000000001, 60.49999999999996, 46.100000000000094, 117.4999999999998, 67.10000000000005, -67.90000000000003, 163.99999999999997, 91.99999999999997, 115.10000000000002, 163.99999999999997, 121.39999999999993, 104.59999999999974, 76.10000000000002, 167.59999999999994, 55.10000000000002, 142.9999999999999, 146.29999999999998, -11.79999999999999, 120.79999999999981, 84.49999999999972, 82.69999999999996, 157.9999999999999, -21.700000000000003, 128.8999999999998, 45.50000000000009, 63.500000000000014, 108.79999999999976, 52.39999999999999, 95.60000000000004, 169.39999999999998, 185.29999999999998, 81.49999999999989, 135.19999999999987, 25.700000000000077, 160.39999999999995, -7.9000000000000625, -7.900000000000015, 167.2999999999999, 136.9999999999998, 121.40000000000003, 166.69999999999996, 120.79999999999994, 76.10000000000011, 32.6, 107.60000000000002, 60.200000000000024, 87.80000000000001, 26.600000000000037, 155.29999999999987, 38.89999999999999, 120.19999999999992, 94.99999999999969, 118.39999999999998, 89.29999999999997, -102.10000000000011, 138.7999999999999, 82.09999999999988, 81.50000000000001, 44.600000000000065, 67.39999999999996, 127.09999999999994, 55.4, 129.19999999999996, 69.8000000000001, -90.70000000000007, 129.79999999999978, 62.600000000000016, 141.2, 103.10000000000002, 59.60000000000002, 179.89999999999995, 175.7, 141.79999999999995, 126.49999999999997, 131.9, -75.10000000000002, 47.60000000000006, 106.69999999999993, 81.50000000000006, 137.29999999999998, -21.700000000000117, 101.60000000000004, 142.0999999999999, 73.69999999999985, 97.99999999999997, 148.69999999999982, 145.99999999999994, 139.6999999999999, 157.69999999999987, -89.50000000000001, 145.39999999999992, 108.5, 121.40000000000003, 156.49999999999991, 168.49999999999986, 127.09999999999988, 168.79999999999993, 81.80000000000003, 132.79999999999987, 70.70000000000002, 42.49999999999998, 114.5, 180.19999999999996, 154.69999999999993, 118.7], "policy_predator_policy_reward": [92.0, 11.0, 18.0, 42.0, 30.0, 30.0, 36.0, 26.0, 31.0, 119.0, 49.0, 48.0, 38.0, 10.0, 24.0, 16.0, 6.0, 6.0, 19.0, 41.0, 29.0, 44.0, 31.0, 28.0, 40.0, 0.0, 29.0, 21.0, 12.0, 5.0, 21.0, 27.0, 36.0, 28.0, 106.0, 30.0, 27.0, 30.0, 43.0, 6.0, 13.0, 25.0, 6.0, 9.0, 61.0, 66.0, 7.0, 65.0, 27.0, 10.0, 36.0, 70.0, 16.0, 9.0, 5.0, 10.0, 21.0, 18.0, 47.0, 0.0, 14.0, 31.0, 37.0, 7.0, 10.0, 74.0, 73.0, 72.0, 28.0, 25.0, 57.0, 36.0, 14.0, 21.0, 45.0, 36.0, 22.0, 33.0, 6.0, 9.0, 2.0, 10.0, 17.0, 29.0, 18.0, 9.0, 107.0, 103.0, 28.0, 52.0, 47.0, 43.0, 27.0, 20.0, 49.0, 113.0, 23.0, 25.0, 32.0, 14.0, 15.0, 78.0, 26.0, 20.0, 5.0, 22.0, 24.0, 35.0, 24.0, 0.0, 13.0, 1.0, 42.0, 52.0, 27.0, 23.0, 17.0, 40.0, 13.0, 29.0, 50.0, 23.0, 30.0, 49.0, 1.0, 0.0, 24.0, 21.0, 34.0, 28.0, 12.0, 92.0, 0.0, 4.0, 16.0, 6.0, 2.0, 14.0, 34.0, 46.0, 57.0, 2.0, 37.0, 26.0, 32.0, 48.0, 8.0, 32.0, 65.0, 78.0, 18.0, 4.0, 38.0, 10.0, 21.0, 37.0, 36.0, 15.0, 0.0, 95.0, 39.0, 39.0, 32.0, 1.0, 33.0, 31.0, 1.0, 2.0, 8.0, 6.0, 91.0, 0.0, 23.0, 23.0, 7.0, 72.0, 37.0, 31.0, 20.0, 31.0, 3.0, 2.0, 11.0, 12.0, 53.0, 11.0, 8.0, 13.0, 10.0, 1.0, 7.0, 3.0, 28.0, 22.0, 12.0, 39.0, 21.0, 13.0, 22.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7754627344458342, "mean_inference_ms": 2.0294927144756545, "mean_action_processing_ms": 0.3295675927123154, "mean_env_wait_ms": 0.2573294716129987, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007880568504333496, "StateBufferConnector_ms": 0.004099607467651367, "ViewRequirementAgentConnector_ms": 0.16475999355316162}, "num_episodes": 18, "episode_return_max": 355.69999999999993, "episode_return_min": -17.30000000000009, "episode_return_mean": 224.35499999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.78318366861635, "num_env_steps_trained_throughput_per_sec": 322.78318366861635, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 12651.575, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12651.515, "sample_time_ms": 1986.371, "learn_time_ms": 10626.734, "learn_throughput": 376.409, "synch_weights_time_ms": 34.466}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-59-26", "timestamp": 1723647566, "time_this_iter_s": 12.422675848007202, "time_total_s": 734.8636951446533, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b1eee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 734.8636951446533, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 47.311764705882354, "ram_util_percent": 82.25294117647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2724203386950115, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.702505879175096, "policy_loss": -0.0031188308342640835, "vf_loss": 7.702629762225681, "vf_explained_var": 0.09789790173687002, "kl": 0.010517274357849245, "entropy": 1.5032184814649916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3866756425963507, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8434225537789564, "policy_loss": -0.004555284589893682, "vf_loss": 3.847345438205376, "vf_explained_var": 0.033664269926686766, "kl": 0.008431981140869125, "entropy": 0.7374383969281716, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 355.69999999999993, "episode_reward_min": 2.8999999999999813, "episode_reward_mean": 238.41599999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -242.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.29999999999998, "predator_policy": 138.0}, "policy_reward_mean": {"prey_policy": 91.52799999999996, "predator_policy": 27.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [275.7999999999996, 192.19999999999948, 272.0999999999997, 297.99999999999983, 196.39999999999984, 156.69999999999987, 235.09999999999985, 151.6999999999999, 257.29999999999984, 290.79999999999984, 166.59999999999965, 193.49999999999963, 243.9999999999997, 153.8999999999997, 181.5999999999999, 135.3, 255.59999999999948, 234.09999999999994, 277.80000000000007, 96.09999999999988, 286.69999999999993, 257.19999999999993, 324.40000000000043, 232.99999999999935, 266.7999999999994, 222.09999999999985, 235.49999999999997, 243.09999999999954, 290.10000000000014, 26.499999999999744, 154.59999999999962, 230.59999999999968, 189.09999999999997, 253.09999999999985, 312.40000000000003, 239.69999999999956, 246.69999999999973, 303.3000000000003, 202.99999999999974, 217.19999999999956, 193.2999999999998, 216.39999999999935, 245.2999999999997, 226.9999999999999, 355.69999999999993, 261.6999999999999, 248.09999999999945, 88.19999999999993, 308.2999999999996, 310.09999999999974, 212.89999999999975, 220.19999999999987, 206.99999999999983, 244.89999999999975, 239.09999999999968, 253.39999999999966, 130.1999999999999, 242.8999999999997, 174.09999999999965, 252.4999999999999, 235.5999999999999, 74.10000000000011, 270.4, 277.29999999999984, 303.4999999999999, 320.5000000000002, 272.39999999999986, 63.499999999999886, 234.19999999999962, 194.6, 311.6999999999998, 222.70000000000005, 299.6999999999998, 320.40000000000043, 119.89999999999964, 250.89999999999975, 336.0000000000003, 305.9000000000001, 264.5999999999998, 164.19999999999962, 328.7000000000001, 312.4, 260.9999999999995, 303.20000000000005, 271.9999999999998, 283.20000000000005, 270.0999999999998, 243.69999999999982, 299.70000000000005, 313.5000000000001, 247.59999999999985, 315.89999999999986, 282.9999999999999, 330.2000000000003, 303.29999999999995, 212.9999999999998, 273.20000000000005, 191.5999999999998, 320.30000000000007, 2.8999999999999813], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [127.99999999999997, 90.79999999999994, 97.3999999999997, 45.8, 105.80000000000005, 128.3, 143.29999999999998, 139.69999999999993, 73.70000000000002, -4.299999999999995, 38.3, 46.40000000000002, 68.29999999999998, 129.8, 41.30000000000001, 4.400000000000055, 132.79999999999995, 99.50000000000001, 129.5, 146.2999999999999, 84.19999999999996, 43.39999999999998, 40.10000000000008, 106.40000000000003, 101.29999999999995, 97.69999999999995, 79.09999999999997, 30.799999999999997, -63.400000000000034, 160.99999999999994, 128.29999999999998, -138.00000000000003, 61.70000000000004, 140.8999999999997, 129.49999999999994, 11.600000000000005, 133.9999999999998, 108.79999999999995, -47.20000000000003, 62.30000000000004, 144.79999999999998, 86.90000000000003, 110.59999999999997, 131.6, 156.79999999999995, 155.5999999999999, 6.499999999999973, 180.49999999999997, 110.89999999999992, 128.89999999999978, -140.80000000000007, 152.89999999999992, 115.1, 40.39999999999999, 7.399999999999984, 145.69999999999996, 80.89999999999999, 162.19999999999987, 19.700000000000045, -155.2000000000001, 60.49999999999996, 46.100000000000094, 117.4999999999998, 67.10000000000005, -67.90000000000003, 163.99999999999997, 91.99999999999997, 115.10000000000002, 163.99999999999997, 121.39999999999993, 104.59999999999974, 76.10000000000002, 167.59999999999994, 55.10000000000002, 142.9999999999999, 146.29999999999998, -11.79999999999999, 120.79999999999981, 84.49999999999972, 82.69999999999996, 157.9999999999999, -21.700000000000003, 128.8999999999998, 45.50000000000009, 63.500000000000014, 108.79999999999976, 52.39999999999999, 95.60000000000004, 169.39999999999998, 185.29999999999998, 81.49999999999989, 135.19999999999987, 25.700000000000077, 160.39999999999995, -7.9000000000000625, -7.900000000000015, 167.2999999999999, 136.9999999999998, 121.40000000000003, 166.69999999999996, 120.79999999999994, 76.10000000000011, 32.6, 107.60000000000002, 60.200000000000024, 87.80000000000001, 26.600000000000037, 155.29999999999987, 38.89999999999999, 120.19999999999992, 94.99999999999969, 118.39999999999998, 89.29999999999997, -102.10000000000011, 138.7999999999999, 82.09999999999988, 81.50000000000001, 44.600000000000065, 67.39999999999996, 127.09999999999994, 55.4, 129.19999999999996, 69.8000000000001, -90.70000000000007, 129.79999999999978, 62.600000000000016, 141.2, 103.10000000000002, 59.60000000000002, 179.89999999999995, 175.7, 141.79999999999995, 126.49999999999997, 131.9, -75.10000000000002, 47.60000000000006, 106.69999999999993, 81.50000000000006, 137.29999999999998, -21.700000000000117, 101.60000000000004, 142.0999999999999, 73.69999999999985, 97.99999999999997, 148.69999999999982, 145.99999999999994, 139.6999999999999, 157.69999999999987, -89.50000000000001, 145.39999999999992, 108.5, 121.40000000000003, 156.49999999999991, 168.49999999999986, 127.09999999999988, 168.79999999999993, 81.80000000000003, 132.79999999999987, 70.70000000000002, 42.49999999999998, 114.5, 180.19999999999996, 154.69999999999993, 118.7, 115.69999999999985, 119.29999999999961, 87.50000000000001, 178.7, 132.49999999999991, 117.49999999999991, 117.19999999999999, 131.0, 149.89999999999995, 60.20000000000004, 148.39999999999998, 47.300000000000026, 154.7, 100.99999999999994, 153.49999999999986, 113.0, 95.00000000000009, 104.59999999999998, 151.09999999999988, 144.79999999999995, 141.79999999999995, 129.19999999999996, 164.59999999999997, 158.59999999999994, 146.6, 148.69999999999996, -181.00000000000006, 148.99999999999983, 168.19999999999993, -4.00000000000006, 97.10000000000002, 48.50000000000003, 135.79999999999995, 159.49999999999983, 79.39999999999992, -242.5], "policy_predator_policy_reward": [27.0, 30.0, 43.0, 6.0, 13.0, 25.0, 6.0, 9.0, 61.0, 66.0, 7.0, 65.0, 27.0, 10.0, 36.0, 70.0, 16.0, 9.0, 5.0, 10.0, 21.0, 18.0, 47.0, 0.0, 14.0, 31.0, 37.0, 7.0, 10.0, 74.0, 73.0, 72.0, 28.0, 25.0, 57.0, 36.0, 14.0, 21.0, 45.0, 36.0, 22.0, 33.0, 6.0, 9.0, 2.0, 10.0, 17.0, 29.0, 18.0, 9.0, 107.0, 103.0, 28.0, 52.0, 47.0, 43.0, 27.0, 20.0, 49.0, 113.0, 23.0, 25.0, 32.0, 14.0, 15.0, 78.0, 26.0, 20.0, 5.0, 22.0, 24.0, 35.0, 24.0, 0.0, 13.0, 1.0, 42.0, 52.0, 27.0, 23.0, 17.0, 40.0, 13.0, 29.0, 50.0, 23.0, 30.0, 49.0, 1.0, 0.0, 24.0, 21.0, 34.0, 28.0, 12.0, 92.0, 0.0, 4.0, 16.0, 6.0, 2.0, 14.0, 34.0, 46.0, 57.0, 2.0, 37.0, 26.0, 32.0, 48.0, 8.0, 32.0, 65.0, 78.0, 18.0, 4.0, 38.0, 10.0, 21.0, 37.0, 36.0, 15.0, 0.0, 95.0, 39.0, 39.0, 32.0, 1.0, 33.0, 31.0, 1.0, 2.0, 8.0, 6.0, 91.0, 0.0, 23.0, 23.0, 7.0, 72.0, 37.0, 31.0, 20.0, 31.0, 3.0, 2.0, 11.0, 12.0, 53.0, 11.0, 8.0, 13.0, 10.0, 1.0, 7.0, 3.0, 28.0, 22.0, 12.0, 39.0, 21.0, 13.0, 22.0, 17.0, 19.0, 7.0, 4.0, 33.0, 20.0, 2.0, 11.0, 24.0, 26.0, 34.0, 40.0, 8.0, 21.0, 23.0, 22.0, 25.0, 29.0, 19.0, 8.0, 12.0, 4.0, 8.0, 1.0, 6.0, 5.0, 3.0, 126.0, 119.0, 58.0, 51.0, 38.0, 8.0, 16.0, 9.0, 28.0, 138.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.777002602073359, "mean_inference_ms": 2.0346234346711416, "mean_action_processing_ms": 0.33007727722199937, "mean_env_wait_ms": 0.25803516941330235, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007956504821777344, "StateBufferConnector_ms": 0.004172801971435547, "ViewRequirementAgentConnector_ms": 0.17499268054962158}, "num_episodes": 18, "episode_return_max": 355.69999999999993, "episode_return_min": 2.8999999999999813, "episode_return_mean": 238.41599999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.0038070139767, "num_env_steps_trained_throughput_per_sec": 323.0038070139767, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 12645.122, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12645.061, "sample_time_ms": 1955.115, "learn_time_ms": 10652.727, "learn_throughput": 375.491, "synch_weights_time_ms": 33.161}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-59-39", "timestamp": 1723647579, "time_this_iter_s": 12.439847946166992, "time_total_s": 747.3035430908203, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee071f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 747.3035430908203, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 48.9388888888889, "ram_util_percent": 82.06111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2284842774350806, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.431625746166896, "policy_loss": -0.0036603862977778864, "vf_loss": 8.433679664702643, "vf_explained_var": 0.04862208101484511, "kl": 0.005641338874329734, "entropy": 1.460142093045371, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.514487311322853, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.750987251725777, "policy_loss": -0.008169826251644365, "vf_loss": 4.758159790341816, "vf_explained_var": 0.028116045710901736, "kl": 0.013297080233301062, "entropy": 0.7856857261329732, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 355.69999999999993, "episode_reward_min": -138.39999999999998, "episode_reward_mean": 223.35799999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.29999999999998, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 79.97899999999996, "predator_policy": 31.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [324.40000000000043, 232.99999999999935, 266.7999999999994, 222.09999999999985, 235.49999999999997, 243.09999999999954, 290.10000000000014, 26.499999999999744, 154.59999999999962, 230.59999999999968, 189.09999999999997, 253.09999999999985, 312.40000000000003, 239.69999999999956, 246.69999999999973, 303.3000000000003, 202.99999999999974, 217.19999999999956, 193.2999999999998, 216.39999999999935, 245.2999999999997, 226.9999999999999, 355.69999999999993, 261.6999999999999, 248.09999999999945, 88.19999999999993, 308.2999999999996, 310.09999999999974, 212.89999999999975, 220.19999999999987, 206.99999999999983, 244.89999999999975, 239.09999999999968, 253.39999999999966, 130.1999999999999, 242.8999999999997, 174.09999999999965, 252.4999999999999, 235.5999999999999, 74.10000000000011, 270.4, 277.29999999999984, 303.4999999999999, 320.5000000000002, 272.39999999999986, 63.499999999999886, 234.19999999999962, 194.6, 311.6999999999998, 222.70000000000005, 299.6999999999998, 320.40000000000043, 119.89999999999964, 250.89999999999975, 336.0000000000003, 305.9000000000001, 264.5999999999998, 164.19999999999962, 328.7000000000001, 312.4, 260.9999999999995, 303.20000000000005, 271.9999999999998, 283.20000000000005, 270.0999999999998, 243.69999999999982, 299.70000000000005, 313.5000000000001, 247.59999999999985, 315.89999999999986, 282.9999999999999, 330.2000000000003, 303.29999999999995, 212.9999999999998, 273.20000000000005, 191.5999999999998, 320.30000000000007, 2.8999999999999813, 266.49999999999983, 301.59999999999974, 72.09999999999957, -84.10000000000022, 47.60000000000001, 41.999999999999865, 140.8999999999999, 189.99999999999918, 176.19999999999993, 134.79999999999993, 201.69999999999996, 242.1999999999995, 280.60000000000014, 234.8999999999999, 328.70000000000084, -138.39999999999998, 221.89999999999966, 175.79999999999976, -13.800000000000125, 118.99999999999989, 96.7999999999999, 265.69999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [156.79999999999995, 155.5999999999999, 6.499999999999973, 180.49999999999997, 110.89999999999992, 128.89999999999978, -140.80000000000007, 152.89999999999992, 115.1, 40.39999999999999, 7.399999999999984, 145.69999999999996, 80.89999999999999, 162.19999999999987, 19.700000000000045, -155.2000000000001, 60.49999999999996, 46.100000000000094, 117.4999999999998, 67.10000000000005, -67.90000000000003, 163.99999999999997, 91.99999999999997, 115.10000000000002, 163.99999999999997, 121.39999999999993, 104.59999999999974, 76.10000000000002, 167.59999999999994, 55.10000000000002, 142.9999999999999, 146.29999999999998, -11.79999999999999, 120.79999999999981, 84.49999999999972, 82.69999999999996, 157.9999999999999, -21.700000000000003, 128.8999999999998, 45.50000000000009, 63.500000000000014, 108.79999999999976, 52.39999999999999, 95.60000000000004, 169.39999999999998, 185.29999999999998, 81.49999999999989, 135.19999999999987, 25.700000000000077, 160.39999999999995, -7.9000000000000625, -7.900000000000015, 167.2999999999999, 136.9999999999998, 121.40000000000003, 166.69999999999996, 120.79999999999994, 76.10000000000011, 32.6, 107.60000000000002, 60.200000000000024, 87.80000000000001, 26.600000000000037, 155.29999999999987, 38.89999999999999, 120.19999999999992, 94.99999999999969, 118.39999999999998, 89.29999999999997, -102.10000000000011, 138.7999999999999, 82.09999999999988, 81.50000000000001, 44.600000000000065, 67.39999999999996, 127.09999999999994, 55.4, 129.19999999999996, 69.8000000000001, -90.70000000000007, 129.79999999999978, 62.600000000000016, 141.2, 103.10000000000002, 59.60000000000002, 179.89999999999995, 175.7, 141.79999999999995, 126.49999999999997, 131.9, -75.10000000000002, 47.60000000000006, 106.69999999999993, 81.50000000000006, 137.29999999999998, -21.700000000000117, 101.60000000000004, 142.0999999999999, 73.69999999999985, 97.99999999999997, 148.69999999999982, 145.99999999999994, 139.6999999999999, 157.69999999999987, -89.50000000000001, 145.39999999999992, 108.5, 121.40000000000003, 156.49999999999991, 168.49999999999986, 127.09999999999988, 168.79999999999993, 81.80000000000003, 132.79999999999987, 70.70000000000002, 42.49999999999998, 114.5, 180.19999999999996, 154.69999999999993, 118.7, 115.69999999999985, 119.29999999999961, 87.50000000000001, 178.7, 132.49999999999991, 117.49999999999991, 117.19999999999999, 131.0, 149.89999999999995, 60.20000000000004, 148.39999999999998, 47.300000000000026, 154.7, 100.99999999999994, 153.49999999999986, 113.0, 95.00000000000009, 104.59999999999998, 151.09999999999988, 144.79999999999995, 141.79999999999995, 129.19999999999996, 164.59999999999997, 158.59999999999994, 146.6, 148.69999999999996, -181.00000000000006, 148.99999999999983, 168.19999999999993, -4.00000000000006, 97.10000000000002, 48.50000000000003, 135.79999999999995, 159.49999999999983, 79.39999999999992, -242.5, 112.69999999999992, 135.79999999999995, 156.79999999999973, 126.79999999999998, -47.199999999999974, 41.300000000000054, -17.80000000000004, -199.3000000000001, -99.7000000000001, 41.30000000000002, -52.0, -12.999999999999979, -98.20000000000003, 112.09999999999991, 36.800000000000146, 102.19999999999993, 128.59999999999997, -195.40000000000003, 154.7, -373.9, 74.0, 70.70000000000002, 63.20000000000009, 142.99999999999991, 132.79999999999978, 126.79999999999994, 86.89999999999998, 94.99999999999999, 151.09999999999985, 167.59999999999985, -84.69999999999999, -228.70000000000002, 76.99999999999999, 92.89999999999998, -18.70000000000004, 111.49999999999999, 11.300000000000004, -150.10000000000014, -0.9999999999999343, 64.99999999999999, -22.600000000000016, -4.60000000000008, 99.79999999999987, 110.89999999999992], "policy_predator_policy_reward": [2.0, 10.0, 17.0, 29.0, 18.0, 9.0, 107.0, 103.0, 28.0, 52.0, 47.0, 43.0, 27.0, 20.0, 49.0, 113.0, 23.0, 25.0, 32.0, 14.0, 15.0, 78.0, 26.0, 20.0, 5.0, 22.0, 24.0, 35.0, 24.0, 0.0, 13.0, 1.0, 42.0, 52.0, 27.0, 23.0, 17.0, 40.0, 13.0, 29.0, 50.0, 23.0, 30.0, 49.0, 1.0, 0.0, 24.0, 21.0, 34.0, 28.0, 12.0, 92.0, 0.0, 4.0, 16.0, 6.0, 2.0, 14.0, 34.0, 46.0, 57.0, 2.0, 37.0, 26.0, 32.0, 48.0, 8.0, 32.0, 65.0, 78.0, 18.0, 4.0, 38.0, 10.0, 21.0, 37.0, 36.0, 15.0, 0.0, 95.0, 39.0, 39.0, 32.0, 1.0, 33.0, 31.0, 1.0, 2.0, 8.0, 6.0, 91.0, 0.0, 23.0, 23.0, 7.0, 72.0, 37.0, 31.0, 20.0, 31.0, 3.0, 2.0, 11.0, 12.0, 53.0, 11.0, 8.0, 13.0, 10.0, 1.0, 7.0, 3.0, 28.0, 22.0, 12.0, 39.0, 21.0, 13.0, 22.0, 17.0, 19.0, 7.0, 4.0, 33.0, 20.0, 2.0, 11.0, 24.0, 26.0, 34.0, 40.0, 8.0, 21.0, 23.0, 22.0, 25.0, 29.0, 19.0, 8.0, 12.0, 4.0, 8.0, 1.0, 6.0, 5.0, 3.0, 126.0, 119.0, 58.0, 51.0, 38.0, 8.0, 16.0, 9.0, 28.0, 138.0, 5.0, 13.0, 4.0, 14.0, 76.0, 2.0, 110.0, 23.0, 67.0, 39.0, 33.0, 74.0, 91.0, 36.0, 24.0, 27.0, 124.0, 119.0, 159.0, 195.0, 51.0, 6.0, 20.0, 16.0, 15.0, 6.0, 50.0, 3.0, 7.0, 3.0, 42.0, 133.0, 15.0, 37.0, 70.0, 13.0, 39.0, 86.0, 12.0, 43.0, 85.0, 39.0, 37.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7803182974820735, "mean_inference_ms": 2.0433180469629946, "mean_action_processing_ms": 0.33118029789289255, "mean_env_wait_ms": 0.2591581390176334, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00481569766998291, "StateBufferConnector_ms": 0.004613161087036133, "ViewRequirementAgentConnector_ms": 0.19153308868408203}, "num_episodes": 22, "episode_return_max": 355.69999999999993, "episode_return_min": -138.39999999999998, "episode_return_mean": 223.35799999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.4002187493178, "num_env_steps_trained_throughput_per_sec": 324.4002187493178, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 12572.194, "restore_workers_time_ms": 0.021, "training_step_time_ms": 12572.13, "sample_time_ms": 1962.678, "learn_time_ms": 10573.089, "learn_throughput": 378.319, "synch_weights_time_ms": 32.316}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "0bdc1_00000", "date": "2024-08-14_10-59-51", "timestamp": 1723647591, "time_this_iter_s": 12.336760997772217, "time_total_s": 759.6403040885925, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee2d1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 759.6403040885925, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 48.39411764705883, "ram_util_percent": 82.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8796394563225842, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.940311491678631, "policy_loss": -0.005645877741912882, "vf_loss": 8.943848949260813, "vf_explained_var": 0.053887171404702325, "kl": 0.007404058258630727, "entropy": 1.4631651384489877, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.348393901851442, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.525276944498536, "policy_loss": -0.005900064739768231, "vf_loss": 6.5303217665859, "vf_explained_var": 0.04378774566625161, "kl": 0.01140330515396238, "entropy": 0.7064030348623871, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 336.0000000000003, "episode_reward_min": -166.60000000000022, "episode_reward_mean": 190.20399999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 180.19999999999996, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 58.63699999999997, "predator_policy": 36.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [261.6999999999999, 248.09999999999945, 88.19999999999993, 308.2999999999996, 310.09999999999974, 212.89999999999975, 220.19999999999987, 206.99999999999983, 244.89999999999975, 239.09999999999968, 253.39999999999966, 130.1999999999999, 242.8999999999997, 174.09999999999965, 252.4999999999999, 235.5999999999999, 74.10000000000011, 270.4, 277.29999999999984, 303.4999999999999, 320.5000000000002, 272.39999999999986, 63.499999999999886, 234.19999999999962, 194.6, 311.6999999999998, 222.70000000000005, 299.6999999999998, 320.40000000000043, 119.89999999999964, 250.89999999999975, 336.0000000000003, 305.9000000000001, 264.5999999999998, 164.19999999999962, 328.7000000000001, 312.4, 260.9999999999995, 303.20000000000005, 271.9999999999998, 283.20000000000005, 270.0999999999998, 243.69999999999982, 299.70000000000005, 313.5000000000001, 247.59999999999985, 315.89999999999986, 282.9999999999999, 330.2000000000003, 303.29999999999995, 212.9999999999998, 273.20000000000005, 191.5999999999998, 320.30000000000007, 2.8999999999999813, 266.49999999999983, 301.59999999999974, 72.09999999999957, -84.10000000000022, 47.60000000000001, 41.999999999999865, 140.8999999999999, 189.99999999999918, 176.19999999999993, 134.79999999999993, 201.69999999999996, 242.1999999999995, 280.60000000000014, 234.8999999999999, 328.70000000000084, -138.39999999999998, 221.89999999999966, 175.79999999999976, -13.800000000000125, 118.99999999999989, 96.7999999999999, 265.69999999999993, 129.5999999999995, -0.49999999999998757, 72.69999999999953, 92.39999999999952, 104.09999999999968, 306.6000000000002, 135.2999999999995, 1.1999999999999922, 310.3000000000002, 64.80000000000013, -166.60000000000022, 119.49999999999997, 155.69999999999953, 88.19999999999999, 115.39999999999966, 46.199999999999875, 128.39999999999955, 185.09999999999988, -112.80000000000013, -74.19999999999999, 107.19999999999891, 133.4999999999999, 171.39999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [81.49999999999989, 135.19999999999987, 25.700000000000077, 160.39999999999995, -7.9000000000000625, -7.900000000000015, 167.2999999999999, 136.9999999999998, 121.40000000000003, 166.69999999999996, 120.79999999999994, 76.10000000000011, 32.6, 107.60000000000002, 60.200000000000024, 87.80000000000001, 26.600000000000037, 155.29999999999987, 38.89999999999999, 120.19999999999992, 94.99999999999969, 118.39999999999998, 89.29999999999997, -102.10000000000011, 138.7999999999999, 82.09999999999988, 81.50000000000001, 44.600000000000065, 67.39999999999996, 127.09999999999994, 55.4, 129.19999999999996, 69.8000000000001, -90.70000000000007, 129.79999999999978, 62.600000000000016, 141.2, 103.10000000000002, 59.60000000000002, 179.89999999999995, 175.7, 141.79999999999995, 126.49999999999997, 131.9, -75.10000000000002, 47.60000000000006, 106.69999999999993, 81.50000000000006, 137.29999999999998, -21.700000000000117, 101.60000000000004, 142.0999999999999, 73.69999999999985, 97.99999999999997, 148.69999999999982, 145.99999999999994, 139.6999999999999, 157.69999999999987, -89.50000000000001, 145.39999999999992, 108.5, 121.40000000000003, 156.49999999999991, 168.49999999999986, 127.09999999999988, 168.79999999999993, 81.80000000000003, 132.79999999999987, 70.70000000000002, 42.49999999999998, 114.5, 180.19999999999996, 154.69999999999993, 118.7, 115.69999999999985, 119.29999999999961, 87.50000000000001, 178.7, 132.49999999999991, 117.49999999999991, 117.19999999999999, 131.0, 149.89999999999995, 60.20000000000004, 148.39999999999998, 47.300000000000026, 154.7, 100.99999999999994, 153.49999999999986, 113.0, 95.00000000000009, 104.59999999999998, 151.09999999999988, 144.79999999999995, 141.79999999999995, 129.19999999999996, 164.59999999999997, 158.59999999999994, 146.6, 148.69999999999996, -181.00000000000006, 148.99999999999983, 168.19999999999993, -4.00000000000006, 97.10000000000002, 48.50000000000003, 135.79999999999995, 159.49999999999983, 79.39999999999992, -242.5, 112.69999999999992, 135.79999999999995, 156.79999999999973, 126.79999999999998, -47.199999999999974, 41.300000000000054, -17.80000000000004, -199.3000000000001, -99.7000000000001, 41.30000000000002, -52.0, -12.999999999999979, -98.20000000000003, 112.09999999999991, 36.800000000000146, 102.19999999999993, 128.59999999999997, -195.40000000000003, 154.7, -373.9, 74.0, 70.70000000000002, 63.20000000000009, 142.99999999999991, 132.79999999999978, 126.79999999999994, 86.89999999999998, 94.99999999999999, 151.09999999999985, 167.59999999999985, -84.69999999999999, -228.70000000000002, 76.99999999999999, 92.89999999999998, -18.70000000000004, 111.49999999999999, 11.300000000000004, -150.10000000000014, -0.9999999999999343, 64.99999999999999, -22.600000000000016, -4.60000000000008, 99.79999999999987, 110.89999999999992, -28.89999999999998, 36.500000000000085, 67.69999999999975, -239.20000000000024, -18.099999999999948, -29.199999999999925, 1.099999999999989, -6.699999999999946, 31.100000000000044, -30.999999999999975, 125.59999999999991, 160.99999999999991, -30.099999999999966, 76.39999999999964, 154.69999999999987, -326.5, 150.49999999999997, 120.79999999999993, -41.20000000000021, -42.99999999999996, -326.7999999999997, -56.80000000000002, 23.30000000000001, 18.200000000000006, 52.700000000000095, 29.00000000000003, 13.100000000000001, -4.900000000000006, 15.800000000000045, 35.60000000000003, -43.89999999999999, -7.899999999999981, 73.4, -12.999999999999986, 39.800000000000054, 83.30000000000001, -108.10000000000005, -147.70000000000005, -108.70000000000005, -101.49999999999997, 60.20000000000014, 20.000000000000014, 9.500000000000012, 37.99999999999999, 91.39999999999996, -82.00000000000014], "policy_predator_policy_reward": [24.0, 21.0, 34.0, 28.0, 12.0, 92.0, 0.0, 4.0, 16.0, 6.0, 2.0, 14.0, 34.0, 46.0, 57.0, 2.0, 37.0, 26.0, 32.0, 48.0, 8.0, 32.0, 65.0, 78.0, 18.0, 4.0, 38.0, 10.0, 21.0, 37.0, 36.0, 15.0, 0.0, 95.0, 39.0, 39.0, 32.0, 1.0, 33.0, 31.0, 1.0, 2.0, 8.0, 6.0, 91.0, 0.0, 23.0, 23.0, 7.0, 72.0, 37.0, 31.0, 20.0, 31.0, 3.0, 2.0, 11.0, 12.0, 53.0, 11.0, 8.0, 13.0, 10.0, 1.0, 7.0, 3.0, 28.0, 22.0, 12.0, 39.0, 21.0, 13.0, 22.0, 17.0, 19.0, 7.0, 4.0, 33.0, 20.0, 2.0, 11.0, 24.0, 26.0, 34.0, 40.0, 8.0, 21.0, 23.0, 22.0, 25.0, 29.0, 19.0, 8.0, 12.0, 4.0, 8.0, 1.0, 6.0, 5.0, 3.0, 126.0, 119.0, 58.0, 51.0, 38.0, 8.0, 16.0, 9.0, 28.0, 138.0, 5.0, 13.0, 4.0, 14.0, 76.0, 2.0, 110.0, 23.0, 67.0, 39.0, 33.0, 74.0, 91.0, 36.0, 24.0, 27.0, 124.0, 119.0, 159.0, 195.0, 51.0, 6.0, 20.0, 16.0, 15.0, 6.0, 50.0, 3.0, 7.0, 3.0, 42.0, 133.0, 15.0, 37.0, 70.0, 13.0, 39.0, 86.0, 12.0, 43.0, 85.0, 39.0, 37.0, 18.0, 79.0, 43.0, 94.0, 77.0, 58.0, 62.0, 59.0, 39.0, 25.0, 79.0, 7.0, 13.0, 58.0, 31.0, 2.0, 171.0, 22.0, 17.0, 61.0, 88.0, 92.0, 125.0, 9.0, 69.0, 2.0, 72.0, 18.0, 62.0, 16.0, 48.0, 88.0, 10.0, 50.0, 18.0, 27.0, 35.0, 8.0, 135.0, 128.0, 8.0, 14.0, 13.0, 34.0, 52.0, 78.0, 84.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7846704352784641, "mean_inference_ms": 2.0544592659785113, "mean_action_processing_ms": 0.33252262408197353, "mean_env_wait_ms": 0.2606553828444489, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047293901443481445, "StateBufferConnector_ms": 0.005288124084472656, "ViewRequirementAgentConnector_ms": 0.2035815715789795}, "num_episodes": 23, "episode_return_max": 336.0000000000003, "episode_return_min": -166.60000000000022, "episode_return_mean": 190.20399999999987, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.4276621929609, "num_env_steps_trained_throughput_per_sec": 315.4276621929609, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 12534.429, "restore_workers_time_ms": 0.023, "training_step_time_ms": 12534.362, "sample_time_ms": 1960.86, "learn_time_ms": 10536.695, "learn_throughput": 379.626, "synch_weights_time_ms": 33.218}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-00-04", "timestamp": 1723647604, "time_this_iter_s": 12.716443061828613, "time_total_s": 772.3567471504211, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee10310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 772.3567471504211, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 48.22631578947368, "ram_util_percent": 82.03684210526316}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8852302568930166, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.914866630867044, "policy_loss": -0.006409281483856301, "vf_loss": 8.918606725823942, "vf_explained_var": -0.03026447195224661, "kl": 0.009373353376931317, "entropy": 1.4640389290436235, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5862786702378084, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.220165657870984, "policy_loss": -0.009670308907146728, "vf_loss": 6.228784754162743, "vf_explained_var": 0.08479000058754411, "kl": 0.014016155368582361, "entropy": 0.7045722645426553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 336.0000000000003, "episode_reward_min": -166.60000000000022, "episode_reward_mean": 161.9529999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 180.19999999999996, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 37.806499999999964, "predator_policy": 43.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [277.29999999999984, 303.4999999999999, 320.5000000000002, 272.39999999999986, 63.499999999999886, 234.19999999999962, 194.6, 311.6999999999998, 222.70000000000005, 299.6999999999998, 320.40000000000043, 119.89999999999964, 250.89999999999975, 336.0000000000003, 305.9000000000001, 264.5999999999998, 164.19999999999962, 328.7000000000001, 312.4, 260.9999999999995, 303.20000000000005, 271.9999999999998, 283.20000000000005, 270.0999999999998, 243.69999999999982, 299.70000000000005, 313.5000000000001, 247.59999999999985, 315.89999999999986, 282.9999999999999, 330.2000000000003, 303.29999999999995, 212.9999999999998, 273.20000000000005, 191.5999999999998, 320.30000000000007, 2.8999999999999813, 266.49999999999983, 301.59999999999974, 72.09999999999957, -84.10000000000022, 47.60000000000001, 41.999999999999865, 140.8999999999999, 189.99999999999918, 176.19999999999993, 134.79999999999993, 201.69999999999996, 242.1999999999995, 280.60000000000014, 234.8999999999999, 328.70000000000084, -138.39999999999998, 221.89999999999966, 175.79999999999976, -13.800000000000125, 118.99999999999989, 96.7999999999999, 265.69999999999993, 129.5999999999995, -0.49999999999998757, 72.69999999999953, 92.39999999999952, 104.09999999999968, 306.6000000000002, 135.2999999999995, 1.1999999999999922, 310.3000000000002, 64.80000000000013, -166.60000000000022, 119.49999999999997, 155.69999999999953, 88.19999999999999, 115.39999999999966, 46.199999999999875, 128.39999999999955, 185.09999999999988, -112.80000000000013, -74.19999999999999, 107.19999999999891, 133.4999999999999, 171.39999999999995, 274.09999999999945, 68.80000000000004, 17.300000000000068, 34.400000000000055, 105.09999999999982, -2.4999999999999893, 32.00000000000006, -141.30000000000018, 35.70000000000001, 41.39999999999995, 43.99999999999983, 217.19999999999993, 200.39999999999986, 198.39999999999966, 17.800000000000047, 50.00000000000001, -65.30000000000052, 21.100000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [141.2, 103.10000000000002, 59.60000000000002, 179.89999999999995, 175.7, 141.79999999999995, 126.49999999999997, 131.9, -75.10000000000002, 47.60000000000006, 106.69999999999993, 81.50000000000006, 137.29999999999998, -21.700000000000117, 101.60000000000004, 142.0999999999999, 73.69999999999985, 97.99999999999997, 148.69999999999982, 145.99999999999994, 139.6999999999999, 157.69999999999987, -89.50000000000001, 145.39999999999992, 108.5, 121.40000000000003, 156.49999999999991, 168.49999999999986, 127.09999999999988, 168.79999999999993, 81.80000000000003, 132.79999999999987, 70.70000000000002, 42.49999999999998, 114.5, 180.19999999999996, 154.69999999999993, 118.7, 115.69999999999985, 119.29999999999961, 87.50000000000001, 178.7, 132.49999999999991, 117.49999999999991, 117.19999999999999, 131.0, 149.89999999999995, 60.20000000000004, 148.39999999999998, 47.300000000000026, 154.7, 100.99999999999994, 153.49999999999986, 113.0, 95.00000000000009, 104.59999999999998, 151.09999999999988, 144.79999999999995, 141.79999999999995, 129.19999999999996, 164.59999999999997, 158.59999999999994, 146.6, 148.69999999999996, -181.00000000000006, 148.99999999999983, 168.19999999999993, -4.00000000000006, 97.10000000000002, 48.50000000000003, 135.79999999999995, 159.49999999999983, 79.39999999999992, -242.5, 112.69999999999992, 135.79999999999995, 156.79999999999973, 126.79999999999998, -47.199999999999974, 41.300000000000054, -17.80000000000004, -199.3000000000001, -99.7000000000001, 41.30000000000002, -52.0, -12.999999999999979, -98.20000000000003, 112.09999999999991, 36.800000000000146, 102.19999999999993, 128.59999999999997, -195.40000000000003, 154.7, -373.9, 74.0, 70.70000000000002, 63.20000000000009, 142.99999999999991, 132.79999999999978, 126.79999999999994, 86.89999999999998, 94.99999999999999, 151.09999999999985, 167.59999999999985, -84.69999999999999, -228.70000000000002, 76.99999999999999, 92.89999999999998, -18.70000000000004, 111.49999999999999, 11.300000000000004, -150.10000000000014, -0.9999999999999343, 64.99999999999999, -22.600000000000016, -4.60000000000008, 99.79999999999987, 110.89999999999992, -28.89999999999998, 36.500000000000085, 67.69999999999975, -239.20000000000024, -18.099999999999948, -29.199999999999925, 1.099999999999989, -6.699999999999946, 31.100000000000044, -30.999999999999975, 125.59999999999991, 160.99999999999991, -30.099999999999966, 76.39999999999964, 154.69999999999987, -326.5, 150.49999999999997, 120.79999999999993, -41.20000000000021, -42.99999999999996, -326.7999999999997, -56.80000000000002, 23.30000000000001, 18.200000000000006, 52.700000000000095, 29.00000000000003, 13.100000000000001, -4.900000000000006, 15.800000000000045, 35.60000000000003, -43.89999999999999, -7.899999999999981, 73.4, -12.999999999999986, 39.800000000000054, 83.30000000000001, -108.10000000000005, -147.70000000000005, -108.70000000000005, -101.49999999999997, 60.20000000000014, 20.000000000000014, 9.500000000000012, 37.99999999999999, 91.39999999999996, -82.00000000000014, 141.49999999999997, 116.59999999999984, -25.899999999999977, -28.299999999999997, 27.2, -283.89999999999975, -22.900000000000002, -48.69999999999996, 34.700000000000024, -10.599999999999996, -26.79999999999997, -87.70000000000024, -94.90000000000009, -0.0999999999999801, -130.30000000000004, -297.9999999999996, 24.800000000000004, -156.1000000000001, 65.59999999999994, -176.20000000000007, -104.19999999999999, -38.79999999999998, -2.8000000000001224, 97.99999999999994, 79.1, 50.29999999999996, 34.70000000000007, 103.6999999999999, -27.700000000000003, -35.5, 85.39999999999998, -192.4, -37.899999999999956, -186.40000000000038, -4.599999999999989, -103.30000000000004], "policy_predator_policy_reward": [32.0, 1.0, 33.0, 31.0, 1.0, 2.0, 8.0, 6.0, 91.0, 0.0, 23.0, 23.0, 7.0, 72.0, 37.0, 31.0, 20.0, 31.0, 3.0, 2.0, 11.0, 12.0, 53.0, 11.0, 8.0, 13.0, 10.0, 1.0, 7.0, 3.0, 28.0, 22.0, 12.0, 39.0, 21.0, 13.0, 22.0, 17.0, 19.0, 7.0, 4.0, 33.0, 20.0, 2.0, 11.0, 24.0, 26.0, 34.0, 40.0, 8.0, 21.0, 23.0, 22.0, 25.0, 29.0, 19.0, 8.0, 12.0, 4.0, 8.0, 1.0, 6.0, 5.0, 3.0, 126.0, 119.0, 58.0, 51.0, 38.0, 8.0, 16.0, 9.0, 28.0, 138.0, 5.0, 13.0, 4.0, 14.0, 76.0, 2.0, 110.0, 23.0, 67.0, 39.0, 33.0, 74.0, 91.0, 36.0, 24.0, 27.0, 124.0, 119.0, 159.0, 195.0, 51.0, 6.0, 20.0, 16.0, 15.0, 6.0, 50.0, 3.0, 7.0, 3.0, 42.0, 133.0, 15.0, 37.0, 70.0, 13.0, 39.0, 86.0, 12.0, 43.0, 85.0, 39.0, 37.0, 18.0, 79.0, 43.0, 94.0, 77.0, 58.0, 62.0, 59.0, 39.0, 25.0, 79.0, 7.0, 13.0, 58.0, 31.0, 2.0, 171.0, 22.0, 17.0, 61.0, 88.0, 92.0, 125.0, 9.0, 69.0, 2.0, 72.0, 18.0, 62.0, 16.0, 48.0, 88.0, 10.0, 50.0, 18.0, 27.0, 35.0, 8.0, 135.0, 128.0, 8.0, 14.0, 13.0, 34.0, 52.0, 78.0, 84.0, 6.0, 10.0, 66.0, 57.0, 129.0, 145.0, 62.0, 44.0, 80.0, 1.0, 23.0, 89.0, 47.0, 80.0, 139.0, 148.0, 75.0, 92.0, 79.0, 73.0, 107.0, 80.0, 64.0, 58.0, 71.0, 0.0, 35.0, 25.0, 2.0, 79.0, 100.0, 57.0, 90.0, 69.0, 36.0, 93.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7885595785871962, "mean_inference_ms": 2.062645732267289, "mean_action_processing_ms": 0.3340716040506719, "mean_env_wait_ms": 0.2615358752878653, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004933714866638184, "StateBufferConnector_ms": 0.00816333293914795, "ViewRequirementAgentConnector_ms": 0.20384573936462402}, "num_episodes": 18, "episode_return_max": 336.0000000000003, "episode_return_min": -166.60000000000022, "episode_return_mean": 161.9529999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 314.0202773966671, "num_env_steps_trained_throughput_per_sec": 314.0202773966671, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 12478.387, "restore_workers_time_ms": 0.027, "training_step_time_ms": 12478.319, "sample_time_ms": 1949.23, "learn_time_ms": 10491.942, "learn_throughput": 381.245, "synch_weights_time_ms": 33.752}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-00-17", "timestamp": 1723647617, "time_this_iter_s": 12.848222970962524, "time_total_s": 785.2049701213837, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29d4670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 785.2049701213837, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 50.66111111111112, "ram_util_percent": 82.15555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.746774917746347, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.378626592827853, "policy_loss": -0.005728026405814542, "vf_loss": 9.382103594522627, "vf_explained_var": -0.002845701023384377, "kl": 0.007904808016883662, "entropy": 1.4469276639519546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4273838685303137, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.9729526444086956, "policy_loss": -0.0071692371697820445, "vf_loss": 5.979100440545057, "vf_explained_var": 0.204477767843418, "kl": 0.013619099880855525, "entropy": 0.6438007091403638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 330.2000000000003, "episode_reward_min": -166.60000000000022, "episode_reward_mean": 119.93799999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.7, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 9.853999999999969, "predator_policy": 50.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [312.4, 260.9999999999995, 303.20000000000005, 271.9999999999998, 283.20000000000005, 270.0999999999998, 243.69999999999982, 299.70000000000005, 313.5000000000001, 247.59999999999985, 315.89999999999986, 282.9999999999999, 330.2000000000003, 303.29999999999995, 212.9999999999998, 273.20000000000005, 191.5999999999998, 320.30000000000007, 2.8999999999999813, 266.49999999999983, 301.59999999999974, 72.09999999999957, -84.10000000000022, 47.60000000000001, 41.999999999999865, 140.8999999999999, 189.99999999999918, 176.19999999999993, 134.79999999999993, 201.69999999999996, 242.1999999999995, 280.60000000000014, 234.8999999999999, 328.70000000000084, -138.39999999999998, 221.89999999999966, 175.79999999999976, -13.800000000000125, 118.99999999999989, 96.7999999999999, 265.69999999999993, 129.5999999999995, -0.49999999999998757, 72.69999999999953, 92.39999999999952, 104.09999999999968, 306.6000000000002, 135.2999999999995, 1.1999999999999922, 310.3000000000002, 64.80000000000013, -166.60000000000022, 119.49999999999997, 155.69999999999953, 88.19999999999999, 115.39999999999966, 46.199999999999875, 128.39999999999955, 185.09999999999988, -112.80000000000013, -74.19999999999999, 107.19999999999891, 133.4999999999999, 171.39999999999995, 274.09999999999945, 68.80000000000004, 17.300000000000068, 34.400000000000055, 105.09999999999982, -2.4999999999999893, 32.00000000000006, -141.30000000000018, 35.70000000000001, 41.39999999999995, 43.99999999999983, 217.19999999999993, 200.39999999999986, 198.39999999999966, 17.800000000000047, 50.00000000000001, -65.30000000000052, 21.100000000000016, -66.4000000000004, 146.1999999999997, -40.89999999999994, -79.70000000000007, 52.89999999999916, -48.79999999999991, 305.4000000000001, -122.80000000000007, 147.1999999999996, 1.900000000000034, 25.80000000000029, -73.59999999999991, 11.800000000000054, -82.50000000000037, -95.90000000000033, 169.39999999999904, 58.999999999999964, 80.19999999999973], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [154.69999999999993, 118.7, 115.69999999999985, 119.29999999999961, 87.50000000000001, 178.7, 132.49999999999991, 117.49999999999991, 117.19999999999999, 131.0, 149.89999999999995, 60.20000000000004, 148.39999999999998, 47.300000000000026, 154.7, 100.99999999999994, 153.49999999999986, 113.0, 95.00000000000009, 104.59999999999998, 151.09999999999988, 144.79999999999995, 141.79999999999995, 129.19999999999996, 164.59999999999997, 158.59999999999994, 146.6, 148.69999999999996, -181.00000000000006, 148.99999999999983, 168.19999999999993, -4.00000000000006, 97.10000000000002, 48.50000000000003, 135.79999999999995, 159.49999999999983, 79.39999999999992, -242.5, 112.69999999999992, 135.79999999999995, 156.79999999999973, 126.79999999999998, -47.199999999999974, 41.300000000000054, -17.80000000000004, -199.3000000000001, -99.7000000000001, 41.30000000000002, -52.0, -12.999999999999979, -98.20000000000003, 112.09999999999991, 36.800000000000146, 102.19999999999993, 128.59999999999997, -195.40000000000003, 154.7, -373.9, 74.0, 70.70000000000002, 63.20000000000009, 142.99999999999991, 132.79999999999978, 126.79999999999994, 86.89999999999998, 94.99999999999999, 151.09999999999985, 167.59999999999985, -84.69999999999999, -228.70000000000002, 76.99999999999999, 92.89999999999998, -18.70000000000004, 111.49999999999999, 11.300000000000004, -150.10000000000014, -0.9999999999999343, 64.99999999999999, -22.600000000000016, -4.60000000000008, 99.79999999999987, 110.89999999999992, -28.89999999999998, 36.500000000000085, 67.69999999999975, -239.20000000000024, -18.099999999999948, -29.199999999999925, 1.099999999999989, -6.699999999999946, 31.100000000000044, -30.999999999999975, 125.59999999999991, 160.99999999999991, -30.099999999999966, 76.39999999999964, 154.69999999999987, -326.5, 150.49999999999997, 120.79999999999993, -41.20000000000021, -42.99999999999996, -326.7999999999997, -56.80000000000002, 23.30000000000001, 18.200000000000006, 52.700000000000095, 29.00000000000003, 13.100000000000001, -4.900000000000006, 15.800000000000045, 35.60000000000003, -43.89999999999999, -7.899999999999981, 73.4, -12.999999999999986, 39.800000000000054, 83.30000000000001, -108.10000000000005, -147.70000000000005, -108.70000000000005, -101.49999999999997, 60.20000000000014, 20.000000000000014, 9.500000000000012, 37.99999999999999, 91.39999999999996, -82.00000000000014, 141.49999999999997, 116.59999999999984, -25.899999999999977, -28.299999999999997, 27.2, -283.89999999999975, -22.900000000000002, -48.69999999999996, 34.700000000000024, -10.599999999999996, -26.79999999999997, -87.70000000000024, -94.90000000000009, -0.0999999999999801, -130.30000000000004, -297.9999999999996, 24.800000000000004, -156.1000000000001, 65.59999999999994, -176.20000000000007, -104.19999999999999, -38.79999999999998, -2.8000000000001224, 97.99999999999994, 79.1, 50.29999999999996, 34.70000000000007, 103.6999999999999, -27.700000000000003, -35.5, 85.39999999999998, -192.4, -37.899999999999956, -186.40000000000038, -4.599999999999989, -103.30000000000004, -185.2000000000002, -62.19999999999982, 53.599999999999994, 29.6, -135.70000000000024, -29.20000000000001, -142.60000000000034, -66.1, -44.199999999999875, -22.899999999999917, -204.10000000000002, -87.6999999999999, 135.79999999999993, 143.6, -164.20000000000005, -130.60000000000016, 88.39999999999989, 30.80000000000004, -96.39999999999998, -63.699999999999946, -27.70000000000001, -11.500000000000036, -175.00000000000006, -127.60000000000004, -47.19999999999998, -66.99999999999997, -87.40000000000019, -117.10000000000028, -158.8000000000001, -66.1, 110.89999999999972, 45.50000000000005, -5.499999999999964, -47.499999999999915, -15.399999999999979, 32.60000000000003], "policy_predator_policy_reward": [22.0, 17.0, 19.0, 7.0, 4.0, 33.0, 20.0, 2.0, 11.0, 24.0, 26.0, 34.0, 40.0, 8.0, 21.0, 23.0, 22.0, 25.0, 29.0, 19.0, 8.0, 12.0, 4.0, 8.0, 1.0, 6.0, 5.0, 3.0, 126.0, 119.0, 58.0, 51.0, 38.0, 8.0, 16.0, 9.0, 28.0, 138.0, 5.0, 13.0, 4.0, 14.0, 76.0, 2.0, 110.0, 23.0, 67.0, 39.0, 33.0, 74.0, 91.0, 36.0, 24.0, 27.0, 124.0, 119.0, 159.0, 195.0, 51.0, 6.0, 20.0, 16.0, 15.0, 6.0, 50.0, 3.0, 7.0, 3.0, 42.0, 133.0, 15.0, 37.0, 70.0, 13.0, 39.0, 86.0, 12.0, 43.0, 85.0, 39.0, 37.0, 18.0, 79.0, 43.0, 94.0, 77.0, 58.0, 62.0, 59.0, 39.0, 25.0, 79.0, 7.0, 13.0, 58.0, 31.0, 2.0, 171.0, 22.0, 17.0, 61.0, 88.0, 92.0, 125.0, 9.0, 69.0, 2.0, 72.0, 18.0, 62.0, 16.0, 48.0, 88.0, 10.0, 50.0, 18.0, 27.0, 35.0, 8.0, 135.0, 128.0, 8.0, 14.0, 13.0, 34.0, 52.0, 78.0, 84.0, 6.0, 10.0, 66.0, 57.0, 129.0, 145.0, 62.0, 44.0, 80.0, 1.0, 23.0, 89.0, 47.0, 80.0, 139.0, 148.0, 75.0, 92.0, 79.0, 73.0, 107.0, 80.0, 64.0, 58.0, 71.0, 0.0, 35.0, 25.0, 2.0, 79.0, 100.0, 57.0, 90.0, 69.0, 36.0, 93.0, 117.0, 64.0, 31.0, 32.0, 100.0, 24.0, 53.0, 76.0, 39.0, 81.0, 124.0, 119.0, 11.0, 15.0, 101.0, 71.0, 0.0, 28.0, 83.0, 79.0, 52.0, 13.0, 132.0, 97.0, 87.0, 39.0, 32.0, 90.0, 6.0, 123.0, 5.0, 8.0, 25.0, 87.0, 15.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7928624550482243, "mean_inference_ms": 2.072749440377629, "mean_action_processing_ms": 0.33572108247021215, "mean_env_wait_ms": 0.2628756345035609, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004680752754211426, "StateBufferConnector_ms": 0.00839698314666748, "ViewRequirementAgentConnector_ms": 0.21470224857330322}, "num_episodes": 18, "episode_return_max": 330.2000000000003, "episode_return_min": -166.60000000000022, "episode_return_mean": 119.93799999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.4707183590552, "num_env_steps_trained_throughput_per_sec": 307.4707183590552, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 12536.027, "restore_workers_time_ms": 0.027, "training_step_time_ms": 12535.958, "sample_time_ms": 1994.293, "learn_time_ms": 10503.844, "learn_throughput": 380.813, "synch_weights_time_ms": 34.051}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-00-30", "timestamp": 1723647630, "time_this_iter_s": 13.095664024353027, "time_total_s": 798.3006341457367, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a338b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 798.3006341457367, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 53.410526315789475, "ram_util_percent": 82.8736842105263}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.258206620512816, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.89831434002629, "policy_loss": -0.0028896168062818193, "vf_loss": 8.899139038469425, "vf_explained_var": -0.15817215414274308, "kl": 0.007251232233800376, "entropy": 1.4336188878962604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4707461592066227, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.446638053813309, "policy_loss": -0.0058767667927202725, "vf_loss": 6.451772598993211, "vf_explained_var": 0.2150102517592213, "kl": 0.009896243104985505, "entropy": 0.6233486519288765, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 328.70000000000084, "episode_reward_min": -166.60000000000022, "episode_reward_mean": 74.1689999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.49999999999991, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -19.265500000000046, "predator_policy": 56.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-84.10000000000022, 47.60000000000001, 41.999999999999865, 140.8999999999999, 189.99999999999918, 176.19999999999993, 134.79999999999993, 201.69999999999996, 242.1999999999995, 280.60000000000014, 234.8999999999999, 328.70000000000084, -138.39999999999998, 221.89999999999966, 175.79999999999976, -13.800000000000125, 118.99999999999989, 96.7999999999999, 265.69999999999993, 129.5999999999995, -0.49999999999998757, 72.69999999999953, 92.39999999999952, 104.09999999999968, 306.6000000000002, 135.2999999999995, 1.1999999999999922, 310.3000000000002, 64.80000000000013, -166.60000000000022, 119.49999999999997, 155.69999999999953, 88.19999999999999, 115.39999999999966, 46.199999999999875, 128.39999999999955, 185.09999999999988, -112.80000000000013, -74.19999999999999, 107.19999999999891, 133.4999999999999, 171.39999999999995, 274.09999999999945, 68.80000000000004, 17.300000000000068, 34.400000000000055, 105.09999999999982, -2.4999999999999893, 32.00000000000006, -141.30000000000018, 35.70000000000001, 41.39999999999995, 43.99999999999983, 217.19999999999993, 200.39999999999986, 198.39999999999966, 17.800000000000047, 50.00000000000001, -65.30000000000052, 21.100000000000016, -66.4000000000004, 146.1999999999997, -40.89999999999994, -79.70000000000007, 52.89999999999916, -48.79999999999991, 305.4000000000001, -122.80000000000007, 147.1999999999996, 1.900000000000034, 25.80000000000029, -73.59999999999991, 11.800000000000054, -82.50000000000037, -95.90000000000033, 169.39999999999904, 58.999999999999964, 80.19999999999973, 164.39999999999927, 246.59999999999954, 271.30000000000024, 173.09999999999917, -114.3000000000003, 37.99999999999954, 135.49999999999915, -52.999999999999844, 32.90000000000029, -116.00000000000057, -56.300000000000225, 69.99999999999967, 207.8999999999993, 73.69999999999986, -128.90000000000006, -47.89999999999966, 25.40000000000019, -80.20000000000087, -116.40000000000056, 201.09999999999962, -11.100000000000012, 187.2999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-17.80000000000004, -199.3000000000001, -99.7000000000001, 41.30000000000002, -52.0, -12.999999999999979, -98.20000000000003, 112.09999999999991, 36.800000000000146, 102.19999999999993, 128.59999999999997, -195.40000000000003, 154.7, -373.9, 74.0, 70.70000000000002, 63.20000000000009, 142.99999999999991, 132.79999999999978, 126.79999999999994, 86.89999999999998, 94.99999999999999, 151.09999999999985, 167.59999999999985, -84.69999999999999, -228.70000000000002, 76.99999999999999, 92.89999999999998, -18.70000000000004, 111.49999999999999, 11.300000000000004, -150.10000000000014, -0.9999999999999343, 64.99999999999999, -22.600000000000016, -4.60000000000008, 99.79999999999987, 110.89999999999992, -28.89999999999998, 36.500000000000085, 67.69999999999975, -239.20000000000024, -18.099999999999948, -29.199999999999925, 1.099999999999989, -6.699999999999946, 31.100000000000044, -30.999999999999975, 125.59999999999991, 160.99999999999991, -30.099999999999966, 76.39999999999964, 154.69999999999987, -326.5, 150.49999999999997, 120.79999999999993, -41.20000000000021, -42.99999999999996, -326.7999999999997, -56.80000000000002, 23.30000000000001, 18.200000000000006, 52.700000000000095, 29.00000000000003, 13.100000000000001, -4.900000000000006, 15.800000000000045, 35.60000000000003, -43.89999999999999, -7.899999999999981, 73.4, -12.999999999999986, 39.800000000000054, 83.30000000000001, -108.10000000000005, -147.70000000000005, -108.70000000000005, -101.49999999999997, 60.20000000000014, 20.000000000000014, 9.500000000000012, 37.99999999999999, 91.39999999999996, -82.00000000000014, 141.49999999999997, 116.59999999999984, -25.899999999999977, -28.299999999999997, 27.2, -283.89999999999975, -22.900000000000002, -48.69999999999996, 34.700000000000024, -10.599999999999996, -26.79999999999997, -87.70000000000024, -94.90000000000009, -0.0999999999999801, -130.30000000000004, -297.9999999999996, 24.800000000000004, -156.1000000000001, 65.59999999999994, -176.20000000000007, -104.19999999999999, -38.79999999999998, -2.8000000000001224, 97.99999999999994, 79.1, 50.29999999999996, 34.70000000000007, 103.6999999999999, -27.700000000000003, -35.5, 85.39999999999998, -192.4, -37.899999999999956, -186.40000000000038, -4.599999999999989, -103.30000000000004, -185.2000000000002, -62.19999999999982, 53.599999999999994, 29.6, -135.70000000000024, -29.20000000000001, -142.60000000000034, -66.1, -44.199999999999875, -22.899999999999917, -204.10000000000002, -87.6999999999999, 135.79999999999993, 143.6, -164.20000000000005, -130.60000000000016, 88.39999999999989, 30.80000000000004, -96.39999999999998, -63.699999999999946, -27.70000000000001, -11.500000000000036, -175.00000000000006, -127.60000000000004, -47.19999999999998, -66.99999999999997, -87.40000000000019, -117.10000000000028, -158.8000000000001, -66.1, 110.89999999999972, 45.50000000000005, -5.499999999999964, -47.499999999999915, -15.399999999999979, 32.60000000000003, 97.99999999999986, -49.60000000000017, 91.1, 81.50000000000003, 177.49999999999991, 84.7999999999999, 98.2999999999995, 63.80000000000004, -152.80000000000018, -212.50000000000014, -109.90000000000009, -18.099999999999913, 8.00000000000002, 78.49999999999953, -87.70000000000029, -127.30000000000024, -102.70000000000026, 17.60000000000013, -105.70000000000029, -190.30000000000018, -35.19999999999995, -147.10000000000022, -1.2999999999999627, -39.69999999999994, 53.00000000000008, 98.89999999999964, 1.0999999999999865, 47.600000000000165, -115.60000000000005, -211.30000000000007, 5.299999999999982, -170.20000000000033, -85.60000000000002, -48.99999999999994, -124.90000000000043, -151.3000000000005, -104.8000000000003, -148.60000000000025, 71.89999999999986, 78.19999999999993, -42.699999999999925, -30.40000000000002, 98.89999999999961, 58.400000000000134], "policy_predator_policy_reward": [110.0, 23.0, 67.0, 39.0, 33.0, 74.0, 91.0, 36.0, 24.0, 27.0, 124.0, 119.0, 159.0, 195.0, 51.0, 6.0, 20.0, 16.0, 15.0, 6.0, 50.0, 3.0, 7.0, 3.0, 42.0, 133.0, 15.0, 37.0, 70.0, 13.0, 39.0, 86.0, 12.0, 43.0, 85.0, 39.0, 37.0, 18.0, 79.0, 43.0, 94.0, 77.0, 58.0, 62.0, 59.0, 39.0, 25.0, 79.0, 7.0, 13.0, 58.0, 31.0, 2.0, 171.0, 22.0, 17.0, 61.0, 88.0, 92.0, 125.0, 9.0, 69.0, 2.0, 72.0, 18.0, 62.0, 16.0, 48.0, 88.0, 10.0, 50.0, 18.0, 27.0, 35.0, 8.0, 135.0, 128.0, 8.0, 14.0, 13.0, 34.0, 52.0, 78.0, 84.0, 6.0, 10.0, 66.0, 57.0, 129.0, 145.0, 62.0, 44.0, 80.0, 1.0, 23.0, 89.0, 47.0, 80.0, 139.0, 148.0, 75.0, 92.0, 79.0, 73.0, 107.0, 80.0, 64.0, 58.0, 71.0, 0.0, 35.0, 25.0, 2.0, 79.0, 100.0, 57.0, 90.0, 69.0, 36.0, 93.0, 117.0, 64.0, 31.0, 32.0, 100.0, 24.0, 53.0, 76.0, 39.0, 81.0, 124.0, 119.0, 11.0, 15.0, 101.0, 71.0, 0.0, 28.0, 83.0, 79.0, 52.0, 13.0, 132.0, 97.0, 87.0, 39.0, 32.0, 90.0, 6.0, 123.0, 5.0, 8.0, 25.0, 87.0, 15.0, 48.0, 55.0, 61.0, 35.0, 39.0, 6.0, 3.0, 10.0, 1.0, 145.0, 106.0, 91.0, 75.0, 0.0, 49.0, 100.0, 62.0, 46.0, 72.0, 73.0, 107.0, 33.0, 93.0, 68.0, 43.0, 22.0, 34.0, 0.0, 25.0, 94.0, 104.0, 44.0, 73.0, 100.0, 60.0, 89.0, 107.0, 12.0, 125.0, 6.0, 45.0, 9.0, 53.0, 12.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7974620573595769, "mean_inference_ms": 2.0850470051293146, "mean_action_processing_ms": 0.33701321257521255, "mean_env_wait_ms": 0.2644905905872356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004683732986450195, "StateBufferConnector_ms": 0.008442282676696777, "ViewRequirementAgentConnector_ms": 0.21739614009857178}, "num_episodes": 22, "episode_return_max": 328.70000000000084, "episode_return_min": -166.60000000000022, "episode_return_mean": 74.1689999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.9801128396376, "num_env_steps_trained_throughput_per_sec": 310.9801128396376, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 12571.166, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12571.092, "sample_time_ms": 2024.6, "learn_time_ms": 10506.489, "learn_throughput": 380.717, "synch_weights_time_ms": 36.165}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-00-43", "timestamp": 1723647643, "time_this_iter_s": 12.922384262084961, "time_total_s": 811.2230184078217, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a33af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 811.2230184078217, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 48.52777777777777, "ram_util_percent": 82.44444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.995351645902351, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.34892608450834, "policy_loss": -0.006699658187214659, "vf_loss": 9.353042828090608, "vf_explained_var": -0.27603304660509503, "kl": 0.009070268529359448, "entropy": 1.4341646800596248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.622630846878839, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.766782210112879, "policy_loss": -0.004822251535508604, "vf_loss": 7.77105197477593, "vf_explained_var": 0.08268029317653999, "kl": 0.007366439873417369, "entropy": 0.6360297734144503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 310.3000000000002, "episode_reward_min": -166.60000000000022, "episode_reward_mean": 41.53899999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -326.7999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.49999999999991, "predator_policy": 171.0}, "policy_reward_mean": {"prey_policy": -38.540500000000065, "predator_policy": 59.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [265.69999999999993, 129.5999999999995, -0.49999999999998757, 72.69999999999953, 92.39999999999952, 104.09999999999968, 306.6000000000002, 135.2999999999995, 1.1999999999999922, 310.3000000000002, 64.80000000000013, -166.60000000000022, 119.49999999999997, 155.69999999999953, 88.19999999999999, 115.39999999999966, 46.199999999999875, 128.39999999999955, 185.09999999999988, -112.80000000000013, -74.19999999999999, 107.19999999999891, 133.4999999999999, 171.39999999999995, 274.09999999999945, 68.80000000000004, 17.300000000000068, 34.400000000000055, 105.09999999999982, -2.4999999999999893, 32.00000000000006, -141.30000000000018, 35.70000000000001, 41.39999999999995, 43.99999999999983, 217.19999999999993, 200.39999999999986, 198.39999999999966, 17.800000000000047, 50.00000000000001, -65.30000000000052, 21.100000000000016, -66.4000000000004, 146.1999999999997, -40.89999999999994, -79.70000000000007, 52.89999999999916, -48.79999999999991, 305.4000000000001, -122.80000000000007, 147.1999999999996, 1.900000000000034, 25.80000000000029, -73.59999999999991, 11.800000000000054, -82.50000000000037, -95.90000000000033, 169.39999999999904, 58.999999999999964, 80.19999999999973, 164.39999999999927, 246.59999999999954, 271.30000000000024, 173.09999999999917, -114.3000000000003, 37.99999999999954, 135.49999999999915, -52.999999999999844, 32.90000000000029, -116.00000000000057, -56.300000000000225, 69.99999999999967, 207.8999999999993, 73.69999999999986, -128.90000000000006, -47.89999999999966, 25.40000000000019, -80.20000000000087, -116.40000000000056, 201.09999999999962, -11.100000000000012, 187.2999999999991, -142.20000000000064, -7.000000000000005, -47.199999999999775, 27.100000000000154, -86.40000000000009, -30.599999999999845, -35.99999999999999, -117.0000000000007, 6.199999999999986, -133.90000000000015, 4.299999999999924, -79.40000000000052, -96.80000000000001, 12.700000000000015, -85.90000000000039, -74.99999999999986, 1.5000000000001696, 19.40000000000029], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [99.79999999999987, 110.89999999999992, -28.89999999999998, 36.500000000000085, 67.69999999999975, -239.20000000000024, -18.099999999999948, -29.199999999999925, 1.099999999999989, -6.699999999999946, 31.100000000000044, -30.999999999999975, 125.59999999999991, 160.99999999999991, -30.099999999999966, 76.39999999999964, 154.69999999999987, -326.5, 150.49999999999997, 120.79999999999993, -41.20000000000021, -42.99999999999996, -326.7999999999997, -56.80000000000002, 23.30000000000001, 18.200000000000006, 52.700000000000095, 29.00000000000003, 13.100000000000001, -4.900000000000006, 15.800000000000045, 35.60000000000003, -43.89999999999999, -7.899999999999981, 73.4, -12.999999999999986, 39.800000000000054, 83.30000000000001, -108.10000000000005, -147.70000000000005, -108.70000000000005, -101.49999999999997, 60.20000000000014, 20.000000000000014, 9.500000000000012, 37.99999999999999, 91.39999999999996, -82.00000000000014, 141.49999999999997, 116.59999999999984, -25.899999999999977, -28.299999999999997, 27.2, -283.89999999999975, -22.900000000000002, -48.69999999999996, 34.700000000000024, -10.599999999999996, -26.79999999999997, -87.70000000000024, -94.90000000000009, -0.0999999999999801, -130.30000000000004, -297.9999999999996, 24.800000000000004, -156.1000000000001, 65.59999999999994, -176.20000000000007, -104.19999999999999, -38.79999999999998, -2.8000000000001224, 97.99999999999994, 79.1, 50.29999999999996, 34.70000000000007, 103.6999999999999, -27.700000000000003, -35.5, 85.39999999999998, -192.4, -37.899999999999956, -186.40000000000038, -4.599999999999989, -103.30000000000004, -185.2000000000002, -62.19999999999982, 53.599999999999994, 29.6, -135.70000000000024, -29.20000000000001, -142.60000000000034, -66.1, -44.199999999999875, -22.899999999999917, -204.10000000000002, -87.6999999999999, 135.79999999999993, 143.6, -164.20000000000005, -130.60000000000016, 88.39999999999989, 30.80000000000004, -96.39999999999998, -63.699999999999946, -27.70000000000001, -11.500000000000036, -175.00000000000006, -127.60000000000004, -47.19999999999998, -66.99999999999997, -87.40000000000019, -117.10000000000028, -158.8000000000001, -66.1, 110.89999999999972, 45.50000000000005, -5.499999999999964, -47.499999999999915, -15.399999999999979, 32.60000000000003, 97.99999999999986, -49.60000000000017, 91.1, 81.50000000000003, 177.49999999999991, 84.7999999999999, 98.2999999999995, 63.80000000000004, -152.80000000000018, -212.50000000000014, -109.90000000000009, -18.099999999999913, 8.00000000000002, 78.49999999999953, -87.70000000000029, -127.30000000000024, -102.70000000000026, 17.60000000000013, -105.70000000000029, -190.30000000000018, -35.19999999999995, -147.10000000000022, -1.2999999999999627, -39.69999999999994, 53.00000000000008, 98.89999999999964, 1.0999999999999865, 47.600000000000165, -115.60000000000005, -211.30000000000007, 5.299999999999982, -170.20000000000033, -85.60000000000002, -48.99999999999994, -124.90000000000043, -151.3000000000005, -104.8000000000003, -148.60000000000025, 71.89999999999986, 78.19999999999993, -42.699999999999925, -30.40000000000002, 98.89999999999961, 58.400000000000134, -167.8000000000003, -156.40000000000032, -57.99999999999979, -39.999999999999815, -74.80000000000034, -108.40000000000035, -30.10000000000001, -17.79999999999974, -102.40000000000023, -100.00000000000014, -137.5000000000003, -39.09999999999991, -103.90000000000015, -63.09999999999999, -220.60000000000042, -111.4000000000002, -66.70000000000005, -18.099999999999895, -156.70000000000016, -128.20000000000007, -16.900000000000013, -95.80000000000065, -120.10000000000032, -118.30000000000031, -202.60000000000016, -107.19999999999996, -75.09999999999997, -11.200000000000012, -80.80000000000014, -156.1000000000004, -167.20000000000016, -116.79999999999995, -75.40000000000003, -42.09999999999993, -79.60000000000028, -4.000000000000033], "policy_predator_policy_reward": [37.0, 18.0, 79.0, 43.0, 94.0, 77.0, 58.0, 62.0, 59.0, 39.0, 25.0, 79.0, 7.0, 13.0, 58.0, 31.0, 2.0, 171.0, 22.0, 17.0, 61.0, 88.0, 92.0, 125.0, 9.0, 69.0, 2.0, 72.0, 18.0, 62.0, 16.0, 48.0, 88.0, 10.0, 50.0, 18.0, 27.0, 35.0, 8.0, 135.0, 128.0, 8.0, 14.0, 13.0, 34.0, 52.0, 78.0, 84.0, 6.0, 10.0, 66.0, 57.0, 129.0, 145.0, 62.0, 44.0, 80.0, 1.0, 23.0, 89.0, 47.0, 80.0, 139.0, 148.0, 75.0, 92.0, 79.0, 73.0, 107.0, 80.0, 64.0, 58.0, 71.0, 0.0, 35.0, 25.0, 2.0, 79.0, 100.0, 57.0, 90.0, 69.0, 36.0, 93.0, 117.0, 64.0, 31.0, 32.0, 100.0, 24.0, 53.0, 76.0, 39.0, 81.0, 124.0, 119.0, 11.0, 15.0, 101.0, 71.0, 0.0, 28.0, 83.0, 79.0, 52.0, 13.0, 132.0, 97.0, 87.0, 39.0, 32.0, 90.0, 6.0, 123.0, 5.0, 8.0, 25.0, 87.0, 15.0, 48.0, 55.0, 61.0, 35.0, 39.0, 6.0, 3.0, 10.0, 1.0, 145.0, 106.0, 91.0, 75.0, 0.0, 49.0, 100.0, 62.0, 46.0, 72.0, 73.0, 107.0, 33.0, 93.0, 68.0, 43.0, 22.0, 34.0, 0.0, 25.0, 94.0, 104.0, 44.0, 73.0, 100.0, 60.0, 89.0, 107.0, 12.0, 125.0, 6.0, 45.0, 9.0, 53.0, 12.0, 18.0, 113.0, 69.0, 58.0, 33.0, 79.0, 57.0, 27.0, 48.0, 68.0, 48.0, 59.0, 87.0, 54.0, 77.0, 143.0, 72.0, 49.0, 42.0, 94.0, 57.0, 50.0, 67.0, 81.0, 78.0, 98.0, 115.0, 51.0, 48.0, 122.0, 29.0, 106.0, 103.0, 56.0, 63.0, 49.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8014466060436277, "mean_inference_ms": 2.09448105814403, "mean_action_processing_ms": 0.33921087262697014, "mean_env_wait_ms": 0.2660257341338401, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004574894905090332, "StateBufferConnector_ms": 0.008126258850097656, "ViewRequirementAgentConnector_ms": 0.20839715003967285}, "num_episodes": 18, "episode_return_max": 310.3000000000002, "episode_return_min": -166.60000000000022, "episode_return_mean": 41.53899999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 315.96138115361805, "num_env_steps_trained_throughput_per_sec": 315.96138115361805, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 12600.033, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12599.962, "sample_time_ms": 2086.962, "learn_time_ms": 10480.621, "learn_throughput": 381.657, "synch_weights_time_ms": 30.659}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-00-56", "timestamp": 1723647656, "time_this_iter_s": 12.6999990940094, "time_total_s": 823.923017501831, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee18ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 823.923017501831, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 49.588888888888896, "ram_util_percent": 82.45555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.187745234039094, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.428368322937576, "policy_loss": -0.006968480330231604, "vf_loss": 8.43240914521394, "vf_explained_var": -0.44476991573338787, "kl": 0.0102809539777156, "entropy": 1.4186233067007923, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.201238767432157, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.0645522589406005, "policy_loss": -0.00250186183115359, "vf_loss": 6.066633979353324, "vf_explained_var": -0.009407289917506868, "kl": 0.005601591370103034, "entropy": 0.6386650354458542, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 305.4000000000001, "episode_reward_min": -142.20000000000064, "episode_reward_mean": 24.473999999999872, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -297.9999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.49999999999991, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": -44.60800000000007, "predator_policy": 56.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [171.39999999999995, 274.09999999999945, 68.80000000000004, 17.300000000000068, 34.400000000000055, 105.09999999999982, -2.4999999999999893, 32.00000000000006, -141.30000000000018, 35.70000000000001, 41.39999999999995, 43.99999999999983, 217.19999999999993, 200.39999999999986, 198.39999999999966, 17.800000000000047, 50.00000000000001, -65.30000000000052, 21.100000000000016, -66.4000000000004, 146.1999999999997, -40.89999999999994, -79.70000000000007, 52.89999999999916, -48.79999999999991, 305.4000000000001, -122.80000000000007, 147.1999999999996, 1.900000000000034, 25.80000000000029, -73.59999999999991, 11.800000000000054, -82.50000000000037, -95.90000000000033, 169.39999999999904, 58.999999999999964, 80.19999999999973, 164.39999999999927, 246.59999999999954, 271.30000000000024, 173.09999999999917, -114.3000000000003, 37.99999999999954, 135.49999999999915, -52.999999999999844, 32.90000000000029, -116.00000000000057, -56.300000000000225, 69.99999999999967, 207.8999999999993, 73.69999999999986, -128.90000000000006, -47.89999999999966, 25.40000000000019, -80.20000000000087, -116.40000000000056, 201.09999999999962, -11.100000000000012, 187.2999999999991, -142.20000000000064, -7.000000000000005, -47.199999999999775, 27.100000000000154, -86.40000000000009, -30.599999999999845, -35.99999999999999, -117.0000000000007, 6.199999999999986, -133.90000000000015, 4.299999999999924, -79.40000000000052, -96.80000000000001, 12.700000000000015, -85.90000000000039, -74.99999999999986, 1.5000000000001696, 19.40000000000029, -63.09999999999991, -35.299999999999756, 61.00000000000038, 46.50000000000037, 14.600000000000067, -19.899999999999885, 24.400000000000222, -31.299999999999926, 85.89999999999938, 45.30000000000039, 38.000000000000284, 84.99999999999906, 23.600000000000136, -45.499999999999744, -3.2999999999998444, 30.800000000000438, 38.100000000000314, 16.400000000000198, 74.59999999999903, 50.800000000000324, 40.29999999999972, 10.100000000000202, 14.299999999999908], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [91.39999999999996, -82.00000000000014, 141.49999999999997, 116.59999999999984, -25.899999999999977, -28.299999999999997, 27.2, -283.89999999999975, -22.900000000000002, -48.69999999999996, 34.700000000000024, -10.599999999999996, -26.79999999999997, -87.70000000000024, -94.90000000000009, -0.0999999999999801, -130.30000000000004, -297.9999999999996, 24.800000000000004, -156.1000000000001, 65.59999999999994, -176.20000000000007, -104.19999999999999, -38.79999999999998, -2.8000000000001224, 97.99999999999994, 79.1, 50.29999999999996, 34.70000000000007, 103.6999999999999, -27.700000000000003, -35.5, 85.39999999999998, -192.4, -37.899999999999956, -186.40000000000038, -4.599999999999989, -103.30000000000004, -185.2000000000002, -62.19999999999982, 53.599999999999994, 29.6, -135.70000000000024, -29.20000000000001, -142.60000000000034, -66.1, -44.199999999999875, -22.899999999999917, -204.10000000000002, -87.6999999999999, 135.79999999999993, 143.6, -164.20000000000005, -130.60000000000016, 88.39999999999989, 30.80000000000004, -96.39999999999998, -63.699999999999946, -27.70000000000001, -11.500000000000036, -175.00000000000006, -127.60000000000004, -47.19999999999998, -66.99999999999997, -87.40000000000019, -117.10000000000028, -158.8000000000001, -66.1, 110.89999999999972, 45.50000000000005, -5.499999999999964, -47.499999999999915, -15.399999999999979, 32.60000000000003, 97.99999999999986, -49.60000000000017, 91.1, 81.50000000000003, 177.49999999999991, 84.7999999999999, 98.2999999999995, 63.80000000000004, -152.80000000000018, -212.50000000000014, -109.90000000000009, -18.099999999999913, 8.00000000000002, 78.49999999999953, -87.70000000000029, -127.30000000000024, -102.70000000000026, 17.60000000000013, -105.70000000000029, -190.30000000000018, -35.19999999999995, -147.10000000000022, -1.2999999999999627, -39.69999999999994, 53.00000000000008, 98.89999999999964, 1.0999999999999865, 47.600000000000165, -115.60000000000005, -211.30000000000007, 5.299999999999982, -170.20000000000033, -85.60000000000002, -48.99999999999994, -124.90000000000043, -151.3000000000005, -104.8000000000003, -148.60000000000025, 71.89999999999986, 78.19999999999993, -42.699999999999925, -30.40000000000002, 98.89999999999961, 58.400000000000134, -167.8000000000003, -156.40000000000032, -57.99999999999979, -39.999999999999815, -74.80000000000034, -108.40000000000035, -30.10000000000001, -17.79999999999974, -102.40000000000023, -100.00000000000014, -137.5000000000003, -39.09999999999991, -103.90000000000015, -63.09999999999999, -220.60000000000042, -111.4000000000002, -66.70000000000005, -18.099999999999895, -156.70000000000016, -128.20000000000007, -16.900000000000013, -95.80000000000065, -120.10000000000032, -118.30000000000031, -202.60000000000016, -107.19999999999996, -75.09999999999997, -11.200000000000012, -80.80000000000014, -156.1000000000004, -167.20000000000016, -116.79999999999995, -75.40000000000003, -42.09999999999993, -79.60000000000028, -4.000000000000033, -98.80000000000032, -85.29999999999993, -45.99999999999987, -193.30000000000055, -3.6999999999999797, 25.70000000000008, 23.900000000000162, -24.399999999999764, -29.5, 1.0999999999999794, -19.30000000000001, -94.60000000000065, 20.000000000000014, -10.60000000000002, -120.09999999999995, -41.1999999999999, 63.19999999999979, -52.29999999999979, 4.69999999999994, 2.6000000000000854, 3.199999999999988, -8.199999999999998, 61.69999999999976, -51.699999999999996, -21.99999999999983, -30.39999999999975, -104.50000000000051, -30.999999999999883, -3.3999999999999404, -109.90000000000005, 9.200000000000003, -27.39999999999999, -28.59999999999998, -19.299999999999947, -41.499999999999886, -0.10000000000001341, 9.499999999999964, 31.100000000000144, 41.90000000000018, -42.09999999999982, -4.899999999999887, -86.80000000000024, -39.69999999999999, -83.19999999999997, 20.000000000000014, -42.69999999999983], "policy_predator_policy_reward": [78.0, 84.0, 6.0, 10.0, 66.0, 57.0, 129.0, 145.0, 62.0, 44.0, 80.0, 1.0, 23.0, 89.0, 47.0, 80.0, 139.0, 148.0, 75.0, 92.0, 79.0, 73.0, 107.0, 80.0, 64.0, 58.0, 71.0, 0.0, 35.0, 25.0, 2.0, 79.0, 100.0, 57.0, 90.0, 69.0, 36.0, 93.0, 117.0, 64.0, 31.0, 32.0, 100.0, 24.0, 53.0, 76.0, 39.0, 81.0, 124.0, 119.0, 11.0, 15.0, 101.0, 71.0, 0.0, 28.0, 83.0, 79.0, 52.0, 13.0, 132.0, 97.0, 87.0, 39.0, 32.0, 90.0, 6.0, 123.0, 5.0, 8.0, 25.0, 87.0, 15.0, 48.0, 55.0, 61.0, 35.0, 39.0, 6.0, 3.0, 10.0, 1.0, 145.0, 106.0, 91.0, 75.0, 0.0, 49.0, 100.0, 62.0, 46.0, 72.0, 73.0, 107.0, 33.0, 93.0, 68.0, 43.0, 22.0, 34.0, 0.0, 25.0, 94.0, 104.0, 44.0, 73.0, 100.0, 60.0, 89.0, 107.0, 12.0, 125.0, 6.0, 45.0, 9.0, 53.0, 12.0, 18.0, 113.0, 69.0, 58.0, 33.0, 79.0, 57.0, 27.0, 48.0, 68.0, 48.0, 59.0, 87.0, 54.0, 77.0, 143.0, 72.0, 49.0, 42.0, 94.0, 57.0, 50.0, 67.0, 81.0, 78.0, 98.0, 115.0, 51.0, 48.0, 122.0, 29.0, 106.0, 103.0, 56.0, 63.0, 49.0, 54.0, 77.0, 44.0, 106.0, 98.0, 4.0, 35.0, 16.0, 31.0, 23.0, 20.0, 22.0, 72.0, 5.0, 10.0, 73.0, 57.0, 27.0, 48.0, 15.0, 23.0, 24.0, 19.0, 34.0, 41.0, 36.0, 40.0, 78.0, 12.0, 54.0, 56.0, 27.0, 22.0, 43.0, 43.0, 35.0, 23.0, 17.0, 17.0, 47.0, 4.0, 67.0, 65.0, 61.0, 72.0, 27.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8055789736510964, "mean_inference_ms": 2.1062858299289573, "mean_action_processing_ms": 0.3408515207707755, "mean_env_wait_ms": 0.2677485958932697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005736351013183594, "StateBufferConnector_ms": 0.010428905487060547, "ViewRequirementAgentConnector_ms": 0.2052217721939087}, "num_episodes": 23, "episode_return_max": 305.4000000000001, "episode_return_min": -142.20000000000064, "episode_return_mean": 24.473999999999872, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.69642701207795, "num_env_steps_trained_throughput_per_sec": 318.69642701207795, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 12605.519, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12605.449, "sample_time_ms": 2108.641, "learn_time_ms": 10464.517, "learn_throughput": 382.244, "synch_weights_time_ms": 30.503}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-01-08", "timestamp": 1723647668, "time_this_iter_s": 12.61018991470337, "time_total_s": 836.5332074165344, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee18d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 836.5332074165344, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 48.72222222222222, "ram_util_percent": 82.5111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3648635326554537, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.469091214074028, "policy_loss": -0.005546280075968415, "vf_loss": 8.472712411577739, "vf_explained_var": -0.6944462903592953, "kl": 0.006760250899121934, "entropy": 1.434276291365346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.241948085487204, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.9687952768234975, "policy_loss": -0.0020489976455570842, "vf_loss": 6.970175020278446, "vf_explained_var": 0.05399612415404547, "kl": 0.00892331352271055, "entropy": 0.5872978161567103, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 305.4000000000001, "episode_reward_min": -142.20000000000064, "episode_reward_mean": 10.565999999999915, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -220.60000000000042, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.49999999999991, "predator_policy": 145.0}, "policy_reward_mean": {"prey_policy": -46.79200000000006, "predator_policy": 52.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.100000000000016, -66.4000000000004, 146.1999999999997, -40.89999999999994, -79.70000000000007, 52.89999999999916, -48.79999999999991, 305.4000000000001, -122.80000000000007, 147.1999999999996, 1.900000000000034, 25.80000000000029, -73.59999999999991, 11.800000000000054, -82.50000000000037, -95.90000000000033, 169.39999999999904, 58.999999999999964, 80.19999999999973, 164.39999999999927, 246.59999999999954, 271.30000000000024, 173.09999999999917, -114.3000000000003, 37.99999999999954, 135.49999999999915, -52.999999999999844, 32.90000000000029, -116.00000000000057, -56.300000000000225, 69.99999999999967, 207.8999999999993, 73.69999999999986, -128.90000000000006, -47.89999999999966, 25.40000000000019, -80.20000000000087, -116.40000000000056, 201.09999999999962, -11.100000000000012, 187.2999999999991, -142.20000000000064, -7.000000000000005, -47.199999999999775, 27.100000000000154, -86.40000000000009, -30.599999999999845, -35.99999999999999, -117.0000000000007, 6.199999999999986, -133.90000000000015, 4.299999999999924, -79.40000000000052, -96.80000000000001, 12.700000000000015, -85.90000000000039, -74.99999999999986, 1.5000000000001696, 19.40000000000029, -63.09999999999991, -35.299999999999756, 61.00000000000038, 46.50000000000037, 14.600000000000067, -19.899999999999885, 24.400000000000222, -31.299999999999926, 85.89999999999938, 45.30000000000039, 38.000000000000284, 84.99999999999906, 23.600000000000136, -45.499999999999744, -3.2999999999998444, 30.800000000000438, 38.100000000000314, 16.400000000000198, 74.59999999999903, 50.800000000000324, 40.29999999999972, 10.100000000000202, 14.299999999999908, -71.99999999999986, -40.49999999999988, -14.299999999999983, -4.100000000000019, 36.99999999999992, 31.200000000000163, 14.800000000000201, 25.800000000000388, -4.100000000000076, -63.600000000000435, -64.29999999999973, 33.50000000000021, -14.900000000000055, 33.20000000000038, -47.89999999999964, -3.2000000000000073, 40.00000000000034, 21.50000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-4.599999999999989, -103.30000000000004, -185.2000000000002, -62.19999999999982, 53.599999999999994, 29.6, -135.70000000000024, -29.20000000000001, -142.60000000000034, -66.1, -44.199999999999875, -22.899999999999917, -204.10000000000002, -87.6999999999999, 135.79999999999993, 143.6, -164.20000000000005, -130.60000000000016, 88.39999999999989, 30.80000000000004, -96.39999999999998, -63.699999999999946, -27.70000000000001, -11.500000000000036, -175.00000000000006, -127.60000000000004, -47.19999999999998, -66.99999999999997, -87.40000000000019, -117.10000000000028, -158.8000000000001, -66.1, 110.89999999999972, 45.50000000000005, -5.499999999999964, -47.499999999999915, -15.399999999999979, 32.60000000000003, 97.99999999999986, -49.60000000000017, 91.1, 81.50000000000003, 177.49999999999991, 84.7999999999999, 98.2999999999995, 63.80000000000004, -152.80000000000018, -212.50000000000014, -109.90000000000009, -18.099999999999913, 8.00000000000002, 78.49999999999953, -87.70000000000029, -127.30000000000024, -102.70000000000026, 17.60000000000013, -105.70000000000029, -190.30000000000018, -35.19999999999995, -147.10000000000022, -1.2999999999999627, -39.69999999999994, 53.00000000000008, 98.89999999999964, 1.0999999999999865, 47.600000000000165, -115.60000000000005, -211.30000000000007, 5.299999999999982, -170.20000000000033, -85.60000000000002, -48.99999999999994, -124.90000000000043, -151.3000000000005, -104.8000000000003, -148.60000000000025, 71.89999999999986, 78.19999999999993, -42.699999999999925, -30.40000000000002, 98.89999999999961, 58.400000000000134, -167.8000000000003, -156.40000000000032, -57.99999999999979, -39.999999999999815, -74.80000000000034, -108.40000000000035, -30.10000000000001, -17.79999999999974, -102.40000000000023, -100.00000000000014, -137.5000000000003, -39.09999999999991, -103.90000000000015, -63.09999999999999, -220.60000000000042, -111.4000000000002, -66.70000000000005, -18.099999999999895, -156.70000000000016, -128.20000000000007, -16.900000000000013, -95.80000000000065, -120.10000000000032, -118.30000000000031, -202.60000000000016, -107.19999999999996, -75.09999999999997, -11.200000000000012, -80.80000000000014, -156.1000000000004, -167.20000000000016, -116.79999999999995, -75.40000000000003, -42.09999999999993, -79.60000000000028, -4.000000000000033, -98.80000000000032, -85.29999999999993, -45.99999999999987, -193.30000000000055, -3.6999999999999797, 25.70000000000008, 23.900000000000162, -24.399999999999764, -29.5, 1.0999999999999794, -19.30000000000001, -94.60000000000065, 20.000000000000014, -10.60000000000002, -120.09999999999995, -41.1999999999999, 63.19999999999979, -52.29999999999979, 4.69999999999994, 2.6000000000000854, 3.199999999999988, -8.199999999999998, 61.69999999999976, -51.699999999999996, -21.99999999999983, -30.39999999999975, -104.50000000000051, -30.999999999999883, -3.3999999999999404, -109.90000000000005, 9.200000000000003, -27.39999999999999, -28.59999999999998, -19.299999999999947, -41.499999999999886, -0.10000000000001341, 9.499999999999964, 31.100000000000144, 41.90000000000018, -42.09999999999982, -4.899999999999887, -86.80000000000024, -39.69999999999999, -83.19999999999997, 20.000000000000014, -42.69999999999983, -126.10000000000024, -64.89999999999995, -64.90000000000006, -70.59999999999997, -23.80000000000003, -107.5000000000005, -0.9999999999999846, -75.09999999999991, 1.4000000000001456, -36.399999999999984, 9.499999999999964, 13.699999999999964, -19.000000000000014, -20.199999999999996, -22.00000000000003, -41.19999999999984, -19.299999999999976, -41.799999999999784, -99.10000000000053, -59.499999999999794, -30.70000000000002, -193.6000000000003, 7.399999999999965, -31.899999999999878, -54.099999999999916, -71.80000000000021, 2.300000000000148, -42.09999999999996, -36.99999999999979, -97.90000000000057, -36.99999999999985, -50.19999999999992, 9.199999999999953, -5.200000000000019, -27.69999999999989, -53.79999999999995], "policy_predator_policy_reward": [36.0, 93.0, 117.0, 64.0, 31.0, 32.0, 100.0, 24.0, 53.0, 76.0, 39.0, 81.0, 124.0, 119.0, 11.0, 15.0, 101.0, 71.0, 0.0, 28.0, 83.0, 79.0, 52.0, 13.0, 132.0, 97.0, 87.0, 39.0, 32.0, 90.0, 6.0, 123.0, 5.0, 8.0, 25.0, 87.0, 15.0, 48.0, 55.0, 61.0, 35.0, 39.0, 6.0, 3.0, 10.0, 1.0, 145.0, 106.0, 91.0, 75.0, 0.0, 49.0, 100.0, 62.0, 46.0, 72.0, 73.0, 107.0, 33.0, 93.0, 68.0, 43.0, 22.0, 34.0, 0.0, 25.0, 94.0, 104.0, 44.0, 73.0, 100.0, 60.0, 89.0, 107.0, 12.0, 125.0, 6.0, 45.0, 9.0, 53.0, 12.0, 18.0, 113.0, 69.0, 58.0, 33.0, 79.0, 57.0, 27.0, 48.0, 68.0, 48.0, 59.0, 87.0, 54.0, 77.0, 143.0, 72.0, 49.0, 42.0, 94.0, 57.0, 50.0, 67.0, 81.0, 78.0, 98.0, 115.0, 51.0, 48.0, 122.0, 29.0, 106.0, 103.0, 56.0, 63.0, 49.0, 54.0, 77.0, 44.0, 106.0, 98.0, 4.0, 35.0, 16.0, 31.0, 23.0, 20.0, 22.0, 72.0, 5.0, 10.0, 73.0, 57.0, 27.0, 48.0, 15.0, 23.0, 24.0, 19.0, 34.0, 41.0, 36.0, 40.0, 78.0, 12.0, 54.0, 56.0, 27.0, 22.0, 43.0, 43.0, 35.0, 23.0, 17.0, 17.0, 47.0, 4.0, 67.0, 65.0, 61.0, 72.0, 27.0, 10.0, 43.0, 76.0, 64.0, 31.0, 69.0, 48.0, 33.0, 39.0, 21.0, 51.0, 5.0, 3.0, 21.0, 33.0, 57.0, 32.0, 12.0, 45.0, 65.0, 30.0, 60.0, 100.0, 31.0, 27.0, 57.0, 54.0, 26.0, 47.0, 27.0, 60.0, 41.0, 43.0, 26.0, 10.0, 78.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8088946625061147, "mean_inference_ms": 2.1160946278092094, "mean_action_processing_ms": 0.3420753603578061, "mean_env_wait_ms": 0.26900759448838585, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005863547325134277, "StateBufferConnector_ms": 0.007575511932373047, "ViewRequirementAgentConnector_ms": 0.18789398670196533}, "num_episodes": 18, "episode_return_max": 305.4000000000001, "episode_return_min": -142.20000000000064, "episode_return_mean": 10.565999999999915, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.98931867301195, "num_env_steps_trained_throughput_per_sec": 310.98931867301195, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 12647.077, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12647.007, "sample_time_ms": 2146.341, "learn_time_ms": 10467.823, "learn_throughput": 382.123, "synch_weights_time_ms": 30.929}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-01-21", "timestamp": 1723647681, "time_this_iter_s": 12.952632188796997, "time_total_s": 849.4858396053314, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee071f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 849.4858396053314, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 49.58888888888889, "ram_util_percent": 82.72222222222221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.664134866409201, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.194202196787273, "policy_loss": -0.00633064116839142, "vf_loss": 8.19764802216222, "vf_explained_var": -0.7230202935360096, "kl": 0.010130399115887388, "entropy": 1.4292138270600132, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.4273135100092205, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.543094174067179, "policy_loss": -0.0045777918630471775, "vf_loss": 6.547247262732692, "vf_explained_var": 0.027927645552095284, "kl": 0.005662836796848712, "entropy": 0.5913368861668955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 271.30000000000024, "episode_reward_min": -142.20000000000064, "episode_reward_mean": 6.775999999999962, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -220.60000000000042, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.49999999999991, "predator_policy": 145.0}, "policy_reward_mean": {"prey_policy": -44.79700000000006, "predator_policy": 48.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [80.19999999999973, 164.39999999999927, 246.59999999999954, 271.30000000000024, 173.09999999999917, -114.3000000000003, 37.99999999999954, 135.49999999999915, -52.999999999999844, 32.90000000000029, -116.00000000000057, -56.300000000000225, 69.99999999999967, 207.8999999999993, 73.69999999999986, -128.90000000000006, -47.89999999999966, 25.40000000000019, -80.20000000000087, -116.40000000000056, 201.09999999999962, -11.100000000000012, 187.2999999999991, -142.20000000000064, -7.000000000000005, -47.199999999999775, 27.100000000000154, -86.40000000000009, -30.599999999999845, -35.99999999999999, -117.0000000000007, 6.199999999999986, -133.90000000000015, 4.299999999999924, -79.40000000000052, -96.80000000000001, 12.700000000000015, -85.90000000000039, -74.99999999999986, 1.5000000000001696, 19.40000000000029, -63.09999999999991, -35.299999999999756, 61.00000000000038, 46.50000000000037, 14.600000000000067, -19.899999999999885, 24.400000000000222, -31.299999999999926, 85.89999999999938, 45.30000000000039, 38.000000000000284, 84.99999999999906, 23.600000000000136, -45.499999999999744, -3.2999999999998444, 30.800000000000438, 38.100000000000314, 16.400000000000198, 74.59999999999903, 50.800000000000324, 40.29999999999972, 10.100000000000202, 14.299999999999908, -71.99999999999986, -40.49999999999988, -14.299999999999983, -4.100000000000019, 36.99999999999992, 31.200000000000163, 14.800000000000201, 25.800000000000388, -4.100000000000076, -63.600000000000435, -64.29999999999973, 33.50000000000021, -14.900000000000055, 33.20000000000038, -47.89999999999964, -3.2000000000000073, 40.00000000000034, 21.50000000000027, -76.9000000000002, 53.10000000000037, -55.799999999999855, 18.90000000000019, 48.199999999998994, 63.19999999999868, -48.399999999999814, 36.60000000000011, 38.70000000000028, -35.799999999999635, 39.90000000000034, -15.499999999999645, -46.09999999999959, -25.099999999999667, -13.399999999999975, -18.99999999999964, 36.100000000000186, -47.599999999999575], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.399999999999979, 32.60000000000003, 97.99999999999986, -49.60000000000017, 91.1, 81.50000000000003, 177.49999999999991, 84.7999999999999, 98.2999999999995, 63.80000000000004, -152.80000000000018, -212.50000000000014, -109.90000000000009, -18.099999999999913, 8.00000000000002, 78.49999999999953, -87.70000000000029, -127.30000000000024, -102.70000000000026, 17.60000000000013, -105.70000000000029, -190.30000000000018, -35.19999999999995, -147.10000000000022, -1.2999999999999627, -39.69999999999994, 53.00000000000008, 98.89999999999964, 1.0999999999999865, 47.600000000000165, -115.60000000000005, -211.30000000000007, 5.299999999999982, -170.20000000000033, -85.60000000000002, -48.99999999999994, -124.90000000000043, -151.3000000000005, -104.8000000000003, -148.60000000000025, 71.89999999999986, 78.19999999999993, -42.699999999999925, -30.40000000000002, 98.89999999999961, 58.400000000000134, -167.8000000000003, -156.40000000000032, -57.99999999999979, -39.999999999999815, -74.80000000000034, -108.40000000000035, -30.10000000000001, -17.79999999999974, -102.40000000000023, -100.00000000000014, -137.5000000000003, -39.09999999999991, -103.90000000000015, -63.09999999999999, -220.60000000000042, -111.4000000000002, -66.70000000000005, -18.099999999999895, -156.70000000000016, -128.20000000000007, -16.900000000000013, -95.80000000000065, -120.10000000000032, -118.30000000000031, -202.60000000000016, -107.19999999999996, -75.09999999999997, -11.200000000000012, -80.80000000000014, -156.1000000000004, -167.20000000000016, -116.79999999999995, -75.40000000000003, -42.09999999999993, -79.60000000000028, -4.000000000000033, -98.80000000000032, -85.29999999999993, -45.99999999999987, -193.30000000000055, -3.6999999999999797, 25.70000000000008, 23.900000000000162, -24.399999999999764, -29.5, 1.0999999999999794, -19.30000000000001, -94.60000000000065, 20.000000000000014, -10.60000000000002, -120.09999999999995, -41.1999999999999, 63.19999999999979, -52.29999999999979, 4.69999999999994, 2.6000000000000854, 3.199999999999988, -8.199999999999998, 61.69999999999976, -51.699999999999996, -21.99999999999983, -30.39999999999975, -104.50000000000051, -30.999999999999883, -3.3999999999999404, -109.90000000000005, 9.200000000000003, -27.39999999999999, -28.59999999999998, -19.299999999999947, -41.499999999999886, -0.10000000000001341, 9.499999999999964, 31.100000000000144, 41.90000000000018, -42.09999999999982, -4.899999999999887, -86.80000000000024, -39.69999999999999, -83.19999999999997, 20.000000000000014, -42.69999999999983, -126.10000000000024, -64.89999999999995, -64.90000000000006, -70.59999999999997, -23.80000000000003, -107.5000000000005, -0.9999999999999846, -75.09999999999991, 1.4000000000001456, -36.399999999999984, 9.499999999999964, 13.699999999999964, -19.000000000000014, -20.199999999999996, -22.00000000000003, -41.19999999999984, -19.299999999999976, -41.799999999999784, -99.10000000000053, -59.499999999999794, -30.70000000000002, -193.6000000000003, 7.399999999999965, -31.899999999999878, -54.099999999999916, -71.80000000000021, 2.300000000000148, -42.09999999999996, -36.99999999999979, -97.90000000000057, -36.99999999999985, -50.19999999999992, 9.199999999999953, -5.200000000000019, -27.69999999999989, -53.79999999999995, -130.30000000000038, -142.60000000000056, -36.099999999999895, 18.200000000000124, -71.79999999999995, -106.0000000000001, -12.099999999999966, -30.999999999999915, -12.099999999999852, -12.699999999999985, 23.000000000000185, -17.79999999999992, -83.80000000000064, -43.59999999999981, 2.899999999999989, 13.699999999999964, 20.000000000000014, 13.699999999999964, -60.099999999999866, -90.70000000000043, -19.599999999999998, 9.499999999999986, -102.40000000000072, -24.100000000000023, -109.00000000000068, -42.09999999999978, -65.79999999999981, -40.29999999999983, -76.8999999999998, 9.499999999999972, -60.99999999999999, -39.99999999999982, -7.299999999999891, 10.399999999999967, -30.699999999999903, -94.90000000000074], "policy_predator_policy_reward": [15.0, 48.0, 55.0, 61.0, 35.0, 39.0, 6.0, 3.0, 10.0, 1.0, 145.0, 106.0, 91.0, 75.0, 0.0, 49.0, 100.0, 62.0, 46.0, 72.0, 73.0, 107.0, 33.0, 93.0, 68.0, 43.0, 22.0, 34.0, 0.0, 25.0, 94.0, 104.0, 44.0, 73.0, 100.0, 60.0, 89.0, 107.0, 12.0, 125.0, 6.0, 45.0, 9.0, 53.0, 12.0, 18.0, 113.0, 69.0, 58.0, 33.0, 79.0, 57.0, 27.0, 48.0, 68.0, 48.0, 59.0, 87.0, 54.0, 77.0, 143.0, 72.0, 49.0, 42.0, 94.0, 57.0, 50.0, 67.0, 81.0, 78.0, 98.0, 115.0, 51.0, 48.0, 122.0, 29.0, 106.0, 103.0, 56.0, 63.0, 49.0, 54.0, 77.0, 44.0, 106.0, 98.0, 4.0, 35.0, 16.0, 31.0, 23.0, 20.0, 22.0, 72.0, 5.0, 10.0, 73.0, 57.0, 27.0, 48.0, 15.0, 23.0, 24.0, 19.0, 34.0, 41.0, 36.0, 40.0, 78.0, 12.0, 54.0, 56.0, 27.0, 22.0, 43.0, 43.0, 35.0, 23.0, 17.0, 17.0, 47.0, 4.0, 67.0, 65.0, 61.0, 72.0, 27.0, 10.0, 43.0, 76.0, 64.0, 31.0, 69.0, 48.0, 33.0, 39.0, 21.0, 51.0, 5.0, 3.0, 21.0, 33.0, 57.0, 32.0, 12.0, 45.0, 65.0, 30.0, 60.0, 100.0, 31.0, 27.0, 57.0, 54.0, 26.0, 47.0, 27.0, 60.0, 41.0, 43.0, 26.0, 10.0, 78.0, 25.0, 125.0, 71.0, 43.0, 28.0, 66.0, 56.0, 27.0, 35.0, 54.0, 19.0, 37.0, 21.0, 57.0, 22.0, 15.0, 5.0, 2.0, 3.0, 54.0, 61.0, 29.0, 21.0, 67.0, 44.0, 41.0, 64.0, 64.0, 17.0, 31.0, 23.0, 35.0, 47.0, 8.0, 25.0, 26.0, 52.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8118839737813534, "mean_inference_ms": 2.1248870490368557, "mean_action_processing_ms": 0.3430605376573989, "mean_env_wait_ms": 0.27006758275503556, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006386995315551758, "StateBufferConnector_ms": 0.00787818431854248, "ViewRequirementAgentConnector_ms": 0.1818709373474121}, "num_episodes": 18, "episode_return_max": 271.30000000000024, "episode_return_min": -142.20000000000064, "episode_return_mean": 6.775999999999962, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.3646809002304, "num_env_steps_trained_throughput_per_sec": 317.3646809002304, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 12668.235, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12668.163, "sample_time_ms": 2168.524, "learn_time_ms": 10471.353, "learn_throughput": 381.995, "synch_weights_time_ms": 25.835}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-01-34", "timestamp": 1723647694, "time_this_iter_s": 12.676272869110107, "time_total_s": 862.1621124744415, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee07430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 862.1621124744415, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 49.85, "ram_util_percent": 82.8111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2253503673606447, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.752927081547086, "policy_loss": -0.005601059290378419, "vf_loss": 6.7563322296849, "vf_explained_var": -0.9555890066913827, "kl": 0.007711272044586318, "entropy": 1.4072384354298708, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.991771962276842, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.731273127863647, "policy_loss": -0.003859729986026804, "vf_loss": 6.734703211557298, "vf_explained_var": 0.05003886443597299, "kl": 0.0057287639111997385, "entropy": 0.5526373832314103, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 187.2999999999991, "episode_reward_min": -142.20000000000064, "episode_reward_mean": -4.526999999999937, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -220.60000000000042, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 98.89999999999961, "predator_policy": 143.0}, "policy_reward_mean": {"prey_policy": -46.58350000000004, "predator_policy": 44.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [187.2999999999991, -142.20000000000064, -7.000000000000005, -47.199999999999775, 27.100000000000154, -86.40000000000009, -30.599999999999845, -35.99999999999999, -117.0000000000007, 6.199999999999986, -133.90000000000015, 4.299999999999924, -79.40000000000052, -96.80000000000001, 12.700000000000015, -85.90000000000039, -74.99999999999986, 1.5000000000001696, 19.40000000000029, -63.09999999999991, -35.299999999999756, 61.00000000000038, 46.50000000000037, 14.600000000000067, -19.899999999999885, 24.400000000000222, -31.299999999999926, 85.89999999999938, 45.30000000000039, 38.000000000000284, 84.99999999999906, 23.600000000000136, -45.499999999999744, -3.2999999999998444, 30.800000000000438, 38.100000000000314, 16.400000000000198, 74.59999999999903, 50.800000000000324, 40.29999999999972, 10.100000000000202, 14.299999999999908, -71.99999999999986, -40.49999999999988, -14.299999999999983, -4.100000000000019, 36.99999999999992, 31.200000000000163, 14.800000000000201, 25.800000000000388, -4.100000000000076, -63.600000000000435, -64.29999999999973, 33.50000000000021, -14.900000000000055, 33.20000000000038, -47.89999999999964, -3.2000000000000073, 40.00000000000034, 21.50000000000027, -76.9000000000002, 53.10000000000037, -55.799999999999855, 18.90000000000019, 48.199999999998994, 63.19999999999868, -48.399999999999814, 36.60000000000011, 38.70000000000028, -35.799999999999635, 39.90000000000034, -15.499999999999645, -46.09999999999959, -25.099999999999667, -13.399999999999975, -18.99999999999964, 36.100000000000186, -47.599999999999575, -66.00000000000057, 40.20000000000046, -19.79999999999953, -48.09999999999961, -14.39999999999993, -17.499999999999932, 32.30000000000014, 27.90000000000011, 10.69999999999993, -30.699999999999513, -50.89999999999961, -12.899999999999686, -63.10000000000002, 1.5999999999999839, 3.2000000000002546, 35.20000000000021, -29.60000000000003, 14.600000000000206, 7.000000000000277, -11.300000000000052, 34.800000000000416, 22.500000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [98.89999999999961, 58.400000000000134, -167.8000000000003, -156.40000000000032, -57.99999999999979, -39.999999999999815, -74.80000000000034, -108.40000000000035, -30.10000000000001, -17.79999999999974, -102.40000000000023, -100.00000000000014, -137.5000000000003, -39.09999999999991, -103.90000000000015, -63.09999999999999, -220.60000000000042, -111.4000000000002, -66.70000000000005, -18.099999999999895, -156.70000000000016, -128.20000000000007, -16.900000000000013, -95.80000000000065, -120.10000000000032, -118.30000000000031, -202.60000000000016, -107.19999999999996, -75.09999999999997, -11.200000000000012, -80.80000000000014, -156.1000000000004, -167.20000000000016, -116.79999999999995, -75.40000000000003, -42.09999999999993, -79.60000000000028, -4.000000000000033, -98.80000000000032, -85.29999999999993, -45.99999999999987, -193.30000000000055, -3.6999999999999797, 25.70000000000008, 23.900000000000162, -24.399999999999764, -29.5, 1.0999999999999794, -19.30000000000001, -94.60000000000065, 20.000000000000014, -10.60000000000002, -120.09999999999995, -41.1999999999999, 63.19999999999979, -52.29999999999979, 4.69999999999994, 2.6000000000000854, 3.199999999999988, -8.199999999999998, 61.69999999999976, -51.699999999999996, -21.99999999999983, -30.39999999999975, -104.50000000000051, -30.999999999999883, -3.3999999999999404, -109.90000000000005, 9.200000000000003, -27.39999999999999, -28.59999999999998, -19.299999999999947, -41.499999999999886, -0.10000000000001341, 9.499999999999964, 31.100000000000144, 41.90000000000018, -42.09999999999982, -4.899999999999887, -86.80000000000024, -39.69999999999999, -83.19999999999997, 20.000000000000014, -42.69999999999983, -126.10000000000024, -64.89999999999995, -64.90000000000006, -70.59999999999997, -23.80000000000003, -107.5000000000005, -0.9999999999999846, -75.09999999999991, 1.4000000000001456, -36.399999999999984, 9.499999999999964, 13.699999999999964, -19.000000000000014, -20.199999999999996, -22.00000000000003, -41.19999999999984, -19.299999999999976, -41.799999999999784, -99.10000000000053, -59.499999999999794, -30.70000000000002, -193.6000000000003, 7.399999999999965, -31.899999999999878, -54.099999999999916, -71.80000000000021, 2.300000000000148, -42.09999999999996, -36.99999999999979, -97.90000000000057, -36.99999999999985, -50.19999999999992, 9.199999999999953, -5.200000000000019, -27.69999999999989, -53.79999999999995, -130.30000000000038, -142.60000000000056, -36.099999999999895, 18.200000000000124, -71.79999999999995, -106.0000000000001, -12.099999999999966, -30.999999999999915, -12.099999999999852, -12.699999999999985, 23.000000000000185, -17.79999999999992, -83.80000000000064, -43.59999999999981, 2.899999999999989, 13.699999999999964, 20.000000000000014, 13.699999999999964, -60.099999999999866, -90.70000000000043, -19.599999999999998, 9.499999999999986, -102.40000000000072, -24.100000000000023, -109.00000000000068, -42.09999999999978, -65.79999999999981, -40.29999999999983, -76.8999999999998, 9.499999999999972, -60.99999999999999, -39.99999999999982, -7.299999999999891, 10.399999999999967, -30.699999999999903, -94.90000000000074, -97.90000000000069, -111.10000000000043, -8.799999999999823, 20.000000000000014, -19.899999999999743, -67.89999999999995, -43.29999999999995, -95.80000000000078, -80.50000000000018, -16.899999999999984, -117.4000000000002, 17.899999999999984, -38.799999999999756, 4.100000000000126, -3.099999999999958, 20.000000000000014, -28.600000000000023, 5.299999999999965, -38.799999999999756, -40.89999999999976, -48.69999999999982, -107.20000000000054, -48.99999999999994, -61.899999999999864, -93.1, -120.99999999999994, 20.000000000000014, -72.40000000000003, -81.39999999999992, -18.400000000000016, -41.19999999999986, 22.40000000000007, -54.39999999999979, -71.20000000000007, -42.09999999999995, -40.29999999999994, -61.59999999999993, -48.39999999999994, 20.000000000000014, -112.29999999999997, -2.2000000000000073, -1.0000000000000182, 17.899999999999988, -9.399999999999855], "policy_predator_policy_reward": [12.0, 18.0, 113.0, 69.0, 58.0, 33.0, 79.0, 57.0, 27.0, 48.0, 68.0, 48.0, 59.0, 87.0, 54.0, 77.0, 143.0, 72.0, 49.0, 42.0, 94.0, 57.0, 50.0, 67.0, 81.0, 78.0, 98.0, 115.0, 51.0, 48.0, 122.0, 29.0, 106.0, 103.0, 56.0, 63.0, 49.0, 54.0, 77.0, 44.0, 106.0, 98.0, 4.0, 35.0, 16.0, 31.0, 23.0, 20.0, 22.0, 72.0, 5.0, 10.0, 73.0, 57.0, 27.0, 48.0, 15.0, 23.0, 24.0, 19.0, 34.0, 41.0, 36.0, 40.0, 78.0, 12.0, 54.0, 56.0, 27.0, 22.0, 43.0, 43.0, 35.0, 23.0, 17.0, 17.0, 47.0, 4.0, 67.0, 65.0, 61.0, 72.0, 27.0, 10.0, 43.0, 76.0, 64.0, 31.0, 69.0, 48.0, 33.0, 39.0, 21.0, 51.0, 5.0, 3.0, 21.0, 33.0, 57.0, 32.0, 12.0, 45.0, 65.0, 30.0, 60.0, 100.0, 31.0, 27.0, 57.0, 54.0, 26.0, 47.0, 27.0, 60.0, 41.0, 43.0, 26.0, 10.0, 78.0, 25.0, 125.0, 71.0, 43.0, 28.0, 66.0, 56.0, 27.0, 35.0, 54.0, 19.0, 37.0, 21.0, 57.0, 22.0, 15.0, 5.0, 2.0, 3.0, 54.0, 61.0, 29.0, 21.0, 67.0, 44.0, 41.0, 64.0, 64.0, 17.0, 31.0, 23.0, 35.0, 47.0, 8.0, 25.0, 26.0, 52.0, 79.0, 64.0, 20.0, 9.0, 33.0, 35.0, 38.0, 53.0, 38.0, 45.0, 52.0, 30.0, 24.0, 43.0, 11.0, 0.0, 20.0, 14.0, 29.0, 20.0, 46.0, 59.0, 62.0, 36.0, 58.0, 93.0, 39.0, 15.0, 54.0, 49.0, 27.0, 27.0, 63.0, 33.0, 41.0, 56.0, 62.0, 55.0, 30.0, 51.0, 25.0, 13.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8156654498188254, "mean_inference_ms": 2.135727006681913, "mean_action_processing_ms": 0.3441196745760633, "mean_env_wait_ms": 0.2713629683733878, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008903026580810547, "StateBufferConnector_ms": 0.00795280933380127, "ViewRequirementAgentConnector_ms": 0.19309639930725098}, "num_episodes": 22, "episode_return_max": 187.2999999999991, "episode_return_min": -142.20000000000064, "episode_return_mean": -4.526999999999937, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 313.224178063627, "num_env_steps_trained_throughput_per_sec": 313.224178063627, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 12706.9, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12706.828, "sample_time_ms": 2190.162, "learn_time_ms": 10487.966, "learn_throughput": 381.389, "synch_weights_time_ms": 26.38}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-01-47", "timestamp": 1723647707, "time_this_iter_s": 12.872121810913086, "time_total_s": 875.0342342853546, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b1ee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 875.0342342853546, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 49.672222222222224, "ram_util_percent": 82.82222222222224}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.236787215237895, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.026525463881316, "policy_loss": -0.007505560170726053, "vf_loss": 7.031438933730756, "vf_explained_var": -0.5748851838566008, "kl": 0.00910255388137065, "entropy": 1.3903841002277597, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.278500249398449, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.011151413438181, "policy_loss": -0.005449517119661092, "vf_loss": 6.015823908457681, "vf_explained_var": 0.017488514588623452, "kl": 0.010360302310368922, "entropy": 0.588863895636387, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 85.89999999999938, "episode_reward_min": -79.7000000000003, "episode_reward_mean": 0.23000000000009668, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -193.6000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.19999999999979, "predator_policy": 125.0}, "policy_reward_mean": {"prey_policy": -38.51500000000004, "predator_policy": 38.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.600000000000067, -19.899999999999885, 24.400000000000222, -31.299999999999926, 85.89999999999938, 45.30000000000039, 38.000000000000284, 84.99999999999906, 23.600000000000136, -45.499999999999744, -3.2999999999998444, 30.800000000000438, 38.100000000000314, 16.400000000000198, 74.59999999999903, 50.800000000000324, 40.29999999999972, 10.100000000000202, 14.299999999999908, -71.99999999999986, -40.49999999999988, -14.299999999999983, -4.100000000000019, 36.99999999999992, 31.200000000000163, 14.800000000000201, 25.800000000000388, -4.100000000000076, -63.600000000000435, -64.29999999999973, 33.50000000000021, -14.900000000000055, 33.20000000000038, -47.89999999999964, -3.2000000000000073, 40.00000000000034, 21.50000000000027, -76.9000000000002, 53.10000000000037, -55.799999999999855, 18.90000000000019, 48.199999999998994, 63.19999999999868, -48.399999999999814, 36.60000000000011, 38.70000000000028, -35.799999999999635, 39.90000000000034, -15.499999999999645, -46.09999999999959, -25.099999999999667, -13.399999999999975, -18.99999999999964, 36.100000000000186, -47.599999999999575, -66.00000000000057, 40.20000000000046, -19.79999999999953, -48.09999999999961, -14.39999999999993, -17.499999999999932, 32.30000000000014, 27.90000000000011, 10.69999999999993, -30.699999999999513, -50.89999999999961, -12.899999999999686, -63.10000000000002, 1.5999999999999839, 3.2000000000002546, 35.20000000000021, -29.60000000000003, 14.600000000000206, 7.000000000000277, -11.300000000000052, 34.800000000000416, 22.500000000000014, 28.300000000000388, 31.100000000000406, 4.799999999999985, 8.100000000000195, 21.3, -32.79999999999964, 8.499999999999932, 6.8999999999999275, -79.7000000000003, 0.49999999999996303, 34.70000000000022, -3.000000000000016, 11.299999999999992, -30.699999999999584, -25.499999999999908, -52.49999999999958, -68.90000000000097, -46.59999999999959, -48.99999999999957, 11.300000000000056, 4.399999999999979, 36.20000000000038, -12.800000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.5, 1.0999999999999794, -19.30000000000001, -94.60000000000065, 20.000000000000014, -10.60000000000002, -120.09999999999995, -41.1999999999999, 63.19999999999979, -52.29999999999979, 4.69999999999994, 2.6000000000000854, 3.199999999999988, -8.199999999999998, 61.69999999999976, -51.699999999999996, -21.99999999999983, -30.39999999999975, -104.50000000000051, -30.999999999999883, -3.3999999999999404, -109.90000000000005, 9.200000000000003, -27.39999999999999, -28.59999999999998, -19.299999999999947, -41.499999999999886, -0.10000000000001341, 9.499999999999964, 31.100000000000144, 41.90000000000018, -42.09999999999982, -4.899999999999887, -86.80000000000024, -39.69999999999999, -83.19999999999997, 20.000000000000014, -42.69999999999983, -126.10000000000024, -64.89999999999995, -64.90000000000006, -70.59999999999997, -23.80000000000003, -107.5000000000005, -0.9999999999999846, -75.09999999999991, 1.4000000000001456, -36.399999999999984, 9.499999999999964, 13.699999999999964, -19.000000000000014, -20.199999999999996, -22.00000000000003, -41.19999999999984, -19.299999999999976, -41.799999999999784, -99.10000000000053, -59.499999999999794, -30.70000000000002, -193.6000000000003, 7.399999999999965, -31.899999999999878, -54.099999999999916, -71.80000000000021, 2.300000000000148, -42.09999999999996, -36.99999999999979, -97.90000000000057, -36.99999999999985, -50.19999999999992, 9.199999999999953, -5.200000000000019, -27.69999999999989, -53.79999999999995, -130.30000000000038, -142.60000000000056, -36.099999999999895, 18.200000000000124, -71.79999999999995, -106.0000000000001, -12.099999999999966, -30.999999999999915, -12.099999999999852, -12.699999999999985, 23.000000000000185, -17.79999999999992, -83.80000000000064, -43.59999999999981, 2.899999999999989, 13.699999999999964, 20.000000000000014, 13.699999999999964, -60.099999999999866, -90.70000000000043, -19.599999999999998, 9.499999999999986, -102.40000000000072, -24.100000000000023, -109.00000000000068, -42.09999999999978, -65.79999999999981, -40.29999999999983, -76.8999999999998, 9.499999999999972, -60.99999999999999, -39.99999999999982, -7.299999999999891, 10.399999999999967, -30.699999999999903, -94.90000000000074, -97.90000000000069, -111.10000000000043, -8.799999999999823, 20.000000000000014, -19.899999999999743, -67.89999999999995, -43.29999999999995, -95.80000000000078, -80.50000000000018, -16.899999999999984, -117.4000000000002, 17.899999999999984, -38.799999999999756, 4.100000000000126, -3.099999999999958, 20.000000000000014, -28.600000000000023, 5.299999999999965, -38.799999999999756, -40.89999999999976, -48.69999999999982, -107.20000000000054, -48.99999999999994, -61.899999999999864, -93.1, -120.99999999999994, 20.000000000000014, -72.40000000000003, -81.39999999999992, -18.400000000000016, -41.19999999999986, 22.40000000000007, -54.39999999999979, -71.20000000000007, -42.09999999999995, -40.29999999999994, -61.59999999999993, -48.39999999999994, 20.000000000000014, -112.29999999999997, -2.2000000000000073, -1.0000000000000182, 17.899999999999988, -9.399999999999855, 1.399999999999977, -9.100000000000032, -22.599999999999905, 16.70000000000018, -113.20000000000053, 20.000000000000014, -26.2, -15.700000000000019, -5.1999999999999265, 9.499999999999964, -88.0000000000006, -29.799999999999834, 3.1999999999999615, -84.70000000000027, 15.799999999999963, -61.89999999999983, -157.3000000000002, -87.40000000000013, -107.50000000000031, -0.9999999999999846, 20.000000000000014, -7.299999999999891, 20.000000000000014, -82.00000000000043, -27.399999999999928, -7.299999999999891, -112.30000000000078, -6.400000000000043, -77.20000000000007, -121.30000000000038, -133.30000000000024, -29.19999999999976, -65.50000000000013, -111.40000000000077, -82.30000000000015, -64.2999999999998, -103.9000000000008, -30.099999999999994, 1.0999999999999865, -32.80000000000005, 20.000000000000014, -94.60000000000046, -27.09999999999993, -24.699999999999996, -5.1999999999999265, -73.60000000000022], "policy_predator_policy_reward": [23.0, 20.0, 22.0, 72.0, 5.0, 10.0, 73.0, 57.0, 27.0, 48.0, 15.0, 23.0, 24.0, 19.0, 34.0, 41.0, 36.0, 40.0, 78.0, 12.0, 54.0, 56.0, 27.0, 22.0, 43.0, 43.0, 35.0, 23.0, 17.0, 17.0, 47.0, 4.0, 67.0, 65.0, 61.0, 72.0, 27.0, 10.0, 43.0, 76.0, 64.0, 31.0, 69.0, 48.0, 33.0, 39.0, 21.0, 51.0, 5.0, 3.0, 21.0, 33.0, 57.0, 32.0, 12.0, 45.0, 65.0, 30.0, 60.0, 100.0, 31.0, 27.0, 57.0, 54.0, 26.0, 47.0, 27.0, 60.0, 41.0, 43.0, 26.0, 10.0, 78.0, 25.0, 125.0, 71.0, 43.0, 28.0, 66.0, 56.0, 27.0, 35.0, 54.0, 19.0, 37.0, 21.0, 57.0, 22.0, 15.0, 5.0, 2.0, 3.0, 54.0, 61.0, 29.0, 21.0, 67.0, 44.0, 41.0, 64.0, 64.0, 17.0, 31.0, 23.0, 35.0, 47.0, 8.0, 25.0, 26.0, 52.0, 79.0, 64.0, 20.0, 9.0, 33.0, 35.0, 38.0, 53.0, 38.0, 45.0, 52.0, 30.0, 24.0, 43.0, 11.0, 0.0, 20.0, 14.0, 29.0, 20.0, 46.0, 59.0, 62.0, 36.0, 58.0, 93.0, 39.0, 15.0, 54.0, 49.0, 27.0, 27.0, 63.0, 33.0, 41.0, 56.0, 62.0, 55.0, 30.0, 51.0, 25.0, 13.0, 0.0, 14.0, 12.0, 24.0, 19.0, 18.0, 48.0, 50.0, 27.0, 23.0, 5.0, 12.0, 68.0, 17.0, 45.0, 45.0, 17.0, 36.0, 93.0, 72.0, 54.0, 55.0, 9.0, 13.0, 40.0, 19.0, 31.0, 15.0, 37.0, 51.0, 97.0, 76.0, 51.0, 59.0, 44.0, 64.0, 55.0, 45.0, 51.0, 34.0, 21.0, 22.0, 45.0, 34.0, 44.0, 44.0, 34.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8198135220268868, "mean_inference_ms": 2.146587028411246, "mean_action_processing_ms": 0.3452212984054605, "mean_env_wait_ms": 0.27268423855756213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013390183448791504, "StateBufferConnector_ms": 0.007146954536437988, "ViewRequirementAgentConnector_ms": 0.19878077507019043}, "num_episodes": 23, "episode_return_max": 85.89999999999938, "episode_return_min": -79.7000000000003, "episode_return_mean": 0.23000000000009668, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.15597196042324, "num_env_steps_trained_throughput_per_sec": 317.15597196042324, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 12735.064, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12734.992, "sample_time_ms": 2189.94, "learn_time_ms": 10514.927, "learn_throughput": 380.412, "synch_weights_time_ms": 27.807}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-02-00", "timestamp": 1723647720, "time_this_iter_s": 12.660719871520996, "time_total_s": 887.6949541568756, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b69430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 887.6949541568756, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 49.37222222222223, "ram_util_percent": 83.02222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.24420251600326, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.22633231834129, "policy_loss": -0.003740823978715867, "vf_loss": 6.22562941621851, "vf_explained_var": -0.7833283277100356, "kl": 0.015604932766141997, "entropy": 1.4112850734165736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.193987840824026, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.677743865320922, "policy_loss": -0.006114384245186571, "vf_loss": 4.683193538050173, "vf_explained_var": -0.004975253501266399, "kl": 0.00886300385517788, "entropy": 0.6286426865549946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 63.19999999999868, "episode_reward_min": -79.7000000000003, "episode_reward_mean": -1.318999999999882, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -193.6000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 24.800000000000153, "predator_policy": 125.0}, "policy_reward_mean": {"prey_policy": -36.89950000000003, "predator_policy": 36.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.299999999999908, -71.99999999999986, -40.49999999999988, -14.299999999999983, -4.100000000000019, 36.99999999999992, 31.200000000000163, 14.800000000000201, 25.800000000000388, -4.100000000000076, -63.600000000000435, -64.29999999999973, 33.50000000000021, -14.900000000000055, 33.20000000000038, -47.89999999999964, -3.2000000000000073, 40.00000000000034, 21.50000000000027, -76.9000000000002, 53.10000000000037, -55.799999999999855, 18.90000000000019, 48.199999999998994, 63.19999999999868, -48.399999999999814, 36.60000000000011, 38.70000000000028, -35.799999999999635, 39.90000000000034, -15.499999999999645, -46.09999999999959, -25.099999999999667, -13.399999999999975, -18.99999999999964, 36.100000000000186, -47.599999999999575, -66.00000000000057, 40.20000000000046, -19.79999999999953, -48.09999999999961, -14.39999999999993, -17.499999999999932, 32.30000000000014, 27.90000000000011, 10.69999999999993, -30.699999999999513, -50.89999999999961, -12.899999999999686, -63.10000000000002, 1.5999999999999839, 3.2000000000002546, 35.20000000000021, -29.60000000000003, 14.600000000000206, 7.000000000000277, -11.300000000000052, 34.800000000000416, 22.500000000000014, 28.300000000000388, 31.100000000000406, 4.799999999999985, 8.100000000000195, 21.3, -32.79999999999964, 8.499999999999932, 6.8999999999999275, -79.7000000000003, 0.49999999999996303, 34.70000000000022, -3.000000000000016, 11.299999999999992, -30.699999999999584, -25.499999999999908, -52.49999999999958, -68.90000000000097, -46.59999999999959, -48.99999999999957, 11.300000000000056, 4.399999999999979, 36.20000000000038, -12.800000000000022, -15.099999999999579, 22.20000000000004, -1.3999999999999617, 18.300000000000008, 43.20000000000037, 43.10000000000048, -7.100000000000103, 5.499999999999968, 9.999999999999954, 40.9000000000004, -6.200000000000093, 3.599999999999945, 37.60000000000029, 22.4, -2.9000000000000346, 29.000000000000128, 27.0000000000002, 52.900000000000404], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -42.69999999999983, -126.10000000000024, -64.89999999999995, -64.90000000000006, -70.59999999999997, -23.80000000000003, -107.5000000000005, -0.9999999999999846, -75.09999999999991, 1.4000000000001456, -36.399999999999984, 9.499999999999964, 13.699999999999964, -19.000000000000014, -20.199999999999996, -22.00000000000003, -41.19999999999984, -19.299999999999976, -41.799999999999784, -99.10000000000053, -59.499999999999794, -30.70000000000002, -193.6000000000003, 7.399999999999965, -31.899999999999878, -54.099999999999916, -71.80000000000021, 2.300000000000148, -42.09999999999996, -36.99999999999979, -97.90000000000057, -36.99999999999985, -50.19999999999992, 9.199999999999953, -5.200000000000019, -27.69999999999989, -53.79999999999995, -130.30000000000038, -142.60000000000056, -36.099999999999895, 18.200000000000124, -71.79999999999995, -106.0000000000001, -12.099999999999966, -30.999999999999915, -12.099999999999852, -12.699999999999985, 23.000000000000185, -17.79999999999992, -83.80000000000064, -43.59999999999981, 2.899999999999989, 13.699999999999964, 20.000000000000014, 13.699999999999964, -60.099999999999866, -90.70000000000043, -19.599999999999998, 9.499999999999986, -102.40000000000072, -24.100000000000023, -109.00000000000068, -42.09999999999978, -65.79999999999981, -40.29999999999983, -76.8999999999998, 9.499999999999972, -60.99999999999999, -39.99999999999982, -7.299999999999891, 10.399999999999967, -30.699999999999903, -94.90000000000074, -97.90000000000069, -111.10000000000043, -8.799999999999823, 20.000000000000014, -19.899999999999743, -67.89999999999995, -43.29999999999995, -95.80000000000078, -80.50000000000018, -16.899999999999984, -117.4000000000002, 17.899999999999984, -38.799999999999756, 4.100000000000126, -3.099999999999958, 20.000000000000014, -28.600000000000023, 5.299999999999965, -38.799999999999756, -40.89999999999976, -48.69999999999982, -107.20000000000054, -48.99999999999994, -61.899999999999864, -93.1, -120.99999999999994, 20.000000000000014, -72.40000000000003, -81.39999999999992, -18.400000000000016, -41.19999999999986, 22.40000000000007, -54.39999999999979, -71.20000000000007, -42.09999999999995, -40.29999999999994, -61.59999999999993, -48.39999999999994, 20.000000000000014, -112.29999999999997, -2.2000000000000073, -1.0000000000000182, 17.899999999999988, -9.399999999999855, 1.399999999999977, -9.100000000000032, -22.599999999999905, 16.70000000000018, -113.20000000000053, 20.000000000000014, -26.2, -15.700000000000019, -5.1999999999999265, 9.499999999999964, -88.0000000000006, -29.799999999999834, 3.1999999999999615, -84.70000000000027, 15.799999999999963, -61.89999999999983, -157.3000000000002, -87.40000000000013, -107.50000000000031, -0.9999999999999846, 20.000000000000014, -7.299999999999891, 20.000000000000014, -82.00000000000043, -27.399999999999928, -7.299999999999891, -112.30000000000078, -6.400000000000043, -77.20000000000007, -121.30000000000038, -133.30000000000024, -29.19999999999976, -65.50000000000013, -111.40000000000077, -82.30000000000015, -64.2999999999998, -103.9000000000008, -30.099999999999994, 1.0999999999999865, -32.80000000000005, 20.000000000000014, -94.60000000000046, -27.09999999999993, -24.699999999999996, -5.1999999999999265, -73.60000000000022, -65.80000000000011, -16.299999999999763, -0.09999999999999937, 5.299999999999965, -41.499999999999766, -4.900000000000004, -0.9999999999999846, 5.299999999999965, -26.19999999999991, 1.399999999999989, 9.499999999999964, -3.399999999999889, -22.899999999999892, -26.199999999999875, -37.599999999999916, 1.09999999999996, -9.40000000000006, -19.59999999999991, -5.500000000000037, -4.600000000000052, -51.3999999999999, -56.79999999999977, -88.30000000000084, 2.8999999999999435, -15.399999999999865, 20.000000000000014, 20.000000000000014, -58.5999999999998, -52.59999999999978, -25.299999999999812, 20.000000000000014, -0.9999999999999846, 1.6999999999999937, -12.699999999999957, 4.100000000000001, 24.800000000000153], "policy_predator_policy_reward": [27.0, 10.0, 43.0, 76.0, 64.0, 31.0, 69.0, 48.0, 33.0, 39.0, 21.0, 51.0, 5.0, 3.0, 21.0, 33.0, 57.0, 32.0, 12.0, 45.0, 65.0, 30.0, 60.0, 100.0, 31.0, 27.0, 57.0, 54.0, 26.0, 47.0, 27.0, 60.0, 41.0, 43.0, 26.0, 10.0, 78.0, 25.0, 125.0, 71.0, 43.0, 28.0, 66.0, 56.0, 27.0, 35.0, 54.0, 19.0, 37.0, 21.0, 57.0, 22.0, 15.0, 5.0, 2.0, 3.0, 54.0, 61.0, 29.0, 21.0, 67.0, 44.0, 41.0, 64.0, 64.0, 17.0, 31.0, 23.0, 35.0, 47.0, 8.0, 25.0, 26.0, 52.0, 79.0, 64.0, 20.0, 9.0, 33.0, 35.0, 38.0, 53.0, 38.0, 45.0, 52.0, 30.0, 24.0, 43.0, 11.0, 0.0, 20.0, 14.0, 29.0, 20.0, 46.0, 59.0, 62.0, 36.0, 58.0, 93.0, 39.0, 15.0, 54.0, 49.0, 27.0, 27.0, 63.0, 33.0, 41.0, 56.0, 62.0, 55.0, 30.0, 51.0, 25.0, 13.0, 0.0, 14.0, 12.0, 24.0, 19.0, 18.0, 48.0, 50.0, 27.0, 23.0, 5.0, 12.0, 68.0, 17.0, 45.0, 45.0, 17.0, 36.0, 93.0, 72.0, 54.0, 55.0, 9.0, 13.0, 40.0, 19.0, 31.0, 15.0, 37.0, 51.0, 97.0, 76.0, 51.0, 59.0, 44.0, 64.0, 55.0, 45.0, 51.0, 34.0, 21.0, 22.0, 45.0, 34.0, 44.0, 44.0, 34.0, 32.0, 26.0, 41.0, 10.0, 7.0, 25.0, 20.0, 10.0, 4.0, 40.0, 28.0, 25.0, 12.0, 9.0, 33.0, 18.0, 24.0, 16.0, 23.0, 27.0, 24.0, 57.0, 45.0, 49.0, 40.0, 18.0, 15.0, 20.0, 41.0, 42.0, 33.0, 10.0, 0.0, 17.0, 21.0, 9.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8228587948829013, "mean_inference_ms": 2.1545564164522375, "mean_action_processing_ms": 0.34614136019430064, "mean_env_wait_ms": 0.2735513240440682, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014653801918029785, "StateBufferConnector_ms": 0.0042688846588134766, "ViewRequirementAgentConnector_ms": 0.20417416095733643}, "num_episodes": 18, "episode_return_max": 63.19999999999868, "episode_return_min": -79.7000000000003, "episode_return_mean": -1.318999999999882, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.86446064377236, "num_env_steps_trained_throughput_per_sec": 306.86446064377236, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 12770.467, "restore_workers_time_ms": 0.027, "training_step_time_ms": 12770.382, "sample_time_ms": 2169.597, "learn_time_ms": 10570.806, "learn_throughput": 378.401, "synch_weights_time_ms": 27.335}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-02-13", "timestamp": 1723647733, "time_this_iter_s": 13.133944034576416, "time_total_s": 900.828898191452, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b1e280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 900.828898191452, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 50.5, "ram_util_percent": 83.13333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.895249452414336, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.818931171124574, "policy_loss": -0.011641318237571608, "vf_loss": 6.826910779337403, "vf_explained_var": -0.44717107367894005, "kl": 0.012858663520936519, "entropy": 1.401834595771063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.931981748941714, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.260144557145537, "policy_loss": -0.005919502153450613, "vf_loss": 6.265472060662729, "vf_explained_var": 0.030270432511334697, "kl": 0.007893150212202764, "entropy": 0.5756870784929821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 63.19999999999868, "episode_reward_min": -79.7000000000003, "episode_reward_mean": -0.6159999999998673, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -157.3000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 24.800000000000153, "predator_policy": 125.0}, "policy_reward_mean": {"prey_policy": -35.93800000000003, "predator_policy": 35.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.50000000000027, -76.9000000000002, 53.10000000000037, -55.799999999999855, 18.90000000000019, 48.199999999998994, 63.19999999999868, -48.399999999999814, 36.60000000000011, 38.70000000000028, -35.799999999999635, 39.90000000000034, -15.499999999999645, -46.09999999999959, -25.099999999999667, -13.399999999999975, -18.99999999999964, 36.100000000000186, -47.599999999999575, -66.00000000000057, 40.20000000000046, -19.79999999999953, -48.09999999999961, -14.39999999999993, -17.499999999999932, 32.30000000000014, 27.90000000000011, 10.69999999999993, -30.699999999999513, -50.89999999999961, -12.899999999999686, -63.10000000000002, 1.5999999999999839, 3.2000000000002546, 35.20000000000021, -29.60000000000003, 14.600000000000206, 7.000000000000277, -11.300000000000052, 34.800000000000416, 22.500000000000014, 28.300000000000388, 31.100000000000406, 4.799999999999985, 8.100000000000195, 21.3, -32.79999999999964, 8.499999999999932, 6.8999999999999275, -79.7000000000003, 0.49999999999996303, 34.70000000000022, -3.000000000000016, 11.299999999999992, -30.699999999999584, -25.499999999999908, -52.49999999999958, -68.90000000000097, -46.59999999999959, -48.99999999999957, 11.300000000000056, 4.399999999999979, 36.20000000000038, -12.800000000000022, -15.099999999999579, 22.20000000000004, -1.3999999999999617, 18.300000000000008, 43.20000000000037, 43.10000000000048, -7.100000000000103, 5.499999999999968, 9.999999999999954, 40.9000000000004, -6.200000000000093, 3.599999999999945, 37.60000000000029, 22.4, -2.9000000000000346, 29.000000000000128, 27.0000000000002, 52.900000000000404, 40.50000000000026, -8.299999999999995, 2.6999999999999664, -18.19999999999968, 32.50000000000041, 29.000000000000384, 42.60000000000041, -39.399999999999665, 8.700000000000104, -67.70000000000022, 35.600000000000236, 1.1999999999999744, -20.199999999999793, 20.199999999999974, -32.59999999999981, -8.200000000000042, -26.699999999999555, -20.49999999999968], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-27.69999999999989, -53.79999999999995, -130.30000000000038, -142.60000000000056, -36.099999999999895, 18.200000000000124, -71.79999999999995, -106.0000000000001, -12.099999999999966, -30.999999999999915, -12.099999999999852, -12.699999999999985, 23.000000000000185, -17.79999999999992, -83.80000000000064, -43.59999999999981, 2.899999999999989, 13.699999999999964, 20.000000000000014, 13.699999999999964, -60.099999999999866, -90.70000000000043, -19.599999999999998, 9.499999999999986, -102.40000000000072, -24.100000000000023, -109.00000000000068, -42.09999999999978, -65.79999999999981, -40.29999999999983, -76.8999999999998, 9.499999999999972, -60.99999999999999, -39.99999999999982, -7.299999999999891, 10.399999999999967, -30.699999999999903, -94.90000000000074, -97.90000000000069, -111.10000000000043, -8.799999999999823, 20.000000000000014, -19.899999999999743, -67.89999999999995, -43.29999999999995, -95.80000000000078, -80.50000000000018, -16.899999999999984, -117.4000000000002, 17.899999999999984, -38.799999999999756, 4.100000000000126, -3.099999999999958, 20.000000000000014, -28.600000000000023, 5.299999999999965, -38.799999999999756, -40.89999999999976, -48.69999999999982, -107.20000000000054, -48.99999999999994, -61.899999999999864, -93.1, -120.99999999999994, 20.000000000000014, -72.40000000000003, -81.39999999999992, -18.400000000000016, -41.19999999999986, 22.40000000000007, -54.39999999999979, -71.20000000000007, -42.09999999999995, -40.29999999999994, -61.59999999999993, -48.39999999999994, 20.000000000000014, -112.29999999999997, -2.2000000000000073, -1.0000000000000182, 17.899999999999988, -9.399999999999855, 1.399999999999977, -9.100000000000032, -22.599999999999905, 16.70000000000018, -113.20000000000053, 20.000000000000014, -26.2, -15.700000000000019, -5.1999999999999265, 9.499999999999964, -88.0000000000006, -29.799999999999834, 3.1999999999999615, -84.70000000000027, 15.799999999999963, -61.89999999999983, -157.3000000000002, -87.40000000000013, -107.50000000000031, -0.9999999999999846, 20.000000000000014, -7.299999999999891, 20.000000000000014, -82.00000000000043, -27.399999999999928, -7.299999999999891, -112.30000000000078, -6.400000000000043, -77.20000000000007, -121.30000000000038, -133.30000000000024, -29.19999999999976, -65.50000000000013, -111.40000000000077, -82.30000000000015, -64.2999999999998, -103.9000000000008, -30.099999999999994, 1.0999999999999865, -32.80000000000005, 20.000000000000014, -94.60000000000046, -27.09999999999993, -24.699999999999996, -5.1999999999999265, -73.60000000000022, -65.80000000000011, -16.299999999999763, -0.09999999999999937, 5.299999999999965, -41.499999999999766, -4.900000000000004, -0.9999999999999846, 5.299999999999965, -26.19999999999991, 1.399999999999989, 9.499999999999964, -3.399999999999889, -22.899999999999892, -26.199999999999875, -37.599999999999916, 1.09999999999996, -9.40000000000006, -19.59999999999991, -5.500000000000037, -4.600000000000052, -51.3999999999999, -56.79999999999977, -88.30000000000084, 2.8999999999999435, -15.399999999999865, 20.000000000000014, 20.000000000000014, -58.5999999999998, -52.59999999999978, -25.299999999999812, 20.000000000000014, -0.9999999999999846, 1.6999999999999937, -12.699999999999957, 4.100000000000001, 24.800000000000153, -15.699999999999747, -17.799999999999997, -39.69999999999978, -34.59999999999978, -8.199999999999909, -45.09999999999978, -63.399999999999984, -17.79999999999974, 20.000000000000014, -71.49999999999997, -7.599999999999827, -66.40000000000019, 4.100000000000137, -17.49999999999995, -90.40000000000013, -51.99999999999982, -89.79999999999998, 3.500000000000029, -110.8000000000003, -82.90000000000035, 11.599999999999964, 20.000000000000014, 20.000000000000014, -86.80000000000021, -41.49999999999986, -48.69999999999978, -30.39999999999975, 11.599999999999964, -40.300000000000004, -76.30000000000022, -45.09999999999986, -18.100000000000005, -30.099999999999774, -73.60000000000005, 20.000000000000014, -119.5000000000006], "policy_predator_policy_reward": [78.0, 25.0, 125.0, 71.0, 43.0, 28.0, 66.0, 56.0, 27.0, 35.0, 54.0, 19.0, 37.0, 21.0, 57.0, 22.0, 15.0, 5.0, 2.0, 3.0, 54.0, 61.0, 29.0, 21.0, 67.0, 44.0, 41.0, 64.0, 64.0, 17.0, 31.0, 23.0, 35.0, 47.0, 8.0, 25.0, 26.0, 52.0, 79.0, 64.0, 20.0, 9.0, 33.0, 35.0, 38.0, 53.0, 38.0, 45.0, 52.0, 30.0, 24.0, 43.0, 11.0, 0.0, 20.0, 14.0, 29.0, 20.0, 46.0, 59.0, 62.0, 36.0, 58.0, 93.0, 39.0, 15.0, 54.0, 49.0, 27.0, 27.0, 63.0, 33.0, 41.0, 56.0, 62.0, 55.0, 30.0, 51.0, 25.0, 13.0, 0.0, 14.0, 12.0, 24.0, 19.0, 18.0, 48.0, 50.0, 27.0, 23.0, 5.0, 12.0, 68.0, 17.0, 45.0, 45.0, 17.0, 36.0, 93.0, 72.0, 54.0, 55.0, 9.0, 13.0, 40.0, 19.0, 31.0, 15.0, 37.0, 51.0, 97.0, 76.0, 51.0, 59.0, 44.0, 64.0, 55.0, 45.0, 51.0, 34.0, 21.0, 22.0, 45.0, 34.0, 44.0, 44.0, 34.0, 32.0, 26.0, 41.0, 10.0, 7.0, 25.0, 20.0, 10.0, 4.0, 40.0, 28.0, 25.0, 12.0, 9.0, 33.0, 18.0, 24.0, 16.0, 23.0, 27.0, 24.0, 57.0, 45.0, 49.0, 40.0, 18.0, 15.0, 20.0, 41.0, 42.0, 33.0, 10.0, 0.0, 17.0, 21.0, 9.0, 15.0, 32.0, 42.0, 31.0, 35.0, 23.0, 33.0, 18.0, 45.0, 39.0, 45.0, 43.0, 60.0, 30.0, 26.0, 50.0, 53.0, 44.0, 51.0, 60.0, 66.0, 0.0, 4.0, 24.0, 44.0, 52.0, 18.0, 24.0, 15.0, 38.0, 46.0, 29.0, 26.0, 35.0, 42.0, 60.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8254544315757198, "mean_inference_ms": 2.1615943181711104, "mean_action_processing_ms": 0.3468915629613038, "mean_env_wait_ms": 0.27457117466592074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014243841171264648, "StateBufferConnector_ms": 0.004673004150390625, "ViewRequirementAgentConnector_ms": 0.19842660427093506}, "num_episodes": 18, "episode_return_max": 63.19999999999868, "episode_return_min": -79.7000000000003, "episode_return_mean": -0.6159999999998673, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 303.530414732779, "num_env_steps_trained_throughput_per_sec": 303.530414732779, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 12814.49, "restore_workers_time_ms": 0.025, "training_step_time_ms": 12814.404, "sample_time_ms": 2156.037, "learn_time_ms": 10626.537, "learn_throughput": 376.416, "synch_weights_time_ms": 29.111}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-02-26", "timestamp": 1723647746, "time_this_iter_s": 13.217089891433716, "time_total_s": 914.0459880828857, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b1e790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 914.0459880828857, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 57.647368421052626, "ram_util_percent": 83.55789473684212}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.3992011969051665, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.496037922082124, "policy_loss": -0.007024515314254338, "vf_loss": 4.499947487992585, "vf_explained_var": -0.4343680078390414, "kl": 0.010938649473007928, "entropy": 1.3777141191341258, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.229915627789876, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.59093255466885, "policy_loss": -0.005760353417801006, "vf_loss": 4.5961319792207584, "vf_explained_var": 0.01001143354587454, "kl": 0.007479009432735097, "entropy": 0.5718797280044152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 52.900000000000404, "episode_reward_min": -79.7000000000003, "episode_reward_mean": 3.763000000000146, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -167.50000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 24.800000000000153, "predator_policy": 97.0}, "policy_reward_mean": {"prey_policy": -30.218500000000002, "predator_policy": 32.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-48.09999999999961, -14.39999999999993, -17.499999999999932, 32.30000000000014, 27.90000000000011, 10.69999999999993, -30.699999999999513, -50.89999999999961, -12.899999999999686, -63.10000000000002, 1.5999999999999839, 3.2000000000002546, 35.20000000000021, -29.60000000000003, 14.600000000000206, 7.000000000000277, -11.300000000000052, 34.800000000000416, 22.500000000000014, 28.300000000000388, 31.100000000000406, 4.799999999999985, 8.100000000000195, 21.3, -32.79999999999964, 8.499999999999932, 6.8999999999999275, -79.7000000000003, 0.49999999999996303, 34.70000000000022, -3.000000000000016, 11.299999999999992, -30.699999999999584, -25.499999999999908, -52.49999999999958, -68.90000000000097, -46.59999999999959, -48.99999999999957, 11.300000000000056, 4.399999999999979, 36.20000000000038, -12.800000000000022, -15.099999999999579, 22.20000000000004, -1.3999999999999617, 18.300000000000008, 43.20000000000037, 43.10000000000048, -7.100000000000103, 5.499999999999968, 9.999999999999954, 40.9000000000004, -6.200000000000093, 3.599999999999945, 37.60000000000029, 22.4, -2.9000000000000346, 29.000000000000128, 27.0000000000002, 52.900000000000404, 40.50000000000026, -8.299999999999995, 2.6999999999999664, -18.19999999999968, 32.50000000000041, 29.000000000000384, 42.60000000000041, -39.399999999999665, 8.700000000000104, -67.70000000000022, 35.600000000000236, 1.1999999999999744, -20.199999999999793, 20.199999999999974, -32.59999999999981, -8.200000000000042, -26.699999999999555, -20.49999999999968, 22.600000000000147, 43.10000000000037, 26.80000000000009, -5.70000000000009, 28.600000000000108, 34.80000000000045, 25.100000000000037, 16.799999999999923, 36.20000000000046, -63.4999999999999, 20.900000000000077, 20.09999999999999, 10.299999999999926, 34.50000000000022, 1.7999999999999108, -36.49999999999959, 30.9000000000002, -8.500000000000046, 28.20000000000033, 47.300000000000466, 32.600000000000435, 18.499999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-43.29999999999995, -95.80000000000078, -80.50000000000018, -16.899999999999984, -117.4000000000002, 17.899999999999984, -38.799999999999756, 4.100000000000126, -3.099999999999958, 20.000000000000014, -28.600000000000023, 5.299999999999965, -38.799999999999756, -40.89999999999976, -48.69999999999982, -107.20000000000054, -48.99999999999994, -61.899999999999864, -93.1, -120.99999999999994, 20.000000000000014, -72.40000000000003, -81.39999999999992, -18.400000000000016, -41.19999999999986, 22.40000000000007, -54.39999999999979, -71.20000000000007, -42.09999999999995, -40.29999999999994, -61.59999999999993, -48.39999999999994, 20.000000000000014, -112.29999999999997, -2.2000000000000073, -1.0000000000000182, 17.899999999999988, -9.399999999999855, 1.399999999999977, -9.100000000000032, -22.599999999999905, 16.70000000000018, -113.20000000000053, 20.000000000000014, -26.2, -15.700000000000019, -5.1999999999999265, 9.499999999999964, -88.0000000000006, -29.799999999999834, 3.1999999999999615, -84.70000000000027, 15.799999999999963, -61.89999999999983, -157.3000000000002, -87.40000000000013, -107.50000000000031, -0.9999999999999846, 20.000000000000014, -7.299999999999891, 20.000000000000014, -82.00000000000043, -27.399999999999928, -7.299999999999891, -112.30000000000078, -6.400000000000043, -77.20000000000007, -121.30000000000038, -133.30000000000024, -29.19999999999976, -65.50000000000013, -111.40000000000077, -82.30000000000015, -64.2999999999998, -103.9000000000008, -30.099999999999994, 1.0999999999999865, -32.80000000000005, 20.000000000000014, -94.60000000000046, -27.09999999999993, -24.699999999999996, -5.1999999999999265, -73.60000000000022, -65.80000000000011, -16.299999999999763, -0.09999999999999937, 5.299999999999965, -41.499999999999766, -4.900000000000004, -0.9999999999999846, 5.299999999999965, -26.19999999999991, 1.399999999999989, 9.499999999999964, -3.399999999999889, -22.899999999999892, -26.199999999999875, -37.599999999999916, 1.09999999999996, -9.40000000000006, -19.59999999999991, -5.500000000000037, -4.600000000000052, -51.3999999999999, -56.79999999999977, -88.30000000000084, 2.8999999999999435, -15.399999999999865, 20.000000000000014, 20.000000000000014, -58.5999999999998, -52.59999999999978, -25.299999999999812, 20.000000000000014, -0.9999999999999846, 1.6999999999999937, -12.699999999999957, 4.100000000000001, 24.800000000000153, -15.699999999999747, -17.799999999999997, -39.69999999999978, -34.59999999999978, -8.199999999999909, -45.09999999999978, -63.399999999999984, -17.79999999999974, 20.000000000000014, -71.49999999999997, -7.599999999999827, -66.40000000000019, 4.100000000000137, -17.49999999999995, -90.40000000000013, -51.99999999999982, -89.79999999999998, 3.500000000000029, -110.8000000000003, -82.90000000000035, 11.599999999999964, 20.000000000000014, 20.000000000000014, -86.80000000000021, -41.49999999999986, -48.69999999999978, -30.39999999999975, 11.599999999999964, -40.300000000000004, -76.30000000000022, -45.09999999999986, -18.100000000000005, -30.099999999999774, -73.60000000000005, 20.000000000000014, -119.5000000000006, 15.799999999999963, -41.19999999999976, 15.799999999999963, 11.299999999999969, 17.899999999999988, -3.099999999999958, -21.099999999999945, -49.599999999999795, -21.399999999999764, 20.000000000000014, 12.199999999999951, -0.399999999999923, -19.299999999999798, -25.599999999999767, 9.499999999999964, -15.69999999999984, -21.399999999999956, 11.599999999999964, -66.99999999999999, -167.50000000000043, -1.0000000000000346, -39.099999999999774, -22.899999999999757, 20.000000000000014, -5.199999999999962, -23.49999999999975, 9.499999999999964, 20.000000000000014, -25.299999999999834, -19.899999999999743, -17.799999999999805, -120.70000000000076, -21.699999999999847, -9.399999999999924, -55.599999999999824, 1.0999999999999799, -4.000000000000055, -17.799999999999898, 7.399999999999965, 8.900000000000187, 13.699999999999964, -15.099999999999984, -4.300000000000066, -5.1999999999999265], "policy_predator_policy_reward": [38.0, 53.0, 38.0, 45.0, 52.0, 30.0, 24.0, 43.0, 11.0, 0.0, 20.0, 14.0, 29.0, 20.0, 46.0, 59.0, 62.0, 36.0, 58.0, 93.0, 39.0, 15.0, 54.0, 49.0, 27.0, 27.0, 63.0, 33.0, 41.0, 56.0, 62.0, 55.0, 30.0, 51.0, 25.0, 13.0, 0.0, 14.0, 12.0, 24.0, 19.0, 18.0, 48.0, 50.0, 27.0, 23.0, 5.0, 12.0, 68.0, 17.0, 45.0, 45.0, 17.0, 36.0, 93.0, 72.0, 54.0, 55.0, 9.0, 13.0, 40.0, 19.0, 31.0, 15.0, 37.0, 51.0, 97.0, 76.0, 51.0, 59.0, 44.0, 64.0, 55.0, 45.0, 51.0, 34.0, 21.0, 22.0, 45.0, 34.0, 44.0, 44.0, 34.0, 32.0, 26.0, 41.0, 10.0, 7.0, 25.0, 20.0, 10.0, 4.0, 40.0, 28.0, 25.0, 12.0, 9.0, 33.0, 18.0, 24.0, 16.0, 23.0, 27.0, 24.0, 57.0, 45.0, 49.0, 40.0, 18.0, 15.0, 20.0, 41.0, 42.0, 33.0, 10.0, 0.0, 17.0, 21.0, 9.0, 15.0, 32.0, 42.0, 31.0, 35.0, 23.0, 33.0, 18.0, 45.0, 39.0, 45.0, 43.0, 60.0, 30.0, 26.0, 50.0, 53.0, 44.0, 51.0, 60.0, 66.0, 0.0, 4.0, 24.0, 44.0, 52.0, 18.0, 24.0, 15.0, 38.0, 46.0, 29.0, 26.0, 35.0, 42.0, 60.0, 19.0, 30.0, 18.0, 11.0, 5.0, 11.0, 1.0, 32.0, 33.0, 12.0, 18.0, 13.0, 10.0, 33.0, 37.0, 16.0, 7.0, 18.0, 28.0, 78.0, 93.0, 34.0, 27.0, 0.0, 23.0, 6.0, 33.0, 5.0, 0.0, 9.0, 38.0, 54.0, 48.0, 29.0, 33.0, 13.0, 33.0, 20.0, 30.0, 14.0, 17.0, 18.0, 16.0, 17.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8273420502773371, "mean_inference_ms": 2.167659275388424, "mean_action_processing_ms": 0.3467463265421424, "mean_env_wait_ms": 0.27541991830807955, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013936877250671387, "StateBufferConnector_ms": 0.004103660583496094, "ViewRequirementAgentConnector_ms": 0.19588923454284668}, "num_episodes": 22, "episode_return_max": 52.900000000000404, "episode_return_min": -79.7000000000003, "episode_return_mean": 3.763000000000146, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.2458460843646, "num_env_steps_trained_throughput_per_sec": 317.2458460843646, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 12774.405, "restore_workers_time_ms": 0.025, "training_step_time_ms": 12774.32, "sample_time_ms": 2071.647, "learn_time_ms": 10672.402, "learn_throughput": 374.798, "synch_weights_time_ms": 27.967}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-02-39", "timestamp": 1723647759, "time_this_iter_s": 12.669752597808838, "time_total_s": 926.7157406806946, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ee10280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 926.7157406806946, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 56.915789473684214, "ram_util_percent": 82.98947368421054}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.910547733622253, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0367498227528165, "policy_loss": -0.007013285657386024, "vf_loss": 3.042330240194129, "vf_explained_var": -0.35187881494325307, "kl": 0.005031750168369696, "entropy": 1.3758652525604087, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.346229340538146, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.867178856632697, "policy_loss": -0.004795566487135907, "vf_loss": 2.8714806997586813, "vf_explained_var": 0.061723591852440404, "kl": 0.006583015750219789, "entropy": 0.5769520367579485, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 55.400000000000475, "episode_reward_min": -79.7000000000003, "episode_reward_mean": 9.584000000000163, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -167.50000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 25.700000000000117, "predator_policy": 97.0}, "policy_reward_mean": {"prey_policy": -23.83299999999999, "predator_policy": 28.625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.500000000000014, 28.300000000000388, 31.100000000000406, 4.799999999999985, 8.100000000000195, 21.3, -32.79999999999964, 8.499999999999932, 6.8999999999999275, -79.7000000000003, 0.49999999999996303, 34.70000000000022, -3.000000000000016, 11.299999999999992, -30.699999999999584, -25.499999999999908, -52.49999999999958, -68.90000000000097, -46.59999999999959, -48.99999999999957, 11.300000000000056, 4.399999999999979, 36.20000000000038, -12.800000000000022, -15.099999999999579, 22.20000000000004, -1.3999999999999617, 18.300000000000008, 43.20000000000037, 43.10000000000048, -7.100000000000103, 5.499999999999968, 9.999999999999954, 40.9000000000004, -6.200000000000093, 3.599999999999945, 37.60000000000029, 22.4, -2.9000000000000346, 29.000000000000128, 27.0000000000002, 52.900000000000404, 40.50000000000026, -8.299999999999995, 2.6999999999999664, -18.19999999999968, 32.50000000000041, 29.000000000000384, 42.60000000000041, -39.399999999999665, 8.700000000000104, -67.70000000000022, 35.600000000000236, 1.1999999999999744, -20.199999999999793, 20.199999999999974, -32.59999999999981, -8.200000000000042, -26.699999999999555, -20.49999999999968, 22.600000000000147, 43.10000000000037, 26.80000000000009, -5.70000000000009, 28.600000000000108, 34.80000000000045, 25.100000000000037, 16.799999999999923, 36.20000000000046, -63.4999999999999, 20.900000000000077, 20.09999999999999, 10.299999999999926, 34.50000000000022, 1.7999999999999108, -36.49999999999959, 30.9000000000002, -8.500000000000046, 28.20000000000033, 47.300000000000466, 32.600000000000435, 18.499999999999993, -19.59999999999954, 9.999999999999991, 11.299999999999919, 47.9000000000004, -19.19999999999952, 32.800000000000445, 1.7000000000001723, 45.00000000000046, 25.50000000000037, 30.10000000000014, 32.80000000000039, 40.70000000000019, 54.70000000000045, 19.099999999999948, 38.80000000000034, 38.20000000000029, 55.400000000000475, 25.70000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, -9.399999999999855, 1.399999999999977, -9.100000000000032, -22.599999999999905, 16.70000000000018, -113.20000000000053, 20.000000000000014, -26.2, -15.700000000000019, -5.1999999999999265, 9.499999999999964, -88.0000000000006, -29.799999999999834, 3.1999999999999615, -84.70000000000027, 15.799999999999963, -61.89999999999983, -157.3000000000002, -87.40000000000013, -107.50000000000031, -0.9999999999999846, 20.000000000000014, -7.299999999999891, 20.000000000000014, -82.00000000000043, -27.399999999999928, -7.299999999999891, -112.30000000000078, -6.400000000000043, -77.20000000000007, -121.30000000000038, -133.30000000000024, -29.19999999999976, -65.50000000000013, -111.40000000000077, -82.30000000000015, -64.2999999999998, -103.9000000000008, -30.099999999999994, 1.0999999999999865, -32.80000000000005, 20.000000000000014, -94.60000000000046, -27.09999999999993, -24.699999999999996, -5.1999999999999265, -73.60000000000022, -65.80000000000011, -16.299999999999763, -0.09999999999999937, 5.299999999999965, -41.499999999999766, -4.900000000000004, -0.9999999999999846, 5.299999999999965, -26.19999999999991, 1.399999999999989, 9.499999999999964, -3.399999999999889, -22.899999999999892, -26.199999999999875, -37.599999999999916, 1.09999999999996, -9.40000000000006, -19.59999999999991, -5.500000000000037, -4.600000000000052, -51.3999999999999, -56.79999999999977, -88.30000000000084, 2.8999999999999435, -15.399999999999865, 20.000000000000014, 20.000000000000014, -58.5999999999998, -52.59999999999978, -25.299999999999812, 20.000000000000014, -0.9999999999999846, 1.6999999999999937, -12.699999999999957, 4.100000000000001, 24.800000000000153, -15.699999999999747, -17.799999999999997, -39.69999999999978, -34.59999999999978, -8.199999999999909, -45.09999999999978, -63.399999999999984, -17.79999999999974, 20.000000000000014, -71.49999999999997, -7.599999999999827, -66.40000000000019, 4.100000000000137, -17.49999999999995, -90.40000000000013, -51.99999999999982, -89.79999999999998, 3.500000000000029, -110.8000000000003, -82.90000000000035, 11.599999999999964, 20.000000000000014, 20.000000000000014, -86.80000000000021, -41.49999999999986, -48.69999999999978, -30.39999999999975, 11.599999999999964, -40.300000000000004, -76.30000000000022, -45.09999999999986, -18.100000000000005, -30.099999999999774, -73.60000000000005, 20.000000000000014, -119.5000000000006, 15.799999999999963, -41.19999999999976, 15.799999999999963, 11.299999999999969, 17.899999999999988, -3.099999999999958, -21.099999999999945, -49.599999999999795, -21.399999999999764, 20.000000000000014, 12.199999999999951, -0.399999999999923, -19.299999999999798, -25.599999999999767, 9.499999999999964, -15.69999999999984, -21.399999999999956, 11.599999999999964, -66.99999999999999, -167.50000000000043, -1.0000000000000346, -39.099999999999774, -22.899999999999757, 20.000000000000014, -5.199999999999962, -23.49999999999975, 9.499999999999964, 20.000000000000014, -25.299999999999834, -19.899999999999743, -17.799999999999805, -120.70000000000076, -21.699999999999847, -9.399999999999924, -55.599999999999824, 1.0999999999999799, -4.000000000000055, -17.799999999999898, 7.399999999999965, 8.900000000000187, 13.699999999999964, -15.099999999999984, -4.300000000000066, -5.1999999999999265, -49.59999999999985, -42.99999999999976, -120.70000000000056, 13.699999999999964, 7.399999999999965, -33.09999999999976, 22.700000000000127, 3.1999999999999615, -5.1999999999999265, -73.00000000000085, -7.300000000000031, 1.0999999999999706, -0.9999999999999846, -46.299999999999805, -38.799999999999756, 24.800000000000253, 21.200000000000244, -42.69999999999978, -11.49999999999989, 14.599999999999966, 25.100000000000218, -40.29999999999976, 16.099999999999955, -0.4000000000000231, 25.700000000000117, 20.000000000000014, -21.999999999999744, 13.099999999999955, -13.599999999999783, 13.400000000000153, 11.299999999999974, 20.900000000000027, 10.699999999999982, 25.700000000000095, 20.000000000000014, -7.299999999999891], "policy_predator_policy_reward": [0.0, 14.0, 12.0, 24.0, 19.0, 18.0, 48.0, 50.0, 27.0, 23.0, 5.0, 12.0, 68.0, 17.0, 45.0, 45.0, 17.0, 36.0, 93.0, 72.0, 54.0, 55.0, 9.0, 13.0, 40.0, 19.0, 31.0, 15.0, 37.0, 51.0, 97.0, 76.0, 51.0, 59.0, 44.0, 64.0, 55.0, 45.0, 51.0, 34.0, 21.0, 22.0, 45.0, 34.0, 44.0, 44.0, 34.0, 32.0, 26.0, 41.0, 10.0, 7.0, 25.0, 20.0, 10.0, 4.0, 40.0, 28.0, 25.0, 12.0, 9.0, 33.0, 18.0, 24.0, 16.0, 23.0, 27.0, 24.0, 57.0, 45.0, 49.0, 40.0, 18.0, 15.0, 20.0, 41.0, 42.0, 33.0, 10.0, 0.0, 17.0, 21.0, 9.0, 15.0, 32.0, 42.0, 31.0, 35.0, 23.0, 33.0, 18.0, 45.0, 39.0, 45.0, 43.0, 60.0, 30.0, 26.0, 50.0, 53.0, 44.0, 51.0, 60.0, 66.0, 0.0, 4.0, 24.0, 44.0, 52.0, 18.0, 24.0, 15.0, 38.0, 46.0, 29.0, 26.0, 35.0, 42.0, 60.0, 19.0, 30.0, 18.0, 11.0, 5.0, 11.0, 1.0, 32.0, 33.0, 12.0, 18.0, 13.0, 10.0, 33.0, 37.0, 16.0, 7.0, 18.0, 28.0, 78.0, 93.0, 34.0, 27.0, 0.0, 23.0, 6.0, 33.0, 5.0, 0.0, 9.0, 38.0, 54.0, 48.0, 29.0, 33.0, 13.0, 33.0, 20.0, 30.0, 14.0, 17.0, 18.0, 16.0, 17.0, 11.0, 36.0, 37.0, 69.0, 48.0, 15.0, 22.0, 10.0, 12.0, 24.0, 35.0, 19.0, 20.0, 32.0, 17.0, 29.0, 30.0, 24.0, 23.0, 10.0, 17.0, 31.0, 17.0, 12.0, 13.0, 4.0, 5.0, 13.0, 15.0, 26.0, 13.0, 5.0, 1.0, 10.0, 9.0, 13.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8282751291272858, "mean_inference_ms": 2.169556732313815, "mean_action_processing_ms": 0.34755788572018687, "mean_env_wait_ms": 0.27597172050213253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012060403823852539, "StateBufferConnector_ms": 0.004128932952880859, "ViewRequirementAgentConnector_ms": 0.18883168697357178}, "num_episodes": 18, "episode_return_max": 55.400000000000475, "episode_return_min": -79.7000000000003, "episode_return_mean": 9.584000000000163, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 328.622556242761, "num_env_steps_trained_throughput_per_sec": 328.622556242761, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 12705.35, "restore_workers_time_ms": 0.024, "training_step_time_ms": 12705.265, "sample_time_ms": 2005.346, "learn_time_ms": 10670.284, "learn_throughput": 374.873, "synch_weights_time_ms": 26.626}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-02-51", "timestamp": 1723647771, "time_this_iter_s": 12.241519212722778, "time_total_s": 938.9572598934174, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a33160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 938.9572598934174, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 50.43529411764706, "ram_util_percent": 83.30588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.564241674652806, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8046308013181838, "policy_loss": -0.007251499406870198, "vf_loss": 1.8100928584419231, "vf_explained_var": -0.3675808988866352, "kl": 0.006283887649858452, "entropy": 1.3618726040320421, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.858476599593642, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0838154705113205, "policy_loss": -0.004941672898296799, "vf_loss": 2.08829849415986, "vf_explained_var": 0.030645499185279562, "kl": 0.006115357079517007, "entropy": 0.5468548403215157, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 56.40000000000049, "episode_reward_min": -67.70000000000022, "episode_reward_mean": 16.46700000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -167.50000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 27.20000000000013, "predator_policy": 93.0}, "policy_reward_mean": {"prey_policy": -15.956499999999966, "predator_policy": 24.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.800000000000022, -15.099999999999579, 22.20000000000004, -1.3999999999999617, 18.300000000000008, 43.20000000000037, 43.10000000000048, -7.100000000000103, 5.499999999999968, 9.999999999999954, 40.9000000000004, -6.200000000000093, 3.599999999999945, 37.60000000000029, 22.4, -2.9000000000000346, 29.000000000000128, 27.0000000000002, 52.900000000000404, 40.50000000000026, -8.299999999999995, 2.6999999999999664, -18.19999999999968, 32.50000000000041, 29.000000000000384, 42.60000000000041, -39.399999999999665, 8.700000000000104, -67.70000000000022, 35.600000000000236, 1.1999999999999744, -20.199999999999793, 20.199999999999974, -32.59999999999981, -8.200000000000042, -26.699999999999555, -20.49999999999968, 22.600000000000147, 43.10000000000037, 26.80000000000009, -5.70000000000009, 28.600000000000108, 34.80000000000045, 25.100000000000037, 16.799999999999923, 36.20000000000046, -63.4999999999999, 20.900000000000077, 20.09999999999999, 10.299999999999926, 34.50000000000022, 1.7999999999999108, -36.49999999999959, 30.9000000000002, -8.500000000000046, 28.20000000000033, 47.300000000000466, 32.600000000000435, 18.499999999999993, -19.59999999999954, 9.999999999999991, 11.299999999999919, 47.9000000000004, -19.19999999999952, 32.800000000000445, 1.7000000000001723, 45.00000000000046, 25.50000000000037, 30.10000000000014, 32.80000000000039, 40.70000000000019, 54.70000000000045, 19.099999999999948, 38.80000000000034, 38.20000000000029, 55.400000000000475, 25.70000000000007, 14.599999999999941, 30.500000000000163, 38.80000000000028, 4.9000000000001, 8.499999999999984, 40.0000000000003, -19.699999999999513, -5.39999999999967, 14.4999999999999, 40.60000000000031, 29.300000000000146, 33.00000000000021, 25.400000000000084, 31.100000000000218, 35.900000000000325, 56.40000000000049, -16.399999999999594, 36.10000000000024, 48.10000000000043, 37.800000000000175, -2.799999999999748, 41.00000000000031, 7.299999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.1999999999999265, -73.60000000000022, -65.80000000000011, -16.299999999999763, -0.09999999999999937, 5.299999999999965, -41.499999999999766, -4.900000000000004, -0.9999999999999846, 5.299999999999965, -26.19999999999991, 1.399999999999989, 9.499999999999964, -3.399999999999889, -22.899999999999892, -26.199999999999875, -37.599999999999916, 1.09999999999996, -9.40000000000006, -19.59999999999991, -5.500000000000037, -4.600000000000052, -51.3999999999999, -56.79999999999977, -88.30000000000084, 2.8999999999999435, -15.399999999999865, 20.000000000000014, 20.000000000000014, -58.5999999999998, -52.59999999999978, -25.299999999999812, 20.000000000000014, -0.9999999999999846, 1.6999999999999937, -12.699999999999957, 4.100000000000001, 24.800000000000153, -15.699999999999747, -17.799999999999997, -39.69999999999978, -34.59999999999978, -8.199999999999909, -45.09999999999978, -63.399999999999984, -17.79999999999974, 20.000000000000014, -71.49999999999997, -7.599999999999827, -66.40000000000019, 4.100000000000137, -17.49999999999995, -90.40000000000013, -51.99999999999982, -89.79999999999998, 3.500000000000029, -110.8000000000003, -82.90000000000035, 11.599999999999964, 20.000000000000014, 20.000000000000014, -86.80000000000021, -41.49999999999986, -48.69999999999978, -30.39999999999975, 11.599999999999964, -40.300000000000004, -76.30000000000022, -45.09999999999986, -18.100000000000005, -30.099999999999774, -73.60000000000005, 20.000000000000014, -119.5000000000006, 15.799999999999963, -41.19999999999976, 15.799999999999963, 11.299999999999969, 17.899999999999988, -3.099999999999958, -21.099999999999945, -49.599999999999795, -21.399999999999764, 20.000000000000014, 12.199999999999951, -0.399999999999923, -19.299999999999798, -25.599999999999767, 9.499999999999964, -15.69999999999984, -21.399999999999956, 11.599999999999964, -66.99999999999999, -167.50000000000043, -1.0000000000000346, -39.099999999999774, -22.899999999999757, 20.000000000000014, -5.199999999999962, -23.49999999999975, 9.499999999999964, 20.000000000000014, -25.299999999999834, -19.899999999999743, -17.799999999999805, -120.70000000000076, -21.699999999999847, -9.399999999999924, -55.599999999999824, 1.0999999999999799, -4.000000000000055, -17.799999999999898, 7.399999999999965, 8.900000000000187, 13.699999999999964, -15.099999999999984, -4.300000000000066, -5.1999999999999265, -49.59999999999985, -42.99999999999976, -120.70000000000056, 13.699999999999964, 7.399999999999965, -33.09999999999976, 22.700000000000127, 3.1999999999999615, -5.1999999999999265, -73.00000000000085, -7.300000000000031, 1.0999999999999706, -0.9999999999999846, -46.299999999999805, -38.799999999999756, 24.800000000000253, 21.200000000000244, -42.69999999999978, -11.49999999999989, 14.599999999999966, 25.100000000000218, -40.29999999999976, 16.099999999999955, -0.4000000000000231, 25.700000000000117, 20.000000000000014, -21.999999999999744, 13.099999999999955, -13.599999999999783, 13.400000000000153, 11.299999999999974, 20.900000000000027, 10.699999999999982, 25.700000000000095, 20.000000000000014, -7.299999999999891, -17.799999999999876, 4.399999999999985, -1.2999999999999847, 15.799999999999962, -12.399999999999816, 21.200000000000035, -24.699999999999754, -51.39999999999979, -6.999999999999909, -29.49999999999975, 20.000000000000014, 20.000000000000014, -24.099999999999795, -34.59999999999975, -28.29999999999975, -3.099999999999958, -2.200000000000043, -16.29999999999975, 21.500000000000036, 13.099999999999968, -57.70000000000045, 20.000000000000014, 1.0999999999999617, 17.899999999999984, 15.799999999999963, -9.40000000000003, 16.399999999999956, -7.300000000000061, -28.29999999999982, 0.20000000000000198, 27.20000000000013, 9.199999999999973, -74.50000000000087, -52.89999999999993, 20.600000000000037, -11.499999999999819, -21.999999999999744, -7.899999999999956, 25.100000000000016, -7.299999999999926, -44.79999999999977, -0.9999999999999846, 13.699999999999969, 14.299999999999972, 8.299999999999965, -67.0000000000008], "policy_predator_policy_reward": [34.0, 32.0, 26.0, 41.0, 10.0, 7.0, 25.0, 20.0, 10.0, 4.0, 40.0, 28.0, 25.0, 12.0, 9.0, 33.0, 18.0, 24.0, 16.0, 23.0, 27.0, 24.0, 57.0, 45.0, 49.0, 40.0, 18.0, 15.0, 20.0, 41.0, 42.0, 33.0, 10.0, 0.0, 17.0, 21.0, 9.0, 15.0, 32.0, 42.0, 31.0, 35.0, 23.0, 33.0, 18.0, 45.0, 39.0, 45.0, 43.0, 60.0, 30.0, 26.0, 50.0, 53.0, 44.0, 51.0, 60.0, 66.0, 0.0, 4.0, 24.0, 44.0, 52.0, 18.0, 24.0, 15.0, 38.0, 46.0, 29.0, 26.0, 35.0, 42.0, 60.0, 19.0, 30.0, 18.0, 11.0, 5.0, 11.0, 1.0, 32.0, 33.0, 12.0, 18.0, 13.0, 10.0, 33.0, 37.0, 16.0, 7.0, 18.0, 28.0, 78.0, 93.0, 34.0, 27.0, 0.0, 23.0, 6.0, 33.0, 5.0, 0.0, 9.0, 38.0, 54.0, 48.0, 29.0, 33.0, 13.0, 33.0, 20.0, 30.0, 14.0, 17.0, 18.0, 16.0, 17.0, 11.0, 36.0, 37.0, 69.0, 48.0, 15.0, 22.0, 10.0, 12.0, 24.0, 35.0, 19.0, 20.0, 32.0, 17.0, 29.0, 30.0, 24.0, 23.0, 10.0, 17.0, 31.0, 17.0, 12.0, 13.0, 4.0, 5.0, 13.0, 15.0, 26.0, 13.0, 5.0, 1.0, 10.0, 9.0, 13.0, 0.0, 13.0, 15.0, 7.0, 9.0, 15.0, 15.0, 28.0, 53.0, 22.0, 23.0, 0.0, 0.0, 3.0, 36.0, 23.0, 3.0, 23.0, 10.0, 5.0, 1.0, 34.0, 33.0, 5.0, 9.0, 7.0, 12.0, 8.0, 14.0, 22.0, 42.0, 9.0, 11.0, 50.0, 61.0, 15.0, 12.0, 37.0, 41.0, 6.0, 14.0, 33.0, 10.0, 1.0, 12.0, 36.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8286623886793265, "mean_inference_ms": 2.171513578658672, "mean_action_processing_ms": 0.3474803364221809, "mean_env_wait_ms": 0.2763674657916076, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00810384750366211, "StateBufferConnector_ms": 0.00413358211517334, "ViewRequirementAgentConnector_ms": 0.16844439506530762}, "num_episodes": 23, "episode_return_max": 56.40000000000049, "episode_return_min": -67.70000000000022, "episode_return_mean": 16.46700000000019, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.54859351746245, "num_env_steps_trained_throughput_per_sec": 317.54859351746245, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 12699.022, "restore_workers_time_ms": 0.022, "training_step_time_ms": 12698.941, "sample_time_ms": 1986.667, "learn_time_ms": 10681.362, "learn_throughput": 374.484, "synch_weights_time_ms": 27.841}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-03-04", "timestamp": 1723647784, "time_this_iter_s": 12.664927005767822, "time_total_s": 951.6221868991852, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b69670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 951.6221868991852, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 51.35555555555556, "ram_util_percent": 83.37222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.421836178580289, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6549809120319507, "policy_loss": -0.008773684406051875, "vf_loss": 1.6624022094030229, "vf_explained_var": -0.40392347375551857, "kl": 0.004749119017668261, "entropy": 1.3706453219923393, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9824779847311595, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6646166315154425, "policy_loss": -0.005158045849757929, "vf_loss": 1.6693001619407108, "vf_explained_var": 0.08851179597239014, "kl": 0.00632688544472115, "entropy": 0.5556975916579917, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 56.40000000000049, "episode_reward_min": -67.70000000000022, "episode_reward_mean": 18.0890000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -167.50000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 28.70000000000016, "predator_policy": 93.0}, "policy_reward_mean": {"prey_policy": -13.56549999999997, "predator_policy": 22.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [52.900000000000404, 40.50000000000026, -8.299999999999995, 2.6999999999999664, -18.19999999999968, 32.50000000000041, 29.000000000000384, 42.60000000000041, -39.399999999999665, 8.700000000000104, -67.70000000000022, 35.600000000000236, 1.1999999999999744, -20.199999999999793, 20.199999999999974, -32.59999999999981, -8.200000000000042, -26.699999999999555, -20.49999999999968, 22.600000000000147, 43.10000000000037, 26.80000000000009, -5.70000000000009, 28.600000000000108, 34.80000000000045, 25.100000000000037, 16.799999999999923, 36.20000000000046, -63.4999999999999, 20.900000000000077, 20.09999999999999, 10.299999999999926, 34.50000000000022, 1.7999999999999108, -36.49999999999959, 30.9000000000002, -8.500000000000046, 28.20000000000033, 47.300000000000466, 32.600000000000435, 18.499999999999993, -19.59999999999954, 9.999999999999991, 11.299999999999919, 47.9000000000004, -19.19999999999952, 32.800000000000445, 1.7000000000001723, 45.00000000000046, 25.50000000000037, 30.10000000000014, 32.80000000000039, 40.70000000000019, 54.70000000000045, 19.099999999999948, 38.80000000000034, 38.20000000000029, 55.400000000000475, 25.70000000000007, 14.599999999999941, 30.500000000000163, 38.80000000000028, 4.9000000000001, 8.499999999999984, 40.0000000000003, -19.699999999999513, -5.39999999999967, 14.4999999999999, 40.60000000000031, 29.300000000000146, 33.00000000000021, 25.400000000000084, 31.100000000000218, 35.900000000000325, 56.40000000000049, -16.399999999999594, 36.10000000000024, 48.10000000000043, 37.800000000000175, -2.799999999999748, 41.00000000000031, 7.299999999999918, 7.000000000000121, 43.000000000000384, 33.400000000000205, 19.19999999999997, 36.70000000000025, 44.20000000000035, 43.00000000000035, -57.000000000001066, 30.1000000000001, 46.20000000000045, 35.600000000000236, 39.30000000000033, 25.400000000000084, 33.70000000000028, 16.299999999999933, 48.60000000000044, 1.7161272403143357e-13, -25.199999999999548], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [4.100000000000001, 24.800000000000153, -15.699999999999747, -17.799999999999997, -39.69999999999978, -34.59999999999978, -8.199999999999909, -45.09999999999978, -63.399999999999984, -17.79999999999974, 20.000000000000014, -71.49999999999997, -7.599999999999827, -66.40000000000019, 4.100000000000137, -17.49999999999995, -90.40000000000013, -51.99999999999982, -89.79999999999998, 3.500000000000029, -110.8000000000003, -82.90000000000035, 11.599999999999964, 20.000000000000014, 20.000000000000014, -86.80000000000021, -41.49999999999986, -48.69999999999978, -30.39999999999975, 11.599999999999964, -40.300000000000004, -76.30000000000022, -45.09999999999986, -18.100000000000005, -30.099999999999774, -73.60000000000005, 20.000000000000014, -119.5000000000006, 15.799999999999963, -41.19999999999976, 15.799999999999963, 11.299999999999969, 17.899999999999988, -3.099999999999958, -21.099999999999945, -49.599999999999795, -21.399999999999764, 20.000000000000014, 12.199999999999951, -0.399999999999923, -19.299999999999798, -25.599999999999767, 9.499999999999964, -15.69999999999984, -21.399999999999956, 11.599999999999964, -66.99999999999999, -167.50000000000043, -1.0000000000000346, -39.099999999999774, -22.899999999999757, 20.000000000000014, -5.199999999999962, -23.49999999999975, 9.499999999999964, 20.000000000000014, -25.299999999999834, -19.899999999999743, -17.799999999999805, -120.70000000000076, -21.699999999999847, -9.399999999999924, -55.599999999999824, 1.0999999999999799, -4.000000000000055, -17.799999999999898, 7.399999999999965, 8.900000000000187, 13.699999999999964, -15.099999999999984, -4.300000000000066, -5.1999999999999265, -49.59999999999985, -42.99999999999976, -120.70000000000056, 13.699999999999964, 7.399999999999965, -33.09999999999976, 22.700000000000127, 3.1999999999999615, -5.1999999999999265, -73.00000000000085, -7.300000000000031, 1.0999999999999706, -0.9999999999999846, -46.299999999999805, -38.799999999999756, 24.800000000000253, 21.200000000000244, -42.69999999999978, -11.49999999999989, 14.599999999999966, 25.100000000000218, -40.29999999999976, 16.099999999999955, -0.4000000000000231, 25.700000000000117, 20.000000000000014, -21.999999999999744, 13.099999999999955, -13.599999999999783, 13.400000000000153, 11.299999999999974, 20.900000000000027, 10.699999999999982, 25.700000000000095, 20.000000000000014, -7.299999999999891, -17.799999999999876, 4.399999999999985, -1.2999999999999847, 15.799999999999962, -12.399999999999816, 21.200000000000035, -24.699999999999754, -51.39999999999979, -6.999999999999909, -29.49999999999975, 20.000000000000014, 20.000000000000014, -24.099999999999795, -34.59999999999975, -28.29999999999975, -3.099999999999958, -2.200000000000043, -16.29999999999975, 21.500000000000036, 13.099999999999968, -57.70000000000045, 20.000000000000014, 1.0999999999999617, 17.899999999999984, 15.799999999999963, -9.40000000000003, 16.399999999999956, -7.300000000000061, -28.29999999999982, 0.20000000000000198, 27.20000000000013, 9.199999999999973, -74.50000000000087, -52.89999999999993, 20.600000000000037, -11.499999999999819, -21.999999999999744, -7.899999999999956, 25.100000000000016, -7.299999999999926, -44.79999999999977, -0.9999999999999846, 13.699999999999969, 14.299999999999972, 8.299999999999965, -67.0000000000008, 17.899999999999988, -40.89999999999976, 4.39999999999999, 11.599999999999964, 20.000000000000014, 7.399999999999965, -47.79999999999977, 20.000000000000014, 13.699999999999966, 20.000000000000014, 20.000000000000014, 18.199999999999996, 10.399999999999968, 23.60000000000007, -80.80000000000084, -47.199999999999775, 16.400000000000002, -28.299999999999784, -11.799999999999846, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, -33.699999999999875, -19.89999999999977, 2.2999999999999607, 20.000000000000014, -19.29999999999979, -9.399999999999915, -7.299999999999891, 17.899999999999988, 28.70000000000016, -29.79999999999977, -44.19999999999979, -91.30000000000084, 7.099999999999963], "policy_predator_policy_reward": [9.0, 15.0, 32.0, 42.0, 31.0, 35.0, 23.0, 33.0, 18.0, 45.0, 39.0, 45.0, 43.0, 60.0, 30.0, 26.0, 50.0, 53.0, 44.0, 51.0, 60.0, 66.0, 0.0, 4.0, 24.0, 44.0, 52.0, 18.0, 24.0, 15.0, 38.0, 46.0, 29.0, 26.0, 35.0, 42.0, 60.0, 19.0, 30.0, 18.0, 11.0, 5.0, 11.0, 1.0, 32.0, 33.0, 12.0, 18.0, 13.0, 10.0, 33.0, 37.0, 16.0, 7.0, 18.0, 28.0, 78.0, 93.0, 34.0, 27.0, 0.0, 23.0, 6.0, 33.0, 5.0, 0.0, 9.0, 38.0, 54.0, 48.0, 29.0, 33.0, 13.0, 33.0, 20.0, 30.0, 14.0, 17.0, 18.0, 16.0, 17.0, 11.0, 36.0, 37.0, 69.0, 48.0, 15.0, 22.0, 10.0, 12.0, 24.0, 35.0, 19.0, 20.0, 32.0, 17.0, 29.0, 30.0, 24.0, 23.0, 10.0, 17.0, 31.0, 17.0, 12.0, 13.0, 4.0, 5.0, 13.0, 15.0, 26.0, 13.0, 5.0, 1.0, 10.0, 9.0, 13.0, 0.0, 13.0, 15.0, 7.0, 9.0, 15.0, 15.0, 28.0, 53.0, 22.0, 23.0, 0.0, 0.0, 3.0, 36.0, 23.0, 3.0, 23.0, 10.0, 5.0, 1.0, 34.0, 33.0, 5.0, 9.0, 7.0, 12.0, 8.0, 14.0, 22.0, 42.0, 9.0, 11.0, 50.0, 61.0, 15.0, 12.0, 37.0, 41.0, 6.0, 14.0, 33.0, 10.0, 1.0, 12.0, 36.0, 30.0, 29.0, 1.0, 12.0, 15.0, 6.0, 0.0, 18.0, 29.0, 0.0, 3.0, 5.0, 1.0, 1.0, 8.0, 26.0, 45.0, 17.0, 25.0, 17.0, 21.0, 1.0, 3.0, 31.0, 22.0, 23.0, 20.0, 8.0, 25.0, 19.0, 14.0, 1.0, 1.0, 25.0, 49.0, 6.0, 53.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8285817046166776, "mean_inference_ms": 2.1717848683510197, "mean_action_processing_ms": 0.3472948600237399, "mean_env_wait_ms": 0.2764046362525287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0057839155197143555, "StateBufferConnector_ms": 0.008887290954589844, "ViewRequirementAgentConnector_ms": 0.1439138650894165}, "num_episodes": 18, "episode_return_max": 56.40000000000049, "episode_return_min": -67.70000000000022, "episode_return_mean": 18.0890000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.24849778409583, "num_env_steps_trained_throughput_per_sec": 333.24849778409583, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 12644.215, "restore_workers_time_ms": 0.022, "training_step_time_ms": 12644.134, "sample_time_ms": 1952.923, "learn_time_ms": 10660.706, "learn_throughput": 375.21, "synch_weights_time_ms": 27.545}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-03-16", "timestamp": 1723647796, "time_this_iter_s": 12.100024938583374, "time_total_s": 963.7222118377686, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b69b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 963.7222118377686, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 47.54705882352942, "ram_util_percent": 82.69999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.056654226527643, "cur_kl_coeff": 0.14238281249999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0915883491121272, "policy_loss": -0.007782576377774594, "vf_loss": 1.0984528611576747, "vf_explained_var": -0.4519313746028476, "kl": 0.006447869713265752, "entropy": 1.3655266818546115, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.530481668124123, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9935282118736751, "policy_loss": -0.006851125758870569, "vf_loss": 0.9999209050463621, "vf_explained_var": 0.07064729755517667, "kl": 0.006112431069223935, "entropy": 0.5030682589641955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 56.40000000000049, "episode_reward_min": -63.4999999999999, "episode_reward_mean": 23.589000000000205, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -167.50000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 29.90000000000024, "predator_policy": 93.0}, "policy_reward_mean": {"prey_policy": -6.620499999999965, "predator_policy": 18.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.70000000000009, 28.600000000000108, 34.80000000000045, 25.100000000000037, 16.799999999999923, 36.20000000000046, -63.4999999999999, 20.900000000000077, 20.09999999999999, 10.299999999999926, 34.50000000000022, 1.7999999999999108, -36.49999999999959, 30.9000000000002, -8.500000000000046, 28.20000000000033, 47.300000000000466, 32.600000000000435, 18.499999999999993, -19.59999999999954, 9.999999999999991, 11.299999999999919, 47.9000000000004, -19.19999999999952, 32.800000000000445, 1.7000000000001723, 45.00000000000046, 25.50000000000037, 30.10000000000014, 32.80000000000039, 40.70000000000019, 54.70000000000045, 19.099999999999948, 38.80000000000034, 38.20000000000029, 55.400000000000475, 25.70000000000007, 14.599999999999941, 30.500000000000163, 38.80000000000028, 4.9000000000001, 8.499999999999984, 40.0000000000003, -19.699999999999513, -5.39999999999967, 14.4999999999999, 40.60000000000031, 29.300000000000146, 33.00000000000021, 25.400000000000084, 31.100000000000218, 35.900000000000325, 56.40000000000049, -16.399999999999594, 36.10000000000024, 48.10000000000043, 37.800000000000175, -2.799999999999748, 41.00000000000031, 7.299999999999918, 7.000000000000121, 43.000000000000384, 33.400000000000205, 19.19999999999997, 36.70000000000025, 44.20000000000035, 43.00000000000035, -57.000000000001066, 30.1000000000001, 46.20000000000045, 35.600000000000236, 39.30000000000033, 25.400000000000084, 33.70000000000028, 16.299999999999933, 48.60000000000044, 1.7161272403143357e-13, -25.199999999999548, 27.700000000000124, 19.199999999999957, 28.800000000000125, 40.0000000000003, 43.400000000000354, 56.300000000000495, 2.100000000000201, 20.19999999999997, 33.50000000000019, 8.000000000000146, 9.900000000000205, 33.80000000000018, 26.40000000000009, 34.200000000000216, 20.2, 44.40000000000037, 28.200000000000117, 30.80000000000016, 47.900000000000446, 42.30000000000033, 36.50000000000025, 32.80000000000011], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-21.099999999999945, -49.599999999999795, -21.399999999999764, 20.000000000000014, 12.199999999999951, -0.399999999999923, -19.299999999999798, -25.599999999999767, 9.499999999999964, -15.69999999999984, -21.399999999999956, 11.599999999999964, -66.99999999999999, -167.50000000000043, -1.0000000000000346, -39.099999999999774, -22.899999999999757, 20.000000000000014, -5.199999999999962, -23.49999999999975, 9.499999999999964, 20.000000000000014, -25.299999999999834, -19.899999999999743, -17.799999999999805, -120.70000000000076, -21.699999999999847, -9.399999999999924, -55.599999999999824, 1.0999999999999799, -4.000000000000055, -17.799999999999898, 7.399999999999965, 8.900000000000187, 13.699999999999964, -15.099999999999984, -4.300000000000066, -5.1999999999999265, -49.59999999999985, -42.99999999999976, -120.70000000000056, 13.699999999999964, 7.399999999999965, -33.09999999999976, 22.700000000000127, 3.1999999999999615, -5.1999999999999265, -73.00000000000085, -7.300000000000031, 1.0999999999999706, -0.9999999999999846, -46.299999999999805, -38.799999999999756, 24.800000000000253, 21.200000000000244, -42.69999999999978, -11.49999999999989, 14.599999999999966, 25.100000000000218, -40.29999999999976, 16.099999999999955, -0.4000000000000231, 25.700000000000117, 20.000000000000014, -21.999999999999744, 13.099999999999955, -13.599999999999783, 13.400000000000153, 11.299999999999974, 20.900000000000027, 10.699999999999982, 25.700000000000095, 20.000000000000014, -7.299999999999891, -17.799999999999876, 4.399999999999985, -1.2999999999999847, 15.799999999999962, -12.399999999999816, 21.200000000000035, -24.699999999999754, -51.39999999999979, -6.999999999999909, -29.49999999999975, 20.000000000000014, 20.000000000000014, -24.099999999999795, -34.59999999999975, -28.29999999999975, -3.099999999999958, -2.200000000000043, -16.29999999999975, 21.500000000000036, 13.099999999999968, -57.70000000000045, 20.000000000000014, 1.0999999999999617, 17.899999999999984, 15.799999999999963, -9.40000000000003, 16.399999999999956, -7.300000000000061, -28.29999999999982, 0.20000000000000198, 27.20000000000013, 9.199999999999973, -74.50000000000087, -52.89999999999993, 20.600000000000037, -11.499999999999819, -21.999999999999744, -7.899999999999956, 25.100000000000016, -7.299999999999926, -44.79999999999977, -0.9999999999999846, 13.699999999999969, 14.299999999999972, 8.299999999999965, -67.0000000000008, 17.899999999999988, -40.89999999999976, 4.39999999999999, 11.599999999999964, 20.000000000000014, 7.399999999999965, -47.79999999999977, 20.000000000000014, 13.699999999999966, 20.000000000000014, 20.000000000000014, 18.199999999999996, 10.399999999999968, 23.60000000000007, -80.80000000000084, -47.199999999999775, 16.400000000000002, -28.299999999999784, -11.799999999999846, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, -33.699999999999875, -19.89999999999977, 2.2999999999999607, 20.000000000000014, -19.29999999999979, -9.399999999999915, -7.299999999999891, 17.899999999999988, 28.70000000000016, -29.79999999999977, -44.19999999999979, -91.30000000000084, 7.099999999999963, -2.1999999999999713, -27.099999999999774, 13.699999999999964, -17.49999999999975, -21.09999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, 17.59999999999998, 15.799999999999963, 7.399999999999965, 29.90000000000024, -49.299999999999905, 7.399999999999965, 20.000000000000014, -17.79999999999975, 19.700000000000003, -2.2000000000000552, -0.9999999999999846, -0.9999999999999846, -34.59999999999975, -5.499999999999881, -9.399999999999968, 3.1999999999999615, -52.60000000000012, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 20.000000000000014, 10.399999999999968, 18.19999999999999, -0.9999999999999846, 13.699999999999964, -25.899999999999757, -40.89999999999977, 24.800000000000093, 20.300000000000022, 20.000000000000014, 12.499999999999964, 20.000000000000014, 19.999999999999996, -5.1999999999999265], "policy_predator_policy_reward": [32.0, 33.0, 12.0, 18.0, 13.0, 10.0, 33.0, 37.0, 16.0, 7.0, 18.0, 28.0, 78.0, 93.0, 34.0, 27.0, 0.0, 23.0, 6.0, 33.0, 5.0, 0.0, 9.0, 38.0, 54.0, 48.0, 29.0, 33.0, 13.0, 33.0, 20.0, 30.0, 14.0, 17.0, 18.0, 16.0, 17.0, 11.0, 36.0, 37.0, 69.0, 48.0, 15.0, 22.0, 10.0, 12.0, 24.0, 35.0, 19.0, 20.0, 32.0, 17.0, 29.0, 30.0, 24.0, 23.0, 10.0, 17.0, 31.0, 17.0, 12.0, 13.0, 4.0, 5.0, 13.0, 15.0, 26.0, 13.0, 5.0, 1.0, 10.0, 9.0, 13.0, 0.0, 13.0, 15.0, 7.0, 9.0, 15.0, 15.0, 28.0, 53.0, 22.0, 23.0, 0.0, 0.0, 3.0, 36.0, 23.0, 3.0, 23.0, 10.0, 5.0, 1.0, 34.0, 33.0, 5.0, 9.0, 7.0, 12.0, 8.0, 14.0, 22.0, 42.0, 9.0, 11.0, 50.0, 61.0, 15.0, 12.0, 37.0, 41.0, 6.0, 14.0, 33.0, 10.0, 1.0, 12.0, 36.0, 30.0, 29.0, 1.0, 12.0, 15.0, 6.0, 0.0, 18.0, 29.0, 0.0, 3.0, 5.0, 1.0, 1.0, 8.0, 26.0, 45.0, 17.0, 25.0, 17.0, 21.0, 1.0, 3.0, 31.0, 22.0, 23.0, 20.0, 8.0, 25.0, 19.0, 14.0, 1.0, 1.0, 25.0, 49.0, 6.0, 53.0, 27.0, 30.0, 13.0, 10.0, 14.0, 18.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 26.0, 18.0, 18.0, 0.0, 15.0, 1.0, 0.0, 10.0, 26.0, 24.0, 11.0, 29.0, 33.0, 26.0, 8.0, 3.0, 12.0, 6.0, 7.0, 7.0, 10.0, 1.0, 20.0, 23.0, 32.0, 32.0, 2.0, 0.0, 0.0, 4.0, 14.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8284467557485456, "mean_inference_ms": 2.1720712298095464, "mean_action_processing_ms": 0.3464978394131312, "mean_env_wait_ms": 0.2762007544538569, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005688786506652832, "StateBufferConnector_ms": 0.008275270462036133, "ViewRequirementAgentConnector_ms": 0.14504194259643555}, "num_episodes": 22, "episode_return_max": 56.40000000000049, "episode_return_min": -63.4999999999999, "episode_return_mean": 23.589000000000205, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.3495809248825, "num_env_steps_trained_throughput_per_sec": 348.3495809248825, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 12506.269, "restore_workers_time_ms": 0.022, "training_step_time_ms": 12506.188, "sample_time_ms": 1913.949, "learn_time_ms": 10560.935, "learn_throughput": 378.754, "synch_weights_time_ms": 28.274}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-03-28", "timestamp": 1723647808, "time_this_iter_s": 11.52530026435852, "time_total_s": 975.2475121021271, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a330d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 975.2475121021271, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 43.03125, "ram_util_percent": 82.78125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9834653331173793, "cur_kl_coeff": 0.14238281249999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6261627730238375, "policy_loss": -0.00807123828492073, "vf_loss": 1.6335434278167744, "vf_explained_var": -0.047253091814656735, "kl": 0.004850143889242971, "entropy": 1.3873206001110179, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.281407770057204, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.760392763690343, "policy_loss": -0.006403310190413207, "vf_loss": 1.766369202622661, "vf_explained_var": 0.029817177284331548, "kl": 0.005691598217595444, "entropy": 0.49784663352701397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 66.50000000000043, "episode_reward_min": -57.000000000001066, "episode_reward_mean": 26.365000000000215, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -120.70000000000056, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 31.400000000000226, "predator_policy": 69.0}, "policy_reward_mean": {"prey_policy": -3.16749999999997, "predator_policy": 16.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.499999999999993, -19.59999999999954, 9.999999999999991, 11.299999999999919, 47.9000000000004, -19.19999999999952, 32.800000000000445, 1.7000000000001723, 45.00000000000046, 25.50000000000037, 30.10000000000014, 32.80000000000039, 40.70000000000019, 54.70000000000045, 19.099999999999948, 38.80000000000034, 38.20000000000029, 55.400000000000475, 25.70000000000007, 14.599999999999941, 30.500000000000163, 38.80000000000028, 4.9000000000001, 8.499999999999984, 40.0000000000003, -19.699999999999513, -5.39999999999967, 14.4999999999999, 40.60000000000031, 29.300000000000146, 33.00000000000021, 25.400000000000084, 31.100000000000218, 35.900000000000325, 56.40000000000049, -16.399999999999594, 36.10000000000024, 48.10000000000043, 37.800000000000175, -2.799999999999748, 41.00000000000031, 7.299999999999918, 7.000000000000121, 43.000000000000384, 33.400000000000205, 19.19999999999997, 36.70000000000025, 44.20000000000035, 43.00000000000035, -57.000000000001066, 30.1000000000001, 46.20000000000045, 35.600000000000236, 39.30000000000033, 25.400000000000084, 33.70000000000028, 16.299999999999933, 48.60000000000044, 1.7161272403143357e-13, -25.199999999999548, 27.700000000000124, 19.199999999999957, 28.800000000000125, 40.0000000000003, 43.400000000000354, 56.300000000000495, 2.100000000000201, 20.19999999999997, 33.50000000000019, 8.000000000000146, 9.900000000000205, 33.80000000000018, 26.40000000000009, 34.200000000000216, 20.2, 44.40000000000037, 28.200000000000117, 30.80000000000016, 47.900000000000446, 42.30000000000033, 36.50000000000025, 32.80000000000011, -9.199999999999635, 43.800000000000345, 5.900000000000096, 30.80000000000016, 26.800000000000086, 31.800000000000182, 25.60000000000008, 31.200000000000166, 31.200000000000163, 25.900000000000077, 39.40000000000029, 29.20000000000031, 4.100000000000181, 33.0000000000002, 35.30000000000023, 36.70000000000025, 66.50000000000043, 43.50000000000035], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-4.300000000000066, -5.1999999999999265, -49.59999999999985, -42.99999999999976, -120.70000000000056, 13.699999999999964, 7.399999999999965, -33.09999999999976, 22.700000000000127, 3.1999999999999615, -5.1999999999999265, -73.00000000000085, -7.300000000000031, 1.0999999999999706, -0.9999999999999846, -46.299999999999805, -38.799999999999756, 24.800000000000253, 21.200000000000244, -42.69999999999978, -11.49999999999989, 14.599999999999966, 25.100000000000218, -40.29999999999976, 16.099999999999955, -0.4000000000000231, 25.700000000000117, 20.000000000000014, -21.999999999999744, 13.099999999999955, -13.599999999999783, 13.400000000000153, 11.299999999999974, 20.900000000000027, 10.699999999999982, 25.700000000000095, 20.000000000000014, -7.299999999999891, -17.799999999999876, 4.399999999999985, -1.2999999999999847, 15.799999999999962, -12.399999999999816, 21.200000000000035, -24.699999999999754, -51.39999999999979, -6.999999999999909, -29.49999999999975, 20.000000000000014, 20.000000000000014, -24.099999999999795, -34.59999999999975, -28.29999999999975, -3.099999999999958, -2.200000000000043, -16.29999999999975, 21.500000000000036, 13.099999999999968, -57.70000000000045, 20.000000000000014, 1.0999999999999617, 17.899999999999984, 15.799999999999963, -9.40000000000003, 16.399999999999956, -7.300000000000061, -28.29999999999982, 0.20000000000000198, 27.20000000000013, 9.199999999999973, -74.50000000000087, -52.89999999999993, 20.600000000000037, -11.499999999999819, -21.999999999999744, -7.899999999999956, 25.100000000000016, -7.299999999999926, -44.79999999999977, -0.9999999999999846, 13.699999999999969, 14.299999999999972, 8.299999999999965, -67.0000000000008, 17.899999999999988, -40.89999999999976, 4.39999999999999, 11.599999999999964, 20.000000000000014, 7.399999999999965, -47.79999999999977, 20.000000000000014, 13.699999999999966, 20.000000000000014, 20.000000000000014, 18.199999999999996, 10.399999999999968, 23.60000000000007, -80.80000000000084, -47.199999999999775, 16.400000000000002, -28.299999999999784, -11.799999999999846, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, -33.699999999999875, -19.89999999999977, 2.2999999999999607, 20.000000000000014, -19.29999999999979, -9.399999999999915, -7.299999999999891, 17.899999999999988, 28.70000000000016, -29.79999999999977, -44.19999999999979, -91.30000000000084, 7.099999999999963, -2.1999999999999713, -27.099999999999774, 13.699999999999964, -17.49999999999975, -21.09999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, 17.59999999999998, 15.799999999999963, 7.399999999999965, 29.90000000000024, -49.299999999999905, 7.399999999999965, 20.000000000000014, -17.79999999999975, 19.700000000000003, -2.2000000000000552, -0.9999999999999846, -0.9999999999999846, -34.59999999999975, -5.499999999999881, -9.399999999999968, 3.1999999999999615, -52.60000000000012, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 20.000000000000014, 10.399999999999968, 18.19999999999999, -0.9999999999999846, 13.699999999999964, -25.899999999999757, -40.89999999999977, 24.800000000000093, 20.300000000000022, 20.000000000000014, 12.499999999999964, 20.000000000000014, 19.999999999999996, -5.1999999999999265, -7.299999999999894, -40.89999999999977, 7.399999999999965, 25.400000000000112, -65.2000000000009, -1.9, 21.800000000000047, -0.9999999999999846, 11.599999999999964, 3.1999999999999615, 8.899999999999967, -30.09999999999979, -11.799999999999836, 7.399999999999965, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 6.7999999999999705, -15.099999999999763, 20.000000000000014, -8.199999999999887, 23.60000000000007, -24.699999999999974, 20.900000000000027, 5.299999999999965, -47.19999999999976, -43.899999999999764, 17.899999999999984, 20.000000000000014, 5.299999999999969, 20.000000000000014, 13.699999999999964, 10.099999999999973, 31.400000000000226, 17.599999999999984, -15.10000000000003], "policy_predator_policy_reward": [17.0, 11.0, 36.0, 37.0, 69.0, 48.0, 15.0, 22.0, 10.0, 12.0, 24.0, 35.0, 19.0, 20.0, 32.0, 17.0, 29.0, 30.0, 24.0, 23.0, 10.0, 17.0, 31.0, 17.0, 12.0, 13.0, 4.0, 5.0, 13.0, 15.0, 26.0, 13.0, 5.0, 1.0, 10.0, 9.0, 13.0, 0.0, 13.0, 15.0, 7.0, 9.0, 15.0, 15.0, 28.0, 53.0, 22.0, 23.0, 0.0, 0.0, 3.0, 36.0, 23.0, 3.0, 23.0, 10.0, 5.0, 1.0, 34.0, 33.0, 5.0, 9.0, 7.0, 12.0, 8.0, 14.0, 22.0, 42.0, 9.0, 11.0, 50.0, 61.0, 15.0, 12.0, 37.0, 41.0, 6.0, 14.0, 33.0, 10.0, 1.0, 12.0, 36.0, 30.0, 29.0, 1.0, 12.0, 15.0, 6.0, 0.0, 18.0, 29.0, 0.0, 3.0, 5.0, 1.0, 1.0, 8.0, 26.0, 45.0, 17.0, 25.0, 17.0, 21.0, 1.0, 3.0, 31.0, 22.0, 23.0, 20.0, 8.0, 25.0, 19.0, 14.0, 1.0, 1.0, 25.0, 49.0, 6.0, 53.0, 27.0, 30.0, 13.0, 10.0, 14.0, 18.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 26.0, 18.0, 18.0, 0.0, 15.0, 1.0, 0.0, 10.0, 26.0, 24.0, 11.0, 29.0, 33.0, 26.0, 8.0, 3.0, 12.0, 6.0, 7.0, 7.0, 10.0, 1.0, 20.0, 23.0, 32.0, 32.0, 2.0, 0.0, 0.0, 4.0, 14.0, 4.0, 2.0, 37.0, 5.0, 6.0, 32.0, 41.0, 0.0, 10.0, 8.0, 4.0, 26.0, 27.0, 17.0, 13.0, 8.0, 0.0, 6.0, 11.0, 7.0, 14.0, 9.0, 15.0, 9.0, 24.0, 25.0, 21.0, 33.0, 26.0, 0.0, 10.0, 0.0, 3.0, 13.0, 12.0, 18.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8289115531977626, "mean_inference_ms": 2.172732616339624, "mean_action_processing_ms": 0.3472475629550017, "mean_env_wait_ms": 0.27629755502003706, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00471186637878418, "StateBufferConnector_ms": 0.012544751167297363, "ViewRequirementAgentConnector_ms": 0.13209068775177002}, "num_episodes": 18, "episode_return_max": 66.50000000000043, "episode_return_min": -57.000000000001066, "episode_return_mean": 26.365000000000215, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.7983208620596, "num_env_steps_trained_throughput_per_sec": 346.7983208620596, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 12399.297, "restore_workers_time_ms": 0.022, "training_step_time_ms": 12399.218, "sample_time_ms": 1885.47, "learn_time_ms": 10480.423, "learn_throughput": 381.664, "synch_weights_time_ms": 30.549}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-03-39", "timestamp": 1723647819, "time_this_iter_s": 11.62566089630127, "time_total_s": 986.8731729984283, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a331f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 986.8731729984283, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 44.66470588235294, "ram_util_percent": 82.66470588235295}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7083603134546332, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2277246081482165, "policy_loss": -0.00834964440997552, "vf_loss": 1.2354883448314415, "vf_explained_var": -0.15142383742584753, "kl": 0.008229999552876177, "entropy": 1.3943163048022638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9354864477480531, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2039284912051347, "policy_loss": -0.005238084124756001, "vf_loss": 1.2085764411422941, "vf_explained_var": 0.0256637952630482, "kl": 0.007868468191967869, "entropy": 0.48343179017778426, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 68.20000000000019, "episode_reward_min": -57.000000000001066, "episode_reward_mean": 26.533000000000197, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -91.30000000000084, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 49.70000000000024, "predator_policy": 61.0}, "policy_reward_mean": {"prey_policy": -2.4084999999999797, "predator_policy": 15.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.499999999999984, 40.0000000000003, -19.699999999999513, -5.39999999999967, 14.4999999999999, 40.60000000000031, 29.300000000000146, 33.00000000000021, 25.400000000000084, 31.100000000000218, 35.900000000000325, 56.40000000000049, -16.399999999999594, 36.10000000000024, 48.10000000000043, 37.800000000000175, -2.799999999999748, 41.00000000000031, 7.299999999999918, 7.000000000000121, 43.000000000000384, 33.400000000000205, 19.19999999999997, 36.70000000000025, 44.20000000000035, 43.00000000000035, -57.000000000001066, 30.1000000000001, 46.20000000000045, 35.600000000000236, 39.30000000000033, 25.400000000000084, 33.70000000000028, 16.299999999999933, 48.60000000000044, 1.7161272403143357e-13, -25.199999999999548, 27.700000000000124, 19.199999999999957, 28.800000000000125, 40.0000000000003, 43.400000000000354, 56.300000000000495, 2.100000000000201, 20.19999999999997, 33.50000000000019, 8.000000000000146, 9.900000000000205, 33.80000000000018, 26.40000000000009, 34.200000000000216, 20.2, 44.40000000000037, 28.200000000000117, 30.80000000000016, 47.900000000000446, 42.30000000000033, 36.50000000000025, 32.80000000000011, -9.199999999999635, 43.800000000000345, 5.900000000000096, 30.80000000000016, 26.800000000000086, 31.800000000000182, 25.60000000000008, 31.200000000000166, 31.200000000000163, 25.900000000000077, 39.40000000000029, 29.20000000000031, 4.100000000000181, 33.0000000000002, 35.30000000000023, 36.70000000000025, 66.50000000000043, 43.50000000000035, 37.50000000000026, 25.700000000000095, 18.50000000000001, 44.10000000000036, 53.50000000000041, 37.90000000000028, -13.2999999999996, 25.700000000000074, 26.60000000000011, 30.900000000000176, 22.200000000000006, 31.40000000000018, 32.40000000000017, 26.600000000000108, 18.400000000000027, -38.39999999999989, 35.600000000000236, 29.600000000000136, 35.40000000000023, 27.70000000000011, 1.800000000000215, 16.999999999999986, 68.20000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-6.999999999999909, -29.49999999999975, 20.000000000000014, 20.000000000000014, -24.099999999999795, -34.59999999999975, -28.29999999999975, -3.099999999999958, -2.200000000000043, -16.29999999999975, 21.500000000000036, 13.099999999999968, -57.70000000000045, 20.000000000000014, 1.0999999999999617, 17.899999999999984, 15.799999999999963, -9.40000000000003, 16.399999999999956, -7.300000000000061, -28.29999999999982, 0.20000000000000198, 27.20000000000013, 9.199999999999973, -74.50000000000087, -52.89999999999993, 20.600000000000037, -11.499999999999819, -21.999999999999744, -7.899999999999956, 25.100000000000016, -7.299999999999926, -44.79999999999977, -0.9999999999999846, 13.699999999999969, 14.299999999999972, 8.299999999999965, -67.0000000000008, 17.899999999999988, -40.89999999999976, 4.39999999999999, 11.599999999999964, 20.000000000000014, 7.399999999999965, -47.79999999999977, 20.000000000000014, 13.699999999999966, 20.000000000000014, 20.000000000000014, 18.199999999999996, 10.399999999999968, 23.60000000000007, -80.80000000000084, -47.199999999999775, 16.400000000000002, -28.299999999999784, -11.799999999999846, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, -33.699999999999875, -19.89999999999977, 2.2999999999999607, 20.000000000000014, -19.29999999999979, -9.399999999999915, -7.299999999999891, 17.899999999999988, 28.70000000000016, -29.79999999999977, -44.19999999999979, -91.30000000000084, 7.099999999999963, -2.1999999999999713, -27.099999999999774, 13.699999999999964, -17.49999999999975, -21.09999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, 17.59999999999998, 15.799999999999963, 7.399999999999965, 29.90000000000024, -49.299999999999905, 7.399999999999965, 20.000000000000014, -17.79999999999975, 19.700000000000003, -2.2000000000000552, -0.9999999999999846, -0.9999999999999846, -34.59999999999975, -5.499999999999881, -9.399999999999968, 3.1999999999999615, -52.60000000000012, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 20.000000000000014, 10.399999999999968, 18.19999999999999, -0.9999999999999846, 13.699999999999964, -25.899999999999757, -40.89999999999977, 24.800000000000093, 20.300000000000022, 20.000000000000014, 12.499999999999964, 20.000000000000014, 19.999999999999996, -5.1999999999999265, -7.299999999999894, -40.89999999999977, 7.399999999999965, 25.400000000000112, -65.2000000000009, -1.9, 21.800000000000047, -0.9999999999999846, 11.599999999999964, 3.1999999999999615, 8.899999999999967, -30.09999999999979, -11.799999999999836, 7.399999999999965, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 6.7999999999999705, -15.099999999999763, 20.000000000000014, -8.199999999999887, 23.60000000000007, -24.699999999999974, 20.900000000000027, 5.299999999999965, -47.19999999999976, -43.899999999999764, 17.899999999999984, 20.000000000000014, 5.299999999999969, 20.000000000000014, 13.699999999999964, 10.099999999999973, 31.400000000000226, 17.599999999999984, -15.10000000000003, 17.899999999999988, 11.599999999999964, 2.299999999999982, -55.599999999999966, 3.1999999999999615, 5.299999999999965, 24.200000000000077, 17.899999999999988, 21.80000000000004, -10.299999999999923, 5.299999999999974, 11.599999999999964, -61.300000000000644, -42.99999999999976, 17.89999999999998, -5.1999999999999265, 9.199999999999976, -34.59999999999979, 9.499999999999964, 7.399999999999977, 13.699999999999964, -8.499999999999908, 20.000000000000014, -28.599999999999753, -16.299999999999812, 13.699999999999964, -33.699999999999775, 5.299999999999965, -26.199999999999747, 14.599999999999955, -54.400000000000205, -85.00000000000082, 13.699999999999964, 17.899999999999988, 13.699999999999964, -3.099999999999958, 20.000000000000014, -34.59999999999975, -3.6999999999999584, 10.399999999999968, -9.999999999999853, -26.199999999999747, 7.399999999999965, -3.399999999999958, 49.70000000000024, 9.499999999999964], "policy_predator_policy_reward": [22.0, 23.0, 0.0, 0.0, 3.0, 36.0, 23.0, 3.0, 23.0, 10.0, 5.0, 1.0, 34.0, 33.0, 5.0, 9.0, 7.0, 12.0, 8.0, 14.0, 22.0, 42.0, 9.0, 11.0, 50.0, 61.0, 15.0, 12.0, 37.0, 41.0, 6.0, 14.0, 33.0, 10.0, 1.0, 12.0, 36.0, 30.0, 29.0, 1.0, 12.0, 15.0, 6.0, 0.0, 18.0, 29.0, 0.0, 3.0, 5.0, 1.0, 1.0, 8.0, 26.0, 45.0, 17.0, 25.0, 17.0, 21.0, 1.0, 3.0, 31.0, 22.0, 23.0, 20.0, 8.0, 25.0, 19.0, 14.0, 1.0, 1.0, 25.0, 49.0, 6.0, 53.0, 27.0, 30.0, 13.0, 10.0, 14.0, 18.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 26.0, 18.0, 18.0, 0.0, 15.0, 1.0, 0.0, 10.0, 26.0, 24.0, 11.0, 29.0, 33.0, 26.0, 8.0, 3.0, 12.0, 6.0, 7.0, 7.0, 10.0, 1.0, 20.0, 23.0, 32.0, 32.0, 2.0, 0.0, 0.0, 4.0, 14.0, 4.0, 2.0, 37.0, 5.0, 6.0, 32.0, 41.0, 0.0, 10.0, 8.0, 4.0, 26.0, 27.0, 17.0, 13.0, 8.0, 0.0, 6.0, 11.0, 7.0, 14.0, 9.0, 15.0, 9.0, 24.0, 25.0, 21.0, 33.0, 26.0, 0.0, 10.0, 0.0, 3.0, 13.0, 12.0, 18.0, 23.0, 4.0, 4.0, 37.0, 42.0, 2.0, 8.0, 1.0, 1.0, 30.0, 12.0, 13.0, 8.0, 45.0, 46.0, 13.0, 0.0, 22.0, 30.0, 4.0, 10.0, 3.0, 14.0, 17.0, 23.0, 19.0, 16.0, 28.0, 27.0, 22.0, 8.0, 49.0, 52.0, 0.0, 4.0, 11.0, 8.0, 24.0, 26.0, 13.0, 8.0, 22.0, 16.0, 13.0, 0.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8299634772826096, "mean_inference_ms": 2.176179178506096, "mean_action_processing_ms": 0.34760077968147773, "mean_env_wait_ms": 0.2766016793120557, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004579901695251465, "StateBufferConnector_ms": 0.012516021728515625, "ViewRequirementAgentConnector_ms": 0.14715516567230225}, "num_episodes": 23, "episode_return_max": 68.20000000000019, "episode_return_min": -57.000000000001066, "episode_return_mean": 26.533000000000197, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.84530986476557, "num_env_steps_trained_throughput_per_sec": 340.84530986476557, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 12295.809, "restore_workers_time_ms": 0.025, "training_step_time_ms": 12295.726, "sample_time_ms": 1853.625, "learn_time_ms": 10409.182, "learn_throughput": 384.276, "synch_weights_time_ms": 29.815}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-03-51", "timestamp": 1723647831, "time_this_iter_s": 11.787348985671997, "time_total_s": 998.6605219841003, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b1e430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 998.6605219841003, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 44.088235294117645, "ram_util_percent": 82.59411764705882}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2547913771457773, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0077278586370604, "policy_loss": -0.011667886584942973, "vf_loss": 1.0183836300379385, "vf_explained_var": -0.1583044751611336, "kl": 0.01421684668219083, "entropy": 1.407373032241902, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7023103541955746, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0342405413193678, "policy_loss": -0.00414215802626497, "vf_loss": 1.0380093155241517, "vf_explained_var": 0.030969554280477856, "kl": 0.004978417688311478, "entropy": 0.4991171277704693, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 68.20000000000019, "episode_reward_min": -57.000000000001066, "episode_reward_mean": 27.334000000000184, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -91.30000000000084, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 49.70000000000024, "predator_policy": 53.0}, "policy_reward_mean": {"prey_policy": -1.1079999999999808, "predator_policy": 14.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.299999999999918, 7.000000000000121, 43.000000000000384, 33.400000000000205, 19.19999999999997, 36.70000000000025, 44.20000000000035, 43.00000000000035, -57.000000000001066, 30.1000000000001, 46.20000000000045, 35.600000000000236, 39.30000000000033, 25.400000000000084, 33.70000000000028, 16.299999999999933, 48.60000000000044, 1.7161272403143357e-13, -25.199999999999548, 27.700000000000124, 19.199999999999957, 28.800000000000125, 40.0000000000003, 43.400000000000354, 56.300000000000495, 2.100000000000201, 20.19999999999997, 33.50000000000019, 8.000000000000146, 9.900000000000205, 33.80000000000018, 26.40000000000009, 34.200000000000216, 20.2, 44.40000000000037, 28.200000000000117, 30.80000000000016, 47.900000000000446, 42.30000000000033, 36.50000000000025, 32.80000000000011, -9.199999999999635, 43.800000000000345, 5.900000000000096, 30.80000000000016, 26.800000000000086, 31.800000000000182, 25.60000000000008, 31.200000000000166, 31.200000000000163, 25.900000000000077, 39.40000000000029, 29.20000000000031, 4.100000000000181, 33.0000000000002, 35.30000000000023, 36.70000000000025, 66.50000000000043, 43.50000000000035, 37.50000000000026, 25.700000000000095, 18.50000000000001, 44.10000000000036, 53.50000000000041, 37.90000000000028, -13.2999999999996, 25.700000000000074, 26.60000000000011, 30.900000000000176, 22.200000000000006, 31.40000000000018, 32.40000000000017, 26.600000000000108, 18.400000000000027, -38.39999999999989, 35.600000000000236, 29.600000000000136, 35.40000000000023, 27.70000000000011, 1.800000000000215, 16.999999999999986, 68.20000000000019, 13.600000000000026, 32.60000000000019, 41.30000000000032, 38.800000000000274, 18.899999999999967, 18.300000000000047, 39.100000000000286, 30.500000000000163, 35.500000000000234, 22.900000000000077, 33.300000000000196, 25.00000000000006, 31.70000000000018, 11.400000000000077, 10.000000000000068, 33.60000000000021, 45.8000000000004, 31.200000000000163], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [8.299999999999965, -67.0000000000008, 17.899999999999988, -40.89999999999976, 4.39999999999999, 11.599999999999964, 20.000000000000014, 7.399999999999965, -47.79999999999977, 20.000000000000014, 13.699999999999966, 20.000000000000014, 20.000000000000014, 18.199999999999996, 10.399999999999968, 23.60000000000007, -80.80000000000084, -47.199999999999775, 16.400000000000002, -28.299999999999784, -11.799999999999846, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, -33.699999999999875, -19.89999999999977, 2.2999999999999607, 20.000000000000014, -19.29999999999979, -9.399999999999915, -7.299999999999891, 17.899999999999988, 28.70000000000016, -29.79999999999977, -44.19999999999979, -91.30000000000084, 7.099999999999963, -2.1999999999999713, -27.099999999999774, 13.699999999999964, -17.49999999999975, -21.09999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, 17.59999999999998, 15.799999999999963, 7.399999999999965, 29.90000000000024, -49.299999999999905, 7.399999999999965, 20.000000000000014, -17.79999999999975, 19.700000000000003, -2.2000000000000552, -0.9999999999999846, -0.9999999999999846, -34.59999999999975, -5.499999999999881, -9.399999999999968, 3.1999999999999615, -52.60000000000012, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 20.000000000000014, 10.399999999999968, 18.19999999999999, -0.9999999999999846, 13.699999999999964, -25.899999999999757, -40.89999999999977, 24.800000000000093, 20.300000000000022, 20.000000000000014, 12.499999999999964, 20.000000000000014, 19.999999999999996, -5.1999999999999265, -7.299999999999894, -40.89999999999977, 7.399999999999965, 25.400000000000112, -65.2000000000009, -1.9, 21.800000000000047, -0.9999999999999846, 11.599999999999964, 3.1999999999999615, 8.899999999999967, -30.09999999999979, -11.799999999999836, 7.399999999999965, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 6.7999999999999705, -15.099999999999763, 20.000000000000014, -8.199999999999887, 23.60000000000007, -24.699999999999974, 20.900000000000027, 5.299999999999965, -47.19999999999976, -43.899999999999764, 17.899999999999984, 20.000000000000014, 5.299999999999969, 20.000000000000014, 13.699999999999964, 10.099999999999973, 31.400000000000226, 17.599999999999984, -15.10000000000003, 17.899999999999988, 11.599999999999964, 2.299999999999982, -55.599999999999966, 3.1999999999999615, 5.299999999999965, 24.200000000000077, 17.899999999999988, 21.80000000000004, -10.299999999999923, 5.299999999999974, 11.599999999999964, -61.300000000000644, -42.99999999999976, 17.89999999999998, -5.1999999999999265, 9.199999999999976, -34.59999999999979, 9.499999999999964, 7.399999999999977, 13.699999999999964, -8.499999999999908, 20.000000000000014, -28.599999999999753, -16.299999999999812, 13.699999999999964, -33.699999999999775, 5.299999999999965, -26.199999999999747, 14.599999999999955, -54.400000000000205, -85.00000000000082, 13.699999999999964, 17.899999999999988, 13.699999999999964, -3.099999999999958, 20.000000000000014, -34.59999999999975, -3.6999999999999584, 10.399999999999968, -9.999999999999853, -26.199999999999747, 7.399999999999965, -3.399999999999958, 49.70000000000024, 9.499999999999964, 7.399999999999965, -17.79999999999974, 20.000000000000014, -27.39999999999975, 9.499999999999964, 18.8, 25.4000000000001, 7.399999999999965, 11.599999999999964, -12.6999999999999, 1.9999999999999802, -6.699999999999907, 20.000000000000014, 7.0999999999999694, 11.599999999999964, 2.899999999999965, 9.499999999999964, 20.000000000000014, -87.70000000000053, 11.599999999999964, -33.69999999999977, 20.000000000000014, 19.700000000000014, -15.699999999999754, 4.099999999999966, -0.40000000000002767, -17.79999999999974, 3.1999999999999615, -6.399999999999922, -25.599999999999753, 20.000000000000014, -0.4000000000000099, 20.000000000000014, 3.7999999999999727, 13.699999999999964, 9.499999999999964], "policy_predator_policy_reward": [36.0, 30.0, 29.0, 1.0, 12.0, 15.0, 6.0, 0.0, 18.0, 29.0, 0.0, 3.0, 5.0, 1.0, 1.0, 8.0, 26.0, 45.0, 17.0, 25.0, 17.0, 21.0, 1.0, 3.0, 31.0, 22.0, 23.0, 20.0, 8.0, 25.0, 19.0, 14.0, 1.0, 1.0, 25.0, 49.0, 6.0, 53.0, 27.0, 30.0, 13.0, 10.0, 14.0, 18.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 26.0, 18.0, 18.0, 0.0, 15.0, 1.0, 0.0, 10.0, 26.0, 24.0, 11.0, 29.0, 33.0, 26.0, 8.0, 3.0, 12.0, 6.0, 7.0, 7.0, 10.0, 1.0, 20.0, 23.0, 32.0, 32.0, 2.0, 0.0, 0.0, 4.0, 14.0, 4.0, 2.0, 37.0, 5.0, 6.0, 32.0, 41.0, 0.0, 10.0, 8.0, 4.0, 26.0, 27.0, 17.0, 13.0, 8.0, 0.0, 6.0, 11.0, 7.0, 14.0, 9.0, 15.0, 9.0, 24.0, 25.0, 21.0, 33.0, 26.0, 0.0, 10.0, 0.0, 3.0, 13.0, 12.0, 18.0, 23.0, 4.0, 4.0, 37.0, 42.0, 2.0, 8.0, 1.0, 1.0, 30.0, 12.0, 13.0, 8.0, 45.0, 46.0, 13.0, 0.0, 22.0, 30.0, 4.0, 10.0, 3.0, 14.0, 17.0, 23.0, 19.0, 16.0, 28.0, 27.0, 22.0, 8.0, 49.0, 52.0, 0.0, 4.0, 11.0, 8.0, 24.0, 26.0, 13.0, 8.0, 22.0, 16.0, 13.0, 0.0, 4.0, 5.0, 6.0, 18.0, 20.0, 20.0, 7.0, 6.0, 6.0, 0.0, 12.0, 8.0, 14.0, 9.0, 2.0, 10.0, 13.0, 3.0, 5.0, 1.0, 52.0, 47.0, 28.0, 19.0, 17.0, 4.0, 23.0, 5.0, 8.0, 18.0, 22.0, 20.0, 11.0, 3.0, 15.0, 7.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8305487187169457, "mean_inference_ms": 2.1787517263954266, "mean_action_processing_ms": 0.3481730897685537, "mean_env_wait_ms": 0.27680804773802614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038814544677734375, "StateBufferConnector_ms": 0.012423396110534668, "ViewRequirementAgentConnector_ms": 0.13496196269989014}, "num_episodes": 18, "episode_return_max": 68.20000000000019, "episode_return_min": -57.000000000001066, "episode_return_mean": 27.334000000000184, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.05837221901606, "num_env_steps_trained_throughput_per_sec": 338.05837221901606, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 12217.827, "restore_workers_time_ms": 0.023, "training_step_time_ms": 12217.747, "sample_time_ms": 1851.616, "learn_time_ms": 10334.735, "learn_throughput": 387.044, "synch_weights_time_ms": 28.302}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-04-03", "timestamp": 1723647843, "time_this_iter_s": 11.880220174789429, "time_total_s": 1010.5407421588898, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b1eee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1010.5407421588898, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 44.241176470588236, "ram_util_percent": 82.24117647058824}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4447447689437363, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.006666165542981, "policy_loss": -0.006003472967339414, "vf_loss": 1.0120777067053255, "vf_explained_var": -0.14807837236495244, "kl": 0.008314661572623842, "entropy": 1.4257351506954778, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3853897215039641, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.879934507324582, "policy_loss": -0.005325191397042501, "vf_loss": 0.8850689598807582, "vf_explained_var": 0.03902829207440533, "kl": 0.005086369778665427, "entropy": 0.491061791414937, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 75.0999999999997, "episode_reward_min": -38.39999999999989, "episode_reward_mean": 28.86600000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -143.80000000000044, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 58.700000000000195, "predator_policy": 75.0}, "policy_reward_mean": {"prey_policy": 0.11300000000002733, "predator_policy": 14.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.199999999999548, 27.700000000000124, 19.199999999999957, 28.800000000000125, 40.0000000000003, 43.400000000000354, 56.300000000000495, 2.100000000000201, 20.19999999999997, 33.50000000000019, 8.000000000000146, 9.900000000000205, 33.80000000000018, 26.40000000000009, 34.200000000000216, 20.2, 44.40000000000037, 28.200000000000117, 30.80000000000016, 47.900000000000446, 42.30000000000033, 36.50000000000025, 32.80000000000011, -9.199999999999635, 43.800000000000345, 5.900000000000096, 30.80000000000016, 26.800000000000086, 31.800000000000182, 25.60000000000008, 31.200000000000166, 31.200000000000163, 25.900000000000077, 39.40000000000029, 29.20000000000031, 4.100000000000181, 33.0000000000002, 35.30000000000023, 36.70000000000025, 66.50000000000043, 43.50000000000035, 37.50000000000026, 25.700000000000095, 18.50000000000001, 44.10000000000036, 53.50000000000041, 37.90000000000028, -13.2999999999996, 25.700000000000074, 26.60000000000011, 30.900000000000176, 22.200000000000006, 31.40000000000018, 32.40000000000017, 26.600000000000108, 18.400000000000027, -38.39999999999989, 35.600000000000236, 29.600000000000136, 35.40000000000023, 27.70000000000011, 1.800000000000215, 16.999999999999986, 68.20000000000019, 13.600000000000026, 32.60000000000019, 41.30000000000032, 38.800000000000274, 18.899999999999967, 18.300000000000047, 39.100000000000286, 30.500000000000163, 35.500000000000234, 22.900000000000077, 33.300000000000196, 25.00000000000006, 31.70000000000018, 11.400000000000077, 10.000000000000068, 33.60000000000021, 45.8000000000004, 31.200000000000163, 9.200000000000106, 18.79999999999999, 37.600000000000264, 29.000000000000124, 33.90000000000035, 66.60000000000026, 16.09999999999994, 21.3000000000004, 32.700000000000195, 14.000000000000004, 35.10000000000024, 62.20000000000051, 24.200000000000042, 28.20000000000012, 45.300000000000416, 75.0999999999997, 17.000000000000004, 38.90000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-91.30000000000084, 7.099999999999963, -2.1999999999999713, -27.099999999999774, 13.699999999999964, -17.49999999999975, -21.09999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, 17.59999999999998, 15.799999999999963, 7.399999999999965, 29.90000000000024, -49.299999999999905, 7.399999999999965, 20.000000000000014, -17.79999999999975, 19.700000000000003, -2.2000000000000552, -0.9999999999999846, -0.9999999999999846, -34.59999999999975, -5.499999999999881, -9.399999999999968, 3.1999999999999615, -52.60000000000012, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 20.000000000000014, 10.399999999999968, 18.19999999999999, -0.9999999999999846, 13.699999999999964, -25.899999999999757, -40.89999999999977, 24.800000000000093, 20.300000000000022, 20.000000000000014, 12.499999999999964, 20.000000000000014, 19.999999999999996, -5.1999999999999265, -7.299999999999894, -40.89999999999977, 7.399999999999965, 25.400000000000112, -65.2000000000009, -1.9, 21.800000000000047, -0.9999999999999846, 11.599999999999964, 3.1999999999999615, 8.899999999999967, -30.09999999999979, -11.799999999999836, 7.399999999999965, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 6.7999999999999705, -15.099999999999763, 20.000000000000014, -8.199999999999887, 23.60000000000007, -24.699999999999974, 20.900000000000027, 5.299999999999965, -47.19999999999976, -43.899999999999764, 17.899999999999984, 20.000000000000014, 5.299999999999969, 20.000000000000014, 13.699999999999964, 10.099999999999973, 31.400000000000226, 17.599999999999984, -15.10000000000003, 17.899999999999988, 11.599999999999964, 2.299999999999982, -55.599999999999966, 3.1999999999999615, 5.299999999999965, 24.200000000000077, 17.899999999999988, 21.80000000000004, -10.299999999999923, 5.299999999999974, 11.599999999999964, -61.300000000000644, -42.99999999999976, 17.89999999999998, -5.1999999999999265, 9.199999999999976, -34.59999999999979, 9.499999999999964, 7.399999999999977, 13.699999999999964, -8.499999999999908, 20.000000000000014, -28.599999999999753, -16.299999999999812, 13.699999999999964, -33.699999999999775, 5.299999999999965, -26.199999999999747, 14.599999999999955, -54.400000000000205, -85.00000000000082, 13.699999999999964, 17.899999999999988, 13.699999999999964, -3.099999999999958, 20.000000000000014, -34.59999999999975, -3.6999999999999584, 10.399999999999968, -9.999999999999853, -26.199999999999747, 7.399999999999965, -3.399999999999958, 49.70000000000024, 9.499999999999964, 7.399999999999965, -17.79999999999974, 20.000000000000014, -27.39999999999975, 9.499999999999964, 18.8, 25.4000000000001, 7.399999999999965, 11.599999999999964, -12.6999999999999, 1.9999999999999802, -6.699999999999907, 20.000000000000014, 7.0999999999999694, 11.599999999999964, 2.899999999999965, 9.499999999999964, 20.000000000000014, -87.70000000000053, 11.599999999999964, -33.69999999999977, 20.000000000000014, 19.700000000000014, -15.699999999999754, 4.099999999999966, -0.40000000000002767, -17.79999999999974, 3.1999999999999615, -6.399999999999922, -25.599999999999753, 20.000000000000014, -0.4000000000000099, 20.000000000000014, 3.7999999999999727, 13.699999999999964, 9.499999999999964, -3.099999999999958, -15.699999999999768, -14.49999999999978, 5.299999999999965, 11.599999999999964, 20.000000000000014, 11.599999999999964, 7.399999999999965, -143.80000000000044, 58.700000000000195, 41.300000000000246, -21.69999999999979, 3.19999999999999, -3.099999999999958, 38.900000000000254, -55.59999999999984, -16.29999999999975, 20.000000000000014, 6.1999999999999655, -26.199999999999747, -10.899999999999942, 20.000000000000014, 29.90000000000018, 14.29999999999996, 11.599999999999964, -3.399999999999958, -12.699999999999829, 17.899999999999988, 7.399999999999965, 23.900000000000073, 47.90000000000024, 3.1999999999999846, 5.299999999999965, -7.299999999999891, 20.000000000000014, 17.899999999999988], "policy_predator_policy_reward": [6.0, 53.0, 27.0, 30.0, 13.0, 10.0, 14.0, 18.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 26.0, 18.0, 18.0, 0.0, 15.0, 1.0, 0.0, 10.0, 26.0, 24.0, 11.0, 29.0, 33.0, 26.0, 8.0, 3.0, 12.0, 6.0, 7.0, 7.0, 10.0, 1.0, 20.0, 23.0, 32.0, 32.0, 2.0, 0.0, 0.0, 4.0, 14.0, 4.0, 2.0, 37.0, 5.0, 6.0, 32.0, 41.0, 0.0, 10.0, 8.0, 4.0, 26.0, 27.0, 17.0, 13.0, 8.0, 0.0, 6.0, 11.0, 7.0, 14.0, 9.0, 15.0, 9.0, 24.0, 25.0, 21.0, 33.0, 26.0, 0.0, 10.0, 0.0, 3.0, 13.0, 12.0, 18.0, 23.0, 4.0, 4.0, 37.0, 42.0, 2.0, 8.0, 1.0, 1.0, 30.0, 12.0, 13.0, 8.0, 45.0, 46.0, 13.0, 0.0, 22.0, 30.0, 4.0, 10.0, 3.0, 14.0, 17.0, 23.0, 19.0, 16.0, 28.0, 27.0, 22.0, 8.0, 49.0, 52.0, 0.0, 4.0, 11.0, 8.0, 24.0, 26.0, 13.0, 8.0, 22.0, 16.0, 13.0, 0.0, 4.0, 5.0, 6.0, 18.0, 20.0, 20.0, 7.0, 6.0, 6.0, 0.0, 12.0, 8.0, 14.0, 9.0, 2.0, 10.0, 13.0, 3.0, 5.0, 1.0, 52.0, 47.0, 28.0, 19.0, 17.0, 4.0, 23.0, 5.0, 8.0, 18.0, 22.0, 20.0, 11.0, 3.0, 15.0, 7.0, 5.0, 3.0, 21.0, 7.0, 18.0, 10.0, 4.0, 2.0, 6.0, 4.0, 44.0, 75.0, 21.0, 26.0, 5.0, 11.0, 2.0, 36.0, 19.0, 10.0, 10.0, 24.0, 16.0, 10.0, 9.0, 9.0, 4.0, 12.0, 22.0, 1.0, 6.0, 8.0, 10.0, 14.0, 13.0, 6.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8315575454608088, "mean_inference_ms": 2.1817340410444626, "mean_action_processing_ms": 0.3486721266634946, "mean_env_wait_ms": 0.27713911285725, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003870844841003418, "StateBufferConnector_ms": 0.0075789690017700195, "ViewRequirementAgentConnector_ms": 0.13299143314361572}, "num_episodes": 18, "episode_return_max": 75.0999999999997, "episode_return_min": -38.39999999999989, "episode_return_mean": 28.86600000000019, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 335.17422062558524, "num_env_steps_trained_throughput_per_sec": 335.17422062558524, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 12107.713, "restore_workers_time_ms": 0.023, "training_step_time_ms": 12107.65, "sample_time_ms": 1827.455, "learn_time_ms": 10251.357, "learn_throughput": 390.192, "synch_weights_time_ms": 26.143}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-04-15", "timestamp": 1723647855, "time_this_iter_s": 11.997084856033325, "time_total_s": 1022.5378270149231, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b944c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1022.5378270149231, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 47.305882352941175, "ram_util_percent": 82.4470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8715858696787446, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8348934543599922, "policy_loss": -0.006960103027128353, "vf_loss": 0.8406753420593247, "vf_explained_var": -0.054223741488481955, "kl": 0.016549940551558586, "entropy": 1.4146826000440689, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.290472814693022, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7788429027275433, "policy_loss": -0.00398953817144194, "vf_loss": 0.7826524006705435, "vf_explained_var": 0.0718955239606282, "kl": 0.004801149083536912, "entropy": 0.4786566729425753, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 75.0999999999997, "episode_reward_min": -57.50000000000035, "episode_reward_mean": 28.455000000000176, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -143.80000000000044, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 58.700000000000195, "predator_policy": 75.0}, "policy_reward_mean": {"prey_policy": 0.44750000000002116, "predator_policy": 13.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.80000000000011, -9.199999999999635, 43.800000000000345, 5.900000000000096, 30.80000000000016, 26.800000000000086, 31.800000000000182, 25.60000000000008, 31.200000000000166, 31.200000000000163, 25.900000000000077, 39.40000000000029, 29.20000000000031, 4.100000000000181, 33.0000000000002, 35.30000000000023, 36.70000000000025, 66.50000000000043, 43.50000000000035, 37.50000000000026, 25.700000000000095, 18.50000000000001, 44.10000000000036, 53.50000000000041, 37.90000000000028, -13.2999999999996, 25.700000000000074, 26.60000000000011, 30.900000000000176, 22.200000000000006, 31.40000000000018, 32.40000000000017, 26.600000000000108, 18.400000000000027, -38.39999999999989, 35.600000000000236, 29.600000000000136, 35.40000000000023, 27.70000000000011, 1.800000000000215, 16.999999999999986, 68.20000000000019, 13.600000000000026, 32.60000000000019, 41.30000000000032, 38.800000000000274, 18.899999999999967, 18.300000000000047, 39.100000000000286, 30.500000000000163, 35.500000000000234, 22.900000000000077, 33.300000000000196, 25.00000000000006, 31.70000000000018, 11.400000000000077, 10.000000000000068, 33.60000000000021, 45.8000000000004, 31.200000000000163, 9.200000000000106, 18.79999999999999, 37.600000000000264, 29.000000000000124, 33.90000000000035, 66.60000000000026, 16.09999999999994, 21.3000000000004, 32.700000000000195, 14.000000000000004, 35.10000000000024, 62.20000000000051, 24.200000000000042, 28.20000000000012, 45.300000000000416, 75.0999999999997, 17.000000000000004, 38.90000000000028, 56.200000000000514, 31.90000000000018, 2.9000000000001873, 38.80000000000028, 44.00000000000036, 37.80000000000027, -19.199999999999534, 27.6000000000001, 43.300000000000345, 42.20000000000034, 34.50000000000022, 24.600000000000065, 39.70000000000031, 32.30000000000018, 37.80000000000027, 37.80000000000027, 31.400000000000166, 27.2000000000001, 11.600000000000048, -57.50000000000035, 16.79999999999994, 25.80000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [19.999999999999996, -5.1999999999999265, -7.299999999999894, -40.89999999999977, 7.399999999999965, 25.400000000000112, -65.2000000000009, -1.9, 21.800000000000047, -0.9999999999999846, 11.599999999999964, 3.1999999999999615, 8.899999999999967, -30.09999999999979, -11.799999999999836, 7.399999999999965, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 6.7999999999999705, -15.099999999999763, 20.000000000000014, -8.199999999999887, 23.60000000000007, -24.699999999999974, 20.900000000000027, 5.299999999999965, -47.19999999999976, -43.899999999999764, 17.899999999999984, 20.000000000000014, 5.299999999999969, 20.000000000000014, 13.699999999999964, 10.099999999999973, 31.400000000000226, 17.599999999999984, -15.10000000000003, 17.899999999999988, 11.599999999999964, 2.299999999999982, -55.599999999999966, 3.1999999999999615, 5.299999999999965, 24.200000000000077, 17.899999999999988, 21.80000000000004, -10.299999999999923, 5.299999999999974, 11.599999999999964, -61.300000000000644, -42.99999999999976, 17.89999999999998, -5.1999999999999265, 9.199999999999976, -34.59999999999979, 9.499999999999964, 7.399999999999977, 13.699999999999964, -8.499999999999908, 20.000000000000014, -28.599999999999753, -16.299999999999812, 13.699999999999964, -33.699999999999775, 5.299999999999965, -26.199999999999747, 14.599999999999955, -54.400000000000205, -85.00000000000082, 13.699999999999964, 17.899999999999988, 13.699999999999964, -3.099999999999958, 20.000000000000014, -34.59999999999975, -3.6999999999999584, 10.399999999999968, -9.999999999999853, -26.199999999999747, 7.399999999999965, -3.399999999999958, 49.70000000000024, 9.499999999999964, 7.399999999999965, -17.79999999999974, 20.000000000000014, -27.39999999999975, 9.499999999999964, 18.8, 25.4000000000001, 7.399999999999965, 11.599999999999964, -12.6999999999999, 1.9999999999999802, -6.699999999999907, 20.000000000000014, 7.0999999999999694, 11.599999999999964, 2.899999999999965, 9.499999999999964, 20.000000000000014, -87.70000000000053, 11.599999999999964, -33.69999999999977, 20.000000000000014, 19.700000000000014, -15.699999999999754, 4.099999999999966, -0.40000000000002767, -17.79999999999974, 3.1999999999999615, -6.399999999999922, -25.599999999999753, 20.000000000000014, -0.4000000000000099, 20.000000000000014, 3.7999999999999727, 13.699999999999964, 9.499999999999964, -3.099999999999958, -15.699999999999768, -14.49999999999978, 5.299999999999965, 11.599999999999964, 20.000000000000014, 11.599999999999964, 7.399999999999965, -143.80000000000044, 58.700000000000195, 41.300000000000246, -21.69999999999979, 3.19999999999999, -3.099999999999958, 38.900000000000254, -55.59999999999984, -16.29999999999975, 20.000000000000014, 6.1999999999999655, -26.199999999999747, -10.899999999999942, 20.000000000000014, 29.90000000000018, 14.29999999999996, 11.599999999999964, -3.399999999999958, -12.699999999999829, 17.899999999999988, 7.399999999999965, 23.900000000000073, 47.90000000000024, 3.1999999999999846, 5.299999999999965, -7.299999999999891, 20.000000000000014, 17.899999999999988, 38.000000000000256, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 7.399999999999965, -41.499999999999766, 15.799999999999963, 20.000000000000014, 17.599999999999984, 19.40000000000001, 15.799999999999963, 20.000000000000014, -100.0000000000008, -5.1999999999999265, 9.499999999999964, 1.0999999999999865, 13.699999999999964, 23.600000000000065, 20.000000000000014, 3.1999999999999686, 20.000000000000014, 9.499999999999964, 7.399999999999965, 3.199999999999974, 23.60000000000008, 1.099999999999983, 15.799999999999963, 9.499999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999964, 15.799999999999963, -22.599999999999753, 15.799999999999963, -11.799999999999818, -19.599999999999753, -127.00000000000074, -11.499999999999819, -48.99999999999983, 15.799999999999963, -21.999999999999744, 15.799999999999963], "policy_predator_policy_reward": [14.0, 4.0, 2.0, 37.0, 5.0, 6.0, 32.0, 41.0, 0.0, 10.0, 8.0, 4.0, 26.0, 27.0, 17.0, 13.0, 8.0, 0.0, 6.0, 11.0, 7.0, 14.0, 9.0, 15.0, 9.0, 24.0, 25.0, 21.0, 33.0, 26.0, 0.0, 10.0, 0.0, 3.0, 13.0, 12.0, 18.0, 23.0, 4.0, 4.0, 37.0, 42.0, 2.0, 8.0, 1.0, 1.0, 30.0, 12.0, 13.0, 8.0, 45.0, 46.0, 13.0, 0.0, 22.0, 30.0, 4.0, 10.0, 3.0, 14.0, 17.0, 23.0, 19.0, 16.0, 28.0, 27.0, 22.0, 8.0, 49.0, 52.0, 0.0, 4.0, 11.0, 8.0, 24.0, 26.0, 13.0, 8.0, 22.0, 16.0, 13.0, 0.0, 4.0, 5.0, 6.0, 18.0, 20.0, 20.0, 7.0, 6.0, 6.0, 0.0, 12.0, 8.0, 14.0, 9.0, 2.0, 10.0, 13.0, 3.0, 5.0, 1.0, 52.0, 47.0, 28.0, 19.0, 17.0, 4.0, 23.0, 5.0, 8.0, 18.0, 22.0, 20.0, 11.0, 3.0, 15.0, 7.0, 5.0, 3.0, 21.0, 7.0, 18.0, 10.0, 4.0, 2.0, 6.0, 4.0, 44.0, 75.0, 21.0, 26.0, 5.0, 11.0, 2.0, 36.0, 19.0, 10.0, 10.0, 24.0, 16.0, 10.0, 9.0, 9.0, 4.0, 12.0, 22.0, 1.0, 6.0, 8.0, 10.0, 14.0, 13.0, 6.0, 0.0, 1.0, 7.0, 8.0, 4.0, 11.0, 28.0, 9.0, 1.0, 2.0, 2.0, 5.0, 2.0, 0.0, 57.0, 29.0, 9.0, 8.0, 3.0, 3.0, 8.0, 11.0, 5.0, 0.0, 13.0, 1.0, 6.0, 9.0, 5.0, 2.0, 2.0, 0.0, 2.0, 0.0, 4.0, 0.0, 21.0, 13.0, 22.0, 21.0, 71.0, 10.0, 35.0, 15.0, 14.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8329016677261629, "mean_inference_ms": 2.185675547974264, "mean_action_processing_ms": 0.34925613319538124, "mean_env_wait_ms": 0.277580779037653, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052214860916137695, "StateBufferConnector_ms": 0.007626175880432129, "ViewRequirementAgentConnector_ms": 0.13169336318969727}, "num_episodes": 22, "episode_return_max": 75.0999999999997, "episode_return_min": -57.50000000000035, "episode_return_mean": 28.455000000000176, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.4088386770519, "num_env_steps_trained_throughput_per_sec": 344.4088386770519, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 11951.298, "restore_workers_time_ms": 0.021, "training_step_time_ms": 11951.239, "sample_time_ms": 1838.717, "learn_time_ms": 10086.735, "learn_throughput": 396.56, "synch_weights_time_ms": 23.176}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-04-27", "timestamp": 1723647867, "time_this_iter_s": 11.64884901046753, "time_total_s": 1034.1866760253906, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b94ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1034.1866760253906, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 45.5125, "ram_util_percent": 82.7625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7456314915544773, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.510467275027087, "policy_loss": -0.0026157391470704207, "vf_loss": 1.5128778338747682, "vf_explained_var": -0.013722519710581138, "kl": 0.0028821098834924293, "entropy": 1.4361288527332285, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3678181790800952, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4625362646327447, "policy_loss": -0.0036469187070098186, "vf_loss": 1.466065752096277, "vf_explained_var": 0.06932951893125261, "kl": 0.006263130162021235, "entropy": 0.4042944264475, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 75.0999999999997, "episode_reward_min": -57.50000000000035, "episode_reward_mean": 27.846000000000178, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -143.80000000000044, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 58.700000000000195, "predator_policy": 75.0}, "policy_reward_mean": {"prey_policy": 0.8330000000000184, "predator_policy": 13.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [43.50000000000035, 37.50000000000026, 25.700000000000095, 18.50000000000001, 44.10000000000036, 53.50000000000041, 37.90000000000028, -13.2999999999996, 25.700000000000074, 26.60000000000011, 30.900000000000176, 22.200000000000006, 31.40000000000018, 32.40000000000017, 26.600000000000108, 18.400000000000027, -38.39999999999989, 35.600000000000236, 29.600000000000136, 35.40000000000023, 27.70000000000011, 1.800000000000215, 16.999999999999986, 68.20000000000019, 13.600000000000026, 32.60000000000019, 41.30000000000032, 38.800000000000274, 18.899999999999967, 18.300000000000047, 39.100000000000286, 30.500000000000163, 35.500000000000234, 22.900000000000077, 33.300000000000196, 25.00000000000006, 31.70000000000018, 11.400000000000077, 10.000000000000068, 33.60000000000021, 45.8000000000004, 31.200000000000163, 9.200000000000106, 18.79999999999999, 37.600000000000264, 29.000000000000124, 33.90000000000035, 66.60000000000026, 16.09999999999994, 21.3000000000004, 32.700000000000195, 14.000000000000004, 35.10000000000024, 62.20000000000051, 24.200000000000042, 28.20000000000012, 45.300000000000416, 75.0999999999997, 17.000000000000004, 38.90000000000028, 56.200000000000514, 31.90000000000018, 2.9000000000001873, 38.80000000000028, 44.00000000000036, 37.80000000000027, -19.199999999999534, 27.6000000000001, 43.300000000000345, 42.20000000000034, 34.50000000000022, 24.600000000000065, 39.70000000000031, 32.30000000000018, 37.80000000000027, 37.80000000000027, 31.400000000000166, 27.2000000000001, 11.600000000000048, -57.50000000000035, 16.79999999999994, 25.80000000000007, 30.100000000000144, 45.20000000000038, 39.20000000000028, 46.100000000000364, 13.60000000000041, 35.30000000000023, 37.700000000000266, 36.70000000000025, 14.700000000000022, 15.799999999999997, 37.700000000000266, -32.599999999999774, 23.800000000000058, 21.399999999999995, 25.700000000000074, 34.50000000000022, 29.000000000000124, 5.999999999999945], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.599999999999984, -15.10000000000003, 17.899999999999988, 11.599999999999964, 2.299999999999982, -55.599999999999966, 3.1999999999999615, 5.299999999999965, 24.200000000000077, 17.899999999999988, 21.80000000000004, -10.299999999999923, 5.299999999999974, 11.599999999999964, -61.300000000000644, -42.99999999999976, 17.89999999999998, -5.1999999999999265, 9.199999999999976, -34.59999999999979, 9.499999999999964, 7.399999999999977, 13.699999999999964, -8.499999999999908, 20.000000000000014, -28.599999999999753, -16.299999999999812, 13.699999999999964, -33.699999999999775, 5.299999999999965, -26.199999999999747, 14.599999999999955, -54.400000000000205, -85.00000000000082, 13.699999999999964, 17.899999999999988, 13.699999999999964, -3.099999999999958, 20.000000000000014, -34.59999999999975, -3.6999999999999584, 10.399999999999968, -9.999999999999853, -26.199999999999747, 7.399999999999965, -3.399999999999958, 49.70000000000024, 9.499999999999964, 7.399999999999965, -17.79999999999974, 20.000000000000014, -27.39999999999975, 9.499999999999964, 18.8, 25.4000000000001, 7.399999999999965, 11.599999999999964, -12.6999999999999, 1.9999999999999802, -6.699999999999907, 20.000000000000014, 7.0999999999999694, 11.599999999999964, 2.899999999999965, 9.499999999999964, 20.000000000000014, -87.70000000000053, 11.599999999999964, -33.69999999999977, 20.000000000000014, 19.700000000000014, -15.699999999999754, 4.099999999999966, -0.40000000000002767, -17.79999999999974, 3.1999999999999615, -6.399999999999922, -25.599999999999753, 20.000000000000014, -0.4000000000000099, 20.000000000000014, 3.7999999999999727, 13.699999999999964, 9.499999999999964, -3.099999999999958, -15.699999999999768, -14.49999999999978, 5.299999999999965, 11.599999999999964, 20.000000000000014, 11.599999999999964, 7.399999999999965, -143.80000000000044, 58.700000000000195, 41.300000000000246, -21.69999999999979, 3.19999999999999, -3.099999999999958, 38.900000000000254, -55.59999999999984, -16.29999999999975, 20.000000000000014, 6.1999999999999655, -26.199999999999747, -10.899999999999942, 20.000000000000014, 29.90000000000018, 14.29999999999996, 11.599999999999964, -3.399999999999958, -12.699999999999829, 17.899999999999988, 7.399999999999965, 23.900000000000073, 47.90000000000024, 3.1999999999999846, 5.299999999999965, -7.299999999999891, 20.000000000000014, 17.899999999999988, 38.000000000000256, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 7.399999999999965, -41.499999999999766, 15.799999999999963, 20.000000000000014, 17.599999999999984, 19.40000000000001, 15.799999999999963, 20.000000000000014, -100.0000000000008, -5.1999999999999265, 9.499999999999964, 1.0999999999999865, 13.699999999999964, 23.600000000000065, 20.000000000000014, 3.1999999999999686, 20.000000000000014, 9.499999999999964, 7.399999999999965, 3.199999999999974, 23.60000000000008, 1.099999999999983, 15.799999999999963, 9.499999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999964, 15.799999999999963, -22.599999999999753, 15.799999999999963, -11.799999999999818, -19.599999999999753, -127.00000000000074, -11.499999999999819, -48.99999999999983, 15.799999999999963, -21.999999999999744, 15.799999999999963, 11.599999999999964, 9.499999999999964, 26.300000000000114, 17.899999999999988, 11.599999999999964, 8.599999999999971, 20.300000000000015, 15.799999999999963, 41.30000000000023, -78.69999999999987, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999966, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 5.299999999999965, -11.499999999999819, 13.699999999999964, 20.000000000000014, -114.40000000000038, 15.799999999999963, -14.799999999999871, 11.599999999999964, 9.499999999999964, -15.099999999999763, 5.299999999999965, 7.399999999999972, 13.699999999999964, 15.799999999999963, 7.399999999999965, 11.599999999999964, -59.79999999999979, 15.799999999999963], "policy_predator_policy_reward": [18.0, 23.0, 4.0, 4.0, 37.0, 42.0, 2.0, 8.0, 1.0, 1.0, 30.0, 12.0, 13.0, 8.0, 45.0, 46.0, 13.0, 0.0, 22.0, 30.0, 4.0, 10.0, 3.0, 14.0, 17.0, 23.0, 19.0, 16.0, 28.0, 27.0, 22.0, 8.0, 49.0, 52.0, 0.0, 4.0, 11.0, 8.0, 24.0, 26.0, 13.0, 8.0, 22.0, 16.0, 13.0, 0.0, 4.0, 5.0, 6.0, 18.0, 20.0, 20.0, 7.0, 6.0, 6.0, 0.0, 12.0, 8.0, 14.0, 9.0, 2.0, 10.0, 13.0, 3.0, 5.0, 1.0, 52.0, 47.0, 28.0, 19.0, 17.0, 4.0, 23.0, 5.0, 8.0, 18.0, 22.0, 20.0, 11.0, 3.0, 15.0, 7.0, 5.0, 3.0, 21.0, 7.0, 18.0, 10.0, 4.0, 2.0, 6.0, 4.0, 44.0, 75.0, 21.0, 26.0, 5.0, 11.0, 2.0, 36.0, 19.0, 10.0, 10.0, 24.0, 16.0, 10.0, 9.0, 9.0, 4.0, 12.0, 22.0, 1.0, 6.0, 8.0, 10.0, 14.0, 13.0, 6.0, 0.0, 1.0, 7.0, 8.0, 4.0, 11.0, 28.0, 9.0, 1.0, 2.0, 2.0, 5.0, 2.0, 0.0, 57.0, 29.0, 9.0, 8.0, 3.0, 3.0, 8.0, 11.0, 5.0, 0.0, 13.0, 1.0, 6.0, 9.0, 5.0, 2.0, 2.0, 0.0, 2.0, 0.0, 4.0, 0.0, 21.0, 13.0, 22.0, 21.0, 71.0, 10.0, 35.0, 15.0, 14.0, 18.0, 5.0, 4.0, 0.0, 1.0, 11.0, 8.0, 2.0, 8.0, 47.0, 4.0, 7.0, 3.0, 3.0, 1.0, 3.0, 0.0, 15.0, 8.0, 7.0, 15.0, 1.0, 3.0, 64.0, 2.0, 11.0, 16.0, 18.0, 9.0, 9.0, 4.0, 3.0, 2.0, 6.0, 4.0, 26.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8340966985112975, "mean_inference_ms": 2.1892295637917023, "mean_action_processing_ms": 0.34963143448542916, "mean_env_wait_ms": 0.27797361902265716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01950693130493164, "StateBufferConnector_ms": 0.0038019418716430664, "ViewRequirementAgentConnector_ms": 0.13564419746398926}, "num_episodes": 18, "episode_return_max": 75.0999999999997, "episode_return_min": -57.50000000000035, "episode_return_mean": 27.846000000000178, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.1796356186318, "num_env_steps_trained_throughput_per_sec": 344.1796356186318, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 11852.629, "restore_workers_time_ms": 0.021, "training_step_time_ms": 11852.572, "sample_time_ms": 1888.003, "learn_time_ms": 9939.594, "learn_throughput": 402.431, "synch_weights_time_ms": 22.354}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-04-38", "timestamp": 1723647878, "time_this_iter_s": 11.657554149627686, "time_total_s": 1045.8442301750183, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b59550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1045.8442301750183, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 43.82941176470588, "ram_util_percent": 82.83529411764708}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1698886002813067, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.746096496244587, "policy_loss": -0.0049545384482751606, "vf_loss": 1.750760447663605, "vf_explained_var": -0.014059490722323221, "kl": 0.008163459016780696, "entropy": 1.448879471279326, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8832386259994809, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.259883986011384, "policy_loss": -0.005566206763291524, "vf_loss": 1.2652615652513253, "vf_explained_var": 0.19575240154745718, "kl": 0.010060062127066706, "entropy": 0.48008279779916085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 75.0999999999997, "episode_reward_min": -57.50000000000035, "episode_reward_mean": 26.496000000000176, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -143.80000000000044, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 58.700000000000195, "predator_policy": 75.0}, "policy_reward_mean": {"prey_policy": 1.1330000000000195, "predator_policy": 12.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [68.20000000000019, 13.600000000000026, 32.60000000000019, 41.30000000000032, 38.800000000000274, 18.899999999999967, 18.300000000000047, 39.100000000000286, 30.500000000000163, 35.500000000000234, 22.900000000000077, 33.300000000000196, 25.00000000000006, 31.70000000000018, 11.400000000000077, 10.000000000000068, 33.60000000000021, 45.8000000000004, 31.200000000000163, 9.200000000000106, 18.79999999999999, 37.600000000000264, 29.000000000000124, 33.90000000000035, 66.60000000000026, 16.09999999999994, 21.3000000000004, 32.700000000000195, 14.000000000000004, 35.10000000000024, 62.20000000000051, 24.200000000000042, 28.20000000000012, 45.300000000000416, 75.0999999999997, 17.000000000000004, 38.90000000000028, 56.200000000000514, 31.90000000000018, 2.9000000000001873, 38.80000000000028, 44.00000000000036, 37.80000000000027, -19.199999999999534, 27.6000000000001, 43.300000000000345, 42.20000000000034, 34.50000000000022, 24.600000000000065, 39.70000000000031, 32.30000000000018, 37.80000000000027, 37.80000000000027, 31.400000000000166, 27.2000000000001, 11.600000000000048, -57.50000000000035, 16.79999999999994, 25.80000000000007, 30.100000000000144, 45.20000000000038, 39.20000000000028, 46.100000000000364, 13.60000000000041, 35.30000000000023, 37.700000000000266, 36.70000000000025, 14.700000000000022, 15.799999999999997, 37.700000000000266, -32.599999999999774, 23.800000000000058, 21.399999999999995, 25.700000000000074, 34.50000000000022, 29.000000000000124, 5.999999999999945, 11.20000000000002, 32.90000000000019, 16.89999999999998, 0.30000000000021426, 35.10000000000023, -14.69999999999985, 29.000000000000124, -19.899999999999675, 33.60000000000021, 28.60000000000012, 37.80000000000027, -16.099999999999827, 32.30000000000018, 19.100000000000062, 5.80000000000002, -19.099999999999937, 29.90000000000014, 15.79999999999999, 39.30000000000029, 30.100000000000144, 36.900000000000254, 33.400000000000205, 37.10000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [49.70000000000024, 9.499999999999964, 7.399999999999965, -17.79999999999974, 20.000000000000014, -27.39999999999975, 9.499999999999964, 18.8, 25.4000000000001, 7.399999999999965, 11.599999999999964, -12.6999999999999, 1.9999999999999802, -6.699999999999907, 20.000000000000014, 7.0999999999999694, 11.599999999999964, 2.899999999999965, 9.499999999999964, 20.000000000000014, -87.70000000000053, 11.599999999999964, -33.69999999999977, 20.000000000000014, 19.700000000000014, -15.699999999999754, 4.099999999999966, -0.40000000000002767, -17.79999999999974, 3.1999999999999615, -6.399999999999922, -25.599999999999753, 20.000000000000014, -0.4000000000000099, 20.000000000000014, 3.7999999999999727, 13.699999999999964, 9.499999999999964, -3.099999999999958, -15.699999999999768, -14.49999999999978, 5.299999999999965, 11.599999999999964, 20.000000000000014, 11.599999999999964, 7.399999999999965, -143.80000000000044, 58.700000000000195, 41.300000000000246, -21.69999999999979, 3.19999999999999, -3.099999999999958, 38.900000000000254, -55.59999999999984, -16.29999999999975, 20.000000000000014, 6.1999999999999655, -26.199999999999747, -10.899999999999942, 20.000000000000014, 29.90000000000018, 14.29999999999996, 11.599999999999964, -3.399999999999958, -12.699999999999829, 17.899999999999988, 7.399999999999965, 23.900000000000073, 47.90000000000024, 3.1999999999999846, 5.299999999999965, -7.299999999999891, 20.000000000000014, 17.899999999999988, 38.000000000000256, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 7.399999999999965, -41.499999999999766, 15.799999999999963, 20.000000000000014, 17.599999999999984, 19.40000000000001, 15.799999999999963, 20.000000000000014, -100.0000000000008, -5.1999999999999265, 9.499999999999964, 1.0999999999999865, 13.699999999999964, 23.600000000000065, 20.000000000000014, 3.1999999999999686, 20.000000000000014, 9.499999999999964, 7.399999999999965, 3.199999999999974, 23.60000000000008, 1.099999999999983, 15.799999999999963, 9.499999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999964, 15.799999999999963, -22.599999999999753, 15.799999999999963, -11.799999999999818, -19.599999999999753, -127.00000000000074, -11.499999999999819, -48.99999999999983, 15.799999999999963, -21.999999999999744, 15.799999999999963, 11.599999999999964, 9.499999999999964, 26.300000000000114, 17.899999999999988, 11.599999999999964, 8.599999999999971, 20.300000000000015, 15.799999999999963, 41.30000000000023, -78.69999999999987, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999966, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 5.299999999999965, -11.499999999999819, 13.699999999999964, 20.000000000000014, -114.40000000000038, 15.799999999999963, -14.799999999999871, 11.599999999999964, 9.499999999999964, -15.099999999999763, 5.299999999999965, 7.399999999999972, 13.699999999999964, 15.799999999999963, 7.399999999999965, 11.599999999999964, -59.79999999999979, 15.799999999999963, 3.199999999999965, -36.99999999999979, 3.1999999999999615, 13.699999999999951, 13.699999999999964, -17.79999999999974, -57.70000000000034, 20.000000000000014, 15.799999999999963, -30.699999999999775, -70.30000000000024, 2.599999999999961, 13.699999999999964, 5.299999999999965, -68.19999999999983, -12.699999999999815, 13.699999999999964, 5.89999999999997, 4.999999999999966, 11.599999999999964, 19.40000000000001, 7.399999999999965, -70.29999999999987, 3.1999999999999673, 7.399999999999965, 17.899999999999984, 5.299999999999967, -5.1999999999999265, -1.0000000000000187, -26.199999999999747, -26.199999999999985, -40.89999999999989, 13.699999999999964, 3.1999999999999615, -17.79999999999974, 11.599999999999964, 20.000000000000014, 5.299999999999965, 11.599999999999964, 9.499999999999964, -0.7000000000000063, -0.40000000000001346, 7.399999999999965, 20.000000000000014, 11.899999999999967, 15.199999999999966], "policy_predator_policy_reward": [4.0, 5.0, 6.0, 18.0, 20.0, 20.0, 7.0, 6.0, 6.0, 0.0, 12.0, 8.0, 14.0, 9.0, 2.0, 10.0, 13.0, 3.0, 5.0, 1.0, 52.0, 47.0, 28.0, 19.0, 17.0, 4.0, 23.0, 5.0, 8.0, 18.0, 22.0, 20.0, 11.0, 3.0, 15.0, 7.0, 5.0, 3.0, 21.0, 7.0, 18.0, 10.0, 4.0, 2.0, 6.0, 4.0, 44.0, 75.0, 21.0, 26.0, 5.0, 11.0, 2.0, 36.0, 19.0, 10.0, 10.0, 24.0, 16.0, 10.0, 9.0, 9.0, 4.0, 12.0, 22.0, 1.0, 6.0, 8.0, 10.0, 14.0, 13.0, 6.0, 0.0, 1.0, 7.0, 8.0, 4.0, 11.0, 28.0, 9.0, 1.0, 2.0, 2.0, 5.0, 2.0, 0.0, 57.0, 29.0, 9.0, 8.0, 3.0, 3.0, 8.0, 11.0, 5.0, 0.0, 13.0, 1.0, 6.0, 9.0, 5.0, 2.0, 2.0, 0.0, 2.0, 0.0, 4.0, 0.0, 21.0, 13.0, 22.0, 21.0, 71.0, 10.0, 35.0, 15.0, 14.0, 18.0, 5.0, 4.0, 0.0, 1.0, 11.0, 8.0, 2.0, 8.0, 47.0, 4.0, 7.0, 3.0, 3.0, 1.0, 3.0, 0.0, 15.0, 8.0, 7.0, 15.0, 1.0, 3.0, 64.0, 2.0, 11.0, 16.0, 18.0, 9.0, 9.0, 4.0, 3.0, 2.0, 6.0, 4.0, 26.0, 24.0, 11.0, 34.0, 8.0, 8.0, 3.0, 18.0, 1.0, 37.0, 22.0, 28.0, 10.0, 43.0, 3.0, 7.0, 42.0, 19.0, 8.0, 6.0, 8.0, 4.0, 6.0, 5.0, 25.0, 26.0, 7.0, 0.0, 12.0, 7.0, 2.0, 31.0, 43.0, 5.0, 5.0, 8.0, 4.0, 18.0, 7.0, 7.0, 5.0, 4.0, 19.0, 19.0, 0.0, 6.0, 4.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8360543503845892, "mean_inference_ms": 2.193002263690448, "mean_action_processing_ms": 0.3501165846564639, "mean_env_wait_ms": 0.278405173527718, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01948559284210205, "StateBufferConnector_ms": 0.004167437553405762, "ViewRequirementAgentConnector_ms": 0.10720062255859375}, "num_episodes": 23, "episode_return_max": 75.0999999999997, "episode_return_min": -57.50000000000035, "episode_return_mean": 26.496000000000176, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.20155089839164, "num_env_steps_trained_throughput_per_sec": 341.20155089839164, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 11807.755, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11807.701, "sample_time_ms": 1945.063, "learn_time_ms": 9840.321, "learn_throughput": 406.491, "synch_weights_time_ms": 20.446}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-04-50", "timestamp": 1723647890, "time_this_iter_s": 11.76220703125, "time_total_s": 1057.6064372062683, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b94c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1057.6064372062683, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 46.44375, "ram_util_percent": 83.025}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.794591844018805, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9667841385934186, "policy_loss": -0.007693068914253403, "vf_loss": 0.973883974828102, "vf_explained_var": -0.04790897520761641, "kl": 0.01666590360613978, "entropy": 1.372546778154121, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.616387919916047, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7371980788373442, "policy_loss": -0.0040114395671509324, "vf_loss": 0.7410200740531008, "vf_explained_var": 0.2922969811492496, "kl": 0.01010374267637376, "entropy": 0.5555304919128065, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 75.0999999999997, "episode_reward_min": -57.50000000000035, "episode_reward_mean": 26.627000000000177, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -143.80000000000044, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 58.700000000000195, "predator_policy": 75.0}, "policy_reward_mean": {"prey_policy": 1.83350000000002, "predator_policy": 11.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.200000000000163, 9.200000000000106, 18.79999999999999, 37.600000000000264, 29.000000000000124, 33.90000000000035, 66.60000000000026, 16.09999999999994, 21.3000000000004, 32.700000000000195, 14.000000000000004, 35.10000000000024, 62.20000000000051, 24.200000000000042, 28.20000000000012, 45.300000000000416, 75.0999999999997, 17.000000000000004, 38.90000000000028, 56.200000000000514, 31.90000000000018, 2.9000000000001873, 38.80000000000028, 44.00000000000036, 37.80000000000027, -19.199999999999534, 27.6000000000001, 43.300000000000345, 42.20000000000034, 34.50000000000022, 24.600000000000065, 39.70000000000031, 32.30000000000018, 37.80000000000027, 37.80000000000027, 31.400000000000166, 27.2000000000001, 11.600000000000048, -57.50000000000035, 16.79999999999994, 25.80000000000007, 30.100000000000144, 45.20000000000038, 39.20000000000028, 46.100000000000364, 13.60000000000041, 35.30000000000023, 37.700000000000266, 36.70000000000025, 14.700000000000022, 15.799999999999997, 37.700000000000266, -32.599999999999774, 23.800000000000058, 21.399999999999995, 25.700000000000074, 34.50000000000022, 29.000000000000124, 5.999999999999945, 11.20000000000002, 32.90000000000019, 16.89999999999998, 0.30000000000021426, 35.10000000000023, -14.69999999999985, 29.000000000000124, -19.899999999999675, 33.60000000000021, 28.60000000000012, 37.80000000000027, -16.099999999999827, 32.30000000000018, 19.100000000000062, 5.80000000000002, -19.099999999999937, 29.90000000000014, 15.79999999999999, 39.30000000000029, 30.100000000000144, 36.900000000000254, 33.400000000000205, 37.10000000000026, 35.90000000000024, 30.100000000000154, 6.900000000000188, 34.50000000000022, 42.00000000000033, 44.60000000000037, 27.500000000000135, 23.000000000000036, 38.70000000000028, 33.4000000000002, 22.500000000000018, 41.60000000000032, 37.40000000000026, 32.30000000000018, 22.700000000000028, 37.80000000000027, 35.30000000000023, 17.399999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, 9.499999999999964, -3.099999999999958, -15.699999999999768, -14.49999999999978, 5.299999999999965, 11.599999999999964, 20.000000000000014, 11.599999999999964, 7.399999999999965, -143.80000000000044, 58.700000000000195, 41.300000000000246, -21.69999999999979, 3.19999999999999, -3.099999999999958, 38.900000000000254, -55.59999999999984, -16.29999999999975, 20.000000000000014, 6.1999999999999655, -26.199999999999747, -10.899999999999942, 20.000000000000014, 29.90000000000018, 14.29999999999996, 11.599999999999964, -3.399999999999958, -12.699999999999829, 17.899999999999988, 7.399999999999965, 23.900000000000073, 47.90000000000024, 3.1999999999999846, 5.299999999999965, -7.299999999999891, 20.000000000000014, 17.899999999999988, 38.000000000000256, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 7.399999999999965, -41.499999999999766, 15.799999999999963, 20.000000000000014, 17.599999999999984, 19.40000000000001, 15.799999999999963, 20.000000000000014, -100.0000000000008, -5.1999999999999265, 9.499999999999964, 1.0999999999999865, 13.699999999999964, 23.600000000000065, 20.000000000000014, 3.1999999999999686, 20.000000000000014, 9.499999999999964, 7.399999999999965, 3.199999999999974, 23.60000000000008, 1.099999999999983, 15.799999999999963, 9.499999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999964, 15.799999999999963, -22.599999999999753, 15.799999999999963, -11.799999999999818, -19.599999999999753, -127.00000000000074, -11.499999999999819, -48.99999999999983, 15.799999999999963, -21.999999999999744, 15.799999999999963, 11.599999999999964, 9.499999999999964, 26.300000000000114, 17.899999999999988, 11.599999999999964, 8.599999999999971, 20.300000000000015, 15.799999999999963, 41.30000000000023, -78.69999999999987, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999966, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 5.299999999999965, -11.499999999999819, 13.699999999999964, 20.000000000000014, -114.40000000000038, 15.799999999999963, -14.799999999999871, 11.599999999999964, 9.499999999999964, -15.099999999999763, 5.299999999999965, 7.399999999999972, 13.699999999999964, 15.799999999999963, 7.399999999999965, 11.599999999999964, -59.79999999999979, 15.799999999999963, 3.199999999999965, -36.99999999999979, 3.1999999999999615, 13.699999999999951, 13.699999999999964, -17.79999999999974, -57.70000000000034, 20.000000000000014, 15.799999999999963, -30.699999999999775, -70.30000000000024, 2.599999999999961, 13.699999999999964, 5.299999999999965, -68.19999999999983, -12.699999999999815, 13.699999999999964, 5.89999999999997, 4.999999999999966, 11.599999999999964, 19.40000000000001, 7.399999999999965, -70.29999999999987, 3.1999999999999673, 7.399999999999965, 17.899999999999984, 5.299999999999967, -5.1999999999999265, -1.0000000000000187, -26.199999999999747, -26.199999999999985, -40.89999999999989, 13.699999999999964, 3.1999999999999615, -17.79999999999974, 11.599999999999964, 20.000000000000014, 5.299999999999965, 11.599999999999964, 9.499999999999964, -0.7000000000000063, -0.40000000000001346, 7.399999999999965, 20.000000000000014, 11.899999999999967, 15.199999999999966, 20.000000000000014, -9.09999999999987, 9.499999999999964, 2.5999999999999646, 37.10000000000025, -83.20000000000009, 13.699999999999964, 15.799999999999963, 13.699999999999955, 17.299999999999976, 24.80000000000009, 15.799999999999963, 4.999999999999966, 9.499999999999964, -42.99999999999977, 7.99999999999997, 13.699999999999964, 20.000000000000014, 13.699999999999964, 13.699999999999964, 21.80000000000004, -28.29999999999975, 20.000000000000014, 20.600000000000026, 7.399999999999965, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -28.299999999999756, 15.799999999999963, 20.000000000000014, -15.699999999999747, 20.000000000000014, 13.699999999999964, -28.29999999999975], "policy_predator_policy_reward": [5.0, 3.0, 21.0, 7.0, 18.0, 10.0, 4.0, 2.0, 6.0, 4.0, 44.0, 75.0, 21.0, 26.0, 5.0, 11.0, 2.0, 36.0, 19.0, 10.0, 10.0, 24.0, 16.0, 10.0, 9.0, 9.0, 4.0, 12.0, 22.0, 1.0, 6.0, 8.0, 10.0, 14.0, 13.0, 6.0, 0.0, 1.0, 7.0, 8.0, 4.0, 11.0, 28.0, 9.0, 1.0, 2.0, 2.0, 5.0, 2.0, 0.0, 57.0, 29.0, 9.0, 8.0, 3.0, 3.0, 8.0, 11.0, 5.0, 0.0, 13.0, 1.0, 6.0, 9.0, 5.0, 2.0, 2.0, 0.0, 2.0, 0.0, 4.0, 0.0, 21.0, 13.0, 22.0, 21.0, 71.0, 10.0, 35.0, 15.0, 14.0, 18.0, 5.0, 4.0, 0.0, 1.0, 11.0, 8.0, 2.0, 8.0, 47.0, 4.0, 7.0, 3.0, 3.0, 1.0, 3.0, 0.0, 15.0, 8.0, 7.0, 15.0, 1.0, 3.0, 64.0, 2.0, 11.0, 16.0, 18.0, 9.0, 9.0, 4.0, 3.0, 2.0, 6.0, 4.0, 26.0, 24.0, 11.0, 34.0, 8.0, 8.0, 3.0, 18.0, 1.0, 37.0, 22.0, 28.0, 10.0, 43.0, 3.0, 7.0, 42.0, 19.0, 8.0, 6.0, 8.0, 4.0, 6.0, 5.0, 25.0, 26.0, 7.0, 0.0, 12.0, 7.0, 2.0, 31.0, 43.0, 5.0, 5.0, 8.0, 4.0, 18.0, 7.0, 7.0, 5.0, 4.0, 19.0, 19.0, 0.0, 6.0, 4.0, 6.0, 12.0, 13.0, 5.0, 13.0, 18.0, 35.0, 2.0, 3.0, 8.0, 3.0, 2.0, 2.0, 9.0, 4.0, 30.0, 28.0, 3.0, 2.0, 3.0, 3.0, 13.0, 16.0, 1.0, 0.0, 5.0, 5.0, 3.0, 4.0, 18.0, 13.0, 0.0, 2.0, 14.0, 17.0, 23.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8374012954462319, "mean_inference_ms": 2.195183498046981, "mean_action_processing_ms": 0.35030716369127324, "mean_env_wait_ms": 0.2787807268493498, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019266724586486816, "StateBufferConnector_ms": 0.00418245792388916, "ViewRequirementAgentConnector_ms": 0.10576260089874268}, "num_episodes": 18, "episode_return_max": 75.0999999999997, "episode_return_min": -57.50000000000035, "episode_return_mean": 26.627000000000177, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.1986384875892, "num_env_steps_trained_throughput_per_sec": 348.1986384875892, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 11696.875, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11696.82, "sample_time_ms": 1939.932, "learn_time_ms": 9736.532, "learn_throughput": 410.824, "synch_weights_time_ms": 18.486}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-05-02", "timestamp": 1723647902, "time_this_iter_s": 11.527615070343018, "time_total_s": 1069.1340522766113, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2a33af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1069.1340522766113, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 43.84117647058823, "ram_util_percent": 82.73529411764704}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6173449084399238, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.235269978472953, "policy_loss": -0.009020078651577472, "vf_loss": 1.2438242533692607, "vf_explained_var": -0.03737488310173075, "kl": 0.013085871312639946, "entropy": 1.3038715633134994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9284297809398994, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2800120574772043, "policy_loss": -0.0036212438653425248, "vf_loss": 1.2835182255695736, "vf_explained_var": 0.11975183474323738, "kl": 0.006137494094809819, "entropy": 0.5500024427812567, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 51.40000000000049, "episode_reward_min": -57.50000000000035, "episode_reward_mean": 25.054000000000183, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -127.00000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.30000000000023, "predator_policy": 71.0}, "policy_reward_mean": {"prey_policy": 1.3070000000000093, "predator_policy": 11.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.80000000000028, 44.00000000000036, 37.80000000000027, -19.199999999999534, 27.6000000000001, 43.300000000000345, 42.20000000000034, 34.50000000000022, 24.600000000000065, 39.70000000000031, 32.30000000000018, 37.80000000000027, 37.80000000000027, 31.400000000000166, 27.2000000000001, 11.600000000000048, -57.50000000000035, 16.79999999999994, 25.80000000000007, 30.100000000000144, 45.20000000000038, 39.20000000000028, 46.100000000000364, 13.60000000000041, 35.30000000000023, 37.700000000000266, 36.70000000000025, 14.700000000000022, 15.799999999999997, 37.700000000000266, -32.599999999999774, 23.800000000000058, 21.399999999999995, 25.700000000000074, 34.50000000000022, 29.000000000000124, 5.999999999999945, 11.20000000000002, 32.90000000000019, 16.89999999999998, 0.30000000000021426, 35.10000000000023, -14.69999999999985, 29.000000000000124, -19.899999999999675, 33.60000000000021, 28.60000000000012, 37.80000000000027, -16.099999999999827, 32.30000000000018, 19.100000000000062, 5.80000000000002, -19.099999999999937, 29.90000000000014, 15.79999999999999, 39.30000000000029, 30.100000000000144, 36.900000000000254, 33.400000000000205, 37.10000000000026, 35.90000000000024, 30.100000000000154, 6.900000000000188, 34.50000000000022, 42.00000000000033, 44.60000000000037, 27.500000000000135, 23.000000000000036, 38.70000000000028, 33.4000000000002, 22.500000000000018, 41.60000000000032, 37.40000000000026, 32.30000000000018, 22.700000000000028, 37.80000000000027, 35.30000000000023, 17.399999999999952, 1.999999999999934, 15.799999999999969, 31.200000000000166, 34.200000000000216, 3.999999999999957, -16.299999999999947, 31.40000000000048, 32.700000000000195, 18.000000000000004, 38.50000000000028, 39.50000000000029, 32.300000000000196, 37.80000000000027, 32.30000000000018, -15.199999999999777, 33.3000000000002, 11.600000000000101, 35.10000000000023, 35.600000000000236, 51.40000000000049, 40.2000000000003, 44.70000000000038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, 20.000000000000014, 17.599999999999984, 19.40000000000001, 15.799999999999963, 20.000000000000014, -100.0000000000008, -5.1999999999999265, 9.499999999999964, 1.0999999999999865, 13.699999999999964, 23.600000000000065, 20.000000000000014, 3.1999999999999686, 20.000000000000014, 9.499999999999964, 7.399999999999965, 3.199999999999974, 23.60000000000008, 1.099999999999983, 15.799999999999963, 9.499999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 15.799999999999963, 11.599999999999964, 15.799999999999963, -22.599999999999753, 15.799999999999963, -11.799999999999818, -19.599999999999753, -127.00000000000074, -11.499999999999819, -48.99999999999983, 15.799999999999963, -21.999999999999744, 15.799999999999963, 11.599999999999964, 9.499999999999964, 26.300000000000114, 17.899999999999988, 11.599999999999964, 8.599999999999971, 20.300000000000015, 15.799999999999963, 41.30000000000023, -78.69999999999987, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999966, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 5.299999999999965, -11.499999999999819, 13.699999999999964, 20.000000000000014, -114.40000000000038, 15.799999999999963, -14.799999999999871, 11.599999999999964, 9.499999999999964, -15.099999999999763, 5.299999999999965, 7.399999999999972, 13.699999999999964, 15.799999999999963, 7.399999999999965, 11.599999999999964, -59.79999999999979, 15.799999999999963, 3.199999999999965, -36.99999999999979, 3.1999999999999615, 13.699999999999951, 13.699999999999964, -17.79999999999974, -57.70000000000034, 20.000000000000014, 15.799999999999963, -30.699999999999775, -70.30000000000024, 2.599999999999961, 13.699999999999964, 5.299999999999965, -68.19999999999983, -12.699999999999815, 13.699999999999964, 5.89999999999997, 4.999999999999966, 11.599999999999964, 19.40000000000001, 7.399999999999965, -70.29999999999987, 3.1999999999999673, 7.399999999999965, 17.899999999999984, 5.299999999999967, -5.1999999999999265, -1.0000000000000187, -26.199999999999747, -26.199999999999985, -40.89999999999989, 13.699999999999964, 3.1999999999999615, -17.79999999999974, 11.599999999999964, 20.000000000000014, 5.299999999999965, 11.599999999999964, 9.499999999999964, -0.7000000000000063, -0.40000000000001346, 7.399999999999965, 20.000000000000014, 11.899999999999967, 15.199999999999966, 20.000000000000014, -9.09999999999987, 9.499999999999964, 2.5999999999999646, 37.10000000000025, -83.20000000000009, 13.699999999999964, 15.799999999999963, 13.699999999999955, 17.299999999999976, 24.80000000000009, 15.799999999999963, 4.999999999999966, 9.499999999999964, -42.99999999999977, 7.99999999999997, 13.699999999999964, 20.000000000000014, 13.699999999999964, 13.699999999999964, 21.80000000000004, -28.29999999999975, 20.000000000000014, 20.600000000000026, 7.399999999999965, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -28.299999999999756, 15.799999999999963, 20.000000000000014, -15.699999999999747, 20.000000000000014, 13.699999999999964, -28.29999999999975, -52.89999999999977, 17.899999999999988, 15.799999999999963, -21.999999999999844, 15.799999999999963, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -72.40000000000055, -25.59999999999978, -7.299999999999912, -63.99999999999988, -5.1999999999997994, 11.599999999999964, 20.000000000000014, -7.299999999999891, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 21.80000000000004, 13.699999999999964, 15.799999999999963, 9.499999999999977, 20.000000000000014, 15.799999999999963, 20.000000000000014, 5.299999999999965, 7.399999999999965, -76.60000000000021, 20.000000000000014, 5.299999999999965, 11.599999999999964, -45.999999999999915, 20.000000000000014, 1.0999999999999865, 13.699999999999964, 17.899999999999988, 13.699999999999964, 31.700000000000212, 22.700000000000053, 9.499999999999964, -25.299999999999763, 20.000000000000014], "policy_predator_policy_reward": [1.0, 2.0, 2.0, 5.0, 2.0, 0.0, 57.0, 29.0, 9.0, 8.0, 3.0, 3.0, 8.0, 11.0, 5.0, 0.0, 13.0, 1.0, 6.0, 9.0, 5.0, 2.0, 2.0, 0.0, 2.0, 0.0, 4.0, 0.0, 21.0, 13.0, 22.0, 21.0, 71.0, 10.0, 35.0, 15.0, 14.0, 18.0, 5.0, 4.0, 0.0, 1.0, 11.0, 8.0, 2.0, 8.0, 47.0, 4.0, 7.0, 3.0, 3.0, 1.0, 3.0, 0.0, 15.0, 8.0, 7.0, 15.0, 1.0, 3.0, 64.0, 2.0, 11.0, 16.0, 18.0, 9.0, 9.0, 4.0, 3.0, 2.0, 6.0, 4.0, 26.0, 24.0, 11.0, 34.0, 8.0, 8.0, 3.0, 18.0, 1.0, 37.0, 22.0, 28.0, 10.0, 43.0, 3.0, 7.0, 42.0, 19.0, 8.0, 6.0, 8.0, 4.0, 6.0, 5.0, 25.0, 26.0, 7.0, 0.0, 12.0, 7.0, 2.0, 31.0, 43.0, 5.0, 5.0, 8.0, 4.0, 18.0, 7.0, 7.0, 5.0, 4.0, 19.0, 19.0, 0.0, 6.0, 4.0, 6.0, 12.0, 13.0, 5.0, 13.0, 18.0, 35.0, 2.0, 3.0, 8.0, 3.0, 2.0, 2.0, 9.0, 4.0, 30.0, 28.0, 3.0, 2.0, 3.0, 3.0, 13.0, 16.0, 1.0, 0.0, 5.0, 5.0, 3.0, 4.0, 18.0, 13.0, 0.0, 2.0, 14.0, 17.0, 23.0, 9.0, 21.0, 16.0, 2.0, 20.0, 6.0, 2.0, 3.0, 8.0, 52.0, 50.0, 7.0, 48.0, 25.0, 0.0, 7.0, 13.0, 12.0, 8.0, 4.0, 5.0, 3.0, 1.0, 3.0, 4.0, 2.0, 0.0, 7.0, 0.0, 8.0, 46.0, 1.0, 7.0, 10.0, 36.0, 7.0, 7.0, 1.0, 3.0, 3.0, 3.0, 5.0, 3.0, 25.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8391038469163254, "mean_inference_ms": 2.1973586761159716, "mean_action_processing_ms": 0.34998718785629107, "mean_env_wait_ms": 0.27907236053751805, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018076181411743164, "StateBufferConnector_ms": 0.004194855690002441, "ViewRequirementAgentConnector_ms": 0.10498499870300293}, "num_episodes": 22, "episode_return_max": 51.40000000000049, "episode_return_min": -57.50000000000035, "episode_return_mean": 25.054000000000183, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.5261678905809, "num_env_steps_trained_throughput_per_sec": 342.5261678905809, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 11664.363, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11664.307, "sample_time_ms": 1942.719, "learn_time_ms": 9701.574, "learn_throughput": 412.304, "synch_weights_time_ms": 17.934}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-05-13", "timestamp": 1723647913, "time_this_iter_s": 11.727923154830933, "time_total_s": 1080.8619754314423, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b69670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1080.8619754314423, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 46.943749999999994, "ram_util_percent": 82.825}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9635506028851504, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0372989362847336, "policy_loss": -0.008630087184005234, "vf_loss": 1.0452580495249657, "vf_explained_var": -0.06003608839221732, "kl": 0.01884987021688332, "entropy": 1.220512275594883, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8815232131216262, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9701217726740257, "policy_loss": -0.0038744728393833, "vf_loss": 0.9738802912374022, "vf_explained_var": 0.2569670048655656, "kl": 0.006184310498610049, "entropy": 0.5060057370908677, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 55.70000000000048, "episode_reward_min": -32.599999999999774, "episode_reward_mean": 25.526000000000167, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -114.40000000000038, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.30000000000023, "predator_policy": 64.0}, "policy_reward_mean": {"prey_policy": 1.8530000000000186, "predator_policy": 10.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.80000000000007, 30.100000000000144, 45.20000000000038, 39.20000000000028, 46.100000000000364, 13.60000000000041, 35.30000000000023, 37.700000000000266, 36.70000000000025, 14.700000000000022, 15.799999999999997, 37.700000000000266, -32.599999999999774, 23.800000000000058, 21.399999999999995, 25.700000000000074, 34.50000000000022, 29.000000000000124, 5.999999999999945, 11.20000000000002, 32.90000000000019, 16.89999999999998, 0.30000000000021426, 35.10000000000023, -14.69999999999985, 29.000000000000124, -19.899999999999675, 33.60000000000021, 28.60000000000012, 37.80000000000027, -16.099999999999827, 32.30000000000018, 19.100000000000062, 5.80000000000002, -19.099999999999937, 29.90000000000014, 15.79999999999999, 39.30000000000029, 30.100000000000144, 36.900000000000254, 33.400000000000205, 37.10000000000026, 35.90000000000024, 30.100000000000154, 6.900000000000188, 34.50000000000022, 42.00000000000033, 44.60000000000037, 27.500000000000135, 23.000000000000036, 38.70000000000028, 33.4000000000002, 22.500000000000018, 41.60000000000032, 37.40000000000026, 32.30000000000018, 22.700000000000028, 37.80000000000027, 35.30000000000023, 17.399999999999952, 1.999999999999934, 15.799999999999969, 31.200000000000166, 34.200000000000216, 3.999999999999957, -16.299999999999947, 31.40000000000048, 32.700000000000195, 18.000000000000004, 38.50000000000028, 39.50000000000029, 32.300000000000196, 37.80000000000027, 32.30000000000018, -15.199999999999777, 33.3000000000002, 11.600000000000101, 35.10000000000023, 35.600000000000236, 51.40000000000049, 40.2000000000003, 44.70000000000038, 33.400000000000205, 20.499999999999986, 24.000000000000078, 26.800000000000086, 31.400000000000176, 10.299999999999907, 33.3000000000002, 29.000000000000128, 23.60000000000023, 26.400000000000095, 55.70000000000048, 21.699999999999996, 7.000000000000149, 32.20000000000018, 20.2, 29.000000000000128, 39.700000000000294, 33.70000000000021], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-21.999999999999744, 15.799999999999963, 11.599999999999964, 9.499999999999964, 26.300000000000114, 17.899999999999988, 11.599999999999964, 8.599999999999971, 20.300000000000015, 15.799999999999963, 41.30000000000023, -78.69999999999987, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999966, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 5.299999999999965, -11.499999999999819, 13.699999999999964, 20.000000000000014, -114.40000000000038, 15.799999999999963, -14.799999999999871, 11.599999999999964, 9.499999999999964, -15.099999999999763, 5.299999999999965, 7.399999999999972, 13.699999999999964, 15.799999999999963, 7.399999999999965, 11.599999999999964, -59.79999999999979, 15.799999999999963, 3.199999999999965, -36.99999999999979, 3.1999999999999615, 13.699999999999951, 13.699999999999964, -17.79999999999974, -57.70000000000034, 20.000000000000014, 15.799999999999963, -30.699999999999775, -70.30000000000024, 2.599999999999961, 13.699999999999964, 5.299999999999965, -68.19999999999983, -12.699999999999815, 13.699999999999964, 5.89999999999997, 4.999999999999966, 11.599999999999964, 19.40000000000001, 7.399999999999965, -70.29999999999987, 3.1999999999999673, 7.399999999999965, 17.899999999999984, 5.299999999999967, -5.1999999999999265, -1.0000000000000187, -26.199999999999747, -26.199999999999985, -40.89999999999989, 13.699999999999964, 3.1999999999999615, -17.79999999999974, 11.599999999999964, 20.000000000000014, 5.299999999999965, 11.599999999999964, 9.499999999999964, -0.7000000000000063, -0.40000000000001346, 7.399999999999965, 20.000000000000014, 11.899999999999967, 15.199999999999966, 20.000000000000014, -9.09999999999987, 9.499999999999964, 2.5999999999999646, 37.10000000000025, -83.20000000000009, 13.699999999999964, 15.799999999999963, 13.699999999999955, 17.299999999999976, 24.80000000000009, 15.799999999999963, 4.999999999999966, 9.499999999999964, -42.99999999999977, 7.99999999999997, 13.699999999999964, 20.000000000000014, 13.699999999999964, 13.699999999999964, 21.80000000000004, -28.29999999999975, 20.000000000000014, 20.600000000000026, 7.399999999999965, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -28.299999999999756, 15.799999999999963, 20.000000000000014, -15.699999999999747, 20.000000000000014, 13.699999999999964, -28.29999999999975, -52.89999999999977, 17.899999999999988, 15.799999999999963, -21.999999999999844, 15.799999999999963, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -72.40000000000055, -25.59999999999978, -7.299999999999912, -63.99999999999988, -5.1999999999997994, 11.599999999999964, 20.000000000000014, -7.299999999999891, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 21.80000000000004, 13.699999999999964, 15.799999999999963, 9.499999999999977, 20.000000000000014, 15.799999999999963, 20.000000000000014, 5.299999999999965, 7.399999999999965, -76.60000000000021, 20.000000000000014, 5.299999999999965, 11.599999999999964, -45.999999999999915, 20.000000000000014, 1.0999999999999865, 13.699999999999964, 17.899999999999988, 13.699999999999964, 31.700000000000212, 22.700000000000053, 9.499999999999964, -25.299999999999763, 20.000000000000014, 7.399999999999965, 20.000000000000014, -42.99999999999979, 9.499999999999964, -6.700000000000035, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 27.200000000000134, -17.79999999999974, -21.9999999999998, 5.299999999999965, 20.000000000000014, 5.299999999999965, 17.899999999999988, 1.0999999999999617, -15.700000000000015, 20.300000000000022, -34.59999999999975, 20.000000000000014, 1.9999999999999607, 31.70000000000022, 3.1999999999999615, 9.499999999999964, -24.099999999999746, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 5.299999999999965, -3.099999999999958, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 17.899999999999984, 20.000000000000014, -1.2999999999999847], "policy_predator_policy_reward": [14.0, 18.0, 5.0, 4.0, 0.0, 1.0, 11.0, 8.0, 2.0, 8.0, 47.0, 4.0, 7.0, 3.0, 3.0, 1.0, 3.0, 0.0, 15.0, 8.0, 7.0, 15.0, 1.0, 3.0, 64.0, 2.0, 11.0, 16.0, 18.0, 9.0, 9.0, 4.0, 3.0, 2.0, 6.0, 4.0, 26.0, 24.0, 11.0, 34.0, 8.0, 8.0, 3.0, 18.0, 1.0, 37.0, 22.0, 28.0, 10.0, 43.0, 3.0, 7.0, 42.0, 19.0, 8.0, 6.0, 8.0, 4.0, 6.0, 5.0, 25.0, 26.0, 7.0, 0.0, 12.0, 7.0, 2.0, 31.0, 43.0, 5.0, 5.0, 8.0, 4.0, 18.0, 7.0, 7.0, 5.0, 4.0, 19.0, 19.0, 0.0, 6.0, 4.0, 6.0, 12.0, 13.0, 5.0, 13.0, 18.0, 35.0, 2.0, 3.0, 8.0, 3.0, 2.0, 2.0, 9.0, 4.0, 30.0, 28.0, 3.0, 2.0, 3.0, 3.0, 13.0, 16.0, 1.0, 0.0, 5.0, 5.0, 3.0, 4.0, 18.0, 13.0, 0.0, 2.0, 14.0, 17.0, 23.0, 9.0, 21.0, 16.0, 2.0, 20.0, 6.0, 2.0, 3.0, 8.0, 52.0, 50.0, 7.0, 48.0, 25.0, 0.0, 7.0, 13.0, 12.0, 8.0, 4.0, 5.0, 3.0, 1.0, 3.0, 4.0, 2.0, 0.0, 7.0, 0.0, 8.0, 46.0, 1.0, 7.0, 10.0, 36.0, 7.0, 7.0, 1.0, 3.0, 3.0, 3.0, 5.0, 3.0, 25.0, 25.0, 6.0, 0.0, 24.0, 30.0, 14.0, 3.0, 4.0, 8.0, 18.0, 4.0, 7.0, 20.0, 1.0, 7.0, 8.0, 2.0, 2.0, 17.0, 15.0, 26.0, 11.0, 11.0, 9.0, 0.0, 9.0, 21.0, 8.0, 1.0, 7.0, 11.0, 10.0, 0.0, 4.0, 2.0, 11.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8401123324510755, "mean_inference_ms": 2.198461337255375, "mean_action_processing_ms": 0.3506499388032164, "mean_env_wait_ms": 0.2794708225135608, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018012404441833496, "StateBufferConnector_ms": 0.004277944564819336, "ViewRequirementAgentConnector_ms": 0.10051500797271729}, "num_episodes": 18, "episode_return_max": 55.70000000000048, "episode_return_min": -32.599999999999774, "episode_return_mean": 25.526000000000167, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.55137233621537, "num_env_steps_trained_throughput_per_sec": 354.55137233621537, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 11644.277, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11644.222, "sample_time_ms": 1935.576, "learn_time_ms": 9690.965, "learn_throughput": 412.756, "synch_weights_time_ms": 15.681}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-05-25", "timestamp": 1723647925, "time_this_iter_s": 11.327887058258057, "time_total_s": 1092.1898624897003, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2afb430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1092.1898624897003, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 45.805882352941175, "ram_util_percent": 82.92352941176469}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.599148875033414, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5284069940594405, "policy_loss": -0.010981079851025864, "vf_loss": 0.5387890934889948, "vf_explained_var": 0.0259864038575894, "kl": 0.016827335660668248, "entropy": 1.1588873038216243, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6361510943483424, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.38311653750598745, "policy_loss": -0.00839396525191626, "vf_loss": 0.3912962506037383, "vf_explained_var": 0.2835892434158022, "kl": 0.011426707440436506, "entropy": 0.5468297172633428, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 60.600000000000506, "episode_reward_min": -19.899999999999675, "episode_reward_mean": 27.20700000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -83.20000000000009, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000025, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": 3.4385000000000208, "predator_policy": 10.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.10000000000023, -14.69999999999985, 29.000000000000124, -19.899999999999675, 33.60000000000021, 28.60000000000012, 37.80000000000027, -16.099999999999827, 32.30000000000018, 19.100000000000062, 5.80000000000002, -19.099999999999937, 29.90000000000014, 15.79999999999999, 39.30000000000029, 30.100000000000144, 36.900000000000254, 33.400000000000205, 37.10000000000026, 35.90000000000024, 30.100000000000154, 6.900000000000188, 34.50000000000022, 42.00000000000033, 44.60000000000037, 27.500000000000135, 23.000000000000036, 38.70000000000028, 33.4000000000002, 22.500000000000018, 41.60000000000032, 37.40000000000026, 32.30000000000018, 22.700000000000028, 37.80000000000027, 35.30000000000023, 17.399999999999952, 1.999999999999934, 15.799999999999969, 31.200000000000166, 34.200000000000216, 3.999999999999957, -16.299999999999947, 31.40000000000048, 32.700000000000195, 18.000000000000004, 38.50000000000028, 39.50000000000029, 32.300000000000196, 37.80000000000027, 32.30000000000018, -15.199999999999777, 33.3000000000002, 11.600000000000101, 35.10000000000023, 35.600000000000236, 51.40000000000049, 40.2000000000003, 44.70000000000038, 33.400000000000205, 20.499999999999986, 24.000000000000078, 26.800000000000086, 31.400000000000176, 10.299999999999907, 33.3000000000002, 29.000000000000128, 23.60000000000023, 26.400000000000095, 55.70000000000048, 21.699999999999996, 7.000000000000149, 32.20000000000018, 20.2, 29.000000000000128, 39.700000000000294, 33.70000000000021, 32.30000000000018, 24.700000000000056, 33.400000000000205, 19.09999999999995, -9.79999999999964, 43.10000000000035, 49.000000000000455, 35.600000000000236, 15.000000000000004, 39.40000000000029, 13.599999999999984, 51.20000000000049, 38.90000000000028, 16.499999999999947, 46.200000000000415, 29.90000000000014, 60.600000000000506, 38.20000000000029, 5.700000000000182, 32.30000000000018, 40.0000000000003, 20.199999999999992, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, -30.699999999999775, -70.30000000000024, 2.599999999999961, 13.699999999999964, 5.299999999999965, -68.19999999999983, -12.699999999999815, 13.699999999999964, 5.89999999999997, 4.999999999999966, 11.599999999999964, 19.40000000000001, 7.399999999999965, -70.29999999999987, 3.1999999999999673, 7.399999999999965, 17.899999999999984, 5.299999999999967, -5.1999999999999265, -1.0000000000000187, -26.199999999999747, -26.199999999999985, -40.89999999999989, 13.699999999999964, 3.1999999999999615, -17.79999999999974, 11.599999999999964, 20.000000000000014, 5.299999999999965, 11.599999999999964, 9.499999999999964, -0.7000000000000063, -0.40000000000001346, 7.399999999999965, 20.000000000000014, 11.899999999999967, 15.199999999999966, 20.000000000000014, -9.09999999999987, 9.499999999999964, 2.5999999999999646, 37.10000000000025, -83.20000000000009, 13.699999999999964, 15.799999999999963, 13.699999999999955, 17.299999999999976, 24.80000000000009, 15.799999999999963, 4.999999999999966, 9.499999999999964, -42.99999999999977, 7.99999999999997, 13.699999999999964, 20.000000000000014, 13.699999999999964, 13.699999999999964, 21.80000000000004, -28.29999999999975, 20.000000000000014, 20.600000000000026, 7.399999999999965, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -28.299999999999756, 15.799999999999963, 20.000000000000014, -15.699999999999747, 20.000000000000014, 13.699999999999964, -28.29999999999975, -52.89999999999977, 17.899999999999988, 15.799999999999963, -21.999999999999844, 15.799999999999963, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -72.40000000000055, -25.59999999999978, -7.299999999999912, -63.99999999999988, -5.1999999999997994, 11.599999999999964, 20.000000000000014, -7.299999999999891, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 21.80000000000004, 13.699999999999964, 15.799999999999963, 9.499999999999977, 20.000000000000014, 15.799999999999963, 20.000000000000014, 5.299999999999965, 7.399999999999965, -76.60000000000021, 20.000000000000014, 5.299999999999965, 11.599999999999964, -45.999999999999915, 20.000000000000014, 1.0999999999999865, 13.699999999999964, 17.899999999999988, 13.699999999999964, 31.700000000000212, 22.700000000000053, 9.499999999999964, -25.299999999999763, 20.000000000000014, 7.399999999999965, 20.000000000000014, -42.99999999999979, 9.499999999999964, -6.700000000000035, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 27.200000000000134, -17.79999999999974, -21.9999999999998, 5.299999999999965, 20.000000000000014, 5.299999999999965, 17.899999999999988, 1.0999999999999617, -15.700000000000015, 20.300000000000022, -34.59999999999975, 20.000000000000014, 1.9999999999999607, 31.70000000000022, 3.1999999999999615, 9.499999999999964, -24.099999999999746, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 5.299999999999965, -3.099999999999958, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 17.899999999999984, 20.000000000000014, -1.2999999999999847, 7.399999999999965, 17.899999999999988, 22.700000000000053, -21.999999999999744, 7.399999999999965, 20.000000000000014, 9.499999999999964, -9.39999999999988, -22.899999999999757, -58.900000000000524, 17.899999999999988, 18.19999999999999, 13.99999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, -19.899999999999743, 8.899999999999967, 20.000000000000014, 16.399999999999967, 3.1999999999999615, -13.599999999999808, 27.200000000000134, 20.000000000000014, 13.699999999999964, 15.199999999999964, 13.399999999999965, -19.89999999999975, -1.8999999999999853, 28.100000000000158, 5.299999999999965, 11.599999999999964, -5.199999999999941, 39.80000000000025, 17.899999999999977, 5.299999999999965, -3.099999999999958, -5.1999999999999265, 13.699999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, -3.100000000000063, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [22.0, 28.0, 10.0, 43.0, 3.0, 7.0, 42.0, 19.0, 8.0, 6.0, 8.0, 4.0, 6.0, 5.0, 25.0, 26.0, 7.0, 0.0, 12.0, 7.0, 2.0, 31.0, 43.0, 5.0, 5.0, 8.0, 4.0, 18.0, 7.0, 7.0, 5.0, 4.0, 19.0, 19.0, 0.0, 6.0, 4.0, 6.0, 12.0, 13.0, 5.0, 13.0, 18.0, 35.0, 2.0, 3.0, 8.0, 3.0, 2.0, 2.0, 9.0, 4.0, 30.0, 28.0, 3.0, 2.0, 3.0, 3.0, 13.0, 16.0, 1.0, 0.0, 5.0, 5.0, 3.0, 4.0, 18.0, 13.0, 0.0, 2.0, 14.0, 17.0, 23.0, 9.0, 21.0, 16.0, 2.0, 20.0, 6.0, 2.0, 3.0, 8.0, 52.0, 50.0, 7.0, 48.0, 25.0, 0.0, 7.0, 13.0, 12.0, 8.0, 4.0, 5.0, 3.0, 1.0, 3.0, 4.0, 2.0, 0.0, 7.0, 0.0, 8.0, 46.0, 1.0, 7.0, 10.0, 36.0, 7.0, 7.0, 1.0, 3.0, 3.0, 3.0, 5.0, 3.0, 25.0, 25.0, 6.0, 0.0, 24.0, 30.0, 14.0, 3.0, 4.0, 8.0, 18.0, 4.0, 7.0, 20.0, 1.0, 7.0, 8.0, 2.0, 2.0, 17.0, 15.0, 26.0, 11.0, 11.0, 9.0, 0.0, 9.0, 21.0, 8.0, 1.0, 7.0, 11.0, 10.0, 0.0, 4.0, 2.0, 11.0, 4.0, 1.0, 6.0, 17.0, 7.0, 5.0, 1.0, 5.0, 14.0, 32.0, 40.0, 4.0, 3.0, 7.0, 8.0, 0.0, 4.0, 19.0, 7.0, 3.0, 0.0, 20.0, 4.0, 1.0, 3.0, 3.0, 7.0, 15.0, 8.0, 13.0, 7.0, 6.0, 7.0, 15.0, 11.0, 8.0, 7.0, 2.0, 12.0, 4.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8408920144403441, "mean_inference_ms": 2.197940074733942, "mean_action_processing_ms": 0.35035214806886456, "mean_env_wait_ms": 0.27961873090110806, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004004359245300293, "StateBufferConnector_ms": 0.0036875009536743164, "ViewRequirementAgentConnector_ms": 0.09201467037200928}, "num_episodes": 23, "episode_return_max": 60.600000000000506, "episode_return_min": -19.899999999999675, "episode_return_mean": 27.20700000000019, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.9103563802084, "num_env_steps_trained_throughput_per_sec": 353.9103563802084, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 11621.099, "restore_workers_time_ms": 0.019, "training_step_time_ms": 11621.043, "sample_time_ms": 1887.619, "learn_time_ms": 9718.715, "learn_throughput": 411.577, "synch_weights_time_ms": 12.954}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-05-36", "timestamp": 1723647936, "time_this_iter_s": 11.343439102172852, "time_total_s": 1103.5333015918732, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32edea0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1103.5333015918732, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 45.587500000000006, "ram_util_percent": 82.7875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.397630489274623, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.24267501533575042, "policy_loss": -0.01020945538150728, "vf_loss": 0.25263296032346605, "vf_explained_var": -0.032764884971437, "kl": 0.00706575373272018, "entropy": 1.1032738264275606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.178848733678066, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.19216974589147695, "policy_loss": -0.005501043897986944, "vf_loss": 0.19740674373097522, "vf_explained_var": 0.2799407303333282, "kl": 0.014082476899464404, "entropy": 0.4805537810401311, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 60.600000000000506, "episode_reward_min": -16.299999999999947, "episode_reward_mean": 29.85300000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -83.20000000000009, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000025, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": 6.05150000000002, "predator_policy": 8.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.10000000000026, 35.90000000000024, 30.100000000000154, 6.900000000000188, 34.50000000000022, 42.00000000000033, 44.60000000000037, 27.500000000000135, 23.000000000000036, 38.70000000000028, 33.4000000000002, 22.500000000000018, 41.60000000000032, 37.40000000000026, 32.30000000000018, 22.700000000000028, 37.80000000000027, 35.30000000000023, 17.399999999999952, 1.999999999999934, 15.799999999999969, 31.200000000000166, 34.200000000000216, 3.999999999999957, -16.299999999999947, 31.40000000000048, 32.700000000000195, 18.000000000000004, 38.50000000000028, 39.50000000000029, 32.300000000000196, 37.80000000000027, 32.30000000000018, -15.199999999999777, 33.3000000000002, 11.600000000000101, 35.10000000000023, 35.600000000000236, 51.40000000000049, 40.2000000000003, 44.70000000000038, 33.400000000000205, 20.499999999999986, 24.000000000000078, 26.800000000000086, 31.400000000000176, 10.299999999999907, 33.3000000000002, 29.000000000000128, 23.60000000000023, 26.400000000000095, 55.70000000000048, 21.699999999999996, 7.000000000000149, 32.20000000000018, 20.2, 29.000000000000128, 39.700000000000294, 33.70000000000021, 32.30000000000018, 24.700000000000056, 33.400000000000205, 19.09999999999995, -9.79999999999964, 43.10000000000035, 49.000000000000455, 35.600000000000236, 15.000000000000004, 39.40000000000029, 13.599999999999984, 51.20000000000049, 38.90000000000028, 16.499999999999947, 46.200000000000415, 29.90000000000014, 60.600000000000506, 38.20000000000029, 5.700000000000182, 32.30000000000018, 40.0000000000003, 20.199999999999992, 40.0000000000003, 37.90000000000027, 38.80000000000028, 37.80000000000027, 33.000000000000206, 23.500000000000032, 32.30000000000018, 37.80000000000027, 23.60000000000003, 37.700000000000266, 30.80000000000016, 35.600000000000236, 38.90000000000028, 36.300000000000246, 35.20000000000023, 27.300000000000097, 34.40000000000022, 47.000000000000426, 13.60000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.899999999999967, 15.199999999999966, 20.000000000000014, -9.09999999999987, 9.499999999999964, 2.5999999999999646, 37.10000000000025, -83.20000000000009, 13.699999999999964, 15.799999999999963, 13.699999999999955, 17.299999999999976, 24.80000000000009, 15.799999999999963, 4.999999999999966, 9.499999999999964, -42.99999999999977, 7.99999999999997, 13.699999999999964, 20.000000000000014, 13.699999999999964, 13.699999999999964, 21.80000000000004, -28.29999999999975, 20.000000000000014, 20.600000000000026, 7.399999999999965, 20.000000000000014, 11.599999999999964, 13.699999999999964, 20.000000000000014, -28.299999999999756, 15.799999999999963, 20.000000000000014, -15.699999999999747, 20.000000000000014, 13.699999999999964, -28.29999999999975, -52.89999999999977, 17.899999999999988, 15.799999999999963, -21.999999999999844, 15.799999999999963, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -72.40000000000055, -25.59999999999978, -7.299999999999912, -63.99999999999988, -5.1999999999997994, 11.599999999999964, 20.000000000000014, -7.299999999999891, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 21.80000000000004, 13.699999999999964, 15.799999999999963, 9.499999999999977, 20.000000000000014, 15.799999999999963, 20.000000000000014, 5.299999999999965, 7.399999999999965, -76.60000000000021, 20.000000000000014, 5.299999999999965, 11.599999999999964, -45.999999999999915, 20.000000000000014, 1.0999999999999865, 13.699999999999964, 17.899999999999988, 13.699999999999964, 31.700000000000212, 22.700000000000053, 9.499999999999964, -25.299999999999763, 20.000000000000014, 7.399999999999965, 20.000000000000014, -42.99999999999979, 9.499999999999964, -6.700000000000035, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 27.200000000000134, -17.79999999999974, -21.9999999999998, 5.299999999999965, 20.000000000000014, 5.299999999999965, 17.899999999999988, 1.0999999999999617, -15.700000000000015, 20.300000000000022, -34.59999999999975, 20.000000000000014, 1.9999999999999607, 31.70000000000022, 3.1999999999999615, 9.499999999999964, -24.099999999999746, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 5.299999999999965, -3.099999999999958, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 17.899999999999984, 20.000000000000014, -1.2999999999999847, 7.399999999999965, 17.899999999999988, 22.700000000000053, -21.999999999999744, 7.399999999999965, 20.000000000000014, 9.499999999999964, -9.39999999999988, -22.899999999999757, -58.900000000000524, 17.899999999999988, 18.19999999999999, 13.99999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, -19.899999999999743, 8.899999999999967, 20.000000000000014, 16.399999999999967, 3.1999999999999615, -13.599999999999808, 27.200000000000134, 20.000000000000014, 13.699999999999964, 15.199999999999964, 13.399999999999965, -19.89999999999975, -1.8999999999999853, 28.100000000000158, 5.299999999999965, 11.599999999999964, -5.199999999999941, 39.80000000000025, 17.899999999999977, 5.299999999999965, -3.099999999999958, -5.1999999999999265, 13.699999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, -3.100000000000063, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 15.799999999999963, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 7.399999999999965, -19.899999999999743, 13.699999999999964, 11.599999999999964, 15.799999999999963, 20.000000000000014, -0.9999999999999846, 11.599999999999964, 15.799999999999963, 8.899999999999967, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 19.100000000000005, 7.399999999999965, 21.80000000000004, 13.699999999999964, -6.399999999999908, 20.000000000000014, 7.399999999999965, 15.799999999999963, 21.20000000000003, -17.79999999999974, 7.399999999999965], "policy_predator_policy_reward": [4.0, 6.0, 12.0, 13.0, 5.0, 13.0, 18.0, 35.0, 2.0, 3.0, 8.0, 3.0, 2.0, 2.0, 9.0, 4.0, 30.0, 28.0, 3.0, 2.0, 3.0, 3.0, 13.0, 16.0, 1.0, 0.0, 5.0, 5.0, 3.0, 4.0, 18.0, 13.0, 0.0, 2.0, 14.0, 17.0, 23.0, 9.0, 21.0, 16.0, 2.0, 20.0, 6.0, 2.0, 3.0, 8.0, 52.0, 50.0, 7.0, 48.0, 25.0, 0.0, 7.0, 13.0, 12.0, 8.0, 4.0, 5.0, 3.0, 1.0, 3.0, 4.0, 2.0, 0.0, 7.0, 0.0, 8.0, 46.0, 1.0, 7.0, 10.0, 36.0, 7.0, 7.0, 1.0, 3.0, 3.0, 3.0, 5.0, 3.0, 25.0, 25.0, 6.0, 0.0, 24.0, 30.0, 14.0, 3.0, 4.0, 8.0, 18.0, 4.0, 7.0, 20.0, 1.0, 7.0, 8.0, 2.0, 2.0, 17.0, 15.0, 26.0, 11.0, 11.0, 9.0, 0.0, 9.0, 21.0, 8.0, 1.0, 7.0, 11.0, 10.0, 0.0, 4.0, 2.0, 11.0, 4.0, 1.0, 6.0, 17.0, 7.0, 5.0, 1.0, 5.0, 14.0, 32.0, 40.0, 4.0, 3.0, 7.0, 8.0, 0.0, 4.0, 19.0, 7.0, 3.0, 0.0, 20.0, 4.0, 1.0, 3.0, 3.0, 7.0, 15.0, 8.0, 13.0, 7.0, 6.0, 7.0, 15.0, 11.0, 8.0, 7.0, 2.0, 12.0, 4.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 11.0, 10.0, 1.0, 2.0, 0.0, 2.0, 8.0, 6.0, 18.0, 18.0, 3.0, 4.0, 0.0, 2.0, 3.0, 10.0, 9.0, 4.0, 4.0, 12.0, 4.0, 0.0, 1.0, 0.0, 6.0, 8.0, 6.0, 0.0, 7.0, 13.0, 1.0, 6.0, 0.0, 10.0, 18.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.840022740584356, "mean_inference_ms": 2.195080919627243, "mean_action_processing_ms": 0.3499059720412136, "mean_env_wait_ms": 0.27928526284336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004448652267456055, "StateBufferConnector_ms": 0.0031518936157226562, "ViewRequirementAgentConnector_ms": 0.09054934978485107}, "num_episodes": 18, "episode_return_max": 60.600000000000506, "episode_return_min": -16.299999999999947, "episode_return_mean": 29.85300000000019, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.8855953647229, "num_env_steps_trained_throughput_per_sec": 364.8855953647229, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 11543.781, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11543.727, "sample_time_ms": 1800.544, "learn_time_ms": 9728.997, "learn_throughput": 411.142, "synch_weights_time_ms": 12.701}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-05-47", "timestamp": 1723647947, "time_this_iter_s": 11.002094984054565, "time_total_s": 1114.5353965759277, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b69c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1114.5353965759277, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 46.580000000000005, "ram_util_percent": 82.89333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3010661655554066, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3496199727068574, "policy_loss": -0.013100807022589145, "vf_loss": 0.3624473211795299, "vf_explained_var": -0.05693665588343585, "kl": 0.007682314919201566, "entropy": 1.0523614471236233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1125699130630997, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.32315886857175324, "policy_loss": -0.0061417054471180395, "vf_loss": 0.32903366973032316, "vf_explained_var": 0.11785469862519118, "kl": 0.014234888176345049, "entropy": 0.42785555020211236, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 60.600000000000506, "episode_reward_min": -16.299999999999947, "episode_reward_mean": 30.435000000000194, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -76.60000000000021, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000025, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": 6.852500000000018, "predator_policy": 8.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.399999999999952, 1.999999999999934, 15.799999999999969, 31.200000000000166, 34.200000000000216, 3.999999999999957, -16.299999999999947, 31.40000000000048, 32.700000000000195, 18.000000000000004, 38.50000000000028, 39.50000000000029, 32.300000000000196, 37.80000000000027, 32.30000000000018, -15.199999999999777, 33.3000000000002, 11.600000000000101, 35.10000000000023, 35.600000000000236, 51.40000000000049, 40.2000000000003, 44.70000000000038, 33.400000000000205, 20.499999999999986, 24.000000000000078, 26.800000000000086, 31.400000000000176, 10.299999999999907, 33.3000000000002, 29.000000000000128, 23.60000000000023, 26.400000000000095, 55.70000000000048, 21.699999999999996, 7.000000000000149, 32.20000000000018, 20.2, 29.000000000000128, 39.700000000000294, 33.70000000000021, 32.30000000000018, 24.700000000000056, 33.400000000000205, 19.09999999999995, -9.79999999999964, 43.10000000000035, 49.000000000000455, 35.600000000000236, 15.000000000000004, 39.40000000000029, 13.599999999999984, 51.20000000000049, 38.90000000000028, 16.499999999999947, 46.200000000000415, 29.90000000000014, 60.600000000000506, 38.20000000000029, 5.700000000000182, 32.30000000000018, 40.0000000000003, 20.199999999999992, 40.0000000000003, 37.90000000000027, 38.80000000000028, 37.80000000000027, 33.000000000000206, 23.500000000000032, 32.30000000000018, 37.80000000000027, 23.60000000000003, 37.700000000000266, 30.80000000000016, 35.600000000000236, 38.90000000000028, 36.300000000000246, 35.20000000000023, 27.300000000000097, 34.40000000000022, 47.000000000000426, 13.60000000000004, 35.600000000000236, 50.90000000000048, 41.200000000000315, 36.60000000000025, 25.70000000000007, 44.50000000000038, 39.800000000000296, 38.60000000000028, 30.200000000000145, 25.900000000000084, 34.50000000000022, 37.600000000000264, 32.30000000000018, 34.50000000000022, 37.700000000000266, 31.800000000000185, 29.600000000000144, 34.50000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, -28.29999999999975, -52.89999999999977, 17.899999999999988, 15.799999999999963, -21.999999999999844, 15.799999999999963, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -72.40000000000055, -25.59999999999978, -7.299999999999912, -63.99999999999988, -5.1999999999997994, 11.599999999999964, 20.000000000000014, -7.299999999999891, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 21.80000000000004, 13.699999999999964, 15.799999999999963, 9.499999999999977, 20.000000000000014, 15.799999999999963, 20.000000000000014, 5.299999999999965, 7.399999999999965, -76.60000000000021, 20.000000000000014, 5.299999999999965, 11.599999999999964, -45.999999999999915, 20.000000000000014, 1.0999999999999865, 13.699999999999964, 17.899999999999988, 13.699999999999964, 31.700000000000212, 22.700000000000053, 9.499999999999964, -25.299999999999763, 20.000000000000014, 7.399999999999965, 20.000000000000014, -42.99999999999979, 9.499999999999964, -6.700000000000035, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 27.200000000000134, -17.79999999999974, -21.9999999999998, 5.299999999999965, 20.000000000000014, 5.299999999999965, 17.899999999999988, 1.0999999999999617, -15.700000000000015, 20.300000000000022, -34.59999999999975, 20.000000000000014, 1.9999999999999607, 31.70000000000022, 3.1999999999999615, 9.499999999999964, -24.099999999999746, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 5.299999999999965, -3.099999999999958, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 17.899999999999984, 20.000000000000014, -1.2999999999999847, 7.399999999999965, 17.899999999999988, 22.700000000000053, -21.999999999999744, 7.399999999999965, 20.000000000000014, 9.499999999999964, -9.39999999999988, -22.899999999999757, -58.900000000000524, 17.899999999999988, 18.19999999999999, 13.99999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, -19.899999999999743, 8.899999999999967, 20.000000000000014, 16.399999999999967, 3.1999999999999615, -13.599999999999808, 27.200000000000134, 20.000000000000014, 13.699999999999964, 15.199999999999964, 13.399999999999965, -19.89999999999975, -1.8999999999999853, 28.100000000000158, 5.299999999999965, 11.599999999999964, -5.199999999999941, 39.80000000000025, 17.899999999999977, 5.299999999999965, -3.099999999999958, -5.1999999999999265, 13.699999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, -3.100000000000063, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 15.799999999999963, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 7.399999999999965, -19.899999999999743, 13.699999999999964, 11.599999999999964, 15.799999999999963, 20.000000000000014, -0.9999999999999846, 11.599999999999964, 15.799999999999963, 8.899999999999967, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 19.100000000000005, 7.399999999999965, 21.80000000000004, 13.699999999999964, -6.399999999999908, 20.000000000000014, 7.399999999999965, 15.799999999999963, 21.20000000000003, -17.79999999999974, 7.399999999999965, 13.699999999999964, 17.899999999999988, 35.30000000000025, 11.599999999999964, 28.100000000000147, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 17.899999999999988, -5.1999999999999265, -35.799999999999756, 26.300000000000114, 20.90000000000003, 17.899999999999988, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, -2.4999999999999893, 7.399999999999965, 11.599999999999964, 17.899999999999988, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 17.899999999999988, 15.799999999999963, 20.000000000000014, -26.199999999999747, 11.599999999999964, -0.9999999999999917, 15.799999999999963, 13.699999999999964], "policy_predator_policy_reward": [23.0, 9.0, 21.0, 16.0, 2.0, 20.0, 6.0, 2.0, 3.0, 8.0, 52.0, 50.0, 7.0, 48.0, 25.0, 0.0, 7.0, 13.0, 12.0, 8.0, 4.0, 5.0, 3.0, 1.0, 3.0, 4.0, 2.0, 0.0, 7.0, 0.0, 8.0, 46.0, 1.0, 7.0, 10.0, 36.0, 7.0, 7.0, 1.0, 3.0, 3.0, 3.0, 5.0, 3.0, 25.0, 25.0, 6.0, 0.0, 24.0, 30.0, 14.0, 3.0, 4.0, 8.0, 18.0, 4.0, 7.0, 20.0, 1.0, 7.0, 8.0, 2.0, 2.0, 17.0, 15.0, 26.0, 11.0, 11.0, 9.0, 0.0, 9.0, 21.0, 8.0, 1.0, 7.0, 11.0, 10.0, 0.0, 4.0, 2.0, 11.0, 4.0, 1.0, 6.0, 17.0, 7.0, 5.0, 1.0, 5.0, 14.0, 32.0, 40.0, 4.0, 3.0, 7.0, 8.0, 0.0, 4.0, 19.0, 7.0, 3.0, 0.0, 20.0, 4.0, 1.0, 3.0, 3.0, 7.0, 15.0, 8.0, 13.0, 7.0, 6.0, 7.0, 15.0, 11.0, 8.0, 7.0, 2.0, 12.0, 4.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 11.0, 10.0, 1.0, 2.0, 0.0, 2.0, 8.0, 6.0, 18.0, 18.0, 3.0, 4.0, 0.0, 2.0, 3.0, 10.0, 9.0, 4.0, 4.0, 12.0, 4.0, 0.0, 1.0, 0.0, 6.0, 8.0, 6.0, 0.0, 7.0, 13.0, 1.0, 6.0, 0.0, 10.0, 18.0, 6.0, 3.0, 1.0, 4.0, 0.0, 9.0, 3.0, 4.0, 1.0, 1.0, 12.0, 27.0, 27.0, 0.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 15.0, 1.0, 4.0, 4.0, 2.0, 0.0, 7.0, 5.0, 0.0, 1.0, 3.0, 21.0, 17.0, 14.0, 5.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.838721696869317, "mean_inference_ms": 2.1908751547193384, "mean_action_processing_ms": 0.3492828626493221, "mean_env_wait_ms": 0.27874268591909385, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004858613014221191, "StateBufferConnector_ms": 0.0031375885009765625, "ViewRequirementAgentConnector_ms": 0.0981215238571167}, "num_episodes": 18, "episode_return_max": 60.600000000000506, "episode_return_min": -16.299999999999947, "episode_return_mean": 30.435000000000194, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.66304005413417, "num_env_steps_trained_throughput_per_sec": 355.66304005413417, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 11485.213, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11485.158, "sample_time_ms": 1706.669, "learn_time_ms": 9764.035, "learn_throughput": 409.667, "synch_weights_time_ms": 12.888}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-05-59", "timestamp": 1723647959, "time_this_iter_s": 11.280884981155396, "time_total_s": 1125.8162815570831, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32ede2f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1125.8162815570831, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 46.306250000000006, "ram_util_percent": 82.94375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7274173672237094, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4227039488150107, "policy_loss": -0.010982453014957842, "vf_loss": 0.43335185453699776, "vf_explained_var": -0.12043887603850592, "kl": 0.009398534701479095, "entropy": 1.0963086874396712, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2020868314321709, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.25591504278361166, "policy_loss": -0.006121985493449583, "vf_loss": 0.26186153735896506, "vf_explained_var": 0.21569179082042955, "kl": 0.009359528552501958, "entropy": 0.46708179682335527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 60.600000000000506, "episode_reward_min": -9.79999999999964, "episode_reward_mean": 32.0820000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -58.900000000000524, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000025, "predator_policy": 40.0}, "policy_reward_mean": {"prey_policy": 8.771000000000019, "predator_policy": 7.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.70000000000038, 33.400000000000205, 20.499999999999986, 24.000000000000078, 26.800000000000086, 31.400000000000176, 10.299999999999907, 33.3000000000002, 29.000000000000128, 23.60000000000023, 26.400000000000095, 55.70000000000048, 21.699999999999996, 7.000000000000149, 32.20000000000018, 20.2, 29.000000000000128, 39.700000000000294, 33.70000000000021, 32.30000000000018, 24.700000000000056, 33.400000000000205, 19.09999999999995, -9.79999999999964, 43.10000000000035, 49.000000000000455, 35.600000000000236, 15.000000000000004, 39.40000000000029, 13.599999999999984, 51.20000000000049, 38.90000000000028, 16.499999999999947, 46.200000000000415, 29.90000000000014, 60.600000000000506, 38.20000000000029, 5.700000000000182, 32.30000000000018, 40.0000000000003, 20.199999999999992, 40.0000000000003, 37.90000000000027, 38.80000000000028, 37.80000000000027, 33.000000000000206, 23.500000000000032, 32.30000000000018, 37.80000000000027, 23.60000000000003, 37.700000000000266, 30.80000000000016, 35.600000000000236, 38.90000000000028, 36.300000000000246, 35.20000000000023, 27.300000000000097, 34.40000000000022, 47.000000000000426, 13.60000000000004, 35.600000000000236, 50.90000000000048, 41.200000000000315, 36.60000000000025, 25.70000000000007, 44.50000000000038, 39.800000000000296, 38.60000000000028, 30.200000000000145, 25.900000000000084, 34.50000000000022, 37.600000000000264, 32.30000000000018, 34.50000000000022, 37.700000000000266, 31.800000000000185, 29.600000000000144, 34.50000000000022, 34.50000000000022, 35.30000000000023, 33.400000000000205, 31.700000000000177, 49.100000000000456, 16.200000000000006, 30.100000000000144, 34.40000000000022, 33.00000000000019, 24.600000000000048, 35.000000000000256, 37.80000000000027, 32.20000000000018, 38.60000000000028, 15.799999999999923, 34.30000000000022, 36.70000000000025, 38.400000000000276, 28.000000000000117, 26.800000000000086, 48.00000000000043, 13.60000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-25.299999999999763, 20.000000000000014, 7.399999999999965, 20.000000000000014, -42.99999999999979, 9.499999999999964, -6.700000000000035, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 27.200000000000134, -17.79999999999974, -21.9999999999998, 5.299999999999965, 20.000000000000014, 5.299999999999965, 17.899999999999988, 1.0999999999999617, -15.700000000000015, 20.300000000000022, -34.59999999999975, 20.000000000000014, 1.9999999999999607, 31.70000000000022, 3.1999999999999615, 9.499999999999964, -24.099999999999746, 1.0999999999999865, 3.1999999999999615, 20.000000000000014, 5.299999999999965, -3.099999999999958, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 17.899999999999984, 20.000000000000014, -1.2999999999999847, 7.399999999999965, 17.899999999999988, 22.700000000000053, -21.999999999999744, 7.399999999999965, 20.000000000000014, 9.499999999999964, -9.39999999999988, -22.899999999999757, -58.900000000000524, 17.899999999999988, 18.19999999999999, 13.99999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, -19.899999999999743, 8.899999999999967, 20.000000000000014, 16.399999999999967, 3.1999999999999615, -13.599999999999808, 27.200000000000134, 20.000000000000014, 13.699999999999964, 15.199999999999964, 13.399999999999965, -19.89999999999975, -1.8999999999999853, 28.100000000000158, 5.299999999999965, 11.599999999999964, -5.199999999999941, 39.80000000000025, 17.899999999999977, 5.299999999999965, -3.099999999999958, -5.1999999999999265, 13.699999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, -3.100000000000063, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 15.799999999999963, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 7.399999999999965, -19.899999999999743, 13.699999999999964, 11.599999999999964, 15.799999999999963, 20.000000000000014, -0.9999999999999846, 11.599999999999964, 15.799999999999963, 8.899999999999967, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 19.100000000000005, 7.399999999999965, 21.80000000000004, 13.699999999999964, -6.399999999999908, 20.000000000000014, 7.399999999999965, 15.799999999999963, 21.20000000000003, -17.79999999999974, 7.399999999999965, 13.699999999999964, 17.899999999999988, 35.30000000000025, 11.599999999999964, 28.100000000000147, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 17.899999999999988, -5.1999999999999265, -35.799999999999756, 26.300000000000114, 20.90000000000003, 17.899999999999988, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, -2.4999999999999893, 7.399999999999965, 11.599999999999964, 17.899999999999988, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 17.899999999999988, 15.799999999999963, 20.000000000000014, -26.199999999999747, 11.599999999999964, -0.9999999999999917, 15.799999999999963, 13.699999999999964, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, 7.399999999999965, -6.699999999999907, 18.8, 23.30000000000006, 1.0999999999999865, 1.0999999999999865, 11.599999999999964, 9.499999999999964, 11.599999999999964, 15.799999999999963, 9.199999999999966, 15.799999999999963, 11.599999999999964, -0.9999999999999846, 11.599999999999964, 4.399999999999973, 15.799999999999963, 20.000000000000014, 13.099999999999966, 1.0999999999999865, 20.000000000000014, 11.599999999999964, -17.799999999999763, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, 7.399999999999965, 20.000000000000014, 16.699999999999967, -15.699999999999747, 3.1999999999999615, 11.599999999999964, 29.90000000000018, 1.0999999999999865, -26.199999999999747, 15.799999999999963], "policy_predator_policy_reward": [25.0, 25.0, 6.0, 0.0, 24.0, 30.0, 14.0, 3.0, 4.0, 8.0, 18.0, 4.0, 7.0, 20.0, 1.0, 7.0, 8.0, 2.0, 2.0, 17.0, 15.0, 26.0, 11.0, 11.0, 9.0, 0.0, 9.0, 21.0, 8.0, 1.0, 7.0, 11.0, 10.0, 0.0, 4.0, 2.0, 11.0, 4.0, 1.0, 6.0, 17.0, 7.0, 5.0, 1.0, 5.0, 14.0, 32.0, 40.0, 4.0, 3.0, 7.0, 8.0, 0.0, 4.0, 19.0, 7.0, 3.0, 0.0, 20.0, 4.0, 1.0, 3.0, 3.0, 7.0, 15.0, 8.0, 13.0, 7.0, 6.0, 7.0, 15.0, 11.0, 8.0, 7.0, 2.0, 12.0, 4.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 11.0, 10.0, 1.0, 2.0, 0.0, 2.0, 8.0, 6.0, 18.0, 18.0, 3.0, 4.0, 0.0, 2.0, 3.0, 10.0, 9.0, 4.0, 4.0, 12.0, 4.0, 0.0, 1.0, 0.0, 6.0, 8.0, 6.0, 0.0, 7.0, 13.0, 1.0, 6.0, 0.0, 10.0, 18.0, 6.0, 3.0, 1.0, 4.0, 0.0, 9.0, 3.0, 4.0, 1.0, 1.0, 12.0, 27.0, 27.0, 0.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 15.0, 1.0, 4.0, 4.0, 2.0, 0.0, 7.0, 5.0, 0.0, 1.0, 3.0, 21.0, 17.0, 14.0, 5.0, 2.0, 3.0, 5.0, 0.0, 3.0, 7.0, 4.0, 2.0, 16.0, 15.0, 0.0, 7.0, 9.0, 5.0, 3.0, 6.0, 4.0, 3.0, 6.0, 2.0, 4.0, 10.0, 2.0, 17.0, 0.0, 2.0, 9.0, 9.0, 4.0, 3.0, 22.0, 0.0, 7.0, 2.0, 3.0, 0.0, 6.0, 5.0, 17.0, 10.0, 8.0, 4.0, 9.0, 8.0, 2.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8362689049151963, "mean_inference_ms": 2.1842562224934685, "mean_action_processing_ms": 0.3482858769228994, "mean_env_wait_ms": 0.2778655627269005, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006873130798339844, "StateBufferConnector_ms": 0.0032106637954711914, "ViewRequirementAgentConnector_ms": 0.10210609436035156}, "num_episodes": 22, "episode_return_max": 60.600000000000506, "episode_return_min": -9.79999999999964, "episode_return_mean": 32.0820000000002, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.61099429575495, "num_env_steps_trained_throughput_per_sec": 354.61099429575495, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 11419.801, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11419.745, "sample_time_ms": 1633.533, "learn_time_ms": 9771.651, "learn_throughput": 409.347, "synch_weights_time_ms": 12.839}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-06-10", "timestamp": 1723647970, "time_this_iter_s": 11.336234092712402, "time_total_s": 1137.1525156497955, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b1e280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1137.1525156497955, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 45.68235294117647, "ram_util_percent": 82.95882352941177}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.591883405412316, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5890592238748762, "policy_loss": -0.00927051401859711, "vf_loss": 0.5980475658541003, "vf_explained_var": 0.16315056457721366, "kl": 0.007927086566290608, "entropy": 1.1525638359564323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.426307601288513, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3186051881975598, "policy_loss": -0.004944195213023001, "vf_loss": 0.3234365256375106, "vf_explained_var": 0.37904878249244084, "kl": 0.0060190348541872985, "entropy": 0.48063018780852124, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 60.600000000000506, "episode_reward_min": -9.79999999999964, "episode_reward_mean": 32.54500000000021, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -58.900000000000524, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000025, "predator_policy": 40.0}, "policy_reward_mean": {"prey_policy": 9.612500000000015, "predator_policy": 6.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.70000000000021, 32.30000000000018, 24.700000000000056, 33.400000000000205, 19.09999999999995, -9.79999999999964, 43.10000000000035, 49.000000000000455, 35.600000000000236, 15.000000000000004, 39.40000000000029, 13.599999999999984, 51.20000000000049, 38.90000000000028, 16.499999999999947, 46.200000000000415, 29.90000000000014, 60.600000000000506, 38.20000000000029, 5.700000000000182, 32.30000000000018, 40.0000000000003, 20.199999999999992, 40.0000000000003, 37.90000000000027, 38.80000000000028, 37.80000000000027, 33.000000000000206, 23.500000000000032, 32.30000000000018, 37.80000000000027, 23.60000000000003, 37.700000000000266, 30.80000000000016, 35.600000000000236, 38.90000000000028, 36.300000000000246, 35.20000000000023, 27.300000000000097, 34.40000000000022, 47.000000000000426, 13.60000000000004, 35.600000000000236, 50.90000000000048, 41.200000000000315, 36.60000000000025, 25.70000000000007, 44.50000000000038, 39.800000000000296, 38.60000000000028, 30.200000000000145, 25.900000000000084, 34.50000000000022, 37.600000000000264, 32.30000000000018, 34.50000000000022, 37.700000000000266, 31.800000000000185, 29.600000000000144, 34.50000000000022, 34.50000000000022, 35.30000000000023, 33.400000000000205, 31.700000000000177, 49.100000000000456, 16.200000000000006, 30.100000000000144, 34.40000000000022, 33.00000000000019, 24.600000000000048, 35.000000000000256, 37.80000000000027, 32.20000000000018, 38.60000000000028, 15.799999999999923, 34.30000000000022, 36.70000000000025, 38.400000000000276, 28.000000000000117, 26.800000000000086, 48.00000000000043, 13.60000000000002, 48.40000000000044, 27.900000000000105, 32.30000000000021, 41.50000000000032, 19.60000000000001, 14.200000000000038, 19.899999999999995, 21.60000000000001, 39.000000000000284, 25.00000000000006, 39.60000000000029, 33.1000000000002, 34.50000000000022, 24.800000000000065, 29.30000000000013, 38.90000000000028, 31.200000000000166, 34.40000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -1.2999999999999847, 7.399999999999965, 17.899999999999988, 22.700000000000053, -21.999999999999744, 7.399999999999965, 20.000000000000014, 9.499999999999964, -9.39999999999988, -22.899999999999757, -58.900000000000524, 17.899999999999988, 18.19999999999999, 13.99999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, -19.899999999999743, 8.899999999999967, 20.000000000000014, 16.399999999999967, 3.1999999999999615, -13.599999999999808, 27.200000000000134, 20.000000000000014, 13.699999999999964, 15.199999999999964, 13.399999999999965, -19.89999999999975, -1.8999999999999853, 28.100000000000158, 5.299999999999965, 11.599999999999964, -5.199999999999941, 39.80000000000025, 17.899999999999977, 5.299999999999965, -3.099999999999958, -5.1999999999999265, 13.699999999999964, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.299999999999965, -3.100000000000063, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 15.799999999999963, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 7.399999999999965, -19.899999999999743, 13.699999999999964, 11.599999999999964, 15.799999999999963, 20.000000000000014, -0.9999999999999846, 11.599999999999964, 15.799999999999963, 8.899999999999967, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 19.100000000000005, 7.399999999999965, 21.80000000000004, 13.699999999999964, -6.399999999999908, 20.000000000000014, 7.399999999999965, 15.799999999999963, 21.20000000000003, -17.79999999999974, 7.399999999999965, 13.699999999999964, 17.899999999999988, 35.30000000000025, 11.599999999999964, 28.100000000000147, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 17.899999999999988, -5.1999999999999265, -35.799999999999756, 26.300000000000114, 20.90000000000003, 17.899999999999988, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, -2.4999999999999893, 7.399999999999965, 11.599999999999964, 17.899999999999988, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 17.899999999999988, 15.799999999999963, 20.000000000000014, -26.199999999999747, 11.599999999999964, -0.9999999999999917, 15.799999999999963, 13.699999999999964, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, 7.399999999999965, -6.699999999999907, 18.8, 23.30000000000006, 1.0999999999999865, 1.0999999999999865, 11.599999999999964, 9.499999999999964, 11.599999999999964, 15.799999999999963, 9.199999999999966, 15.799999999999963, 11.599999999999964, -0.9999999999999846, 11.599999999999964, 4.399999999999973, 15.799999999999963, 20.000000000000014, 13.099999999999966, 1.0999999999999865, 20.000000000000014, 11.599999999999964, -17.799999999999763, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, 7.399999999999965, 20.000000000000014, 16.699999999999967, -15.699999999999747, 3.1999999999999615, 11.599999999999964, 29.90000000000018, 1.0999999999999865, -26.199999999999747, 15.799999999999963, 29.600000000000176, 15.799999999999963, 11.599999999999964, 5.299999999999965, 15.799999999999963, 9.499999999999956, 22.700000000000053, 15.799999999999963, 7.399999999999965, -8.799999999999871, -0.9999999999999846, 3.1999999999999615, -5.199999999999934, -10.89999999999985, 17.899999999999988, -16.299999999999763, 20.000000000000014, -0.9999999999999846, -8.799999999999878, 15.799999999999963, 20.90000000000003, 13.699999999999964, -34.59999999999975, 22.700000000000053, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 2.59999999999997, 13.699999999999964, 11.599999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 23.30000000000006, 1.10000000000001], "policy_predator_policy_reward": [11.0, 4.0, 1.0, 6.0, 17.0, 7.0, 5.0, 1.0, 5.0, 14.0, 32.0, 40.0, 4.0, 3.0, 7.0, 8.0, 0.0, 4.0, 19.0, 7.0, 3.0, 0.0, 20.0, 4.0, 1.0, 3.0, 3.0, 7.0, 15.0, 8.0, 13.0, 7.0, 6.0, 7.0, 15.0, 11.0, 8.0, 7.0, 2.0, 12.0, 4.0, 3.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 11.0, 10.0, 1.0, 2.0, 0.0, 2.0, 8.0, 6.0, 18.0, 18.0, 3.0, 4.0, 0.0, 2.0, 3.0, 10.0, 9.0, 4.0, 4.0, 12.0, 4.0, 0.0, 1.0, 0.0, 6.0, 8.0, 6.0, 0.0, 7.0, 13.0, 1.0, 6.0, 0.0, 10.0, 18.0, 6.0, 3.0, 1.0, 4.0, 0.0, 9.0, 3.0, 4.0, 1.0, 1.0, 12.0, 27.0, 27.0, 0.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 15.0, 1.0, 4.0, 4.0, 2.0, 0.0, 7.0, 5.0, 0.0, 1.0, 3.0, 21.0, 17.0, 14.0, 5.0, 2.0, 3.0, 5.0, 0.0, 3.0, 7.0, 4.0, 2.0, 16.0, 15.0, 0.0, 7.0, 9.0, 5.0, 3.0, 6.0, 4.0, 3.0, 6.0, 2.0, 4.0, 10.0, 2.0, 17.0, 0.0, 2.0, 9.0, 9.0, 4.0, 3.0, 22.0, 0.0, 7.0, 2.0, 3.0, 0.0, 6.0, 5.0, 17.0, 10.0, 8.0, 4.0, 9.0, 8.0, 2.0, 22.0, 1.0, 2.0, 7.0, 4.0, 5.0, 2.0, 2.0, 1.0, 6.0, 15.0, 2.0, 10.0, 19.0, 17.0, 15.0, 5.0, 10.0, 10.0, 6.0, 12.0, 3.0, 2.0, 19.0, 26.0, 0.0, 5.0, 11.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 8.0, 1.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8340499657644564, "mean_inference_ms": 2.1782672330544073, "mean_action_processing_ms": 0.34740383512307643, "mean_env_wait_ms": 0.277111585904538, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00882875919342041, "StateBufferConnector_ms": 0.003220677375793457, "ViewRequirementAgentConnector_ms": 0.10750913619995117}, "num_episodes": 18, "episode_return_max": 60.600000000000506, "episode_return_min": -9.79999999999964, "episode_return_mean": 32.54500000000021, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.7319739273449, "num_env_steps_trained_throughput_per_sec": 349.7319739273449, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 11402.124, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11402.067, "sample_time_ms": 1583.818, "learn_time_ms": 9803.13, "learn_throughput": 408.033, "synch_weights_time_ms": 13.386}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-06-21", "timestamp": 1723647981, "time_this_iter_s": 11.484716892242432, "time_total_s": 1148.637232542038, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32edea8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1148.637232542038, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 47.5875, "ram_util_percent": 83.05}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6173718767033682, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5849456112309194, "policy_loss": -0.00228396265388087, "vf_loss": 0.587090953400053, "vf_explained_var": 0.2592892463245089, "kl": 0.00389429804954633, "entropy": 1.1303987369966255, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3706533688716787, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3907652451957344, "policy_loss": -0.005841125518812862, "vf_loss": 0.39636216099378924, "vf_explained_var": 0.5241233235313779, "kl": 0.013024508856353803, "entropy": 0.49393803511977824, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 54.200000000000465, "episode_reward_min": 13.60000000000002, "episode_reward_mean": 33.725000000000215, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -35.799999999999756, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000025, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 11.11250000000001, "predator_policy": 5.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 37.90000000000027, 38.80000000000028, 37.80000000000027, 33.000000000000206, 23.500000000000032, 32.30000000000018, 37.80000000000027, 23.60000000000003, 37.700000000000266, 30.80000000000016, 35.600000000000236, 38.90000000000028, 36.300000000000246, 35.20000000000023, 27.300000000000097, 34.40000000000022, 47.000000000000426, 13.60000000000004, 35.600000000000236, 50.90000000000048, 41.200000000000315, 36.60000000000025, 25.70000000000007, 44.50000000000038, 39.800000000000296, 38.60000000000028, 30.200000000000145, 25.900000000000084, 34.50000000000022, 37.600000000000264, 32.30000000000018, 34.50000000000022, 37.700000000000266, 31.800000000000185, 29.600000000000144, 34.50000000000022, 34.50000000000022, 35.30000000000023, 33.400000000000205, 31.700000000000177, 49.100000000000456, 16.200000000000006, 30.100000000000144, 34.40000000000022, 33.00000000000019, 24.600000000000048, 35.000000000000256, 37.80000000000027, 32.20000000000018, 38.60000000000028, 15.799999999999923, 34.30000000000022, 36.70000000000025, 38.400000000000276, 28.000000000000117, 26.800000000000086, 48.00000000000043, 13.60000000000002, 48.40000000000044, 27.900000000000105, 32.30000000000021, 41.50000000000032, 19.60000000000001, 14.200000000000038, 19.899999999999995, 21.60000000000001, 39.000000000000284, 25.00000000000006, 39.60000000000029, 33.1000000000002, 34.50000000000022, 24.800000000000065, 29.30000000000013, 38.90000000000028, 31.200000000000166, 34.40000000000026, 44.30000000000038, 32.30000000000018, 18.800000000000164, 37.700000000000266, 33.4000000000002, 35.40000000000023, 29.900000000000148, 27.900000000000105, 40.0000000000003, 35.600000000000236, 15.799999999999901, 40.500000000000306, 31.900000000000176, 42.90000000000034, 34.50000000000022, 38.80000000000028, 38.70000000000028, 36.70000000000025, 50.80000000000048, 54.200000000000465, 36.70000000000025, 38.80000000000028, 31.20000000000017], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, 15.799999999999963, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 7.399999999999965, -19.899999999999743, 13.699999999999964, 11.599999999999964, 15.799999999999963, 20.000000000000014, -0.9999999999999846, 11.599999999999964, 15.799999999999963, 8.899999999999967, -5.1999999999999265, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 17.899999999999988, 3.1999999999999615, 19.100000000000005, 7.399999999999965, 21.80000000000004, 13.699999999999964, -6.399999999999908, 20.000000000000014, 7.399999999999965, 15.799999999999963, 21.20000000000003, -17.79999999999974, 7.399999999999965, 13.699999999999964, 17.899999999999988, 35.30000000000025, 11.599999999999964, 28.100000000000147, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 17.899999999999988, -5.1999999999999265, -35.799999999999756, 26.300000000000114, 20.90000000000003, 17.899999999999988, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, -2.4999999999999893, 7.399999999999965, 11.599999999999964, 17.899999999999988, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 17.899999999999988, 15.799999999999963, 20.000000000000014, -26.199999999999747, 11.599999999999964, -0.9999999999999917, 15.799999999999963, 13.699999999999964, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, 7.399999999999965, -6.699999999999907, 18.8, 23.30000000000006, 1.0999999999999865, 1.0999999999999865, 11.599999999999964, 9.499999999999964, 11.599999999999964, 15.799999999999963, 9.199999999999966, 15.799999999999963, 11.599999999999964, -0.9999999999999846, 11.599999999999964, 4.399999999999973, 15.799999999999963, 20.000000000000014, 13.099999999999966, 1.0999999999999865, 20.000000000000014, 11.599999999999964, -17.799999999999763, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, 7.399999999999965, 20.000000000000014, 16.699999999999967, -15.699999999999747, 3.1999999999999615, 11.599999999999964, 29.90000000000018, 1.0999999999999865, -26.199999999999747, 15.799999999999963, 29.600000000000176, 15.799999999999963, 11.599999999999964, 5.299999999999965, 15.799999999999963, 9.499999999999956, 22.700000000000053, 15.799999999999963, 7.399999999999965, -8.799999999999871, -0.9999999999999846, 3.1999999999999615, -5.199999999999934, -10.89999999999985, 17.899999999999988, -16.299999999999763, 20.000000000000014, -0.9999999999999846, -8.799999999999878, 15.799999999999963, 20.90000000000003, 13.699999999999964, -34.59999999999975, 22.700000000000053, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 2.59999999999997, 13.699999999999964, 11.599999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 23.30000000000006, 1.10000000000001, 5.299999999999965, 13.999999999999968, 15.799999999999963, 9.499999999999964, 20.000000000000014, -26.200000000000045, 13.699999999999964, 20.000000000000014, 15.799999999999963, 11.599999999999964, 20.000000000000014, 7.399999999999965, -3.099999999999965, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999966, 17.899999999999988, 5.299999999999965, -11.500000000000046, 17.899999999999988, 11.599999999999968, 15.499999999999964, 7.399999999999965, 14.899999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 20.000000000000014, 17.899999999999988, 18.8, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.800000000000196, 13.699999999999964, 30.5000000000002, 13.699999999999964, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999615], "policy_predator_policy_reward": [0.0, 0.0, 11.0, 10.0, 1.0, 2.0, 0.0, 2.0, 8.0, 6.0, 18.0, 18.0, 3.0, 4.0, 0.0, 2.0, 3.0, 10.0, 9.0, 4.0, 4.0, 12.0, 4.0, 0.0, 1.0, 0.0, 6.0, 8.0, 6.0, 0.0, 7.0, 13.0, 1.0, 6.0, 0.0, 10.0, 18.0, 6.0, 3.0, 1.0, 4.0, 0.0, 9.0, 3.0, 4.0, 1.0, 1.0, 12.0, 27.0, 27.0, 0.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 15.0, 1.0, 4.0, 4.0, 2.0, 0.0, 7.0, 5.0, 0.0, 1.0, 3.0, 21.0, 17.0, 14.0, 5.0, 2.0, 3.0, 5.0, 0.0, 3.0, 7.0, 4.0, 2.0, 16.0, 15.0, 0.0, 7.0, 9.0, 5.0, 3.0, 6.0, 4.0, 3.0, 6.0, 2.0, 4.0, 10.0, 2.0, 17.0, 0.0, 2.0, 9.0, 9.0, 4.0, 3.0, 22.0, 0.0, 7.0, 2.0, 3.0, 0.0, 6.0, 5.0, 17.0, 10.0, 8.0, 4.0, 9.0, 8.0, 2.0, 22.0, 1.0, 2.0, 7.0, 4.0, 5.0, 2.0, 2.0, 1.0, 6.0, 15.0, 2.0, 10.0, 19.0, 17.0, 15.0, 5.0, 10.0, 10.0, 6.0, 12.0, 3.0, 2.0, 19.0, 26.0, 0.0, 5.0, 11.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 8.0, 1.0, 9.0, 12.0, 13.0, 2.0, 5.0, 22.0, 3.0, 3.0, 1.0, 4.0, 2.0, 6.0, 2.0, 11.0, 2.0, 4.0, 7.0, 0.0, 0.0, 1.0, 3.0, 0.0, 22.0, 7.0, 4.0, 6.0, 3.0, 3.0, 5.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 7.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8311285583160811, "mean_inference_ms": 2.17050493568982, "mean_action_processing_ms": 0.34626115020717185, "mean_env_wait_ms": 0.27615867949682077, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008502960205078125, "StateBufferConnector_ms": 0.003224015235900879, "ViewRequirementAgentConnector_ms": 0.11213254928588867}, "num_episodes": 23, "episode_return_max": 54.200000000000465, "episode_return_min": 13.60000000000002, "episode_return_mean": 33.725000000000215, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.0454376633839, "num_env_steps_trained_throughput_per_sec": 356.0454376633839, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 11363.392, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11363.334, "sample_time_ms": 1497.4, "learn_time_ms": 9850.673, "learn_throughput": 406.064, "synch_weights_time_ms": 13.471}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-06-33", "timestamp": 1723647993, "time_this_iter_s": 11.290438175201416, "time_total_s": 1159.9276707172394, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32edea1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1159.9276707172394, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 46.356249999999996, "ram_util_percent": 83.05000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3261205164370713, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7544429889441562, "policy_loss": -0.011884565512457538, "vf_loss": 0.7660784419409181, "vf_explained_var": 0.10529856451604733, "kl": 0.013996622869837841, "entropy": 1.0558124541605591, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1209116195244766, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3975022366201436, "policy_loss": -0.004258785466540348, "vf_loss": 0.4016668284696246, "vf_explained_var": 0.47563725763527803, "kl": 0.005023707855709877, "entropy": 0.45625958086321594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 54.200000000000465, "episode_reward_min": -5.399999999999837, "episode_reward_mean": 33.067000000000206, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -63.999999999999766, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000025, "predator_policy": 37.0}, "policy_reward_mean": {"prey_policy": 10.608500000000008, "predator_policy": 5.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.60000000000004, 35.600000000000236, 50.90000000000048, 41.200000000000315, 36.60000000000025, 25.70000000000007, 44.50000000000038, 39.800000000000296, 38.60000000000028, 30.200000000000145, 25.900000000000084, 34.50000000000022, 37.600000000000264, 32.30000000000018, 34.50000000000022, 37.700000000000266, 31.800000000000185, 29.600000000000144, 34.50000000000022, 34.50000000000022, 35.30000000000023, 33.400000000000205, 31.700000000000177, 49.100000000000456, 16.200000000000006, 30.100000000000144, 34.40000000000022, 33.00000000000019, 24.600000000000048, 35.000000000000256, 37.80000000000027, 32.20000000000018, 38.60000000000028, 15.799999999999923, 34.30000000000022, 36.70000000000025, 38.400000000000276, 28.000000000000117, 26.800000000000086, 48.00000000000043, 13.60000000000002, 48.40000000000044, 27.900000000000105, 32.30000000000021, 41.50000000000032, 19.60000000000001, 14.200000000000038, 19.899999999999995, 21.60000000000001, 39.000000000000284, 25.00000000000006, 39.60000000000029, 33.1000000000002, 34.50000000000022, 24.800000000000065, 29.30000000000013, 38.90000000000028, 31.200000000000166, 34.40000000000026, 44.30000000000038, 32.30000000000018, 18.800000000000164, 37.700000000000266, 33.4000000000002, 35.40000000000023, 29.900000000000148, 27.900000000000105, 40.0000000000003, 35.600000000000236, 15.799999999999901, 40.500000000000306, 31.900000000000176, 42.90000000000034, 34.50000000000022, 38.80000000000028, 38.70000000000028, 36.70000000000025, 50.80000000000048, 54.200000000000465, 36.70000000000025, 38.80000000000028, 31.20000000000017, 21.299999999999994, 29.60000000000014, 38.60000000000028, 37.50000000000026, 30.100000000000147, 34.50000000000022, 38.90000000000028, 35.40000000000023, 33.800000000000196, -5.399999999999837, 14.299999999999999, 31.200000000000166, 36.70000000000025, 38.20000000000027, 37.80000000000027, 32.30000000000018, 38.90000000000028, 38.400000000000276], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-17.79999999999974, 7.399999999999965, 13.699999999999964, 17.899999999999988, 35.30000000000025, 11.599999999999964, 28.100000000000147, 1.0999999999999865, 11.599999999999964, 20.000000000000014, 17.899999999999988, -5.1999999999999265, -35.799999999999756, 26.300000000000114, 20.90000000000003, 17.899999999999988, 20.000000000000014, 11.599999999999964, 15.799999999999963, 7.399999999999965, -2.4999999999999893, 7.399999999999965, 11.599999999999964, 17.899999999999988, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 9.499999999999964, 17.899999999999988, 15.799999999999963, 20.000000000000014, -26.199999999999747, 11.599999999999964, -0.9999999999999917, 15.799999999999963, 13.699999999999964, 20.000000000000014, 9.499999999999964, 5.299999999999965, 20.000000000000014, 9.499999999999964, 17.899999999999988, 7.399999999999965, -6.699999999999907, 18.8, 23.30000000000006, 1.0999999999999865, 1.0999999999999865, 11.599999999999964, 9.499999999999964, 11.599999999999964, 15.799999999999963, 9.199999999999966, 15.799999999999963, 11.599999999999964, -0.9999999999999846, 11.599999999999964, 4.399999999999973, 15.799999999999963, 20.000000000000014, 13.099999999999966, 1.0999999999999865, 20.000000000000014, 11.599999999999964, -17.799999999999763, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, 7.399999999999965, 20.000000000000014, 16.699999999999967, -15.699999999999747, 3.1999999999999615, 11.599999999999964, 29.90000000000018, 1.0999999999999865, -26.199999999999747, 15.799999999999963, 29.600000000000176, 15.799999999999963, 11.599999999999964, 5.299999999999965, 15.799999999999963, 9.499999999999956, 22.700000000000053, 15.799999999999963, 7.399999999999965, -8.799999999999871, -0.9999999999999846, 3.1999999999999615, -5.199999999999934, -10.89999999999985, 17.899999999999988, -16.299999999999763, 20.000000000000014, -0.9999999999999846, -8.799999999999878, 15.799999999999963, 20.90000000000003, 13.699999999999964, -34.59999999999975, 22.700000000000053, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 2.59999999999997, 13.699999999999964, 11.599999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 23.30000000000006, 1.10000000000001, 5.299999999999965, 13.999999999999968, 15.799999999999963, 9.499999999999964, 20.000000000000014, -26.200000000000045, 13.699999999999964, 20.000000000000014, 15.799999999999963, 11.599999999999964, 20.000000000000014, 7.399999999999965, -3.099999999999965, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999966, 17.899999999999988, 5.299999999999965, -11.500000000000046, 17.899999999999988, 11.599999999999968, 15.499999999999964, 7.399999999999965, 14.899999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 20.000000000000014, 17.899999999999988, 18.8, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.800000000000196, 13.699999999999964, 30.5000000000002, 13.699999999999964, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -9.399999999999862, 13.699999999999964, 20.900000000000027, -7.299999999999908, 11.599999999999964, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 1.099999999999983, 17.899999999999988, 11.599999999999964, 17.899999999999988, 20.000000000000014, 7.399999999999965, 20.000000000000014, 7.399999999999965, 4.399999999999977, 11.599999999999982, -63.999999999999766, 1.0999999999999794, -17.79999999999975, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 15.799999999999963, 20.000000000000014, -2.799999999999972, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965], "policy_predator_policy_reward": [18.0, 6.0, 3.0, 1.0, 4.0, 0.0, 9.0, 3.0, 4.0, 1.0, 1.0, 12.0, 27.0, 27.0, 0.0, 1.0, 3.0, 4.0, 1.0, 6.0, 6.0, 15.0, 1.0, 4.0, 4.0, 2.0, 0.0, 7.0, 5.0, 0.0, 1.0, 3.0, 21.0, 17.0, 14.0, 5.0, 2.0, 3.0, 5.0, 0.0, 3.0, 7.0, 4.0, 2.0, 16.0, 15.0, 0.0, 7.0, 9.0, 5.0, 3.0, 6.0, 4.0, 3.0, 6.0, 2.0, 4.0, 10.0, 2.0, 17.0, 0.0, 2.0, 9.0, 9.0, 4.0, 3.0, 22.0, 0.0, 7.0, 2.0, 3.0, 0.0, 6.0, 5.0, 17.0, 10.0, 8.0, 4.0, 9.0, 8.0, 2.0, 22.0, 1.0, 2.0, 7.0, 4.0, 5.0, 2.0, 2.0, 1.0, 6.0, 15.0, 2.0, 10.0, 19.0, 17.0, 15.0, 5.0, 10.0, 10.0, 6.0, 12.0, 3.0, 2.0, 19.0, 26.0, 0.0, 5.0, 11.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 8.0, 1.0, 9.0, 12.0, 13.0, 2.0, 5.0, 22.0, 3.0, 3.0, 1.0, 4.0, 2.0, 6.0, 2.0, 11.0, 2.0, 4.0, 7.0, 0.0, 0.0, 1.0, 3.0, 0.0, 22.0, 7.0, 4.0, 6.0, 3.0, 3.0, 5.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 7.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 13.0, 4.0, 13.0, 3.0, 3.0, 4.0, 3.0, 5.0, 0.0, 9.0, 1.0, 4.0, 0.0, 1.0, 2.0, 6.0, 12.0, 10.0, 10.0, 37.0, 14.0, 17.0, 8.0, 0.0, 1.0, 2.0, 13.0, 8.0, 2.0, 0.0, 2.0, 5.0, 1.0, 0.0, 6.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8289235191437495, "mean_inference_ms": 2.1647377933222214, "mean_action_processing_ms": 0.3454283275107671, "mean_env_wait_ms": 0.27547952527573283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008031845092773438, "StateBufferConnector_ms": 0.003321051597595215, "ViewRequirementAgentConnector_ms": 0.11632633209228516}, "num_episodes": 18, "episode_return_max": 54.200000000000465, "episode_return_min": -5.399999999999837, "episode_return_mean": 33.067000000000206, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.6494428927345, "num_env_steps_trained_throughput_per_sec": 346.6494428927345, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 11344.968, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11344.91, "sample_time_ms": 1422.228, "learn_time_ms": 9906.605, "learn_throughput": 403.771, "synch_weights_time_ms": 14.008}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-06-44", "timestamp": 1723648004, "time_this_iter_s": 11.599303960800171, "time_total_s": 1171.5269746780396, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2bd8550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1171.5269746780396, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 47.81875, "ram_util_percent": 83.2125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.210914665965176, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4320385263693795, "policy_loss": -0.010474457038029359, "vf_loss": 0.44233216073896203, "vf_explained_var": 0.056508885931085655, "kl": 0.010159743057572689, "entropy": 0.9970269133489599, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7628605402808972, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3707766468050303, "policy_loss": -0.0035026630214243025, "vf_loss": 0.3741359922995485, "vf_explained_var": 0.3174050116665149, "kl": 0.007643603970915193, "entropy": 0.47040303639633946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 60.800000000000495, "episode_reward_min": -5.399999999999837, "episode_reward_mean": 33.088000000000214, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -63.999999999999766, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.90000000000024, "predator_policy": 37.0}, "policy_reward_mean": {"prey_policy": 10.19900000000001, "predator_policy": 6.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.700000000000177, 49.100000000000456, 16.200000000000006, 30.100000000000144, 34.40000000000022, 33.00000000000019, 24.600000000000048, 35.000000000000256, 37.80000000000027, 32.20000000000018, 38.60000000000028, 15.799999999999923, 34.30000000000022, 36.70000000000025, 38.400000000000276, 28.000000000000117, 26.800000000000086, 48.00000000000043, 13.60000000000002, 48.40000000000044, 27.900000000000105, 32.30000000000021, 41.50000000000032, 19.60000000000001, 14.200000000000038, 19.899999999999995, 21.60000000000001, 39.000000000000284, 25.00000000000006, 39.60000000000029, 33.1000000000002, 34.50000000000022, 24.800000000000065, 29.30000000000013, 38.90000000000028, 31.200000000000166, 34.40000000000026, 44.30000000000038, 32.30000000000018, 18.800000000000164, 37.700000000000266, 33.4000000000002, 35.40000000000023, 29.900000000000148, 27.900000000000105, 40.0000000000003, 35.600000000000236, 15.799999999999901, 40.500000000000306, 31.900000000000176, 42.90000000000034, 34.50000000000022, 38.80000000000028, 38.70000000000028, 36.70000000000025, 50.80000000000048, 54.200000000000465, 36.70000000000025, 38.80000000000028, 31.20000000000017, 21.299999999999994, 29.60000000000014, 38.60000000000028, 37.50000000000026, 30.100000000000147, 34.50000000000022, 38.90000000000028, 35.40000000000023, 33.800000000000196, -5.399999999999837, 14.299999999999999, 31.200000000000166, 36.70000000000025, 38.20000000000027, 37.80000000000027, 32.30000000000018, 38.90000000000028, 38.400000000000276, 60.800000000000495, 37.10000000000026, 35.600000000000236, 33.3000000000002, 35.30000000000023, 37.000000000000256, 37.50000000000026, 29.000000000000142, 36.900000000000254, 37.80000000000027, 27.6000000000001, 33.60000000000021, 25.600000000000065, 15.19999999999999, 29.000000000000124, 42.80000000000034, 50.600000000000485, 36.300000000000246, 15.99999999999999, 30.100000000000144, 34.80000000000022, 38.50000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, -6.699999999999907, 18.8, 23.30000000000006, 1.0999999999999865, 1.0999999999999865, 11.599999999999964, 9.499999999999964, 11.599999999999964, 15.799999999999963, 9.199999999999966, 15.799999999999963, 11.599999999999964, -0.9999999999999846, 11.599999999999964, 4.399999999999973, 15.799999999999963, 20.000000000000014, 13.099999999999966, 1.0999999999999865, 20.000000000000014, 11.599999999999964, -17.799999999999763, 11.599999999999964, 5.299999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, 7.399999999999965, 20.000000000000014, 16.699999999999967, -15.699999999999747, 3.1999999999999615, 11.599999999999964, 29.90000000000018, 1.0999999999999865, -26.199999999999747, 15.799999999999963, 29.600000000000176, 15.799999999999963, 11.599999999999964, 5.299999999999965, 15.799999999999963, 9.499999999999956, 22.700000000000053, 15.799999999999963, 7.399999999999965, -8.799999999999871, -0.9999999999999846, 3.1999999999999615, -5.199999999999934, -10.89999999999985, 17.899999999999988, -16.299999999999763, 20.000000000000014, -0.9999999999999846, -8.799999999999878, 15.799999999999963, 20.90000000000003, 13.699999999999964, -34.59999999999975, 22.700000000000053, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 2.59999999999997, 13.699999999999964, 11.599999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 23.30000000000006, 1.10000000000001, 5.299999999999965, 13.999999999999968, 15.799999999999963, 9.499999999999964, 20.000000000000014, -26.200000000000045, 13.699999999999964, 20.000000000000014, 15.799999999999963, 11.599999999999964, 20.000000000000014, 7.399999999999965, -3.099999999999965, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999966, 17.899999999999988, 5.299999999999965, -11.500000000000046, 17.899999999999988, 11.599999999999968, 15.499999999999964, 7.399999999999965, 14.899999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 20.000000000000014, 17.899999999999988, 18.8, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.800000000000196, 13.699999999999964, 30.5000000000002, 13.699999999999964, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -9.399999999999862, 13.699999999999964, 20.900000000000027, -7.299999999999908, 11.599999999999964, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 1.099999999999983, 17.899999999999988, 11.599999999999964, 17.899999999999988, 20.000000000000014, 7.399999999999965, 20.000000000000014, 7.399999999999965, 4.399999999999977, 11.599999999999982, -63.999999999999766, 1.0999999999999794, -17.79999999999975, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 15.799999999999963, 20.000000000000014, -2.799999999999972, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 38.90000000000024, 17.899999999999988, -13.899999999999782, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, 5.299999999999965, 9.499999999999964, 15.799999999999963, 20.000000000000014, 1.9999999999999607, 20.000000000000014, 9.499999999999964, 5.299999999999974, 13.699999999999964, -0.9999999999999846, 20.90000000000003, 20.000000000000014, 15.799999999999963, -3.099999999999958, 13.699999999999964, 17.899999999999988, -28.29999999999975, 5.299999999999965, 5.299999999999965, -36.699999999999754, -3.099999999999958, 5.299999999999965, 13.699999999999964, 20.900000000000027, 17.899999999999984, 14.599999999999966, 20.000000000000014, 5.299999999999965, 20.000000000000014, -5.199999999999934, 3.1999999999999615, 15.799999999999963, 5.299999999999965, 11.599999999999964, -5.799999999999967, 20.000000000000014, 9.499999999999964], "policy_predator_policy_reward": [16.0, 15.0, 0.0, 7.0, 9.0, 5.0, 3.0, 6.0, 4.0, 3.0, 6.0, 2.0, 4.0, 10.0, 2.0, 17.0, 0.0, 2.0, 9.0, 9.0, 4.0, 3.0, 22.0, 0.0, 7.0, 2.0, 3.0, 0.0, 6.0, 5.0, 17.0, 10.0, 8.0, 4.0, 9.0, 8.0, 2.0, 22.0, 1.0, 2.0, 7.0, 4.0, 5.0, 2.0, 2.0, 1.0, 6.0, 15.0, 2.0, 10.0, 19.0, 17.0, 15.0, 5.0, 10.0, 10.0, 6.0, 12.0, 3.0, 2.0, 19.0, 26.0, 0.0, 5.0, 11.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 8.0, 1.0, 9.0, 12.0, 13.0, 2.0, 5.0, 22.0, 3.0, 3.0, 1.0, 4.0, 2.0, 6.0, 2.0, 11.0, 2.0, 4.0, 7.0, 0.0, 0.0, 1.0, 3.0, 0.0, 22.0, 7.0, 4.0, 6.0, 3.0, 3.0, 5.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 7.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 13.0, 4.0, 13.0, 3.0, 3.0, 4.0, 3.0, 5.0, 0.0, 9.0, 1.0, 4.0, 0.0, 1.0, 2.0, 6.0, 12.0, 10.0, 10.0, 37.0, 14.0, 17.0, 8.0, 0.0, 1.0, 2.0, 13.0, 8.0, 2.0, 0.0, 2.0, 5.0, 1.0, 0.0, 6.0, 5.0, 3.0, 1.0, 15.0, 16.0, 3.0, 1.0, 6.0, 2.0, 5.0, 5.0, 3.0, 12.0, 5.0, 3.0, 3.0, 7.0, 7.0, 10.0, 2.0, 0.0, 7.0, 10.0, 23.0, 21.0, 5.0, 10.0, 27.0, 28.0, 7.0, 3.0, 4.0, 0.0, 8.0, 8.0, 4.0, 7.0, 0.0, 18.0, 7.0, 2.0, 6.0, 23.0, 5.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8269500504493901, "mean_inference_ms": 2.1589516394148465, "mean_action_processing_ms": 0.34415252974038824, "mean_env_wait_ms": 0.2747954093253845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0077103376388549805, "StateBufferConnector_ms": 0.003548741340637207, "ViewRequirementAgentConnector_ms": 0.11211419105529785}, "num_episodes": 22, "episode_return_max": 60.800000000000495, "episode_return_min": -5.399999999999837, "episode_return_mean": 33.088000000000214, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.8499815721335, "num_env_steps_trained_throughput_per_sec": 348.8499815721335, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 11342.823, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11342.766, "sample_time_ms": 1374.854, "learn_time_ms": 9951.753, "learn_throughput": 401.939, "synch_weights_time_ms": 14.146}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-06-56", "timestamp": 1723648016, "time_this_iter_s": 11.484358072280884, "time_total_s": 1183.0113327503204, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2bd8f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1183.0113327503204, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 44.411764705882355, "ram_util_percent": 77.72352941176472}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3831353471313834, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2644826380312908, "policy_loss": -0.01073402808116818, "vf_loss": 0.27505681827250456, "vf_explained_var": 0.39711192669691864, "kl": 0.008981283961031828, "entropy": 1.0759621951630507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8889921446247075, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1277980890033721, "policy_loss": -0.005793655868964615, "vf_loss": 0.13329773296986425, "vf_explained_var": 0.30765132563454767, "kl": 0.015680623750983554, "entropy": 0.39155306835023185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 77.1999999999995, "episode_reward_min": -5.399999999999837, "episode_reward_mean": 33.76600000000021, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -63.999999999999766, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.400000000000205, "predator_policy": 37.0}, "policy_reward_mean": {"prey_policy": 10.89800000000001, "predator_policy": 5.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.60000000000002, 48.40000000000044, 27.900000000000105, 32.30000000000021, 41.50000000000032, 19.60000000000001, 14.200000000000038, 19.899999999999995, 21.60000000000001, 39.000000000000284, 25.00000000000006, 39.60000000000029, 33.1000000000002, 34.50000000000022, 24.800000000000065, 29.30000000000013, 38.90000000000028, 31.200000000000166, 34.40000000000026, 44.30000000000038, 32.30000000000018, 18.800000000000164, 37.700000000000266, 33.4000000000002, 35.40000000000023, 29.900000000000148, 27.900000000000105, 40.0000000000003, 35.600000000000236, 15.799999999999901, 40.500000000000306, 31.900000000000176, 42.90000000000034, 34.50000000000022, 38.80000000000028, 38.70000000000028, 36.70000000000025, 50.80000000000048, 54.200000000000465, 36.70000000000025, 38.80000000000028, 31.20000000000017, 21.299999999999994, 29.60000000000014, 38.60000000000028, 37.50000000000026, 30.100000000000147, 34.50000000000022, 38.90000000000028, 35.40000000000023, 33.800000000000196, -5.399999999999837, 14.299999999999999, 31.200000000000166, 36.70000000000025, 38.20000000000027, 37.80000000000027, 32.30000000000018, 38.90000000000028, 38.400000000000276, 60.800000000000495, 37.10000000000026, 35.600000000000236, 33.3000000000002, 35.30000000000023, 37.000000000000256, 37.50000000000026, 29.000000000000142, 36.900000000000254, 37.80000000000027, 27.6000000000001, 33.60000000000021, 25.600000000000065, 15.19999999999999, 29.000000000000124, 42.80000000000034, 50.600000000000485, 36.300000000000246, 15.99999999999999, 30.100000000000144, 34.80000000000022, 38.50000000000028, 36.60000000000025, 13.60000000000004, 30.900000000000166, 44.30000000000036, 36.70000000000025, 33.80000000000021, 33.4000000000002, 77.1999999999995, 37.80000000000027, 20.50000000000001, 34.200000000000216, 36.70000000000025, 26.800000000000086, 38.70000000000028, 28.400000000000134, 36.70000000000025, 37.50000000000026, 54.700000000000514], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.199999999999747, 15.799999999999963, 29.600000000000176, 15.799999999999963, 11.599999999999964, 5.299999999999965, 15.799999999999963, 9.499999999999956, 22.700000000000053, 15.799999999999963, 7.399999999999965, -8.799999999999871, -0.9999999999999846, 3.1999999999999615, -5.199999999999934, -10.89999999999985, 17.899999999999988, -16.299999999999763, 20.000000000000014, -0.9999999999999846, -8.799999999999878, 15.799999999999963, 20.90000000000003, 13.699999999999964, -34.59999999999975, 22.700000000000053, 9.499999999999964, 20.000000000000014, 3.1999999999999615, 2.59999999999997, 13.699999999999964, 11.599999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 23.30000000000006, 1.10000000000001, 5.299999999999965, 13.999999999999968, 15.799999999999963, 9.499999999999964, 20.000000000000014, -26.200000000000045, 13.699999999999964, 20.000000000000014, 15.799999999999963, 11.599999999999964, 20.000000000000014, 7.399999999999965, -3.099999999999965, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999966, 17.899999999999988, 5.299999999999965, -11.500000000000046, 17.899999999999988, 11.599999999999968, 15.499999999999964, 7.399999999999965, 14.899999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 20.000000000000014, 17.899999999999988, 18.8, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.800000000000196, 13.699999999999964, 30.5000000000002, 13.699999999999964, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -9.399999999999862, 13.699999999999964, 20.900000000000027, -7.299999999999908, 11.599999999999964, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 1.099999999999983, 17.899999999999988, 11.599999999999964, 17.899999999999988, 20.000000000000014, 7.399999999999965, 20.000000000000014, 7.399999999999965, 4.399999999999977, 11.599999999999982, -63.999999999999766, 1.0999999999999794, -17.79999999999975, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 15.799999999999963, 20.000000000000014, -2.799999999999972, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 38.90000000000024, 17.899999999999988, -13.899999999999782, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, 5.299999999999965, 9.499999999999964, 15.799999999999963, 20.000000000000014, 1.9999999999999607, 20.000000000000014, 9.499999999999964, 5.299999999999974, 13.699999999999964, -0.9999999999999846, 20.90000000000003, 20.000000000000014, 15.799999999999963, -3.099999999999958, 13.699999999999964, 17.899999999999988, -28.29999999999975, 5.299999999999965, 5.299999999999965, -36.699999999999754, -3.099999999999958, 5.299999999999965, 13.699999999999964, 20.900000000000027, 17.899999999999984, 14.599999999999966, 20.000000000000014, 5.299999999999965, 20.000000000000014, -5.199999999999934, 3.1999999999999615, 15.799999999999963, 5.299999999999965, 11.599999999999964, -5.799999999999967, 20.000000000000014, 9.499999999999964, 11.599999999999964, 20.000000000000014, -11.499999999999819, 1.0999999999999865, 20.000000000000014, -3.0999999999999615, 17.899999999999988, 25.400000000000098, 13.699999999999964, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 15.799999999999963, 11.599999999999964, 15.799999999999963, 46.400000000000205, 17.899999999999988, 17.899999999999988, 5.299999999999965, 3.1999999999999615, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 13.699999999999964, 7.399999999999965, 7.399999999999965, 20.90000000000003, 15.799999999999963, 20.000000000000014, -13.599999999999783, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999964, 38.000000000000256, 13.699999999999964], "policy_predator_policy_reward": [2.0, 22.0, 1.0, 2.0, 7.0, 4.0, 5.0, 2.0, 2.0, 1.0, 6.0, 15.0, 2.0, 10.0, 19.0, 17.0, 15.0, 5.0, 10.0, 10.0, 6.0, 12.0, 3.0, 2.0, 19.0, 26.0, 0.0, 5.0, 11.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 8.0, 1.0, 9.0, 12.0, 13.0, 2.0, 5.0, 22.0, 3.0, 3.0, 1.0, 4.0, 2.0, 6.0, 2.0, 11.0, 2.0, 4.0, 7.0, 0.0, 0.0, 1.0, 3.0, 0.0, 22.0, 7.0, 4.0, 6.0, 3.0, 3.0, 5.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 7.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 13.0, 4.0, 13.0, 3.0, 3.0, 4.0, 3.0, 5.0, 0.0, 9.0, 1.0, 4.0, 0.0, 1.0, 2.0, 6.0, 12.0, 10.0, 10.0, 37.0, 14.0, 17.0, 8.0, 0.0, 1.0, 2.0, 13.0, 8.0, 2.0, 0.0, 2.0, 5.0, 1.0, 0.0, 6.0, 5.0, 3.0, 1.0, 15.0, 16.0, 3.0, 1.0, 6.0, 2.0, 5.0, 5.0, 3.0, 12.0, 5.0, 3.0, 3.0, 7.0, 7.0, 10.0, 2.0, 0.0, 7.0, 10.0, 23.0, 21.0, 5.0, 10.0, 27.0, 28.0, 7.0, 3.0, 4.0, 0.0, 8.0, 8.0, 4.0, 7.0, 0.0, 18.0, 7.0, 2.0, 6.0, 23.0, 5.0, 4.0, 4.0, 1.0, 9.0, 15.0, 10.0, 4.0, 1.0, 0.0, 3.0, 0.0, 7.0, 12.0, 2.0, 4.0, 7.0, 8.0, 1.0, 1.0, 4.0, 8.0, 3.0, 8.0, 3.0, 0.0, 6.0, 6.0, 2.0, 0.0, 6.0, 16.0, 3.0, 0.0, 5.0, 3.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8247518855976168, "mean_inference_ms": 2.153801866490846, "mean_action_processing_ms": 0.3438142349133716, "mean_env_wait_ms": 0.2742326213639233, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0057212114334106445, "StateBufferConnector_ms": 0.0034574270248413086, "ViewRequirementAgentConnector_ms": 0.10729968547821045}, "num_episodes": 18, "episode_return_max": 77.1999999999995, "episode_return_min": -5.399999999999837, "episode_return_mean": 33.76600000000021, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.4889515274477, "num_env_steps_trained_throughput_per_sec": 343.4889515274477, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 11339.549, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11339.496, "sample_time_ms": 1304.219, "learn_time_ms": 10019.469, "learn_throughput": 399.223, "synch_weights_time_ms": 14.008}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-07-08", "timestamp": 1723648028, "time_this_iter_s": 11.653723955154419, "time_total_s": 1194.6650567054749, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x32edea040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1194.6650567054749, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 49.075, "ram_util_percent": 77.03125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5963855215323666, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.33715073825426833, "policy_loss": -0.00853660773244445, "vf_loss": 0.3455653931664687, "vf_explained_var": -0.01897203767741168, "kl": 0.006852131423158582, "entropy": 1.1035744092451831, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0260963971100787, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.25507437866279686, "policy_loss": -0.005845856451843347, "vf_loss": 0.2607546892849896, "vf_explained_var": 0.10934605674138145, "kl": 0.008829149776938352, "entropy": 0.3500458300507889, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 79.89999999999934, "episode_reward_min": -5.399999999999837, "episode_reward_mean": 35.632000000000204, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -63.999999999999766, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.40000000000022, "predator_policy": 37.0}, "policy_reward_mean": {"prey_policy": 11.996000000000013, "predator_policy": 5.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.4000000000002, 35.40000000000023, 29.900000000000148, 27.900000000000105, 40.0000000000003, 35.600000000000236, 15.799999999999901, 40.500000000000306, 31.900000000000176, 42.90000000000034, 34.50000000000022, 38.80000000000028, 38.70000000000028, 36.70000000000025, 50.80000000000048, 54.200000000000465, 36.70000000000025, 38.80000000000028, 31.20000000000017, 21.299999999999994, 29.60000000000014, 38.60000000000028, 37.50000000000026, 30.100000000000147, 34.50000000000022, 38.90000000000028, 35.40000000000023, 33.800000000000196, -5.399999999999837, 14.299999999999999, 31.200000000000166, 36.70000000000025, 38.20000000000027, 37.80000000000027, 32.30000000000018, 38.90000000000028, 38.400000000000276, 60.800000000000495, 37.10000000000026, 35.600000000000236, 33.3000000000002, 35.30000000000023, 37.000000000000256, 37.50000000000026, 29.000000000000142, 36.900000000000254, 37.80000000000027, 27.6000000000001, 33.60000000000021, 25.600000000000065, 15.19999999999999, 29.000000000000124, 42.80000000000034, 50.600000000000485, 36.300000000000246, 15.99999999999999, 30.100000000000144, 34.80000000000022, 38.50000000000028, 36.60000000000025, 13.60000000000004, 30.900000000000166, 44.30000000000036, 36.70000000000025, 33.80000000000021, 33.4000000000002, 77.1999999999995, 37.80000000000027, 20.50000000000001, 34.200000000000216, 36.70000000000025, 26.800000000000086, 38.70000000000028, 28.400000000000134, 36.70000000000025, 37.50000000000026, 54.700000000000514, 67.60000000000024, 32.10000000000018, 30.100000000000147, 39.800000000000296, 33.3000000000002, 8.40000000000013, 37.80000000000027, 38.90000000000028, 37.600000000000264, 33.700000000000216, 26.900000000000144, 56.700000000000514, 37.80000000000027, 27.800000000000107, 19.399999999999977, 79.89999999999934, 33.2000000000002, 36.200000000000244, 58.00000000000049, 42.40000000000033, 35.00000000000023, 40.400000000000304, 35.500000000000234], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, 11.599999999999964, 20.000000000000014, 7.399999999999965, -3.099999999999965, 20.000000000000014, 11.599999999999964, 5.299999999999965, 20.000000000000014, 20.000000000000014, 13.699999999999966, 17.899999999999988, 5.299999999999965, -11.500000000000046, 17.899999999999988, 11.599999999999968, 15.499999999999964, 7.399999999999965, 14.899999999999967, 20.000000000000014, 20.000000000000014, 9.499999999999964, 15.799999999999963, 20.000000000000014, 17.899999999999988, 18.8, 13.699999999999964, 20.000000000000014, 20.000000000000014, 30.800000000000196, 13.699999999999964, 30.5000000000002, 13.699999999999964, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -9.399999999999862, 13.699999999999964, 20.900000000000027, -7.299999999999908, 11.599999999999964, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 1.099999999999983, 17.899999999999988, 11.599999999999964, 17.899999999999988, 20.000000000000014, 7.399999999999965, 20.000000000000014, 7.399999999999965, 4.399999999999977, 11.599999999999982, -63.999999999999766, 1.0999999999999794, -17.79999999999975, 20.000000000000014, 3.1999999999999615, 17.899999999999988, 15.799999999999963, 20.000000000000014, -2.799999999999972, 15.799999999999963, 20.000000000000014, 15.799999999999963, 9.499999999999964, 17.899999999999988, 20.000000000000014, 20.000000000000014, 7.399999999999965, 38.90000000000024, 17.899999999999988, -13.899999999999782, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, 5.299999999999965, 9.499999999999964, 15.799999999999963, 20.000000000000014, 1.9999999999999607, 20.000000000000014, 9.499999999999964, 5.299999999999974, 13.699999999999964, -0.9999999999999846, 20.90000000000003, 20.000000000000014, 15.799999999999963, -3.099999999999958, 13.699999999999964, 17.899999999999988, -28.29999999999975, 5.299999999999965, 5.299999999999965, -36.699999999999754, -3.099999999999958, 5.299999999999965, 13.699999999999964, 20.900000000000027, 17.899999999999984, 14.599999999999966, 20.000000000000014, 5.299999999999965, 20.000000000000014, -5.199999999999934, 3.1999999999999615, 15.799999999999963, 5.299999999999965, 11.599999999999964, -5.799999999999967, 20.000000000000014, 9.499999999999964, 11.599999999999964, 20.000000000000014, -11.499999999999819, 1.0999999999999865, 20.000000000000014, -3.0999999999999615, 17.899999999999988, 25.400000000000098, 13.699999999999964, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 15.799999999999963, 11.599999999999964, 15.799999999999963, 46.400000000000205, 17.899999999999988, 17.899999999999988, 5.299999999999965, 3.1999999999999615, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 13.699999999999964, 7.399999999999965, 7.399999999999965, 20.90000000000003, 15.799999999999963, 20.000000000000014, -13.599999999999783, 20.000000000000014, 13.699999999999964, 20.000000000000014, 9.499999999999964, 38.000000000000256, 13.699999999999964, 41.600000000000236, 20.000000000000014, 5.299999999999965, 18.799999999999997, 20.000000000000014, 1.0999999999999865, 15.799999999999963, 20.000000000000014, 14.899999999999967, 7.399999999999965, -0.9999999999999846, -13.599999999999783, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, 11.599999999999964, 20.000000000000014, 17.899999999999988, 0.7999999999999865, -32.79999999999981, 13.699999999999964, 13.699999999999964, 38.000000000000256, 15.799999999999963, 20.000000000000014, 15.499999999999963, -3.6999999999999655, -22.599999999999753, 20.000000000000014, 9.499999999999964, 61.40000000000022, 3.1999999999999615, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 26.000000000000117, 20.000000000000014, 9.499999999999964, 26.900000000000126, -0.9999999999999846, 20.000000000000014, 10.399999999999965, -1.0000000000000133, 20.000000000000014, -11.499999999999819], "policy_predator_policy_reward": [4.0, 2.0, 6.0, 2.0, 11.0, 2.0, 4.0, 7.0, 0.0, 0.0, 1.0, 3.0, 0.0, 22.0, 7.0, 4.0, 6.0, 3.0, 3.0, 5.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 7.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 13.0, 4.0, 13.0, 3.0, 3.0, 4.0, 3.0, 5.0, 0.0, 9.0, 1.0, 4.0, 0.0, 1.0, 2.0, 6.0, 12.0, 10.0, 10.0, 37.0, 14.0, 17.0, 8.0, 0.0, 1.0, 2.0, 13.0, 8.0, 2.0, 0.0, 2.0, 5.0, 1.0, 0.0, 6.0, 5.0, 3.0, 1.0, 15.0, 16.0, 3.0, 1.0, 6.0, 2.0, 5.0, 5.0, 3.0, 12.0, 5.0, 3.0, 3.0, 7.0, 7.0, 10.0, 2.0, 0.0, 7.0, 10.0, 23.0, 21.0, 5.0, 10.0, 27.0, 28.0, 7.0, 3.0, 4.0, 0.0, 8.0, 8.0, 4.0, 7.0, 0.0, 18.0, 7.0, 2.0, 6.0, 23.0, 5.0, 4.0, 4.0, 1.0, 9.0, 15.0, 10.0, 4.0, 1.0, 0.0, 3.0, 0.0, 7.0, 12.0, 2.0, 4.0, 7.0, 8.0, 1.0, 1.0, 4.0, 8.0, 3.0, 8.0, 3.0, 0.0, 6.0, 6.0, 2.0, 0.0, 6.0, 16.0, 3.0, 0.0, 5.0, 3.0, 3.0, 0.0, 3.0, 3.0, 7.0, 1.0, 9.0, 0.0, 2.0, 2.0, 5.0, 6.0, 7.0, 16.0, 2.0, 0.0, 0.0, 1.0, 2.0, 4.0, 10.0, 5.0, 36.0, 10.0, 3.0, 2.0, 2.0, 0.0, 13.0, 3.0, 22.0, 0.0, 5.0, 4.0, 2.0, 8.0, 8.0, 5.0, 7.0, 5.0, 1.0, 5.0, 10.0, 6.0, 16.0, 15.0, 13.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8237129312484887, "mean_inference_ms": 2.1513410634623025, "mean_action_processing_ms": 0.34308807078041553, "mean_env_wait_ms": 0.2739884826955476, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038613080978393555, "StateBufferConnector_ms": 0.0033556222915649414, "ViewRequirementAgentConnector_ms": 0.11261224746704102}, "num_episodes": 23, "episode_return_max": 79.89999999999934, "episode_return_min": -5.399999999999837, "episode_return_mean": 35.632000000000204, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.00008396532706, "num_env_steps_trained_throughput_per_sec": 276.00008396532706, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 11660.638, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11660.583, "sample_time_ms": 1390.806, "learn_time_ms": 10253.699, "learn_throughput": 390.103, "synch_weights_time_ms": 14.17}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "0bdc1_00000", "date": "2024-08-14_11-07-22", "timestamp": 1723648042, "time_this_iter_s": 14.537874937057495, "time_total_s": 1209.2029316425323, "pid": 47600, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2b69c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1209.2029316425323, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 65.97142857142858, "ram_util_percent": 83.27142857142857}}
