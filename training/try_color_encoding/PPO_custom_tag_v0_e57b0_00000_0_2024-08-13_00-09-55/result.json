{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.026004419184078, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.514230019201047, "policy_loss": -0.001071158539326418, "vf_loss": 8.514552944173257, "vf_explained_var": 0.008387729194429186, "kl": 0.00374116935334461, "entropy": 1.6057687268055305, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.20232890601117146, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.769472153350789, "policy_loss": -0.005345200157660262, "vf_loss": 4.772682932444981, "vf_explained_var": -8.512230777235888e-05, "kl": 0.01067212311800197, "entropy": 1.59901294197355, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 282.60000000000053, "episode_reward_min": -105.29999999999984, "episode_reward_mean": 47.63888888888878, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -284.5000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.7, "predator_policy": 165.0}, "policy_reward_mean": {"prey_policy": -14.958333333333387, "predator_policy": 38.77777777777778}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.900000000000029, 62.50000000000026, -44.29999999999989, -16.899999999999963, 111.19999999999906, 71.09999999999948, 11.999999999999993, 58.70000000000011, -105.29999999999984, 282.60000000000053, 31.60000000000032, -74.80000000000142, 24.900000000000077, 130.2999999999997, 150.19999999999905, 50.80000000000049, 95.59999999999985, 33.20000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [107.29999999999995, -275.20000000000005, 20.000000000000014, 42.50000000000008, -284.5000000000002, 51.20000000000002, -227.2000000000001, 17.29999999999999, 59.30000000000002, 20.90000000000003, 37.4000000000001, -4.299999999999914, -51.40000000000046, 13.400000000000176, 4.399999999999999, -15.69999999999991, -152.20000000000002, -228.1000000000001, 113.0, 140.59999999999988, -31.599999999999824, 3.1999999999999766, -58.6000000000007, -86.20000000000071, 10.1, -89.2000000000005, 2.2999999999999643, 106.99999999999997, 32.300000000000225, 110.89999999999965, 30.8000000000002, 20.000000000000014, 175.7, -171.10000000000002, -13.599999999999875, 30.800000000000104], "policy_predator_policy_reward": [12.0, 140.0, 0.0, 0.0, 128.0, 61.0, 165.0, 28.0, 31.0, 0.0, 24.0, 14.0, 0.0, 50.0, 39.0, 31.0, 142.0, 133.0, 0.0, 29.0, 29.0, 31.0, 52.0, 18.0, 0.0, 104.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 91.0, 0.0, 0.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5849023152028243, "mean_inference_ms": 7.9068112237073205, "mean_action_processing_ms": 1.2359228958662336, "mean_env_wait_ms": 1.0476396431709913, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008806255128648546, "StateBufferConnector_ms": 0.004846519894070095, "ViewRequirementAgentConnector_ms": 0.39345357153150773}, "num_episodes": 18, "episode_return_max": 282.60000000000053, "episode_return_min": -105.29999999999984, "episode_return_mean": 47.63888888888878, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 160.71607501394476, "num_env_steps_trained_throughput_per_sec": 160.71607501394476, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 24888.761, "restore_workers_time_ms": 0.083, "training_step_time_ms": 24888.453, "sample_time_ms": 6053.515, "learn_time_ms": 18804.815, "learn_throughput": 212.711, "synch_weights_time_ms": 15.121}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "e57b0_00000", "date": "2024-08-13_00-10-44", "timestamp": 1723522244, "time_this_iter_s": 24.953065156936646, "time_total_s": 24.953065156936646, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bb820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 24.953065156936646, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 90.07027027027029, "ram_util_percent": 83.64324324324325}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.922605036206977, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.154498313722156, "policy_loss": -0.00293802614348433, "vf_loss": 7.156136289727751, "vf_explained_var": 0.0050398037547156925, "kl": 0.01300064444355398, "entropy": 1.592816934888325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2571129859124542, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.365844147293656, "policy_loss": -0.002277772041486093, "vf_loss": 3.367109718083074, "vf_explained_var": 0.0018391999302717745, "kl": 0.0050610056823409385, "entropy": 1.5928563696997506, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 282.60000000000053, "episode_reward_min": -105.29999999999984, "episode_reward_mean": 47.87777777777767, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -284.5000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.7, "predator_policy": 165.0}, "policy_reward_mean": {"prey_policy": -11.11666666666672, "predator_policy": 35.05555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.900000000000029, 62.50000000000026, -44.29999999999989, -16.899999999999963, 111.19999999999906, 71.09999999999948, 11.999999999999993, 58.70000000000011, -105.29999999999984, 282.60000000000053, 31.60000000000032, -74.80000000000142, 24.900000000000077, 130.2999999999997, 150.19999999999905, 50.80000000000049, 95.59999999999985, 33.20000000000013, 271.1999999999999, 20.699999999999946, -19.899999999999977, 17.200000000000244, -41.69999999999978, 82.50000000000009, 118.29999999999862, -76.09999999999997, 173.5999999999991, 40.0000000000003, 148.59999999999928, 58.90000000000027, -56.300000000000445, 60.899999999999764, -18.299999999999535, 66.29999999999997, -32.89999999999974, 53.10000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [107.29999999999995, -275.20000000000005, 20.000000000000014, 42.50000000000008, -284.5000000000002, 51.20000000000002, -227.2000000000001, 17.29999999999999, 59.30000000000002, 20.90000000000003, 37.4000000000001, -4.299999999999914, -51.40000000000046, 13.400000000000176, 4.399999999999999, -15.69999999999991, -152.20000000000002, -228.1000000000001, 113.0, 140.59999999999988, -31.599999999999824, 3.1999999999999766, -58.6000000000007, -86.20000000000071, 10.1, -89.2000000000005, 2.2999999999999643, 106.99999999999997, 32.300000000000225, 110.89999999999965, 30.8000000000002, 20.000000000000014, 175.7, -171.10000000000002, -13.599999999999875, 30.800000000000104, 86.0, 153.19999999999973, -64.3000000000003, 20.000000000000014, -134.80000000000015, -39.09999999999988, -91.6000000000002, 21.800000000000047, -136.3, -30.399999999999814, 39.199999999999996, -9.699999999999939, 72.19999999999962, 46.09999999999997, -28.299999999999827, -155.79999999999984, 70.39999999999982, 57.19999999999956, 20.000000000000014, 20.000000000000014, -57.999999999999815, 155.59999999999985, 34.39999999999999, 24.500000000000096, -211.30000000000004, 20.000000000000014, -21.099999999999998, 20.000000000000014, -57.70000000000048, -13.599999999999897, -34.59999999999985, 65.89999999999993, -152.20000000000056, 17.300000000000054, 39.800000000000026, -6.699999999999864], "policy_predator_policy_reward": [12.0, 140.0, 0.0, 0.0, 128.0, 61.0, 165.0, 28.0, 31.0, 0.0, 24.0, 14.0, 0.0, 50.0, 39.0, 31.0, 142.0, 133.0, 0.0, 29.0, 29.0, 31.0, 52.0, 18.0, 0.0, 104.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 91.0, 0.0, 0.0, 16.0, 0.0, 32.0, 65.0, 0.0, 78.0, 76.0, 6.0, 81.0, 24.0, 101.0, 53.0, 0.0, 0.0, 0.0, 85.0, 23.0, 22.0, 24.0, 0.0, 0.0, 23.0, 28.0, 0.0, 0.0, 135.0, 0.0, 0.0, 62.0, 0.0, 53.0, 35.0, 0.0, 72.0, 30.0, 19.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 3.174414580111256, "mean_inference_ms": 9.227209294581955, "mean_action_processing_ms": 1.4463329377172782, "mean_env_wait_ms": 1.186304317772418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.07641812165578206, "StateBufferConnector_ms": 0.010614593823750814, "ViewRequirementAgentConnector_ms": 0.9051925606197782}, "num_episodes": 18, "episode_return_max": 282.60000000000053, "episode_return_min": -105.29999999999984, "episode_return_mean": 47.87777777777767, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.5391396739118, "num_env_steps_trained_throughput_per_sec": 131.5391396739118, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 27649.049, "restore_workers_time_ms": 0.587, "training_step_time_ms": 27648.229, "sample_time_ms": 8516.189, "learn_time_ms": 19085.68, "learn_throughput": 209.581, "synch_weights_time_ms": 34.114}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "e57b0_00000", "date": "2024-08-13_00-11-19", "timestamp": 1723522279, "time_this_iter_s": 30.76103711128235, "time_total_s": 55.714102268218994, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bb310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 55.714102268218994, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 92.00833333333333, "ram_util_percent": 83.62916666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.082354193973163, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.0151537444856435, "policy_loss": -0.002540272664125989, "vf_loss": 5.016603249090689, "vf_explained_var": 0.02839732318328171, "kl": 0.010907484773182995, "entropy": 1.5770681475205397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.33703888647810176, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.971494363792359, "policy_loss": -0.004081246163696051, "vf_loss": 1.9741200144328768, "vf_explained_var": 0.004971459839079115, "kl": 0.007277973475175918, "entropy": 1.6022466980591021, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 282.60000000000053, "episode_reward_min": -105.29999999999984, "episode_reward_mean": 52.818518518518374, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -284.5000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.7, "predator_policy": 165.0}, "policy_reward_mean": {"prey_policy": -2.2111111111111534, "predator_policy": 28.62037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.900000000000029, 62.50000000000026, -44.29999999999989, -16.899999999999963, 111.19999999999906, 71.09999999999948, 11.999999999999993, 58.70000000000011, -105.29999999999984, 282.60000000000053, 31.60000000000032, -74.80000000000142, 24.900000000000077, 130.2999999999997, 150.19999999999905, 50.80000000000049, 95.59999999999985, 33.20000000000013, 271.1999999999999, 20.699999999999946, -19.899999999999977, 17.200000000000244, -41.69999999999978, 82.50000000000009, 118.29999999999862, -76.09999999999997, 173.5999999999991, 40.0000000000003, 148.59999999999928, 58.90000000000027, -56.300000000000445, 60.899999999999764, -18.299999999999535, 66.29999999999997, -32.89999999999974, 53.10000000000012, 160.6999999999991, 129.09999999999917, 97.59999999999849, 62.30000000000031, 34.600000000000016, 60.70000000000049, 137.39999999999918, 11.500000000000139, 85.90000000000002, 17.200000000000017, 23.600000000000097, 66.20000000000006, 53.80000000000045, 6.20000000000007, 84.99999999999903, 28.400000000000134, -30.60000000000052, 98.99999999999893], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [107.29999999999995, -275.20000000000005, 20.000000000000014, 42.50000000000008, -284.5000000000002, 51.20000000000002, -227.2000000000001, 17.29999999999999, 59.30000000000002, 20.90000000000003, 37.4000000000001, -4.299999999999914, -51.40000000000046, 13.400000000000176, 4.399999999999999, -15.69999999999991, -152.20000000000002, -228.1000000000001, 113.0, 140.59999999999988, -31.599999999999824, 3.1999999999999766, -58.6000000000007, -86.20000000000071, 10.1, -89.2000000000005, 2.2999999999999643, 106.99999999999997, 32.300000000000225, 110.89999999999965, 30.8000000000002, 20.000000000000014, 175.7, -171.10000000000002, -13.599999999999875, 30.800000000000104, 86.0, 153.19999999999973, -64.3000000000003, 20.000000000000014, -134.80000000000015, -39.09999999999988, -91.6000000000002, 21.800000000000047, -136.3, -30.399999999999814, 39.199999999999996, -9.699999999999939, 72.19999999999962, 46.09999999999997, -28.299999999999827, -155.79999999999984, 70.39999999999982, 57.19999999999956, 20.000000000000014, 20.000000000000014, -57.999999999999815, 155.59999999999985, 34.39999999999999, 24.500000000000096, -211.30000000000004, 20.000000000000014, -21.099999999999998, 20.000000000000014, -57.70000000000048, -13.599999999999897, -34.59999999999985, 65.89999999999993, -152.20000000000056, 17.300000000000054, 39.800000000000026, -6.699999999999864, 146.89999999999975, -17.19999999999986, 106.3999999999997, 22.700000000000056, 20.000000000000014, 77.59999999999923, -7.299999999999979, 23.60000000000001, 20.000000000000014, -21.399999999999984, 40.700000000000244, 20.000000000000014, 53.00000000000014, 49.40000000000006, 1.100000000000079, -22.599999999999802, 95.59999999999998, -36.69999999999977, -79.0, 0.19999999999998655, 9.49999999999997, 1.0999999999999734, 45.800000000000125, -46.600000000000136, 38.60000000000022, 3.1999999999999775, -45.09999999999976, 17.300000000000075, 20.000000000000014, 65.00000000000004, -64.00000000000088, 52.40000000000021, -76.00000000000048, -49.59999999999995, 28.100000000000055, 68.8999999999998], "policy_predator_policy_reward": [12.0, 140.0, 0.0, 0.0, 128.0, 61.0, 165.0, 28.0, 31.0, 0.0, 24.0, 14.0, 0.0, 50.0, 39.0, 31.0, 142.0, 133.0, 0.0, 29.0, 29.0, 31.0, 52.0, 18.0, 0.0, 104.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 91.0, 0.0, 0.0, 16.0, 0.0, 32.0, 65.0, 0.0, 78.0, 76.0, 6.0, 81.0, 24.0, 101.0, 53.0, 0.0, 0.0, 0.0, 85.0, 23.0, 22.0, 24.0, 0.0, 0.0, 23.0, 28.0, 0.0, 0.0, 135.0, 0.0, 0.0, 62.0, 0.0, 53.0, 35.0, 0.0, 72.0, 30.0, 19.0, 1.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 14.0, 32.0, 0.0, 36.0, 0.0, 0.0, 35.0, 0.0, 33.0, 0.0, 27.0, 0.0, 55.0, 41.0, 13.0, 0.0, 46.0, 21.0, 12.0, 0.0, 13.0, 21.0, 0.0, 0.0, 40.0, 0.0, 74.0, 21.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 3.2183443561327874, "mean_inference_ms": 9.233770551217667, "mean_action_processing_ms": 1.4412071908174806, "mean_env_wait_ms": 1.1826802012066249, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.05333622296651205, "StateBufferConnector_ms": 0.008128748999701606, "ViewRequirementAgentConnector_ms": 0.6559875276353624}, "num_episodes": 18, "episode_return_max": 282.60000000000053, "episode_return_min": -105.29999999999984, "episode_return_mean": 52.818518518518374, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 261.0218751158107, "num_env_steps_trained_throughput_per_sec": 261.0218751158107, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 23540.864, "restore_workers_time_ms": 0.408, "training_step_time_ms": 23540.25, "sample_time_ms": 7375.547, "learn_time_ms": 16128.2, "learn_throughput": 248.013, "synch_weights_time_ms": 27.986}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "e57b0_00000", "date": "2024-08-13_00-11-34", "timestamp": 1723522294, "time_this_iter_s": 15.366901874542236, "time_total_s": 71.08100414276123, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bbca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 71.08100414276123, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 80.89090909090908, "ram_util_percent": 83.23181818181817}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.58331210860815, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.275685963176546, "policy_loss": -0.001959360873809567, "vf_loss": 4.276823093525317, "vf_explained_var": 0.003322760737131512, "kl": 0.008222428461211044, "entropy": 1.5618519793111811, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.17575165227094972, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7383378081851535, "policy_loss": -0.001146224980543136, "vf_loss": 2.7391634552567092, "vf_explained_var": 0.003697244893936884, "kl": 0.0016028332643390436, "entropy": 1.606726662885575, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 282.60000000000053, "episode_reward_min": -105.29999999999984, "episode_reward_mean": 47.254166666666556, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -284.5000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.7, "predator_policy": 165.0}, "policy_reward_mean": {"prey_policy": -2.956250000000046, "predator_policy": 26.583333333333332}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.900000000000029, 62.50000000000026, -44.29999999999989, -16.899999999999963, 111.19999999999906, 71.09999999999948, 11.999999999999993, 58.70000000000011, -105.29999999999984, 282.60000000000053, 31.60000000000032, -74.80000000000142, 24.900000000000077, 130.2999999999997, 150.19999999999905, 50.80000000000049, 95.59999999999985, 33.20000000000013, 271.1999999999999, 20.699999999999946, -19.899999999999977, 17.200000000000244, -41.69999999999978, 82.50000000000009, 118.29999999999862, -76.09999999999997, 173.5999999999991, 40.0000000000003, 148.59999999999928, 58.90000000000027, -56.300000000000445, 60.899999999999764, -18.299999999999535, 66.29999999999997, -32.89999999999974, 53.10000000000012, 160.6999999999991, 129.09999999999917, 97.59999999999849, 62.30000000000031, 34.600000000000016, 60.70000000000049, 137.39999999999918, 11.500000000000139, 85.90000000000002, 17.200000000000017, 23.600000000000097, 66.20000000000006, 53.80000000000045, 6.20000000000007, 84.99999999999903, 28.400000000000134, -30.60000000000052, 98.99999999999893, -62.200000000000635, -5.799999999999754, 122.59999999999876, -5.499999999999943, 56.00000000000033, -24.499999999999517, 86.8999999999988, -9.399999999999759, 67.70000000000002, -15.399999999999649, 40.0000000000003, 13.299999999999931, 49.90000000000028, 47.20000000000042, 35.600000000000264, 74.19999999999976, 50.500000000000405, 29.000000000000128], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [107.29999999999995, -275.20000000000005, 20.000000000000014, 42.50000000000008, -284.5000000000002, 51.20000000000002, -227.2000000000001, 17.29999999999999, 59.30000000000002, 20.90000000000003, 37.4000000000001, -4.299999999999914, -51.40000000000046, 13.400000000000176, 4.399999999999999, -15.69999999999991, -152.20000000000002, -228.1000000000001, 113.0, 140.59999999999988, -31.599999999999824, 3.1999999999999766, -58.6000000000007, -86.20000000000071, 10.1, -89.2000000000005, 2.2999999999999643, 106.99999999999997, 32.300000000000225, 110.89999999999965, 30.8000000000002, 20.000000000000014, 175.7, -171.10000000000002, -13.599999999999875, 30.800000000000104, 86.0, 153.19999999999973, -64.3000000000003, 20.000000000000014, -134.80000000000015, -39.09999999999988, -91.6000000000002, 21.800000000000047, -136.3, -30.399999999999814, 39.199999999999996, -9.699999999999939, 72.19999999999962, 46.09999999999997, -28.299999999999827, -155.79999999999984, 70.39999999999982, 57.19999999999956, 20.000000000000014, 20.000000000000014, -57.999999999999815, 155.59999999999985, 34.39999999999999, 24.500000000000096, -211.30000000000004, 20.000000000000014, -21.099999999999998, 20.000000000000014, -57.70000000000048, -13.599999999999897, -34.59999999999985, 65.89999999999993, -152.20000000000056, 17.300000000000054, 39.800000000000026, -6.699999999999864, 146.89999999999975, -17.19999999999986, 106.3999999999997, 22.700000000000056, 20.000000000000014, 77.59999999999923, -7.299999999999979, 23.60000000000001, 20.000000000000014, -21.399999999999984, 40.700000000000244, 20.000000000000014, 53.00000000000014, 49.40000000000006, 1.100000000000079, -22.599999999999802, 95.59999999999998, -36.69999999999977, -79.0, 0.19999999999998655, 9.49999999999997, 1.0999999999999734, 45.800000000000125, -46.600000000000136, 38.60000000000022, 3.1999999999999775, -45.09999999999976, 17.300000000000075, 20.000000000000014, 65.00000000000004, -64.00000000000088, 52.40000000000021, -76.00000000000048, -49.59999999999995, 28.100000000000055, 68.8999999999998, -202.60000000000053, -37.60000000000011, 11.299999999999972, -66.10000000000085, 101.5999999999995, 20.000000000000014, -0.7000000000000057, -110.79999999999998, -28.000000000000128, 38.00000000000005, -71.50000000000082, -0.9999999999999846, 35.30000000000021, 29.60000000000019, -120.70000000000005, 44.30000000000018, 7.100000000000038, 14.599999999999964, 27.20000000000013, -121.6000000000005, 20.000000000000014, 20.000000000000014, -70.30000000000041, 35.60000000000021, 29.9, 20.000000000000014, 20.000000000000014, 27.200000000000138, 29.90000000000012, -7.3000000000000504, 27.200000000000145, 47.00000000000024, -13.299999999999834, 39.80000000000025, -0.9999999999999846, 20.000000000000014], "policy_predator_policy_reward": [12.0, 140.0, 0.0, 0.0, 128.0, 61.0, 165.0, 28.0, 31.0, 0.0, 24.0, 14.0, 0.0, 50.0, 39.0, 31.0, 142.0, 133.0, 0.0, 29.0, 29.0, 31.0, 52.0, 18.0, 0.0, 104.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 91.0, 0.0, 0.0, 16.0, 0.0, 32.0, 65.0, 0.0, 78.0, 76.0, 6.0, 81.0, 24.0, 101.0, 53.0, 0.0, 0.0, 0.0, 85.0, 23.0, 22.0, 24.0, 0.0, 0.0, 23.0, 28.0, 0.0, 0.0, 135.0, 0.0, 0.0, 62.0, 0.0, 53.0, 35.0, 0.0, 72.0, 30.0, 19.0, 1.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 14.0, 32.0, 0.0, 36.0, 0.0, 0.0, 35.0, 0.0, 33.0, 0.0, 27.0, 0.0, 55.0, 41.0, 13.0, 0.0, 46.0, 21.0, 12.0, 0.0, 13.0, 21.0, 0.0, 0.0, 40.0, 0.0, 74.0, 21.0, 2.0, 0.0, 106.0, 72.0, 8.0, 41.0, 1.0, 0.0, 42.0, 64.0, 46.0, 0.0, 0.0, 48.0, 17.0, 5.0, 67.0, 0.0, 46.0, 0.0, 0.0, 79.0, 0.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 23.0, 1.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 3.180439244539217, "mean_inference_ms": 9.042074567897668, "mean_action_processing_ms": 1.409885926798408, "mean_env_wait_ms": 1.156567832552927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04523793856302897, "StateBufferConnector_ms": 0.006970432069566514, "ViewRequirementAgentConnector_ms": 0.5750932627254062}, "num_episodes": 18, "episode_return_max": 282.60000000000053, "episode_return_min": -105.29999999999984, "episode_return_mean": 47.254166666666556, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 234.62098933434294, "num_env_steps_trained_throughput_per_sec": 234.62098933434294, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 21917.843, "restore_workers_time_ms": 0.31, "training_step_time_ms": 21917.371, "sample_time_ms": 6883.962, "learn_time_ms": 15000.542, "learn_throughput": 266.657, "synch_weights_time_ms": 26.045}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "e57b0_00000", "date": "2024-08-13_00-11-51", "timestamp": 1723522311, "time_this_iter_s": 17.1094012260437, "time_total_s": 88.19040536880493, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09db790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 88.19040536880493, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 84.83749999999999, "ram_util_percent": 83.25000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.522083196816621, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.748559813398533, "policy_loss": -0.0012355280209766337, "vf_loss": 4.748904925679404, "vf_explained_var": -0.010501273094661652, "kl": 0.008904216856748078, "entropy": 1.539625628600045, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.22289253601597414, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2662937961558187, "policy_loss": -0.006284164299784356, "vf_loss": 3.2717876112650313, "vf_explained_var": 0.009330816117544024, "kl": 0.007903487479369161, "entropy": 1.5919409239102924, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 282.60000000000053, "episode_reward_min": -116.60000000000008, "episode_reward_mean": 35.870707070706956, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -284.5000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.7, "predator_policy": 165.0}, "policy_reward_mean": {"prey_policy": -8.236363636363683, "predator_policy": 26.171717171717173}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.900000000000029, 62.50000000000026, -44.29999999999989, -16.899999999999963, 111.19999999999906, 71.09999999999948, 11.999999999999993, 58.70000000000011, -105.29999999999984, 282.60000000000053, 31.60000000000032, -74.80000000000142, 24.900000000000077, 130.2999999999997, 150.19999999999905, 50.80000000000049, 95.59999999999985, 33.20000000000013, 271.1999999999999, 20.699999999999946, -19.899999999999977, 17.200000000000244, -41.69999999999978, 82.50000000000009, 118.29999999999862, -76.09999999999997, 173.5999999999991, 40.0000000000003, 148.59999999999928, 58.90000000000027, -56.300000000000445, 60.899999999999764, -18.299999999999535, 66.29999999999997, -32.89999999999974, 53.10000000000012, 160.6999999999991, 129.09999999999917, 97.59999999999849, 62.30000000000031, 34.600000000000016, 60.70000000000049, 137.39999999999918, 11.500000000000139, 85.90000000000002, 17.200000000000017, 23.600000000000097, 66.20000000000006, 53.80000000000045, 6.20000000000007, 84.99999999999903, 28.400000000000134, -30.60000000000052, 98.99999999999893, -62.200000000000635, -5.799999999999754, 122.59999999999876, -5.499999999999943, 56.00000000000033, -24.499999999999517, 86.8999999999988, -9.399999999999759, 67.70000000000002, -15.399999999999649, 40.0000000000003, 13.299999999999931, 49.90000000000028, 47.20000000000042, 35.600000000000264, 74.19999999999976, 50.500000000000405, 29.000000000000128, 104.79999999999853, 22.20000000000016, 44.600000000000385, -36.29999999999999, -10.699999999999967, -48.89999999999988, 3.1000000000001577, -21.19999999999991, -92.59999999999972, 83.89999999999905, -6.20000000000007, 37.800000000000296, 86.59999999999891, 77.79999999999944, -14.599999999999644, 32.19999999999966, -47.30000000000094, 83.699999999999, -113.39999999999978, -44.299999999999926, 15.699999999999967, 66.50000000000014, -116.60000000000008, 14.300000000000106, 40.0000000000003, 21.300000000000065, -33.499999999999694], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [107.29999999999995, -275.20000000000005, 20.000000000000014, 42.50000000000008, -284.5000000000002, 51.20000000000002, -227.2000000000001, 17.29999999999999, 59.30000000000002, 20.90000000000003, 37.4000000000001, -4.299999999999914, -51.40000000000046, 13.400000000000176, 4.399999999999999, -15.69999999999991, -152.20000000000002, -228.1000000000001, 113.0, 140.59999999999988, -31.599999999999824, 3.1999999999999766, -58.6000000000007, -86.20000000000071, 10.1, -89.2000000000005, 2.2999999999999643, 106.99999999999997, 32.300000000000225, 110.89999999999965, 30.8000000000002, 20.000000000000014, 175.7, -171.10000000000002, -13.599999999999875, 30.800000000000104, 86.0, 153.19999999999973, -64.3000000000003, 20.000000000000014, -134.80000000000015, -39.09999999999988, -91.6000000000002, 21.800000000000047, -136.3, -30.399999999999814, 39.199999999999996, -9.699999999999939, 72.19999999999962, 46.09999999999997, -28.299999999999827, -155.79999999999984, 70.39999999999982, 57.19999999999956, 20.000000000000014, 20.000000000000014, -57.999999999999815, 155.59999999999985, 34.39999999999999, 24.500000000000096, -211.30000000000004, 20.000000000000014, -21.099999999999998, 20.000000000000014, -57.70000000000048, -13.599999999999897, -34.59999999999985, 65.89999999999993, -152.20000000000056, 17.300000000000054, 39.800000000000026, -6.699999999999864, 146.89999999999975, -17.19999999999986, 106.3999999999997, 22.700000000000056, 20.000000000000014, 77.59999999999923, -7.299999999999979, 23.60000000000001, 20.000000000000014, -21.399999999999984, 40.700000000000244, 20.000000000000014, 53.00000000000014, 49.40000000000006, 1.100000000000079, -22.599999999999802, 95.59999999999998, -36.69999999999977, -79.0, 0.19999999999998655, 9.49999999999997, 1.0999999999999734, 45.800000000000125, -46.600000000000136, 38.60000000000022, 3.1999999999999775, -45.09999999999976, 17.300000000000075, 20.000000000000014, 65.00000000000004, -64.00000000000088, 52.40000000000021, -76.00000000000048, -49.59999999999995, 28.100000000000055, 68.8999999999998, -202.60000000000053, -37.60000000000011, 11.299999999999972, -66.10000000000085, 101.5999999999995, 20.000000000000014, -0.7000000000000057, -110.79999999999998, -28.000000000000128, 38.00000000000005, -71.50000000000082, -0.9999999999999846, 35.30000000000021, 29.60000000000019, -120.70000000000005, 44.30000000000018, 7.100000000000038, 14.599999999999964, 27.20000000000013, -121.6000000000005, 20.000000000000014, 20.000000000000014, -70.30000000000041, 35.60000000000021, 29.9, 20.000000000000014, 20.000000000000014, 27.200000000000138, 29.90000000000012, -7.3000000000000504, 27.200000000000145, 47.00000000000024, -13.299999999999834, 39.80000000000025, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 84.79999999999927, -50.800000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999975, 44.60000000000006, -223.9000000000003, 20.000000000000014, -108.70000000000047, -112.30000000000014, -13.599999999999868, -49.299999999999784, 16.399999999999977, 20.000000000000014, -113.20000000000009, -32.50000000000003, -138.1000000000003, 20.000000000000014, 62.90000000000021, 9.499999999999964, -57.69999999999997, 15.799999999999976, 20.000000000000014, -18.099999999999824, 67.69999999999989, 57.80000000000019, 20.000000000000014, -99.70000000000064, 28.100000000000158, 44.59999999999997, -108.40000000000002, -83.20000000000003, -15.100000000000144, -21.999999999999787, 76.69999999999929, -84.99999999999983, -135.4000000000007, -37.89999999999998, -63.400000000000006, -36.69999999999976, 25.400000000000098, 35.90000000000006, -3.400000000000012, -78.69999999999996, -160.90000000000026, -42.99999999999976, 26.300000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -33.6999999999998, 27.20000000000013, -135.7000000000005], "policy_predator_policy_reward": [12.0, 140.0, 0.0, 0.0, 128.0, 61.0, 165.0, 28.0, 31.0, 0.0, 24.0, 14.0, 0.0, 50.0, 39.0, 31.0, 142.0, 133.0, 0.0, 29.0, 29.0, 31.0, 52.0, 18.0, 0.0, 104.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 91.0, 0.0, 0.0, 16.0, 0.0, 32.0, 65.0, 0.0, 78.0, 76.0, 6.0, 81.0, 24.0, 101.0, 53.0, 0.0, 0.0, 0.0, 85.0, 23.0, 22.0, 24.0, 0.0, 0.0, 23.0, 28.0, 0.0, 0.0, 135.0, 0.0, 0.0, 62.0, 0.0, 53.0, 35.0, 0.0, 72.0, 30.0, 19.0, 1.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 14.0, 32.0, 0.0, 36.0, 0.0, 0.0, 35.0, 0.0, 33.0, 0.0, 27.0, 0.0, 55.0, 41.0, 13.0, 0.0, 46.0, 21.0, 12.0, 0.0, 13.0, 21.0, 0.0, 0.0, 40.0, 0.0, 74.0, 21.0, 2.0, 0.0, 106.0, 72.0, 8.0, 41.0, 1.0, 0.0, 42.0, 64.0, 46.0, 0.0, 0.0, 48.0, 17.0, 5.0, 67.0, 0.0, 46.0, 0.0, 0.0, 79.0, 0.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 23.0, 1.0, 10.0, 0.0, 0.0, 0.0, 25.0, 28.0, 13.0, 0.0, 95.0, 48.0, 0.0, 78.0, 0.0, 77.0, 3.0, 33.0, 0.0, 72.0, 28.0, 50.0, 0.0, 1.0, 37.0, 5.0, 2.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 57.0, 45.0, 51.0, 51.0, 0.0, 0.0, 29.0, 28.0, 79.0, 0.0, 57.0, 0.0, 27.0, 34.0, 0.0, 12.0, 111.0, 30.0, 1.0, 0.0, 0.0, 35.0, 0.0, 75.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 3.08929663571325, "mean_inference_ms": 8.663808864377684, "mean_action_processing_ms": 1.3493483557404093, "mean_env_wait_ms": 1.1032410012012785, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03711069473112472, "StateBufferConnector_ms": 0.0061328965004044346, "ViewRequirementAgentConnector_ms": 0.48139275926532166}, "num_episodes": 27, "episode_return_max": 282.60000000000053, "episode_return_min": -116.60000000000008, "episode_return_mean": 35.870707070706956, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 164.2962011333305, "num_env_steps_trained_throughput_per_sec": 164.2962011333305, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 22403.531, "restore_workers_time_ms": 0.251, "training_step_time_ms": 22403.138, "sample_time_ms": 6239.921, "learn_time_ms": 16126.142, "learn_throughput": 248.044, "synch_weights_time_ms": 31.013}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "e57b0_00000", "date": "2024-08-13_00-12-16", "timestamp": 1723522336, "time_this_iter_s": 24.47066307067871, "time_total_s": 112.66106843948364, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b4b1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 112.66106843948364, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 94.2, "ram_util_percent": 83.57575757575758}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1295920080845319, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.592756481902309, "policy_loss": -0.004026807024434366, "vf_loss": 5.5952622711343105, "vf_explained_var": -0.006315296194540761, "kl": 0.015210197524238037, "entropy": 1.5313009884622362, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.32782048907860245, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0272577414436945, "policy_loss": -0.0036493751622007162, "vf_loss": 4.030006788395069, "vf_explained_var": 0.0041203083184661055, "kl": 0.009003257782511051, "entropy": 1.5651291299118566, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 271.1999999999999, "episode_reward_min": -337.39999999999907, "episode_reward_mean": 18.68699999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -331.6000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 155.59999999999985, "predator_policy": 177.0}, "policy_reward_mean": {"prey_policy": -16.97150000000004, "predator_policy": 26.315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.20000000000013, 271.1999999999999, 20.699999999999946, -19.899999999999977, 17.200000000000244, -41.69999999999978, 82.50000000000009, 118.29999999999862, -76.09999999999997, 173.5999999999991, 40.0000000000003, 148.59999999999928, 58.90000000000027, -56.300000000000445, 60.899999999999764, -18.299999999999535, 66.29999999999997, -32.89999999999974, 53.10000000000012, 160.6999999999991, 129.09999999999917, 97.59999999999849, 62.30000000000031, 34.600000000000016, 60.70000000000049, 137.39999999999918, 11.500000000000139, 85.90000000000002, 17.200000000000017, 23.600000000000097, 66.20000000000006, 53.80000000000045, 6.20000000000007, 84.99999999999903, 28.400000000000134, -30.60000000000052, 98.99999999999893, -62.200000000000635, -5.799999999999754, 122.59999999999876, -5.499999999999943, 56.00000000000033, -24.499999999999517, 86.8999999999988, -9.399999999999759, 67.70000000000002, -15.399999999999649, 40.0000000000003, 13.299999999999931, 49.90000000000028, 47.20000000000042, 35.600000000000264, 74.19999999999976, 50.500000000000405, 29.000000000000128, 104.79999999999853, 22.20000000000016, 44.600000000000385, -36.29999999999999, -10.699999999999967, -48.89999999999988, 3.1000000000001577, -21.19999999999991, -92.59999999999972, 83.89999999999905, -6.20000000000007, 37.800000000000296, 86.59999999999891, 77.79999999999944, -14.599999999999644, 32.19999999999966, -47.30000000000094, 83.699999999999, -113.39999999999978, -44.299999999999926, 15.699999999999967, 66.50000000000014, -116.60000000000008, 14.300000000000106, 40.0000000000003, 21.300000000000065, -33.499999999999694, 58.00000000000051, -199.39999999999986, -29.999999999999744, -91.10000000000011, -27.29999999999985, -84.9, 30.300000000000374, -337.39999999999907, 21.30000000000003, 79.59999999999928, -12.899999999999771, -77.99999999999999, 23.400000000000027, -76.10000000000083, -74.30000000000003, -60.99999999999992, 41.800000000000324, -40.199999999999555], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-13.599999999999875, 30.800000000000104, 86.0, 153.19999999999973, -64.3000000000003, 20.000000000000014, -134.80000000000015, -39.09999999999988, -91.6000000000002, 21.800000000000047, -136.3, -30.399999999999814, 39.199999999999996, -9.699999999999939, 72.19999999999962, 46.09999999999997, -28.299999999999827, -155.79999999999984, 70.39999999999982, 57.19999999999956, 20.000000000000014, 20.000000000000014, -57.999999999999815, 155.59999999999985, 34.39999999999999, 24.500000000000096, -211.30000000000004, 20.000000000000014, -21.099999999999998, 20.000000000000014, -57.70000000000048, -13.599999999999897, -34.59999999999985, 65.89999999999993, -152.20000000000056, 17.300000000000054, 39.800000000000026, -6.699999999999864, 146.89999999999975, -17.19999999999986, 106.3999999999997, 22.700000000000056, 20.000000000000014, 77.59999999999923, -7.299999999999979, 23.60000000000001, 20.000000000000014, -21.399999999999984, 40.700000000000244, 20.000000000000014, 53.00000000000014, 49.40000000000006, 1.100000000000079, -22.599999999999802, 95.59999999999998, -36.69999999999977, -79.0, 0.19999999999998655, 9.49999999999997, 1.0999999999999734, 45.800000000000125, -46.600000000000136, 38.60000000000022, 3.1999999999999775, -45.09999999999976, 17.300000000000075, 20.000000000000014, 65.00000000000004, -64.00000000000088, 52.40000000000021, -76.00000000000048, -49.59999999999995, 28.100000000000055, 68.8999999999998, -202.60000000000053, -37.60000000000011, 11.299999999999972, -66.10000000000085, 101.5999999999995, 20.000000000000014, -0.7000000000000057, -110.79999999999998, -28.000000000000128, 38.00000000000005, -71.50000000000082, -0.9999999999999846, 35.30000000000021, 29.60000000000019, -120.70000000000005, 44.30000000000018, 7.100000000000038, 14.599999999999964, 27.20000000000013, -121.6000000000005, 20.000000000000014, 20.000000000000014, -70.30000000000041, 35.60000000000021, 29.9, 20.000000000000014, 20.000000000000014, 27.200000000000138, 29.90000000000012, -7.3000000000000504, 27.200000000000145, 47.00000000000024, -13.299999999999834, 39.80000000000025, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 84.79999999999927, -50.800000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999975, 44.60000000000006, -223.9000000000003, 20.000000000000014, -108.70000000000047, -112.30000000000014, -13.599999999999868, -49.299999999999784, 16.399999999999977, 20.000000000000014, -113.20000000000009, -32.50000000000003, -138.1000000000003, 20.000000000000014, 62.90000000000021, 9.499999999999964, -57.69999999999997, 15.799999999999976, 20.000000000000014, -18.099999999999824, 67.69999999999989, 57.80000000000019, 20.000000000000014, -99.70000000000064, 28.100000000000158, 44.59999999999997, -108.40000000000002, -83.20000000000003, -15.100000000000144, -21.999999999999787, 76.69999999999929, -84.99999999999983, -135.4000000000007, -37.89999999999998, -63.400000000000006, -36.69999999999976, 25.400000000000098, 35.90000000000006, -3.400000000000012, -78.69999999999996, -160.90000000000026, -42.99999999999976, 26.300000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -33.6999999999998, 27.20000000000013, -135.7000000000005, 20.000000000000014, 38.00000000000025, -161.49999999999983, -214.90000000000003, -127.00000000000011, -9.99999999999996, 20.000000000000014, -250.09999999999988, -128.3000000000001, 20.000000000000014, -116.50000000000009, -33.39999999999995, -5.200000000000031, 9.499999999999982, -331.6000000000001, -185.8000000000002, -33.6999999999998, 20.000000000000014, 20.000000000000014, 50.60000000000009, -64.00000000000054, 1.0999999999999688, -205.00000000000014, 1.9999999999999107, 20.000000000000014, -13.599999999999964, -182.80000000000055, -28.3, -70.29999999999984, -109.00000000000006, -167.20000000000005, -32.799999999999834, 20.000000000000014, 21.80000000000004, -129.10000000000073, 17.899999999999988], "policy_predator_policy_reward": [0.0, 16.0, 0.0, 32.0, 65.0, 0.0, 78.0, 76.0, 6.0, 81.0, 24.0, 101.0, 53.0, 0.0, 0.0, 0.0, 85.0, 23.0, 22.0, 24.0, 0.0, 0.0, 23.0, 28.0, 0.0, 0.0, 135.0, 0.0, 0.0, 62.0, 0.0, 53.0, 35.0, 0.0, 72.0, 30.0, 19.0, 1.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 14.0, 32.0, 0.0, 36.0, 0.0, 0.0, 35.0, 0.0, 33.0, 0.0, 27.0, 0.0, 55.0, 41.0, 13.0, 0.0, 46.0, 21.0, 12.0, 0.0, 13.0, 21.0, 0.0, 0.0, 40.0, 0.0, 74.0, 21.0, 2.0, 0.0, 106.0, 72.0, 8.0, 41.0, 1.0, 0.0, 42.0, 64.0, 46.0, 0.0, 0.0, 48.0, 17.0, 5.0, 67.0, 0.0, 46.0, 0.0, 0.0, 79.0, 0.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 23.0, 1.0, 10.0, 0.0, 0.0, 0.0, 25.0, 28.0, 13.0, 0.0, 95.0, 48.0, 0.0, 78.0, 0.0, 77.0, 3.0, 33.0, 0.0, 72.0, 28.0, 50.0, 0.0, 1.0, 37.0, 5.0, 2.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 57.0, 45.0, 51.0, 51.0, 0.0, 0.0, 29.0, 28.0, 79.0, 0.0, 57.0, 0.0, 27.0, 34.0, 0.0, 12.0, 111.0, 30.0, 1.0, 0.0, 0.0, 35.0, 0.0, 75.0, 0.0, 0.0, 0.0, 177.0, 0.0, 107.0, 0.0, 139.0, 0.0, 0.0, 81.0, 0.0, 65.0, 12.0, 14.0, 9.0, 171.0, 35.0, 0.0, 9.0, 0.0, 49.0, 1.0, 36.0, 89.0, 9.0, 8.0, 22.0, 113.0, 89.0, 16.0, 135.0, 4.0, 0.0, 0.0, 68.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 3.1190334099173795, "mean_inference_ms": 8.581100497295058, "mean_action_processing_ms": 1.335705652269844, "mean_env_wait_ms": 1.0850745947605398, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03603172302246094, "StateBufferConnector_ms": 0.005892753601074219, "ViewRequirementAgentConnector_ms": 0.4567868709564209}, "num_episodes": 18, "episode_return_max": 271.1999999999999, "episode_return_min": -337.39999999999907, "episode_return_mean": 18.68699999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 188.31017749585527, "num_env_steps_trained_throughput_per_sec": 188.31017749585527, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 22209.871, "restore_workers_time_ms": 0.216, "training_step_time_ms": 22209.525, "sample_time_ms": 6123.874, "learn_time_ms": 16050.785, "learn_throughput": 249.209, "synch_weights_time_ms": 28.601}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "e57b0_00000", "date": "2024-08-13_00-12-37", "timestamp": 1723522357, "time_this_iter_s": 21.29367470741272, "time_total_s": 133.95474314689636, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b415e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 133.95474314689636, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 89.8741935483871, "ram_util_percent": 83.77419354838712}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.032816601075508, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.974353707530511, "policy_loss": -0.007228985609161475, "vf_loss": 6.979367961076202, "vf_explained_var": -0.00037267223867789776, "kl": 0.022147551970231272, "entropy": 1.4794791880738798, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49281880987226645, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.660248214731771, "policy_loss": -0.0035216350492740436, "vf_loss": 6.662552329219838, "vf_explained_var": 0.004082176168128927, "kl": 0.012175409938802036, "entropy": 1.5325714171878875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 160.6999999999991, "episode_reward_min": -337.39999999999907, "episode_reward_mean": -5.2750000000000785, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -331.6000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 146.89999999999975, "predator_policy": 214.0}, "policy_reward_mean": {"prey_policy": -36.50750000000006, "predator_policy": 33.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [53.10000000000012, 160.6999999999991, 129.09999999999917, 97.59999999999849, 62.30000000000031, 34.600000000000016, 60.70000000000049, 137.39999999999918, 11.500000000000139, 85.90000000000002, 17.200000000000017, 23.600000000000097, 66.20000000000006, 53.80000000000045, 6.20000000000007, 84.99999999999903, 28.400000000000134, -30.60000000000052, 98.99999999999893, -62.200000000000635, -5.799999999999754, 122.59999999999876, -5.499999999999943, 56.00000000000033, -24.499999999999517, 86.8999999999988, -9.399999999999759, 67.70000000000002, -15.399999999999649, 40.0000000000003, 13.299999999999931, 49.90000000000028, 47.20000000000042, 35.600000000000264, 74.19999999999976, 50.500000000000405, 29.000000000000128, 104.79999999999853, 22.20000000000016, 44.600000000000385, -36.29999999999999, -10.699999999999967, -48.89999999999988, 3.1000000000001577, -21.19999999999991, -92.59999999999972, 83.89999999999905, -6.20000000000007, 37.800000000000296, 86.59999999999891, 77.79999999999944, -14.599999999999644, 32.19999999999966, -47.30000000000094, 83.699999999999, -113.39999999999978, -44.299999999999926, 15.699999999999967, 66.50000000000014, -116.60000000000008, 14.300000000000106, 40.0000000000003, 21.300000000000065, -33.499999999999694, 58.00000000000051, -199.39999999999986, -29.999999999999744, -91.10000000000011, -27.29999999999985, -84.9, 30.300000000000374, -337.39999999999907, 21.30000000000003, 79.59999999999928, -12.899999999999771, -77.99999999999999, 23.400000000000027, -76.10000000000083, -74.30000000000003, -60.99999999999992, 41.800000000000324, -40.199999999999555, -276.9000000000002, -34.099999999999746, -152.80000000000047, 35.600000000000236, -245.5000000000002, 132.89999999999938, 40.0000000000003, -75.29999999999993, -103.40000000000012, -138.39999999999992, -36.999999999999545, -84.80000000000028, -97.70000000000016, -236.2000000000006, -115.00000000000037, -189.10000000000068, -4.1999999999995925, 31.900000000000368], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [39.800000000000026, -6.699999999999864, 146.89999999999975, -17.19999999999986, 106.3999999999997, 22.700000000000056, 20.000000000000014, 77.59999999999923, -7.299999999999979, 23.60000000000001, 20.000000000000014, -21.399999999999984, 40.700000000000244, 20.000000000000014, 53.00000000000014, 49.40000000000006, 1.100000000000079, -22.599999999999802, 95.59999999999998, -36.69999999999977, -79.0, 0.19999999999998655, 9.49999999999997, 1.0999999999999734, 45.800000000000125, -46.600000000000136, 38.60000000000022, 3.1999999999999775, -45.09999999999976, 17.300000000000075, 20.000000000000014, 65.00000000000004, -64.00000000000088, 52.40000000000021, -76.00000000000048, -49.59999999999995, 28.100000000000055, 68.8999999999998, -202.60000000000053, -37.60000000000011, 11.299999999999972, -66.10000000000085, 101.5999999999995, 20.000000000000014, -0.7000000000000057, -110.79999999999998, -28.000000000000128, 38.00000000000005, -71.50000000000082, -0.9999999999999846, 35.30000000000021, 29.60000000000019, -120.70000000000005, 44.30000000000018, 7.100000000000038, 14.599999999999964, 27.20000000000013, -121.6000000000005, 20.000000000000014, 20.000000000000014, -70.30000000000041, 35.60000000000021, 29.9, 20.000000000000014, 20.000000000000014, 27.200000000000138, 29.90000000000012, -7.3000000000000504, 27.200000000000145, 47.00000000000024, -13.299999999999834, 39.80000000000025, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 84.79999999999927, -50.800000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999975, 44.60000000000006, -223.9000000000003, 20.000000000000014, -108.70000000000047, -112.30000000000014, -13.599999999999868, -49.299999999999784, 16.399999999999977, 20.000000000000014, -113.20000000000009, -32.50000000000003, -138.1000000000003, 20.000000000000014, 62.90000000000021, 9.499999999999964, -57.69999999999997, 15.799999999999976, 20.000000000000014, -18.099999999999824, 67.69999999999989, 57.80000000000019, 20.000000000000014, -99.70000000000064, 28.100000000000158, 44.59999999999997, -108.40000000000002, -83.20000000000003, -15.100000000000144, -21.999999999999787, 76.69999999999929, -84.99999999999983, -135.4000000000007, -37.89999999999998, -63.400000000000006, -36.69999999999976, 25.400000000000098, 35.90000000000006, -3.400000000000012, -78.69999999999996, -160.90000000000026, -42.99999999999976, 26.300000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -33.6999999999998, 27.20000000000013, -135.7000000000005, 20.000000000000014, 38.00000000000025, -161.49999999999983, -214.90000000000003, -127.00000000000011, -9.99999999999996, 20.000000000000014, -250.09999999999988, -128.3000000000001, 20.000000000000014, -116.50000000000009, -33.39999999999995, -5.200000000000031, 9.499999999999982, -331.6000000000001, -185.8000000000002, -33.6999999999998, 20.000000000000014, 20.000000000000014, 50.60000000000009, -64.00000000000054, 1.0999999999999688, -205.00000000000014, 1.9999999999999107, 20.000000000000014, -13.599999999999964, -182.80000000000055, -28.3, -70.29999999999984, -109.00000000000006, -167.20000000000005, -32.799999999999834, 20.000000000000014, 21.80000000000004, -129.10000000000073, 17.899999999999988, -198.40000000000043, -305.50000000000006, 11.899999999999949, -183.99999999999994, -103.90000000000002, -208.90000000000043, 20.000000000000014, 11.599999999999964, -131.50000000000009, -273.99999999999966, 71.29999999999961, -86.40000000000006, 20.000000000000014, 20.000000000000014, -63.69999999999991, -139.60000000000014, -261.40000000000015, 20.000000000000014, -156.50000000000003, -325.9, -84.10000000000072, -19.899999999999743, -271.2, -127.60000000000045, -136.30000000000038, -178.40000000000003, -204.70000000000033, -197.5000000000002, -89.19999999999999, -164.80000000000015, -278.1999999999997, -103.90000000000005, -27.399999999999793, -17.800000000000008, -6.399999999999979, -12.699999999999978], "policy_predator_policy_reward": [19.0, 1.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 14.0, 32.0, 0.0, 36.0, 0.0, 0.0, 35.0, 0.0, 33.0, 0.0, 27.0, 0.0, 55.0, 41.0, 13.0, 0.0, 46.0, 21.0, 12.0, 0.0, 13.0, 21.0, 0.0, 0.0, 40.0, 0.0, 74.0, 21.0, 2.0, 0.0, 106.0, 72.0, 8.0, 41.0, 1.0, 0.0, 42.0, 64.0, 46.0, 0.0, 0.0, 48.0, 17.0, 5.0, 67.0, 0.0, 46.0, 0.0, 0.0, 79.0, 0.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 23.0, 1.0, 10.0, 0.0, 0.0, 0.0, 25.0, 28.0, 13.0, 0.0, 95.0, 48.0, 0.0, 78.0, 0.0, 77.0, 3.0, 33.0, 0.0, 72.0, 28.0, 50.0, 0.0, 1.0, 37.0, 5.0, 2.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 57.0, 45.0, 51.0, 51.0, 0.0, 0.0, 29.0, 28.0, 79.0, 0.0, 57.0, 0.0, 27.0, 34.0, 0.0, 12.0, 111.0, 30.0, 1.0, 0.0, 0.0, 35.0, 0.0, 75.0, 0.0, 0.0, 0.0, 177.0, 0.0, 107.0, 0.0, 139.0, 0.0, 0.0, 81.0, 0.0, 65.0, 12.0, 14.0, 9.0, 171.0, 35.0, 0.0, 9.0, 0.0, 49.0, 1.0, 36.0, 89.0, 9.0, 8.0, 22.0, 113.0, 89.0, 16.0, 135.0, 4.0, 0.0, 0.0, 68.0, 3.0, 36.0, 191.0, 25.0, 113.0, 154.0, 6.0, 4.0, 0.0, 0.0, 160.0, 80.0, 68.0, 0.0, 0.0, 52.0, 76.0, 134.0, 4.0, 155.0, 189.0, 4.0, 63.0, 185.0, 129.0, 3.0, 214.0, 62.0, 104.0, 33.0, 106.0, 50.0, 143.0, 41.0, 0.0, 10.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.941771614342561, "mean_inference_ms": 8.01995904207151, "mean_action_processing_ms": 1.2497623495352057, "mean_env_wait_ms": 1.0186260773529958, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019662022590637207, "StateBufferConnector_ms": 0.0036687850952148438, "ViewRequirementAgentConnector_ms": 0.2987605333328247}, "num_episodes": 18, "episode_return_max": 160.6999999999991, "episode_return_min": -337.39999999999907, "episode_return_mean": -5.2750000000000785, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.14825407408676, "num_env_steps_trained_throughput_per_sec": 212.14825407408676, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 21730.568, "restore_workers_time_ms": 0.188, "training_step_time_ms": 21730.264, "sample_time_ms": 5966.938, "learn_time_ms": 15730.656, "learn_throughput": 254.281, "synch_weights_time_ms": 27.123}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "e57b0_00000", "date": "2024-08-13_00-12-56", "timestamp": 1723522376, "time_this_iter_s": 18.957803964614868, "time_total_s": 152.91254711151123, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b094ae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 152.91254711151123, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 87.67777777777779, "ram_util_percent": 83.74074074074075}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2041494572919513, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.8327437510566105, "policy_loss": -0.0016321055737703487, "vf_loss": 4.833357528277806, "vf_explained_var": -0.005872177604645017, "kl": 0.0067889137316820255, "entropy": 1.4350703709970707, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3621884494290623, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.936114558845601, "policy_loss": -0.0052516527776975954, "vf_loss": 4.940489273601108, "vf_explained_var": 0.0011131710476345487, "kl": 0.008769402652633226, "entropy": 1.5410886462403353, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 132.89999999999938, "episode_reward_min": -337.39999999999907, "episode_reward_mean": -27.253000000000053, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -362.19999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 101.5999999999995, "predator_policy": 214.0}, "policy_reward_mean": {"prey_policy": -55.80150000000007, "predator_policy": 42.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [98.99999999999893, -62.200000000000635, -5.799999999999754, 122.59999999999876, -5.499999999999943, 56.00000000000033, -24.499999999999517, 86.8999999999988, -9.399999999999759, 67.70000000000002, -15.399999999999649, 40.0000000000003, 13.299999999999931, 49.90000000000028, 47.20000000000042, 35.600000000000264, 74.19999999999976, 50.500000000000405, 29.000000000000128, 104.79999999999853, 22.20000000000016, 44.600000000000385, -36.29999999999999, -10.699999999999967, -48.89999999999988, 3.1000000000001577, -21.19999999999991, -92.59999999999972, 83.89999999999905, -6.20000000000007, 37.800000000000296, 86.59999999999891, 77.79999999999944, -14.599999999999644, 32.19999999999966, -47.30000000000094, 83.699999999999, -113.39999999999978, -44.299999999999926, 15.699999999999967, 66.50000000000014, -116.60000000000008, 14.300000000000106, 40.0000000000003, 21.300000000000065, -33.499999999999694, 58.00000000000051, -199.39999999999986, -29.999999999999744, -91.10000000000011, -27.29999999999985, -84.9, 30.300000000000374, -337.39999999999907, 21.30000000000003, 79.59999999999928, -12.899999999999771, -77.99999999999999, 23.400000000000027, -76.10000000000083, -74.30000000000003, -60.99999999999992, 41.800000000000324, -40.199999999999555, -276.9000000000002, -34.099999999999746, -152.80000000000047, 35.600000000000236, -245.5000000000002, 132.89999999999938, 40.0000000000003, -75.29999999999993, -103.40000000000012, -138.39999999999992, -36.999999999999545, -84.80000000000028, -97.70000000000016, -236.2000000000006, -115.00000000000037, -189.10000000000068, -4.1999999999995925, 31.900000000000368, -46.49999999999969, 40.0000000000003, -40.99999999999976, -79.60000000000096, -38.29999999999957, -53.49999999999958, 85.89999999999884, 52.20000000000051, -70.39999999999989, -112.30000000000024, -142.40000000000003, 37.40000000000027, -64.50000000000091, -154.30000000000058, -281.60000000000053, 18.300000000000036, 9.799999999999967, -274.29999999999984], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [28.100000000000055, 68.8999999999998, -202.60000000000053, -37.60000000000011, 11.299999999999972, -66.10000000000085, 101.5999999999995, 20.000000000000014, -0.7000000000000057, -110.79999999999998, -28.000000000000128, 38.00000000000005, -71.50000000000082, -0.9999999999999846, 35.30000000000021, 29.60000000000019, -120.70000000000005, 44.30000000000018, 7.100000000000038, 14.599999999999964, 27.20000000000013, -121.6000000000005, 20.000000000000014, 20.000000000000014, -70.30000000000041, 35.60000000000021, 29.9, 20.000000000000014, 20.000000000000014, 27.200000000000138, 29.90000000000012, -7.3000000000000504, 27.200000000000145, 47.00000000000024, -13.299999999999834, 39.80000000000025, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 84.79999999999927, -50.800000000000004, 20.000000000000014, 20.000000000000014, 11.599999999999975, 44.60000000000006, -223.9000000000003, 20.000000000000014, -108.70000000000047, -112.30000000000014, -13.599999999999868, -49.299999999999784, 16.399999999999977, 20.000000000000014, -113.20000000000009, -32.50000000000003, -138.1000000000003, 20.000000000000014, 62.90000000000021, 9.499999999999964, -57.69999999999997, 15.799999999999976, 20.000000000000014, -18.099999999999824, 67.69999999999989, 57.80000000000019, 20.000000000000014, -99.70000000000064, 28.100000000000158, 44.59999999999997, -108.40000000000002, -83.20000000000003, -15.100000000000144, -21.999999999999787, 76.69999999999929, -84.99999999999983, -135.4000000000007, -37.89999999999998, -63.400000000000006, -36.69999999999976, 25.400000000000098, 35.90000000000006, -3.400000000000012, -78.69999999999996, -160.90000000000026, -42.99999999999976, 26.300000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -33.6999999999998, 27.20000000000013, -135.7000000000005, 20.000000000000014, 38.00000000000025, -161.49999999999983, -214.90000000000003, -127.00000000000011, -9.99999999999996, 20.000000000000014, -250.09999999999988, -128.3000000000001, 20.000000000000014, -116.50000000000009, -33.39999999999995, -5.200000000000031, 9.499999999999982, -331.6000000000001, -185.8000000000002, -33.6999999999998, 20.000000000000014, 20.000000000000014, 50.60000000000009, -64.00000000000054, 1.0999999999999688, -205.00000000000014, 1.9999999999999107, 20.000000000000014, -13.599999999999964, -182.80000000000055, -28.3, -70.29999999999984, -109.00000000000006, -167.20000000000005, -32.799999999999834, 20.000000000000014, 21.80000000000004, -129.10000000000073, 17.899999999999988, -198.40000000000043, -305.50000000000006, 11.899999999999949, -183.99999999999994, -103.90000000000002, -208.90000000000043, 20.000000000000014, 11.599999999999964, -131.50000000000009, -273.99999999999966, 71.29999999999961, -86.40000000000006, 20.000000000000014, 20.000000000000014, -63.69999999999991, -139.60000000000014, -261.40000000000015, 20.000000000000014, -156.50000000000003, -325.9, -84.10000000000072, -19.899999999999743, -271.2, -127.60000000000045, -136.30000000000038, -178.40000000000003, -204.70000000000033, -197.5000000000002, -89.19999999999999, -164.80000000000015, -278.1999999999997, -103.90000000000005, -27.399999999999793, -17.800000000000008, -6.399999999999979, -12.699999999999978, -215.20000000000044, 40.70000000000025, 20.000000000000014, 20.000000000000014, -77.20000000000076, -119.80000000000024, -99.70000000000053, -163.9000000000004, -32.49999999999976, -59.80000000000041, -158.50000000000065, 20.000000000000014, 65.9, 20.000000000000014, 23.000000000000057, 27.20000000000013, 29.90000000000018, -275.29999999999984, -337.1999999999996, -78.10000000000002, -56.19999999999992, -251.2, 18.199999999999992, -11.79999999999986, -179.50000000000057, 20.000000000000014, -286.2000000000002, -96.10000000000056, -255.10000000000036, -179.50000000000026, 11.600000000000009, -34.299999999999805, 20.000000000000014, -89.20000000000056, -362.19999999999993, -279.0999999999999], "policy_predator_policy_reward": [2.0, 0.0, 106.0, 72.0, 8.0, 41.0, 1.0, 0.0, 42.0, 64.0, 46.0, 0.0, 0.0, 48.0, 17.0, 5.0, 67.0, 0.0, 46.0, 0.0, 0.0, 79.0, 0.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 23.0, 1.0, 10.0, 0.0, 0.0, 0.0, 25.0, 28.0, 13.0, 0.0, 95.0, 48.0, 0.0, 78.0, 0.0, 77.0, 3.0, 33.0, 0.0, 72.0, 28.0, 50.0, 0.0, 1.0, 37.0, 5.0, 2.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 57.0, 45.0, 51.0, 51.0, 0.0, 0.0, 29.0, 28.0, 79.0, 0.0, 57.0, 0.0, 27.0, 34.0, 0.0, 12.0, 111.0, 30.0, 1.0, 0.0, 0.0, 35.0, 0.0, 75.0, 0.0, 0.0, 0.0, 177.0, 0.0, 107.0, 0.0, 139.0, 0.0, 0.0, 81.0, 0.0, 65.0, 12.0, 14.0, 9.0, 171.0, 35.0, 0.0, 9.0, 0.0, 49.0, 1.0, 36.0, 89.0, 9.0, 8.0, 22.0, 113.0, 89.0, 16.0, 135.0, 4.0, 0.0, 0.0, 68.0, 3.0, 36.0, 191.0, 25.0, 113.0, 154.0, 6.0, 4.0, 0.0, 0.0, 160.0, 80.0, 68.0, 0.0, 0.0, 52.0, 76.0, 134.0, 4.0, 155.0, 189.0, 4.0, 63.0, 185.0, 129.0, 3.0, 214.0, 62.0, 104.0, 33.0, 106.0, 50.0, 143.0, 41.0, 0.0, 10.0, 41.0, 99.0, 29.0, 0.0, 0.0, 32.0, 124.0, 112.0, 72.0, 8.0, 46.0, 66.0, 19.0, 0.0, 0.0, 0.0, 2.0, 35.0, 140.0, 109.0, 194.0, 43.0, 122.0, 0.0, 31.0, 95.0, 0.0, 151.0, 77.0, 153.0, 0.0, 0.0, 41.0, 47.0, 32.0, 162.0, 205.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.8034224516035233, "mean_inference_ms": 7.603282907532595, "mean_action_processing_ms": 1.183109119800191, "mean_env_wait_ms": 0.9667450967060828, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019176483154296875, "StateBufferConnector_ms": 0.003698110580444336, "ViewRequirementAgentConnector_ms": 0.3579901456832886}, "num_episodes": 18, "episode_return_max": 132.89999999999938, "episode_return_min": -337.39999999999907, "episode_return_mean": -27.253000000000053, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 237.91474726850387, "num_env_steps_trained_throughput_per_sec": 237.91474726850387, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 21115.841, "restore_workers_time_ms": 0.167, "training_step_time_ms": 21114.842, "sample_time_ms": 5695.737, "learn_time_ms": 15388.305, "learn_throughput": 259.938, "synch_weights_time_ms": 25.555}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "e57b0_00000", "date": "2024-08-13_00-13-13", "timestamp": 1723522393, "time_this_iter_s": 16.900321006774902, "time_total_s": 169.81286811828613, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b093cd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 169.81286811828613, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 85.72500000000001, "ram_util_percent": 83.21666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9491963027725144, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.783482398936357, "policy_loss": -0.000580371319927354, "vf_loss": 8.783664784860358, "vf_explained_var": -0.0006627056018385307, "kl": 0.002653336449417633, "entropy": 1.4718277857417152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30070159802085195, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.362417586644491, "policy_loss": -0.011455311544520397, "vf_loss": 6.3712013522153175, "vf_explained_var": -0.0007387884079463899, "kl": 0.026715299823504235, "entropy": 1.4540019020201669, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 132.89999999999938, "episode_reward_min": -568.8, "episode_reward_mean": -77.63600000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -683.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 76.69999999999929, "predator_policy": 596.0}, "policy_reward_mean": {"prey_policy": -102.97800000000007, "predator_policy": 64.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-36.29999999999999, -10.699999999999967, -48.89999999999988, 3.1000000000001577, -21.19999999999991, -92.59999999999972, 83.89999999999905, -6.20000000000007, 37.800000000000296, 86.59999999999891, 77.79999999999944, -14.599999999999644, 32.19999999999966, -47.30000000000094, 83.699999999999, -113.39999999999978, -44.299999999999926, 15.699999999999967, 66.50000000000014, -116.60000000000008, 14.300000000000106, 40.0000000000003, 21.300000000000065, -33.499999999999694, 58.00000000000051, -199.39999999999986, -29.999999999999744, -91.10000000000011, -27.29999999999985, -84.9, 30.300000000000374, -337.39999999999907, 21.30000000000003, 79.59999999999928, -12.899999999999771, -77.99999999999999, 23.400000000000027, -76.10000000000083, -74.30000000000003, -60.99999999999992, 41.800000000000324, -40.199999999999555, -276.9000000000002, -34.099999999999746, -152.80000000000047, 35.600000000000236, -245.5000000000002, 132.89999999999938, 40.0000000000003, -75.29999999999993, -103.40000000000012, -138.39999999999992, -36.999999999999545, -84.80000000000028, -97.70000000000016, -236.2000000000006, -115.00000000000037, -189.10000000000068, -4.1999999999995925, 31.900000000000368, -46.49999999999969, 40.0000000000003, -40.99999999999976, -79.60000000000096, -38.29999999999957, -53.49999999999958, 85.89999999999884, 52.20000000000051, -70.39999999999989, -112.30000000000024, -142.40000000000003, 37.40000000000027, -64.50000000000091, -154.30000000000058, -281.60000000000053, 18.300000000000036, 9.799999999999967, -274.29999999999984, 40.0000000000003, -420.49999999999966, -107.10000000000036, 16.899999999999906, -568.8, -183.80000000000018, -28.099999999999774, -524.6999999999998, -194.49999999999997, -153.40000000000018, -459.0, -357.30000000000007, -76.49999999999977, -158.89999999999998, -19.29999999999987, 9.90000000000034, 35.90000000000033, -361.60000000000014, -110.80000000000075, -291.4999999999999, 25.10000000000014, -329.5999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [44.60000000000006, -223.9000000000003, 20.000000000000014, -108.70000000000047, -112.30000000000014, -13.599999999999868, -49.299999999999784, 16.399999999999977, 20.000000000000014, -113.20000000000009, -32.50000000000003, -138.1000000000003, 20.000000000000014, 62.90000000000021, 9.499999999999964, -57.69999999999997, 15.799999999999976, 20.000000000000014, -18.099999999999824, 67.69999999999989, 57.80000000000019, 20.000000000000014, -99.70000000000064, 28.100000000000158, 44.59999999999997, -108.40000000000002, -83.20000000000003, -15.100000000000144, -21.999999999999787, 76.69999999999929, -84.99999999999983, -135.4000000000007, -37.89999999999998, -63.400000000000006, -36.69999999999976, 25.400000000000098, 35.90000000000006, -3.400000000000012, -78.69999999999996, -160.90000000000026, -42.99999999999976, 26.300000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -33.6999999999998, 27.20000000000013, -135.7000000000005, 20.000000000000014, 38.00000000000025, -161.49999999999983, -214.90000000000003, -127.00000000000011, -9.99999999999996, 20.000000000000014, -250.09999999999988, -128.3000000000001, 20.000000000000014, -116.50000000000009, -33.39999999999995, -5.200000000000031, 9.499999999999982, -331.6000000000001, -185.8000000000002, -33.6999999999998, 20.000000000000014, 20.000000000000014, 50.60000000000009, -64.00000000000054, 1.0999999999999688, -205.00000000000014, 1.9999999999999107, 20.000000000000014, -13.599999999999964, -182.80000000000055, -28.3, -70.29999999999984, -109.00000000000006, -167.20000000000005, -32.799999999999834, 20.000000000000014, 21.80000000000004, -129.10000000000073, 17.899999999999988, -198.40000000000043, -305.50000000000006, 11.899999999999949, -183.99999999999994, -103.90000000000002, -208.90000000000043, 20.000000000000014, 11.599999999999964, -131.50000000000009, -273.99999999999966, 71.29999999999961, -86.40000000000006, 20.000000000000014, 20.000000000000014, -63.69999999999991, -139.60000000000014, -261.40000000000015, 20.000000000000014, -156.50000000000003, -325.9, -84.10000000000072, -19.899999999999743, -271.2, -127.60000000000045, -136.30000000000038, -178.40000000000003, -204.70000000000033, -197.5000000000002, -89.19999999999999, -164.80000000000015, -278.1999999999997, -103.90000000000005, -27.399999999999793, -17.800000000000008, -6.399999999999979, -12.699999999999978, -215.20000000000044, 40.70000000000025, 20.000000000000014, 20.000000000000014, -77.20000000000076, -119.80000000000024, -99.70000000000053, -163.9000000000004, -32.49999999999976, -59.80000000000041, -158.50000000000065, 20.000000000000014, 65.9, 20.000000000000014, 23.000000000000057, 27.20000000000013, 29.90000000000018, -275.29999999999984, -337.1999999999996, -78.10000000000002, -56.19999999999992, -251.2, 18.199999999999992, -11.79999999999986, -179.50000000000057, 20.000000000000014, -286.2000000000002, -96.10000000000056, -255.10000000000036, -179.50000000000026, 11.600000000000009, -34.299999999999805, 20.000000000000014, -89.20000000000056, -362.19999999999993, -279.0999999999999, 20.000000000000014, 20.000000000000014, -301.40000000000003, -421.0999999999998, -130.00000000000023, -108.10000000000079, 20.000000000000014, -24.09999999999988, -613.5, -535.3, -431.3999999999994, -114.40000000000003, -123.10000000000034, 20.000000000000014, -595.8999999999999, -683.8, -303.4, -177.10000000000005, -141.10000000000036, -196.3, -529.9, -621.1, -374.4, -240.89999999999998, -126.99999999999984, -53.499999999999815, -73.90000000000003, -208.00000000000023, -51.09999999999999, -137.20000000000024, -9.69999999999996, -36.399999999999864, -7.300000000000036, 18.200000000000152, -311.9000000000002, -527.7, -5.2000000000000295, -223.60000000000025, -231.7, -188.79999999999993, -129.10000000000053, 63.200000000000195, -235.79999999999998, -356.7999999999997], "policy_predator_policy_reward": [95.0, 48.0, 0.0, 78.0, 0.0, 77.0, 3.0, 33.0, 0.0, 72.0, 28.0, 50.0, 0.0, 1.0, 37.0, 5.0, 2.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 57.0, 45.0, 51.0, 51.0, 0.0, 0.0, 29.0, 28.0, 79.0, 0.0, 57.0, 0.0, 27.0, 34.0, 0.0, 12.0, 111.0, 30.0, 1.0, 0.0, 0.0, 35.0, 0.0, 75.0, 0.0, 0.0, 0.0, 177.0, 0.0, 107.0, 0.0, 139.0, 0.0, 0.0, 81.0, 0.0, 65.0, 12.0, 14.0, 9.0, 171.0, 35.0, 0.0, 9.0, 0.0, 49.0, 1.0, 36.0, 89.0, 9.0, 8.0, 22.0, 113.0, 89.0, 16.0, 135.0, 4.0, 0.0, 0.0, 68.0, 3.0, 36.0, 191.0, 25.0, 113.0, 154.0, 6.0, 4.0, 0.0, 0.0, 160.0, 80.0, 68.0, 0.0, 0.0, 52.0, 76.0, 134.0, 4.0, 155.0, 189.0, 4.0, 63.0, 185.0, 129.0, 3.0, 214.0, 62.0, 104.0, 33.0, 106.0, 50.0, 143.0, 41.0, 0.0, 10.0, 41.0, 99.0, 29.0, 0.0, 0.0, 32.0, 124.0, 112.0, 72.0, 8.0, 46.0, 66.0, 19.0, 0.0, 0.0, 0.0, 2.0, 35.0, 140.0, 109.0, 194.0, 43.0, 122.0, 0.0, 31.0, 95.0, 0.0, 151.0, 77.0, 153.0, 0.0, 0.0, 41.0, 47.0, 32.0, 162.0, 205.0, 0.0, 0.0, 210.0, 92.0, 115.0, 16.0, 14.0, 7.0, 21.0, 559.0, 64.0, 298.0, 0.0, 75.0, 269.0, 486.0, 73.0, 213.0, 109.0, 75.0, 596.0, 96.0, 11.0, 247.0, 71.0, 33.0, 0.0, 123.0, 82.0, 87.0, 17.0, 39.0, 25.0, 0.0, 362.0, 116.0, 2.0, 116.0, 129.0, 0.0, 53.0, 38.0, 56.0, 207.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.669443079329439, "mean_inference_ms": 7.1972361194297845, "mean_action_processing_ms": 1.117389756723265, "mean_env_wait_ms": 0.9142586165299074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01674509048461914, "StateBufferConnector_ms": 0.003637075424194336, "ViewRequirementAgentConnector_ms": 0.31931793689727783}, "num_episodes": 22, "episode_return_max": 132.89999999999938, "episode_return_min": -568.8, "episode_return_mean": -77.63600000000002, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 227.23414905103232, "num_env_steps_trained_throughput_per_sec": 227.23414905103232, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 20725.525, "restore_workers_time_ms": 0.15, "training_step_time_ms": 20724.632, "sample_time_ms": 5311.379, "learn_time_ms": 15384.432, "learn_throughput": 260.003, "synch_weights_time_ms": 24.035}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "e57b0_00000", "date": "2024-08-13_00-13-31", "timestamp": 1723522411, "time_this_iter_s": 17.67702889442444, "time_total_s": 187.48989701271057, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b3b0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 187.48989701271057, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 89.556, "ram_util_percent": 83.26799999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9517175149586465, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.403452619926009, "policy_loss": -0.008101521927750023, "vf_loss": 9.409764369076521, "vf_explained_var": 0.0018732001226415078, "kl": 0.023863584020488007, "entropy": 1.4447644617822435, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3870805469809701, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.718020908668558, "policy_loss": -0.007259836171325001, "vf_loss": 8.72320370875969, "vf_explained_var": -4.421292789398678e-05, "kl": 0.01384687828509283, "entropy": 1.3869574058623542, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 132.89999999999938, "episode_reward_min": -568.8, "episode_reward_mean": -122.57499999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -731.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 71.29999999999961, "predator_policy": 626.0}, "policy_reward_mean": {"prey_policy": -177.76750000000004, "predator_policy": 116.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-33.499999999999694, 58.00000000000051, -199.39999999999986, -29.999999999999744, -91.10000000000011, -27.29999999999985, -84.9, 30.300000000000374, -337.39999999999907, 21.30000000000003, 79.59999999999928, -12.899999999999771, -77.99999999999999, 23.400000000000027, -76.10000000000083, -74.30000000000003, -60.99999999999992, 41.800000000000324, -40.199999999999555, -276.9000000000002, -34.099999999999746, -152.80000000000047, 35.600000000000236, -245.5000000000002, 132.89999999999938, 40.0000000000003, -75.29999999999993, -103.40000000000012, -138.39999999999992, -36.999999999999545, -84.80000000000028, -97.70000000000016, -236.2000000000006, -115.00000000000037, -189.10000000000068, -4.1999999999995925, 31.900000000000368, -46.49999999999969, 40.0000000000003, -40.99999999999976, -79.60000000000096, -38.29999999999957, -53.49999999999958, 85.89999999999884, 52.20000000000051, -70.39999999999989, -112.30000000000024, -142.40000000000003, 37.40000000000027, -64.50000000000091, -154.30000000000058, -281.60000000000053, 18.300000000000036, 9.799999999999967, -274.29999999999984, 40.0000000000003, -420.49999999999966, -107.10000000000036, 16.899999999999906, -568.8, -183.80000000000018, -28.099999999999774, -524.6999999999998, -194.49999999999997, -153.40000000000018, -459.0, -357.30000000000007, -76.49999999999977, -158.89999999999998, -19.29999999999987, 9.90000000000034, 35.90000000000033, -361.60000000000014, -110.80000000000075, -291.4999999999999, 25.10000000000014, -329.5999999999996, -369.5, -109.89999999999998, -211.89999999999992, -441.99999999999994, -207.8, -263.6, -116.89999999999978, -344.5, -3.1999999999999034, -366.30000000000007, -359.8000000000001, -242.4999999999999, -73.40000000000018, 66.79999999999961, 40.0000000000003, -234.0, -230.69999999999993, -19.99999999999976, -193.10000000000008, -226.29999999999993, -319.99999999999756, -170.80000000000013, -83.69999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [27.20000000000013, -135.7000000000005, 20.000000000000014, 38.00000000000025, -161.49999999999983, -214.90000000000003, -127.00000000000011, -9.99999999999996, 20.000000000000014, -250.09999999999988, -128.3000000000001, 20.000000000000014, -116.50000000000009, -33.39999999999995, -5.200000000000031, 9.499999999999982, -331.6000000000001, -185.8000000000002, -33.6999999999998, 20.000000000000014, 20.000000000000014, 50.60000000000009, -64.00000000000054, 1.0999999999999688, -205.00000000000014, 1.9999999999999107, 20.000000000000014, -13.599999999999964, -182.80000000000055, -28.3, -70.29999999999984, -109.00000000000006, -167.20000000000005, -32.799999999999834, 20.000000000000014, 21.80000000000004, -129.10000000000073, 17.899999999999988, -198.40000000000043, -305.50000000000006, 11.899999999999949, -183.99999999999994, -103.90000000000002, -208.90000000000043, 20.000000000000014, 11.599999999999964, -131.50000000000009, -273.99999999999966, 71.29999999999961, -86.40000000000006, 20.000000000000014, 20.000000000000014, -63.69999999999991, -139.60000000000014, -261.40000000000015, 20.000000000000014, -156.50000000000003, -325.9, -84.10000000000072, -19.899999999999743, -271.2, -127.60000000000045, -136.30000000000038, -178.40000000000003, -204.70000000000033, -197.5000000000002, -89.19999999999999, -164.80000000000015, -278.1999999999997, -103.90000000000005, -27.399999999999793, -17.800000000000008, -6.399999999999979, -12.699999999999978, -215.20000000000044, 40.70000000000025, 20.000000000000014, 20.000000000000014, -77.20000000000076, -119.80000000000024, -99.70000000000053, -163.9000000000004, -32.49999999999976, -59.80000000000041, -158.50000000000065, 20.000000000000014, 65.9, 20.000000000000014, 23.000000000000057, 27.20000000000013, 29.90000000000018, -275.29999999999984, -337.1999999999996, -78.10000000000002, -56.19999999999992, -251.2, 18.199999999999992, -11.79999999999986, -179.50000000000057, 20.000000000000014, -286.2000000000002, -96.10000000000056, -255.10000000000036, -179.50000000000026, 11.600000000000009, -34.299999999999805, 20.000000000000014, -89.20000000000056, -362.19999999999993, -279.0999999999999, 20.000000000000014, 20.000000000000014, -301.40000000000003, -421.0999999999998, -130.00000000000023, -108.10000000000079, 20.000000000000014, -24.09999999999988, -613.5, -535.3, -431.3999999999994, -114.40000000000003, -123.10000000000034, 20.000000000000014, -595.8999999999999, -683.8, -303.4, -177.10000000000005, -141.10000000000036, -196.3, -529.9, -621.1, -374.4, -240.89999999999998, -126.99999999999984, -53.499999999999815, -73.90000000000003, -208.00000000000023, -51.09999999999999, -137.20000000000024, -9.69999999999996, -36.399999999999864, -7.300000000000036, 18.200000000000152, -311.9000000000002, -527.7, -5.2000000000000295, -223.60000000000025, -231.7, -188.79999999999993, -129.10000000000053, 63.200000000000195, -235.79999999999998, -356.7999999999997, -446.19999999999993, -442.29999999999995, -474.0, -599.9, -536.1999999999999, -190.6999999999999, -364.1, -499.90000000000003, -573.0, -731.8, -427.5, -213.1000000000001, -402.9999999999999, -461.9, -519.7, -678.8, 20.600000000000207, -71.7999999999999, -278.19999999999993, -443.10000000000014, -535.2, -495.59999999999997, -235.60000000000002, -244.89999999999998, -278.1999999999994, -17.19999999999998, -495.9, -284.2999999999999, 20.000000000000014, 20.000000000000014, -617.0999999999999, -505.9, -532.8, -539.9, -13.600000000000009, -30.40000000000002, -168.5999999999999, -464.5, -347.79999999999995, -307.5, -206.40000000000032, -302.59999999999883, -127.9, -313.9, -427.0, -372.70000000000005], "policy_predator_policy_reward": [75.0, 0.0, 0.0, 0.0, 177.0, 0.0, 107.0, 0.0, 139.0, 0.0, 0.0, 81.0, 0.0, 65.0, 12.0, 14.0, 9.0, 171.0, 35.0, 0.0, 9.0, 0.0, 49.0, 1.0, 36.0, 89.0, 9.0, 8.0, 22.0, 113.0, 89.0, 16.0, 135.0, 4.0, 0.0, 0.0, 68.0, 3.0, 36.0, 191.0, 25.0, 113.0, 154.0, 6.0, 4.0, 0.0, 0.0, 160.0, 80.0, 68.0, 0.0, 0.0, 52.0, 76.0, 134.0, 4.0, 155.0, 189.0, 4.0, 63.0, 185.0, 129.0, 3.0, 214.0, 62.0, 104.0, 33.0, 106.0, 50.0, 143.0, 41.0, 0.0, 10.0, 41.0, 99.0, 29.0, 0.0, 0.0, 32.0, 124.0, 112.0, 72.0, 8.0, 46.0, 66.0, 19.0, 0.0, 0.0, 0.0, 2.0, 35.0, 140.0, 109.0, 194.0, 43.0, 122.0, 0.0, 31.0, 95.0, 0.0, 151.0, 77.0, 153.0, 0.0, 0.0, 41.0, 47.0, 32.0, 162.0, 205.0, 0.0, 0.0, 210.0, 92.0, 115.0, 16.0, 14.0, 7.0, 21.0, 559.0, 64.0, 298.0, 0.0, 75.0, 269.0, 486.0, 73.0, 213.0, 109.0, 75.0, 596.0, 96.0, 11.0, 247.0, 71.0, 33.0, 0.0, 123.0, 82.0, 87.0, 17.0, 39.0, 25.0, 0.0, 362.0, 116.0, 2.0, 116.0, 129.0, 0.0, 53.0, 38.0, 56.0, 207.0, 437.0, 82.0, 562.0, 402.0, 141.0, 374.0, 0.0, 422.0, 626.0, 471.0, 257.0, 120.0, 443.0, 305.0, 306.0, 548.0, 48.0, 0.0, 13.0, 342.0, 533.0, 138.0, 189.0, 49.0, 108.0, 114.0, 397.0, 450.0, 0.0, 0.0, 386.0, 503.0, 410.0, 432.0, 0.0, 24.0, 365.0, 75.0, 192.0, 237.0, 0.0, 189.0, 143.0, 128.0, 338.0, 378.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.568779586848282, "mean_inference_ms": 6.907988973815347, "mean_action_processing_ms": 1.0770685624860712, "mean_env_wait_ms": 0.8892705380725431, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015823841094970703, "StateBufferConnector_ms": 0.0054367780685424805, "ViewRequirementAgentConnector_ms": 0.37713623046875}, "num_episodes": 23, "episode_return_max": 132.89999999999938, "episode_return_min": -568.8, "episode_return_mean": -122.57499999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.9087864363103, "num_env_steps_trained_throughput_per_sec": 215.9087864363103, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 20505.608, "restore_workers_time_ms": 0.137, "training_step_time_ms": 20504.799, "sample_time_ms": 5282.337, "learn_time_ms": 15195.04, "learn_throughput": 263.244, "synch_weights_time_ms": 22.948}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "e57b0_00000", "date": "2024-08-13_00-13-50", "timestamp": 1723522430, "time_this_iter_s": 18.58481502532959, "time_total_s": 206.07471203804016, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b641f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 206.07471203804016, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 87.73846153846154, "ram_util_percent": 83.5153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0112486903274815, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.533097128262596, "policy_loss": -0.010348492853156237, "vf_loss": 4.5408339731276985, "vf_explained_var": 0.0014432908681334643, "kl": 0.02321470585522667, "entropy": 1.415014932016847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45710828558556615, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.468821358049988, "policy_loss": -0.000739950270308231, "vf_loss": 5.469254997798375, "vf_explained_var": 0.0004416584653198404, "kl": 0.002042072116126871, "entropy": 1.4184771159338572, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 213.6999999999992, "episode_reward_min": -568.8, "episode_reward_mean": -112.01299999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -731.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 71.29999999999961, "predator_policy": 626.0}, "policy_reward_mean": {"prey_policy": -186.39650000000006, "predator_policy": 130.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.199999999999555, -276.9000000000002, -34.099999999999746, -152.80000000000047, 35.600000000000236, -245.5000000000002, 132.89999999999938, 40.0000000000003, -75.29999999999993, -103.40000000000012, -138.39999999999992, -36.999999999999545, -84.80000000000028, -97.70000000000016, -236.2000000000006, -115.00000000000037, -189.10000000000068, -4.1999999999995925, 31.900000000000368, -46.49999999999969, 40.0000000000003, -40.99999999999976, -79.60000000000096, -38.29999999999957, -53.49999999999958, 85.89999999999884, 52.20000000000051, -70.39999999999989, -112.30000000000024, -142.40000000000003, 37.40000000000027, -64.50000000000091, -154.30000000000058, -281.60000000000053, 18.300000000000036, 9.799999999999967, -274.29999999999984, 40.0000000000003, -420.49999999999966, -107.10000000000036, 16.899999999999906, -568.8, -183.80000000000018, -28.099999999999774, -524.6999999999998, -194.49999999999997, -153.40000000000018, -459.0, -357.30000000000007, -76.49999999999977, -158.89999999999998, -19.29999999999987, 9.90000000000034, 35.90000000000033, -361.60000000000014, -110.80000000000075, -291.4999999999999, 25.10000000000014, -329.5999999999996, -369.5, -109.89999999999998, -211.89999999999992, -441.99999999999994, -207.8, -263.6, -116.89999999999978, -344.5, -3.1999999999999034, -366.30000000000007, -359.8000000000001, -242.4999999999999, -73.40000000000018, 66.79999999999961, 40.0000000000003, -234.0, -230.69999999999993, -19.99999999999976, -193.10000000000008, -226.29999999999993, -319.99999999999756, -170.80000000000013, -83.69999999999996, -34.09999999999969, 78.69999999999922, 42.70000000000034, 42.600000000000335, 213.6999999999992, 68.90000000000012, 4.800000000000155, 12.100000000000016, -77.4000000000006, 3.0000000000000524, 45.9000000000002, 11.699999999999937, -39.69999999999963, 40.0000000000003, -138.00000000000017, 73.69999999999993, -22.499999999999773, -121.40000000000111], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-129.10000000000073, 17.899999999999988, -198.40000000000043, -305.50000000000006, 11.899999999999949, -183.99999999999994, -103.90000000000002, -208.90000000000043, 20.000000000000014, 11.599999999999964, -131.50000000000009, -273.99999999999966, 71.29999999999961, -86.40000000000006, 20.000000000000014, 20.000000000000014, -63.69999999999991, -139.60000000000014, -261.40000000000015, 20.000000000000014, -156.50000000000003, -325.9, -84.10000000000072, -19.899999999999743, -271.2, -127.60000000000045, -136.30000000000038, -178.40000000000003, -204.70000000000033, -197.5000000000002, -89.19999999999999, -164.80000000000015, -278.1999999999997, -103.90000000000005, -27.399999999999793, -17.800000000000008, -6.399999999999979, -12.699999999999978, -215.20000000000044, 40.70000000000025, 20.000000000000014, 20.000000000000014, -77.20000000000076, -119.80000000000024, -99.70000000000053, -163.9000000000004, -32.49999999999976, -59.80000000000041, -158.50000000000065, 20.000000000000014, 65.9, 20.000000000000014, 23.000000000000057, 27.20000000000013, 29.90000000000018, -275.29999999999984, -337.1999999999996, -78.10000000000002, -56.19999999999992, -251.2, 18.199999999999992, -11.79999999999986, -179.50000000000057, 20.000000000000014, -286.2000000000002, -96.10000000000056, -255.10000000000036, -179.50000000000026, 11.600000000000009, -34.299999999999805, 20.000000000000014, -89.20000000000056, -362.19999999999993, -279.0999999999999, 20.000000000000014, 20.000000000000014, -301.40000000000003, -421.0999999999998, -130.00000000000023, -108.10000000000079, 20.000000000000014, -24.09999999999988, -613.5, -535.3, -431.3999999999994, -114.40000000000003, -123.10000000000034, 20.000000000000014, -595.8999999999999, -683.8, -303.4, -177.10000000000005, -141.10000000000036, -196.3, -529.9, -621.1, -374.4, -240.89999999999998, -126.99999999999984, -53.499999999999815, -73.90000000000003, -208.00000000000023, -51.09999999999999, -137.20000000000024, -9.69999999999996, -36.399999999999864, -7.300000000000036, 18.200000000000152, -311.9000000000002, -527.7, -5.2000000000000295, -223.60000000000025, -231.7, -188.79999999999993, -129.10000000000053, 63.200000000000195, -235.79999999999998, -356.7999999999997, -446.19999999999993, -442.29999999999995, -474.0, -599.9, -536.1999999999999, -190.6999999999999, -364.1, -499.90000000000003, -573.0, -731.8, -427.5, -213.1000000000001, -402.9999999999999, -461.9, -519.7, -678.8, 20.600000000000207, -71.7999999999999, -278.19999999999993, -443.10000000000014, -535.2, -495.59999999999997, -235.60000000000002, -244.89999999999998, -278.1999999999994, -17.19999999999998, -495.9, -284.2999999999999, 20.000000000000014, 20.000000000000014, -617.0999999999999, -505.9, -532.8, -539.9, -13.600000000000009, -30.40000000000002, -168.5999999999999, -464.5, -347.79999999999995, -307.5, -206.40000000000032, -302.59999999999883, -127.9, -313.9, -427.0, -372.70000000000005, -271.29999999999995, -71.80000000000081, 47.600000000000236, 19.100000000000158, 20.000000000000014, 22.700000000000053, 9.49999999999998, 28.100000000000147, 58.700000000000216, -643.0, 20.000000000000014, 44.900000000000226, 23.900000000000073, -573.0999999999999, -69.10000000000083, 36.200000000000166, -400.2, -77.20000000000061, -86.80000000000068, 30.800000000000203, -464.89999999999986, 21.80000000000004, -91.30000000000015, 20.000000000000014, -50.79999999999986, -79.90000000000069, 20.000000000000014, 20.000000000000014, -351.1999999999993, -301.80000000000007, -333.1, 15.799999999999963, -306.4999999999999, -75.99999999999986, -116.50000000000054, -136.90000000000063], "policy_predator_policy_reward": [68.0, 3.0, 36.0, 191.0, 25.0, 113.0, 154.0, 6.0, 4.0, 0.0, 0.0, 160.0, 80.0, 68.0, 0.0, 0.0, 52.0, 76.0, 134.0, 4.0, 155.0, 189.0, 4.0, 63.0, 185.0, 129.0, 3.0, 214.0, 62.0, 104.0, 33.0, 106.0, 50.0, 143.0, 41.0, 0.0, 10.0, 41.0, 99.0, 29.0, 0.0, 0.0, 32.0, 124.0, 112.0, 72.0, 8.0, 46.0, 66.0, 19.0, 0.0, 0.0, 0.0, 2.0, 35.0, 140.0, 109.0, 194.0, 43.0, 122.0, 0.0, 31.0, 95.0, 0.0, 151.0, 77.0, 153.0, 0.0, 0.0, 41.0, 47.0, 32.0, 162.0, 205.0, 0.0, 0.0, 210.0, 92.0, 115.0, 16.0, 14.0, 7.0, 21.0, 559.0, 64.0, 298.0, 0.0, 75.0, 269.0, 486.0, 73.0, 213.0, 109.0, 75.0, 596.0, 96.0, 11.0, 247.0, 71.0, 33.0, 0.0, 123.0, 82.0, 87.0, 17.0, 39.0, 25.0, 0.0, 362.0, 116.0, 2.0, 116.0, 129.0, 0.0, 53.0, 38.0, 56.0, 207.0, 437.0, 82.0, 562.0, 402.0, 141.0, 374.0, 0.0, 422.0, 626.0, 471.0, 257.0, 120.0, 443.0, 305.0, 306.0, 548.0, 48.0, 0.0, 13.0, 342.0, 533.0, 138.0, 189.0, 49.0, 108.0, 114.0, 397.0, 450.0, 0.0, 0.0, 386.0, 503.0, 410.0, 432.0, 0.0, 24.0, 365.0, 75.0, 192.0, 237.0, 0.0, 189.0, 143.0, 128.0, 338.0, 378.0, 147.0, 162.0, 2.0, 10.0, 0.0, 0.0, 0.0, 5.0, 503.0, 295.0, 4.0, 0.0, 220.0, 334.0, 45.0, 0.0, 280.0, 120.0, 0.0, 59.0, 221.0, 268.0, 43.0, 40.0, 19.0, 72.0, 0.0, 0.0, 166.0, 349.0, 214.0, 177.0, 185.0, 175.0, 104.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.492230210226905, "mean_inference_ms": 6.662642158549386, "mean_action_processing_ms": 1.042404033396502, "mean_env_wait_ms": 0.8606249438382655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01572275161743164, "StateBufferConnector_ms": 0.005325436592102051, "ViewRequirementAgentConnector_ms": 0.3609727621078491}, "num_episodes": 18, "episode_return_max": 213.6999999999992, "episode_return_min": -568.8, "episode_return_mean": -112.01299999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.87179423985523, "num_env_steps_trained_throughput_per_sec": 233.87179423985523, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 19727.071, "restore_workers_time_ms": 0.13, "training_step_time_ms": 19726.289, "sample_time_ms": 4977.132, "learn_time_ms": 14723.262, "learn_throughput": 271.679, "synch_weights_time_ms": 22.784}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "e57b0_00000", "date": "2024-08-13_00-14-07", "timestamp": 1723522447, "time_this_iter_s": 17.165337085723877, "time_total_s": 223.24004912376404, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b64dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 223.24004912376404, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 87.10000000000001, "ram_util_percent": 83.56666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9729200743808948, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4994912029574157, "policy_loss": -0.008817056992840239, "vf_loss": 2.5055930488954776, "vf_explained_var": -0.0038095320343340517, "kl": 0.016090102654371937, "entropy": 1.368248217320316, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3604751256959779, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.607344803355989, "policy_loss": -0.0012383690416793186, "vf_loss": 2.6083142088203832, "vf_explained_var": 0.002697683957518724, "kl": 0.003586180078492569, "entropy": 1.4486766161742033, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 213.6999999999992, "episode_reward_min": -568.8, "episode_reward_mean": -93.46999999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -731.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 65.9, "predator_policy": 626.0}, "policy_reward_mean": {"prey_policy": -171.105, "predator_policy": 124.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.900000000000368, -46.49999999999969, 40.0000000000003, -40.99999999999976, -79.60000000000096, -38.29999999999957, -53.49999999999958, 85.89999999999884, 52.20000000000051, -70.39999999999989, -112.30000000000024, -142.40000000000003, 37.40000000000027, -64.50000000000091, -154.30000000000058, -281.60000000000053, 18.300000000000036, 9.799999999999967, -274.29999999999984, 40.0000000000003, -420.49999999999966, -107.10000000000036, 16.899999999999906, -568.8, -183.80000000000018, -28.099999999999774, -524.6999999999998, -194.49999999999997, -153.40000000000018, -459.0, -357.30000000000007, -76.49999999999977, -158.89999999999998, -19.29999999999987, 9.90000000000034, 35.90000000000033, -361.60000000000014, -110.80000000000075, -291.4999999999999, 25.10000000000014, -329.5999999999996, -369.5, -109.89999999999998, -211.89999999999992, -441.99999999999994, -207.8, -263.6, -116.89999999999978, -344.5, -3.1999999999999034, -366.30000000000007, -359.8000000000001, -242.4999999999999, -73.40000000000018, 66.79999999999961, 40.0000000000003, -234.0, -230.69999999999993, -19.99999999999976, -193.10000000000008, -226.29999999999993, -319.99999999999756, -170.80000000000013, -83.69999999999996, -34.09999999999969, 78.69999999999922, 42.70000000000034, 42.600000000000335, 213.6999999999992, 68.90000000000012, 4.800000000000155, 12.100000000000016, -77.4000000000006, 3.0000000000000524, 45.9000000000002, 11.699999999999937, -39.69999999999963, 40.0000000000003, -138.00000000000017, 73.69999999999993, -22.499999999999773, -121.40000000000111, 71.49999999999991, 6.100000000000042, 2.9000000000001895, -77.20000000000078, -79.90000000000086, -69.40000000000074, 70.60000000000005, 10.099999999999985, 60.90000000000048, 27.000000000000117, -38.49999999999967, 41.80000000000033, 24.700000000000045, 31.800000000000185, 64.80000000000037, 66.10000000000034, -26.7999999999996, 45.700000000000394], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-6.399999999999979, -12.699999999999978, -215.20000000000044, 40.70000000000025, 20.000000000000014, 20.000000000000014, -77.20000000000076, -119.80000000000024, -99.70000000000053, -163.9000000000004, -32.49999999999976, -59.80000000000041, -158.50000000000065, 20.000000000000014, 65.9, 20.000000000000014, 23.000000000000057, 27.20000000000013, 29.90000000000018, -275.29999999999984, -337.1999999999996, -78.10000000000002, -56.19999999999992, -251.2, 18.199999999999992, -11.79999999999986, -179.50000000000057, 20.000000000000014, -286.2000000000002, -96.10000000000056, -255.10000000000036, -179.50000000000026, 11.600000000000009, -34.299999999999805, 20.000000000000014, -89.20000000000056, -362.19999999999993, -279.0999999999999, 20.000000000000014, 20.000000000000014, -301.40000000000003, -421.0999999999998, -130.00000000000023, -108.10000000000079, 20.000000000000014, -24.09999999999988, -613.5, -535.3, -431.3999999999994, -114.40000000000003, -123.10000000000034, 20.000000000000014, -595.8999999999999, -683.8, -303.4, -177.10000000000005, -141.10000000000036, -196.3, -529.9, -621.1, -374.4, -240.89999999999998, -126.99999999999984, -53.499999999999815, -73.90000000000003, -208.00000000000023, -51.09999999999999, -137.20000000000024, -9.69999999999996, -36.399999999999864, -7.300000000000036, 18.200000000000152, -311.9000000000002, -527.7, -5.2000000000000295, -223.60000000000025, -231.7, -188.79999999999993, -129.10000000000053, 63.200000000000195, -235.79999999999998, -356.7999999999997, -446.19999999999993, -442.29999999999995, -474.0, -599.9, -536.1999999999999, -190.6999999999999, -364.1, -499.90000000000003, -573.0, -731.8, -427.5, -213.1000000000001, -402.9999999999999, -461.9, -519.7, -678.8, 20.600000000000207, -71.7999999999999, -278.19999999999993, -443.10000000000014, -535.2, -495.59999999999997, -235.60000000000002, -244.89999999999998, -278.1999999999994, -17.19999999999998, -495.9, -284.2999999999999, 20.000000000000014, 20.000000000000014, -617.0999999999999, -505.9, -532.8, -539.9, -13.600000000000009, -30.40000000000002, -168.5999999999999, -464.5, -347.79999999999995, -307.5, -206.40000000000032, -302.59999999999883, -127.9, -313.9, -427.0, -372.70000000000005, -271.29999999999995, -71.80000000000081, 47.600000000000236, 19.100000000000158, 20.000000000000014, 22.700000000000053, 9.49999999999998, 28.100000000000147, 58.700000000000216, -643.0, 20.000000000000014, 44.900000000000226, 23.900000000000073, -573.0999999999999, -69.10000000000083, 36.200000000000166, -400.2, -77.20000000000061, -86.80000000000068, 30.800000000000203, -464.89999999999986, 21.80000000000004, -91.30000000000015, 20.000000000000014, -50.79999999999986, -79.90000000000069, 20.000000000000014, 20.000000000000014, -351.1999999999993, -301.80000000000007, -333.1, 15.799999999999963, -306.4999999999999, -75.99999999999986, -116.50000000000054, -136.90000000000063, 51.500000000000206, 20.000000000000014, -49.299999999999805, 7.399999999999965, -369.29999999999995, -68.8000000000007, -42.99999999999978, -152.20000000000036, -143.8000000000007, -84.10000000000036, -102.10000000000056, -151.3000000000002, 29.90000000000018, 40.70000000000025, -21.699999999999783, -11.199999999999884, 26.900000000000126, 16.999999999999996, 12.499999999999964, -14.499999999999808, -70.30000000000078, -152.20000000000033, 12.799999999999962, 20.000000000000014, -91.30000000000057, 20.000000000000014, 7.999999999999972, -5.199999999999951, -23.799999999999834, 59.600000000000215, 34.40000000000023, 31.700000000000202, -111.7000000000007, 20.90000000000003, -2.4999999999999716, 36.20000000000025], "policy_predator_policy_reward": [10.0, 41.0, 99.0, 29.0, 0.0, 0.0, 32.0, 124.0, 112.0, 72.0, 8.0, 46.0, 66.0, 19.0, 0.0, 0.0, 0.0, 2.0, 35.0, 140.0, 109.0, 194.0, 43.0, 122.0, 0.0, 31.0, 95.0, 0.0, 151.0, 77.0, 153.0, 0.0, 0.0, 41.0, 47.0, 32.0, 162.0, 205.0, 0.0, 0.0, 210.0, 92.0, 115.0, 16.0, 14.0, 7.0, 21.0, 559.0, 64.0, 298.0, 0.0, 75.0, 269.0, 486.0, 73.0, 213.0, 109.0, 75.0, 596.0, 96.0, 11.0, 247.0, 71.0, 33.0, 0.0, 123.0, 82.0, 87.0, 17.0, 39.0, 25.0, 0.0, 362.0, 116.0, 2.0, 116.0, 129.0, 0.0, 53.0, 38.0, 56.0, 207.0, 437.0, 82.0, 562.0, 402.0, 141.0, 374.0, 0.0, 422.0, 626.0, 471.0, 257.0, 120.0, 443.0, 305.0, 306.0, 548.0, 48.0, 0.0, 13.0, 342.0, 533.0, 138.0, 189.0, 49.0, 108.0, 114.0, 397.0, 450.0, 0.0, 0.0, 386.0, 503.0, 410.0, 432.0, 0.0, 24.0, 365.0, 75.0, 192.0, 237.0, 0.0, 189.0, 143.0, 128.0, 338.0, 378.0, 147.0, 162.0, 2.0, 10.0, 0.0, 0.0, 0.0, 5.0, 503.0, 295.0, 4.0, 0.0, 220.0, 334.0, 45.0, 0.0, 280.0, 120.0, 0.0, 59.0, 221.0, 268.0, 43.0, 40.0, 19.0, 72.0, 0.0, 0.0, 166.0, 349.0, 214.0, 177.0, 185.0, 175.0, 104.0, 28.0, 0.0, 0.0, 39.0, 9.0, 297.0, 144.0, 43.0, 75.0, 45.0, 103.0, 71.0, 113.0, 0.0, 0.0, 13.0, 30.0, 16.0, 1.0, 4.0, 25.0, 98.0, 86.0, 9.0, 0.0, 51.0, 45.0, 19.0, 10.0, 9.0, 20.0, 0.0, 0.0, 5.0, 59.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.413725085817505, "mean_inference_ms": 6.401962354249772, "mean_action_processing_ms": 1.0056510005000663, "mean_env_wait_ms": 0.8304483134954671, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006918549537658691, "StateBufferConnector_ms": 0.005225181579589844, "ViewRequirementAgentConnector_ms": 0.3217482566833496}, "num_episodes": 18, "episode_return_max": 213.6999999999992, "episode_return_min": -568.8, "episode_return_mean": -93.46999999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 241.93227117055685, "num_env_steps_trained_throughput_per_sec": 241.93227117055685, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 18339.493, "restore_workers_time_ms": 0.022, "training_step_time_ms": 18338.839, "sample_time_ms": 4152.488, "learn_time_ms": 14165.01, "learn_throughput": 282.386, "synch_weights_time_ms": 18.799}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "e57b0_00000", "date": "2024-08-13_00-14-24", "timestamp": 1723522464, "time_this_iter_s": 16.589638710021973, "time_total_s": 239.829687833786, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b3bd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 239.829687833786, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 85.72916666666667, "ram_util_percent": 83.39166666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8692213168614125, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0535364320550962, "policy_loss": -0.0026682891133955862, "vf_loss": 1.0546036919588766, "vf_explained_var": 0.00071272023771175, "kl": 0.009487550049171902, "entropy": 1.3362509041866928, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29618932365700995, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9209828254722413, "policy_loss": -0.0034597076795916393, "vf_loss": 0.9239161741481257, "vf_explained_var": 0.0037276294496324325, "kl": 0.014036210002374415, "entropy": 1.4204981761003928, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 213.6999999999992, "episode_reward_min": -568.8, "episode_reward_mean": -81.58199999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -731.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.200000000000195, "predator_policy": 626.0}, "policy_reward_mean": {"prey_policy": -158.29100000000003, "predator_policy": 117.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-274.29999999999984, 40.0000000000003, -420.49999999999966, -107.10000000000036, 16.899999999999906, -568.8, -183.80000000000018, -28.099999999999774, -524.6999999999998, -194.49999999999997, -153.40000000000018, -459.0, -357.30000000000007, -76.49999999999977, -158.89999999999998, -19.29999999999987, 9.90000000000034, 35.90000000000033, -361.60000000000014, -110.80000000000075, -291.4999999999999, 25.10000000000014, -329.5999999999996, -369.5, -109.89999999999998, -211.89999999999992, -441.99999999999994, -207.8, -263.6, -116.89999999999978, -344.5, -3.1999999999999034, -366.30000000000007, -359.8000000000001, -242.4999999999999, -73.40000000000018, 66.79999999999961, 40.0000000000003, -234.0, -230.69999999999993, -19.99999999999976, -193.10000000000008, -226.29999999999993, -319.99999999999756, -170.80000000000013, -83.69999999999996, -34.09999999999969, 78.69999999999922, 42.70000000000034, 42.600000000000335, 213.6999999999992, 68.90000000000012, 4.800000000000155, 12.100000000000016, -77.4000000000006, 3.0000000000000524, 45.9000000000002, 11.699999999999937, -39.69999999999963, 40.0000000000003, -138.00000000000017, 73.69999999999993, -22.499999999999773, -121.40000000000111, 71.49999999999991, 6.100000000000042, 2.9000000000001895, -77.20000000000078, -79.90000000000086, -69.40000000000074, 70.60000000000005, 10.099999999999985, 60.90000000000048, 27.000000000000117, -38.49999999999967, 41.80000000000033, 24.700000000000045, 31.800000000000185, 64.80000000000037, 66.10000000000034, -26.7999999999996, 45.700000000000394, -64.90000000000148, 33.0000000000002, 50.70000000000043, 61.50000000000048, 66.90000000000023, -4.899999999999729, -20.49999999999958, 2.600000000000102, -27.499999999999773, 40.0000000000003, -36.09999999999957, 68.8000000000001, 76.89999999999954, 10.29999999999992, 28.200000000000113, 40.90000000000031, 9.200000000000085, 44.80000000000038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-362.19999999999993, -279.0999999999999, 20.000000000000014, 20.000000000000014, -301.40000000000003, -421.0999999999998, -130.00000000000023, -108.10000000000079, 20.000000000000014, -24.09999999999988, -613.5, -535.3, -431.3999999999994, -114.40000000000003, -123.10000000000034, 20.000000000000014, -595.8999999999999, -683.8, -303.4, -177.10000000000005, -141.10000000000036, -196.3, -529.9, -621.1, -374.4, -240.89999999999998, -126.99999999999984, -53.499999999999815, -73.90000000000003, -208.00000000000023, -51.09999999999999, -137.20000000000024, -9.69999999999996, -36.399999999999864, -7.300000000000036, 18.200000000000152, -311.9000000000002, -527.7, -5.2000000000000295, -223.60000000000025, -231.7, -188.79999999999993, -129.10000000000053, 63.200000000000195, -235.79999999999998, -356.7999999999997, -446.19999999999993, -442.29999999999995, -474.0, -599.9, -536.1999999999999, -190.6999999999999, -364.1, -499.90000000000003, -573.0, -731.8, -427.5, -213.1000000000001, -402.9999999999999, -461.9, -519.7, -678.8, 20.600000000000207, -71.7999999999999, -278.19999999999993, -443.10000000000014, -535.2, -495.59999999999997, -235.60000000000002, -244.89999999999998, -278.1999999999994, -17.19999999999998, -495.9, -284.2999999999999, 20.000000000000014, 20.000000000000014, -617.0999999999999, -505.9, -532.8, -539.9, -13.600000000000009, -30.40000000000002, -168.5999999999999, -464.5, -347.79999999999995, -307.5, -206.40000000000032, -302.59999999999883, -127.9, -313.9, -427.0, -372.70000000000005, -271.29999999999995, -71.80000000000081, 47.600000000000236, 19.100000000000158, 20.000000000000014, 22.700000000000053, 9.49999999999998, 28.100000000000147, 58.700000000000216, -643.0, 20.000000000000014, 44.900000000000226, 23.900000000000073, -573.0999999999999, -69.10000000000083, 36.200000000000166, -400.2, -77.20000000000061, -86.80000000000068, 30.800000000000203, -464.89999999999986, 21.80000000000004, -91.30000000000015, 20.000000000000014, -50.79999999999986, -79.90000000000069, 20.000000000000014, 20.000000000000014, -351.1999999999993, -301.80000000000007, -333.1, 15.799999999999963, -306.4999999999999, -75.99999999999986, -116.50000000000054, -136.90000000000063, 51.500000000000206, 20.000000000000014, -49.299999999999805, 7.399999999999965, -369.29999999999995, -68.8000000000007, -42.99999999999978, -152.20000000000036, -143.8000000000007, -84.10000000000036, -102.10000000000056, -151.3000000000002, 29.90000000000018, 40.70000000000025, -21.699999999999783, -11.199999999999884, 26.900000000000126, 16.999999999999996, 12.499999999999964, -14.499999999999808, -70.30000000000078, -152.20000000000033, 12.799999999999962, 20.000000000000014, -91.30000000000057, 20.000000000000014, 7.999999999999972, -5.199999999999951, -23.799999999999834, 59.600000000000215, 34.40000000000023, 31.700000000000202, -111.7000000000007, 20.90000000000003, -2.4999999999999716, 36.20000000000025, -42.9999999999998, -115.90000000000069, 26.300000000000114, -28.29999999999975, 35.900000000000205, -8.199999999999902, 36.500000000000234, 20.000000000000014, 20.90000000000003, 32.00000000000022, -9.699999999999854, -35.19999999999978, -91.30000000000075, 15.799999999999962, 20.000000000000014, -51.39999999999989, -14.799999999999892, -78.7000000000004, 20.000000000000014, 20.000000000000014, -95.50000000000077, -22.59999999999976, 20.000000000000014, 48.80000000000021, 20.000000000000014, 56.90000000000021, 20.000000000000014, -36.69999999999981, -33.399999999999764, 20.600000000000037, 20.900000000000027, 20.000000000000014, 20.000000000000014, -38.799999999999756, 31.700000000000216, 1.0999999999999865], "policy_predator_policy_reward": [162.0, 205.0, 0.0, 0.0, 210.0, 92.0, 115.0, 16.0, 14.0, 7.0, 21.0, 559.0, 64.0, 298.0, 0.0, 75.0, 269.0, 486.0, 73.0, 213.0, 109.0, 75.0, 596.0, 96.0, 11.0, 247.0, 71.0, 33.0, 0.0, 123.0, 82.0, 87.0, 17.0, 39.0, 25.0, 0.0, 362.0, 116.0, 2.0, 116.0, 129.0, 0.0, 53.0, 38.0, 56.0, 207.0, 437.0, 82.0, 562.0, 402.0, 141.0, 374.0, 0.0, 422.0, 626.0, 471.0, 257.0, 120.0, 443.0, 305.0, 306.0, 548.0, 48.0, 0.0, 13.0, 342.0, 533.0, 138.0, 189.0, 49.0, 108.0, 114.0, 397.0, 450.0, 0.0, 0.0, 386.0, 503.0, 410.0, 432.0, 0.0, 24.0, 365.0, 75.0, 192.0, 237.0, 0.0, 189.0, 143.0, 128.0, 338.0, 378.0, 147.0, 162.0, 2.0, 10.0, 0.0, 0.0, 0.0, 5.0, 503.0, 295.0, 4.0, 0.0, 220.0, 334.0, 45.0, 0.0, 280.0, 120.0, 0.0, 59.0, 221.0, 268.0, 43.0, 40.0, 19.0, 72.0, 0.0, 0.0, 166.0, 349.0, 214.0, 177.0, 185.0, 175.0, 104.0, 28.0, 0.0, 0.0, 39.0, 9.0, 297.0, 144.0, 43.0, 75.0, 45.0, 103.0, 71.0, 113.0, 0.0, 0.0, 13.0, 30.0, 16.0, 1.0, 4.0, 25.0, 98.0, 86.0, 9.0, 0.0, 51.0, 45.0, 19.0, 10.0, 9.0, 20.0, 0.0, 0.0, 5.0, 59.0, 0.0, 12.0, 47.0, 47.0, 23.0, 12.0, 23.0, 0.0, 5.0, 0.0, 1.0, 13.0, 10.0, 30.0, 11.0, 44.0, 1.0, 33.0, 25.0, 41.0, 0.0, 0.0, 44.0, 38.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 41.0, 0.0, 0.0, 0.0, 28.0, 0.0, 3.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.346662323347416, "mean_inference_ms": 6.162902208019175, "mean_action_processing_ms": 0.9697298473954595, "mean_env_wait_ms": 0.8008194332116926, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008325338363647461, "StateBufferConnector_ms": 0.0051642656326293945, "ViewRequirementAgentConnector_ms": 0.27027392387390137}, "num_episodes": 18, "episode_return_max": 213.6999999999992, "episode_return_min": -568.8, "episode_return_mean": -81.58199999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 220.64670523355358, "num_env_steps_trained_throughput_per_sec": 220.64670523355358, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 18619.898, "restore_workers_time_ms": 0.018, "training_step_time_ms": 18619.259, "sample_time_ms": 3900.309, "learn_time_ms": 14698.0, "learn_throughput": 272.146, "synch_weights_time_ms": 18.377}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "e57b0_00000", "date": "2024-08-13_00-14-42", "timestamp": 1723522482, "time_this_iter_s": 18.2154598236084, "time_total_s": 258.0451476573944, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b59040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 258.0451476573944, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 88.38076923076923, "ram_util_percent": 83.62692307692308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9166061460971833, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4779330022593655, "policy_loss": -0.007186985138074431, "vf_loss": 1.4820557506942245, "vf_explained_var": -0.0115345939126595, "kl": 0.018158438489102827, "entropy": 1.2671031283953833, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2774106318416892, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1325850466887155, "policy_loss": -0.0032797957120078896, "vf_loss": 1.1355978017367383, "vf_explained_var": 0.001903164954412551, "kl": 0.007121094546161138, "entropy": 1.382090148408577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 213.6999999999992, "episode_reward_min": -366.30000000000007, "episode_reward_mean": -20.00399999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -731.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 59.600000000000215, "predator_policy": 626.0}, "policy_reward_mean": {"prey_policy": -90.99699999999999, "predator_policy": 80.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-207.8, -263.6, -116.89999999999978, -344.5, -3.1999999999999034, -366.30000000000007, -359.8000000000001, -242.4999999999999, -73.40000000000018, 66.79999999999961, 40.0000000000003, -234.0, -230.69999999999993, -19.99999999999976, -193.10000000000008, -226.29999999999993, -319.99999999999756, -170.80000000000013, -83.69999999999996, -34.09999999999969, 78.69999999999922, 42.70000000000034, 42.600000000000335, 213.6999999999992, 68.90000000000012, 4.800000000000155, 12.100000000000016, -77.4000000000006, 3.0000000000000524, 45.9000000000002, 11.699999999999937, -39.69999999999963, 40.0000000000003, -138.00000000000017, 73.69999999999993, -22.499999999999773, -121.40000000000111, 71.49999999999991, 6.100000000000042, 2.9000000000001895, -77.20000000000078, -79.90000000000086, -69.40000000000074, 70.60000000000005, 10.099999999999985, 60.90000000000048, 27.000000000000117, -38.49999999999967, 41.80000000000033, 24.700000000000045, 31.800000000000185, 64.80000000000037, 66.10000000000034, -26.7999999999996, 45.700000000000394, -64.90000000000148, 33.0000000000002, 50.70000000000043, 61.50000000000048, 66.90000000000023, -4.899999999999729, -20.49999999999958, 2.600000000000102, -27.499999999999773, 40.0000000000003, -36.09999999999957, 68.8000000000001, 76.89999999999954, 10.29999999999992, 28.200000000000113, 40.90000000000031, 9.200000000000085, 44.80000000000038, 40.0000000000003, 40.0000000000003, 21.70000000000001, 60.30000000000043, 51.70000000000049, 34.000000000000234, -65.50000000000144, 31.200000000000166, -19.399999999999565, 16.899999999999974, -28.49999999999953, 40.500000000000306, 33.400000000000205, 21.100000000000005, 40.0000000000003, 9.199999999999957, 63.40000000000048, 71.49999999999991, -33.19999999999971, -35.899999999999615, -24.59999999999956, 50.20000000000047, 26.30000000000007, 2.6000000000001338, -1.799999999999772, 47.50000000000044, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-573.0, -731.8, -427.5, -213.1000000000001, -402.9999999999999, -461.9, -519.7, -678.8, 20.600000000000207, -71.7999999999999, -278.19999999999993, -443.10000000000014, -535.2, -495.59999999999997, -235.60000000000002, -244.89999999999998, -278.1999999999994, -17.19999999999998, -495.9, -284.2999999999999, 20.000000000000014, 20.000000000000014, -617.0999999999999, -505.9, -532.8, -539.9, -13.600000000000009, -30.40000000000002, -168.5999999999999, -464.5, -347.79999999999995, -307.5, -206.40000000000032, -302.59999999999883, -127.9, -313.9, -427.0, -372.70000000000005, -271.29999999999995, -71.80000000000081, 47.600000000000236, 19.100000000000158, 20.000000000000014, 22.700000000000053, 9.49999999999998, 28.100000000000147, 58.700000000000216, -643.0, 20.000000000000014, 44.900000000000226, 23.900000000000073, -573.0999999999999, -69.10000000000083, 36.200000000000166, -400.2, -77.20000000000061, -86.80000000000068, 30.800000000000203, -464.89999999999986, 21.80000000000004, -91.30000000000015, 20.000000000000014, -50.79999999999986, -79.90000000000069, 20.000000000000014, 20.000000000000014, -351.1999999999993, -301.80000000000007, -333.1, 15.799999999999963, -306.4999999999999, -75.99999999999986, -116.50000000000054, -136.90000000000063, 51.500000000000206, 20.000000000000014, -49.299999999999805, 7.399999999999965, -369.29999999999995, -68.8000000000007, -42.99999999999978, -152.20000000000036, -143.8000000000007, -84.10000000000036, -102.10000000000056, -151.3000000000002, 29.90000000000018, 40.70000000000025, -21.699999999999783, -11.199999999999884, 26.900000000000126, 16.999999999999996, 12.499999999999964, -14.499999999999808, -70.30000000000078, -152.20000000000033, 12.799999999999962, 20.000000000000014, -91.30000000000057, 20.000000000000014, 7.999999999999972, -5.199999999999951, -23.799999999999834, 59.600000000000215, 34.40000000000023, 31.700000000000202, -111.7000000000007, 20.90000000000003, -2.4999999999999716, 36.20000000000025, -42.9999999999998, -115.90000000000069, 26.300000000000114, -28.29999999999975, 35.900000000000205, -8.199999999999902, 36.500000000000234, 20.000000000000014, 20.90000000000003, 32.00000000000022, -9.699999999999854, -35.19999999999978, -91.30000000000075, 15.799999999999962, 20.000000000000014, -51.39999999999989, -14.799999999999892, -78.7000000000004, 20.000000000000014, 20.000000000000014, -95.50000000000077, -22.59999999999976, 20.000000000000014, 48.80000000000021, 20.000000000000014, 56.90000000000021, 20.000000000000014, -36.69999999999981, -33.399999999999764, 20.600000000000037, 20.900000000000027, 20.000000000000014, 20.000000000000014, -38.799999999999756, 31.700000000000216, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 2.899999999999965, 20.000000000000014, 29.30000000000019, 31.700000000000212, 20.000000000000014, -8.799999999999928, 6.79999999999999, -33.699999999999825, -80.80000000000072, 20.000000000000014, 3.1999999999999615, -33.999999999999766, -51.399999999999814, 20.000000000000014, -24.099999999999746, -47.19999999999978, -28.29999999999975, 9.499999999999972, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, -25.899999999999785, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.799999999999756, 29.000000000000163, 34.40000000000023, 51.50000000000021, 20.000000000000014, 3.4999999999999654, -129.70000000000047, -19.899999999999785, -85.00000000000057, -87.10000000000066, 9.49999999999998, 20.000000000000014, 27.200000000000134, 20.000000000000014, -36.69999999999984, -51.399999999999935, 20.000000000000014, -57.70000000000032, 17.899999999999988, 16.999999999999975, 9.499999999999964, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [626.0, 471.0, 257.0, 120.0, 443.0, 305.0, 306.0, 548.0, 48.0, 0.0, 13.0, 342.0, 533.0, 138.0, 189.0, 49.0, 108.0, 114.0, 397.0, 450.0, 0.0, 0.0, 386.0, 503.0, 410.0, 432.0, 0.0, 24.0, 365.0, 75.0, 192.0, 237.0, 0.0, 189.0, 143.0, 128.0, 338.0, 378.0, 147.0, 162.0, 2.0, 10.0, 0.0, 0.0, 0.0, 5.0, 503.0, 295.0, 4.0, 0.0, 220.0, 334.0, 45.0, 0.0, 280.0, 120.0, 0.0, 59.0, 221.0, 268.0, 43.0, 40.0, 19.0, 72.0, 0.0, 0.0, 166.0, 349.0, 214.0, 177.0, 185.0, 175.0, 104.0, 28.0, 0.0, 0.0, 39.0, 9.0, 297.0, 144.0, 43.0, 75.0, 45.0, 103.0, 71.0, 113.0, 0.0, 0.0, 13.0, 30.0, 16.0, 1.0, 4.0, 25.0, 98.0, 86.0, 9.0, 0.0, 51.0, 45.0, 19.0, 10.0, 9.0, 20.0, 0.0, 0.0, 5.0, 59.0, 0.0, 12.0, 47.0, 47.0, 23.0, 12.0, 23.0, 0.0, 5.0, 0.0, 1.0, 13.0, 10.0, 30.0, 11.0, 44.0, 1.0, 33.0, 25.0, 41.0, 0.0, 0.0, 44.0, 38.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 41.0, 0.0, 0.0, 0.0, 28.0, 0.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 11.0, 0.0, 0.0, 0.0, 26.0, 10.0, 0.0, 49.0, 8.0, 0.0, 5.0, 61.0, 21.0, 0.0, 47.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 20.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 0.0, 0.0, 31.0, 62.0, 21.0, 48.0, 30.0, 23.0, 3.0, 0.0, 22.0, 21.0, 15.0, 19.0, 25.0, 13.0, 5.0, 16.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2875566951700725, "mean_inference_ms": 5.9553599117835105, "mean_action_processing_ms": 0.9406034435893761, "mean_env_wait_ms": 0.7737928135263012, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006989836692810059, "StateBufferConnector_ms": 0.005273342132568359, "ViewRequirementAgentConnector_ms": 0.27713704109191895}, "num_episodes": 27, "episode_return_max": 213.6999999999992, "episode_return_min": -366.30000000000007, "episode_return_mean": -20.00399999999991, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 192.85307898557852, "num_env_steps_trained_throughput_per_sec": 192.85307898557852, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 18989.138, "restore_workers_time_ms": 0.019, "training_step_time_ms": 18988.499, "sample_time_ms": 3871.154, "learn_time_ms": 15096.746, "learn_throughput": 264.958, "synch_weights_time_ms": 18.078}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "e57b0_00000", "date": "2024-08-13_00-15-03", "timestamp": 1723522503, "time_this_iter_s": 20.8445782661438, "time_total_s": 278.8897259235382, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09dba60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 278.8897259235382, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 89.97142857142856, "ram_util_percent": 83.69642857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.21071681509573, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6025262013314263, "policy_loss": -0.002131756342006305, "vf_loss": 2.603764132154051, "vf_explained_var": -0.0013579009386597487, "kl": 0.005296784742123544, "entropy": 1.3205600454693749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31481937520679026, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9096293749632658, "policy_loss": -0.005810946820638877, "vf_loss": 1.9146940698699346, "vf_explained_var": 0.000257893718739666, "kl": 0.019900132956229836, "entropy": 1.2709469003652138, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 213.6999999999992, "episode_reward_min": -276.09999999999997, "episode_reward_mean": 14.0120000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -643.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 59.600000000000215, "predator_policy": 569.0}, "policy_reward_mean": {"prey_policy": -36.40900000000001, "predator_policy": 43.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-83.69999999999996, -34.09999999999969, 78.69999999999922, 42.70000000000034, 42.600000000000335, 213.6999999999992, 68.90000000000012, 4.800000000000155, 12.100000000000016, -77.4000000000006, 3.0000000000000524, 45.9000000000002, 11.699999999999937, -39.69999999999963, 40.0000000000003, -138.00000000000017, 73.69999999999993, -22.499999999999773, -121.40000000000111, 71.49999999999991, 6.100000000000042, 2.9000000000001895, -77.20000000000078, -79.90000000000086, -69.40000000000074, 70.60000000000005, 10.099999999999985, 60.90000000000048, 27.000000000000117, -38.49999999999967, 41.80000000000033, 24.700000000000045, 31.800000000000185, 64.80000000000037, 66.10000000000034, -26.7999999999996, 45.700000000000394, -64.90000000000148, 33.0000000000002, 50.70000000000043, 61.50000000000048, 66.90000000000023, -4.899999999999729, -20.49999999999958, 2.600000000000102, -27.499999999999773, 40.0000000000003, -36.09999999999957, 68.8000000000001, 76.89999999999954, 10.29999999999992, 28.200000000000113, 40.90000000000031, 9.200000000000085, 44.80000000000038, 40.0000000000003, 40.0000000000003, 21.70000000000001, 60.30000000000043, 51.70000000000049, 34.000000000000234, -65.50000000000144, 31.200000000000166, -19.399999999999565, 16.899999999999974, -28.49999999999953, 40.500000000000306, 33.400000000000205, 21.100000000000005, 40.0000000000003, 9.199999999999957, 63.40000000000048, 71.49999999999991, -33.19999999999971, -35.899999999999615, -24.59999999999956, 50.20000000000047, 26.30000000000007, 2.6000000000001338, -1.799999999999772, 47.50000000000044, 40.0000000000003, 43.800000000000374, 46.50000000000041, 9.700000000000037, 40.0000000000003, 46.30000000000041, 26.000000000000107, 9.999999999999954, 19.599999999999973, 49.900000000000475, 21.800000000000015, 68.50000000000011, 35.3000000000002, -179.40000000000055, 24.60000000000005, 51.0000000000005, -276.09999999999997, 65.30000000000035, 32.70000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-427.0, -372.70000000000005, -271.29999999999995, -71.80000000000081, 47.600000000000236, 19.100000000000158, 20.000000000000014, 22.700000000000053, 9.49999999999998, 28.100000000000147, 58.700000000000216, -643.0, 20.000000000000014, 44.900000000000226, 23.900000000000073, -573.0999999999999, -69.10000000000083, 36.200000000000166, -400.2, -77.20000000000061, -86.80000000000068, 30.800000000000203, -464.89999999999986, 21.80000000000004, -91.30000000000015, 20.000000000000014, -50.79999999999986, -79.90000000000069, 20.000000000000014, 20.000000000000014, -351.1999999999993, -301.80000000000007, -333.1, 15.799999999999963, -306.4999999999999, -75.99999999999986, -116.50000000000054, -136.90000000000063, 51.500000000000206, 20.000000000000014, -49.299999999999805, 7.399999999999965, -369.29999999999995, -68.8000000000007, -42.99999999999978, -152.20000000000036, -143.8000000000007, -84.10000000000036, -102.10000000000056, -151.3000000000002, 29.90000000000018, 40.70000000000025, -21.699999999999783, -11.199999999999884, 26.900000000000126, 16.999999999999996, 12.499999999999964, -14.499999999999808, -70.30000000000078, -152.20000000000033, 12.799999999999962, 20.000000000000014, -91.30000000000057, 20.000000000000014, 7.999999999999972, -5.199999999999951, -23.799999999999834, 59.600000000000215, 34.40000000000023, 31.700000000000202, -111.7000000000007, 20.90000000000003, -2.4999999999999716, 36.20000000000025, -42.9999999999998, -115.90000000000069, 26.300000000000114, -28.29999999999975, 35.900000000000205, -8.199999999999902, 36.500000000000234, 20.000000000000014, 20.90000000000003, 32.00000000000022, -9.699999999999854, -35.19999999999978, -91.30000000000075, 15.799999999999962, 20.000000000000014, -51.39999999999989, -14.799999999999892, -78.7000000000004, 20.000000000000014, 20.000000000000014, -95.50000000000077, -22.59999999999976, 20.000000000000014, 48.80000000000021, 20.000000000000014, 56.90000000000021, 20.000000000000014, -36.69999999999981, -33.399999999999764, 20.600000000000037, 20.900000000000027, 20.000000000000014, 20.000000000000014, -38.799999999999756, 31.700000000000216, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 2.899999999999965, 20.000000000000014, 29.30000000000019, 31.700000000000212, 20.000000000000014, -8.799999999999928, 6.79999999999999, -33.699999999999825, -80.80000000000072, 20.000000000000014, 3.1999999999999615, -33.999999999999766, -51.399999999999814, 20.000000000000014, -24.099999999999746, -47.19999999999978, -28.29999999999975, 9.499999999999972, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, -25.899999999999785, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.799999999999756, 29.000000000000163, 34.40000000000023, 51.50000000000021, 20.000000000000014, 3.4999999999999654, -129.70000000000047, -19.899999999999785, -85.00000000000057, -87.10000000000066, 9.49999999999998, 20.000000000000014, 27.200000000000134, 20.000000000000014, -36.69999999999984, -51.399999999999935, 20.000000000000014, -57.70000000000032, 17.899999999999988, 16.999999999999975, 9.499999999999964, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 25.400000000000098, 13.09999999999997, 0.19999999999998389, -29.499999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.30000000000012, 8.89999999999997, -61.90000000000071, 13.999999999999996, -42.99999999999976, 17.899999999999977, -19.29999999999975, 29.900000000000187, 20.000000000000014, 20.000000000000014, -17.19999999999976, 40.70000000000022, 21.800000000000093, -1.0000000000000364, 26.300000000000114, -133.3000000000003, -168.10000000000028, -9.399999999999855, 20.000000000000014, 23.000000000000064, 20.000000000000014, -296.5, -613.6, 24.500000000000092, 36.8000000000002, 20.000000000000014, -1.300000000000003], "policy_predator_policy_reward": [338.0, 378.0, 147.0, 162.0, 2.0, 10.0, 0.0, 0.0, 0.0, 5.0, 503.0, 295.0, 4.0, 0.0, 220.0, 334.0, 45.0, 0.0, 280.0, 120.0, 0.0, 59.0, 221.0, 268.0, 43.0, 40.0, 19.0, 72.0, 0.0, 0.0, 166.0, 349.0, 214.0, 177.0, 185.0, 175.0, 104.0, 28.0, 0.0, 0.0, 39.0, 9.0, 297.0, 144.0, 43.0, 75.0, 45.0, 103.0, 71.0, 113.0, 0.0, 0.0, 13.0, 30.0, 16.0, 1.0, 4.0, 25.0, 98.0, 86.0, 9.0, 0.0, 51.0, 45.0, 19.0, 10.0, 9.0, 20.0, 0.0, 0.0, 5.0, 59.0, 0.0, 12.0, 47.0, 47.0, 23.0, 12.0, 23.0, 0.0, 5.0, 0.0, 1.0, 13.0, 10.0, 30.0, 11.0, 44.0, 1.0, 33.0, 25.0, 41.0, 0.0, 0.0, 44.0, 38.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 41.0, 0.0, 0.0, 0.0, 28.0, 0.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 11.0, 0.0, 0.0, 0.0, 26.0, 10.0, 0.0, 49.0, 8.0, 0.0, 5.0, 61.0, 21.0, 0.0, 47.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 20.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 0.0, 0.0, 31.0, 62.0, 21.0, 48.0, 30.0, 23.0, 3.0, 0.0, 22.0, 21.0, 15.0, 19.0, 25.0, 13.0, 5.0, 16.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 5.0, 34.0, 0.0, 0.0, 0.0, 0.0, 48.0, 31.0, 39.0, 0.0, 1.0, 20.0, 0.0, 0.0, 18.0, 1.0, 0.0, 6.0, 8.0, 2.0, 45.0, 77.0, 0.0, 14.0, 0.0, 8.0, 569.0, 65.0, 4.0, 0.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.271060467177195, "mean_inference_ms": 5.898909776981951, "mean_action_processing_ms": 0.9227743141493175, "mean_env_wait_ms": 0.7674779897299594, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005719542503356934, "StateBufferConnector_ms": 0.003929495811462402, "ViewRequirementAgentConnector_ms": 0.31508827209472656}, "num_episodes": 18, "episode_return_max": 213.6999999999992, "episode_return_min": -276.09999999999997, "episode_return_mean": 14.0120000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.08704651712068, "num_env_steps_trained_throughput_per_sec": 195.08704651712068, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 18604.878, "restore_workers_time_ms": 0.019, "training_step_time_ms": 18604.241, "sample_time_ms": 4428.88, "learn_time_ms": 14158.4, "learn_throughput": 282.518, "synch_weights_time_ms": 14.475}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "e57b0_00000", "date": "2024-08-13_00-15-23", "timestamp": 1723522523, "time_this_iter_s": 20.569480180740356, "time_total_s": 299.45920610427856, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b71040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 299.45920610427856, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 90.34482758620689, "ram_util_percent": 83.42758620689655}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9128137255393008, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.006120244535819, "policy_loss": -0.000616661009314672, "vf_loss": 7.006242611042406, "vf_explained_var": -0.00013741122351752387, "kl": 0.0029292886881994587, "entropy": 1.3066678714499902, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31008781404998254, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.666544138691413, "policy_loss": -0.0051236718825296195, "vf_loss": 4.671227798890815, "vf_explained_var": -8.717037382579985e-06, "kl": 0.011734017879026245, "entropy": 1.2970592866498958, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 76.89999999999954, "episode_reward_min": -549.6000000000001, "episode_reward_mean": -3.2409999999998824, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -638.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 59.600000000000215, "predator_policy": 569.0}, "policy_reward_mean": {"prey_policy": -37.6905, "predator_policy": 36.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-121.40000000000111, 71.49999999999991, 6.100000000000042, 2.9000000000001895, -77.20000000000078, -79.90000000000086, -69.40000000000074, 70.60000000000005, 10.099999999999985, 60.90000000000048, 27.000000000000117, -38.49999999999967, 41.80000000000033, 24.700000000000045, 31.800000000000185, 64.80000000000037, 66.10000000000034, -26.7999999999996, 45.700000000000394, -64.90000000000148, 33.0000000000002, 50.70000000000043, 61.50000000000048, 66.90000000000023, -4.899999999999729, -20.49999999999958, 2.600000000000102, -27.499999999999773, 40.0000000000003, -36.09999999999957, 68.8000000000001, 76.89999999999954, 10.29999999999992, 28.200000000000113, 40.90000000000031, 9.200000000000085, 44.80000000000038, 40.0000000000003, 40.0000000000003, 21.70000000000001, 60.30000000000043, 51.70000000000049, 34.000000000000234, -65.50000000000144, 31.200000000000166, -19.399999999999565, 16.899999999999974, -28.49999999999953, 40.500000000000306, 33.400000000000205, 21.100000000000005, 40.0000000000003, 9.199999999999957, 63.40000000000048, 71.49999999999991, -33.19999999999971, -35.899999999999615, -24.59999999999956, 50.20000000000047, 26.30000000000007, 2.6000000000001338, -1.799999999999772, 47.50000000000044, 40.0000000000003, 43.800000000000374, 46.50000000000041, 9.700000000000037, 40.0000000000003, 46.30000000000041, 26.000000000000107, 9.999999999999954, 19.599999999999973, 49.900000000000475, 21.800000000000015, 68.50000000000011, 35.3000000000002, -179.40000000000055, 24.60000000000005, 51.0000000000005, -276.09999999999997, 65.30000000000035, 32.70000000000019, 44.300000000000374, 14.5, 44.2000000000005, -42.99999999999977, 40.0000000000003, 4.800000000000182, 0.10000000000020004, -344.3, -12.200000000000063, -93.20000000000113, -166.59999999999974, -11.499999999999794, -549.6000000000001, -372.59999999999985, 4.800000000000182, -30.000000000000057, -58.19999999999979, 45.60000000000041], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-116.50000000000054, -136.90000000000063, 51.500000000000206, 20.000000000000014, -49.299999999999805, 7.399999999999965, -369.29999999999995, -68.8000000000007, -42.99999999999978, -152.20000000000036, -143.8000000000007, -84.10000000000036, -102.10000000000056, -151.3000000000002, 29.90000000000018, 40.70000000000025, -21.699999999999783, -11.199999999999884, 26.900000000000126, 16.999999999999996, 12.499999999999964, -14.499999999999808, -70.30000000000078, -152.20000000000033, 12.799999999999962, 20.000000000000014, -91.30000000000057, 20.000000000000014, 7.999999999999972, -5.199999999999951, -23.799999999999834, 59.600000000000215, 34.40000000000023, 31.700000000000202, -111.7000000000007, 20.90000000000003, -2.4999999999999716, 36.20000000000025, -42.9999999999998, -115.90000000000069, 26.300000000000114, -28.29999999999975, 35.900000000000205, -8.199999999999902, 36.500000000000234, 20.000000000000014, 20.90000000000003, 32.00000000000022, -9.699999999999854, -35.19999999999978, -91.30000000000075, 15.799999999999962, 20.000000000000014, -51.39999999999989, -14.799999999999892, -78.7000000000004, 20.000000000000014, 20.000000000000014, -95.50000000000077, -22.59999999999976, 20.000000000000014, 48.80000000000021, 20.000000000000014, 56.90000000000021, 20.000000000000014, -36.69999999999981, -33.399999999999764, 20.600000000000037, 20.900000000000027, 20.000000000000014, 20.000000000000014, -38.799999999999756, 31.700000000000216, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 2.899999999999965, 20.000000000000014, 29.30000000000019, 31.700000000000212, 20.000000000000014, -8.799999999999928, 6.79999999999999, -33.699999999999825, -80.80000000000072, 20.000000000000014, 3.1999999999999615, -33.999999999999766, -51.399999999999814, 20.000000000000014, -24.099999999999746, -47.19999999999978, -28.29999999999975, 9.499999999999972, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, -25.899999999999785, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.799999999999756, 29.000000000000163, 34.40000000000023, 51.50000000000021, 20.000000000000014, 3.4999999999999654, -129.70000000000047, -19.899999999999785, -85.00000000000057, -87.10000000000066, 9.49999999999998, 20.000000000000014, 27.200000000000134, 20.000000000000014, -36.69999999999984, -51.399999999999935, 20.000000000000014, -57.70000000000032, 17.899999999999988, 16.999999999999975, 9.499999999999964, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 25.400000000000098, 13.09999999999997, 0.19999999999998389, -29.499999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.30000000000012, 8.89999999999997, -61.90000000000071, 13.999999999999996, -42.99999999999976, 17.899999999999977, -19.29999999999975, 29.900000000000187, 20.000000000000014, 20.000000000000014, -17.19999999999976, 40.70000000000022, 21.800000000000093, -1.0000000000000364, 26.300000000000114, -133.3000000000003, -168.10000000000028, -9.399999999999855, 20.000000000000014, 23.000000000000064, 20.000000000000014, -296.5, -613.6, 24.500000000000092, 36.8000000000002, 20.000000000000014, -1.300000000000003, 20.000000000000014, 14.299999999999967, -602.0, -236.50000000000003, 1.0999999999999972, 34.10000000000026, -261.8999999999999, -24.100000000000023, 20.000000000000014, 20.000000000000014, -21.099999999999973, -3.100000000000003, -16.899999999999743, -42.99999999999978, -464.4, -534.9, -59.79999999999979, -9.400000000000034, -121.60000000000053, -97.60000000000079, -133.29999999999984, -157.29999999999984, -19.900000000000023, -10.59999999999999, -638.4000000000001, -466.20000000000005, -435.2000000000001, -437.3999999999999, -15.699999999999747, -11.499999999999819, -11.500000000000007, -53.4999999999998, -45.100000000000044, -60.100000000000016, 17.60000000000001, 20.000000000000014], "policy_predator_policy_reward": [104.0, 28.0, 0.0, 0.0, 39.0, 9.0, 297.0, 144.0, 43.0, 75.0, 45.0, 103.0, 71.0, 113.0, 0.0, 0.0, 13.0, 30.0, 16.0, 1.0, 4.0, 25.0, 98.0, 86.0, 9.0, 0.0, 51.0, 45.0, 19.0, 10.0, 9.0, 20.0, 0.0, 0.0, 5.0, 59.0, 0.0, 12.0, 47.0, 47.0, 23.0, 12.0, 23.0, 0.0, 5.0, 0.0, 1.0, 13.0, 10.0, 30.0, 11.0, 44.0, 1.0, 33.0, 25.0, 41.0, 0.0, 0.0, 44.0, 38.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 41.0, 0.0, 0.0, 0.0, 28.0, 0.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 11.0, 0.0, 0.0, 0.0, 26.0, 10.0, 0.0, 49.0, 8.0, 0.0, 5.0, 61.0, 21.0, 0.0, 47.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 20.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 0.0, 0.0, 31.0, 62.0, 21.0, 48.0, 30.0, 23.0, 3.0, 0.0, 22.0, 21.0, 15.0, 19.0, 25.0, 13.0, 5.0, 16.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 5.0, 34.0, 0.0, 0.0, 0.0, 0.0, 48.0, 31.0, 39.0, 0.0, 1.0, 20.0, 0.0, 0.0, 18.0, 1.0, 0.0, 6.0, 8.0, 2.0, 45.0, 77.0, 0.0, 14.0, 0.0, 8.0, 569.0, 65.0, 4.0, 0.0, 0.0, 14.0, 10.0, 0.0, 320.0, 533.0, 0.0, 9.0, 46.0, 197.0, 0.0, 0.0, 0.0, 29.0, 29.0, 31.0, 230.0, 425.0, 18.0, 39.0, 0.0, 126.0, 118.0, 6.0, 0.0, 19.0, 0.0, 555.0, 483.0, 17.0, 17.0, 15.0, 35.0, 0.0, 47.0, 0.0, 0.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.25760380255642, "mean_inference_ms": 5.873937059325445, "mean_action_processing_ms": 0.9147548710251848, "mean_env_wait_ms": 0.7652924078514668, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005742907524108887, "StateBufferConnector_ms": 0.004126548767089844, "ViewRequirementAgentConnector_ms": 0.3242708444595337}, "num_episodes": 18, "episode_return_max": 76.89999999999954, "episode_return_min": -549.6000000000001, "episode_return_mean": -3.2409999999998824, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 242.32082034500397, "num_env_steps_trained_throughput_per_sec": 242.32082034500397, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 18131.426, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18130.796, "sample_time_ms": 4244.207, "learn_time_ms": 13870.733, "learn_throughput": 288.377, "synch_weights_time_ms": 13.977}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "e57b0_00000", "date": "2024-08-13_00-15-40", "timestamp": 1723522540, "time_this_iter_s": 16.555105209350586, "time_total_s": 316.01431131362915, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b59b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 316.01431131362915, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 83.34347826086957, "ram_util_percent": 82.90434782608696}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1118473593993161, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.477967358644678, "policy_loss": -0.006178393041981118, "vf_loss": 9.48274087804966, "vf_explained_var": 0.00125410380186858, "kl": 0.01665042478412926, "entropy": 1.325742524515384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36416787197074246, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.980655211494082, "policy_loss": -0.005305411692193793, "vf_loss": 7.985484230202973, "vf_explained_var": 7.433708382662011e-05, "kl": 0.012704216569677957, "entropy": 1.243749787063195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 76.89999999999954, "episode_reward_min": -549.6000000000001, "episode_reward_mean": -32.777999999999864, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -638.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 56.90000000000021, "predator_policy": 636.0}, "policy_reward_mean": {"prey_policy": -79.83399999999997, "predator_policy": 63.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.700000000000394, -64.90000000000148, 33.0000000000002, 50.70000000000043, 61.50000000000048, 66.90000000000023, -4.899999999999729, -20.49999999999958, 2.600000000000102, -27.499999999999773, 40.0000000000003, -36.09999999999957, 68.8000000000001, 76.89999999999954, 10.29999999999992, 28.200000000000113, 40.90000000000031, 9.200000000000085, 44.80000000000038, 40.0000000000003, 40.0000000000003, 21.70000000000001, 60.30000000000043, 51.70000000000049, 34.000000000000234, -65.50000000000144, 31.200000000000166, -19.399999999999565, 16.899999999999974, -28.49999999999953, 40.500000000000306, 33.400000000000205, 21.100000000000005, 40.0000000000003, 9.199999999999957, 63.40000000000048, 71.49999999999991, -33.19999999999971, -35.899999999999615, -24.59999999999956, 50.20000000000047, 26.30000000000007, 2.6000000000001338, -1.799999999999772, 47.50000000000044, 40.0000000000003, 43.800000000000374, 46.50000000000041, 9.700000000000037, 40.0000000000003, 46.30000000000041, 26.000000000000107, 9.999999999999954, 19.599999999999973, 49.900000000000475, 21.800000000000015, 68.50000000000011, 35.3000000000002, -179.40000000000055, 24.60000000000005, 51.0000000000005, -276.09999999999997, 65.30000000000035, 32.70000000000019, 44.300000000000374, 14.5, 44.2000000000005, -42.99999999999977, 40.0000000000003, 4.800000000000182, 0.10000000000020004, -344.3, -12.200000000000063, -93.20000000000113, -166.59999999999974, -11.499999999999794, -549.6000000000001, -372.59999999999985, 4.800000000000182, -30.000000000000057, -58.19999999999979, 45.60000000000041, -23.599999999999827, -147.60000000000002, -169.49999999999986, 26.999999999999112, -103.09999999999988, 23.300000000000487, -470.0, -63.899999999999835, -72.29999999999966, -95.2999999999999, -149.49999999999997, -128.9999999999999, -125.90000000000023, -171.89999999999984, -444.69999999999993, -401.09999999999985, -160.49999999999994, -211.00000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-2.4999999999999716, 36.20000000000025, -42.9999999999998, -115.90000000000069, 26.300000000000114, -28.29999999999975, 35.900000000000205, -8.199999999999902, 36.500000000000234, 20.000000000000014, 20.90000000000003, 32.00000000000022, -9.699999999999854, -35.19999999999978, -91.30000000000075, 15.799999999999962, 20.000000000000014, -51.39999999999989, -14.799999999999892, -78.7000000000004, 20.000000000000014, 20.000000000000014, -95.50000000000077, -22.59999999999976, 20.000000000000014, 48.80000000000021, 20.000000000000014, 56.90000000000021, 20.000000000000014, -36.69999999999981, -33.399999999999764, 20.600000000000037, 20.900000000000027, 20.000000000000014, 20.000000000000014, -38.799999999999756, 31.700000000000216, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 2.899999999999965, 20.000000000000014, 29.30000000000019, 31.700000000000212, 20.000000000000014, -8.799999999999928, 6.79999999999999, -33.699999999999825, -80.80000000000072, 20.000000000000014, 3.1999999999999615, -33.999999999999766, -51.399999999999814, 20.000000000000014, -24.099999999999746, -47.19999999999978, -28.29999999999975, 9.499999999999972, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, -25.899999999999785, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.799999999999756, 29.000000000000163, 34.40000000000023, 51.50000000000021, 20.000000000000014, 3.4999999999999654, -129.70000000000047, -19.899999999999785, -85.00000000000057, -87.10000000000066, 9.49999999999998, 20.000000000000014, 27.200000000000134, 20.000000000000014, -36.69999999999984, -51.399999999999935, 20.000000000000014, -57.70000000000032, 17.899999999999988, 16.999999999999975, 9.499999999999964, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 25.400000000000098, 13.09999999999997, 0.19999999999998389, -29.499999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.30000000000012, 8.89999999999997, -61.90000000000071, 13.999999999999996, -42.99999999999976, 17.899999999999977, -19.29999999999975, 29.900000000000187, 20.000000000000014, 20.000000000000014, -17.19999999999976, 40.70000000000022, 21.800000000000093, -1.0000000000000364, 26.300000000000114, -133.3000000000003, -168.10000000000028, -9.399999999999855, 20.000000000000014, 23.000000000000064, 20.000000000000014, -296.5, -613.6, 24.500000000000092, 36.8000000000002, 20.000000000000014, -1.300000000000003, 20.000000000000014, 14.299999999999967, -602.0, -236.50000000000003, 1.0999999999999972, 34.10000000000026, -261.8999999999999, -24.100000000000023, 20.000000000000014, 20.000000000000014, -21.099999999999973, -3.100000000000003, -16.899999999999743, -42.99999999999978, -464.4, -534.9, -59.79999999999979, -9.400000000000034, -121.60000000000053, -97.60000000000079, -133.29999999999984, -157.29999999999984, -19.900000000000023, -10.59999999999999, -638.4000000000001, -466.20000000000005, -435.2000000000001, -437.3999999999999, -15.699999999999747, -11.499999999999819, -11.500000000000007, -53.4999999999998, -45.100000000000044, -60.100000000000016, 17.60000000000001, 20.000000000000014, -545.0, 37.40000000000022, -406.49999999999994, -461.1, -131.20000000000002, -205.29999999999995, -84.99999999999994, -488.00000000000034, -443.7, 5.600000000000172, -1.0, 14.300000000000246, -595.8, -499.2, -380.2, -88.69999999999985, -85.30000000000001, -63.999999999999986, -134.8, -109.50000000000003, -500.3, -437.20000000000005, -251.49999999999986, -220.50000000000003, 20.000000000000014, -347.9000000000001, -255.2, -178.69999999999993, -587.0999999999999, -493.59999999999997, -454.40000000000003, -582.7, -76.89999999999986, -226.6000000000005, -524.8999999999994, -150.0999999999999], "policy_predator_policy_reward": [0.0, 12.0, 47.0, 47.0, 23.0, 12.0, 23.0, 0.0, 5.0, 0.0, 1.0, 13.0, 10.0, 30.0, 11.0, 44.0, 1.0, 33.0, 25.0, 41.0, 0.0, 0.0, 44.0, 38.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 41.0, 0.0, 0.0, 0.0, 28.0, 0.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 11.0, 0.0, 0.0, 0.0, 26.0, 10.0, 0.0, 49.0, 8.0, 0.0, 5.0, 61.0, 21.0, 0.0, 47.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 20.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 0.0, 0.0, 31.0, 62.0, 21.0, 48.0, 30.0, 23.0, 3.0, 0.0, 22.0, 21.0, 15.0, 19.0, 25.0, 13.0, 5.0, 16.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 5.0, 34.0, 0.0, 0.0, 0.0, 0.0, 48.0, 31.0, 39.0, 0.0, 1.0, 20.0, 0.0, 0.0, 18.0, 1.0, 0.0, 6.0, 8.0, 2.0, 45.0, 77.0, 0.0, 14.0, 0.0, 8.0, 569.0, 65.0, 4.0, 0.0, 0.0, 14.0, 10.0, 0.0, 320.0, 533.0, 0.0, 9.0, 46.0, 197.0, 0.0, 0.0, 0.0, 29.0, 29.0, 31.0, 230.0, 425.0, 18.0, 39.0, 0.0, 126.0, 118.0, 6.0, 0.0, 19.0, 0.0, 555.0, 483.0, 17.0, 17.0, 15.0, 35.0, 0.0, 47.0, 0.0, 0.0, 8.0, 477.0, 7.0, 366.0, 354.0, 56.0, 111.0, 278.0, 322.0, 0.0, 335.0, 10.0, 0.0, 71.0, 554.0, 132.0, 273.0, 52.0, 25.0, 132.0, 17.0, 337.0, 451.0, 209.0, 134.0, 6.0, 196.0, 148.0, 114.0, 0.0, 636.0, 547.0, 89.0, 122.0, 21.0, 0.0, 464.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2467111341908077, "mean_inference_ms": 5.8637550136642735, "mean_action_processing_ms": 0.9083742788489321, "mean_env_wait_ms": 0.7644929592612325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005620598793029785, "StateBufferConnector_ms": 0.004081249237060547, "ViewRequirementAgentConnector_ms": 0.3057187795639038}, "num_episodes": 18, "episode_return_max": 76.89999999999954, "episode_return_min": -549.6000000000001, "episode_return_mean": -32.777999999999864, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.58275492329753, "num_env_steps_trained_throughput_per_sec": 200.58275492329753, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 18240.142, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18239.506, "sample_time_ms": 3981.542, "learn_time_ms": 14238.927, "learn_throughput": 280.92, "synch_weights_time_ms": 17.041}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "e57b0_00000", "date": "2024-08-13_00-16-00", "timestamp": 1723522560, "time_this_iter_s": 20.01347017288208, "time_total_s": 336.02778148651123, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b3b3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 336.02778148651123, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 89.43793103448277, "ram_util_percent": 83.44827586206897}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2223894625823333, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.2901183210352745, "policy_loss": -0.006837968648012195, "vf_loss": 5.295764154731912, "vf_explained_var": 0.0020441934229835632, "kl": 0.014129103952428078, "entropy": 1.25491698103607, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.39348202044804576, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.859985853124548, "policy_loss": -0.002436168066585663, "vf_loss": 6.862059181960172, "vf_explained_var": -0.00017948872828609728, "kl": 0.009674886681420759, "entropy": 1.222729820296878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 115.60000000000011, "episode_reward_min": -549.6000000000001, "episode_reward_mean": -46.16099999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -764.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 51.50000000000021, "predator_policy": 698.0}, "policy_reward_mean": {"prey_policy": -127.47549999999997, "predator_policy": 104.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.30000000000043, 51.70000000000049, 34.000000000000234, -65.50000000000144, 31.200000000000166, -19.399999999999565, 16.899999999999974, -28.49999999999953, 40.500000000000306, 33.400000000000205, 21.100000000000005, 40.0000000000003, 9.199999999999957, 63.40000000000048, 71.49999999999991, -33.19999999999971, -35.899999999999615, -24.59999999999956, 50.20000000000047, 26.30000000000007, 2.6000000000001338, -1.799999999999772, 47.50000000000044, 40.0000000000003, 43.800000000000374, 46.50000000000041, 9.700000000000037, 40.0000000000003, 46.30000000000041, 26.000000000000107, 9.999999999999954, 19.599999999999973, 49.900000000000475, 21.800000000000015, 68.50000000000011, 35.3000000000002, -179.40000000000055, 24.60000000000005, 51.0000000000005, -276.09999999999997, 65.30000000000035, 32.70000000000019, 44.300000000000374, 14.5, 44.2000000000005, -42.99999999999977, 40.0000000000003, 4.800000000000182, 0.10000000000020004, -344.3, -12.200000000000063, -93.20000000000113, -166.59999999999974, -11.499999999999794, -549.6000000000001, -372.59999999999985, 4.800000000000182, -30.000000000000057, -58.19999999999979, 45.60000000000041, -23.599999999999827, -147.60000000000002, -169.49999999999986, 26.999999999999112, -103.09999999999988, 23.300000000000487, -470.0, -63.899999999999835, -72.29999999999966, -95.2999999999999, -149.49999999999997, -128.9999999999999, -125.90000000000023, -171.89999999999984, -444.69999999999993, -401.09999999999985, -160.49999999999994, -211.00000000000023, 115.60000000000011, -14.59999999999993, 64.50000000000027, 11.100000000000072, -152.20000000000005, -46.60000000000032, -330.69999999999993, 36.70000000000025, -21.699999999999605, -56.60000000000002, 5.900000000000139, 79.10000000000034, -280.10000000000014, 40.0000000000003, -108.89999999999999, 86.79999999999941, -60.09999999999988, -14.999999999999723, -259.4, 34.30000000000024, -26.29999999999992, 87.20000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 29.30000000000019, 31.700000000000212, 20.000000000000014, -8.799999999999928, 6.79999999999999, -33.699999999999825, -80.80000000000072, 20.000000000000014, 3.1999999999999615, -33.999999999999766, -51.399999999999814, 20.000000000000014, -24.099999999999746, -47.19999999999978, -28.29999999999975, 9.499999999999972, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, -25.899999999999785, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.799999999999756, 29.000000000000163, 34.40000000000023, 51.50000000000021, 20.000000000000014, 3.4999999999999654, -129.70000000000047, -19.899999999999785, -85.00000000000057, -87.10000000000066, 9.49999999999998, 20.000000000000014, 27.200000000000134, 20.000000000000014, -36.69999999999984, -51.399999999999935, 20.000000000000014, -57.70000000000032, 17.899999999999988, 16.999999999999975, 9.499999999999964, 20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 25.400000000000098, 13.09999999999997, 0.19999999999998389, -29.499999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.30000000000012, 8.89999999999997, -61.90000000000071, 13.999999999999996, -42.99999999999976, 17.899999999999977, -19.29999999999975, 29.900000000000187, 20.000000000000014, 20.000000000000014, -17.19999999999976, 40.70000000000022, 21.800000000000093, -1.0000000000000364, 26.300000000000114, -133.3000000000003, -168.10000000000028, -9.399999999999855, 20.000000000000014, 23.000000000000064, 20.000000000000014, -296.5, -613.6, 24.500000000000092, 36.8000000000002, 20.000000000000014, -1.300000000000003, 20.000000000000014, 14.299999999999967, -602.0, -236.50000000000003, 1.0999999999999972, 34.10000000000026, -261.8999999999999, -24.100000000000023, 20.000000000000014, 20.000000000000014, -21.099999999999973, -3.100000000000003, -16.899999999999743, -42.99999999999978, -464.4, -534.9, -59.79999999999979, -9.400000000000034, -121.60000000000053, -97.60000000000079, -133.29999999999984, -157.29999999999984, -19.900000000000023, -10.59999999999999, -638.4000000000001, -466.20000000000005, -435.2000000000001, -437.3999999999999, -15.699999999999747, -11.499999999999819, -11.500000000000007, -53.4999999999998, -45.100000000000044, -60.100000000000016, 17.60000000000001, 20.000000000000014, -545.0, 37.40000000000022, -406.49999999999994, -461.1, -131.20000000000002, -205.29999999999995, -84.99999999999994, -488.00000000000034, -443.7, 5.600000000000172, -1.0, 14.300000000000246, -595.8, -499.2, -380.2, -88.69999999999985, -85.30000000000001, -63.999999999999986, -134.8, -109.50000000000003, -500.3, -437.20000000000005, -251.49999999999986, -220.50000000000003, 20.000000000000014, -347.9000000000001, -255.2, -178.69999999999993, -587.0999999999999, -493.59999999999997, -454.40000000000003, -582.7, -76.89999999999986, -226.6000000000005, -524.8999999999994, -150.0999999999999, -702.1, -70.30000000000003, -19.899999999999764, -171.70000000000016, -549.6, -82.89999999999985, -390.90000000000003, -85.00000000000014, -301.4000000000002, -286.7999999999996, -36.699999999999775, -70.90000000000076, -692.0, -289.70000000000005, 13.699999999999967, 20.000000000000014, -28.599999999999767, -81.09999999999994, -400.9, -190.70000000000005, -45.09999999999976, 20.000000000000014, 20.000000000000014, -154.89999999999986, -183.00000000000009, -728.1, 20.000000000000014, 20.000000000000014, -764.7, -583.2, 17.900000000000013, -442.09999999999945, -67.00000000000014, -114.09999999999997, 29.000000000000167, -115.00000000000023, -467.4, -758.0, -214.49999999999997, 30.800000000000207, -494.3, 20.000000000000014, 26.600000000000122, -248.39999999999986], "policy_predator_policy_reward": [11.0, 0.0, 0.0, 0.0, 26.0, 10.0, 0.0, 49.0, 8.0, 0.0, 5.0, 61.0, 21.0, 0.0, 47.0, 0.0, 0.0, 11.0, 0.0, 6.0, 7.0, 20.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 0.0, 0.0, 31.0, 62.0, 21.0, 48.0, 30.0, 23.0, 3.0, 0.0, 22.0, 21.0, 15.0, 19.0, 25.0, 13.0, 5.0, 16.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 5.0, 34.0, 0.0, 0.0, 0.0, 0.0, 48.0, 31.0, 39.0, 0.0, 1.0, 20.0, 0.0, 0.0, 18.0, 1.0, 0.0, 6.0, 8.0, 2.0, 45.0, 77.0, 0.0, 14.0, 0.0, 8.0, 569.0, 65.0, 4.0, 0.0, 0.0, 14.0, 10.0, 0.0, 320.0, 533.0, 0.0, 9.0, 46.0, 197.0, 0.0, 0.0, 0.0, 29.0, 29.0, 31.0, 230.0, 425.0, 18.0, 39.0, 0.0, 126.0, 118.0, 6.0, 0.0, 19.0, 0.0, 555.0, 483.0, 17.0, 17.0, 15.0, 35.0, 0.0, 47.0, 0.0, 0.0, 8.0, 477.0, 7.0, 366.0, 354.0, 56.0, 111.0, 278.0, 322.0, 0.0, 335.0, 10.0, 0.0, 71.0, 554.0, 132.0, 273.0, 52.0, 25.0, 132.0, 17.0, 337.0, 451.0, 209.0, 134.0, 6.0, 196.0, 148.0, 114.0, 0.0, 636.0, 547.0, 89.0, 122.0, 21.0, 0.0, 464.0, 439.0, 449.0, 110.0, 67.0, 420.0, 277.0, 323.0, 164.0, 305.0, 131.0, 6.0, 55.0, 626.0, 25.0, 3.0, 0.0, 57.0, 31.0, 343.0, 192.0, 31.0, 0.0, 84.0, 130.0, 0.0, 631.0, 0.0, 0.0, 541.0, 698.0, 238.0, 273.0, 101.0, 20.0, 65.0, 6.0, 325.0, 641.0, 93.0, 125.0, 393.0, 55.0, 178.0, 131.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.260487185589588, "mean_inference_ms": 5.926201523751797, "mean_action_processing_ms": 0.9094905122378444, "mean_env_wait_ms": 0.7743735011807223, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008412480354309082, "StateBufferConnector_ms": 0.004087328910827637, "ViewRequirementAgentConnector_ms": 0.31647825241088867}, "num_episodes": 22, "episode_return_max": 115.60000000000011, "episode_return_min": -549.6000000000001, "episode_return_mean": -46.16099999999989, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 223.7707409245007, "num_env_steps_trained_throughput_per_sec": 223.7707409245007, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 18346.412, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18346.357, "sample_time_ms": 4209.322, "learn_time_ms": 14117.038, "learn_throughput": 283.346, "synch_weights_time_ms": 18.141}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "e57b0_00000", "date": "2024-08-13_00-16-18", "timestamp": 1723522578, "time_this_iter_s": 17.93600583076477, "time_total_s": 353.963787317276, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bbca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 353.963787317276, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 87.64, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0742945665286647, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.393139953272683, "policy_loss": -0.007252838570506326, "vf_loss": 2.3992564482663674, "vf_explained_var": 0.004199792247600656, "kl": 0.013467718572292384, "entropy": 1.2183354114729261, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5101037397645611, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6278702633721487, "policy_loss": -0.0012822252175913602, "vf_loss": 2.628861299898259, "vf_explained_var": 0.007414569205077237, "kl": 0.007765014554183693, "entropy": 1.2751864278127276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 117.79999999999994, "episode_reward_min": -549.6000000000001, "episode_reward_mean": -45.2269999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -764.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000023, "predator_policy": 698.0}, "policy_reward_mean": {"prey_policy": -133.49349999999998, "predator_policy": 110.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 43.800000000000374, 46.50000000000041, 9.700000000000037, 40.0000000000003, 46.30000000000041, 26.000000000000107, 9.999999999999954, 19.599999999999973, 49.900000000000475, 21.800000000000015, 68.50000000000011, 35.3000000000002, -179.40000000000055, 24.60000000000005, 51.0000000000005, -276.09999999999997, 65.30000000000035, 32.70000000000019, 44.300000000000374, 14.5, 44.2000000000005, -42.99999999999977, 40.0000000000003, 4.800000000000182, 0.10000000000020004, -344.3, -12.200000000000063, -93.20000000000113, -166.59999999999974, -11.499999999999794, -549.6000000000001, -372.59999999999985, 4.800000000000182, -30.000000000000057, -58.19999999999979, 45.60000000000041, -23.599999999999827, -147.60000000000002, -169.49999999999986, 26.999999999999112, -103.09999999999988, 23.300000000000487, -470.0, -63.899999999999835, -72.29999999999966, -95.2999999999999, -149.49999999999997, -128.9999999999999, -125.90000000000023, -171.89999999999984, -444.69999999999993, -401.09999999999985, -160.49999999999994, -211.00000000000023, 115.60000000000011, -14.59999999999993, 64.50000000000027, 11.100000000000072, -152.20000000000005, -46.60000000000032, -330.69999999999993, 36.70000000000025, -21.699999999999605, -56.60000000000002, 5.900000000000139, 79.10000000000034, -280.10000000000014, 40.0000000000003, -108.89999999999999, 86.79999999999941, -60.09999999999988, -14.999999999999723, -259.4, 34.30000000000024, -26.29999999999992, 87.20000000000013, 18.49999999999996, 35.90000000000024, 33.1000000000002, 37.80000000000027, 63.40000000000051, -80.10000000000116, 61.40000000000052, 32.30000000000018, 117.79999999999994, 44.00000000000036, 4.09999999999993, 40.0000000000003, 58.10000000000047, 22.100000000000033, -266.1, 79.59999999999937, 51.10000000000048, 34.30000000000022, 44.90000000000041, 34.700000000000266, -25.599999999999767, 43.8000000000005, -0.7999999999998141], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 15.79999999999996, 20.000000000000014, 25.400000000000098, 13.09999999999997, 0.19999999999998389, -29.499999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.30000000000012, 8.89999999999997, -61.90000000000071, 13.999999999999996, -42.99999999999976, 17.899999999999977, -19.29999999999975, 29.900000000000187, 20.000000000000014, 20.000000000000014, -17.19999999999976, 40.70000000000022, 21.800000000000093, -1.0000000000000364, 26.300000000000114, -133.3000000000003, -168.10000000000028, -9.399999999999855, 20.000000000000014, 23.000000000000064, 20.000000000000014, -296.5, -613.6, 24.500000000000092, 36.8000000000002, 20.000000000000014, -1.300000000000003, 20.000000000000014, 14.299999999999967, -602.0, -236.50000000000003, 1.0999999999999972, 34.10000000000026, -261.8999999999999, -24.100000000000023, 20.000000000000014, 20.000000000000014, -21.099999999999973, -3.100000000000003, -16.899999999999743, -42.99999999999978, -464.4, -534.9, -59.79999999999979, -9.400000000000034, -121.60000000000053, -97.60000000000079, -133.29999999999984, -157.29999999999984, -19.900000000000023, -10.59999999999999, -638.4000000000001, -466.20000000000005, -435.2000000000001, -437.3999999999999, -15.699999999999747, -11.499999999999819, -11.500000000000007, -53.4999999999998, -45.100000000000044, -60.100000000000016, 17.60000000000001, 20.000000000000014, -545.0, 37.40000000000022, -406.49999999999994, -461.1, -131.20000000000002, -205.29999999999995, -84.99999999999994, -488.00000000000034, -443.7, 5.600000000000172, -1.0, 14.300000000000246, -595.8, -499.2, -380.2, -88.69999999999985, -85.30000000000001, -63.999999999999986, -134.8, -109.50000000000003, -500.3, -437.20000000000005, -251.49999999999986, -220.50000000000003, 20.000000000000014, -347.9000000000001, -255.2, -178.69999999999993, -587.0999999999999, -493.59999999999997, -454.40000000000003, -582.7, -76.89999999999986, -226.6000000000005, -524.8999999999994, -150.0999999999999, -702.1, -70.30000000000003, -19.899999999999764, -171.70000000000016, -549.6, -82.89999999999985, -390.90000000000003, -85.00000000000014, -301.4000000000002, -286.7999999999996, -36.699999999999775, -70.90000000000076, -692.0, -289.70000000000005, 13.699999999999967, 20.000000000000014, -28.599999999999767, -81.09999999999994, -400.9, -190.70000000000005, -45.09999999999976, 20.000000000000014, 20.000000000000014, -154.89999999999986, -183.00000000000009, -728.1, 20.000000000000014, 20.000000000000014, -764.7, -583.2, 17.900000000000013, -442.09999999999945, -67.00000000000014, -114.09999999999997, 29.000000000000167, -115.00000000000023, -467.4, -758.0, -214.49999999999997, 30.800000000000207, -494.3, 20.000000000000014, 26.600000000000122, -248.39999999999986, -23.49999999999975, 20.000000000000014, 3.1999999999999686, 7.699999999999971, 22.100000000000044, -0.9999999999999881, 20.000000000000014, 15.799999999999962, 43.40000000000025, 20.000000000000014, -116.80000000000067, -94.30000000000054, 37.70000000000025, 19.700000000000014, 11.599999999999966, 13.699999999999969, 15.499999999999966, -400.7, 5.299999999999965, 31.700000000000216, 35.30000000000024, -131.2000000000007, 20.000000000000014, 20.000000000000014, 47.90000000000023, -17.799999999999834, -40.89999999999977, 20.000000000000014, -429.8, -458.29999999999995, 43.40000000000023, 36.20000000000025, 20.000000000000014, 19.100000000000012, 8.299999999999965, 20.000000000000014, -101.80000000000004, 31.700000000000212, 20.000000000000014, -28.300000000000033, -3.099999999999972, -179.50000000000028, 20.90000000000003, 14.89999999999999, -120.70000000000076, 5.89999999999997], "policy_predator_policy_reward": [0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 5.0, 34.0, 0.0, 0.0, 0.0, 0.0, 48.0, 31.0, 39.0, 0.0, 1.0, 20.0, 0.0, 0.0, 18.0, 1.0, 0.0, 6.0, 8.0, 2.0, 45.0, 77.0, 0.0, 14.0, 0.0, 8.0, 569.0, 65.0, 4.0, 0.0, 0.0, 14.0, 10.0, 0.0, 320.0, 533.0, 0.0, 9.0, 46.0, 197.0, 0.0, 0.0, 0.0, 29.0, 29.0, 31.0, 230.0, 425.0, 18.0, 39.0, 0.0, 126.0, 118.0, 6.0, 0.0, 19.0, 0.0, 555.0, 483.0, 17.0, 17.0, 15.0, 35.0, 0.0, 47.0, 0.0, 0.0, 8.0, 477.0, 7.0, 366.0, 354.0, 56.0, 111.0, 278.0, 322.0, 0.0, 335.0, 10.0, 0.0, 71.0, 554.0, 132.0, 273.0, 52.0, 25.0, 132.0, 17.0, 337.0, 451.0, 209.0, 134.0, 6.0, 196.0, 148.0, 114.0, 0.0, 636.0, 547.0, 89.0, 122.0, 21.0, 0.0, 464.0, 439.0, 449.0, 110.0, 67.0, 420.0, 277.0, 323.0, 164.0, 305.0, 131.0, 6.0, 55.0, 626.0, 25.0, 3.0, 0.0, 57.0, 31.0, 343.0, 192.0, 31.0, 0.0, 84.0, 130.0, 0.0, 631.0, 0.0, 0.0, 541.0, 698.0, 238.0, 273.0, 101.0, 20.0, 65.0, 6.0, 325.0, 641.0, 93.0, 125.0, 393.0, 55.0, 178.0, 131.0, 22.0, 0.0, 14.0, 11.0, 3.0, 9.0, 0.0, 2.0, 0.0, 0.0, 45.0, 86.0, 0.0, 4.0, 5.0, 2.0, 258.0, 245.0, 7.0, 0.0, 55.0, 45.0, 0.0, 0.0, 11.0, 17.0, 23.0, 20.0, 230.0, 392.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 57.0, 58.0, 21.0, 22.0, 61.0, 96.0, 7.0, 1.0, 62.0, 52.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.262432026527613, "mean_inference_ms": 5.949009311617251, "mean_action_processing_ms": 0.9093312973397962, "mean_env_wait_ms": 0.7786265251158127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008591055870056152, "StateBufferConnector_ms": 0.0045490264892578125, "ViewRequirementAgentConnector_ms": 0.3052353858947754}, "num_episodes": 23, "episode_return_max": 117.79999999999994, "episode_return_min": -549.6000000000001, "episode_return_mean": -45.2269999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 248.40801120550455, "num_env_steps_trained_throughput_per_sec": 248.40801120550455, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 18196.367, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18196.311, "sample_time_ms": 4267.325, "learn_time_ms": 13908.431, "learn_throughput": 287.595, "synch_weights_time_ms": 18.284}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "e57b0_00000", "date": "2024-08-13_00-16-34", "timestamp": 1723522594, "time_this_iter_s": 16.192321062088013, "time_total_s": 370.156108379364, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bb940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 370.156108379364, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 84.6086956521739, "ram_util_percent": 83.25652173913043}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8644779754299966, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.44235821087209, "policy_loss": -0.007381711966757264, "vf_loss": 1.4483569366591318, "vf_explained_var": 0.00044771041819658227, "kl": 0.01639102646597141, "entropy": 1.1433014139296516, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3461131155274059, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.610856035493669, "policy_loss": -0.0009279303506470073, "vf_loss": 1.6115749924901932, "vf_explained_var": 0.0016129114955821366, "kl": 0.005572730864646569, "entropy": 1.2891156839315223, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 117.79999999999994, "episode_reward_min": -549.6000000000001, "episode_reward_mean": -44.42799999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -764.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000023, "predator_policy": 698.0}, "policy_reward_mean": {"prey_policy": -133.569, "predator_policy": 111.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.70000000000019, 44.300000000000374, 14.5, 44.2000000000005, -42.99999999999977, 40.0000000000003, 4.800000000000182, 0.10000000000020004, -344.3, -12.200000000000063, -93.20000000000113, -166.59999999999974, -11.499999999999794, -549.6000000000001, -372.59999999999985, 4.800000000000182, -30.000000000000057, -58.19999999999979, 45.60000000000041, -23.599999999999827, -147.60000000000002, -169.49999999999986, 26.999999999999112, -103.09999999999988, 23.300000000000487, -470.0, -63.899999999999835, -72.29999999999966, -95.2999999999999, -149.49999999999997, -128.9999999999999, -125.90000000000023, -171.89999999999984, -444.69999999999993, -401.09999999999985, -160.49999999999994, -211.00000000000023, 115.60000000000011, -14.59999999999993, 64.50000000000027, 11.100000000000072, -152.20000000000005, -46.60000000000032, -330.69999999999993, 36.70000000000025, -21.699999999999605, -56.60000000000002, 5.900000000000139, 79.10000000000034, -280.10000000000014, 40.0000000000003, -108.89999999999999, 86.79999999999941, -60.09999999999988, -14.999999999999723, -259.4, 34.30000000000024, -26.29999999999992, 87.20000000000013, 18.49999999999996, 35.90000000000024, 33.1000000000002, 37.80000000000027, 63.40000000000051, -80.10000000000116, 61.40000000000052, 32.30000000000018, 117.79999999999994, 44.00000000000036, 4.09999999999993, 40.0000000000003, 58.10000000000047, 22.100000000000033, -266.1, 79.59999999999937, 51.10000000000048, 34.30000000000022, 44.90000000000041, 34.700000000000266, -25.599999999999767, 43.8000000000005, -0.7999999999998141, 34.40000000000022, 27.90000000000011, 64.3000000000005, -30.69999999999967, 23.600000000000037, -52.50000000000082, -6.59999999999985, 13.899999999999958, -18.99999999999963, 37.400000000000254, 0.8000000000001716, 31.00000000000017, -8.499999999999758, 9.499999999999998, 4.600000000000037, -28.99999999999961, 84.09999999999904, 37.50000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -1.300000000000003, 20.000000000000014, 14.299999999999967, -602.0, -236.50000000000003, 1.0999999999999972, 34.10000000000026, -261.8999999999999, -24.100000000000023, 20.000000000000014, 20.000000000000014, -21.099999999999973, -3.100000000000003, -16.899999999999743, -42.99999999999978, -464.4, -534.9, -59.79999999999979, -9.400000000000034, -121.60000000000053, -97.60000000000079, -133.29999999999984, -157.29999999999984, -19.900000000000023, -10.59999999999999, -638.4000000000001, -466.20000000000005, -435.2000000000001, -437.3999999999999, -15.699999999999747, -11.499999999999819, -11.500000000000007, -53.4999999999998, -45.100000000000044, -60.100000000000016, 17.60000000000001, 20.000000000000014, -545.0, 37.40000000000022, -406.49999999999994, -461.1, -131.20000000000002, -205.29999999999995, -84.99999999999994, -488.00000000000034, -443.7, 5.600000000000172, -1.0, 14.300000000000246, -595.8, -499.2, -380.2, -88.69999999999985, -85.30000000000001, -63.999999999999986, -134.8, -109.50000000000003, -500.3, -437.20000000000005, -251.49999999999986, -220.50000000000003, 20.000000000000014, -347.9000000000001, -255.2, -178.69999999999993, -587.0999999999999, -493.59999999999997, -454.40000000000003, -582.7, -76.89999999999986, -226.6000000000005, -524.8999999999994, -150.0999999999999, -702.1, -70.30000000000003, -19.899999999999764, -171.70000000000016, -549.6, -82.89999999999985, -390.90000000000003, -85.00000000000014, -301.4000000000002, -286.7999999999996, -36.699999999999775, -70.90000000000076, -692.0, -289.70000000000005, 13.699999999999967, 20.000000000000014, -28.599999999999767, -81.09999999999994, -400.9, -190.70000000000005, -45.09999999999976, 20.000000000000014, 20.000000000000014, -154.89999999999986, -183.00000000000009, -728.1, 20.000000000000014, 20.000000000000014, -764.7, -583.2, 17.900000000000013, -442.09999999999945, -67.00000000000014, -114.09999999999997, 29.000000000000167, -115.00000000000023, -467.4, -758.0, -214.49999999999997, 30.800000000000207, -494.3, 20.000000000000014, 26.600000000000122, -248.39999999999986, -23.49999999999975, 20.000000000000014, 3.1999999999999686, 7.699999999999971, 22.100000000000044, -0.9999999999999881, 20.000000000000014, 15.799999999999962, 43.40000000000025, 20.000000000000014, -116.80000000000067, -94.30000000000054, 37.70000000000025, 19.700000000000014, 11.599999999999966, 13.699999999999969, 15.499999999999966, -400.7, 5.299999999999965, 31.700000000000216, 35.30000000000024, -131.2000000000007, 20.000000000000014, 20.000000000000014, 47.90000000000023, -17.799999999999834, -40.89999999999977, 20.000000000000014, -429.8, -458.29999999999995, 43.40000000000023, 36.20000000000025, 20.000000000000014, 19.100000000000012, 8.299999999999965, 20.000000000000014, -101.80000000000004, 31.700000000000212, 20.000000000000014, -28.300000000000033, -3.099999999999972, -179.50000000000028, 20.90000000000003, 14.89999999999999, -120.70000000000076, 5.89999999999997, 4.399999999999968, 20.000000000000014, -3.099999999999958, 20.000000000000014, 41.60000000000025, 22.700000000000053, 20.000000000000014, -141.70000000000053, -0.40000000000002767, -0.9999999999999846, -47.19999999999977, -49.29999999999976, -7.8999999999998884, -204.7000000000004, -8.499999999999908, -13.599999999999804, -106.00000000000063, 20.000000000000014, 28.100000000000147, -12.699999999999829, -15.999999999999789, -26.199999999999747, -13.29999999999982, 26.300000000000118, -319.6999999999979, -32.799999999999756, -9.999999999999906, -11.499999999999822, 20.000000000000014, -57.40000000000029, -108.10000000000063, -31.89999999999977, 42.50000000000025, 41.60000000000023, 20.900000000000027, 11.599999999999964], "policy_predator_policy_reward": [0.0, 14.0, 10.0, 0.0, 320.0, 533.0, 0.0, 9.0, 46.0, 197.0, 0.0, 0.0, 0.0, 29.0, 29.0, 31.0, 230.0, 425.0, 18.0, 39.0, 0.0, 126.0, 118.0, 6.0, 0.0, 19.0, 0.0, 555.0, 483.0, 17.0, 17.0, 15.0, 35.0, 0.0, 47.0, 0.0, 0.0, 8.0, 477.0, 7.0, 366.0, 354.0, 56.0, 111.0, 278.0, 322.0, 0.0, 335.0, 10.0, 0.0, 71.0, 554.0, 132.0, 273.0, 52.0, 25.0, 132.0, 17.0, 337.0, 451.0, 209.0, 134.0, 6.0, 196.0, 148.0, 114.0, 0.0, 636.0, 547.0, 89.0, 122.0, 21.0, 0.0, 464.0, 439.0, 449.0, 110.0, 67.0, 420.0, 277.0, 323.0, 164.0, 305.0, 131.0, 6.0, 55.0, 626.0, 25.0, 3.0, 0.0, 57.0, 31.0, 343.0, 192.0, 31.0, 0.0, 84.0, 130.0, 0.0, 631.0, 0.0, 0.0, 541.0, 698.0, 238.0, 273.0, 101.0, 20.0, 65.0, 6.0, 325.0, 641.0, 93.0, 125.0, 393.0, 55.0, 178.0, 131.0, 22.0, 0.0, 14.0, 11.0, 3.0, 9.0, 0.0, 2.0, 0.0, 0.0, 45.0, 86.0, 0.0, 4.0, 5.0, 2.0, 258.0, 245.0, 7.0, 0.0, 55.0, 45.0, 0.0, 0.0, 11.0, 17.0, 23.0, 20.0, 230.0, 392.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 57.0, 58.0, 21.0, 22.0, 61.0, 96.0, 7.0, 1.0, 62.0, 52.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 76.0, 19.0, 6.0, 22.0, 22.0, 115.0, 91.0, 21.0, 15.0, 59.0, 8.0, 22.0, 0.0, 43.0, 0.0, 18.0, 0.0, 132.0, 212.0, 0.0, 31.0, 5.0, 37.0, 61.0, 50.0, 0.0, 0.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.232127007335535, "mean_inference_ms": 5.861562996925087, "mean_action_processing_ms": 0.8979209044092136, "mean_env_wait_ms": 0.7658082768685138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008509397506713867, "StateBufferConnector_ms": 0.003924012184143066, "ViewRequirementAgentConnector_ms": 0.2164137363433838}, "num_episodes": 18, "episode_return_max": 117.79999999999994, "episode_return_min": -549.6000000000001, "episode_return_mean": -44.42799999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.4304784171482, "num_env_steps_trained_throughput_per_sec": 244.4304784171482, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 17980.19, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17980.134, "sample_time_ms": 3981.452, "learn_time_ms": 13978.16, "learn_throughput": 286.161, "synch_weights_time_ms": 18.148}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "e57b0_00000", "date": "2024-08-13_00-16-51", "timestamp": 1723522611, "time_this_iter_s": 16.43543791770935, "time_total_s": 386.59154629707336, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b718b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 386.59154629707336, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 86.42608695652174, "ram_util_percent": 83.27391304347825}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8872189872912944, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5343659104670955, "policy_loss": -0.0015168946240067718, "vf_loss": 0.5351733733766846, "vf_explained_var": 0.06441492838834328, "kl": 0.008408074849840987, "entropy": 1.1748096105913637, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31757098049536425, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.30960067553573817, "policy_loss": -0.003222606689348896, "vf_loss": 0.3126105816187288, "vf_explained_var": 0.019455146726477083, "kl": 0.005672006126101138, "entropy": 1.2652947912140498, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 117.79999999999994, "episode_reward_min": -470.0, "episode_reward_mean": -21.99599999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -764.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000023, "predator_policy": 698.0}, "policy_reward_mean": {"prey_policy": -106.38799999999998, "predator_policy": 95.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.60000000000041, -23.599999999999827, -147.60000000000002, -169.49999999999986, 26.999999999999112, -103.09999999999988, 23.300000000000487, -470.0, -63.899999999999835, -72.29999999999966, -95.2999999999999, -149.49999999999997, -128.9999999999999, -125.90000000000023, -171.89999999999984, -444.69999999999993, -401.09999999999985, -160.49999999999994, -211.00000000000023, 115.60000000000011, -14.59999999999993, 64.50000000000027, 11.100000000000072, -152.20000000000005, -46.60000000000032, -330.69999999999993, 36.70000000000025, -21.699999999999605, -56.60000000000002, 5.900000000000139, 79.10000000000034, -280.10000000000014, 40.0000000000003, -108.89999999999999, 86.79999999999941, -60.09999999999988, -14.999999999999723, -259.4, 34.30000000000024, -26.29999999999992, 87.20000000000013, 18.49999999999996, 35.90000000000024, 33.1000000000002, 37.80000000000027, 63.40000000000051, -80.10000000000116, 61.40000000000052, 32.30000000000018, 117.79999999999994, 44.00000000000036, 4.09999999999993, 40.0000000000003, 58.10000000000047, 22.100000000000033, -266.1, 79.59999999999937, 51.10000000000048, 34.30000000000022, 44.90000000000041, 34.700000000000266, -25.599999999999767, 43.8000000000005, -0.7999999999998141, 34.40000000000022, 27.90000000000011, 64.3000000000005, -30.69999999999967, 23.600000000000037, -52.50000000000082, -6.59999999999985, 13.899999999999958, -18.99999999999963, 37.400000000000254, 0.8000000000001716, 31.00000000000017, -8.499999999999758, 9.499999999999998, 4.600000000000037, -28.99999999999961, 84.09999999999904, 37.50000000000026, 35.80000000000024, 20.399999999999995, 40.0000000000003, 48.800000000000445, 49.900000000000475, 40.0000000000003, 0.5000000000001219, 42.20000000000033, 42.70000000000034, 27.900000000000116, 51.70000000000047, 66.10000000000034, 35.00000000000022, 42.70000000000034, 40.0000000000003, 56.20000000000053, 32.40000000000022, 75.09999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.60000000000001, 20.000000000000014, -545.0, 37.40000000000022, -406.49999999999994, -461.1, -131.20000000000002, -205.29999999999995, -84.99999999999994, -488.00000000000034, -443.7, 5.600000000000172, -1.0, 14.300000000000246, -595.8, -499.2, -380.2, -88.69999999999985, -85.30000000000001, -63.999999999999986, -134.8, -109.50000000000003, -500.3, -437.20000000000005, -251.49999999999986, -220.50000000000003, 20.000000000000014, -347.9000000000001, -255.2, -178.69999999999993, -587.0999999999999, -493.59999999999997, -454.40000000000003, -582.7, -76.89999999999986, -226.6000000000005, -524.8999999999994, -150.0999999999999, -702.1, -70.30000000000003, -19.899999999999764, -171.70000000000016, -549.6, -82.89999999999985, -390.90000000000003, -85.00000000000014, -301.4000000000002, -286.7999999999996, -36.699999999999775, -70.90000000000076, -692.0, -289.70000000000005, 13.699999999999967, 20.000000000000014, -28.599999999999767, -81.09999999999994, -400.9, -190.70000000000005, -45.09999999999976, 20.000000000000014, 20.000000000000014, -154.89999999999986, -183.00000000000009, -728.1, 20.000000000000014, 20.000000000000014, -764.7, -583.2, 17.900000000000013, -442.09999999999945, -67.00000000000014, -114.09999999999997, 29.000000000000167, -115.00000000000023, -467.4, -758.0, -214.49999999999997, 30.800000000000207, -494.3, 20.000000000000014, 26.600000000000122, -248.39999999999986, -23.49999999999975, 20.000000000000014, 3.1999999999999686, 7.699999999999971, 22.100000000000044, -0.9999999999999881, 20.000000000000014, 15.799999999999962, 43.40000000000025, 20.000000000000014, -116.80000000000067, -94.30000000000054, 37.70000000000025, 19.700000000000014, 11.599999999999966, 13.699999999999969, 15.499999999999966, -400.7, 5.299999999999965, 31.700000000000216, 35.30000000000024, -131.2000000000007, 20.000000000000014, 20.000000000000014, 47.90000000000023, -17.799999999999834, -40.89999999999977, 20.000000000000014, -429.8, -458.29999999999995, 43.40000000000023, 36.20000000000025, 20.000000000000014, 19.100000000000012, 8.299999999999965, 20.000000000000014, -101.80000000000004, 31.700000000000212, 20.000000000000014, -28.300000000000033, -3.099999999999972, -179.50000000000028, 20.90000000000003, 14.89999999999999, -120.70000000000076, 5.89999999999997, 4.399999999999968, 20.000000000000014, -3.099999999999958, 20.000000000000014, 41.60000000000025, 22.700000000000053, 20.000000000000014, -141.70000000000053, -0.40000000000002767, -0.9999999999999846, -47.19999999999977, -49.29999999999976, -7.8999999999998884, -204.7000000000004, -8.499999999999908, -13.599999999999804, -106.00000000000063, 20.000000000000014, 28.100000000000147, -12.699999999999829, -15.999999999999789, -26.199999999999747, -13.29999999999982, 26.300000000000118, -319.6999999999979, -32.799999999999756, -9.999999999999906, -11.499999999999822, 20.000000000000014, -57.40000000000029, -108.10000000000063, -31.89999999999977, 42.50000000000025, 41.60000000000023, 20.900000000000027, 11.599999999999964, 20.000000000000014, -5.1999999999999265, -16.29999999999977, 10.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.800000000000143, 39.80000000000024, 1.0999999999999635, 20.000000000000014, 20.000000000000014, -56.80000000000024, 11.299999999999985, 20.000000000000014, 15.199999999999964, 20.000000000000014, 22.700000000000053, 20.000000000000014, -12.099999999999831, 20.000000000000014, 31.70000000000022, 20.000000000000014, 46.10000000000023, -9.999999999999867, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 24.50000000000008, 31.700000000000212, -19.899999999999785, 32.300000000000225, 38.900000000000254, 36.20000000000026], "policy_predator_policy_reward": [0.0, 8.0, 477.0, 7.0, 366.0, 354.0, 56.0, 111.0, 278.0, 322.0, 0.0, 335.0, 10.0, 0.0, 71.0, 554.0, 132.0, 273.0, 52.0, 25.0, 132.0, 17.0, 337.0, 451.0, 209.0, 134.0, 6.0, 196.0, 148.0, 114.0, 0.0, 636.0, 547.0, 89.0, 122.0, 21.0, 0.0, 464.0, 439.0, 449.0, 110.0, 67.0, 420.0, 277.0, 323.0, 164.0, 305.0, 131.0, 6.0, 55.0, 626.0, 25.0, 3.0, 0.0, 57.0, 31.0, 343.0, 192.0, 31.0, 0.0, 84.0, 130.0, 0.0, 631.0, 0.0, 0.0, 541.0, 698.0, 238.0, 273.0, 101.0, 20.0, 65.0, 6.0, 325.0, 641.0, 93.0, 125.0, 393.0, 55.0, 178.0, 131.0, 22.0, 0.0, 14.0, 11.0, 3.0, 9.0, 0.0, 2.0, 0.0, 0.0, 45.0, 86.0, 0.0, 4.0, 5.0, 2.0, 258.0, 245.0, 7.0, 0.0, 55.0, 45.0, 0.0, 0.0, 11.0, 17.0, 23.0, 20.0, 230.0, 392.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 57.0, 58.0, 21.0, 22.0, 61.0, 96.0, 7.0, 1.0, 62.0, 52.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 76.0, 19.0, 6.0, 22.0, 22.0, 115.0, 91.0, 21.0, 15.0, 59.0, 8.0, 22.0, 0.0, 43.0, 0.0, 18.0, 0.0, 132.0, 212.0, 0.0, 31.0, 5.0, 37.0, 61.0, 50.0, 0.0, 0.0, 3.0, 2.0, 12.0, 9.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 34.0, 12.0, 0.0, 7.0, 0.0, 0.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.198998160177139, "mean_inference_ms": 5.768186358959706, "mean_action_processing_ms": 0.883957834658053, "mean_env_wait_ms": 0.7526405966891755, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0085601806640625, "StateBufferConnector_ms": 0.003789067268371582, "ViewRequirementAgentConnector_ms": 0.18760919570922852}, "num_episodes": 18, "episode_return_max": 117.79999999999994, "episode_return_min": -470.0, "episode_return_mean": -21.99599999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 226.44776502969145, "num_env_steps_trained_throughput_per_sec": 226.44776502969145, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 18036.263, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18036.207, "sample_time_ms": 3913.517, "learn_time_ms": 14098.45, "learn_throughput": 283.719, "synch_weights_time_ms": 21.911}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "e57b0_00000", "date": "2024-08-13_00-17-09", "timestamp": 1723522629, "time_this_iter_s": 17.736183166503906, "time_total_s": 404.32772946357727, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b094ae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 404.32772946357727, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 87.92399999999998, "ram_util_percent": 81.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8777885149237971, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9669720127804097, "policy_loss": -0.0028900714384184943, "vf_loss": 0.968756948829328, "vf_explained_var": 0.013633183985160141, "kl": 0.013097896707792388, "entropy": 1.239534053474507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30433630217950813, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5748954068889063, "policy_loss": -0.003954170242434851, "vf_loss": 0.5783479350070203, "vf_explained_var": 0.00011045169578027473, "kl": 0.013377074044647237, "entropy": 1.2839143183496264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 117.79999999999994, "episode_reward_min": -330.69999999999993, "episode_reward_mean": 12.321000000000174, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -764.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000023, "predator_policy": 698.0}, "policy_reward_mean": {"prey_policy": -57.09949999999997, "predator_policy": 63.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-211.00000000000023, 115.60000000000011, -14.59999999999993, 64.50000000000027, 11.100000000000072, -152.20000000000005, -46.60000000000032, -330.69999999999993, 36.70000000000025, -21.699999999999605, -56.60000000000002, 5.900000000000139, 79.10000000000034, -280.10000000000014, 40.0000000000003, -108.89999999999999, 86.79999999999941, -60.09999999999988, -14.999999999999723, -259.4, 34.30000000000024, -26.29999999999992, 87.20000000000013, 18.49999999999996, 35.90000000000024, 33.1000000000002, 37.80000000000027, 63.40000000000051, -80.10000000000116, 61.40000000000052, 32.30000000000018, 117.79999999999994, 44.00000000000036, 4.09999999999993, 40.0000000000003, 58.10000000000047, 22.100000000000033, -266.1, 79.59999999999937, 51.10000000000048, 34.30000000000022, 44.90000000000041, 34.700000000000266, -25.599999999999767, 43.8000000000005, -0.7999999999998141, 34.40000000000022, 27.90000000000011, 64.3000000000005, -30.69999999999967, 23.600000000000037, -52.50000000000082, -6.59999999999985, 13.899999999999958, -18.99999999999963, 37.400000000000254, 0.8000000000001716, 31.00000000000017, -8.499999999999758, 9.499999999999998, 4.600000000000037, -28.99999999999961, 84.09999999999904, 37.50000000000026, 35.80000000000024, 20.399999999999995, 40.0000000000003, 48.800000000000445, 49.900000000000475, 40.0000000000003, 0.5000000000001219, 42.20000000000033, 42.70000000000034, 27.900000000000116, 51.70000000000047, 66.10000000000034, 35.00000000000022, 42.70000000000034, 40.0000000000003, 56.20000000000053, 32.40000000000022, 75.09999999999972, 38.90000000000028, 35.70000000000024, 33.400000000000205, 59.80000000000046, 61.000000000000504, 25.500000000000078, 59.8000000000005, 29.50000000000014, 29.400000000000148, 50.800000000000495, 24.600000000000072, 52.5000000000005, 44.300000000000374, 35.600000000000236, 40.5000000000003, 54.40000000000049, 60.1000000000005, 63.900000000000496], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-524.8999999999994, -150.0999999999999, -702.1, -70.30000000000003, -19.899999999999764, -171.70000000000016, -549.6, -82.89999999999985, -390.90000000000003, -85.00000000000014, -301.4000000000002, -286.7999999999996, -36.699999999999775, -70.90000000000076, -692.0, -289.70000000000005, 13.699999999999967, 20.000000000000014, -28.599999999999767, -81.09999999999994, -400.9, -190.70000000000005, -45.09999999999976, 20.000000000000014, 20.000000000000014, -154.89999999999986, -183.00000000000009, -728.1, 20.000000000000014, 20.000000000000014, -764.7, -583.2, 17.900000000000013, -442.09999999999945, -67.00000000000014, -114.09999999999997, 29.000000000000167, -115.00000000000023, -467.4, -758.0, -214.49999999999997, 30.800000000000207, -494.3, 20.000000000000014, 26.600000000000122, -248.39999999999986, -23.49999999999975, 20.000000000000014, 3.1999999999999686, 7.699999999999971, 22.100000000000044, -0.9999999999999881, 20.000000000000014, 15.799999999999962, 43.40000000000025, 20.000000000000014, -116.80000000000067, -94.30000000000054, 37.70000000000025, 19.700000000000014, 11.599999999999966, 13.699999999999969, 15.499999999999966, -400.7, 5.299999999999965, 31.700000000000216, 35.30000000000024, -131.2000000000007, 20.000000000000014, 20.000000000000014, 47.90000000000023, -17.799999999999834, -40.89999999999977, 20.000000000000014, -429.8, -458.29999999999995, 43.40000000000023, 36.20000000000025, 20.000000000000014, 19.100000000000012, 8.299999999999965, 20.000000000000014, -101.80000000000004, 31.700000000000212, 20.000000000000014, -28.300000000000033, -3.099999999999972, -179.50000000000028, 20.90000000000003, 14.89999999999999, -120.70000000000076, 5.89999999999997, 4.399999999999968, 20.000000000000014, -3.099999999999958, 20.000000000000014, 41.60000000000025, 22.700000000000053, 20.000000000000014, -141.70000000000053, -0.40000000000002767, -0.9999999999999846, -47.19999999999977, -49.29999999999976, -7.8999999999998884, -204.7000000000004, -8.499999999999908, -13.599999999999804, -106.00000000000063, 20.000000000000014, 28.100000000000147, -12.699999999999829, -15.999999999999789, -26.199999999999747, -13.29999999999982, 26.300000000000118, -319.6999999999979, -32.799999999999756, -9.999999999999906, -11.499999999999822, 20.000000000000014, -57.40000000000029, -108.10000000000063, -31.89999999999977, 42.50000000000025, 41.60000000000023, 20.900000000000027, 11.599999999999964, 20.000000000000014, -5.1999999999999265, -16.29999999999977, 10.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.800000000000143, 39.80000000000024, 1.0999999999999635, 20.000000000000014, 20.000000000000014, -56.80000000000024, 11.299999999999985, 20.000000000000014, 15.199999999999964, 20.000000000000014, 22.700000000000053, 20.000000000000014, -12.099999999999831, 20.000000000000014, 31.70000000000022, 20.000000000000014, 46.10000000000023, -9.999999999999867, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 24.50000000000008, 31.700000000000212, -19.899999999999785, 32.300000000000225, 38.900000000000254, 36.20000000000026, 17.899999999999988, 20.000000000000014, 24.50000000000008, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 20.000000000000014, 39.800000000000225, 42.50000000000025, 15.499999999999964, -32.49999999999978, 26.000000000000124, 39.800000000000246, 20.000000000000014, 20.000000000000014, -2.500000000000011, -47.19999999999976, 41.60000000000023, 17.899999999999988, 23.900000000000084, 9.499999999999964, 1.099999999999967, 27.500000000000142, 20.000000000000014, 20.000000000000014, 14.299999999999969, 20.000000000000014, 11.599999999999971, 20.000000000000014, 18.499999999999996, 20.000000000000014, 34.40000000000024, 32.300000000000225, 15.79999999999996, 43.40000000000025, 9.499999999999973], "policy_predator_policy_reward": [0.0, 464.0, 439.0, 449.0, 110.0, 67.0, 420.0, 277.0, 323.0, 164.0, 305.0, 131.0, 6.0, 55.0, 626.0, 25.0, 3.0, 0.0, 57.0, 31.0, 343.0, 192.0, 31.0, 0.0, 84.0, 130.0, 0.0, 631.0, 0.0, 0.0, 541.0, 698.0, 238.0, 273.0, 101.0, 20.0, 65.0, 6.0, 325.0, 641.0, 93.0, 125.0, 393.0, 55.0, 178.0, 131.0, 22.0, 0.0, 14.0, 11.0, 3.0, 9.0, 0.0, 2.0, 0.0, 0.0, 45.0, 86.0, 0.0, 4.0, 5.0, 2.0, 258.0, 245.0, 7.0, 0.0, 55.0, 45.0, 0.0, 0.0, 11.0, 17.0, 23.0, 20.0, 230.0, 392.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 57.0, 58.0, 21.0, 22.0, 61.0, 96.0, 7.0, 1.0, 62.0, 52.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 76.0, 19.0, 6.0, 22.0, 22.0, 115.0, 91.0, 21.0, 15.0, 59.0, 8.0, 22.0, 0.0, 43.0, 0.0, 18.0, 0.0, 132.0, 212.0, 0.0, 31.0, 5.0, 37.0, 61.0, 50.0, 0.0, 0.0, 3.0, 2.0, 12.0, 9.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 34.0, 12.0, 0.0, 7.0, 0.0, 0.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 3.0, 0.0, 17.0, 15.0, 0.0, 0.0, 12.0, 0.0, 21.0, 14.0, 0.0, 9.0, 0.0, 14.0, 0.0, 5.0, 0.0, 10.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1707056820323443, "mean_inference_ms": 5.687628938769354, "mean_action_processing_ms": 0.8714516180433387, "mean_env_wait_ms": 0.7413610273799262, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008600234985351562, "StateBufferConnector_ms": 0.0038346052169799805, "ViewRequirementAgentConnector_ms": 0.1942688226699829}, "num_episodes": 18, "episode_return_max": 117.79999999999994, "episode_return_min": -330.69999999999993, "episode_return_mean": 12.321000000000174, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 279.80823251032604, "num_env_steps_trained_throughput_per_sec": 279.80823251032604, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 17812.458, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17812.402, "sample_time_ms": 3890.582, "learn_time_ms": 13897.02, "learn_throughput": 287.831, "synch_weights_time_ms": 21.957}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "e57b0_00000", "date": "2024-08-13_00-17-23", "timestamp": 1723522643, "time_this_iter_s": 14.364490032196045, "time_total_s": 418.6922194957733, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b3bd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 418.6922194957733, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 79.08571428571429, "ram_util_percent": 80.50000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9933430040008807, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.785151216099975, "policy_loss": -0.0024632798685204414, "vf_loss": 0.7865447905249696, "vf_explained_var": -0.04111979124407289, "kl": 0.012678026788569783, "entropy": 1.2697616259256999, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3594518372660907, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5634922700584251, "policy_loss": -0.0030837887277205783, "vf_loss": 0.566222950371682, "vf_explained_var": 0.013702103353682018, "kl": 0.009416261259375738, "entropy": 1.325476208376506, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 117.79999999999994, "episode_reward_min": -266.1, "episode_reward_mean": 29.976000000000223, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -458.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000023, "predator_policy": 392.0}, "policy_reward_mean": {"prey_policy": -4.156999999999943, "predator_policy": 19.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [63.40000000000051, -80.10000000000116, 61.40000000000052, 32.30000000000018, 117.79999999999994, 44.00000000000036, 4.09999999999993, 40.0000000000003, 58.10000000000047, 22.100000000000033, -266.1, 79.59999999999937, 51.10000000000048, 34.30000000000022, 44.90000000000041, 34.700000000000266, -25.599999999999767, 43.8000000000005, -0.7999999999998141, 34.40000000000022, 27.90000000000011, 64.3000000000005, -30.69999999999967, 23.600000000000037, -52.50000000000082, -6.59999999999985, 13.899999999999958, -18.99999999999963, 37.400000000000254, 0.8000000000001716, 31.00000000000017, -8.499999999999758, 9.499999999999998, 4.600000000000037, -28.99999999999961, 84.09999999999904, 37.50000000000026, 35.80000000000024, 20.399999999999995, 40.0000000000003, 48.800000000000445, 49.900000000000475, 40.0000000000003, 0.5000000000001219, 42.20000000000033, 42.70000000000034, 27.900000000000116, 51.70000000000047, 66.10000000000034, 35.00000000000022, 42.70000000000034, 40.0000000000003, 56.20000000000053, 32.40000000000022, 75.09999999999972, 38.90000000000028, 35.70000000000024, 33.400000000000205, 59.80000000000046, 61.000000000000504, 25.500000000000078, 59.8000000000005, 29.50000000000014, 29.400000000000148, 50.800000000000495, 24.600000000000072, 52.5000000000005, 44.300000000000374, 35.600000000000236, 40.5000000000003, 54.40000000000049, 60.1000000000005, 63.900000000000496, 50.80000000000048, 44.500000000000384, 36.900000000000254, 5.400000000000148, 31.400000000000194, 40.0000000000003, 64.30000000000048, 44.50000000000038, 14.799999999999924, 59.50000000000045, 54.200000000000514, 40.0000000000003, 34.00000000000024, 8.50000000000008, 32.600000000000186, -26.799999999999592, 12.69999999999994, 35.90000000000024, 35.00000000000022, -0.699999999999807, 25.600000000000076, 64.90000000000038, 45.20000000000038, 40.0000000000003, -9.899999999999604, 21.2, 64.30000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [43.40000000000025, 20.000000000000014, -116.80000000000067, -94.30000000000054, 37.70000000000025, 19.700000000000014, 11.599999999999966, 13.699999999999969, 15.499999999999966, -400.7, 5.299999999999965, 31.700000000000216, 35.30000000000024, -131.2000000000007, 20.000000000000014, 20.000000000000014, 47.90000000000023, -17.799999999999834, -40.89999999999977, 20.000000000000014, -429.8, -458.29999999999995, 43.40000000000023, 36.20000000000025, 20.000000000000014, 19.100000000000012, 8.299999999999965, 20.000000000000014, -101.80000000000004, 31.700000000000212, 20.000000000000014, -28.300000000000033, -3.099999999999972, -179.50000000000028, 20.90000000000003, 14.89999999999999, -120.70000000000076, 5.89999999999997, 4.399999999999968, 20.000000000000014, -3.099999999999958, 20.000000000000014, 41.60000000000025, 22.700000000000053, 20.000000000000014, -141.70000000000053, -0.40000000000002767, -0.9999999999999846, -47.19999999999977, -49.29999999999976, -7.8999999999998884, -204.7000000000004, -8.499999999999908, -13.599999999999804, -106.00000000000063, 20.000000000000014, 28.100000000000147, -12.699999999999829, -15.999999999999789, -26.199999999999747, -13.29999999999982, 26.300000000000118, -319.6999999999979, -32.799999999999756, -9.999999999999906, -11.499999999999822, 20.000000000000014, -57.40000000000029, -108.10000000000063, -31.89999999999977, 42.50000000000025, 41.60000000000023, 20.900000000000027, 11.599999999999964, 20.000000000000014, -5.1999999999999265, -16.29999999999977, 10.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.800000000000143, 39.80000000000024, 1.0999999999999635, 20.000000000000014, 20.000000000000014, -56.80000000000024, 11.299999999999985, 20.000000000000014, 15.199999999999964, 20.000000000000014, 22.700000000000053, 20.000000000000014, -12.099999999999831, 20.000000000000014, 31.70000000000022, 20.000000000000014, 46.10000000000023, -9.999999999999867, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 24.50000000000008, 31.700000000000212, -19.899999999999785, 32.300000000000225, 38.900000000000254, 36.20000000000026, 17.899999999999988, 20.000000000000014, 24.50000000000008, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 20.000000000000014, 39.800000000000225, 42.50000000000025, 15.499999999999964, -32.49999999999978, 26.000000000000124, 39.800000000000246, 20.000000000000014, 20.000000000000014, -2.500000000000011, -47.19999999999976, 41.60000000000023, 17.899999999999988, 23.900000000000084, 9.499999999999964, 1.099999999999967, 27.500000000000142, 20.000000000000014, 20.000000000000014, 14.299999999999969, 20.000000000000014, 11.599999999999971, 20.000000000000014, 18.499999999999996, 20.000000000000014, 34.40000000000024, 32.300000000000225, 15.79999999999996, 43.40000000000025, 9.499999999999973, 20.000000000000014, 30.800000000000203, 20.000000000000014, 15.499999999999961, 20.000000000000014, 5.89999999999997, -10.599999999999854, -9.999999999999853, 11.59999999999998, -5.199999999999937, 20.000000000000014, 20.000000000000014, 44.300000000000246, 20.000000000000014, 14.599999999999966, 23.900000000000077, -17.79999999999977, -3.4000000000000012, 7.399999999999965, 46.10000000000022, 20.000000000000014, 33.20000000000024, 20.000000000000014, 20.000000000000014, 37.10000000000026, -24.09999999999978, 22.700000000000053, -47.19999999999976, -9.399999999999883, 20.000000000000014, -50.5999999999998, -47.1999999999998, -15.39999999999982, -10.899999999999864, 7.699999999999971, 15.19999999999996, 20.000000000000014, -1.0000000000000204, -76.60000000000086, 29.90000000000018, 20.000000000000014, -30.39999999999975, 42.50000000000025, 7.399999999999999, 20.000000000000014, 24.200000000000077, 20.000000000000014, 20.000000000000014, -19.899999999999743, -18.999999999999744, 20.000000000000014, -20.799999999999756, 42.50000000000024, 21.80000000000004], "policy_predator_policy_reward": [0.0, 0.0, 45.0, 86.0, 0.0, 4.0, 5.0, 2.0, 258.0, 245.0, 7.0, 0.0, 55.0, 45.0, 0.0, 0.0, 11.0, 17.0, 23.0, 20.0, 230.0, 392.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 57.0, 58.0, 21.0, 22.0, 61.0, 96.0, 7.0, 1.0, 62.0, 52.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 76.0, 19.0, 6.0, 22.0, 22.0, 115.0, 91.0, 21.0, 15.0, 59.0, 8.0, 22.0, 0.0, 43.0, 0.0, 18.0, 0.0, 132.0, 212.0, 0.0, 31.0, 5.0, 37.0, 61.0, 50.0, 0.0, 0.0, 3.0, 2.0, 12.0, 9.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 34.0, 12.0, 0.0, 7.0, 0.0, 0.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 3.0, 0.0, 17.0, 15.0, 0.0, 0.0, 12.0, 0.0, 21.0, 14.0, 0.0, 9.0, 0.0, 14.0, 0.0, 5.0, 0.0, 10.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 26.0, 13.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 15.0, 21.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 21.0, 17.0, 16.0, 15.0, 7.0, 58.0, 13.0, 0.0, 39.0, 0.0, 13.0, 0.0, 16.0, 46.0, 0.0, 23.0, 13.0, 15.0, 0.0, 0.0, 1.0, 0.0, 0.0, 15.0, 14.0, 0.0, 22.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.107762506765128, "mean_inference_ms": 5.510857046112147, "mean_action_processing_ms": 0.8464967795792709, "mean_env_wait_ms": 0.7184988760891392, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006505012512207031, "StateBufferConnector_ms": 0.004793763160705566, "ViewRequirementAgentConnector_ms": 0.15877127647399902}, "num_episodes": 27, "episode_return_max": 117.79999999999994, "episode_return_min": -266.1, "episode_return_mean": 29.976000000000223, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.4694946443174, "num_env_steps_trained_throughput_per_sec": 316.4694946443174, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 17263.551, "restore_workers_time_ms": 0.02, "training_step_time_ms": 17263.488, "sample_time_ms": 3812.982, "learn_time_ms": 13424.84, "learn_throughput": 297.955, "synch_weights_time_ms": 22.305}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "e57b0_00000", "date": "2024-08-13_00-17-36", "timestamp": 1723522656, "time_this_iter_s": 12.742987155914307, "time_total_s": 431.4352066516876, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b3b430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 431.4352066516876, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 70.5111111111111, "ram_util_percent": 83.13888888888887}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9089990934366903, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1724152160226984, "policy_loss": -0.0049072092179721465, "vf_loss": 1.1759990729509837, "vf_explained_var": 0.00015952530361357188, "kl": 0.015684167879098872, "entropy": 1.2953219315993092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35510014772572845, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7685100559046659, "policy_loss": -0.002691345450483144, "vf_loss": 0.7708648596525626, "vf_explained_var": 0.007838452871514376, "kl": 0.008974431233712252, "entropy": 1.2821388635685835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 84.09999999999904, "episode_reward_min": -52.50000000000082, "episode_reward_mean": 31.328000000000245, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.6999999999979, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.10000000000023, "predator_policy": 212.0}, "policy_reward_mean": {"prey_policy": 3.7540000000000657, "predator_policy": 11.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.7999999999998141, 34.40000000000022, 27.90000000000011, 64.3000000000005, -30.69999999999967, 23.600000000000037, -52.50000000000082, -6.59999999999985, 13.899999999999958, -18.99999999999963, 37.400000000000254, 0.8000000000001716, 31.00000000000017, -8.499999999999758, 9.499999999999998, 4.600000000000037, -28.99999999999961, 84.09999999999904, 37.50000000000026, 35.80000000000024, 20.399999999999995, 40.0000000000003, 48.800000000000445, 49.900000000000475, 40.0000000000003, 0.5000000000001219, 42.20000000000033, 42.70000000000034, 27.900000000000116, 51.70000000000047, 66.10000000000034, 35.00000000000022, 42.70000000000034, 40.0000000000003, 56.20000000000053, 32.40000000000022, 75.09999999999972, 38.90000000000028, 35.70000000000024, 33.400000000000205, 59.80000000000046, 61.000000000000504, 25.500000000000078, 59.8000000000005, 29.50000000000014, 29.400000000000148, 50.800000000000495, 24.600000000000072, 52.5000000000005, 44.300000000000374, 35.600000000000236, 40.5000000000003, 54.40000000000049, 60.1000000000005, 63.900000000000496, 50.80000000000048, 44.500000000000384, 36.900000000000254, 5.400000000000148, 31.400000000000194, 40.0000000000003, 64.30000000000048, 44.50000000000038, 14.799999999999924, 59.50000000000045, 54.200000000000514, 40.0000000000003, 34.00000000000024, 8.50000000000008, 32.600000000000186, -26.799999999999592, 12.69999999999994, 35.90000000000024, 35.00000000000022, -0.699999999999807, 25.600000000000076, 64.90000000000038, 45.20000000000038, 40.0000000000003, -9.899999999999604, 21.2, 64.30000000000047, 40.0000000000003, 68.20000000000014, 38.90000000000028, 3.7000000000001383, 40.0000000000003, 37.80000000000027, 44.50000000000037, -8.199999999999674, 17.59999999999994, 22.30000000000003, 34.900000000000226, 40.0000000000003, 5.900000000000135, 10.099999999999941, -26.399999999999558, 34.50000000000027, 58.50000000000044, 32.700000000000195], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-120.70000000000076, 5.89999999999997, 4.399999999999968, 20.000000000000014, -3.099999999999958, 20.000000000000014, 41.60000000000025, 22.700000000000053, 20.000000000000014, -141.70000000000053, -0.40000000000002767, -0.9999999999999846, -47.19999999999977, -49.29999999999976, -7.8999999999998884, -204.7000000000004, -8.499999999999908, -13.599999999999804, -106.00000000000063, 20.000000000000014, 28.100000000000147, -12.699999999999829, -15.999999999999789, -26.199999999999747, -13.29999999999982, 26.300000000000118, -319.6999999999979, -32.799999999999756, -9.999999999999906, -11.499999999999822, 20.000000000000014, -57.40000000000029, -108.10000000000063, -31.89999999999977, 42.50000000000025, 41.60000000000023, 20.900000000000027, 11.599999999999964, 20.000000000000014, -5.1999999999999265, -16.29999999999977, 10.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.800000000000143, 39.80000000000024, 1.0999999999999635, 20.000000000000014, 20.000000000000014, -56.80000000000024, 11.299999999999985, 20.000000000000014, 15.199999999999964, 20.000000000000014, 22.700000000000053, 20.000000000000014, -12.099999999999831, 20.000000000000014, 31.70000000000022, 20.000000000000014, 46.10000000000023, -9.999999999999867, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 24.50000000000008, 31.700000000000212, -19.899999999999785, 32.300000000000225, 38.900000000000254, 36.20000000000026, 17.899999999999988, 20.000000000000014, 24.50000000000008, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 20.000000000000014, 39.800000000000225, 42.50000000000025, 15.499999999999964, -32.49999999999978, 26.000000000000124, 39.800000000000246, 20.000000000000014, 20.000000000000014, -2.500000000000011, -47.19999999999976, 41.60000000000023, 17.899999999999988, 23.900000000000084, 9.499999999999964, 1.099999999999967, 27.500000000000142, 20.000000000000014, 20.000000000000014, 14.299999999999969, 20.000000000000014, 11.599999999999971, 20.000000000000014, 18.499999999999996, 20.000000000000014, 34.40000000000024, 32.300000000000225, 15.79999999999996, 43.40000000000025, 9.499999999999973, 20.000000000000014, 30.800000000000203, 20.000000000000014, 15.499999999999961, 20.000000000000014, 5.89999999999997, -10.599999999999854, -9.999999999999853, 11.59999999999998, -5.199999999999937, 20.000000000000014, 20.000000000000014, 44.300000000000246, 20.000000000000014, 14.599999999999966, 23.900000000000077, -17.79999999999977, -3.4000000000000012, 7.399999999999965, 46.10000000000022, 20.000000000000014, 33.20000000000024, 20.000000000000014, 20.000000000000014, 37.10000000000026, -24.09999999999978, 22.700000000000053, -47.19999999999976, -9.399999999999883, 20.000000000000014, -50.5999999999998, -47.1999999999998, -15.39999999999982, -10.899999999999864, 7.699999999999971, 15.19999999999996, 20.000000000000014, -1.0000000000000204, -76.60000000000086, 29.90000000000018, 20.000000000000014, -30.39999999999975, 42.50000000000025, 7.399999999999999, 20.000000000000014, 24.200000000000077, 20.000000000000014, 20.000000000000014, -19.899999999999743, -18.999999999999744, 20.000000000000014, -20.799999999999756, 42.50000000000024, 21.80000000000004, 20.000000000000014, 20.000000000000014, 45.2000000000002, 20.000000000000014, 20.000000000000014, 8.899999999999977, -49.299999999999834, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 24.50000000000008, -19.89999999999977, -28.29999999999977, -45.09999999999976, 31.70000000000022, -27.699999999999783, 20.000000000000014, 17.899999999999988, 4.99999999999997, 20.000000000000014, 20.000000000000014, -9.39999999999988, -15.699999999999747, -15.39999999999977, -14.499999999999837, -110.20000000000076, 21.80000000000004, -7.299999999999947, 18.8, 20.000000000000014, 27.50000000000015, 1.6999999999999729, 20.000000000000014], "policy_predator_policy_reward": [62.0, 52.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 76.0, 19.0, 6.0, 22.0, 22.0, 115.0, 91.0, 21.0, 15.0, 59.0, 8.0, 22.0, 0.0, 43.0, 0.0, 18.0, 0.0, 132.0, 212.0, 0.0, 31.0, 5.0, 37.0, 61.0, 50.0, 0.0, 0.0, 3.0, 2.0, 12.0, 9.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 34.0, 12.0, 0.0, 7.0, 0.0, 0.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 3.0, 0.0, 17.0, 15.0, 0.0, 0.0, 12.0, 0.0, 21.0, 14.0, 0.0, 9.0, 0.0, 14.0, 0.0, 5.0, 0.0, 10.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 26.0, 13.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 15.0, 21.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 21.0, 17.0, 16.0, 15.0, 7.0, 58.0, 13.0, 0.0, 39.0, 0.0, 13.0, 0.0, 16.0, 46.0, 0.0, 23.0, 13.0, 15.0, 0.0, 0.0, 1.0, 0.0, 0.0, 15.0, 14.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 10.0, 0.0, 33.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 27.0, 13.0, 31.0, 0.0, 16.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 40.0, 47.0, 15.0, 0.0, 23.0, 11.0, 0.0, 4.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0621929480436454, "mean_inference_ms": 5.390232234681163, "mean_action_processing_ms": 0.8271325054459595, "mean_env_wait_ms": 0.7020481325517106, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006783008575439453, "StateBufferConnector_ms": 0.004280209541320801, "ViewRequirementAgentConnector_ms": 0.1619786024093628}, "num_episodes": 18, "episode_return_max": 84.09999999999904, "episode_return_min": -52.50000000000082, "episode_return_mean": 31.328000000000245, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.1759499418205, "num_env_steps_trained_throughput_per_sec": 305.1759499418205, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 16500.152, "restore_workers_time_ms": 0.019, "training_step_time_ms": 16500.087, "sample_time_ms": 3477.08, "learn_time_ms": 12997.041, "learn_throughput": 307.762, "synch_weights_time_ms": 22.021}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "e57b0_00000", "date": "2024-08-13_00-17-49", "timestamp": 1723522669, "time_this_iter_s": 13.165593147277832, "time_total_s": 444.60079979896545, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b41940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 444.60079979896545, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 73.78421052631579, "ram_util_percent": 83.31578947368422}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0689641617199102, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8718747541071876, "policy_loss": -0.00036051279505488104, "vf_loss": 1.871761157178374, "vf_explained_var": 0.00044038983249159716, "kl": 0.0056190764446807755, "entropy": 1.3131006324732746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4318596062403192, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.001028781135877, "policy_loss": -0.006108844252155413, "vf_loss": 1.0063561593098616, "vf_explained_var": 0.002294314727581367, "kl": 0.020839064089333323, "entropy": 1.2596414432954537, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 75.09999999999972, "episode_reward_min": -127.30000000000007, "episode_reward_mean": 35.57100000000028, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -191.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.10000000000023, "predator_policy": 140.0}, "policy_reward_mean": {"prey_policy": 10.13550000000007, "predator_policy": 7.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.50000000000026, 35.80000000000024, 20.399999999999995, 40.0000000000003, 48.800000000000445, 49.900000000000475, 40.0000000000003, 0.5000000000001219, 42.20000000000033, 42.70000000000034, 27.900000000000116, 51.70000000000047, 66.10000000000034, 35.00000000000022, 42.70000000000034, 40.0000000000003, 56.20000000000053, 32.40000000000022, 75.09999999999972, 38.90000000000028, 35.70000000000024, 33.400000000000205, 59.80000000000046, 61.000000000000504, 25.500000000000078, 59.8000000000005, 29.50000000000014, 29.400000000000148, 50.800000000000495, 24.600000000000072, 52.5000000000005, 44.300000000000374, 35.600000000000236, 40.5000000000003, 54.40000000000049, 60.1000000000005, 63.900000000000496, 50.80000000000048, 44.500000000000384, 36.900000000000254, 5.400000000000148, 31.400000000000194, 40.0000000000003, 64.30000000000048, 44.50000000000038, 14.799999999999924, 59.50000000000045, 54.200000000000514, 40.0000000000003, 34.00000000000024, 8.50000000000008, 32.600000000000186, -26.799999999999592, 12.69999999999994, 35.90000000000024, 35.00000000000022, -0.699999999999807, 25.600000000000076, 64.90000000000038, 45.20000000000038, 40.0000000000003, -9.899999999999604, 21.2, 64.30000000000047, 40.0000000000003, 68.20000000000014, 38.90000000000028, 3.7000000000001383, 40.0000000000003, 37.80000000000027, 44.50000000000037, -8.199999999999674, 17.59999999999994, 22.30000000000003, 34.900000000000226, 40.0000000000003, 5.900000000000135, 10.099999999999941, -26.399999999999558, 34.50000000000027, 58.50000000000044, 32.700000000000195, 58.00000000000051, 54.80000000000049, -127.30000000000007, 46.90000000000042, 54.6000000000005, 62.500000000000476, -5.899999999999704, 52.20000000000051, 70.60000000000001, 55.50000000000045, 26.500000000000103, 54.20000000000047, 31.60000000000018, 34.50000000000027, 46.300000000000395, 25.600000000000197, 59.80000000000052, 8.299999999999928], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.900000000000027, 11.599999999999964, 20.000000000000014, -5.1999999999999265, -16.29999999999977, 10.699999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.800000000000143, 39.80000000000024, 1.0999999999999635, 20.000000000000014, 20.000000000000014, -56.80000000000024, 11.299999999999985, 20.000000000000014, 15.199999999999964, 20.000000000000014, 22.700000000000053, 20.000000000000014, -12.099999999999831, 20.000000000000014, 31.70000000000022, 20.000000000000014, 46.10000000000023, -9.999999999999867, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, 24.50000000000008, 31.700000000000212, -19.899999999999785, 32.300000000000225, 38.900000000000254, 36.20000000000026, 17.899999999999988, 20.000000000000014, 24.50000000000008, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 20.000000000000014, 39.800000000000225, 42.50000000000025, 15.499999999999964, -32.49999999999978, 26.000000000000124, 39.800000000000246, 20.000000000000014, 20.000000000000014, -2.500000000000011, -47.19999999999976, 41.60000000000023, 17.899999999999988, 23.900000000000084, 9.499999999999964, 1.099999999999967, 27.500000000000142, 20.000000000000014, 20.000000000000014, 14.299999999999969, 20.000000000000014, 11.599999999999971, 20.000000000000014, 18.499999999999996, 20.000000000000014, 34.40000000000024, 32.300000000000225, 15.79999999999996, 43.40000000000025, 9.499999999999973, 20.000000000000014, 30.800000000000203, 20.000000000000014, 15.499999999999961, 20.000000000000014, 5.89999999999997, -10.599999999999854, -9.999999999999853, 11.59999999999998, -5.199999999999937, 20.000000000000014, 20.000000000000014, 44.300000000000246, 20.000000000000014, 14.599999999999966, 23.900000000000077, -17.79999999999977, -3.4000000000000012, 7.399999999999965, 46.10000000000022, 20.000000000000014, 33.20000000000024, 20.000000000000014, 20.000000000000014, 37.10000000000026, -24.09999999999978, 22.700000000000053, -47.19999999999976, -9.399999999999883, 20.000000000000014, -50.5999999999998, -47.1999999999998, -15.39999999999982, -10.899999999999864, 7.699999999999971, 15.19999999999996, 20.000000000000014, -1.0000000000000204, -76.60000000000086, 29.90000000000018, 20.000000000000014, -30.39999999999975, 42.50000000000025, 7.399999999999999, 20.000000000000014, 24.200000000000077, 20.000000000000014, 20.000000000000014, -19.899999999999743, -18.999999999999744, 20.000000000000014, -20.799999999999756, 42.50000000000024, 21.80000000000004, 20.000000000000014, 20.000000000000014, 45.2000000000002, 20.000000000000014, 20.000000000000014, 8.899999999999977, -49.299999999999834, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 24.50000000000008, -19.89999999999977, -28.29999999999977, -45.09999999999976, 31.70000000000022, -27.699999999999783, 20.000000000000014, 17.899999999999988, 4.99999999999997, 20.000000000000014, 20.000000000000014, -9.39999999999988, -15.699999999999747, -15.39999999999977, -14.499999999999837, -110.20000000000076, 21.80000000000004, -7.299999999999947, 18.8, 20.000000000000014, 27.50000000000015, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 38.000000000000256, 10.699999999999973, 34.100000000000236, -80.50000000000014, -191.8, 28.40000000000016, 3.4999999999999654, 20.000000000000014, 26.600000000000126, 42.50000000000023, 20.000000000000014, -30.399999999999807, -20.49999999999975, 17.899999999999988, 32.300000000000225, 33.50000000000024, 28.100000000000158, 10.399999999999968, 37.10000000000022, 12.499999999999972, -12.999999999999842, 11.599999999999975, 32.60000000000023, -19.89999999999977, 27.500000000000142, 9.499999999999948, 20.000000000000014, 26.300000000000114, 20.000000000000014, -7.300000000000043, 11.899999999999949, 37.10000000000026, 22.700000000000053, -8.200000000000049, -17.499999999999787], "policy_predator_policy_reward": [3.0, 2.0, 12.0, 9.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 34.0, 12.0, 0.0, 7.0, 0.0, 0.0, 15.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 3.0, 0.0, 17.0, 15.0, 0.0, 0.0, 12.0, 0.0, 21.0, 14.0, 0.0, 9.0, 0.0, 14.0, 0.0, 5.0, 0.0, 10.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 26.0, 13.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 15.0, 21.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 21.0, 17.0, 16.0, 15.0, 7.0, 58.0, 13.0, 0.0, 39.0, 0.0, 13.0, 0.0, 16.0, 46.0, 0.0, 23.0, 13.0, 15.0, 0.0, 0.0, 1.0, 0.0, 0.0, 15.0, 14.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 10.0, 0.0, 33.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 27.0, 13.0, 31.0, 0.0, 16.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 40.0, 47.0, 15.0, 0.0, 23.0, 11.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 10.0, 140.0, 5.0, 3.0, 12.0, 5.0, 3.0, 0.0, 0.0, 39.0, 6.0, 1.0, 1.0, 1.0, 8.0, 0.0, 8.0, 27.0, 0.0, 0.0, 10.0, 19.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 13.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0196272935078463, "mean_inference_ms": 5.279466688737666, "mean_action_processing_ms": 0.8106333940575473, "mean_env_wait_ms": 0.687296757009521, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007183432579040527, "StateBufferConnector_ms": 0.004311323165893555, "ViewRequirementAgentConnector_ms": 0.16000699996948242}, "num_episodes": 18, "episode_return_max": 75.09999999999972, "episode_return_min": -127.30000000000007, "episode_return_mean": 35.57100000000028, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.7541318209222, "num_env_steps_trained_throughput_per_sec": 306.7541318209222, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 15753.762, "restore_workers_time_ms": 0.02, "training_step_time_ms": 15753.697, "sample_time_ms": 2747.572, "learn_time_ms": 12974.983, "learn_throughput": 308.286, "synch_weights_time_ms": 27.339}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "e57b0_00000", "date": "2024-08-13_00-18-02", "timestamp": 1723522682, "time_this_iter_s": 13.15030288696289, "time_total_s": 457.75110268592834, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09fbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 457.75110268592834, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 72.26111111111112, "ram_util_percent": 83.22777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0799231000914775, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.120995826948256, "policy_loss": -0.0029238259652629496, "vf_loss": 5.122752740269616, "vf_explained_var": -0.0008617489110855829, "kl": 0.01382990020801247, "entropy": 1.262491086614195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49628867942583627, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3295178022334184, "policy_loss": -0.007530149204715613, "vf_loss": 3.3359878383616293, "vf_explained_var": -0.00041507271231797636, "kl": 0.01884635961480253, "entropy": 1.2197451320905535, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 89.19999999999827, "episode_reward_min": -178.39999999999998, "episode_reward_mean": 30.190000000000246, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -497.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.10000000000022, "predator_policy": 366.0}, "policy_reward_mean": {"prey_policy": 4.02000000000007, "predator_policy": 11.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [75.09999999999972, 38.90000000000028, 35.70000000000024, 33.400000000000205, 59.80000000000046, 61.000000000000504, 25.500000000000078, 59.8000000000005, 29.50000000000014, 29.400000000000148, 50.800000000000495, 24.600000000000072, 52.5000000000005, 44.300000000000374, 35.600000000000236, 40.5000000000003, 54.40000000000049, 60.1000000000005, 63.900000000000496, 50.80000000000048, 44.500000000000384, 36.900000000000254, 5.400000000000148, 31.400000000000194, 40.0000000000003, 64.30000000000048, 44.50000000000038, 14.799999999999924, 59.50000000000045, 54.200000000000514, 40.0000000000003, 34.00000000000024, 8.50000000000008, 32.600000000000186, -26.799999999999592, 12.69999999999994, 35.90000000000024, 35.00000000000022, -0.699999999999807, 25.600000000000076, 64.90000000000038, 45.20000000000038, 40.0000000000003, -9.899999999999604, 21.2, 64.30000000000047, 40.0000000000003, 68.20000000000014, 38.90000000000028, 3.7000000000001383, 40.0000000000003, 37.80000000000027, 44.50000000000037, -8.199999999999674, 17.59999999999994, 22.30000000000003, 34.900000000000226, 40.0000000000003, 5.900000000000135, 10.099999999999941, -26.399999999999558, 34.50000000000027, 58.50000000000044, 32.700000000000195, 58.00000000000051, 54.80000000000049, -127.30000000000007, 46.90000000000042, 54.6000000000005, 62.500000000000476, -5.899999999999704, 52.20000000000051, 70.60000000000001, 55.50000000000045, 26.500000000000103, 54.20000000000047, 31.60000000000018, 34.50000000000027, 46.300000000000395, 25.600000000000197, 59.80000000000052, 8.299999999999928, -1.49999999999973, 89.19999999999827, 24.400000000000063, 40.0000000000003, -35.69999999999956, 18.9, 59.80000000000051, 9.499999999999936, 49.90000000000046, 10.000000000000039, -26.39999999999987, -178.39999999999998, 56.90000000000051, 24.600000000000037, -66.0999999999998, 10.000000000000213, 37.80000000000025, 48.800000000000445], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [38.900000000000254, 36.20000000000026, 17.899999999999988, 20.000000000000014, 24.50000000000008, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 20.000000000000014, 39.800000000000225, 42.50000000000025, 15.499999999999964, -32.49999999999978, 26.000000000000124, 39.800000000000246, 20.000000000000014, 20.000000000000014, -2.500000000000011, -47.19999999999976, 41.60000000000023, 17.899999999999988, 23.900000000000084, 9.499999999999964, 1.099999999999967, 27.500000000000142, 20.000000000000014, 20.000000000000014, 14.299999999999969, 20.000000000000014, 11.599999999999971, 20.000000000000014, 18.499999999999996, 20.000000000000014, 34.40000000000024, 32.300000000000225, 15.79999999999996, 43.40000000000025, 9.499999999999973, 20.000000000000014, 30.800000000000203, 20.000000000000014, 15.499999999999961, 20.000000000000014, 5.89999999999997, -10.599999999999854, -9.999999999999853, 11.59999999999998, -5.199999999999937, 20.000000000000014, 20.000000000000014, 44.300000000000246, 20.000000000000014, 14.599999999999966, 23.900000000000077, -17.79999999999977, -3.4000000000000012, 7.399999999999965, 46.10000000000022, 20.000000000000014, 33.20000000000024, 20.000000000000014, 20.000000000000014, 37.10000000000026, -24.09999999999978, 22.700000000000053, -47.19999999999976, -9.399999999999883, 20.000000000000014, -50.5999999999998, -47.1999999999998, -15.39999999999982, -10.899999999999864, 7.699999999999971, 15.19999999999996, 20.000000000000014, -1.0000000000000204, -76.60000000000086, 29.90000000000018, 20.000000000000014, -30.39999999999975, 42.50000000000025, 7.399999999999999, 20.000000000000014, 24.200000000000077, 20.000000000000014, 20.000000000000014, -19.899999999999743, -18.999999999999744, 20.000000000000014, -20.799999999999756, 42.50000000000024, 21.80000000000004, 20.000000000000014, 20.000000000000014, 45.2000000000002, 20.000000000000014, 20.000000000000014, 8.899999999999977, -49.299999999999834, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 24.50000000000008, -19.89999999999977, -28.29999999999977, -45.09999999999976, 31.70000000000022, -27.699999999999783, 20.000000000000014, 17.899999999999988, 4.99999999999997, 20.000000000000014, 20.000000000000014, -9.39999999999988, -15.699999999999747, -15.39999999999977, -14.499999999999837, -110.20000000000076, 21.80000000000004, -7.299999999999947, 18.8, 20.000000000000014, 27.50000000000015, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 38.000000000000256, 10.699999999999973, 34.100000000000236, -80.50000000000014, -191.8, 28.40000000000016, 3.4999999999999654, 20.000000000000014, 26.600000000000126, 42.50000000000023, 20.000000000000014, -30.399999999999807, -20.49999999999975, 17.899999999999988, 32.300000000000225, 33.50000000000024, 28.100000000000158, 10.399999999999968, 37.10000000000022, 12.499999999999972, -12.999999999999842, 11.599999999999975, 32.60000000000023, -19.89999999999977, 27.500000000000142, 9.499999999999948, 20.000000000000014, 26.300000000000114, 20.000000000000014, -7.300000000000043, 11.899999999999949, 37.10000000000026, 22.700000000000053, -8.200000000000049, -17.499999999999787, -172.40000000000003, 17.900000000000013, 37.40000000000021, 45.80000000000023, 20.000000000000014, -19.599999999999767, 20.000000000000014, 20.000000000000014, -23.49999999999978, -47.199999999999896, -21.09999999999981, 20.000000000000014, 20.000000000000014, 39.80000000000025, 21.500000000000036, -82.00000000000071, 20.000000000000014, 29.90000000000018, -51.40000000000002, 25.400000000000098, -32.50000000000003, -19.900000000000023, -67.00000000000003, -497.4000000000001, 35.900000000000254, 20.000000000000014, -5.799999999999908, 7.400000000000233, -42.39999999999986, -84.7, -5.200000000000033, 3.200000000000003, 20.000000000000014, 6.799999999999972, 17.899999999999988, 29.90000000000018], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 3.0, 0.0, 17.0, 15.0, 0.0, 0.0, 12.0, 0.0, 21.0, 14.0, 0.0, 9.0, 0.0, 14.0, 0.0, 5.0, 0.0, 10.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 26.0, 13.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 15.0, 21.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 21.0, 17.0, 16.0, 15.0, 7.0, 58.0, 13.0, 0.0, 39.0, 0.0, 13.0, 0.0, 16.0, 46.0, 0.0, 23.0, 13.0, 15.0, 0.0, 0.0, 1.0, 0.0, 0.0, 15.0, 14.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 10.0, 0.0, 33.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 27.0, 13.0, 31.0, 0.0, 16.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 40.0, 47.0, 15.0, 0.0, 23.0, 11.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 10.0, 140.0, 5.0, 3.0, 12.0, 5.0, 3.0, 0.0, 0.0, 39.0, 6.0, 1.0, 1.0, 1.0, 8.0, 0.0, 8.0, 27.0, 0.0, 0.0, 10.0, 19.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 13.0, 21.0, 3.0, 150.0, 0.0, 6.0, 11.0, 13.0, 0.0, 0.0, 0.0, 35.0, 20.0, 0.0, 0.0, 0.0, 36.0, 34.0, 0.0, 0.0, 34.0, 2.0, 19.0, 7.0, 20.0, 366.0, 1.0, 0.0, 0.0, 23.0, 0.0, 61.0, 4.0, 8.0, 11.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.9854115495004325, "mean_inference_ms": 5.195197711889664, "mean_action_processing_ms": 0.7976014424066764, "mean_env_wait_ms": 0.6760487323692171, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007816672325134277, "StateBufferConnector_ms": 0.0043936967849731445, "ViewRequirementAgentConnector_ms": 0.2444779872894287}, "num_episodes": 18, "episode_return_max": 89.19999999999827, "episode_return_min": -178.39999999999998, "episode_return_mean": 30.190000000000246, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.6567459400139, "num_env_steps_trained_throughput_per_sec": 247.6567459400139, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 15718.196, "restore_workers_time_ms": 0.019, "training_step_time_ms": 15718.131, "sample_time_ms": 2766.089, "learn_time_ms": 12920.492, "learn_throughput": 309.586, "synch_weights_time_ms": 27.661}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "e57b0_00000", "date": "2024-08-13_00-18-18", "timestamp": 1723522698, "time_this_iter_s": 16.204514026641846, "time_total_s": 473.9556167125702, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09fb3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 473.9556167125702, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 80.10869565217394, "ram_util_percent": 83.26521739130433}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6636990776985253, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.580148934561109, "policy_loss": -0.008684379546090014, "vf_loss": 9.587424589591052, "vf_explained_var": 8.056261552073968e-05, "kl": 0.01669594581880267, "entropy": 1.2749023814049978, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4855765024111384, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.515212002506962, "policy_loss": -0.007500675059214392, "vf_loss": 9.521523437298164, "vf_explained_var": -0.00025019428086659265, "kl": 0.021141638715177765, "entropy": 1.142401714236648, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 301.80000000000064, "episode_reward_min": -567.5999999999999, "episode_reward_mean": -21.226999999999798, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1070.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.10000000000022, "predator_policy": 983.0}, "policy_reward_mean": {"prey_policy": -119.04349999999995, "predator_policy": 108.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.400000000000148, 31.400000000000194, 40.0000000000003, 64.30000000000048, 44.50000000000038, 14.799999999999924, 59.50000000000045, 54.200000000000514, 40.0000000000003, 34.00000000000024, 8.50000000000008, 32.600000000000186, -26.799999999999592, 12.69999999999994, 35.90000000000024, 35.00000000000022, -0.699999999999807, 25.600000000000076, 64.90000000000038, 45.20000000000038, 40.0000000000003, -9.899999999999604, 21.2, 64.30000000000047, 40.0000000000003, 68.20000000000014, 38.90000000000028, 3.7000000000001383, 40.0000000000003, 37.80000000000027, 44.50000000000037, -8.199999999999674, 17.59999999999994, 22.30000000000003, 34.900000000000226, 40.0000000000003, 5.900000000000135, 10.099999999999941, -26.399999999999558, 34.50000000000027, 58.50000000000044, 32.700000000000195, 58.00000000000051, 54.80000000000049, -127.30000000000007, 46.90000000000042, 54.6000000000005, 62.500000000000476, -5.899999999999704, 52.20000000000051, 70.60000000000001, 55.50000000000045, 26.500000000000103, 54.20000000000047, 31.60000000000018, 34.50000000000027, 46.300000000000395, 25.600000000000197, 59.80000000000052, 8.299999999999928, -1.49999999999973, 89.19999999999827, 24.400000000000063, 40.0000000000003, -35.69999999999956, 18.9, 59.80000000000051, 9.499999999999936, 49.90000000000046, 10.000000000000039, -26.39999999999987, -178.39999999999998, 56.90000000000051, 24.600000000000037, -66.0999999999998, 10.000000000000213, 37.80000000000025, 48.800000000000445, -462.0999999999999, -152.8999999999999, 69.2999999999999, 64.30000000000047, -567.5999999999999, -3.7000000000005002, -231.39999999999992, -136.69999999999976, -134.6, -307.09999999999997, -478.5999999999999, -212.1999999999999, -144.09999999999962, -71.49999999999989, -418.0999999999999, -277.2, -305.29999999999984, -337.4999999999999, -275.20000000000005, -53.00000000000003, -1.2999999999997343, 301.80000000000064], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.599999999999854, -9.999999999999853, 11.59999999999998, -5.199999999999937, 20.000000000000014, 20.000000000000014, 44.300000000000246, 20.000000000000014, 14.599999999999966, 23.900000000000077, -17.79999999999977, -3.4000000000000012, 7.399999999999965, 46.10000000000022, 20.000000000000014, 33.20000000000024, 20.000000000000014, 20.000000000000014, 37.10000000000026, -24.09999999999978, 22.700000000000053, -47.19999999999976, -9.399999999999883, 20.000000000000014, -50.5999999999998, -47.1999999999998, -15.39999999999982, -10.899999999999864, 7.699999999999971, 15.19999999999996, 20.000000000000014, -1.0000000000000204, -76.60000000000086, 29.90000000000018, 20.000000000000014, -30.39999999999975, 42.50000000000025, 7.399999999999999, 20.000000000000014, 24.200000000000077, 20.000000000000014, 20.000000000000014, -19.899999999999743, -18.999999999999744, 20.000000000000014, -20.799999999999756, 42.50000000000024, 21.80000000000004, 20.000000000000014, 20.000000000000014, 45.2000000000002, 20.000000000000014, 20.000000000000014, 8.899999999999977, -49.299999999999834, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 24.50000000000008, -19.89999999999977, -28.29999999999977, -45.09999999999976, 31.70000000000022, -27.699999999999783, 20.000000000000014, 17.899999999999988, 4.99999999999997, 20.000000000000014, 20.000000000000014, -9.39999999999988, -15.699999999999747, -15.39999999999977, -14.499999999999837, -110.20000000000076, 21.80000000000004, -7.299999999999947, 18.8, 20.000000000000014, 27.50000000000015, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 38.000000000000256, 10.699999999999973, 34.100000000000236, -80.50000000000014, -191.8, 28.40000000000016, 3.4999999999999654, 20.000000000000014, 26.600000000000126, 42.50000000000023, 20.000000000000014, -30.399999999999807, -20.49999999999975, 17.899999999999988, 32.300000000000225, 33.50000000000024, 28.100000000000158, 10.399999999999968, 37.10000000000022, 12.499999999999972, -12.999999999999842, 11.599999999999975, 32.60000000000023, -19.89999999999977, 27.500000000000142, 9.499999999999948, 20.000000000000014, 26.300000000000114, 20.000000000000014, -7.300000000000043, 11.899999999999949, 37.10000000000026, 22.700000000000053, -8.200000000000049, -17.499999999999787, -172.40000000000003, 17.900000000000013, 37.40000000000021, 45.80000000000023, 20.000000000000014, -19.599999999999767, 20.000000000000014, 20.000000000000014, -23.49999999999978, -47.199999999999896, -21.09999999999981, 20.000000000000014, 20.000000000000014, 39.80000000000025, 21.500000000000036, -82.00000000000071, 20.000000000000014, 29.90000000000018, -51.40000000000002, 25.400000000000098, -32.50000000000003, -19.900000000000023, -67.00000000000003, -497.4000000000001, 35.900000000000254, 20.000000000000014, -5.799999999999908, 7.400000000000233, -42.39999999999986, -84.7, -5.200000000000033, 3.200000000000003, 20.000000000000014, 6.799999999999972, 17.899999999999988, 29.90000000000018, -785.8, -408.3, -266.0, -920.9, -335.40000000000003, -770.2999999999997, 20.000000000000014, 44.30000000000024, -826.5999999999999, -924.0, -343.9000000000003, -692.8000000000002, -743.6999999999999, -221.70000000000002, -369.8, -246.8999999999999, -444.40000000000003, -763.2, -848.8, -656.3, -840.0999999999999, -918.5, -381.90000000000003, -298.3, -160.79999999999984, -185.30000000000004, -1025.7, -345.8, -543.2, -296.90000000000003, -1070.8, -1070.4, -446.2999999999999, -414.0, -1006.5, -797.0, -647.1, -548.1, -889.2, -749.8, -9.0, -23.300000000000004, -645.6, 28.40000000000016], "policy_predator_policy_reward": [0.0, 26.0, 13.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 15.0, 21.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 21.0, 17.0, 16.0, 15.0, 7.0, 58.0, 13.0, 0.0, 39.0, 0.0, 13.0, 0.0, 16.0, 46.0, 0.0, 23.0, 13.0, 15.0, 0.0, 0.0, 1.0, 0.0, 0.0, 15.0, 14.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 10.0, 0.0, 33.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 27.0, 13.0, 31.0, 0.0, 16.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 40.0, 47.0, 15.0, 0.0, 23.0, 11.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 10.0, 140.0, 5.0, 3.0, 12.0, 5.0, 3.0, 0.0, 0.0, 39.0, 6.0, 1.0, 1.0, 1.0, 8.0, 0.0, 8.0, 27.0, 0.0, 0.0, 10.0, 19.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 13.0, 21.0, 3.0, 150.0, 0.0, 6.0, 11.0, 13.0, 0.0, 0.0, 0.0, 35.0, 20.0, 0.0, 0.0, 0.0, 36.0, 34.0, 0.0, 0.0, 34.0, 2.0, 19.0, 7.0, 20.0, 366.0, 1.0, 0.0, 0.0, 23.0, 0.0, 61.0, 4.0, 8.0, 11.0, 0.0, 0.0, 1.0, 13.0, 719.0, 711.0, 323.0, 668.0, 507.0, 0.0, 0.0, 871.0, 312.0, 484.0, 549.0, 635.0, 99.0, 265.0, 215.0, 327.0, 746.0, 415.0, 783.0, 297.0, 983.0, 305.0, 163.0, 197.0, 5.0, 651.0, 649.0, 380.0, 42.0, 927.0, 937.0, 14.0, 541.0, 774.0, 692.0, 322.0, 598.0, 833.0, 753.0, 0.0, 31.0, 475.0, 444.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.9476984824962442, "mean_inference_ms": 5.09530311163569, "mean_action_processing_ms": 0.7822516341003727, "mean_env_wait_ms": 0.6636849698029045, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009143352508544922, "StateBufferConnector_ms": 0.005368709564208984, "ViewRequirementAgentConnector_ms": 0.25171613693237305}, "num_episodes": 22, "episode_return_max": 301.80000000000064, "episode_return_min": -567.5999999999999, "episode_return_mean": -21.226999999999798, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 216.48219529449096, "num_env_steps_trained_throughput_per_sec": 216.48219529449096, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 15571.733, "restore_workers_time_ms": 0.019, "training_step_time_ms": 15571.674, "sample_time_ms": 2714.72, "learn_time_ms": 12829.082, "learn_throughput": 311.792, "synch_weights_time_ms": 24.128}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "e57b0_00000", "date": "2024-08-13_00-18-37", "timestamp": 1723522717, "time_this_iter_s": 18.522053956985474, "time_total_s": 492.47767066955566, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b591f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 492.47767066955566, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 83.41923076923078, "ram_util_percent": 82.76538461538462}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8861085107323354, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.175201339318008, "policy_loss": -0.010050475129995634, "vf_loss": 6.1833735970593, "vf_explained_var": 0.000823009834087715, "kl": 0.022260178879716132, "entropy": 1.1593633925473248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4329301641692245, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.858475216355904, "policy_loss": -0.0012556754641491112, "vf_loss": 7.859307758391849, "vf_explained_var": -5.597200973954781e-05, "kl": 0.005014728103320262, "entropy": 1.1090327738454102, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 535.5000000000009, "episode_reward_min": -567.5999999999999, "episode_reward_mean": -0.5599999999998378, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1070.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.80000000000023, "predator_policy": 1099.0}, "policy_reward_mean": {"prey_policy": -209.595, "predator_policy": 209.315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [64.30000000000047, 40.0000000000003, 68.20000000000014, 38.90000000000028, 3.7000000000001383, 40.0000000000003, 37.80000000000027, 44.50000000000037, -8.199999999999674, 17.59999999999994, 22.30000000000003, 34.900000000000226, 40.0000000000003, 5.900000000000135, 10.099999999999941, -26.399999999999558, 34.50000000000027, 58.50000000000044, 32.700000000000195, 58.00000000000051, 54.80000000000049, -127.30000000000007, 46.90000000000042, 54.6000000000005, 62.500000000000476, -5.899999999999704, 52.20000000000051, 70.60000000000001, 55.50000000000045, 26.500000000000103, 54.20000000000047, 31.60000000000018, 34.50000000000027, 46.300000000000395, 25.600000000000197, 59.80000000000052, 8.299999999999928, -1.49999999999973, 89.19999999999827, 24.400000000000063, 40.0000000000003, -35.69999999999956, 18.9, 59.80000000000051, 9.499999999999936, 49.90000000000046, 10.000000000000039, -26.39999999999987, -178.39999999999998, 56.90000000000051, 24.600000000000037, -66.0999999999998, 10.000000000000213, 37.80000000000025, 48.800000000000445, -462.0999999999999, -152.8999999999999, 69.2999999999999, 64.30000000000047, -567.5999999999999, -3.7000000000005002, -231.39999999999992, -136.69999999999976, -134.6, -307.09999999999997, -478.5999999999999, -212.1999999999999, -144.09999999999962, -71.49999999999989, -418.0999999999999, -277.2, -305.29999999999984, -337.4999999999999, -275.20000000000005, -53.00000000000003, -1.2999999999997343, 301.80000000000064, 49.300000000000175, 162.29999999999995, 233.69999999999945, 381.90000000000066, -17.39999999999994, 63.40000000000048, 36.70000000000025, -51.10000000000071, 23.600000000000023, 535.5000000000009, 269.20000000000016, -10.599999999999909, 297.39999999999964, 3.40000000000002, -15.600000000000044, 19.600000000000406, 377.5000000000008, -427.20000000000005, 288.6999999999997, 157.49999999999977, 275.99999999999983, 52.00000000000003, 33.20000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [42.50000000000024, 21.80000000000004, 20.000000000000014, 20.000000000000014, 45.2000000000002, 20.000000000000014, 20.000000000000014, 8.899999999999977, -49.299999999999834, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 24.50000000000008, -19.89999999999977, -28.29999999999977, -45.09999999999976, 31.70000000000022, -27.699999999999783, 20.000000000000014, 17.899999999999988, 4.99999999999997, 20.000000000000014, 20.000000000000014, -9.39999999999988, -15.699999999999747, -15.39999999999977, -14.499999999999837, -110.20000000000076, 21.80000000000004, -7.299999999999947, 18.8, 20.000000000000014, 27.50000000000015, 1.6999999999999729, 20.000000000000014, 20.000000000000014, 38.000000000000256, 10.699999999999973, 34.100000000000236, -80.50000000000014, -191.8, 28.40000000000016, 3.4999999999999654, 20.000000000000014, 26.600000000000126, 42.50000000000023, 20.000000000000014, -30.399999999999807, -20.49999999999975, 17.899999999999988, 32.300000000000225, 33.50000000000024, 28.100000000000158, 10.399999999999968, 37.10000000000022, 12.499999999999972, -12.999999999999842, 11.599999999999975, 32.60000000000023, -19.89999999999977, 27.500000000000142, 9.499999999999948, 20.000000000000014, 26.300000000000114, 20.000000000000014, -7.300000000000043, 11.899999999999949, 37.10000000000026, 22.700000000000053, -8.200000000000049, -17.499999999999787, -172.40000000000003, 17.900000000000013, 37.40000000000021, 45.80000000000023, 20.000000000000014, -19.599999999999767, 20.000000000000014, 20.000000000000014, -23.49999999999978, -47.199999999999896, -21.09999999999981, 20.000000000000014, 20.000000000000014, 39.80000000000025, 21.500000000000036, -82.00000000000071, 20.000000000000014, 29.90000000000018, -51.40000000000002, 25.400000000000098, -32.50000000000003, -19.900000000000023, -67.00000000000003, -497.4000000000001, 35.900000000000254, 20.000000000000014, -5.799999999999908, 7.400000000000233, -42.39999999999986, -84.7, -5.200000000000033, 3.200000000000003, 20.000000000000014, 6.799999999999972, 17.899999999999988, 29.90000000000018, -785.8, -408.3, -266.0, -920.9, -335.40000000000003, -770.2999999999997, 20.000000000000014, 44.30000000000024, -826.5999999999999, -924.0, -343.9000000000003, -692.8000000000002, -743.6999999999999, -221.70000000000002, -369.8, -246.8999999999999, -444.40000000000003, -763.2, -848.8, -656.3, -840.0999999999999, -918.5, -381.90000000000003, -298.3, -160.79999999999984, -185.30000000000004, -1025.7, -345.8, -543.2, -296.90000000000003, -1070.8, -1070.4, -446.2999999999999, -414.0, -1006.5, -797.0, -647.1, -548.1, -889.2, -749.8, -9.0, -23.300000000000004, -645.6, 28.40000000000016, -114.40000000000002, -506.3, -513.2, -11.499999999999819, 20.000000000000014, -684.3, -975.0, -45.09999999999998, -995.1, -407.2999999999998, 20.000000000000014, 43.40000000000023, 13.699999999999966, 20.000000000000014, -51.39999999999996, -69.70000000000084, -624.8, -594.6, -818.5, 20.000000000000014, -669.1999999999999, -13.60000000000001, -331.1, -591.5, 20.000000000000014, -707.6, -889.4, -843.2, -249.60000000000002, -201.99999999999994, -14.199999999999775, -100.19999999999995, -903.4, 20.90000000000003, -464.70000000000005, -832.5, -3.399999999999958, -644.9, -528.5000000000002, 29.000000000000167, -370.29999999999984, -1027.7, 21.800000000000047, -292.79999999999995, -1068.8000000000013, -971.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 10.0, 0.0, 33.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 27.0, 13.0, 31.0, 0.0, 16.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 40.0, 47.0, 15.0, 0.0, 23.0, 11.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 10.0, 140.0, 5.0, 3.0, 12.0, 5.0, 3.0, 0.0, 0.0, 39.0, 6.0, 1.0, 1.0, 1.0, 8.0, 0.0, 8.0, 27.0, 0.0, 0.0, 10.0, 19.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 13.0, 21.0, 3.0, 150.0, 0.0, 6.0, 11.0, 13.0, 0.0, 0.0, 0.0, 35.0, 20.0, 0.0, 0.0, 0.0, 36.0, 34.0, 0.0, 0.0, 34.0, 2.0, 19.0, 7.0, 20.0, 366.0, 1.0, 0.0, 0.0, 23.0, 0.0, 61.0, 4.0, 8.0, 11.0, 0.0, 0.0, 1.0, 13.0, 719.0, 711.0, 323.0, 668.0, 507.0, 0.0, 0.0, 871.0, 312.0, 484.0, 549.0, 635.0, 99.0, 265.0, 215.0, 327.0, 746.0, 415.0, 783.0, 297.0, 983.0, 305.0, 163.0, 197.0, 5.0, 651.0, 649.0, 380.0, 42.0, 927.0, 937.0, 14.0, 541.0, 774.0, 692.0, 322.0, 598.0, 833.0, 753.0, 0.0, 31.0, 475.0, 444.0, 269.0, 401.0, 372.0, 315.0, 409.0, 489.0, 712.0, 690.0, 688.0, 697.0, 0.0, 0.0, 0.0, 3.0, 30.0, 40.0, 511.0, 732.0, 706.0, 628.0, 428.0, 524.0, 533.0, 379.0, 451.0, 534.0, 743.0, 993.0, 224.0, 212.0, 68.0, 66.0, 548.0, 712.0, 851.0, 19.0, 458.0, 479.0, 403.0, 254.0, 766.0, 908.0, 175.0, 148.0, 1099.0, 974.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.9078233522866521, "mean_inference_ms": 5.01446106556279, "mean_action_processing_ms": 0.8062555878933984, "mean_env_wait_ms": 0.6508474780359437, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014283299446105957, "StateBufferConnector_ms": 0.004701972007751465, "ViewRequirementAgentConnector_ms": 0.2580071687698364}, "num_episodes": 23, "episode_return_max": 535.5000000000009, "episode_return_min": -567.5999999999999, "episode_return_mean": -0.5599999999998378, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.4173748858637, "num_env_steps_trained_throughput_per_sec": 229.4173748858637, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 15527.736, "restore_workers_time_ms": 0.019, "training_step_time_ms": 15527.677, "sample_time_ms": 2577.733, "learn_time_ms": 12922.483, "learn_throughput": 309.538, "synch_weights_time_ms": 23.506}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "e57b0_00000", "date": "2024-08-13_00-18-55", "timestamp": 1723522735, "time_this_iter_s": 17.546895742416382, "time_total_s": 510.02456641197205, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bb940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 510.02456641197205, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 81.24, "ram_util_percent": 83.27599999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8841891436192094, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.292849828263439, "policy_loss": -0.00471101161277306, "vf_loss": 2.2962801216771362, "vf_explained_var": 0.0005638780101897224, "kl": 0.010119274742067778, "entropy": 1.1604361277408701, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5208660474155473, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.747929533953389, "policy_loss": -0.0037858165206791704, "vf_loss": 3.750697689333921, "vf_explained_var": -0.00011983996345883324, "kl": 0.012061004119015915, "entropy": 1.0261620307725574, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 535.5000000000009, "episode_reward_min": -567.5999999999999, "episode_reward_mean": 0.683000000000138, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1070.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.80000000000023, "predator_policy": 1099.0}, "policy_reward_mean": {"prey_policy": -216.08849999999995, "predator_policy": 216.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.700000000000195, 58.00000000000051, 54.80000000000049, -127.30000000000007, 46.90000000000042, 54.6000000000005, 62.500000000000476, -5.899999999999704, 52.20000000000051, 70.60000000000001, 55.50000000000045, 26.500000000000103, 54.20000000000047, 31.60000000000018, 34.50000000000027, 46.300000000000395, 25.600000000000197, 59.80000000000052, 8.299999999999928, -1.49999999999973, 89.19999999999827, 24.400000000000063, 40.0000000000003, -35.69999999999956, 18.9, 59.80000000000051, 9.499999999999936, 49.90000000000046, 10.000000000000039, -26.39999999999987, -178.39999999999998, 56.90000000000051, 24.600000000000037, -66.0999999999998, 10.000000000000213, 37.80000000000025, 48.800000000000445, -462.0999999999999, -152.8999999999999, 69.2999999999999, 64.30000000000047, -567.5999999999999, -3.7000000000005002, -231.39999999999992, -136.69999999999976, -134.6, -307.09999999999997, -478.5999999999999, -212.1999999999999, -144.09999999999962, -71.49999999999989, -418.0999999999999, -277.2, -305.29999999999984, -337.4999999999999, -275.20000000000005, -53.00000000000003, -1.2999999999997343, 301.80000000000064, 49.300000000000175, 162.29999999999995, 233.69999999999945, 381.90000000000066, -17.39999999999994, 63.40000000000048, 36.70000000000025, -51.10000000000071, 23.600000000000023, 535.5000000000009, 269.20000000000016, -10.599999999999909, 297.39999999999964, 3.40000000000002, -15.600000000000044, 19.600000000000406, 377.5000000000008, -427.20000000000005, 288.6999999999997, 157.49999999999977, 275.99999999999983, 52.00000000000003, 33.20000000000003, 64.80000000000042, 104.80000000000013, 36.70000000000025, 69.6999999999997, 31.700000000000177, 17.79999999999995, 35.80000000000026, -0.999999999999949, -1.399999999999864, 16.199999999999935, 8.100000000000088, 40.0000000000003, -21.99999999999961, 56.40000000000008, 2.6000000000001586, 55.300000000000516, 95.39999999999901, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.6999999999999729, 20.000000000000014, 20.000000000000014, 38.000000000000256, 10.699999999999973, 34.100000000000236, -80.50000000000014, -191.8, 28.40000000000016, 3.4999999999999654, 20.000000000000014, 26.600000000000126, 42.50000000000023, 20.000000000000014, -30.399999999999807, -20.49999999999975, 17.899999999999988, 32.300000000000225, 33.50000000000024, 28.100000000000158, 10.399999999999968, 37.10000000000022, 12.499999999999972, -12.999999999999842, 11.599999999999975, 32.60000000000023, -19.89999999999977, 27.500000000000142, 9.499999999999948, 20.000000000000014, 26.300000000000114, 20.000000000000014, -7.300000000000043, 11.899999999999949, 37.10000000000026, 22.700000000000053, -8.200000000000049, -17.499999999999787, -172.40000000000003, 17.900000000000013, 37.40000000000021, 45.80000000000023, 20.000000000000014, -19.599999999999767, 20.000000000000014, 20.000000000000014, -23.49999999999978, -47.199999999999896, -21.09999999999981, 20.000000000000014, 20.000000000000014, 39.80000000000025, 21.500000000000036, -82.00000000000071, 20.000000000000014, 29.90000000000018, -51.40000000000002, 25.400000000000098, -32.50000000000003, -19.900000000000023, -67.00000000000003, -497.4000000000001, 35.900000000000254, 20.000000000000014, -5.799999999999908, 7.400000000000233, -42.39999999999986, -84.7, -5.200000000000033, 3.200000000000003, 20.000000000000014, 6.799999999999972, 17.899999999999988, 29.90000000000018, -785.8, -408.3, -266.0, -920.9, -335.40000000000003, -770.2999999999997, 20.000000000000014, 44.30000000000024, -826.5999999999999, -924.0, -343.9000000000003, -692.8000000000002, -743.6999999999999, -221.70000000000002, -369.8, -246.8999999999999, -444.40000000000003, -763.2, -848.8, -656.3, -840.0999999999999, -918.5, -381.90000000000003, -298.3, -160.79999999999984, -185.30000000000004, -1025.7, -345.8, -543.2, -296.90000000000003, -1070.8, -1070.4, -446.2999999999999, -414.0, -1006.5, -797.0, -647.1, -548.1, -889.2, -749.8, -9.0, -23.300000000000004, -645.6, 28.40000000000016, -114.40000000000002, -506.3, -513.2, -11.499999999999819, 20.000000000000014, -684.3, -975.0, -45.09999999999998, -995.1, -407.2999999999998, 20.000000000000014, 43.40000000000023, 13.699999999999966, 20.000000000000014, -51.39999999999996, -69.70000000000084, -624.8, -594.6, -818.5, 20.000000000000014, -669.1999999999999, -13.60000000000001, -331.1, -591.5, 20.000000000000014, -707.6, -889.4, -843.2, -249.60000000000002, -201.99999999999994, -14.199999999999775, -100.19999999999995, -903.4, 20.90000000000003, -464.70000000000005, -832.5, -3.399999999999958, -644.9, -528.5000000000002, 29.000000000000167, -370.29999999999984, -1027.7, 21.800000000000047, -292.79999999999995, -1068.8000000000013, -971.0, 45.20000000000023, 11.6, 20.000000000000014, -190.20000000000005, 20.000000000000014, 13.699999999999964, -302.69999999999936, 7.399999999999967, 5.299999999999965, 7.3999999999999755, 11.299999999999978, -26.499999999999766, -202.59999999999994, 34.40000000000022, -40.89999999999986, -3.1000000000000045, -11.499999999999819, -49.89999999999982, -9.699999999999882, -3.0999999999999615, -13.599999999999808, -7.299999999999891, 20.000000000000014, 20.000000000000014, 7.399999999999967, -156.4000000000006, -135.50000000000003, 17.899999999999988, -45.09999999999977, 13.699999999999964, 20.000000000000014, 35.30000000000026, -297.7999999999985, 45.20000000000023, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [4.0, 7.0, 0.0, 0.0, 0.0, 10.0, 140.0, 5.0, 3.0, 12.0, 5.0, 3.0, 0.0, 0.0, 39.0, 6.0, 1.0, 1.0, 1.0, 8.0, 0.0, 8.0, 27.0, 0.0, 0.0, 10.0, 19.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 13.0, 21.0, 3.0, 150.0, 0.0, 6.0, 11.0, 13.0, 0.0, 0.0, 0.0, 35.0, 20.0, 0.0, 0.0, 0.0, 36.0, 34.0, 0.0, 0.0, 34.0, 2.0, 19.0, 7.0, 20.0, 366.0, 1.0, 0.0, 0.0, 23.0, 0.0, 61.0, 4.0, 8.0, 11.0, 0.0, 0.0, 1.0, 13.0, 719.0, 711.0, 323.0, 668.0, 507.0, 0.0, 0.0, 871.0, 312.0, 484.0, 549.0, 635.0, 99.0, 265.0, 215.0, 327.0, 746.0, 415.0, 783.0, 297.0, 983.0, 305.0, 163.0, 197.0, 5.0, 651.0, 649.0, 380.0, 42.0, 927.0, 937.0, 14.0, 541.0, 774.0, 692.0, 322.0, 598.0, 833.0, 753.0, 0.0, 31.0, 475.0, 444.0, 269.0, 401.0, 372.0, 315.0, 409.0, 489.0, 712.0, 690.0, 688.0, 697.0, 0.0, 0.0, 0.0, 3.0, 30.0, 40.0, 511.0, 732.0, 706.0, 628.0, 428.0, 524.0, 533.0, 379.0, 451.0, 534.0, 743.0, 993.0, 224.0, 212.0, 68.0, 66.0, 548.0, 712.0, 851.0, 19.0, 458.0, 479.0, 403.0, 254.0, 766.0, 908.0, 175.0, 148.0, 1099.0, 974.0, 4.0, 4.0, 150.0, 125.0, 3.0, 0.0, 187.0, 178.0, 0.0, 19.0, 17.0, 16.0, 98.0, 106.0, 0.0, 43.0, 39.0, 21.0, 0.0, 29.0, 0.0, 29.0, 0.0, 0.0, 89.0, 38.0, 73.0, 101.0, 31.0, 3.0, 0.0, 0.0, 133.0, 215.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.881381731093724, "mean_inference_ms": 4.9576419697878364, "mean_action_processing_ms": 0.8239659582996023, "mean_env_wait_ms": 0.6424124389831678, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014340519905090332, "StateBufferConnector_ms": 0.004827380180358887, "ViewRequirementAgentConnector_ms": 0.23070001602172852}, "num_episodes": 18, "episode_return_max": 535.5000000000009, "episode_return_min": -567.5999999999999, "episode_return_mean": 0.683000000000138, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 282.81396695635186, "num_env_steps_trained_throughput_per_sec": 282.81396695635186, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 15331.84, "restore_workers_time_ms": 0.019, "training_step_time_ms": 15331.78, "sample_time_ms": 2509.777, "learn_time_ms": 12795.069, "learn_throughput": 312.62, "synch_weights_time_ms": 23.323}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "e57b0_00000", "date": "2024-08-13_00-19-09", "timestamp": 1723522749, "time_this_iter_s": 14.19867491722107, "time_total_s": 524.2232413291931, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b094aee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 524.2232413291931, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 77.20000000000002, "ram_util_percent": 83.565}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8188226690289204, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.211011587729845, "policy_loss": -0.006599979396298449, "vf_loss": 1.216353733151678, "vf_explained_var": -0.0003939124957594291, "kl": 0.009938433499201012, "entropy": 1.208071365179839, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4082275936153358, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8230846898265616, "policy_loss": -0.001339560371784188, "vf_loss": 1.8240128483721818, "vf_explained_var": -4.3169058189190255e-05, "kl": 0.004875904095820044, "entropy": 1.0252541823992654, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 535.5000000000009, "episode_reward_min": -567.5999999999999, "episode_reward_mean": 1.1220000000001313, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1070.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.80000000000023, "predator_policy": 1099.0}, "policy_reward_mean": {"prey_policy": -219.14899999999997, "predator_policy": 219.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.299999999999928, -1.49999999999973, 89.19999999999827, 24.400000000000063, 40.0000000000003, -35.69999999999956, 18.9, 59.80000000000051, 9.499999999999936, 49.90000000000046, 10.000000000000039, -26.39999999999987, -178.39999999999998, 56.90000000000051, 24.600000000000037, -66.0999999999998, 10.000000000000213, 37.80000000000025, 48.800000000000445, -462.0999999999999, -152.8999999999999, 69.2999999999999, 64.30000000000047, -567.5999999999999, -3.7000000000005002, -231.39999999999992, -136.69999999999976, -134.6, -307.09999999999997, -478.5999999999999, -212.1999999999999, -144.09999999999962, -71.49999999999989, -418.0999999999999, -277.2, -305.29999999999984, -337.4999999999999, -275.20000000000005, -53.00000000000003, -1.2999999999997343, 301.80000000000064, 49.300000000000175, 162.29999999999995, 233.69999999999945, 381.90000000000066, -17.39999999999994, 63.40000000000048, 36.70000000000025, -51.10000000000071, 23.600000000000023, 535.5000000000009, 269.20000000000016, -10.599999999999909, 297.39999999999964, 3.40000000000002, -15.600000000000044, 19.600000000000406, 377.5000000000008, -427.20000000000005, 288.6999999999997, 157.49999999999977, 275.99999999999983, 52.00000000000003, 33.20000000000003, 64.80000000000042, 104.80000000000013, 36.70000000000025, 69.6999999999997, 31.700000000000177, 17.79999999999995, 35.80000000000026, -0.999999999999949, -1.399999999999864, 16.199999999999935, 8.100000000000088, 40.0000000000003, -21.99999999999961, 56.40000000000008, 2.6000000000001586, 55.300000000000516, 95.39999999999901, 40.0000000000003, 16.89999999999993, 28.70000000000016, 53.100000000000506, 53.80000000000044, 32.10000000000019, 66.10000000000035, 38.900000000000276, 32.30000000000018, 52.20000000000049, -12.599999999999616, 35.600000000000236, 24.900000000000052, 47.10000000000042, 56.20000000000049, 6.3000000000000735, 48.40000000000044, 57.00000000000026, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.200000000000049, -17.499999999999787, -172.40000000000003, 17.900000000000013, 37.40000000000021, 45.80000000000023, 20.000000000000014, -19.599999999999767, 20.000000000000014, 20.000000000000014, -23.49999999999978, -47.199999999999896, -21.09999999999981, 20.000000000000014, 20.000000000000014, 39.80000000000025, 21.500000000000036, -82.00000000000071, 20.000000000000014, 29.90000000000018, -51.40000000000002, 25.400000000000098, -32.50000000000003, -19.900000000000023, -67.00000000000003, -497.4000000000001, 35.900000000000254, 20.000000000000014, -5.799999999999908, 7.400000000000233, -42.39999999999986, -84.7, -5.200000000000033, 3.200000000000003, 20.000000000000014, 6.799999999999972, 17.899999999999988, 29.90000000000018, -785.8, -408.3, -266.0, -920.9, -335.40000000000003, -770.2999999999997, 20.000000000000014, 44.30000000000024, -826.5999999999999, -924.0, -343.9000000000003, -692.8000000000002, -743.6999999999999, -221.70000000000002, -369.8, -246.8999999999999, -444.40000000000003, -763.2, -848.8, -656.3, -840.0999999999999, -918.5, -381.90000000000003, -298.3, -160.79999999999984, -185.30000000000004, -1025.7, -345.8, -543.2, -296.90000000000003, -1070.8, -1070.4, -446.2999999999999, -414.0, -1006.5, -797.0, -647.1, -548.1, -889.2, -749.8, -9.0, -23.300000000000004, -645.6, 28.40000000000016, -114.40000000000002, -506.3, -513.2, -11.499999999999819, 20.000000000000014, -684.3, -975.0, -45.09999999999998, -995.1, -407.2999999999998, 20.000000000000014, 43.40000000000023, 13.699999999999966, 20.000000000000014, -51.39999999999996, -69.70000000000084, -624.8, -594.6, -818.5, 20.000000000000014, -669.1999999999999, -13.60000000000001, -331.1, -591.5, 20.000000000000014, -707.6, -889.4, -843.2, -249.60000000000002, -201.99999999999994, -14.199999999999775, -100.19999999999995, -903.4, 20.90000000000003, -464.70000000000005, -832.5, -3.399999999999958, -644.9, -528.5000000000002, 29.000000000000167, -370.29999999999984, -1027.7, 21.800000000000047, -292.79999999999995, -1068.8000000000013, -971.0, 45.20000000000023, 11.6, 20.000000000000014, -190.20000000000005, 20.000000000000014, 13.699999999999964, -302.69999999999936, 7.399999999999967, 5.299999999999965, 7.3999999999999755, 11.299999999999978, -26.499999999999766, -202.59999999999994, 34.40000000000022, -40.89999999999986, -3.1000000000000045, -11.499999999999819, -49.89999999999982, -9.699999999999882, -3.0999999999999615, -13.599999999999808, -7.299999999999891, 20.000000000000014, 20.000000000000014, 7.399999999999967, -156.4000000000006, -135.50000000000003, 17.899999999999988, -45.09999999999977, 13.699999999999964, 20.000000000000014, 35.30000000000026, -297.7999999999985, 45.20000000000023, 20.000000000000014, 20.000000000000014, -24.099999999999767, 20.000000000000014, 20.000000000000014, -25.29999999999979, 31.100000000000204, 20.000000000000014, 17.899999999999988, -18.09999999999985, -327.1999999999984, 23.30000000000006, 41.60000000000024, 24.50000000000008, 20.000000000000014, 17.899999999999977, 9.499999999999964, 15.799999999999963, 30.20000000000019, 20.000000000000014, -36.69999999999977, -10.899999999999864, 11.599999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 29.90000000000018, -17.79999999999974, 20.000000000000014, 36.200000000000244, -99.70000000000077, 20.000000000000014, 13.699999999999964, 31.700000000000212, -330.99999999999835, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [13.0, 21.0, 3.0, 150.0, 0.0, 6.0, 11.0, 13.0, 0.0, 0.0, 0.0, 35.0, 20.0, 0.0, 0.0, 0.0, 36.0, 34.0, 0.0, 0.0, 34.0, 2.0, 19.0, 7.0, 20.0, 366.0, 1.0, 0.0, 0.0, 23.0, 0.0, 61.0, 4.0, 8.0, 11.0, 0.0, 0.0, 1.0, 13.0, 719.0, 711.0, 323.0, 668.0, 507.0, 0.0, 0.0, 871.0, 312.0, 484.0, 549.0, 635.0, 99.0, 265.0, 215.0, 327.0, 746.0, 415.0, 783.0, 297.0, 983.0, 305.0, 163.0, 197.0, 5.0, 651.0, 649.0, 380.0, 42.0, 927.0, 937.0, 14.0, 541.0, 774.0, 692.0, 322.0, 598.0, 833.0, 753.0, 0.0, 31.0, 475.0, 444.0, 269.0, 401.0, 372.0, 315.0, 409.0, 489.0, 712.0, 690.0, 688.0, 697.0, 0.0, 0.0, 0.0, 3.0, 30.0, 40.0, 511.0, 732.0, 706.0, 628.0, 428.0, 524.0, 533.0, 379.0, 451.0, 534.0, 743.0, 993.0, 224.0, 212.0, 68.0, 66.0, 548.0, 712.0, 851.0, 19.0, 458.0, 479.0, 403.0, 254.0, 766.0, 908.0, 175.0, 148.0, 1099.0, 974.0, 4.0, 4.0, 150.0, 125.0, 3.0, 0.0, 187.0, 178.0, 0.0, 19.0, 17.0, 16.0, 98.0, 106.0, 0.0, 43.0, 39.0, 21.0, 0.0, 29.0, 0.0, 29.0, 0.0, 0.0, 89.0, 38.0, 73.0, 101.0, 31.0, 3.0, 0.0, 0.0, 133.0, 215.0, 0.0, 0.0, 4.0, 17.0, 21.0, 13.0, 0.0, 2.0, 29.0, 25.0, 239.0, 97.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 0.0, 2.0, 0.0, 35.0, 0.0, 4.0, 8.0, 0.0, 17.0, 18.0, 0.0, 0.0, 29.0, 57.0, 0.0, 3.0, 132.0, 236.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.8577984414156683, "mean_inference_ms": 4.907292011920376, "mean_action_processing_ms": 0.8416122273760474, "mean_env_wait_ms": 0.6349909039223103, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013996005058288574, "StateBufferConnector_ms": 0.00493621826171875, "ViewRequirementAgentConnector_ms": 0.23296427726745605}, "num_episodes": 18, "episode_return_max": 535.5000000000009, "episode_return_min": -567.5999999999999, "episode_return_mean": 1.1220000000001313, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 245.52254565128345, "num_env_steps_trained_throughput_per_sec": 245.52254565128345, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 15324.561, "restore_workers_time_ms": 0.019, "training_step_time_ms": 15324.499, "sample_time_ms": 2498.331, "learn_time_ms": 12798.805, "learn_throughput": 312.529, "synch_weights_time_ms": 23.729}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "e57b0_00000", "date": "2024-08-13_00-19-25", "timestamp": 1723522765, "time_this_iter_s": 16.36036705970764, "time_total_s": 540.5836083889008, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b51b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 540.5836083889008, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 83.41739130434783, "ram_util_percent": 83.38260869565217}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8299264758233986, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6372239569684973, "policy_loss": -0.0005342645104974509, "vf_loss": 0.6374055464283893, "vf_explained_var": -0.0408153720949062, "kl": 0.0027865707414060394, "entropy": 1.1957049680134606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3860409223114845, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6263114897347001, "policy_loss": -0.0045761260553879085, "vf_loss": 0.6300441645992496, "vf_explained_var": -0.0012437367880785907, "kl": 0.019992927568507426, "entropy": 1.029895966582828, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 535.5000000000009, "episode_reward_min": -567.5999999999999, "episode_reward_mean": 6.402000000000165, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1070.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.20000000000023, "predator_policy": 1099.0}, "policy_reward_mean": {"prey_policy": -214.73899999999998, "predator_policy": 217.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [48.800000000000445, -462.0999999999999, -152.8999999999999, 69.2999999999999, 64.30000000000047, -567.5999999999999, -3.7000000000005002, -231.39999999999992, -136.69999999999976, -134.6, -307.09999999999997, -478.5999999999999, -212.1999999999999, -144.09999999999962, -71.49999999999989, -418.0999999999999, -277.2, -305.29999999999984, -337.4999999999999, -275.20000000000005, -53.00000000000003, -1.2999999999997343, 301.80000000000064, 49.300000000000175, 162.29999999999995, 233.69999999999945, 381.90000000000066, -17.39999999999994, 63.40000000000048, 36.70000000000025, -51.10000000000071, 23.600000000000023, 535.5000000000009, 269.20000000000016, -10.599999999999909, 297.39999999999964, 3.40000000000002, -15.600000000000044, 19.600000000000406, 377.5000000000008, -427.20000000000005, 288.6999999999997, 157.49999999999977, 275.99999999999983, 52.00000000000003, 33.20000000000003, 64.80000000000042, 104.80000000000013, 36.70000000000025, 69.6999999999997, 31.700000000000177, 17.79999999999995, 35.80000000000026, -0.999999999999949, -1.399999999999864, 16.199999999999935, 8.100000000000088, 40.0000000000003, -21.99999999999961, 56.40000000000008, 2.6000000000001586, 55.300000000000516, 95.39999999999901, 40.0000000000003, 16.89999999999993, 28.70000000000016, 53.100000000000506, 53.80000000000044, 32.10000000000019, 66.10000000000035, 38.900000000000276, 32.30000000000018, 52.20000000000049, -12.599999999999616, 35.600000000000236, 24.900000000000052, 47.10000000000042, 56.20000000000049, 6.3000000000000735, 48.40000000000044, 57.00000000000026, 40.0000000000003, 14.699999999999932, 64.3000000000005, 51.5000000000005, 6.300000000000152, 42.00000000000033, 64.80000000000044, 30.10000000000013, 55.30000000000052, 49.50000000000046, 40.0000000000003, -4.6999999999999496, 35.40000000000023, 55.300000000000516, 29.000000000000128, 19.19999999999999, 36.400000000000276, 39.700000000000294, 30.400000000000183], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, 29.90000000000018, -785.8, -408.3, -266.0, -920.9, -335.40000000000003, -770.2999999999997, 20.000000000000014, 44.30000000000024, -826.5999999999999, -924.0, -343.9000000000003, -692.8000000000002, -743.6999999999999, -221.70000000000002, -369.8, -246.8999999999999, -444.40000000000003, -763.2, -848.8, -656.3, -840.0999999999999, -918.5, -381.90000000000003, -298.3, -160.79999999999984, -185.30000000000004, -1025.7, -345.8, -543.2, -296.90000000000003, -1070.8, -1070.4, -446.2999999999999, -414.0, -1006.5, -797.0, -647.1, -548.1, -889.2, -749.8, -9.0, -23.300000000000004, -645.6, 28.40000000000016, -114.40000000000002, -506.3, -513.2, -11.499999999999819, 20.000000000000014, -684.3, -975.0, -45.09999999999998, -995.1, -407.2999999999998, 20.000000000000014, 43.40000000000023, 13.699999999999966, 20.000000000000014, -51.39999999999996, -69.70000000000084, -624.8, -594.6, -818.5, 20.000000000000014, -669.1999999999999, -13.60000000000001, -331.1, -591.5, 20.000000000000014, -707.6, -889.4, -843.2, -249.60000000000002, -201.99999999999994, -14.199999999999775, -100.19999999999995, -903.4, 20.90000000000003, -464.70000000000005, -832.5, -3.399999999999958, -644.9, -528.5000000000002, 29.000000000000167, -370.29999999999984, -1027.7, 21.800000000000047, -292.79999999999995, -1068.8000000000013, -971.0, 45.20000000000023, 11.6, 20.000000000000014, -190.20000000000005, 20.000000000000014, 13.699999999999964, -302.69999999999936, 7.399999999999967, 5.299999999999965, 7.3999999999999755, 11.299999999999978, -26.499999999999766, -202.59999999999994, 34.40000000000022, -40.89999999999986, -3.1000000000000045, -11.499999999999819, -49.89999999999982, -9.699999999999882, -3.0999999999999615, -13.599999999999808, -7.299999999999891, 20.000000000000014, 20.000000000000014, 7.399999999999967, -156.4000000000006, -135.50000000000003, 17.899999999999988, -45.09999999999977, 13.699999999999964, 20.000000000000014, 35.30000000000026, -297.7999999999985, 45.20000000000023, 20.000000000000014, 20.000000000000014, -24.099999999999767, 20.000000000000014, 20.000000000000014, -25.29999999999979, 31.100000000000204, 20.000000000000014, 17.899999999999988, -18.09999999999985, -327.1999999999984, 23.30000000000006, 41.60000000000024, 24.50000000000008, 20.000000000000014, 17.899999999999977, 9.499999999999964, 15.799999999999963, 30.20000000000019, 20.000000000000014, -36.69999999999977, -10.899999999999864, 11.599999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 29.90000000000018, -17.79999999999974, 20.000000000000014, 36.200000000000244, -99.70000000000077, 20.000000000000014, 13.699999999999964, 31.700000000000212, -330.99999999999835, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.90000000000052, 23.60000000000007, 38.900000000000254, 25.400000000000098, 24.20000000000008, 23.300000000000065, -5.199999999999941, -11.499999999999819, 20.90000000000003, 13.099999999999971, 26.300000000000114, 36.50000000000024, -30.399999999999807, 24.50000000000008, 35.30000000000026, 20.000000000000014, 41.60000000000025, -3.099999999999958, 20.000000000000014, 20.000000000000014, 3.4999999999999654, -131.2000000000004, 26.300000000000114, -4.899999999999949, 20.000000000000014, 35.30000000000026, -0.9999999999999846, 20.000000000000014, -110.20000000000056, 7.399999999999965, 20.000000000000014, -1.600000000000021, 20.000000000000014, 13.699999999999967, 11.599999999999968, -11.199999999999891], "policy_predator_policy_reward": [0.0, 1.0, 13.0, 719.0, 711.0, 323.0, 668.0, 507.0, 0.0, 0.0, 871.0, 312.0, 484.0, 549.0, 635.0, 99.0, 265.0, 215.0, 327.0, 746.0, 415.0, 783.0, 297.0, 983.0, 305.0, 163.0, 197.0, 5.0, 651.0, 649.0, 380.0, 42.0, 927.0, 937.0, 14.0, 541.0, 774.0, 692.0, 322.0, 598.0, 833.0, 753.0, 0.0, 31.0, 475.0, 444.0, 269.0, 401.0, 372.0, 315.0, 409.0, 489.0, 712.0, 690.0, 688.0, 697.0, 0.0, 0.0, 0.0, 3.0, 30.0, 40.0, 511.0, 732.0, 706.0, 628.0, 428.0, 524.0, 533.0, 379.0, 451.0, 534.0, 743.0, 993.0, 224.0, 212.0, 68.0, 66.0, 548.0, 712.0, 851.0, 19.0, 458.0, 479.0, 403.0, 254.0, 766.0, 908.0, 175.0, 148.0, 1099.0, 974.0, 4.0, 4.0, 150.0, 125.0, 3.0, 0.0, 187.0, 178.0, 0.0, 19.0, 17.0, 16.0, 98.0, 106.0, 0.0, 43.0, 39.0, 21.0, 0.0, 29.0, 0.0, 29.0, 0.0, 0.0, 89.0, 38.0, 73.0, 101.0, 31.0, 3.0, 0.0, 0.0, 133.0, 215.0, 0.0, 0.0, 4.0, 17.0, 21.0, 13.0, 0.0, 2.0, 29.0, 25.0, 239.0, 97.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 0.0, 2.0, 0.0, 35.0, 0.0, 4.0, 8.0, 0.0, 17.0, 18.0, 0.0, 0.0, 29.0, 57.0, 0.0, 3.0, 132.0, 236.0, 0.0, 0.0, 79.0, 58.0, 0.0, 0.0, 0.0, 4.0, 23.0, 0.0, 8.0, 0.0, 0.0, 2.0, 12.0, 24.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 82.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 10.0, 54.0, 68.0, 0.0, 18.0, 6.0, 0.0, 30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.830707421105826, "mean_inference_ms": 4.844954033865233, "mean_action_processing_ms": 0.8566202641825253, "mean_env_wait_ms": 0.6258517157340929, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01847076416015625, "StateBufferConnector_ms": 0.0048732757568359375, "ViewRequirementAgentConnector_ms": 0.21562647819519043}, "num_episodes": 18, "episode_return_max": 535.5000000000009, "episode_return_min": -567.5999999999999, "episode_return_mean": 6.402000000000165, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 265.91819354081184, "num_env_steps_trained_throughput_per_sec": 265.91819354081184, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 15062.371, "restore_workers_time_ms": 0.019, "training_step_time_ms": 15062.299, "sample_time_ms": 2470.722, "learn_time_ms": 12566.556, "learn_throughput": 318.305, "synch_weights_time_ms": 21.141}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "e57b0_00000", "date": "2024-08-13_00-19-40", "timestamp": 1723522780, "time_this_iter_s": 15.211094856262207, "time_total_s": 555.794703245163, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b51dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 555.794703245163, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 80.92727272727274, "ram_util_percent": 83.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7564872677364046, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2172038340852374, "policy_loss": -0.002130306097457097, "vf_loss": 1.2188062273636067, "vf_explained_var": -0.009514658633994047, "kl": 0.008342331939943347, "entropy": 1.1578864083088265, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43123006956287163, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0603449453121772, "policy_loss": -0.0010172784486144938, "vf_loss": 1.0612144740958693, "vf_explained_var": 0.0007338451645361683, "kl": 0.0035022124670491595, "entropy": 1.0017784706183843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 535.5000000000009, "episode_reward_min": -427.20000000000005, "episode_reward_mean": 45.24700000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1068.8000000000013, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.20000000000023, "predator_policy": 1099.0}, "policy_reward_mean": {"prey_policy": -81.76649999999997, "predator_policy": 104.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.39999999999994, 63.40000000000048, 36.70000000000025, -51.10000000000071, 23.600000000000023, 535.5000000000009, 269.20000000000016, -10.599999999999909, 297.39999999999964, 3.40000000000002, -15.600000000000044, 19.600000000000406, 377.5000000000008, -427.20000000000005, 288.6999999999997, 157.49999999999977, 275.99999999999983, 52.00000000000003, 33.20000000000003, 64.80000000000042, 104.80000000000013, 36.70000000000025, 69.6999999999997, 31.700000000000177, 17.79999999999995, 35.80000000000026, -0.999999999999949, -1.399999999999864, 16.199999999999935, 8.100000000000088, 40.0000000000003, -21.99999999999961, 56.40000000000008, 2.6000000000001586, 55.300000000000516, 95.39999999999901, 40.0000000000003, 16.89999999999993, 28.70000000000016, 53.100000000000506, 53.80000000000044, 32.10000000000019, 66.10000000000035, 38.900000000000276, 32.30000000000018, 52.20000000000049, -12.599999999999616, 35.600000000000236, 24.900000000000052, 47.10000000000042, 56.20000000000049, 6.3000000000000735, 48.40000000000044, 57.00000000000026, 40.0000000000003, 14.699999999999932, 64.3000000000005, 51.5000000000005, 6.300000000000152, 42.00000000000033, 64.80000000000044, 30.10000000000013, 55.30000000000052, 49.50000000000046, 40.0000000000003, -4.6999999999999496, 35.40000000000023, 55.300000000000516, 29.000000000000128, 19.19999999999999, 36.400000000000276, 39.700000000000294, 30.400000000000183, 47.20000000000042, 40.200000000000294, 40.0000000000003, 40.90000000000031, 37.50000000000026, -54.800000000000935, 31.600000000000186, 14.699999999999987, 11.40000000000003, 33.900000000000205, 15.899999999999947, 46.300000000000395, 40.0000000000003, 27.400000000000116, 36.700000000000244, 35.00000000000021, 31.60000000000018, -5.499999999999719, 69.70000000000012, 17.69999999999995, 40.0000000000003, -2.2999999999997582, -60.400000000001086, -21.699999999999676, 40.0000000000003, 40.0000000000003, 32.800000000000196], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-995.1, -407.2999999999998, 20.000000000000014, 43.40000000000023, 13.699999999999966, 20.000000000000014, -51.39999999999996, -69.70000000000084, -624.8, -594.6, -818.5, 20.000000000000014, -669.1999999999999, -13.60000000000001, -331.1, -591.5, 20.000000000000014, -707.6, -889.4, -843.2, -249.60000000000002, -201.99999999999994, -14.199999999999775, -100.19999999999995, -903.4, 20.90000000000003, -464.70000000000005, -832.5, -3.399999999999958, -644.9, -528.5000000000002, 29.000000000000167, -370.29999999999984, -1027.7, 21.800000000000047, -292.79999999999995, -1068.8000000000013, -971.0, 45.20000000000023, 11.6, 20.000000000000014, -190.20000000000005, 20.000000000000014, 13.699999999999964, -302.69999999999936, 7.399999999999967, 5.299999999999965, 7.3999999999999755, 11.299999999999978, -26.499999999999766, -202.59999999999994, 34.40000000000022, -40.89999999999986, -3.1000000000000045, -11.499999999999819, -49.89999999999982, -9.699999999999882, -3.0999999999999615, -13.599999999999808, -7.299999999999891, 20.000000000000014, 20.000000000000014, 7.399999999999967, -156.4000000000006, -135.50000000000003, 17.899999999999988, -45.09999999999977, 13.699999999999964, 20.000000000000014, 35.30000000000026, -297.7999999999985, 45.20000000000023, 20.000000000000014, 20.000000000000014, -24.099999999999767, 20.000000000000014, 20.000000000000014, -25.29999999999979, 31.100000000000204, 20.000000000000014, 17.899999999999988, -18.09999999999985, -327.1999999999984, 23.30000000000006, 41.60000000000024, 24.50000000000008, 20.000000000000014, 17.899999999999977, 9.499999999999964, 15.799999999999963, 30.20000000000019, 20.000000000000014, -36.69999999999977, -10.899999999999864, 11.599999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 29.90000000000018, -17.79999999999974, 20.000000000000014, 36.200000000000244, -99.70000000000077, 20.000000000000014, 13.699999999999964, 31.700000000000212, -330.99999999999835, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.90000000000052, 23.60000000000007, 38.900000000000254, 25.400000000000098, 24.20000000000008, 23.300000000000065, -5.199999999999941, -11.499999999999819, 20.90000000000003, 13.099999999999971, 26.300000000000114, 36.50000000000024, -30.399999999999807, 24.50000000000008, 35.30000000000026, 20.000000000000014, 41.60000000000025, -3.099999999999958, 20.000000000000014, 20.000000000000014, 3.4999999999999654, -131.2000000000004, 26.300000000000114, -4.899999999999949, 20.000000000000014, 35.30000000000026, -0.9999999999999846, 20.000000000000014, -110.20000000000056, 7.399999999999965, 20.000000000000014, -1.600000000000021, 20.000000000000014, 13.699999999999967, 11.599999999999968, -11.199999999999891, 22.700000000000053, 24.500000000000085, 12.199999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999968, 20.000000000000014, -124.90000000000074, -10.89999999999987, -30.39999999999978, 20.000000000000014, 20.000000000000014, -28.29999999999975, -21.99999999999976, 13.399999999999968, 1.09999999999996, 15.799999999999963, 13.999999999999966, -33.09999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, -36.69999999999977, 37.10000000000025, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999787, -3.3999999999999724, 20.000000000000014, 20.000000000000014, -74.50000000000088, 38.900000000000254, 30.800000000000196, -28.299999999999798, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, -118.6000000000006, -59.80000000000042, -32.499999999999815, -26.19999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.7999999999999656, 20.000000000000014], "policy_predator_policy_reward": [688.0, 697.0, 0.0, 0.0, 0.0, 3.0, 30.0, 40.0, 511.0, 732.0, 706.0, 628.0, 428.0, 524.0, 533.0, 379.0, 451.0, 534.0, 743.0, 993.0, 224.0, 212.0, 68.0, 66.0, 548.0, 712.0, 851.0, 19.0, 458.0, 479.0, 403.0, 254.0, 766.0, 908.0, 175.0, 148.0, 1099.0, 974.0, 4.0, 4.0, 150.0, 125.0, 3.0, 0.0, 187.0, 178.0, 0.0, 19.0, 17.0, 16.0, 98.0, 106.0, 0.0, 43.0, 39.0, 21.0, 0.0, 29.0, 0.0, 29.0, 0.0, 0.0, 89.0, 38.0, 73.0, 101.0, 31.0, 3.0, 0.0, 0.0, 133.0, 215.0, 0.0, 0.0, 4.0, 17.0, 21.0, 13.0, 0.0, 2.0, 29.0, 25.0, 239.0, 97.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 0.0, 2.0, 0.0, 35.0, 0.0, 4.0, 8.0, 0.0, 17.0, 18.0, 0.0, 0.0, 29.0, 57.0, 0.0, 3.0, 132.0, 236.0, 0.0, 0.0, 79.0, 58.0, 0.0, 0.0, 0.0, 4.0, 23.0, 0.0, 8.0, 0.0, 0.0, 2.0, 12.0, 24.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 82.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 10.0, 54.0, 68.0, 0.0, 18.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 39.0, 42.0, 20.0, 22.0, 23.0, 0.0, 20.0, 0.0, 17.0, 0.0, 8.0, 27.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 3.0, 19.0, 18.0, 0.0, 15.0, 16.0, 33.0, 0.0, 0.0, 3.0, 23.0, 0.0, 0.0, 23.0, 25.0, 52.0, 66.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.800431887019255, "mean_inference_ms": 4.7708555311009535, "mean_action_processing_ms": 0.8755986207521164, "mean_env_wait_ms": 0.6165708751302662, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01785135269165039, "StateBufferConnector_ms": 0.009420394897460938, "ViewRequirementAgentConnector_ms": 0.1826612949371338}, "num_episodes": 27, "episode_return_max": 535.5000000000009, "episode_return_min": -427.20000000000005, "episode_return_mean": 45.24700000000016, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.77984896162374, "num_env_steps_trained_throughput_per_sec": 129.77984896162374, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 16714.964, "restore_workers_time_ms": 0.02, "training_step_time_ms": 16714.891, "sample_time_ms": 2540.868, "learn_time_ms": 14144.93, "learn_throughput": 282.787, "synch_weights_time_ms": 25.036}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "e57b0_00000", "date": "2024-08-13_00-20-12", "timestamp": 1723522812, "time_this_iter_s": 31.375036001205444, "time_total_s": 587.1697392463684, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bb670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 587.1697392463684, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 96.91666666666667, "ram_util_percent": 83.93571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7720508903619789, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6906238014105135, "policy_loss": -0.004187070067094826, "vf_loss": 1.6938906807117362, "vf_explained_var": -0.00902990597896475, "kl": 0.014541283283371828, "entropy": 1.255534504645716, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40332438420287514, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.605384662258562, "policy_loss": -0.0016830851800651069, "vf_loss": 1.6069257424306618, "vf_explained_var": 0.002605700902837925, "kl": 0.0067318455518212235, "entropy": 0.9645801933354171, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 104.80000000000013, "episode_reward_min": -60.400000000001086, "episode_reward_mean": 30.4200000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1068.8000000000013, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.20000000000023, "predator_policy": 1099.0}, "policy_reward_mean": {"prey_policy": -17.744999999999976, "predator_policy": 32.955}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.20000000000003, 64.80000000000042, 104.80000000000013, 36.70000000000025, 69.6999999999997, 31.700000000000177, 17.79999999999995, 35.80000000000026, -0.999999999999949, -1.399999999999864, 16.199999999999935, 8.100000000000088, 40.0000000000003, -21.99999999999961, 56.40000000000008, 2.6000000000001586, 55.300000000000516, 95.39999999999901, 40.0000000000003, 16.89999999999993, 28.70000000000016, 53.100000000000506, 53.80000000000044, 32.10000000000019, 66.10000000000035, 38.900000000000276, 32.30000000000018, 52.20000000000049, -12.599999999999616, 35.600000000000236, 24.900000000000052, 47.10000000000042, 56.20000000000049, 6.3000000000000735, 48.40000000000044, 57.00000000000026, 40.0000000000003, 14.699999999999932, 64.3000000000005, 51.5000000000005, 6.300000000000152, 42.00000000000033, 64.80000000000044, 30.10000000000013, 55.30000000000052, 49.50000000000046, 40.0000000000003, -4.6999999999999496, 35.40000000000023, 55.300000000000516, 29.000000000000128, 19.19999999999999, 36.400000000000276, 39.700000000000294, 30.400000000000183, 47.20000000000042, 40.200000000000294, 40.0000000000003, 40.90000000000031, 37.50000000000026, -54.800000000000935, 31.600000000000186, 14.699999999999987, 11.40000000000003, 33.900000000000205, 15.899999999999947, 46.300000000000395, 40.0000000000003, 27.400000000000116, 36.700000000000244, 35.00000000000021, 31.60000000000018, -5.499999999999719, 69.70000000000012, 17.69999999999995, 40.0000000000003, -2.2999999999997582, -60.400000000001086, -21.699999999999676, 40.0000000000003, 40.0000000000003, 32.800000000000196, 15.699999999999944, -10.099999999999667, 73.39999999999982, 41.800000000000324, 38.900000000000276, -1.7999999999998857, 41.50000000000033, -3.999999999999724, -31.79999999999962, 43.5000000000004, 21.900000000000034, -11.399999999999642, -17.499999999999602, 59.800000000000495, 61.90000000000046, 11.599999999999984, 57.90000000000049, 4.600000000000136], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1068.8000000000013, -971.0, 45.20000000000023, 11.6, 20.000000000000014, -190.20000000000005, 20.000000000000014, 13.699999999999964, -302.69999999999936, 7.399999999999967, 5.299999999999965, 7.3999999999999755, 11.299999999999978, -26.499999999999766, -202.59999999999994, 34.40000000000022, -40.89999999999986, -3.1000000000000045, -11.499999999999819, -49.89999999999982, -9.699999999999882, -3.0999999999999615, -13.599999999999808, -7.299999999999891, 20.000000000000014, 20.000000000000014, 7.399999999999967, -156.4000000000006, -135.50000000000003, 17.899999999999988, -45.09999999999977, 13.699999999999964, 20.000000000000014, 35.30000000000026, -297.7999999999985, 45.20000000000023, 20.000000000000014, 20.000000000000014, -24.099999999999767, 20.000000000000014, 20.000000000000014, -25.29999999999979, 31.100000000000204, 20.000000000000014, 17.899999999999988, -18.09999999999985, -327.1999999999984, 23.30000000000006, 41.60000000000024, 24.50000000000008, 20.000000000000014, 17.899999999999977, 9.499999999999964, 15.799999999999963, 30.20000000000019, 20.000000000000014, -36.69999999999977, -10.899999999999864, 11.599999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 29.90000000000018, -17.79999999999974, 20.000000000000014, 36.200000000000244, -99.70000000000077, 20.000000000000014, 13.699999999999964, 31.700000000000212, -330.99999999999835, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.90000000000052, 23.60000000000007, 38.900000000000254, 25.400000000000098, 24.20000000000008, 23.300000000000065, -5.199999999999941, -11.499999999999819, 20.90000000000003, 13.099999999999971, 26.300000000000114, 36.50000000000024, -30.399999999999807, 24.50000000000008, 35.30000000000026, 20.000000000000014, 41.60000000000025, -3.099999999999958, 20.000000000000014, 20.000000000000014, 3.4999999999999654, -131.2000000000004, 26.300000000000114, -4.899999999999949, 20.000000000000014, 35.30000000000026, -0.9999999999999846, 20.000000000000014, -110.20000000000056, 7.399999999999965, 20.000000000000014, -1.600000000000021, 20.000000000000014, 13.699999999999967, 11.599999999999968, -11.199999999999891, 22.700000000000053, 24.500000000000085, 12.199999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999968, 20.000000000000014, -124.90000000000074, -10.89999999999987, -30.39999999999978, 20.000000000000014, 20.000000000000014, -28.29999999999975, -21.99999999999976, 13.399999999999968, 1.09999999999996, 15.799999999999963, 13.999999999999966, -33.09999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, -36.69999999999977, 37.10000000000025, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999787, -3.3999999999999724, 20.000000000000014, 20.000000000000014, -74.50000000000088, 38.900000000000254, 30.800000000000196, -28.299999999999798, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, -118.6000000000006, -59.80000000000042, -32.499999999999815, -26.19999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.7999999999999656, 20.000000000000014, -31.299999999999763, 20.000000000000014, -147.20000000000073, -19.899999999999743, 30.50000000000024, 38.900000000000254, 20.000000000000014, 21.80000000000004, 17.899999999999984, 20.000000000000014, 20.000000000000014, -59.800000000000395, 15.499999999999963, 20.000000000000014, 15.799999999999963, -59.80000000000062, -24.09999999999979, -63.70000000000062, 7.999999999999984, 15.499999999999961, 20.000000000000014, -45.09999999999981, 3.7999999999999745, -62.20000000000077, -68.2000000000007, -16.299999999999777, 39.80000000000024, 20.000000000000014, 20.000000000000014, 38.90000000000022, -15.099999999999802, -7.299999999999891, 7.099999999999966, 39.80000000000024, -70.30000000000088, 8.89999999999997], "policy_predator_policy_reward": [1099.0, 974.0, 4.0, 4.0, 150.0, 125.0, 3.0, 0.0, 187.0, 178.0, 0.0, 19.0, 17.0, 16.0, 98.0, 106.0, 0.0, 43.0, 39.0, 21.0, 0.0, 29.0, 0.0, 29.0, 0.0, 0.0, 89.0, 38.0, 73.0, 101.0, 31.0, 3.0, 0.0, 0.0, 133.0, 215.0, 0.0, 0.0, 4.0, 17.0, 21.0, 13.0, 0.0, 2.0, 29.0, 25.0, 239.0, 97.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 0.0, 2.0, 0.0, 35.0, 0.0, 4.0, 8.0, 0.0, 17.0, 18.0, 0.0, 0.0, 29.0, 57.0, 0.0, 3.0, 132.0, 236.0, 0.0, 0.0, 79.0, 58.0, 0.0, 0.0, 0.0, 4.0, 23.0, 0.0, 8.0, 0.0, 0.0, 2.0, 12.0, 24.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 82.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 10.0, 54.0, 68.0, 0.0, 18.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 39.0, 42.0, 20.0, 22.0, 23.0, 0.0, 20.0, 0.0, 17.0, 0.0, 8.0, 27.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 3.0, 19.0, 18.0, 0.0, 15.0, 16.0, 33.0, 0.0, 0.0, 3.0, 23.0, 0.0, 0.0, 23.0, 25.0, 52.0, 66.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 27.0, 0.0, 89.0, 68.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 21.0, 0.0, 6.0, 12.0, 28.0, 11.0, 45.0, 1.0, 19.0, 27.0, 20.0, 2.0, 45.0, 39.0, 28.0, 0.0, 0.0, 3.0, 0.0, 34.0, 0.0, 5.0, 6.0, 43.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.786651836289515, "mean_inference_ms": 4.746419788761513, "mean_action_processing_ms": 0.8653414045455436, "mean_env_wait_ms": 0.6126431908088544, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012174487113952637, "StateBufferConnector_ms": 0.009444832801818848, "ViewRequirementAgentConnector_ms": 0.2234436273574829}, "num_episodes": 18, "episode_return_max": 104.80000000000013, "episode_return_min": -60.400000000001086, "episode_return_mean": 30.4200000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 169.03471068031922, "num_env_steps_trained_throughput_per_sec": 169.03471068031922, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 17817.775, "restore_workers_time_ms": 0.186, "training_step_time_ms": 17817.061, "sample_time_ms": 2962.707, "learn_time_ms": 14825.879, "learn_throughput": 269.799, "synch_weights_time_ms": 24.879}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "e57b0_00000", "date": "2024-08-13_00-20-36", "timestamp": 1723522836, "time_this_iter_s": 23.74345302581787, "time_total_s": 610.9131922721863, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09dbd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 610.9131922721863, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 88.028125, "ram_util_percent": 83.9}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8242739874573927, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0838229440192066, "policy_loss": -0.0023369811642816457, "vf_loss": 1.0853879748986512, "vf_explained_var": -0.02765451855760403, "kl": 0.012198757114537998, "entropy": 1.252846567719071, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35537459920086556, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0041389392166542, "policy_loss": -0.007732882432851487, "vf_loss": 1.0114852880753538, "vf_explained_var": 0.007937109943420168, "kl": 0.018324614065506215, "entropy": 0.9148106621686743, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 75.09999999999971, "episode_reward_min": -60.400000000001086, "episode_reward_mean": 27.631000000000217, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -330.99999999999835, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.60000000000025, "predator_policy": 239.0}, "policy_reward_mean": {"prey_policy": -2.0344999999999707, "predator_policy": 15.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 16.89999999999993, 28.70000000000016, 53.100000000000506, 53.80000000000044, 32.10000000000019, 66.10000000000035, 38.900000000000276, 32.30000000000018, 52.20000000000049, -12.599999999999616, 35.600000000000236, 24.900000000000052, 47.10000000000042, 56.20000000000049, 6.3000000000000735, 48.40000000000044, 57.00000000000026, 40.0000000000003, 14.699999999999932, 64.3000000000005, 51.5000000000005, 6.300000000000152, 42.00000000000033, 64.80000000000044, 30.10000000000013, 55.30000000000052, 49.50000000000046, 40.0000000000003, -4.6999999999999496, 35.40000000000023, 55.300000000000516, 29.000000000000128, 19.19999999999999, 36.400000000000276, 39.700000000000294, 30.400000000000183, 47.20000000000042, 40.200000000000294, 40.0000000000003, 40.90000000000031, 37.50000000000026, -54.800000000000935, 31.600000000000186, 14.699999999999987, 11.40000000000003, 33.900000000000205, 15.899999999999947, 46.300000000000395, 40.0000000000003, 27.400000000000116, 36.700000000000244, 35.00000000000021, 31.60000000000018, -5.499999999999719, 69.70000000000012, 17.69999999999995, 40.0000000000003, -2.2999999999997582, -60.400000000001086, -21.699999999999676, 40.0000000000003, 40.0000000000003, 32.800000000000196, 15.699999999999944, -10.099999999999667, 73.39999999999982, 41.800000000000324, 38.900000000000276, -1.7999999999998857, 41.50000000000033, -3.999999999999724, -31.79999999999962, 43.5000000000004, 21.900000000000034, -11.399999999999642, -17.499999999999602, 59.800000000000495, 61.90000000000046, 11.599999999999984, 57.90000000000049, 4.600000000000136, -22.299999999999542, 13.799999999999969, 40.0000000000003, -8.39999999999966, 8.900000000000029, 45.20000000000039, -29.29999999999957, -39.400000000000134, 62.500000000000504, -40.49999999999998, 28.700000000000113, 75.09999999999971, 26.70000000000011, 55.30000000000052, 36.40000000000023, 49.00000000000045, 35.600000000000236, 27.90000000000011], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -24.099999999999767, 20.000000000000014, 20.000000000000014, -25.29999999999979, 31.100000000000204, 20.000000000000014, 17.899999999999988, -18.09999999999985, -327.1999999999984, 23.30000000000006, 41.60000000000024, 24.50000000000008, 20.000000000000014, 17.899999999999977, 9.499999999999964, 15.799999999999963, 30.20000000000019, 20.000000000000014, -36.69999999999977, -10.899999999999864, 11.599999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 29.90000000000018, -17.79999999999974, 20.000000000000014, 36.200000000000244, -99.70000000000077, 20.000000000000014, 13.699999999999964, 31.700000000000212, -330.99999999999835, 20.000000000000014, 20.000000000000014, 20.000000000000014, -145.90000000000052, 23.60000000000007, 38.900000000000254, 25.400000000000098, 24.20000000000008, 23.300000000000065, -5.199999999999941, -11.499999999999819, 20.90000000000003, 13.099999999999971, 26.300000000000114, 36.50000000000024, -30.399999999999807, 24.50000000000008, 35.30000000000026, 20.000000000000014, 41.60000000000025, -3.099999999999958, 20.000000000000014, 20.000000000000014, 3.4999999999999654, -131.2000000000004, 26.300000000000114, -4.899999999999949, 20.000000000000014, 35.30000000000026, -0.9999999999999846, 20.000000000000014, -110.20000000000056, 7.399999999999965, 20.000000000000014, -1.600000000000021, 20.000000000000014, 13.699999999999967, 11.599999999999968, -11.199999999999891, 22.700000000000053, 24.500000000000085, 12.199999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999968, 20.000000000000014, -124.90000000000074, -10.89999999999987, -30.39999999999978, 20.000000000000014, 20.000000000000014, -28.29999999999975, -21.99999999999976, 13.399999999999968, 1.09999999999996, 15.799999999999963, 13.999999999999966, -33.09999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, -36.69999999999977, 37.10000000000025, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999787, -3.3999999999999724, 20.000000000000014, 20.000000000000014, -74.50000000000088, 38.900000000000254, 30.800000000000196, -28.299999999999798, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, -118.6000000000006, -59.80000000000042, -32.499999999999815, -26.19999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.7999999999999656, 20.000000000000014, -31.299999999999763, 20.000000000000014, -147.20000000000073, -19.899999999999743, 30.50000000000024, 38.900000000000254, 20.000000000000014, 21.80000000000004, 17.899999999999984, 20.000000000000014, 20.000000000000014, -59.800000000000395, 15.499999999999963, 20.000000000000014, 15.799999999999963, -59.80000000000062, -24.09999999999979, -63.70000000000062, 7.999999999999984, 15.499999999999961, 20.000000000000014, -45.09999999999981, 3.7999999999999745, -62.20000000000077, -68.2000000000007, -16.299999999999777, 39.80000000000024, 20.000000000000014, 20.000000000000014, 38.90000000000022, -15.099999999999802, -7.299999999999891, 7.099999999999966, 39.80000000000024, -70.30000000000088, 8.89999999999997, -42.69999999999977, -13.599999999999815, -61.900000000000766, 31.700000000000216, 20.000000000000014, 20.000000000000014, -38.799999999999756, -13.599999999999833, -15.699999999999747, -9.399999999999904, 25.4000000000001, 15.799999999999963, -1.000000000000031, -91.30000000000061, -33.999999999999766, -33.399999999999764, 36.200000000000244, 26.300000000000118, -53.50000000000008, -42.999999999999794, -7.299999999999962, 20.000000000000014, 37.10000000000026, 38.00000000000025, -42.99999999999979, 13.699999999999967, 35.30000000000026, 20.000000000000014, 7.399999999999981, 20.000000000000014, 29.000000000000163, 20.000000000000014, 15.799999999999963, 15.799999999999962, -3.099999999999958, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 4.0, 17.0, 21.0, 13.0, 0.0, 2.0, 29.0, 25.0, 239.0, 97.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 0.0, 2.0, 0.0, 35.0, 0.0, 4.0, 8.0, 0.0, 17.0, 18.0, 0.0, 0.0, 29.0, 57.0, 0.0, 3.0, 132.0, 236.0, 0.0, 0.0, 79.0, 58.0, 0.0, 0.0, 0.0, 4.0, 23.0, 0.0, 8.0, 0.0, 0.0, 2.0, 12.0, 24.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 82.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 10.0, 54.0, 68.0, 0.0, 18.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 39.0, 42.0, 20.0, 22.0, 23.0, 0.0, 20.0, 0.0, 17.0, 0.0, 8.0, 27.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 3.0, 19.0, 18.0, 0.0, 15.0, 16.0, 33.0, 0.0, 0.0, 3.0, 23.0, 0.0, 0.0, 23.0, 25.0, 52.0, 66.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 27.0, 0.0, 89.0, 68.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 21.0, 0.0, 6.0, 12.0, 28.0, 11.0, 45.0, 1.0, 19.0, 27.0, 20.0, 2.0, 45.0, 39.0, 28.0, 0.0, 0.0, 3.0, 0.0, 34.0, 0.0, 5.0, 6.0, 43.0, 23.0, 6.0, 28.0, 39.0, 5.0, 0.0, 0.0, 44.0, 0.0, 0.0, 34.0, 0.0, 4.0, 26.0, 37.0, 0.0, 28.0, 0.0, 0.0, 28.0, 28.0, 16.0, 0.0, 0.0, 0.0, 28.0, 28.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.7813557236934274, "mean_inference_ms": 4.742734433638559, "mean_action_processing_ms": 0.860528062638611, "mean_env_wait_ms": 0.6134496899039231, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011552810668945312, "StateBufferConnector_ms": 0.011731147766113281, "ViewRequirementAgentConnector_ms": 0.2634693384170532}, "num_episodes": 18, "episode_return_max": 75.09999999999971, "episode_return_min": -60.400000000001086, "episode_return_mean": 27.631000000000217, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.94281329347544, "num_env_steps_trained_throughput_per_sec": 157.94281329347544, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 19039.619, "restore_workers_time_ms": 0.187, "training_step_time_ms": 19038.905, "sample_time_ms": 3283.561, "learn_time_ms": 15727.321, "learn_throughput": 254.334, "synch_weights_time_ms": 24.799}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "e57b0_00000", "date": "2024-08-13_00-21-02", "timestamp": 1723522862, "time_this_iter_s": 25.56574583053589, "time_total_s": 636.4789381027222, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09fbca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 636.4789381027222, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 93.30555555555556, "ram_util_percent": 83.78333333333336}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7048939267439501, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5427186160333572, "policy_loss": -0.0032497137733217742, "vf_loss": 1.5447911071871954, "vf_explained_var": -0.012583814663861794, "kl": 0.018603054302403416, "entropy": 1.278470323325465, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.34158342984066437, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.239140738948943, "policy_loss": -0.003974453335204137, "vf_loss": 1.242862311667866, "vf_explained_var": 0.0028927493347692744, "kl": 0.011988447616049938, "entropy": 0.891490341305102, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 75.09999999999971, "episode_reward_min": -60.400000000001086, "episode_reward_mean": 22.876000000000193, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -147.20000000000073, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.60000000000025, "predator_policy": 89.0}, "policy_reward_mean": {"prey_policy": -2.636999999999988, "predator_policy": 14.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 14.699999999999932, 64.3000000000005, 51.5000000000005, 6.300000000000152, 42.00000000000033, 64.80000000000044, 30.10000000000013, 55.30000000000052, 49.50000000000046, 40.0000000000003, -4.6999999999999496, 35.40000000000023, 55.300000000000516, 29.000000000000128, 19.19999999999999, 36.400000000000276, 39.700000000000294, 30.400000000000183, 47.20000000000042, 40.200000000000294, 40.0000000000003, 40.90000000000031, 37.50000000000026, -54.800000000000935, 31.600000000000186, 14.699999999999987, 11.40000000000003, 33.900000000000205, 15.899999999999947, 46.300000000000395, 40.0000000000003, 27.400000000000116, 36.700000000000244, 35.00000000000021, 31.60000000000018, -5.499999999999719, 69.70000000000012, 17.69999999999995, 40.0000000000003, -2.2999999999997582, -60.400000000001086, -21.699999999999676, 40.0000000000003, 40.0000000000003, 32.800000000000196, 15.699999999999944, -10.099999999999667, 73.39999999999982, 41.800000000000324, 38.900000000000276, -1.7999999999998857, 41.50000000000033, -3.999999999999724, -31.79999999999962, 43.5000000000004, 21.900000000000034, -11.399999999999642, -17.499999999999602, 59.800000000000495, 61.90000000000046, 11.599999999999984, 57.90000000000049, 4.600000000000136, -22.299999999999542, 13.799999999999969, 40.0000000000003, -8.39999999999966, 8.900000000000029, 45.20000000000039, -29.29999999999957, -39.400000000000134, 62.500000000000504, -40.49999999999998, 28.700000000000113, 75.09999999999971, 26.70000000000011, 55.30000000000052, 36.40000000000023, 49.00000000000045, 35.600000000000236, 27.90000000000011, 12.49999999999992, 11.399999999999922, 10.500000000000005, 5.800000000000068, 19.599999999999977, -25.999999999999595, 12.599999999999994, -3.9999999999997384, -14.299999999999596, -6.399999999999798, 37.700000000000266, 34.0000000000002, 40.3000000000003, -11.799999999999725, 11.900000000000025, 40.0000000000003, 12.699999999999958, 14.999999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -145.90000000000052, 23.60000000000007, 38.900000000000254, 25.400000000000098, 24.20000000000008, 23.300000000000065, -5.199999999999941, -11.499999999999819, 20.90000000000003, 13.099999999999971, 26.300000000000114, 36.50000000000024, -30.399999999999807, 24.50000000000008, 35.30000000000026, 20.000000000000014, 41.60000000000025, -3.099999999999958, 20.000000000000014, 20.000000000000014, 3.4999999999999654, -131.2000000000004, 26.300000000000114, -4.899999999999949, 20.000000000000014, 35.30000000000026, -0.9999999999999846, 20.000000000000014, -110.20000000000056, 7.399999999999965, 20.000000000000014, -1.600000000000021, 20.000000000000014, 13.699999999999967, 11.599999999999968, -11.199999999999891, 22.700000000000053, 24.500000000000085, 12.199999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.900000000000027, 20.000000000000014, 9.499999999999968, 20.000000000000014, -124.90000000000074, -10.89999999999987, -30.39999999999978, 20.000000000000014, 20.000000000000014, -28.29999999999975, -21.99999999999976, 13.399999999999968, 1.09999999999996, 15.799999999999963, 13.999999999999966, -33.09999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, -36.69999999999977, 37.10000000000025, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999787, -3.3999999999999724, 20.000000000000014, 20.000000000000014, -74.50000000000088, 38.900000000000254, 30.800000000000196, -28.299999999999798, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, -118.6000000000006, -59.80000000000042, -32.499999999999815, -26.19999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.7999999999999656, 20.000000000000014, -31.299999999999763, 20.000000000000014, -147.20000000000073, -19.899999999999743, 30.50000000000024, 38.900000000000254, 20.000000000000014, 21.80000000000004, 17.899999999999984, 20.000000000000014, 20.000000000000014, -59.800000000000395, 15.499999999999963, 20.000000000000014, 15.799999999999963, -59.80000000000062, -24.09999999999979, -63.70000000000062, 7.999999999999984, 15.499999999999961, 20.000000000000014, -45.09999999999981, 3.7999999999999745, -62.20000000000077, -68.2000000000007, -16.299999999999777, 39.80000000000024, 20.000000000000014, 20.000000000000014, 38.90000000000022, -15.099999999999802, -7.299999999999891, 7.099999999999966, 39.80000000000024, -70.30000000000088, 8.89999999999997, -42.69999999999977, -13.599999999999815, -61.900000000000766, 31.700000000000216, 20.000000000000014, 20.000000000000014, -38.799999999999756, -13.599999999999833, -15.699999999999747, -9.399999999999904, 25.4000000000001, 15.799999999999963, -1.000000000000031, -91.30000000000061, -33.999999999999766, -33.399999999999764, 36.200000000000244, 26.300000000000118, -53.50000000000008, -42.999999999999794, -7.299999999999962, 20.000000000000014, 37.10000000000026, 38.00000000000025, -42.99999999999979, 13.699999999999967, 35.30000000000026, 20.000000000000014, 7.399999999999981, 20.000000000000014, 29.000000000000163, 20.000000000000014, 15.799999999999963, 15.799999999999962, -3.099999999999958, 20.000000000000014, 20.000000000000014, -32.49999999999981, -34.5999999999998, 20.000000000000014, -12.699999999999847, -2.8000000000000185, -55.60000000000025, 25.400000000000098, 20.000000000000014, -21.39999999999975, -30.399999999999785, -28.599999999999802, 20.000000000000014, -36.399999999999764, 20.000000000000014, -64.00000000000091, -82.90000000000077, 11.599999999999964, -38.79999999999986, -28.59999999999981, 10.699999999999967, 20.000000000000014, -42.99999999999981, 20.000000000000014, 23.600000000000065, -13.299999999999812, -34.599999999999824, -47.19999999999981, 22.700000000000053, -38.799999999999756, 20.000000000000014, 20.000000000000014, -19.899999999999757, -36.39999999999981, 15.799999999999963, -26.799999999999756], "policy_predator_policy_reward": [0.0, 0.0, 79.0, 58.0, 0.0, 0.0, 0.0, 4.0, 23.0, 0.0, 8.0, 0.0, 0.0, 2.0, 12.0, 24.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 82.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 10.0, 54.0, 68.0, 0.0, 18.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 39.0, 42.0, 20.0, 22.0, 23.0, 0.0, 20.0, 0.0, 17.0, 0.0, 8.0, 27.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 3.0, 19.0, 18.0, 0.0, 15.0, 16.0, 33.0, 0.0, 0.0, 3.0, 23.0, 0.0, 0.0, 23.0, 25.0, 52.0, 66.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 27.0, 0.0, 89.0, 68.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 21.0, 0.0, 6.0, 12.0, 28.0, 11.0, 45.0, 1.0, 19.0, 27.0, 20.0, 2.0, 45.0, 39.0, 28.0, 0.0, 0.0, 3.0, 0.0, 34.0, 0.0, 5.0, 6.0, 43.0, 23.0, 6.0, 28.0, 39.0, 5.0, 0.0, 0.0, 44.0, 0.0, 0.0, 34.0, 0.0, 4.0, 26.0, 37.0, 0.0, 28.0, 0.0, 0.0, 28.0, 28.0, 16.0, 0.0, 0.0, 0.0, 28.0, 28.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 0.0, 25.0, 26.0, 0.0, 18.0, 8.0, 36.0, 0.0, 0.0, 21.0, 0.0, 33.0, 12.0, 17.0, 40.0, 0.0, 31.0, 26.0, 6.0, 55.0, 0.0, 7.0, 30.0, 27.0, 9.0, 21.0, 30.0, 40.0, 19.0, 9.0, 0.0, 0.0, 27.0, 42.0, 12.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.7865802679782394, "mean_inference_ms": 4.767908319481622, "mean_action_processing_ms": 0.8606267398438839, "mean_env_wait_ms": 0.6176762626676607, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0242767333984375, "StateBufferConnector_ms": 0.016202569007873535, "ViewRequirementAgentConnector_ms": 0.3651682138442993}, "num_episodes": 18, "episode_return_max": 75.09999999999971, "episode_return_min": -60.400000000001086, "episode_return_mean": 22.876000000000193, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.0869378690808, "num_env_steps_trained_throughput_per_sec": 137.0869378690808, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 20653.5, "restore_workers_time_ms": 0.187, "training_step_time_ms": 20652.784, "sample_time_ms": 3688.557, "learn_time_ms": 16941.157, "learn_throughput": 236.111, "synch_weights_time_ms": 19.782}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "e57b0_00000", "date": "2024-08-13_00-21-32", "timestamp": 1723522892, "time_this_iter_s": 29.356801986694336, "time_total_s": 665.8357400894165, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09c7550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 665.8357400894165, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 97.48536585365854, "ram_util_percent": 83.10975609756098}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8453462925813501, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0719791630095747, "policy_loss": -0.001377104524345625, "vf_loss": 1.0730529909726805, "vf_explained_var": 0.020537316357647932, "kl": 0.004792484432087189, "entropy": 1.322208441060687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3802117191274803, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8874733891752031, "policy_loss": -0.0018290319807689498, "vf_loss": 0.8891610835200895, "vf_explained_var": 0.0021216442976048386, "kl": 0.006700456509058229, "entropy": 1.0076208183374356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 80.49999999999933, "episode_reward_min": -60.400000000001086, "episode_reward_mean": 19.45900000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -147.20000000000073, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.50000000000022, "predator_policy": 89.0}, "policy_reward_mean": {"prey_policy": -4.195499999999979, "predator_policy": 13.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.90000000000031, 37.50000000000026, -54.800000000000935, 31.600000000000186, 14.699999999999987, 11.40000000000003, 33.900000000000205, 15.899999999999947, 46.300000000000395, 40.0000000000003, 27.400000000000116, 36.700000000000244, 35.00000000000021, 31.60000000000018, -5.499999999999719, 69.70000000000012, 17.69999999999995, 40.0000000000003, -2.2999999999997582, -60.400000000001086, -21.699999999999676, 40.0000000000003, 40.0000000000003, 32.800000000000196, 15.699999999999944, -10.099999999999667, 73.39999999999982, 41.800000000000324, 38.900000000000276, -1.7999999999998857, 41.50000000000033, -3.999999999999724, -31.79999999999962, 43.5000000000004, 21.900000000000034, -11.399999999999642, -17.499999999999602, 59.800000000000495, 61.90000000000046, 11.599999999999984, 57.90000000000049, 4.600000000000136, -22.299999999999542, 13.799999999999969, 40.0000000000003, -8.39999999999966, 8.900000000000029, 45.20000000000039, -29.29999999999957, -39.400000000000134, 62.500000000000504, -40.49999999999998, 28.700000000000113, 75.09999999999971, 26.70000000000011, 55.30000000000052, 36.40000000000023, 49.00000000000045, 35.600000000000236, 27.90000000000011, 12.49999999999992, 11.399999999999922, 10.500000000000005, 5.800000000000068, 19.599999999999977, -25.999999999999595, 12.599999999999994, -3.9999999999997384, -14.299999999999596, -6.399999999999798, 37.700000000000266, 34.0000000000002, 40.3000000000003, -11.799999999999725, 11.900000000000025, 40.0000000000003, 12.699999999999958, 14.999999999999943, 31.800000000000175, 28.70000000000014, -5.099999999999749, 25.40000000000008, 60.60000000000048, -6.199999999999731, 14.699999999999994, 40.0000000000003, -5.59999999999974, 14.899999999999924, 49.00000000000045, 80.49999999999933, 59.8000000000005, 40.0000000000003, 58.00000000000048, 13.600000000000012, 5.800000000000168, 24.60000000000005, -58.90000000000092, 42.00000000000036, -42.49999999999999, 13.799999999999923], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.900000000000027, 20.000000000000014, 9.499999999999968, 20.000000000000014, -124.90000000000074, -10.89999999999987, -30.39999999999978, 20.000000000000014, 20.000000000000014, -28.29999999999975, -21.99999999999976, 13.399999999999968, 1.09999999999996, 15.799999999999963, 13.999999999999966, -33.09999999999976, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, -36.69999999999977, 37.10000000000025, 13.69999999999997, 20.000000000000014, 20.000000000000014, -21.999999999999787, -3.3999999999999724, 20.000000000000014, 20.000000000000014, -74.50000000000088, 38.900000000000254, 30.800000000000196, -28.299999999999798, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -70.30000000000089, -118.6000000000006, -59.80000000000042, -32.499999999999815, -26.19999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.7999999999999656, 20.000000000000014, -31.299999999999763, 20.000000000000014, -147.20000000000073, -19.899999999999743, 30.50000000000024, 38.900000000000254, 20.000000000000014, 21.80000000000004, 17.899999999999984, 20.000000000000014, 20.000000000000014, -59.800000000000395, 15.499999999999963, 20.000000000000014, 15.799999999999963, -59.80000000000062, -24.09999999999979, -63.70000000000062, 7.999999999999984, 15.499999999999961, 20.000000000000014, -45.09999999999981, 3.7999999999999745, -62.20000000000077, -68.2000000000007, -16.299999999999777, 39.80000000000024, 20.000000000000014, 20.000000000000014, 38.90000000000022, -15.099999999999802, -7.299999999999891, 7.099999999999966, 39.80000000000024, -70.30000000000088, 8.89999999999997, -42.69999999999977, -13.599999999999815, -61.900000000000766, 31.700000000000216, 20.000000000000014, 20.000000000000014, -38.799999999999756, -13.599999999999833, -15.699999999999747, -9.399999999999904, 25.4000000000001, 15.799999999999963, -1.000000000000031, -91.30000000000061, -33.999999999999766, -33.399999999999764, 36.200000000000244, 26.300000000000118, -53.50000000000008, -42.999999999999794, -7.299999999999962, 20.000000000000014, 37.10000000000026, 38.00000000000025, -42.99999999999979, 13.699999999999967, 35.30000000000026, 20.000000000000014, 7.399999999999981, 20.000000000000014, 29.000000000000163, 20.000000000000014, 15.799999999999963, 15.799999999999962, -3.099999999999958, 20.000000000000014, 20.000000000000014, -32.49999999999981, -34.5999999999998, 20.000000000000014, -12.699999999999847, -2.8000000000000185, -55.60000000000025, 25.400000000000098, 20.000000000000014, -21.39999999999975, -30.399999999999785, -28.599999999999802, 20.000000000000014, -36.399999999999764, 20.000000000000014, -64.00000000000091, -82.90000000000077, 11.599999999999964, -38.79999999999986, -28.59999999999981, 10.699999999999967, 20.000000000000014, -42.99999999999981, 20.000000000000014, 23.600000000000065, -13.299999999999812, -34.599999999999824, -47.19999999999981, 22.700000000000053, -38.799999999999756, 20.000000000000014, 20.000000000000014, -19.899999999999757, -36.39999999999981, 15.799999999999963, -26.799999999999756, 3.1999999999999615, 5.599999999999984, 45.50000000000022, -59.80000000000058, -66.10000000000082, 20.000000000000014, 9.499999999999977, -3.099999999999972, 35.60000000000022, 20.000000000000014, -21.999999999999744, -26.199999999999797, -5.1999999999999265, -3.0999999999999757, 20.000000000000014, 20.000000000000014, -40.899999999999785, -36.69999999999977, 20.000000000000014, -51.09999999999997, 29.000000000000163, 20.000000000000014, 39.80000000000025, 40.70000000000025, 20.90000000000003, 38.90000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000234, 20.000000000000014, -30.39999999999975, -17.79999999999974, -9.399999999999855, 20.000000000000014, -9.399999999999855, -47.199999999999825, -57.700000000000166, 36.20000000000026, -11.199999999999852, -42.99999999999983, -32.49999999999981, -34.599999999999795, 7.399999999999965], "policy_predator_policy_reward": [0.0, 0.0, 8.0, 0.0, 39.0, 42.0, 20.0, 22.0, 23.0, 0.0, 20.0, 0.0, 17.0, 0.0, 8.0, 27.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 3.0, 19.0, 18.0, 0.0, 15.0, 16.0, 33.0, 0.0, 0.0, 3.0, 23.0, 0.0, 0.0, 23.0, 25.0, 52.0, 66.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 27.0, 0.0, 89.0, 68.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 21.0, 0.0, 6.0, 12.0, 28.0, 11.0, 45.0, 1.0, 19.0, 27.0, 20.0, 2.0, 45.0, 39.0, 28.0, 0.0, 0.0, 3.0, 0.0, 34.0, 0.0, 5.0, 6.0, 43.0, 23.0, 6.0, 28.0, 39.0, 5.0, 0.0, 0.0, 44.0, 0.0, 0.0, 34.0, 0.0, 4.0, 26.0, 37.0, 0.0, 28.0, 0.0, 0.0, 28.0, 28.0, 16.0, 0.0, 0.0, 0.0, 28.0, 28.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 0.0, 25.0, 26.0, 0.0, 18.0, 8.0, 36.0, 0.0, 0.0, 21.0, 0.0, 33.0, 12.0, 17.0, 40.0, 0.0, 31.0, 26.0, 6.0, 55.0, 0.0, 7.0, 30.0, 27.0, 9.0, 21.0, 30.0, 40.0, 19.0, 9.0, 0.0, 0.0, 27.0, 42.0, 12.0, 14.0, 23.0, 0.0, 38.0, 5.0, 19.0, 22.0, 0.0, 19.0, 0.0, 5.0, 42.0, 0.0, 0.0, 23.0, 0.0, 0.0, 41.0, 31.0, 24.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 18.0, 15.0, 0.0, 14.0, 46.0, 0.0, 17.0, 0.0, 0.0, 33.0, 18.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.796317656022012, "mean_inference_ms": 4.7982436097621095, "mean_action_processing_ms": 0.8604101541595618, "mean_env_wait_ms": 0.6240484529920284, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01908707618713379, "StateBufferConnector_ms": 0.016175150871276855, "ViewRequirementAgentConnector_ms": 0.32649779319763184}, "num_episodes": 22, "episode_return_max": 80.49999999999933, "episode_return_min": -60.400000000001086, "episode_return_mean": 19.45900000000016, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 271.4229980829794, "num_env_steps_trained_throughput_per_sec": 271.4229980829794, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 20512.097, "restore_workers_time_ms": 0.209, "training_step_time_ms": 20511.338, "sample_time_ms": 3500.352, "learn_time_ms": 16986.104, "learn_throughput": 235.487, "synch_weights_time_ms": 20.321}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "e57b0_00000", "date": "2024-08-13_00-21-46", "timestamp": 1723522906, "time_this_iter_s": 14.798699855804443, "time_total_s": 680.634439945221, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09fb280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 680.634439945221, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 77.69999999999999, "ram_util_percent": 83.61428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8708552236870798, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1514664759475088, "policy_loss": -0.005621442032692136, "vf_loss": 1.1563640956052397, "vf_explained_var": -0.0027303565116155717, "kl": 0.022876317937190693, "entropy": 1.3366874614720623, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.335951394209313, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9909088656227425, "policy_loss": -0.0028356692814095704, "vf_loss": 0.9934775150957562, "vf_explained_var": 0.0031312184043662257, "kl": 0.012658744720491225, "entropy": 0.8948712383628522, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 80.49999999999933, "episode_reward_min": -58.90000000000092, "episode_reward_mean": 21.3500000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -147.20000000000073, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.50000000000022, "predator_policy": 89.0}, "policy_reward_mean": {"prey_policy": -2.924999999999977, "predator_policy": 13.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.800000000000196, 15.699999999999944, -10.099999999999667, 73.39999999999982, 41.800000000000324, 38.900000000000276, -1.7999999999998857, 41.50000000000033, -3.999999999999724, -31.79999999999962, 43.5000000000004, 21.900000000000034, -11.399999999999642, -17.499999999999602, 59.800000000000495, 61.90000000000046, 11.599999999999984, 57.90000000000049, 4.600000000000136, -22.299999999999542, 13.799999999999969, 40.0000000000003, -8.39999999999966, 8.900000000000029, 45.20000000000039, -29.29999999999957, -39.400000000000134, 62.500000000000504, -40.49999999999998, 28.700000000000113, 75.09999999999971, 26.70000000000011, 55.30000000000052, 36.40000000000023, 49.00000000000045, 35.600000000000236, 27.90000000000011, 12.49999999999992, 11.399999999999922, 10.500000000000005, 5.800000000000068, 19.599999999999977, -25.999999999999595, 12.599999999999994, -3.9999999999997384, -14.299999999999596, -6.399999999999798, 37.700000000000266, 34.0000000000002, 40.3000000000003, -11.799999999999725, 11.900000000000025, 40.0000000000003, 12.699999999999958, 14.999999999999943, 31.800000000000175, 28.70000000000014, -5.099999999999749, 25.40000000000008, 60.60000000000048, -6.199999999999731, 14.699999999999994, 40.0000000000003, -5.59999999999974, 14.899999999999924, 49.00000000000045, 80.49999999999933, 59.8000000000005, 40.0000000000003, 58.00000000000048, 13.600000000000012, 5.800000000000168, 24.60000000000005, -58.90000000000092, 42.00000000000036, -42.49999999999999, 13.799999999999923, 64.30000000000048, 11.899999999999975, 55.80000000000048, 29.100000000000136, -33.69999999999953, 4.900000000000128, 45.800000000000395, -18.099999999999532, 26.50000000000011, 40.90000000000031, 46.300000000000395, 37.30000000000031, 48.900000000000475, 10.300000000000045, 46.10000000000044, 20.199999999999974, 13.499999999999927, 21.299999999999994, 40.50000000000031, 6.199999999999967, 43.60000000000035, 53.10000000000049, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.7999999999999656, 20.000000000000014, -31.299999999999763, 20.000000000000014, -147.20000000000073, -19.899999999999743, 30.50000000000024, 38.900000000000254, 20.000000000000014, 21.80000000000004, 17.899999999999984, 20.000000000000014, 20.000000000000014, -59.800000000000395, 15.499999999999963, 20.000000000000014, 15.799999999999963, -59.80000000000062, -24.09999999999979, -63.70000000000062, 7.999999999999984, 15.499999999999961, 20.000000000000014, -45.09999999999981, 3.7999999999999745, -62.20000000000077, -68.2000000000007, -16.299999999999777, 39.80000000000024, 20.000000000000014, 20.000000000000014, 38.90000000000022, -15.099999999999802, -7.299999999999891, 7.099999999999966, 39.80000000000024, -70.30000000000088, 8.89999999999997, -42.69999999999977, -13.599999999999815, -61.900000000000766, 31.700000000000216, 20.000000000000014, 20.000000000000014, -38.799999999999756, -13.599999999999833, -15.699999999999747, -9.399999999999904, 25.4000000000001, 15.799999999999963, -1.000000000000031, -91.30000000000061, -33.999999999999766, -33.399999999999764, 36.200000000000244, 26.300000000000118, -53.50000000000008, -42.999999999999794, -7.299999999999962, 20.000000000000014, 37.10000000000026, 38.00000000000025, -42.99999999999979, 13.699999999999967, 35.30000000000026, 20.000000000000014, 7.399999999999981, 20.000000000000014, 29.000000000000163, 20.000000000000014, 15.799999999999963, 15.799999999999962, -3.099999999999958, 20.000000000000014, 20.000000000000014, -32.49999999999981, -34.5999999999998, 20.000000000000014, -12.699999999999847, -2.8000000000000185, -55.60000000000025, 25.400000000000098, 20.000000000000014, -21.39999999999975, -30.399999999999785, -28.599999999999802, 20.000000000000014, -36.399999999999764, 20.000000000000014, -64.00000000000091, -82.90000000000077, 11.599999999999964, -38.79999999999986, -28.59999999999981, 10.699999999999967, 20.000000000000014, -42.99999999999981, 20.000000000000014, 23.600000000000065, -13.299999999999812, -34.599999999999824, -47.19999999999981, 22.700000000000053, -38.799999999999756, 20.000000000000014, 20.000000000000014, -19.899999999999757, -36.39999999999981, 15.799999999999963, -26.799999999999756, 3.1999999999999615, 5.599999999999984, 45.50000000000022, -59.80000000000058, -66.10000000000082, 20.000000000000014, 9.499999999999977, -3.099999999999972, 35.60000000000022, 20.000000000000014, -21.999999999999744, -26.199999999999797, -5.1999999999999265, -3.0999999999999757, 20.000000000000014, 20.000000000000014, -40.899999999999785, -36.69999999999977, 20.000000000000014, -51.09999999999997, 29.000000000000163, 20.000000000000014, 39.80000000000025, 40.70000000000025, 20.90000000000003, 38.90000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000234, 20.000000000000014, -30.39999999999975, -17.79999999999974, -9.399999999999855, 20.000000000000014, -9.399999999999855, -47.199999999999825, -57.700000000000166, 36.20000000000026, -11.199999999999852, -42.99999999999983, -32.49999999999981, -34.599999999999795, 7.399999999999965, 20.000000000000014, 44.300000000000246, -30.399999999999785, 14.299999999999965, 20.000000000000014, 24.80000000000011, 7.699999999999967, 7.399999999999968, -11.499999999999833, -89.20000000000076, 20.000000000000014, -63.100000000000826, 23.600000000000065, 15.199999999999964, -25.29999999999975, -56.800000000000296, 9.499999999999973, -1.0000000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -7.2999999999999154, 17.59999999999998, 20.000000000000014, 14.899999999999961, 20.000000000000014, -36.699999999999754, 20.000000000000014, 16.09999999999996, 20.000000000000014, -17.79999999999974, -66.10000000000079, 38.600000000000236, 20.000000000000014, -15.699999999999747, 36.200000000000244, -15.699999999999747, -78.7000000000007, -3.099999999999958, 20.000000000000014, 23.600000000000065, 31.100000000000207, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [9.0, 0.0, 27.0, 0.0, 89.0, 68.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 21.0, 0.0, 6.0, 12.0, 28.0, 11.0, 45.0, 1.0, 19.0, 27.0, 20.0, 2.0, 45.0, 39.0, 28.0, 0.0, 0.0, 3.0, 0.0, 34.0, 0.0, 5.0, 6.0, 43.0, 23.0, 6.0, 28.0, 39.0, 5.0, 0.0, 0.0, 44.0, 0.0, 0.0, 34.0, 0.0, 4.0, 26.0, 37.0, 0.0, 28.0, 0.0, 0.0, 28.0, 28.0, 16.0, 0.0, 0.0, 0.0, 28.0, 28.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 0.0, 25.0, 26.0, 0.0, 18.0, 8.0, 36.0, 0.0, 0.0, 21.0, 0.0, 33.0, 12.0, 17.0, 40.0, 0.0, 31.0, 26.0, 6.0, 55.0, 0.0, 7.0, 30.0, 27.0, 9.0, 21.0, 30.0, 40.0, 19.0, 9.0, 0.0, 0.0, 27.0, 42.0, 12.0, 14.0, 23.0, 0.0, 38.0, 5.0, 19.0, 22.0, 0.0, 19.0, 0.0, 5.0, 42.0, 0.0, 0.0, 23.0, 0.0, 0.0, 41.0, 31.0, 24.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 18.0, 15.0, 0.0, 14.0, 46.0, 0.0, 17.0, 0.0, 0.0, 33.0, 18.0, 23.0, 0.0, 0.0, 0.0, 28.0, 11.0, 0.0, 0.0, 14.0, 23.0, 44.0, 40.0, 8.0, 7.0, 0.0, 41.0, 23.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 14.0, 0.0, 13.0, 14.0, 10.0, 0.0, 0.0, 18.0, 0.0, 41.0, 0.0, 17.0, 3.0, 17.0, 41.0, 47.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.800483248142669, "mean_inference_ms": 4.828598811606463, "mean_action_processing_ms": 0.8615562508625344, "mean_env_wait_ms": 0.6276799841231365, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018486618995666504, "StateBufferConnector_ms": 0.010990381240844727, "ViewRequirementAgentConnector_ms": 0.3192784786224365}, "num_episodes": 23, "episode_return_max": 80.49999999999933, "episode_return_min": -58.90000000000092, "episode_return_mean": 21.3500000000002, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.2530435218429, "num_env_steps_trained_throughput_per_sec": 290.2530435218429, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 20042.477, "restore_workers_time_ms": 0.208, "training_step_time_ms": 20041.716, "sample_time_ms": 3545.771, "learn_time_ms": 16470.748, "learn_throughput": 242.855, "synch_weights_time_ms": 20.639}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "e57b0_00000", "date": "2024-08-13_00-22-00", "timestamp": 1723522920, "time_this_iter_s": 13.85781216621399, "time_total_s": 694.4922521114349, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b3bca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 694.4922521114349, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 78.08500000000001, "ram_util_percent": 83.23500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9706824679065633, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9321663219146628, "policy_loss": -0.0020031750660448795, "vf_loss": 1.9334706214685289, "vf_explained_var": 0.005462351993278221, "kl": 0.014725257182622454, "entropy": 1.333581834495383, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3863659182179069, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.125882124459302, "policy_loss": -0.0037932478963205265, "vf_loss": 1.1294830292305618, "vf_explained_var": 0.0022796783497724582, "kl": 0.0091184396800544, "entropy": 0.8656748701024939, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 80.49999999999933, "episode_reward_min": -259.40000000000083, "episode_reward_mean": 18.480000000000153, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -204.70000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.10000000000021, "predator_policy": 108.0}, "policy_reward_mean": {"prey_policy": -4.209999999999969, "predator_policy": 13.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.600000000000136, -22.299999999999542, 13.799999999999969, 40.0000000000003, -8.39999999999966, 8.900000000000029, 45.20000000000039, -29.29999999999957, -39.400000000000134, 62.500000000000504, -40.49999999999998, 28.700000000000113, 75.09999999999971, 26.70000000000011, 55.30000000000052, 36.40000000000023, 49.00000000000045, 35.600000000000236, 27.90000000000011, 12.49999999999992, 11.399999999999922, 10.500000000000005, 5.800000000000068, 19.599999999999977, -25.999999999999595, 12.599999999999994, -3.9999999999997384, -14.299999999999596, -6.399999999999798, 37.700000000000266, 34.0000000000002, 40.3000000000003, -11.799999999999725, 11.900000000000025, 40.0000000000003, 12.699999999999958, 14.999999999999943, 31.800000000000175, 28.70000000000014, -5.099999999999749, 25.40000000000008, 60.60000000000048, -6.199999999999731, 14.699999999999994, 40.0000000000003, -5.59999999999974, 14.899999999999924, 49.00000000000045, 80.49999999999933, 59.8000000000005, 40.0000000000003, 58.00000000000048, 13.600000000000012, 5.800000000000168, 24.60000000000005, -58.90000000000092, 42.00000000000036, -42.49999999999999, 13.799999999999923, 64.30000000000048, 11.899999999999975, 55.80000000000048, 29.100000000000136, -33.69999999999953, 4.900000000000128, 45.800000000000395, -18.099999999999532, 26.50000000000011, 40.90000000000031, 46.300000000000395, 37.30000000000031, 48.900000000000475, 10.300000000000045, 46.10000000000044, 20.199999999999974, 13.499999999999927, 21.299999999999994, 40.50000000000031, 6.199999999999967, 43.60000000000035, 53.10000000000049, 40.0000000000003, 49.90000000000046, 16.299999999999972, 23.500000000000064, 15.099999999999923, 62.10000000000045, 10.499999999999991, 49.70000000000046, -24.49999999999993, 50.80000000000049, 40.0000000000003, 35.600000000000236, 28.600000000000122, -57.90000000000128, 59.40000000000048, -259.40000000000083, 49.10000000000046, 41.500000000000355, -53.20000000000091], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-70.30000000000088, 8.89999999999997, -42.69999999999977, -13.599999999999815, -61.900000000000766, 31.700000000000216, 20.000000000000014, 20.000000000000014, -38.799999999999756, -13.599999999999833, -15.699999999999747, -9.399999999999904, 25.4000000000001, 15.799999999999963, -1.000000000000031, -91.30000000000061, -33.999999999999766, -33.399999999999764, 36.200000000000244, 26.300000000000118, -53.50000000000008, -42.999999999999794, -7.299999999999962, 20.000000000000014, 37.10000000000026, 38.00000000000025, -42.99999999999979, 13.699999999999967, 35.30000000000026, 20.000000000000014, 7.399999999999981, 20.000000000000014, 29.000000000000163, 20.000000000000014, 15.799999999999963, 15.799999999999962, -3.099999999999958, 20.000000000000014, 20.000000000000014, -32.49999999999981, -34.5999999999998, 20.000000000000014, -12.699999999999847, -2.8000000000000185, -55.60000000000025, 25.400000000000098, 20.000000000000014, -21.39999999999975, -30.399999999999785, -28.599999999999802, 20.000000000000014, -36.399999999999764, 20.000000000000014, -64.00000000000091, -82.90000000000077, 11.599999999999964, -38.79999999999986, -28.59999999999981, 10.699999999999967, 20.000000000000014, -42.99999999999981, 20.000000000000014, 23.600000000000065, -13.299999999999812, -34.599999999999824, -47.19999999999981, 22.700000000000053, -38.799999999999756, 20.000000000000014, 20.000000000000014, -19.899999999999757, -36.39999999999981, 15.799999999999963, -26.799999999999756, 3.1999999999999615, 5.599999999999984, 45.50000000000022, -59.80000000000058, -66.10000000000082, 20.000000000000014, 9.499999999999977, -3.099999999999972, 35.60000000000022, 20.000000000000014, -21.999999999999744, -26.199999999999797, -5.1999999999999265, -3.0999999999999757, 20.000000000000014, 20.000000000000014, -40.899999999999785, -36.69999999999977, 20.000000000000014, -51.09999999999997, 29.000000000000163, 20.000000000000014, 39.80000000000025, 40.70000000000025, 20.90000000000003, 38.90000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000234, 20.000000000000014, -30.39999999999975, -17.79999999999974, -9.399999999999855, 20.000000000000014, -9.399999999999855, -47.199999999999825, -57.700000000000166, 36.20000000000026, -11.199999999999852, -42.99999999999983, -32.49999999999981, -34.599999999999795, 7.399999999999965, 20.000000000000014, 44.300000000000246, -30.399999999999785, 14.299999999999965, 20.000000000000014, 24.80000000000011, 7.699999999999967, 7.399999999999968, -11.499999999999833, -89.20000000000076, 20.000000000000014, -63.100000000000826, 23.600000000000065, 15.199999999999964, -25.29999999999975, -56.800000000000296, 9.499999999999973, -1.0000000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -7.2999999999999154, 17.59999999999998, 20.000000000000014, 14.899999999999961, 20.000000000000014, -36.699999999999754, 20.000000000000014, 16.09999999999996, 20.000000000000014, -17.79999999999974, -66.10000000000079, 38.600000000000236, 20.000000000000014, -15.699999999999747, 36.200000000000244, -15.699999999999747, -78.7000000000007, -3.099999999999958, 20.000000000000014, 23.600000000000065, 31.100000000000207, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000013, 22.700000000000053, 0.19999999999996523, 1.0999999999999688, 4.099999999999978, -13.599999999999786, -19.899999999999743, 1.9999999999999625, -21.999999999999744, 64.10000000000021, -36.699999999999754, -17.799999999999798, 17.899999999999988, 30.800000000000196, -80.79999999999993, 5.299999999999985, 30.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 21.80000000000004, -5.1999999999999265, -93.40000000000079, -32.49999999999977, 47.30000000000023, 1.09999999999996, -162.70000000000041, -204.70000000000036, 10.099999999999973, 20.000000000000014, 41.300000000000246, -59.80000000000051, -57.700000000000365, -32.49999999999978], "policy_predator_policy_reward": [43.0, 23.0, 6.0, 28.0, 39.0, 5.0, 0.0, 0.0, 44.0, 0.0, 0.0, 34.0, 0.0, 4.0, 26.0, 37.0, 0.0, 28.0, 0.0, 0.0, 28.0, 28.0, 16.0, 0.0, 0.0, 0.0, 28.0, 28.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 0.0, 25.0, 26.0, 0.0, 18.0, 8.0, 36.0, 0.0, 0.0, 21.0, 0.0, 33.0, 12.0, 17.0, 40.0, 0.0, 31.0, 26.0, 6.0, 55.0, 0.0, 7.0, 30.0, 27.0, 9.0, 21.0, 30.0, 40.0, 19.0, 9.0, 0.0, 0.0, 27.0, 42.0, 12.0, 14.0, 23.0, 0.0, 38.0, 5.0, 19.0, 22.0, 0.0, 19.0, 0.0, 5.0, 42.0, 0.0, 0.0, 23.0, 0.0, 0.0, 41.0, 31.0, 24.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 18.0, 15.0, 0.0, 14.0, 46.0, 0.0, 17.0, 0.0, 0.0, 33.0, 18.0, 23.0, 0.0, 0.0, 0.0, 28.0, 11.0, 0.0, 0.0, 14.0, 23.0, 44.0, 40.0, 8.0, 7.0, 0.0, 41.0, 23.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 14.0, 0.0, 13.0, 14.0, 10.0, 0.0, 0.0, 18.0, 0.0, 41.0, 0.0, 17.0, 3.0, 17.0, 41.0, 47.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 8.0, 25.0, 2.0, 31.0, 20.0, 0.0, 25.0, 40.0, 0.0, 1.0, 5.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 45.0, 23.0, 0.0, 11.0, 0.0, 108.0, 11.0, 8.0, 24.0, 36.0, 37.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.8000328375532186, "mean_inference_ms": 4.830425469544622, "mean_action_processing_ms": 0.8595306524487805, "mean_env_wait_ms": 0.6281487614262264, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020351529121398926, "StateBufferConnector_ms": 0.011394500732421875, "ViewRequirementAgentConnector_ms": 0.2951383590698242}, "num_episodes": 18, "episode_return_max": 80.49999999999933, "episode_return_min": -259.40000000000083, "episode_return_mean": 18.480000000000153, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.3727896577122, "num_env_steps_trained_throughput_per_sec": 276.3727896577122, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 19746.251, "restore_workers_time_ms": 0.209, "training_step_time_ms": 19745.489, "sample_time_ms": 3396.283, "learn_time_ms": 16324.839, "learn_throughput": 245.025, "synch_weights_time_ms": 20.001}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "e57b0_00000", "date": "2024-08-13_00-22-15", "timestamp": 1723522935, "time_this_iter_s": 14.503838062286377, "time_total_s": 708.9960901737213, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b41940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 708.9960901737213, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 75.87619047619049, "ram_util_percent": 81.17619047619047}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9432888570680189, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.833735015657213, "policy_loss": -0.0067646722395524935, "vf_loss": 2.8394948377811087, "vf_explained_var": -0.0061962969719417515, "kl": 0.021172272065718124, "entropy": 1.2682113146025038, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40696391635155554, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4096469134880754, "policy_loss": -0.0007113133282425306, "vf_loss": 2.4103210305410716, "vf_explained_var": 0.0022117475983957765, "kl": 0.0017635270706001303, "entropy": 0.8732096520365862, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 80.49999999999933, "episode_reward_min": -438.5, "episode_reward_mean": 14.131000000000151, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.10000000000021, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -8.624499999999987, "predator_policy": 15.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.90000000000011, 12.49999999999992, 11.399999999999922, 10.500000000000005, 5.800000000000068, 19.599999999999977, -25.999999999999595, 12.599999999999994, -3.9999999999997384, -14.299999999999596, -6.399999999999798, 37.700000000000266, 34.0000000000002, 40.3000000000003, -11.799999999999725, 11.900000000000025, 40.0000000000003, 12.699999999999958, 14.999999999999943, 31.800000000000175, 28.70000000000014, -5.099999999999749, 25.40000000000008, 60.60000000000048, -6.199999999999731, 14.699999999999994, 40.0000000000003, -5.59999999999974, 14.899999999999924, 49.00000000000045, 80.49999999999933, 59.8000000000005, 40.0000000000003, 58.00000000000048, 13.600000000000012, 5.800000000000168, 24.60000000000005, -58.90000000000092, 42.00000000000036, -42.49999999999999, 13.799999999999923, 64.30000000000048, 11.899999999999975, 55.80000000000048, 29.100000000000136, -33.69999999999953, 4.900000000000128, 45.800000000000395, -18.099999999999532, 26.50000000000011, 40.90000000000031, 46.300000000000395, 37.30000000000031, 48.900000000000475, 10.300000000000045, 46.10000000000044, 20.199999999999974, 13.499999999999927, 21.299999999999994, 40.50000000000031, 6.199999999999967, 43.60000000000035, 53.10000000000049, 40.0000000000003, 49.90000000000046, 16.299999999999972, 23.500000000000064, 15.099999999999923, 62.10000000000045, 10.499999999999991, 49.70000000000046, -24.49999999999993, 50.80000000000049, 40.0000000000003, 35.600000000000236, 28.600000000000122, -57.90000000000128, 59.40000000000048, -259.40000000000083, 49.10000000000046, 41.500000000000355, -53.20000000000091, 35.600000000000236, -0.19999999999991366, 40.0000000000003, 51.70000000000049, 67.0000000000003, -2.8999999999997446, 48.10000000000044, -21.79999999999962, 41.800000000000324, -5.499999999999927, -438.5, -55.200000000000614, 27.40000000000011, -9.899999999999697, 42.100000000000364, 38.20000000000037, 24.60000000000005, 24.50000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.099999999999958, 20.000000000000014, 20.000000000000014, -32.49999999999981, -34.5999999999998, 20.000000000000014, -12.699999999999847, -2.8000000000000185, -55.60000000000025, 25.400000000000098, 20.000000000000014, -21.39999999999975, -30.399999999999785, -28.599999999999802, 20.000000000000014, -36.399999999999764, 20.000000000000014, -64.00000000000091, -82.90000000000077, 11.599999999999964, -38.79999999999986, -28.59999999999981, 10.699999999999967, 20.000000000000014, -42.99999999999981, 20.000000000000014, 23.600000000000065, -13.299999999999812, -34.599999999999824, -47.19999999999981, 22.700000000000053, -38.799999999999756, 20.000000000000014, 20.000000000000014, -19.899999999999757, -36.39999999999981, 15.799999999999963, -26.799999999999756, 3.1999999999999615, 5.599999999999984, 45.50000000000022, -59.80000000000058, -66.10000000000082, 20.000000000000014, 9.499999999999977, -3.099999999999972, 35.60000000000022, 20.000000000000014, -21.999999999999744, -26.199999999999797, -5.1999999999999265, -3.0999999999999757, 20.000000000000014, 20.000000000000014, -40.899999999999785, -36.69999999999977, 20.000000000000014, -51.09999999999997, 29.000000000000163, 20.000000000000014, 39.80000000000025, 40.70000000000025, 20.90000000000003, 38.90000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000234, 20.000000000000014, -30.39999999999975, -17.79999999999974, -9.399999999999855, 20.000000000000014, -9.399999999999855, -47.199999999999825, -57.700000000000166, 36.20000000000026, -11.199999999999852, -42.99999999999983, -32.49999999999981, -34.599999999999795, 7.399999999999965, 20.000000000000014, 44.300000000000246, -30.399999999999785, 14.299999999999965, 20.000000000000014, 24.80000000000011, 7.699999999999967, 7.399999999999968, -11.499999999999833, -89.20000000000076, 20.000000000000014, -63.100000000000826, 23.600000000000065, 15.199999999999964, -25.29999999999975, -56.800000000000296, 9.499999999999973, -1.0000000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -7.2999999999999154, 17.59999999999998, 20.000000000000014, 14.899999999999961, 20.000000000000014, -36.699999999999754, 20.000000000000014, 16.09999999999996, 20.000000000000014, -17.79999999999974, -66.10000000000079, 38.600000000000236, 20.000000000000014, -15.699999999999747, 36.200000000000244, -15.699999999999747, -78.7000000000007, -3.099999999999958, 20.000000000000014, 23.600000000000065, 31.100000000000207, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000013, 22.700000000000053, 0.19999999999996523, 1.0999999999999688, 4.099999999999978, -13.599999999999786, -19.899999999999743, 1.9999999999999625, -21.999999999999744, 64.10000000000021, -36.699999999999754, -17.799999999999798, 17.899999999999988, 30.800000000000196, -80.79999999999993, 5.299999999999985, 30.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 21.80000000000004, -5.1999999999999265, -93.40000000000079, -32.49999999999977, 47.30000000000023, 1.09999999999996, -162.70000000000041, -204.70000000000036, 10.099999999999973, 20.000000000000014, 41.300000000000246, -59.80000000000051, -57.700000000000365, -32.49999999999978, 20.000000000000014, 11.599999999999964, 37.700000000000216, -109.90000000000069, 20.000000000000014, 20.000000000000014, 31.700000000000212, 20.000000000000014, 30.800000000000196, 36.20000000000026, 20.000000000000014, -61.900000000000766, 28.100000000000154, 20.000000000000014, -80.80000000000082, -85.00000000000045, 20.000000000000014, 21.80000000000004, 12.800000000000146, -91.30000000000051, -395.8, -240.7, -108.10000000000076, -42.09999999999981, 27.20000000000013, -17.799999999999756, -129.10000000000073, 36.200000000000244, 25.40000000000016, -13.299999999999798, -103.90000000000047, 43.1000000000002, 5.299999999999969, 5.299999999999965, 13.699999999999964, -26.199999999999747], "policy_predator_policy_reward": [0.0, 11.0, 0.0, 25.0, 26.0, 0.0, 18.0, 8.0, 36.0, 0.0, 0.0, 21.0, 0.0, 33.0, 12.0, 17.0, 40.0, 0.0, 31.0, 26.0, 6.0, 55.0, 0.0, 7.0, 30.0, 27.0, 9.0, 21.0, 30.0, 40.0, 19.0, 9.0, 0.0, 0.0, 27.0, 42.0, 12.0, 14.0, 23.0, 0.0, 38.0, 5.0, 19.0, 22.0, 0.0, 19.0, 0.0, 5.0, 42.0, 0.0, 0.0, 23.0, 0.0, 0.0, 41.0, 31.0, 24.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 18.0, 15.0, 0.0, 14.0, 46.0, 0.0, 17.0, 0.0, 0.0, 33.0, 18.0, 23.0, 0.0, 0.0, 0.0, 28.0, 11.0, 0.0, 0.0, 14.0, 23.0, 44.0, 40.0, 8.0, 7.0, 0.0, 41.0, 23.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 14.0, 0.0, 13.0, 14.0, 10.0, 0.0, 0.0, 18.0, 0.0, 41.0, 0.0, 17.0, 3.0, 17.0, 41.0, 47.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 8.0, 25.0, 2.0, 31.0, 20.0, 0.0, 25.0, 40.0, 0.0, 1.0, 5.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 45.0, 23.0, 0.0, 11.0, 0.0, 108.0, 11.0, 8.0, 24.0, 36.0, 37.0, 0.0, 4.0, 0.0, 69.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 2.0, 0.0, 0.0, 57.0, 87.0, 0.0, 0.0, 0.0, 73.0, 198.0, 0.0, 45.0, 50.0, 18.0, 0.0, 49.0, 34.0, 12.0, 18.0, 46.0, 53.0, 0.0, 14.0, 17.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.7930520790802487, "mean_inference_ms": 4.812461177714162, "mean_action_processing_ms": 0.8543355415596209, "mean_env_wait_ms": 0.6251690221644589, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019167184829711914, "StateBufferConnector_ms": 0.009119868278503418, "ViewRequirementAgentConnector_ms": 0.26294589042663574}, "num_episodes": 18, "episode_return_max": 80.49999999999933, "episode_return_min": -438.5, "episode_return_mean": 14.131000000000151, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.9011594425942, "num_env_steps_trained_throughput_per_sec": 343.9011594425942, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 19495.018, "restore_workers_time_ms": 0.208, "training_step_time_ms": 19494.256, "sample_time_ms": 3367.974, "learn_time_ms": 16101.421, "learn_throughput": 248.425, "synch_weights_time_ms": 20.073}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "e57b0_00000", "date": "2024-08-13_00-22-27", "timestamp": 1723522947, "time_this_iter_s": 11.692622184753418, "time_total_s": 720.6887123584747, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b71700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 720.6887123584747, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 66.2625, "ram_util_percent": 83.33125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9229921369680336, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.160001197315398, "policy_loss": -0.0048762185043266055, "vf_loss": 4.163548592411021, "vf_explained_var": -0.0002672245262791871, "kl": 0.018665558921364796, "entropy": 1.238446078161714, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4324462886190131, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.422962072602025, "policy_loss": -0.00655671191061773, "vf_loss": 2.4293951670959513, "vf_explained_var": 0.00013736732422359407, "kl": 0.011720769370704815, "entropy": 0.8120447307036667, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 80.49999999999933, "episode_reward_min": -724.9, "episode_reward_mean": -6.297999999999847, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -846.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.10000000000021, "predator_policy": 806.0}, "policy_reward_mean": {"prey_policy": -27.913999999999984, "predator_policy": 24.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.40000000000008, 60.60000000000048, -6.199999999999731, 14.699999999999994, 40.0000000000003, -5.59999999999974, 14.899999999999924, 49.00000000000045, 80.49999999999933, 59.8000000000005, 40.0000000000003, 58.00000000000048, 13.600000000000012, 5.800000000000168, 24.60000000000005, -58.90000000000092, 42.00000000000036, -42.49999999999999, 13.799999999999923, 64.30000000000048, 11.899999999999975, 55.80000000000048, 29.100000000000136, -33.69999999999953, 4.900000000000128, 45.800000000000395, -18.099999999999532, 26.50000000000011, 40.90000000000031, 46.300000000000395, 37.30000000000031, 48.900000000000475, 10.300000000000045, 46.10000000000044, 20.199999999999974, 13.499999999999927, 21.299999999999994, 40.50000000000031, 6.199999999999967, 43.60000000000035, 53.10000000000049, 40.0000000000003, 49.90000000000046, 16.299999999999972, 23.500000000000064, 15.099999999999923, 62.10000000000045, 10.499999999999991, 49.70000000000046, -24.49999999999993, 50.80000000000049, 40.0000000000003, 35.600000000000236, 28.600000000000122, -57.90000000000128, 59.40000000000048, -259.40000000000083, 49.10000000000046, 41.500000000000355, -53.20000000000091, 35.600000000000236, -0.19999999999991366, 40.0000000000003, 51.70000000000049, 67.0000000000003, -2.8999999999997446, 48.10000000000044, -21.79999999999962, 41.800000000000324, -5.499999999999927, -438.5, -55.200000000000614, 27.40000000000011, -9.899999999999697, 42.100000000000364, 38.20000000000037, 24.60000000000005, 24.50000000000005, 7.900000000000061, 22.10000000000011, -552.1999999999999, -92.60000000000048, -724.9, 57.2000000000004, 26.900000000000105, 0.4000000000002072, 36.10000000000024, 58.90000000000052, 40.0000000000003, -453.7, -84.4, 64.60000000000043, 61.500000000000426, -211.19999999999982, 39.60000000000029, 52.60000000000051, -251.5000000000002, 76.89999999999955, 35.600000000000236, 32.10000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999977, -3.099999999999972, 35.60000000000022, 20.000000000000014, -21.999999999999744, -26.199999999999797, -5.1999999999999265, -3.0999999999999757, 20.000000000000014, 20.000000000000014, -40.899999999999785, -36.69999999999977, 20.000000000000014, -51.09999999999997, 29.000000000000163, 20.000000000000014, 39.80000000000025, 40.70000000000025, 20.90000000000003, 38.90000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000234, 20.000000000000014, -30.39999999999975, -17.79999999999974, -9.399999999999855, 20.000000000000014, -9.399999999999855, -47.199999999999825, -57.700000000000166, 36.20000000000026, -11.199999999999852, -42.99999999999983, -32.49999999999981, -34.599999999999795, 7.399999999999965, 20.000000000000014, 44.300000000000246, -30.399999999999785, 14.299999999999965, 20.000000000000014, 24.80000000000011, 7.699999999999967, 7.399999999999968, -11.499999999999833, -89.20000000000076, 20.000000000000014, -63.100000000000826, 23.600000000000065, 15.199999999999964, -25.29999999999975, -56.800000000000296, 9.499999999999973, -1.0000000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -7.2999999999999154, 17.59999999999998, 20.000000000000014, 14.899999999999961, 20.000000000000014, -36.699999999999754, 20.000000000000014, 16.09999999999996, 20.000000000000014, -17.79999999999974, -66.10000000000079, 38.600000000000236, 20.000000000000014, -15.699999999999747, 36.200000000000244, -15.699999999999747, -78.7000000000007, -3.099999999999958, 20.000000000000014, 23.600000000000065, 31.100000000000207, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000013, 22.700000000000053, 0.19999999999996523, 1.0999999999999688, 4.099999999999978, -13.599999999999786, -19.899999999999743, 1.9999999999999625, -21.999999999999744, 64.10000000000021, -36.699999999999754, -17.799999999999798, 17.899999999999988, 30.800000000000196, -80.79999999999993, 5.299999999999985, 30.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 21.80000000000004, -5.1999999999999265, -93.40000000000079, -32.49999999999977, 47.30000000000023, 1.09999999999996, -162.70000000000041, -204.70000000000036, 10.099999999999973, 20.000000000000014, 41.300000000000246, -59.80000000000051, -57.700000000000365, -32.49999999999978, 20.000000000000014, 11.599999999999964, 37.700000000000216, -109.90000000000069, 20.000000000000014, 20.000000000000014, 31.700000000000212, 20.000000000000014, 30.800000000000196, 36.20000000000026, 20.000000000000014, -61.900000000000766, 28.100000000000154, 20.000000000000014, -80.80000000000082, -85.00000000000045, 20.000000000000014, 21.80000000000004, 12.800000000000146, -91.30000000000051, -395.8, -240.7, -108.10000000000076, -42.09999999999981, 27.20000000000013, -17.799999999999756, -129.10000000000073, 36.200000000000244, 25.40000000000016, -13.299999999999798, -103.90000000000047, 43.1000000000002, 5.299999999999969, 5.299999999999965, 13.699999999999964, -26.199999999999747, -42.09999999999978, 20.000000000000014, -26.799999999999834, 8.900000000000004, -543.7, -405.5, -125.80000000000032, -101.80000000000021, -684.9000000000001, -846.0, -53.50000000000011, 10.699999999999989, 20.000000000000014, -9.09999999999988, -55.60000000000032, 20.000000000000014, 20.000000000000014, -19.899999999999743, 22.700000000000053, 36.20000000000026, 20.000000000000014, 20.000000000000014, -311.8, -313.9, -57.699999999999974, -96.70000000000022, 20.000000000000014, 41.600000000000236, 35.300000000000196, 0.1999999999999599, -163.00000000000006, -545.1999999999998, -5.49999999999994, 28.100000000000154, 7.399999999999965, 36.20000000000026, -184.60000000000014, -229.90000000000015, 46.10000000000023, 30.800000000000203, 11.599999999999964, 20.000000000000014, 30.800000000000203, -15.699999999999754], "policy_predator_policy_reward": [0.0, 19.0, 0.0, 5.0, 42.0, 0.0, 0.0, 23.0, 0.0, 0.0, 41.0, 31.0, 24.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 18.0, 15.0, 0.0, 14.0, 46.0, 0.0, 17.0, 0.0, 0.0, 33.0, 18.0, 23.0, 0.0, 0.0, 0.0, 28.0, 11.0, 0.0, 0.0, 14.0, 23.0, 44.0, 40.0, 8.0, 7.0, 0.0, 41.0, 23.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 14.0, 0.0, 13.0, 14.0, 10.0, 0.0, 0.0, 18.0, 0.0, 41.0, 0.0, 17.0, 3.0, 17.0, 41.0, 47.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 8.0, 25.0, 2.0, 31.0, 20.0, 0.0, 25.0, 40.0, 0.0, 1.0, 5.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 45.0, 23.0, 0.0, 11.0, 0.0, 108.0, 11.0, 8.0, 24.0, 36.0, 37.0, 0.0, 4.0, 0.0, 69.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 2.0, 0.0, 0.0, 57.0, 87.0, 0.0, 0.0, 0.0, 73.0, 198.0, 0.0, 45.0, 50.0, 18.0, 0.0, 49.0, 34.0, 12.0, 18.0, 46.0, 53.0, 0.0, 14.0, 17.0, 20.0, 30.0, 0.0, 0.0, 40.0, 393.0, 4.0, 28.0, 107.0, 0.0, 806.0, 53.0, 47.0, 0.0, 16.0, 19.0, 17.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 172.0, 11.0, 59.0, 0.0, 3.0, 11.0, 15.0, 497.0, 0.0, 0.0, 17.0, 3.0, 6.0, 128.0, 35.0, 0.0, 0.0, 0.0, 4.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.7764949897673359, "mean_inference_ms": 4.754669401612926, "mean_action_processing_ms": 0.8431500709140282, "mean_env_wait_ms": 0.6186228394714174, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007662177085876465, "StateBufferConnector_ms": 0.004945993423461914, "ViewRequirementAgentConnector_ms": 0.17304158210754395}, "num_episodes": 22, "episode_return_max": 80.49999999999933, "episode_return_min": -724.9, "episode_return_mean": -6.297999999999847, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.0095934815146, "num_env_steps_trained_throughput_per_sec": 350.0095934815146, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 19008.666, "restore_workers_time_ms": 0.209, "training_step_time_ms": 19007.905, "sample_time_ms": 3334.429, "learn_time_ms": 15648.348, "learn_throughput": 255.618, "synch_weights_time_ms": 20.171}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "e57b0_00000", "date": "2024-08-13_00-22-38", "timestamp": 1723522958, "time_this_iter_s": 11.48195195198059, "time_total_s": 732.1706643104553, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b51310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 732.1706643104553, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 62.14705882352941, "ram_util_percent": 83.78235294117648}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6937022556900663, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.551245784002637, "policy_loss": -0.0014178461791878496, "vf_loss": 8.55216333500292, "vf_explained_var": 0.0011303905456785171, "kl": 0.00702762678233449, "entropy": 1.2210067116394245, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5251355181334826, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.663946656827574, "policy_loss": -0.005328904010266775, "vf_loss": 5.669202455894026, "vf_explained_var": 0.00012482026266673254, "kl": 0.0069324707607599555, "entropy": 0.7681855035206628, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 76.89999999999955, "episode_reward_min": -838.0, "episode_reward_mean": -74.21699999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1065.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.10000000000021, "predator_policy": 1100.0}, "policy_reward_mean": {"prey_policy": -100.0185, "predator_policy": 62.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-33.69999999999953, 4.900000000000128, 45.800000000000395, -18.099999999999532, 26.50000000000011, 40.90000000000031, 46.300000000000395, 37.30000000000031, 48.900000000000475, 10.300000000000045, 46.10000000000044, 20.199999999999974, 13.499999999999927, 21.299999999999994, 40.50000000000031, 6.199999999999967, 43.60000000000035, 53.10000000000049, 40.0000000000003, 49.90000000000046, 16.299999999999972, 23.500000000000064, 15.099999999999923, 62.10000000000045, 10.499999999999991, 49.70000000000046, -24.49999999999993, 50.80000000000049, 40.0000000000003, 35.600000000000236, 28.600000000000122, -57.90000000000128, 59.40000000000048, -259.40000000000083, 49.10000000000046, 41.500000000000355, -53.20000000000091, 35.600000000000236, -0.19999999999991366, 40.0000000000003, 51.70000000000049, 67.0000000000003, -2.8999999999997446, 48.10000000000044, -21.79999999999962, 41.800000000000324, -5.499999999999927, -438.5, -55.200000000000614, 27.40000000000011, -9.899999999999697, 42.100000000000364, 38.20000000000037, 24.60000000000005, 24.50000000000005, 7.900000000000061, 22.10000000000011, -552.1999999999999, -92.60000000000048, -724.9, 57.2000000000004, 26.900000000000105, 0.4000000000002072, 36.10000000000024, 58.90000000000052, 40.0000000000003, -453.7, -84.4, 64.60000000000043, 61.500000000000426, -211.19999999999982, 39.60000000000029, 52.60000000000051, -251.5000000000002, 76.89999999999955, 35.600000000000236, 32.10000000000018, -584.0999999999999, -838.0, -168.09999999999985, -110.70000000000005, -223.0999999999998, -332.69999999999993, -251.9999999999999, 55.00000000000045, -300.0000000000001, -340.19999999999993, -315.8, -223.10000000000082, -343.0999999999999, -374.4000000000001, -58.599999999999994, -301.5999999999998, -370.8999999999997, 24.700000000000056, -174.59999999999985, -445.20000000000005, 31.400000000000176, -588.5, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.499999999999833, -89.20000000000076, 20.000000000000014, -63.100000000000826, 23.600000000000065, 15.199999999999964, -25.29999999999975, -56.800000000000296, 9.499999999999973, -1.0000000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 26.300000000000114, -7.2999999999999154, 17.59999999999998, 20.000000000000014, 14.899999999999961, 20.000000000000014, -36.699999999999754, 20.000000000000014, 16.09999999999996, 20.000000000000014, -17.79999999999974, -66.10000000000079, 38.600000000000236, 20.000000000000014, -15.699999999999747, 36.200000000000244, -15.699999999999747, -78.7000000000007, -3.099999999999958, 20.000000000000014, 23.600000000000065, 31.100000000000207, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000013, 22.700000000000053, 0.19999999999996523, 1.0999999999999688, 4.099999999999978, -13.599999999999786, -19.899999999999743, 1.9999999999999625, -21.999999999999744, 64.10000000000021, -36.699999999999754, -17.799999999999798, 17.899999999999988, 30.800000000000196, -80.79999999999993, 5.299999999999985, 30.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 21.80000000000004, -5.1999999999999265, -93.40000000000079, -32.49999999999977, 47.30000000000023, 1.09999999999996, -162.70000000000041, -204.70000000000036, 10.099999999999973, 20.000000000000014, 41.300000000000246, -59.80000000000051, -57.700000000000365, -32.49999999999978, 20.000000000000014, 11.599999999999964, 37.700000000000216, -109.90000000000069, 20.000000000000014, 20.000000000000014, 31.700000000000212, 20.000000000000014, 30.800000000000196, 36.20000000000026, 20.000000000000014, -61.900000000000766, 28.100000000000154, 20.000000000000014, -80.80000000000082, -85.00000000000045, 20.000000000000014, 21.80000000000004, 12.800000000000146, -91.30000000000051, -395.8, -240.7, -108.10000000000076, -42.09999999999981, 27.20000000000013, -17.799999999999756, -129.10000000000073, 36.200000000000244, 25.40000000000016, -13.299999999999798, -103.90000000000047, 43.1000000000002, 5.299999999999969, 5.299999999999965, 13.699999999999964, -26.199999999999747, -42.09999999999978, 20.000000000000014, -26.799999999999834, 8.900000000000004, -543.7, -405.5, -125.80000000000032, -101.80000000000021, -684.9000000000001, -846.0, -53.50000000000011, 10.699999999999989, 20.000000000000014, -9.09999999999988, -55.60000000000032, 20.000000000000014, 20.000000000000014, -19.899999999999743, 22.700000000000053, 36.20000000000026, 20.000000000000014, 20.000000000000014, -311.8, -313.9, -57.699999999999974, -96.70000000000022, 20.000000000000014, 41.600000000000236, 35.300000000000196, 0.1999999999999599, -163.00000000000006, -545.1999999999998, -5.49999999999994, 28.100000000000154, 7.399999999999965, 36.20000000000026, -184.60000000000014, -229.90000000000015, 46.10000000000023, 30.800000000000203, 11.599999999999964, 20.000000000000014, 30.800000000000203, -15.699999999999754, -643.0999999999999, -931.0, -1065.1, -875.9, -99.70000000000005, -272.39999999999986, -145.89999999999986, -101.80000000000001, -192.70000000000005, -213.39999999999992, -252.6999999999999, -464.99999999999994, -383.0999999999999, -488.9, 29.00000000000017, 20.000000000000014, -341.19999999999993, -152.79999999999998, -256.9, -273.2999999999999, -368.5, -217.3, -173.2000000000004, -166.90000000000043, -261.39999999999986, -336.7, -274.0, -240.40000000000003, -29.800000000000008, -101.79999999999987, -373.3, -290.30000000000007, -383.99999999999983, -412.90000000000003, 20.000000000000014, -28.299999999999756, -125.40000000000002, -235.20000000000002, -918.1999999999999, -594.0, -53.50000000000019, 35.90000000000024, -965.3, -723.2, 20.000000000000014, 5.299999999999965], "policy_predator_policy_reward": [23.0, 44.0, 40.0, 8.0, 7.0, 0.0, 41.0, 23.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 14.0, 0.0, 13.0, 14.0, 10.0, 0.0, 0.0, 18.0, 0.0, 41.0, 0.0, 17.0, 3.0, 17.0, 41.0, 47.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 8.0, 25.0, 2.0, 31.0, 20.0, 0.0, 25.0, 40.0, 0.0, 1.0, 5.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 45.0, 23.0, 0.0, 11.0, 0.0, 108.0, 11.0, 8.0, 24.0, 36.0, 37.0, 0.0, 4.0, 0.0, 69.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 2.0, 0.0, 0.0, 57.0, 87.0, 0.0, 0.0, 0.0, 73.0, 198.0, 0.0, 45.0, 50.0, 18.0, 0.0, 49.0, 34.0, 12.0, 18.0, 46.0, 53.0, 0.0, 14.0, 17.0, 20.0, 30.0, 0.0, 0.0, 40.0, 393.0, 4.0, 28.0, 107.0, 0.0, 806.0, 53.0, 47.0, 0.0, 16.0, 19.0, 17.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 172.0, 11.0, 59.0, 0.0, 3.0, 11.0, 15.0, 497.0, 0.0, 0.0, 17.0, 3.0, 6.0, 128.0, 35.0, 0.0, 0.0, 0.0, 4.0, 0.0, 17.0, 990.0, 0.0, 7.0, 1096.0, 202.0, 2.0, 61.0, 76.0, 183.0, 0.0, 41.0, 344.0, 238.0, 382.0, 6.0, 0.0, 23.0, 171.0, 0.0, 190.0, 191.0, 79.0, 103.0, 14.0, 254.0, 1.0, 134.0, 6.0, 73.0, 0.0, 358.0, 4.0, 422.0, 4.0, 16.0, 17.0, 172.0, 14.0, 223.0, 844.0, 29.0, 20.0, 0.0, 1100.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.757471548023763, "mean_inference_ms": 4.714175886077262, "mean_action_processing_ms": 0.8337475534681192, "mean_env_wait_ms": 0.61186734279663, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007584691047668457, "StateBufferConnector_ms": 0.004602670669555664, "ViewRequirementAgentConnector_ms": 0.16670918464660645}, "num_episodes": 23, "episode_return_max": 76.89999999999955, "episode_return_min": -838.0, "episode_return_mean": -74.21699999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 256.1849108098761, "num_env_steps_trained_throughput_per_sec": 256.1849108098761, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 19065.816, "restore_workers_time_ms": 0.209, "training_step_time_ms": 19065.062, "sample_time_ms": 3435.335, "learn_time_ms": 15605.45, "learn_throughput": 256.321, "synch_weights_time_ms": 18.951}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "e57b0_00000", "date": "2024-08-13_00-22-54", "timestamp": 1723522974, "time_this_iter_s": 15.648089170455933, "time_total_s": 747.8187534809113, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b41040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 747.8187534809113, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 76.54090909090908, "ram_util_percent": 81.6090909090909}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.706601616231695, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.315402557988646, "policy_loss": -0.001340330448420472, "vf_loss": 8.316243620776625, "vf_explained_var": 0.001084294457914968, "kl": 0.007013056544469186, "entropy": 1.1899153693012459, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5663600344782469, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.983863538156742, "policy_loss": -0.004172933656751873, "vf_loss": 6.987954381407884, "vf_explained_var": 0.00037092500262790254, "kl": 0.007780822758801396, "entropy": 0.8257987931291894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 103.40000000000009, "episode_reward_min": -870.2, "episode_reward_mean": -144.3309999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.10000000000021, "predator_policy": 1356.0}, "policy_reward_mean": {"prey_policy": -206.00550000000004, "predator_policy": 133.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 49.90000000000046, 16.299999999999972, 23.500000000000064, 15.099999999999923, 62.10000000000045, 10.499999999999991, 49.70000000000046, -24.49999999999993, 50.80000000000049, 40.0000000000003, 35.600000000000236, 28.600000000000122, -57.90000000000128, 59.40000000000048, -259.40000000000083, 49.10000000000046, 41.500000000000355, -53.20000000000091, 35.600000000000236, -0.19999999999991366, 40.0000000000003, 51.70000000000049, 67.0000000000003, -2.8999999999997446, 48.10000000000044, -21.79999999999962, 41.800000000000324, -5.499999999999927, -438.5, -55.200000000000614, 27.40000000000011, -9.899999999999697, 42.100000000000364, 38.20000000000037, 24.60000000000005, 24.50000000000005, 7.900000000000061, 22.10000000000011, -552.1999999999999, -92.60000000000048, -724.9, 57.2000000000004, 26.900000000000105, 0.4000000000002072, 36.10000000000024, 58.90000000000052, 40.0000000000003, -453.7, -84.4, 64.60000000000043, 61.500000000000426, -211.19999999999982, 39.60000000000029, 52.60000000000051, -251.5000000000002, 76.89999999999955, 35.600000000000236, 32.10000000000018, -584.0999999999999, -838.0, -168.09999999999985, -110.70000000000005, -223.0999999999998, -332.69999999999993, -251.9999999999999, 55.00000000000045, -300.0000000000001, -340.19999999999993, -315.8, -223.10000000000082, -343.0999999999999, -374.4000000000001, -58.599999999999994, -301.5999999999998, -370.8999999999997, 24.700000000000056, -174.59999999999985, -445.20000000000005, 31.400000000000176, -588.5, 32.30000000000018, -317.0000000000001, 50.90000000000045, -284.49999999999994, -760.3, -178.50000000000003, -166.79999999999967, -728.6, -548.2, -601.0999999999999, -631.0, 58.90000000000048, -339.49999999999994, -109.59999999999992, -346.20000000000005, 103.40000000000009, -870.2, -734.2, -155.29999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 27.20000000000013, 22.700000000000053, 0.19999999999996523, 1.0999999999999688, 4.099999999999978, -13.599999999999786, -19.899999999999743, 1.9999999999999625, -21.999999999999744, 64.10000000000021, -36.699999999999754, -17.799999999999798, 17.899999999999988, 30.800000000000196, -80.79999999999993, 5.299999999999985, 30.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 21.80000000000004, -5.1999999999999265, -93.40000000000079, -32.49999999999977, 47.30000000000023, 1.09999999999996, -162.70000000000041, -204.70000000000036, 10.099999999999973, 20.000000000000014, 41.300000000000246, -59.80000000000051, -57.700000000000365, -32.49999999999978, 20.000000000000014, 11.599999999999964, 37.700000000000216, -109.90000000000069, 20.000000000000014, 20.000000000000014, 31.700000000000212, 20.000000000000014, 30.800000000000196, 36.20000000000026, 20.000000000000014, -61.900000000000766, 28.100000000000154, 20.000000000000014, -80.80000000000082, -85.00000000000045, 20.000000000000014, 21.80000000000004, 12.800000000000146, -91.30000000000051, -395.8, -240.7, -108.10000000000076, -42.09999999999981, 27.20000000000013, -17.799999999999756, -129.10000000000073, 36.200000000000244, 25.40000000000016, -13.299999999999798, -103.90000000000047, 43.1000000000002, 5.299999999999969, 5.299999999999965, 13.699999999999964, -26.199999999999747, -42.09999999999978, 20.000000000000014, -26.799999999999834, 8.900000000000004, -543.7, -405.5, -125.80000000000032, -101.80000000000021, -684.9000000000001, -846.0, -53.50000000000011, 10.699999999999989, 20.000000000000014, -9.09999999999988, -55.60000000000032, 20.000000000000014, 20.000000000000014, -19.899999999999743, 22.700000000000053, 36.20000000000026, 20.000000000000014, 20.000000000000014, -311.8, -313.9, -57.699999999999974, -96.70000000000022, 20.000000000000014, 41.600000000000236, 35.300000000000196, 0.1999999999999599, -163.00000000000006, -545.1999999999998, -5.49999999999994, 28.100000000000154, 7.399999999999965, 36.20000000000026, -184.60000000000014, -229.90000000000015, 46.10000000000023, 30.800000000000203, 11.599999999999964, 20.000000000000014, 30.800000000000203, -15.699999999999754, -643.0999999999999, -931.0, -1065.1, -875.9, -99.70000000000005, -272.39999999999986, -145.89999999999986, -101.80000000000001, -192.70000000000005, -213.39999999999992, -252.6999999999999, -464.99999999999994, -383.0999999999999, -488.9, 29.00000000000017, 20.000000000000014, -341.19999999999993, -152.79999999999998, -256.9, -273.2999999999999, -368.5, -217.3, -173.2000000000004, -166.90000000000043, -261.39999999999986, -336.7, -274.0, -240.40000000000003, -29.800000000000008, -101.79999999999987, -373.3, -290.30000000000007, -383.99999999999983, -412.90000000000003, 20.000000000000014, -28.299999999999756, -125.40000000000002, -235.20000000000002, -918.1999999999999, -594.0, -53.50000000000019, 35.90000000000024, -965.3, -723.2, 20.000000000000014, 5.299999999999965, -986.5, -1029.5, 26.90000000000013, 20.000000000000014, -248.10000000000002, -257.40000000000003, -1002.5999999999999, -911.7, -174.09999999999985, -135.40000000000003, -231.10000000000002, -210.7000000000006, -692.3, -1212.3, -589.1, -637.1, -685.6, -674.5, -583.8, -1039.2, 35.30000000000024, 23.600000000000065, -634.4, -821.1, -68.50000000000001, -108.09999999999995, -333.6, -410.6, -1227.4, -212.19999999999985, -1400.0, -1096.2, -711.6, -687.6, -1092.9, -1212.4], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 8.0, 25.0, 2.0, 31.0, 20.0, 0.0, 25.0, 40.0, 0.0, 1.0, 5.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 45.0, 23.0, 0.0, 11.0, 0.0, 108.0, 11.0, 8.0, 24.0, 36.0, 37.0, 0.0, 4.0, 0.0, 69.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 2.0, 0.0, 0.0, 57.0, 87.0, 0.0, 0.0, 0.0, 73.0, 198.0, 0.0, 45.0, 50.0, 18.0, 0.0, 49.0, 34.0, 12.0, 18.0, 46.0, 53.0, 0.0, 14.0, 17.0, 20.0, 30.0, 0.0, 0.0, 40.0, 393.0, 4.0, 28.0, 107.0, 0.0, 806.0, 53.0, 47.0, 0.0, 16.0, 19.0, 17.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 172.0, 11.0, 59.0, 0.0, 3.0, 11.0, 15.0, 497.0, 0.0, 0.0, 17.0, 3.0, 6.0, 128.0, 35.0, 0.0, 0.0, 0.0, 4.0, 0.0, 17.0, 990.0, 0.0, 7.0, 1096.0, 202.0, 2.0, 61.0, 76.0, 183.0, 0.0, 41.0, 344.0, 238.0, 382.0, 6.0, 0.0, 23.0, 171.0, 0.0, 190.0, 191.0, 79.0, 103.0, 14.0, 254.0, 1.0, 134.0, 6.0, 73.0, 0.0, 358.0, 4.0, 422.0, 4.0, 16.0, 17.0, 172.0, 14.0, 223.0, 844.0, 29.0, 20.0, 0.0, 1100.0, 7.0, 0.0, 836.0, 863.0, 4.0, 0.0, 221.0, 0.0, 932.0, 222.0, 94.0, 37.0, 258.0, 17.0, 1146.0, 30.0, 0.0, 678.0, 749.0, 10.0, 949.0, 43.0, 0.0, 0.0, 699.0, 417.0, 5.0, 62.0, 352.0, 46.0, 923.0, 620.0, 1356.0, 270.0, 0.0, 665.0, 1141.0, 1009.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.7431518507205368, "mean_inference_ms": 4.677008386017721, "mean_action_processing_ms": 0.8245635200866539, "mean_env_wait_ms": 0.6065508130894461, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00767362117767334, "StateBufferConnector_ms": 0.01341235637664795, "ViewRequirementAgentConnector_ms": 0.1863691806793213}, "num_episodes": 18, "episode_return_max": 103.40000000000009, "episode_return_min": -870.2, "episode_return_mean": -144.3309999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 309.57694402019706, "num_env_steps_trained_throughput_per_sec": 309.57694402019706, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 17275.759, "restore_workers_time_ms": 0.208, "training_step_time_ms": 17275.007, "sample_time_ms": 3341.859, "learn_time_ms": 13913.943, "learn_throughput": 287.481, "synch_weights_time_ms": 14.847}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "e57b0_00000", "date": "2024-08-13_00-23-07", "timestamp": 1723522987, "time_this_iter_s": 12.954292058944702, "time_total_s": 760.773045539856, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b513a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 760.773045539856, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 67.31666666666666, "ram_util_percent": 79.75}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.623903025950862, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.433516909331871, "policy_loss": -0.0004643517324612254, "vf_loss": 8.433805028723661, "vf_explained_var": 0.000633599076952253, "kl": 0.0024753917470755698, "entropy": 1.1726976781925826, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5572912209406101, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.248790398602763, "policy_loss": -0.004670693047921217, "vf_loss": 7.253367386923896, "vf_explained_var": 0.0006731503224246717, "kl": 0.00888442900647711, "entropy": 0.8684388273922855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 533.8000000000005, "episode_reward_min": -898.2, "episode_reward_mean": -187.1459999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.10000000000023, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -312.848, "predator_policy": 219.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-53.20000000000091, 35.600000000000236, -0.19999999999991366, 40.0000000000003, 51.70000000000049, 67.0000000000003, -2.8999999999997446, 48.10000000000044, -21.79999999999962, 41.800000000000324, -5.499999999999927, -438.5, -55.200000000000614, 27.40000000000011, -9.899999999999697, 42.100000000000364, 38.20000000000037, 24.60000000000005, 24.50000000000005, 7.900000000000061, 22.10000000000011, -552.1999999999999, -92.60000000000048, -724.9, 57.2000000000004, 26.900000000000105, 0.4000000000002072, 36.10000000000024, 58.90000000000052, 40.0000000000003, -453.7, -84.4, 64.60000000000043, 61.500000000000426, -211.19999999999982, 39.60000000000029, 52.60000000000051, -251.5000000000002, 76.89999999999955, 35.600000000000236, 32.10000000000018, -584.0999999999999, -838.0, -168.09999999999985, -110.70000000000005, -223.0999999999998, -332.69999999999993, -251.9999999999999, 55.00000000000045, -300.0000000000001, -340.19999999999993, -315.8, -223.10000000000082, -343.0999999999999, -374.4000000000001, -58.599999999999994, -301.5999999999998, -370.8999999999997, 24.700000000000056, -174.59999999999985, -445.20000000000005, 31.400000000000176, -588.5, 32.30000000000018, -317.0000000000001, 50.90000000000045, -284.49999999999994, -760.3, -178.50000000000003, -166.79999999999967, -728.6, -548.2, -601.0999999999999, -631.0, 58.90000000000048, -339.49999999999994, -109.59999999999992, -346.20000000000005, 103.40000000000009, -870.2, -734.2, -155.29999999999993, -295.00000000000006, -860.8, 43.60000000000035, -159.00000000000006, 533.8000000000005, -374.59999999999997, -898.2, -166.19999999999987, 254.60000000000036, -69.9, -177.59999999999997, -227.69999999999993, -448.4, -196.4999999999997, -209.4999999999997, -399.0, -493.29999999999995, 92.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-57.700000000000365, -32.49999999999978, 20.000000000000014, 11.599999999999964, 37.700000000000216, -109.90000000000069, 20.000000000000014, 20.000000000000014, 31.700000000000212, 20.000000000000014, 30.800000000000196, 36.20000000000026, 20.000000000000014, -61.900000000000766, 28.100000000000154, 20.000000000000014, -80.80000000000082, -85.00000000000045, 20.000000000000014, 21.80000000000004, 12.800000000000146, -91.30000000000051, -395.8, -240.7, -108.10000000000076, -42.09999999999981, 27.20000000000013, -17.799999999999756, -129.10000000000073, 36.200000000000244, 25.40000000000016, -13.299999999999798, -103.90000000000047, 43.1000000000002, 5.299999999999969, 5.299999999999965, 13.699999999999964, -26.199999999999747, -42.09999999999978, 20.000000000000014, -26.799999999999834, 8.900000000000004, -543.7, -405.5, -125.80000000000032, -101.80000000000021, -684.9000000000001, -846.0, -53.50000000000011, 10.699999999999989, 20.000000000000014, -9.09999999999988, -55.60000000000032, 20.000000000000014, 20.000000000000014, -19.899999999999743, 22.700000000000053, 36.20000000000026, 20.000000000000014, 20.000000000000014, -311.8, -313.9, -57.699999999999974, -96.70000000000022, 20.000000000000014, 41.600000000000236, 35.300000000000196, 0.1999999999999599, -163.00000000000006, -545.1999999999998, -5.49999999999994, 28.100000000000154, 7.399999999999965, 36.20000000000026, -184.60000000000014, -229.90000000000015, 46.10000000000023, 30.800000000000203, 11.599999999999964, 20.000000000000014, 30.800000000000203, -15.699999999999754, -643.0999999999999, -931.0, -1065.1, -875.9, -99.70000000000005, -272.39999999999986, -145.89999999999986, -101.80000000000001, -192.70000000000005, -213.39999999999992, -252.6999999999999, -464.99999999999994, -383.0999999999999, -488.9, 29.00000000000017, 20.000000000000014, -341.19999999999993, -152.79999999999998, -256.9, -273.2999999999999, -368.5, -217.3, -173.2000000000004, -166.90000000000043, -261.39999999999986, -336.7, -274.0, -240.40000000000003, -29.800000000000008, -101.79999999999987, -373.3, -290.30000000000007, -383.99999999999983, -412.90000000000003, 20.000000000000014, -28.299999999999756, -125.40000000000002, -235.20000000000002, -918.1999999999999, -594.0, -53.50000000000019, 35.90000000000024, -965.3, -723.2, 20.000000000000014, 5.299999999999965, -986.5, -1029.5, 26.90000000000013, 20.000000000000014, -248.10000000000002, -257.40000000000003, -1002.5999999999999, -911.7, -174.09999999999985, -135.40000000000003, -231.10000000000002, -210.7000000000006, -692.3, -1212.3, -589.1, -637.1, -685.6, -674.5, -583.8, -1039.2, 35.30000000000024, 23.600000000000065, -634.4, -821.1, -68.50000000000001, -108.09999999999995, -333.6, -410.6, -1227.4, -212.19999999999985, -1400.0, -1096.2, -711.6, -687.6, -1092.9, -1212.4, -322.5, -483.5, -893.6, -1051.2, 23.600000000000065, 20.000000000000014, -414.9, -301.1, -870.4, -17.80000000000004, -550.8, -796.8, -966.3, -1033.9, -222.10000000000065, -132.10000000000002, -611.3999999999999, -1120.0, -47.20000000000003, -99.69999999999982, -381.70000000000005, -705.9, -1081.0, -1269.7, -1380.4, -1008.0, -366.89999999999986, -204.59999999999997, -345.0999999999998, -299.39999999999986, -453.5999999999999, -460.40000000000003, -1122.7, -816.5999999999999, -1122.9, -727.6], "policy_predator_policy_reward": [37.0, 0.0, 4.0, 0.0, 69.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 2.0, 0.0, 0.0, 57.0, 87.0, 0.0, 0.0, 0.0, 73.0, 198.0, 0.0, 45.0, 50.0, 18.0, 0.0, 49.0, 34.0, 12.0, 18.0, 46.0, 53.0, 0.0, 14.0, 17.0, 20.0, 30.0, 0.0, 0.0, 40.0, 393.0, 4.0, 28.0, 107.0, 0.0, 806.0, 53.0, 47.0, 0.0, 16.0, 19.0, 17.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 172.0, 11.0, 59.0, 0.0, 3.0, 11.0, 15.0, 497.0, 0.0, 0.0, 17.0, 3.0, 6.0, 128.0, 35.0, 0.0, 0.0, 0.0, 4.0, 0.0, 17.0, 990.0, 0.0, 7.0, 1096.0, 202.0, 2.0, 61.0, 76.0, 183.0, 0.0, 41.0, 344.0, 238.0, 382.0, 6.0, 0.0, 23.0, 171.0, 0.0, 190.0, 191.0, 79.0, 103.0, 14.0, 254.0, 1.0, 134.0, 6.0, 73.0, 0.0, 358.0, 4.0, 422.0, 4.0, 16.0, 17.0, 172.0, 14.0, 223.0, 844.0, 29.0, 20.0, 0.0, 1100.0, 7.0, 0.0, 836.0, 863.0, 4.0, 0.0, 221.0, 0.0, 932.0, 222.0, 94.0, 37.0, 258.0, 17.0, 1146.0, 30.0, 0.0, 678.0, 749.0, 10.0, 949.0, 43.0, 0.0, 0.0, 699.0, 417.0, 5.0, 62.0, 352.0, 46.0, 923.0, 620.0, 1356.0, 270.0, 0.0, 665.0, 1141.0, 1009.0, 494.0, 17.0, 0.0, 1084.0, 0.0, 0.0, 0.0, 557.0, 787.0, 635.0, 663.0, 310.0, 200.0, 902.0, 37.0, 151.0, 1030.0, 956.0, 57.0, 20.0, 472.0, 438.0, 1174.0, 949.0, 516.0, 1424.0, 2.0, 373.0, 393.0, 42.0, 108.0, 407.0, 241.0, 1205.0, 790.0, 1153.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.7289293899852123, "mean_inference_ms": 4.637271489927083, "mean_action_processing_ms": 0.8156782947357439, "mean_env_wait_ms": 0.6012750332645155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00574648380279541, "StateBufferConnector_ms": 0.01292276382446289, "ViewRequirementAgentConnector_ms": 0.1895430088043213}, "num_episodes": 18, "episode_return_max": 533.8000000000005, "episode_return_min": -898.2, "episode_return_mean": -187.1459999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 313.3836520218683, "num_env_steps_trained_throughput_per_sec": 313.3836520218683, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 16185.393, "restore_workers_time_ms": 0.038, "training_step_time_ms": 16185.288, "sample_time_ms": 2980.152, "learn_time_ms": 13186.179, "learn_throughput": 303.348, "synch_weights_time_ms": 14.684}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "e57b0_00000", "date": "2024-08-13_00-23-20", "timestamp": 1723523000, "time_this_iter_s": 12.814335107803345, "time_total_s": 773.5873806476593, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bbca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 773.5873806476593, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 67.71111111111111, "ram_util_percent": 80.3611111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5017937366057326, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.620834995451428, "policy_loss": -0.004712539425651942, "vf_loss": 9.625114252706053, "vf_explained_var": 0.001469567717698516, "kl": 0.012171840786326448, "entropy": 1.1321922631490797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36645805586188557, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.962552976860572, "policy_loss": -0.0016486338275686775, "vf_loss": 9.964102389320495, "vf_explained_var": 0.000421223312458664, "kl": 0.009408056327914084, "entropy": 0.7161173751429906, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 627.7000000000002, "episode_reward_min": -933.2, "episode_reward_mean": -194.37799999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.10000000000023, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -416.15399999999994, "predator_policy": 318.965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.50000000000005, 7.900000000000061, 22.10000000000011, -552.1999999999999, -92.60000000000048, -724.9, 57.2000000000004, 26.900000000000105, 0.4000000000002072, 36.10000000000024, 58.90000000000052, 40.0000000000003, -453.7, -84.4, 64.60000000000043, 61.500000000000426, -211.19999999999982, 39.60000000000029, 52.60000000000051, -251.5000000000002, 76.89999999999955, 35.600000000000236, 32.10000000000018, -584.0999999999999, -838.0, -168.09999999999985, -110.70000000000005, -223.0999999999998, -332.69999999999993, -251.9999999999999, 55.00000000000045, -300.0000000000001, -340.19999999999993, -315.8, -223.10000000000082, -343.0999999999999, -374.4000000000001, -58.599999999999994, -301.5999999999998, -370.8999999999997, 24.700000000000056, -174.59999999999985, -445.20000000000005, 31.400000000000176, -588.5, 32.30000000000018, -317.0000000000001, 50.90000000000045, -284.49999999999994, -760.3, -178.50000000000003, -166.79999999999967, -728.6, -548.2, -601.0999999999999, -631.0, 58.90000000000048, -339.49999999999994, -109.59999999999992, -346.20000000000005, 103.40000000000009, -870.2, -734.2, -155.29999999999993, -295.00000000000006, -860.8, 43.60000000000035, -159.00000000000006, 533.8000000000005, -374.59999999999997, -898.2, -166.19999999999987, 254.60000000000036, -69.9, -177.59999999999997, -227.69999999999993, -448.4, -196.4999999999997, -209.4999999999997, -399.0, -493.29999999999995, 92.5, -475.4, 374.5, -269.9999999999998, 611.1000000000001, -199.79999999999978, 90.99999999999997, 58.00000000000035, -503.0999999999999, -456.79999999999995, 105.90000000000012, -933.2, 627.7000000000002, 166.0000000000002, -566.0, 30.50000000000044, 70.20000000000019, 223.20000000000005, 152.30000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, -26.199999999999747, -42.09999999999978, 20.000000000000014, -26.799999999999834, 8.900000000000004, -543.7, -405.5, -125.80000000000032, -101.80000000000021, -684.9000000000001, -846.0, -53.50000000000011, 10.699999999999989, 20.000000000000014, -9.09999999999988, -55.60000000000032, 20.000000000000014, 20.000000000000014, -19.899999999999743, 22.700000000000053, 36.20000000000026, 20.000000000000014, 20.000000000000014, -311.8, -313.9, -57.699999999999974, -96.70000000000022, 20.000000000000014, 41.600000000000236, 35.300000000000196, 0.1999999999999599, -163.00000000000006, -545.1999999999998, -5.49999999999994, 28.100000000000154, 7.399999999999965, 36.20000000000026, -184.60000000000014, -229.90000000000015, 46.10000000000023, 30.800000000000203, 11.599999999999964, 20.000000000000014, 30.800000000000203, -15.699999999999754, -643.0999999999999, -931.0, -1065.1, -875.9, -99.70000000000005, -272.39999999999986, -145.89999999999986, -101.80000000000001, -192.70000000000005, -213.39999999999992, -252.6999999999999, -464.99999999999994, -383.0999999999999, -488.9, 29.00000000000017, 20.000000000000014, -341.19999999999993, -152.79999999999998, -256.9, -273.2999999999999, -368.5, -217.3, -173.2000000000004, -166.90000000000043, -261.39999999999986, -336.7, -274.0, -240.40000000000003, -29.800000000000008, -101.79999999999987, -373.3, -290.30000000000007, -383.99999999999983, -412.90000000000003, 20.000000000000014, -28.299999999999756, -125.40000000000002, -235.20000000000002, -918.1999999999999, -594.0, -53.50000000000019, 35.90000000000024, -965.3, -723.2, 20.000000000000014, 5.299999999999965, -986.5, -1029.5, 26.90000000000013, 20.000000000000014, -248.10000000000002, -257.40000000000003, -1002.5999999999999, -911.7, -174.09999999999985, -135.40000000000003, -231.10000000000002, -210.7000000000006, -692.3, -1212.3, -589.1, -637.1, -685.6, -674.5, -583.8, -1039.2, 35.30000000000024, 23.600000000000065, -634.4, -821.1, -68.50000000000001, -108.09999999999995, -333.6, -410.6, -1227.4, -212.19999999999985, -1400.0, -1096.2, -711.6, -687.6, -1092.9, -1212.4, -322.5, -483.5, -893.6, -1051.2, 23.600000000000065, 20.000000000000014, -414.9, -301.1, -870.4, -17.80000000000004, -550.8, -796.8, -966.3, -1033.9, -222.10000000000065, -132.10000000000002, -611.3999999999999, -1120.0, -47.20000000000003, -99.69999999999982, -381.70000000000005, -705.9, -1081.0, -1269.7, -1380.4, -1008.0, -366.89999999999986, -204.59999999999997, -345.0999999999998, -299.39999999999986, -453.5999999999999, -460.40000000000003, -1122.7, -816.5999999999999, -1122.9, -727.6, -1182.4, -661.0, -1181.7, -80.80000000000004, -302.20000000000005, -413.79999999999995, -675.3, -182.5999999999999, -445.6, -383.19999999999993, -689.0, -497.9999999999999, -299.0, -33.999999999999815, -871.5, -901.5999999999999, -481.40000000000003, -481.40000000000003, -819.5999999999999, -825.5, -949.8, -948.4, -378.0999999999999, -1086.2, -683.9000000000001, -85.10000000000002, -923.2, -1001.8, -62.499999999999815, 20.000000000000014, -396.6999999999999, -810.1, -354.90000000000003, -1320.9, -382.8, -963.9], "policy_predator_policy_reward": [17.0, 20.0, 30.0, 0.0, 0.0, 40.0, 393.0, 4.0, 28.0, 107.0, 0.0, 806.0, 53.0, 47.0, 0.0, 16.0, 19.0, 17.0, 17.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 172.0, 11.0, 59.0, 0.0, 3.0, 11.0, 15.0, 497.0, 0.0, 0.0, 17.0, 3.0, 6.0, 128.0, 35.0, 0.0, 0.0, 0.0, 4.0, 0.0, 17.0, 990.0, 0.0, 7.0, 1096.0, 202.0, 2.0, 61.0, 76.0, 183.0, 0.0, 41.0, 344.0, 238.0, 382.0, 6.0, 0.0, 23.0, 171.0, 0.0, 190.0, 191.0, 79.0, 103.0, 14.0, 254.0, 1.0, 134.0, 6.0, 73.0, 0.0, 358.0, 4.0, 422.0, 4.0, 16.0, 17.0, 172.0, 14.0, 223.0, 844.0, 29.0, 20.0, 0.0, 1100.0, 7.0, 0.0, 836.0, 863.0, 4.0, 0.0, 221.0, 0.0, 932.0, 222.0, 94.0, 37.0, 258.0, 17.0, 1146.0, 30.0, 0.0, 678.0, 749.0, 10.0, 949.0, 43.0, 0.0, 0.0, 699.0, 417.0, 5.0, 62.0, 352.0, 46.0, 923.0, 620.0, 1356.0, 270.0, 0.0, 665.0, 1141.0, 1009.0, 494.0, 17.0, 0.0, 1084.0, 0.0, 0.0, 0.0, 557.0, 787.0, 635.0, 663.0, 310.0, 200.0, 902.0, 37.0, 151.0, 1030.0, 956.0, 57.0, 20.0, 472.0, 438.0, 1174.0, 949.0, 516.0, 1424.0, 2.0, 373.0, 393.0, 42.0, 108.0, 407.0, 241.0, 1205.0, 790.0, 1153.0, 212.0, 1156.0, 679.0, 958.0, 24.0, 422.0, 756.0, 713.0, 388.0, 241.0, 584.0, 694.0, 284.0, 107.0, 378.0, 892.0, 445.0, 61.0, 835.0, 916.0, 22.0, 943.0, 1021.0, 1071.0, 321.0, 614.0, 1171.0, 188.0, 47.0, 26.0, 697.0, 580.0, 1125.0, 774.0, 665.0, 834.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.7149124608679915, "mean_inference_ms": 4.5976205175871625, "mean_action_processing_ms": 0.806797411259058, "mean_env_wait_ms": 0.5960656042306831, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005594015121459961, "StateBufferConnector_ms": 0.01275634765625, "ViewRequirementAgentConnector_ms": 0.1836531162261963}, "num_episodes": 18, "episode_return_max": 627.7000000000002, "episode_return_min": -933.2, "episode_return_mean": -194.37799999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.8568664463996, "num_env_steps_trained_throughput_per_sec": 349.8568664463996, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 14796.154, "restore_workers_time_ms": 0.037, "training_step_time_ms": 14796.052, "sample_time_ms": 2637.047, "learn_time_ms": 12140.375, "learn_throughput": 329.479, "synch_weights_time_ms": 14.459}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "e57b0_00000", "date": "2024-08-13_00-23-31", "timestamp": 1723523011, "time_this_iter_s": 11.498768329620361, "time_total_s": 785.0861489772797, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09fbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 785.0861489772797, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 58.182352941176475, "ram_util_percent": 80.15294117647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7820191446829725, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.931449102220081, "policy_loss": -0.003796988175245662, "vf_loss": 7.934906594967716, "vf_explained_var": 0.0011242261008610802, "kl": 0.009537858332796897, "entropy": 1.0692238591966174, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.981732142409162, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.716238806991981, "policy_loss": -0.0023735736755447255, "vf_loss": 8.718538654670514, "vf_explained_var": 0.0017545896232443513, "kl": 0.006988238505260123, "entropy": 0.7560354832934324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 903.1000000000018, "episode_reward_min": -933.2, "episode_reward_mean": -160.40599999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.90000000000024, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -530.423, "predator_policy": 450.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.10000000000018, -584.0999999999999, -838.0, -168.09999999999985, -110.70000000000005, -223.0999999999998, -332.69999999999993, -251.9999999999999, 55.00000000000045, -300.0000000000001, -340.19999999999993, -315.8, -223.10000000000082, -343.0999999999999, -374.4000000000001, -58.599999999999994, -301.5999999999998, -370.8999999999997, 24.700000000000056, -174.59999999999985, -445.20000000000005, 31.400000000000176, -588.5, 32.30000000000018, -317.0000000000001, 50.90000000000045, -284.49999999999994, -760.3, -178.50000000000003, -166.79999999999967, -728.6, -548.2, -601.0999999999999, -631.0, 58.90000000000048, -339.49999999999994, -109.59999999999992, -346.20000000000005, 103.40000000000009, -870.2, -734.2, -155.29999999999993, -295.00000000000006, -860.8, 43.60000000000035, -159.00000000000006, 533.8000000000005, -374.59999999999997, -898.2, -166.19999999999987, 254.60000000000036, -69.9, -177.59999999999997, -227.69999999999993, -448.4, -196.4999999999997, -209.4999999999997, -399.0, -493.29999999999995, 92.5, -475.4, 374.5, -269.9999999999998, 611.1000000000001, -199.79999999999978, 90.99999999999997, 58.00000000000035, -503.0999999999999, -456.79999999999995, 105.90000000000012, -933.2, 627.7000000000002, 166.0000000000002, -566.0, 30.50000000000044, 70.20000000000019, 223.20000000000005, 152.30000000000013, 198.70000000000007, 186.5999999999997, -362.6, -388.6, -197.20000000000002, 12.200000000000271, -175.79999999999984, 602.3000000000008, 37.600000000000264, 405.19999999999993, 442.9999999999999, -225.09999999999982, -190.89999999999998, 53.90000000000046, -9.799999999999955, 903.1000000000018, 152.7000000000002, -283.9, -157.70000000000005, -21.9999999999998, 591.3000000000003, 58.500000000000064], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [30.800000000000203, -15.699999999999754, -643.0999999999999, -931.0, -1065.1, -875.9, -99.70000000000005, -272.39999999999986, -145.89999999999986, -101.80000000000001, -192.70000000000005, -213.39999999999992, -252.6999999999999, -464.99999999999994, -383.0999999999999, -488.9, 29.00000000000017, 20.000000000000014, -341.19999999999993, -152.79999999999998, -256.9, -273.2999999999999, -368.5, -217.3, -173.2000000000004, -166.90000000000043, -261.39999999999986, -336.7, -274.0, -240.40000000000003, -29.800000000000008, -101.79999999999987, -373.3, -290.30000000000007, -383.99999999999983, -412.90000000000003, 20.000000000000014, -28.299999999999756, -125.40000000000002, -235.20000000000002, -918.1999999999999, -594.0, -53.50000000000019, 35.90000000000024, -965.3, -723.2, 20.000000000000014, 5.299999999999965, -986.5, -1029.5, 26.90000000000013, 20.000000000000014, -248.10000000000002, -257.40000000000003, -1002.5999999999999, -911.7, -174.09999999999985, -135.40000000000003, -231.10000000000002, -210.7000000000006, -692.3, -1212.3, -589.1, -637.1, -685.6, -674.5, -583.8, -1039.2, 35.30000000000024, 23.600000000000065, -634.4, -821.1, -68.50000000000001, -108.09999999999995, -333.6, -410.6, -1227.4, -212.19999999999985, -1400.0, -1096.2, -711.6, -687.6, -1092.9, -1212.4, -322.5, -483.5, -893.6, -1051.2, 23.600000000000065, 20.000000000000014, -414.9, -301.1, -870.4, -17.80000000000004, -550.8, -796.8, -966.3, -1033.9, -222.10000000000065, -132.10000000000002, -611.3999999999999, -1120.0, -47.20000000000003, -99.69999999999982, -381.70000000000005, -705.9, -1081.0, -1269.7, -1380.4, -1008.0, -366.89999999999986, -204.59999999999997, -345.0999999999998, -299.39999999999986, -453.5999999999999, -460.40000000000003, -1122.7, -816.5999999999999, -1122.9, -727.6, -1182.4, -661.0, -1181.7, -80.80000000000004, -302.20000000000005, -413.79999999999995, -675.3, -182.5999999999999, -445.6, -383.19999999999993, -689.0, -497.9999999999999, -299.0, -33.999999999999815, -871.5, -901.5999999999999, -481.40000000000003, -481.40000000000003, -819.5999999999999, -825.5, -949.8, -948.4, -378.0999999999999, -1086.2, -683.9000000000001, -85.10000000000002, -923.2, -1001.8, -62.499999999999815, 20.000000000000014, -396.6999999999999, -810.1, -354.90000000000003, -1320.9, -382.8, -963.9, -3.1000000000000014, -992.2, 20.000000000000014, -769.4, -1094.1, -1118.5, -1284.8, -1265.8, -555.9000000000001, -931.3, -55.59999999999994, 15.799999999999963, -611.7, -709.0999999999999, -1116.7, 20.000000000000014, -9.40000000000004, 20.000000000000014, -1085.8, -183.00000000000003, -93.40000000000003, -1063.6, -422.90000000000003, -226.20000000000002, -891.2, -1066.7, -48.0999999999998, 20.000000000000014, -1313.9, -1118.9, -143.99999999999983, -1399.9, -957.7, -603.6, -642.0, -695.9, -766.4, -1151.3, -145.99999999999994, -315.0, -1287.8, -271.89999999999986, -914.4, 17.900000000000013], "policy_predator_policy_reward": [0.0, 17.0, 990.0, 0.0, 7.0, 1096.0, 202.0, 2.0, 61.0, 76.0, 183.0, 0.0, 41.0, 344.0, 238.0, 382.0, 6.0, 0.0, 23.0, 171.0, 0.0, 190.0, 191.0, 79.0, 103.0, 14.0, 254.0, 1.0, 134.0, 6.0, 73.0, 0.0, 358.0, 4.0, 422.0, 4.0, 16.0, 17.0, 172.0, 14.0, 223.0, 844.0, 29.0, 20.0, 0.0, 1100.0, 7.0, 0.0, 836.0, 863.0, 4.0, 0.0, 221.0, 0.0, 932.0, 222.0, 94.0, 37.0, 258.0, 17.0, 1146.0, 30.0, 0.0, 678.0, 749.0, 10.0, 949.0, 43.0, 0.0, 0.0, 699.0, 417.0, 5.0, 62.0, 352.0, 46.0, 923.0, 620.0, 1356.0, 270.0, 0.0, 665.0, 1141.0, 1009.0, 494.0, 17.0, 0.0, 1084.0, 0.0, 0.0, 0.0, 557.0, 787.0, 635.0, 663.0, 310.0, 200.0, 902.0, 37.0, 151.0, 1030.0, 956.0, 57.0, 20.0, 472.0, 438.0, 1174.0, 949.0, 516.0, 1424.0, 2.0, 373.0, 393.0, 42.0, 108.0, 407.0, 241.0, 1205.0, 790.0, 1153.0, 212.0, 1156.0, 679.0, 958.0, 24.0, 422.0, 756.0, 713.0, 388.0, 241.0, 584.0, 694.0, 284.0, 107.0, 378.0, 892.0, 445.0, 61.0, 835.0, 916.0, 22.0, 943.0, 1021.0, 1071.0, 321.0, 614.0, 1171.0, 188.0, 47.0, 26.0, 697.0, 580.0, 1125.0, 774.0, 665.0, 834.0, 918.0, 276.0, 651.0, 285.0, 971.0, 879.0, 841.0, 1321.0, 886.0, 404.0, 11.0, 41.0, 423.0, 722.0, 740.0, 959.0, 14.0, 13.0, 1056.0, 618.0, 943.0, 657.0, 11.0, 413.0, 995.0, 772.0, 41.0, 41.0, 1268.0, 1155.0, 1345.0, 1102.0, 750.0, 964.0, 460.0, 594.0, 687.0, 1073.0, 206.0, 233.0, 1193.0, 958.0, 855.0, 100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.6997353306234817, "mean_inference_ms": 4.552686573358554, "mean_action_processing_ms": 0.7965729056903684, "mean_env_wait_ms": 0.5901368886551581, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004282951354980469, "StateBufferConnector_ms": 0.01233530044555664, "ViewRequirementAgentConnector_ms": 0.16701626777648926}, "num_episodes": 22, "episode_return_max": 903.1000000000018, "episode_return_min": -933.2, "episode_return_mean": -160.40599999999986, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 211.46483093473978, "num_env_steps_trained_throughput_per_sec": 211.46483093473978, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 13769.865, "restore_workers_time_ms": 0.036, "training_step_time_ms": 13769.765, "sample_time_ms": 2233.286, "learn_time_ms": 11518.416, "learn_throughput": 347.27, "synch_weights_time_ms": 13.97}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "e57b0_00000", "date": "2024-08-13_00-23-50", "timestamp": 1723523030, "time_this_iter_s": 18.98220181465149, "time_total_s": 804.0683507919312, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0db5700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 804.0683507919312, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 87.28888888888888, "ram_util_percent": 83.08888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6577925482242512, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.463617709326366, "policy_loss": -0.004626942484851473, "vf_loss": 5.467920660341858, "vf_explained_var": 0.0016004266562285247, "kl": 0.009101619479178128, "entropy": 1.0056776914016279, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9315576520861772, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.011920189226746, "policy_loss": -0.003991786459653032, "vf_loss": 8.015826697072024, "vf_explained_var": 0.0010834045195705676, "kl": 0.008083809978105443, "entropy": 0.7570689599350016, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 1009.5000000000019, "episode_reward_min": -933.2, "episode_reward_mean": -51.51699999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000024, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -539.1985000000001, "predator_policy": 513.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, -317.0000000000001, 50.90000000000045, -284.49999999999994, -760.3, -178.50000000000003, -166.79999999999967, -728.6, -548.2, -601.0999999999999, -631.0, 58.90000000000048, -339.49999999999994, -109.59999999999992, -346.20000000000005, 103.40000000000009, -870.2, -734.2, -155.29999999999993, -295.00000000000006, -860.8, 43.60000000000035, -159.00000000000006, 533.8000000000005, -374.59999999999997, -898.2, -166.19999999999987, 254.60000000000036, -69.9, -177.59999999999997, -227.69999999999993, -448.4, -196.4999999999997, -209.4999999999997, -399.0, -493.29999999999995, 92.5, -475.4, 374.5, -269.9999999999998, 611.1000000000001, -199.79999999999978, 90.99999999999997, 58.00000000000035, -503.0999999999999, -456.79999999999995, 105.90000000000012, -933.2, 627.7000000000002, 166.0000000000002, -566.0, 30.50000000000044, 70.20000000000019, 223.20000000000005, 152.30000000000013, 198.70000000000007, 186.5999999999997, -362.6, -388.6, -197.20000000000002, 12.200000000000271, -175.79999999999984, 602.3000000000008, 37.600000000000264, 405.19999999999993, 442.9999999999999, -225.09999999999982, -190.89999999999998, 53.90000000000046, -9.799999999999955, 903.1000000000018, 152.7000000000002, -283.9, -157.70000000000005, -21.9999999999998, 591.3000000000003, 58.500000000000064, 920.900000000002, 46.10000000000024, 50.50000000000045, 7.0, 83.40000000000029, 40.0000000000003, -0.7999999999998226, 509.10000000000093, 119.89999999999998, 158.19999999999928, 951.9000000000016, -208.79999999999998, -74.90000000000009, 51.70000000000049, 1009.5000000000019, 31.099999999999987, 527.5000000000006, -87.99999999999984, 499.90000000000043, 81.20000000000019, -52.79999999999974, 38.300000000000274, -13.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 5.299999999999965, -986.5, -1029.5, 26.90000000000013, 20.000000000000014, -248.10000000000002, -257.40000000000003, -1002.5999999999999, -911.7, -174.09999999999985, -135.40000000000003, -231.10000000000002, -210.7000000000006, -692.3, -1212.3, -589.1, -637.1, -685.6, -674.5, -583.8, -1039.2, 35.30000000000024, 23.600000000000065, -634.4, -821.1, -68.50000000000001, -108.09999999999995, -333.6, -410.6, -1227.4, -212.19999999999985, -1400.0, -1096.2, -711.6, -687.6, -1092.9, -1212.4, -322.5, -483.5, -893.6, -1051.2, 23.600000000000065, 20.000000000000014, -414.9, -301.1, -870.4, -17.80000000000004, -550.8, -796.8, -966.3, -1033.9, -222.10000000000065, -132.10000000000002, -611.3999999999999, -1120.0, -47.20000000000003, -99.69999999999982, -381.70000000000005, -705.9, -1081.0, -1269.7, -1380.4, -1008.0, -366.89999999999986, -204.59999999999997, -345.0999999999998, -299.39999999999986, -453.5999999999999, -460.40000000000003, -1122.7, -816.5999999999999, -1122.9, -727.6, -1182.4, -661.0, -1181.7, -80.80000000000004, -302.20000000000005, -413.79999999999995, -675.3, -182.5999999999999, -445.6, -383.19999999999993, -689.0, -497.9999999999999, -299.0, -33.999999999999815, -871.5, -901.5999999999999, -481.40000000000003, -481.40000000000003, -819.5999999999999, -825.5, -949.8, -948.4, -378.0999999999999, -1086.2, -683.9000000000001, -85.10000000000002, -923.2, -1001.8, -62.499999999999815, 20.000000000000014, -396.6999999999999, -810.1, -354.90000000000003, -1320.9, -382.8, -963.9, -3.1000000000000014, -992.2, 20.000000000000014, -769.4, -1094.1, -1118.5, -1284.8, -1265.8, -555.9000000000001, -931.3, -55.59999999999994, 15.799999999999963, -611.7, -709.0999999999999, -1116.7, 20.000000000000014, -9.40000000000004, 20.000000000000014, -1085.8, -183.00000000000003, -93.40000000000003, -1063.6, -422.90000000000003, -226.20000000000002, -891.2, -1066.7, -48.0999999999998, 20.000000000000014, -1313.9, -1118.9, -143.99999999999983, -1399.9, -957.7, -603.6, -642.0, -695.9, -766.4, -1151.3, -145.99999999999994, -315.0, -1287.8, -271.89999999999986, -914.4, 17.900000000000013, 20.000000000000014, -1201.1, -69.90000000000003, 20.000000000000014, -69.09999999999985, 17.59999999999998, -732.9999999999999, -771.0, -248.60000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -143.79999999999987, -15.699999999999754, -779.2, -1352.9, -1135.2, 39.80000000000024, -451.5999999999999, 20.000000000000014, -1173.1, -592.1999999999999, -482.6, -511.1999999999998, -880.6999999999999, 20.000000000000014, 31.700000000000212, -1347.9, -13.599999999999783, -256.7999999999999, -162.10000000000005, 20.000000000000014, -648.5, -47.20000000000003, -131.80000000000004, 12.499999999999964, -850.6, -328.9999999999999, -372.8, -273.79999999999995, 20.000000000000014, 16.399999999999967, 17.899999999999988, -144.39999999999998, -1189.1], "policy_predator_policy_reward": [7.0, 0.0, 836.0, 863.0, 4.0, 0.0, 221.0, 0.0, 932.0, 222.0, 94.0, 37.0, 258.0, 17.0, 1146.0, 30.0, 0.0, 678.0, 749.0, 10.0, 949.0, 43.0, 0.0, 0.0, 699.0, 417.0, 5.0, 62.0, 352.0, 46.0, 923.0, 620.0, 1356.0, 270.0, 0.0, 665.0, 1141.0, 1009.0, 494.0, 17.0, 0.0, 1084.0, 0.0, 0.0, 0.0, 557.0, 787.0, 635.0, 663.0, 310.0, 200.0, 902.0, 37.0, 151.0, 1030.0, 956.0, 57.0, 20.0, 472.0, 438.0, 1174.0, 949.0, 516.0, 1424.0, 2.0, 373.0, 393.0, 42.0, 108.0, 407.0, 241.0, 1205.0, 790.0, 1153.0, 212.0, 1156.0, 679.0, 958.0, 24.0, 422.0, 756.0, 713.0, 388.0, 241.0, 584.0, 694.0, 284.0, 107.0, 378.0, 892.0, 445.0, 61.0, 835.0, 916.0, 22.0, 943.0, 1021.0, 1071.0, 321.0, 614.0, 1171.0, 188.0, 47.0, 26.0, 697.0, 580.0, 1125.0, 774.0, 665.0, 834.0, 918.0, 276.0, 651.0, 285.0, 971.0, 879.0, 841.0, 1321.0, 886.0, 404.0, 11.0, 41.0, 423.0, 722.0, 740.0, 959.0, 14.0, 13.0, 1056.0, 618.0, 943.0, 657.0, 11.0, 413.0, 995.0, 772.0, 41.0, 41.0, 1268.0, 1155.0, 1345.0, 1102.0, 750.0, 964.0, 460.0, 594.0, 687.0, 1073.0, 206.0, 233.0, 1193.0, 958.0, 855.0, 100.0, 1105.0, 997.0, 48.0, 48.0, 55.0, 47.0, 796.0, 715.0, 154.0, 158.0, 0.0, 0.0, 79.0, 65.0, 685.0, 619.0, 1210.0, 1398.0, 297.0, 273.0, 1064.0, 1041.0, 829.0, 37.0, 876.0, 441.0, 0.0, 0.0, 1241.0, 1130.0, 219.0, 231.0, 574.0, 582.0, 17.0, 74.0, 654.0, 684.0, 405.0, 378.0, 191.0, 10.0, 3.0, 1.0, 247.0, 1073.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.6827297459845125, "mean_inference_ms": 4.497983580396571, "mean_action_processing_ms": 0.785264997602338, "mean_env_wait_ms": 0.5829131305274994, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004781842231750488, "StateBufferConnector_ms": 0.012347936630249023, "ViewRequirementAgentConnector_ms": 0.18270468711853027}, "num_episodes": 23, "episode_return_max": 1009.5000000000019, "episode_return_min": -933.2, "episode_return_mean": -51.51699999999982, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.2371607454702, "num_env_steps_trained_throughput_per_sec": 339.2371607454702, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 13475.245, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13475.188, "sample_time_ms": 2208.918, "learn_time_ms": 11250.086, "learn_throughput": 355.553, "synch_weights_time_ms": 13.402}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "e57b0_00000", "date": "2024-08-13_00-24-02", "timestamp": 1723523042, "time_this_iter_s": 11.832819938659668, "time_total_s": 815.9011707305908, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dbad30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 815.9011707305908, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 62.1, "ram_util_percent": 83.725}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.149652561543401, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9028692116813053, "policy_loss": -0.0016561089825161076, "vf_loss": 2.9043649466580184, "vf_explained_var": 0.0031023667287574243, "kl": 0.004505389607803789, "entropy": 1.0245160893157677, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9286016975327459, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9318904652166617, "policy_loss": -0.0019817789385794963, "vf_loss": 3.933789978834687, "vf_explained_var": 0.001316886414926519, "kl": 0.007799048913355714, "entropy": 0.8134913918833253, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 1009.5000000000019, "episode_reward_min": -933.2, "episode_reward_mean": 22.95300000000023, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1399.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000024, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -455.1085, "predator_policy": 466.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-155.29999999999993, -295.00000000000006, -860.8, 43.60000000000035, -159.00000000000006, 533.8000000000005, -374.59999999999997, -898.2, -166.19999999999987, 254.60000000000036, -69.9, -177.59999999999997, -227.69999999999993, -448.4, -196.4999999999997, -209.4999999999997, -399.0, -493.29999999999995, 92.5, -475.4, 374.5, -269.9999999999998, 611.1000000000001, -199.79999999999978, 90.99999999999997, 58.00000000000035, -503.0999999999999, -456.79999999999995, 105.90000000000012, -933.2, 627.7000000000002, 166.0000000000002, -566.0, 30.50000000000044, 70.20000000000019, 223.20000000000005, 152.30000000000013, 198.70000000000007, 186.5999999999997, -362.6, -388.6, -197.20000000000002, 12.200000000000271, -175.79999999999984, 602.3000000000008, 37.600000000000264, 405.19999999999993, 442.9999999999999, -225.09999999999982, -190.89999999999998, 53.90000000000046, -9.799999999999955, 903.1000000000018, 152.7000000000002, -283.9, -157.70000000000005, -21.9999999999998, 591.3000000000003, 58.500000000000064, 920.900000000002, 46.10000000000024, 50.50000000000045, 7.0, 83.40000000000029, 40.0000000000003, -0.7999999999998226, 509.10000000000093, 119.89999999999998, 158.19999999999928, 951.9000000000016, -208.79999999999998, -74.90000000000009, 51.70000000000049, 1009.5000000000019, 31.099999999999987, 527.5000000000006, -87.99999999999984, 499.90000000000043, 81.20000000000019, -52.79999999999974, 38.300000000000274, -13.5, 40.0000000000003, 38.90000000000045, -21.899999999999487, 21.299999999999994, -14.099999999999799, 58.500000000000504, 329.9000000000002, 48.10000000000043, 27.800000000000114, 32.700000000000195, 17.89999999999996, 19.500000000000004, 2.6999999999999895, -53.50000000000004, 63.40000000000053, 30.100000000000147, -15.799999999999848, 451.3000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1092.9, -1212.4, -322.5, -483.5, -893.6, -1051.2, 23.600000000000065, 20.000000000000014, -414.9, -301.1, -870.4, -17.80000000000004, -550.8, -796.8, -966.3, -1033.9, -222.10000000000065, -132.10000000000002, -611.3999999999999, -1120.0, -47.20000000000003, -99.69999999999982, -381.70000000000005, -705.9, -1081.0, -1269.7, -1380.4, -1008.0, -366.89999999999986, -204.59999999999997, -345.0999999999998, -299.39999999999986, -453.5999999999999, -460.40000000000003, -1122.7, -816.5999999999999, -1122.9, -727.6, -1182.4, -661.0, -1181.7, -80.80000000000004, -302.20000000000005, -413.79999999999995, -675.3, -182.5999999999999, -445.6, -383.19999999999993, -689.0, -497.9999999999999, -299.0, -33.999999999999815, -871.5, -901.5999999999999, -481.40000000000003, -481.40000000000003, -819.5999999999999, -825.5, -949.8, -948.4, -378.0999999999999, -1086.2, -683.9000000000001, -85.10000000000002, -923.2, -1001.8, -62.499999999999815, 20.000000000000014, -396.6999999999999, -810.1, -354.90000000000003, -1320.9, -382.8, -963.9, -3.1000000000000014, -992.2, 20.000000000000014, -769.4, -1094.1, -1118.5, -1284.8, -1265.8, -555.9000000000001, -931.3, -55.59999999999994, 15.799999999999963, -611.7, -709.0999999999999, -1116.7, 20.000000000000014, -9.40000000000004, 20.000000000000014, -1085.8, -183.00000000000003, -93.40000000000003, -1063.6, -422.90000000000003, -226.20000000000002, -891.2, -1066.7, -48.0999999999998, 20.000000000000014, -1313.9, -1118.9, -143.99999999999983, -1399.9, -957.7, -603.6, -642.0, -695.9, -766.4, -1151.3, -145.99999999999994, -315.0, -1287.8, -271.89999999999986, -914.4, 17.900000000000013, 20.000000000000014, -1201.1, -69.90000000000003, 20.000000000000014, -69.09999999999985, 17.59999999999998, -732.9999999999999, -771.0, -248.60000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -143.79999999999987, -15.699999999999754, -779.2, -1352.9, -1135.2, 39.80000000000024, -451.5999999999999, 20.000000000000014, -1173.1, -592.1999999999999, -482.6, -511.1999999999998, -880.6999999999999, 20.000000000000014, 31.700000000000212, -1347.9, -13.599999999999783, -256.7999999999999, -162.10000000000005, 20.000000000000014, -648.5, -47.20000000000003, -131.80000000000004, 12.499999999999964, -850.6, -328.9999999999999, -372.8, -273.79999999999995, 20.000000000000014, 16.399999999999967, 17.899999999999988, -144.39999999999998, -1189.1, 20.000000000000014, 20.000000000000014, -24.100000000000048, 29.000000000000167, -19.899999999999743, -21.999999999999744, -15.699999999999747, 20.000000000000014, -600.6, 9.499999999999964, 21.80000000000004, 34.70000000000025, 20.000000000000014, -653.1, 20.000000000000014, 28.100000000000147, 6.499999999999972, -3.6999999999999584, 15.499999999999963, 3.1999999999999615, 20.000000000000014, -66.09999999999997, -0.9999999999999846, 9.499999999999964, -70.30000000000054, 16.999999999999975, -91.29999999999984, -105.20000000000005, 34.40000000000026, 29.000000000000163, 1.0999999999999865, 20.000000000000014, -11.500000000000014, -70.30000000000037, 37.10000000000024, -724.8], "policy_predator_policy_reward": [1141.0, 1009.0, 494.0, 17.0, 0.0, 1084.0, 0.0, 0.0, 0.0, 557.0, 787.0, 635.0, 663.0, 310.0, 200.0, 902.0, 37.0, 151.0, 1030.0, 956.0, 57.0, 20.0, 472.0, 438.0, 1174.0, 949.0, 516.0, 1424.0, 2.0, 373.0, 393.0, 42.0, 108.0, 407.0, 241.0, 1205.0, 790.0, 1153.0, 212.0, 1156.0, 679.0, 958.0, 24.0, 422.0, 756.0, 713.0, 388.0, 241.0, 584.0, 694.0, 284.0, 107.0, 378.0, 892.0, 445.0, 61.0, 835.0, 916.0, 22.0, 943.0, 1021.0, 1071.0, 321.0, 614.0, 1171.0, 188.0, 47.0, 26.0, 697.0, 580.0, 1125.0, 774.0, 665.0, 834.0, 918.0, 276.0, 651.0, 285.0, 971.0, 879.0, 841.0, 1321.0, 886.0, 404.0, 11.0, 41.0, 423.0, 722.0, 740.0, 959.0, 14.0, 13.0, 1056.0, 618.0, 943.0, 657.0, 11.0, 413.0, 995.0, 772.0, 41.0, 41.0, 1268.0, 1155.0, 1345.0, 1102.0, 750.0, 964.0, 460.0, 594.0, 687.0, 1073.0, 206.0, 233.0, 1193.0, 958.0, 855.0, 100.0, 1105.0, 997.0, 48.0, 48.0, 55.0, 47.0, 796.0, 715.0, 154.0, 158.0, 0.0, 0.0, 79.0, 65.0, 685.0, 619.0, 1210.0, 1398.0, 297.0, 273.0, 1064.0, 1041.0, 829.0, 37.0, 876.0, 441.0, 0.0, 0.0, 1241.0, 1130.0, 219.0, 231.0, 574.0, 582.0, 17.0, 74.0, 654.0, 684.0, 405.0, 378.0, 191.0, 10.0, 3.0, 1.0, 247.0, 1073.0, 0.0, 0.0, 13.0, 21.0, 0.0, 20.0, 0.0, 17.0, 100.0, 477.0, 2.0, 0.0, 476.0, 487.0, 0.0, 0.0, 12.0, 13.0, 0.0, 14.0, 34.0, 30.0, 0.0, 11.0, 9.0, 47.0, 72.0, 71.0, 0.0, 0.0, 0.0, 9.0, 58.0, 8.0, 582.0, 557.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.6683234243191682, "mean_inference_ms": 4.454697635322425, "mean_action_processing_ms": 0.7764581082508721, "mean_env_wait_ms": 0.5769372051603257, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005009651184082031, "StateBufferConnector_ms": 0.0035158395767211914, "ViewRequirementAgentConnector_ms": 0.16490674018859863}, "num_episodes": 18, "episode_return_max": 1009.5000000000019, "episode_return_min": -933.2, "episode_return_mean": 22.95300000000023, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.25646822684126, "num_env_steps_trained_throughput_per_sec": 290.25646822684126, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 13475.229, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13475.176, "sample_time_ms": 2149.008, "learn_time_ms": 11310.486, "learn_throughput": 353.654, "synch_weights_time_ms": 12.894}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "e57b0_00000", "date": "2024-08-13_00-24-16", "timestamp": 1723523056, "time_this_iter_s": 13.851895093917847, "time_total_s": 829.7530658245087, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dba160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 829.7530658245087, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 73.27, "ram_util_percent": 83.455}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8620755582929603, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.160400630809643, "policy_loss": -0.00418722825149498, "vf_loss": 2.164385271072388, "vf_explained_var": 0.001964011583378706, "kl": 0.011382413661116263, "entropy": 1.0411962195678994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7708056746651887, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5696533510924646, "policy_loss": -0.0013443672497357641, "vf_loss": 2.5708935887094526, "vf_explained_var": -0.00012362173625401088, "kl": 0.009872476644482875, "entropy": 0.8426947259713733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 1009.5000000000019, "episode_reward_min": -933.2, "episode_reward_mean": 72.94100000000022, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1399.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000024, "predator_policy": 1398.0}, "policy_reward_mean": {"prey_policy": -358.00949999999995, "predator_policy": 394.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [92.5, -475.4, 374.5, -269.9999999999998, 611.1000000000001, -199.79999999999978, 90.99999999999997, 58.00000000000035, -503.0999999999999, -456.79999999999995, 105.90000000000012, -933.2, 627.7000000000002, 166.0000000000002, -566.0, 30.50000000000044, 70.20000000000019, 223.20000000000005, 152.30000000000013, 198.70000000000007, 186.5999999999997, -362.6, -388.6, -197.20000000000002, 12.200000000000271, -175.79999999999984, 602.3000000000008, 37.600000000000264, 405.19999999999993, 442.9999999999999, -225.09999999999982, -190.89999999999998, 53.90000000000046, -9.799999999999955, 903.1000000000018, 152.7000000000002, -283.9, -157.70000000000005, -21.9999999999998, 591.3000000000003, 58.500000000000064, 920.900000000002, 46.10000000000024, 50.50000000000045, 7.0, 83.40000000000029, 40.0000000000003, -0.7999999999998226, 509.10000000000093, 119.89999999999998, 158.19999999999928, 951.9000000000016, -208.79999999999998, -74.90000000000009, 51.70000000000049, 1009.5000000000019, 31.099999999999987, 527.5000000000006, -87.99999999999984, 499.90000000000043, 81.20000000000019, -52.79999999999974, 38.300000000000274, -13.5, 40.0000000000003, 38.90000000000045, -21.899999999999487, 21.299999999999994, -14.099999999999799, 58.500000000000504, 329.9000000000002, 48.10000000000043, 27.800000000000114, 32.700000000000195, 17.89999999999996, 19.500000000000004, 2.6999999999999895, -53.50000000000004, 63.40000000000053, 30.100000000000147, -15.799999999999848, 451.3000000000018, -32.199999999999655, 1.0000000000002356, 37.800000000000296, 40.90000000000031, -76.20000000000053, 42.700000000000344, 58.0000000000005, 12.50000000000003, 18.599999999999977, -146.60000000000045, 32.0000000000002, 44.40000000000037, 40.0000000000003, 40.400000000000304, 316.9000000000001, 38.90000000000028, 40.0000000000003, 190.69999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1122.9, -727.6, -1182.4, -661.0, -1181.7, -80.80000000000004, -302.20000000000005, -413.79999999999995, -675.3, -182.5999999999999, -445.6, -383.19999999999993, -689.0, -497.9999999999999, -299.0, -33.999999999999815, -871.5, -901.5999999999999, -481.40000000000003, -481.40000000000003, -819.5999999999999, -825.5, -949.8, -948.4, -378.0999999999999, -1086.2, -683.9000000000001, -85.10000000000002, -923.2, -1001.8, -62.499999999999815, 20.000000000000014, -396.6999999999999, -810.1, -354.90000000000003, -1320.9, -382.8, -963.9, -3.1000000000000014, -992.2, 20.000000000000014, -769.4, -1094.1, -1118.5, -1284.8, -1265.8, -555.9000000000001, -931.3, -55.59999999999994, 15.799999999999963, -611.7, -709.0999999999999, -1116.7, 20.000000000000014, -9.40000000000004, 20.000000000000014, -1085.8, -183.00000000000003, -93.40000000000003, -1063.6, -422.90000000000003, -226.20000000000002, -891.2, -1066.7, -48.0999999999998, 20.000000000000014, -1313.9, -1118.9, -143.99999999999983, -1399.9, -957.7, -603.6, -642.0, -695.9, -766.4, -1151.3, -145.99999999999994, -315.0, -1287.8, -271.89999999999986, -914.4, 17.900000000000013, 20.000000000000014, -1201.1, -69.90000000000003, 20.000000000000014, -69.09999999999985, 17.59999999999998, -732.9999999999999, -771.0, -248.60000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -143.79999999999987, -15.699999999999754, -779.2, -1352.9, -1135.2, 39.80000000000024, -451.5999999999999, 20.000000000000014, -1173.1, -592.1999999999999, -482.6, -511.1999999999998, -880.6999999999999, 20.000000000000014, 31.700000000000212, -1347.9, -13.599999999999783, -256.7999999999999, -162.10000000000005, 20.000000000000014, -648.5, -47.20000000000003, -131.80000000000004, 12.499999999999964, -850.6, -328.9999999999999, -372.8, -273.79999999999995, 20.000000000000014, 16.399999999999967, 17.899999999999988, -144.39999999999998, -1189.1, 20.000000000000014, 20.000000000000014, -24.100000000000048, 29.000000000000167, -19.899999999999743, -21.999999999999744, -15.699999999999747, 20.000000000000014, -600.6, 9.499999999999964, 21.80000000000004, 34.70000000000025, 20.000000000000014, -653.1, 20.000000000000014, 28.100000000000147, 6.499999999999972, -3.6999999999999584, 15.499999999999963, 3.1999999999999615, 20.000000000000014, -66.09999999999997, -0.9999999999999846, 9.499999999999964, -70.30000000000054, 16.999999999999975, -91.29999999999984, -105.20000000000005, 34.40000000000026, 29.000000000000163, 1.0999999999999865, 20.000000000000014, -11.500000000000014, -70.30000000000037, 37.10000000000024, -724.8, 15.799999999999946, -148.00000000000054, -5.1999999999999265, -17.79999999999975, 20.000000000000014, 15.799999999999946, 20.000000000000014, 20.90000000000003, -271.4999999999991, -78.70000000000027, 20.000000000000014, 13.699999999999973, 38.00000000000024, 20.000000000000014, -30.39999999999975, 17.899999999999988, 20.000000000000014, -51.39999999999977, -206.80000000000015, -143.80000000000032, -87.10000000000046, 25.1000000000001, 20.000000000000014, 19.40000000000001, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, -877.2, 7.0999999999999694, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -867.5, -332.7999999999997], "policy_predator_policy_reward": [790.0, 1153.0, 212.0, 1156.0, 679.0, 958.0, 24.0, 422.0, 756.0, 713.0, 388.0, 241.0, 584.0, 694.0, 284.0, 107.0, 378.0, 892.0, 445.0, 61.0, 835.0, 916.0, 22.0, 943.0, 1021.0, 1071.0, 321.0, 614.0, 1171.0, 188.0, 47.0, 26.0, 697.0, 580.0, 1125.0, 774.0, 665.0, 834.0, 918.0, 276.0, 651.0, 285.0, 971.0, 879.0, 841.0, 1321.0, 886.0, 404.0, 11.0, 41.0, 423.0, 722.0, 740.0, 959.0, 14.0, 13.0, 1056.0, 618.0, 943.0, 657.0, 11.0, 413.0, 995.0, 772.0, 41.0, 41.0, 1268.0, 1155.0, 1345.0, 1102.0, 750.0, 964.0, 460.0, 594.0, 687.0, 1073.0, 206.0, 233.0, 1193.0, 958.0, 855.0, 100.0, 1105.0, 997.0, 48.0, 48.0, 55.0, 47.0, 796.0, 715.0, 154.0, 158.0, 0.0, 0.0, 79.0, 65.0, 685.0, 619.0, 1210.0, 1398.0, 297.0, 273.0, 1064.0, 1041.0, 829.0, 37.0, 876.0, 441.0, 0.0, 0.0, 1241.0, 1130.0, 219.0, 231.0, 574.0, 582.0, 17.0, 74.0, 654.0, 684.0, 405.0, 378.0, 191.0, 10.0, 3.0, 1.0, 247.0, 1073.0, 0.0, 0.0, 13.0, 21.0, 0.0, 20.0, 0.0, 17.0, 100.0, 477.0, 2.0, 0.0, 476.0, 487.0, 0.0, 0.0, 12.0, 13.0, 0.0, 14.0, 34.0, 30.0, 0.0, 11.0, 9.0, 47.0, 72.0, 71.0, 0.0, 0.0, 0.0, 9.0, 58.0, 8.0, 582.0, 557.0, 20.0, 80.0, 0.0, 24.0, 0.0, 2.0, 0.0, 0.0, 129.0, 145.0, 9.0, 0.0, 0.0, 0.0, 25.0, 0.0, 34.0, 16.0, 116.0, 88.0, 50.0, 44.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 537.0, 650.0, 0.0, 1.0, 0.0, 0.0, 670.0, 721.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.6527710348180369, "mean_inference_ms": 4.409103521618219, "mean_action_processing_ms": 0.7674089888500976, "mean_env_wait_ms": 0.5708021739683196, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005325794219970703, "StateBufferConnector_ms": 0.0033260583877563477, "ViewRequirementAgentConnector_ms": 0.13238120079040527}, "num_episodes": 18, "episode_return_max": 1009.5000000000019, "episode_return_min": -933.2, "episode_return_mean": 72.94100000000022, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.01985974191393, "num_env_steps_trained_throughput_per_sec": 360.01985974191393, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 13138.958, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13138.907, "sample_time_ms": 1985.533, "learn_time_ms": 11137.987, "learn_throughput": 359.131, "synch_weights_time_ms": 12.709}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "e57b0_00000", "date": "2024-08-13_00-24-27", "timestamp": 1723523067, "time_this_iter_s": 11.202116012573242, "time_total_s": 840.9551818370819, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0db5040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 840.9551818370819, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 57.71875, "ram_util_percent": 83.45625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9640058096675646, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0987913304417538, "policy_loss": -0.004956327059685632, "vf_loss": 1.1034089791553991, "vf_explained_var": 0.0066705964229725025, "kl": 0.019029279920201647, "entropy": 1.079179210069949, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6321485865624651, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5093996891899715, "policy_loss": -0.0030214835517601204, "vf_loss": 1.5122342354721494, "vf_explained_var": -0.002241514221070305, "kl": 0.017724567494806137, "entropy": 0.7801953978639431, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 1009.5000000000019, "episode_reward_min": -388.6, "episode_reward_mean": 89.64200000000024, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1399.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.700000000000244, "predator_policy": 1398.0}, "policy_reward_mean": {"prey_policy": -223.14399999999995, "predator_policy": 267.965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-388.6, -197.20000000000002, 12.200000000000271, -175.79999999999984, 602.3000000000008, 37.600000000000264, 405.19999999999993, 442.9999999999999, -225.09999999999982, -190.89999999999998, 53.90000000000046, -9.799999999999955, 903.1000000000018, 152.7000000000002, -283.9, -157.70000000000005, -21.9999999999998, 591.3000000000003, 58.500000000000064, 920.900000000002, 46.10000000000024, 50.50000000000045, 7.0, 83.40000000000029, 40.0000000000003, -0.7999999999998226, 509.10000000000093, 119.89999999999998, 158.19999999999928, 951.9000000000016, -208.79999999999998, -74.90000000000009, 51.70000000000049, 1009.5000000000019, 31.099999999999987, 527.5000000000006, -87.99999999999984, 499.90000000000043, 81.20000000000019, -52.79999999999974, 38.300000000000274, -13.5, 40.0000000000003, 38.90000000000045, -21.899999999999487, 21.299999999999994, -14.099999999999799, 58.500000000000504, 329.9000000000002, 48.10000000000043, 27.800000000000114, 32.700000000000195, 17.89999999999996, 19.500000000000004, 2.6999999999999895, -53.50000000000004, 63.40000000000053, 30.100000000000147, -15.799999999999848, 451.3000000000018, -32.199999999999655, 1.0000000000002356, 37.800000000000296, 40.90000000000031, -76.20000000000053, 42.700000000000344, 58.0000000000005, 12.50000000000003, 18.599999999999977, -146.60000000000045, 32.0000000000002, 44.40000000000037, 40.0000000000003, 40.400000000000304, 316.9000000000001, 38.90000000000028, 40.0000000000003, 190.69999999999987, 17.999999999999943, 40.0000000000003, -19.599999999999532, 30.800000000000146, 41.800000000000324, 3.100000000000159, 24.600000000000055, 11.699999999999937, 46.300000000000395, 45.40000000000038, 46.60000000000043, 40.0000000000003, 13.599999999999913, 11.000000000000092, 225.19999999999925, 76.69999999999925, 30.200000000000145, 58.00000000000054, 67.90000000000023, 40.0000000000003, -8.49999999999978, 48.60000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1284.8, -1265.8, -555.9000000000001, -931.3, -55.59999999999994, 15.799999999999963, -611.7, -709.0999999999999, -1116.7, 20.000000000000014, -9.40000000000004, 20.000000000000014, -1085.8, -183.00000000000003, -93.40000000000003, -1063.6, -422.90000000000003, -226.20000000000002, -891.2, -1066.7, -48.0999999999998, 20.000000000000014, -1313.9, -1118.9, -143.99999999999983, -1399.9, -957.7, -603.6, -642.0, -695.9, -766.4, -1151.3, -145.99999999999994, -315.0, -1287.8, -271.89999999999986, -914.4, 17.900000000000013, 20.000000000000014, -1201.1, -69.90000000000003, 20.000000000000014, -69.09999999999985, 17.59999999999998, -732.9999999999999, -771.0, -248.60000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -143.79999999999987, -15.699999999999754, -779.2, -1352.9, -1135.2, 39.80000000000024, -451.5999999999999, 20.000000000000014, -1173.1, -592.1999999999999, -482.6, -511.1999999999998, -880.6999999999999, 20.000000000000014, 31.700000000000212, -1347.9, -13.599999999999783, -256.7999999999999, -162.10000000000005, 20.000000000000014, -648.5, -47.20000000000003, -131.80000000000004, 12.499999999999964, -850.6, -328.9999999999999, -372.8, -273.79999999999995, 20.000000000000014, 16.399999999999967, 17.899999999999988, -144.39999999999998, -1189.1, 20.000000000000014, 20.000000000000014, -24.100000000000048, 29.000000000000167, -19.899999999999743, -21.999999999999744, -15.699999999999747, 20.000000000000014, -600.6, 9.499999999999964, 21.80000000000004, 34.70000000000025, 20.000000000000014, -653.1, 20.000000000000014, 28.100000000000147, 6.499999999999972, -3.6999999999999584, 15.499999999999963, 3.1999999999999615, 20.000000000000014, -66.09999999999997, -0.9999999999999846, 9.499999999999964, -70.30000000000054, 16.999999999999975, -91.29999999999984, -105.20000000000005, 34.40000000000026, 29.000000000000163, 1.0999999999999865, 20.000000000000014, -11.500000000000014, -70.30000000000037, 37.10000000000024, -724.8, 15.799999999999946, -148.00000000000054, -5.1999999999999265, -17.79999999999975, 20.000000000000014, 15.799999999999946, 20.000000000000014, 20.90000000000003, -271.4999999999991, -78.70000000000027, 20.000000000000014, 13.699999999999973, 38.00000000000024, 20.000000000000014, -30.39999999999975, 17.899999999999988, 20.000000000000014, -51.39999999999977, -206.80000000000015, -143.80000000000032, -87.10000000000046, 25.1000000000001, 20.000000000000014, 19.40000000000001, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, -877.2, 7.0999999999999694, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -867.5, -332.7999999999997, 6.7999999999999705, -17.799999999999756, 20.000000000000014, 20.000000000000014, 7.399999999999968, -85.00000000000071, 27.50000000000014, -15.699999999999765, 21.80000000000004, 20.000000000000014, -55.60000000000031, 22.700000000000053, -9.399999999999862, 20.000000000000014, 13.699999999999966, -42.99999999999981, 21.80000000000004, 24.50000000000008, 20.000000000000014, 25.400000000000098, 39.80000000000025, -5.199999999999941, 20.000000000000014, 20.000000000000014, 5.299999999999965, -15.699999999999825, -0.9999999999999846, 1.9999999999999731, 16.69999999999997, -513.4999999999998, 23.900000000000077, -316.1999999999992, 17.899999999999988, 5.299999999999965, 29.000000000000163, 29.000000000000163, 30.800000000000196, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, -140.5000000000006, 40.700000000000244, -3.0999999999999615], "policy_predator_policy_reward": [841.0, 1321.0, 886.0, 404.0, 11.0, 41.0, 423.0, 722.0, 740.0, 959.0, 14.0, 13.0, 1056.0, 618.0, 943.0, 657.0, 11.0, 413.0, 995.0, 772.0, 41.0, 41.0, 1268.0, 1155.0, 1345.0, 1102.0, 750.0, 964.0, 460.0, 594.0, 687.0, 1073.0, 206.0, 233.0, 1193.0, 958.0, 855.0, 100.0, 1105.0, 997.0, 48.0, 48.0, 55.0, 47.0, 796.0, 715.0, 154.0, 158.0, 0.0, 0.0, 79.0, 65.0, 685.0, 619.0, 1210.0, 1398.0, 297.0, 273.0, 1064.0, 1041.0, 829.0, 37.0, 876.0, 441.0, 0.0, 0.0, 1241.0, 1130.0, 219.0, 231.0, 574.0, 582.0, 17.0, 74.0, 654.0, 684.0, 405.0, 378.0, 191.0, 10.0, 3.0, 1.0, 247.0, 1073.0, 0.0, 0.0, 13.0, 21.0, 0.0, 20.0, 0.0, 17.0, 100.0, 477.0, 2.0, 0.0, 476.0, 487.0, 0.0, 0.0, 12.0, 13.0, 0.0, 14.0, 34.0, 30.0, 0.0, 11.0, 9.0, 47.0, 72.0, 71.0, 0.0, 0.0, 0.0, 9.0, 58.0, 8.0, 582.0, 557.0, 20.0, 80.0, 0.0, 24.0, 0.0, 2.0, 0.0, 0.0, 129.0, 145.0, 9.0, 0.0, 0.0, 0.0, 25.0, 0.0, 34.0, 16.0, 116.0, 88.0, 50.0, 44.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 537.0, 650.0, 0.0, 1.0, 0.0, 0.0, 670.0, 721.0, 15.0, 14.0, 0.0, 0.0, 50.0, 8.0, 3.0, 16.0, 0.0, 0.0, 36.0, 0.0, 10.0, 4.0, 15.0, 26.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 0.0, 3.0, 21.0, 10.0, 0.0, 340.0, 382.0, 172.0, 197.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 92.0, 20.0, 0.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.6392312376190301, "mean_inference_ms": 4.358460901829641, "mean_action_processing_ms": 0.7578148093321551, "mean_env_wait_ms": 0.56513365357903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018213868141174316, "StateBufferConnector_ms": 0.003323078155517578, "ViewRequirementAgentConnector_ms": 0.1436758041381836}, "num_episodes": 22, "episode_return_max": 1009.5000000000019, "episode_return_min": -388.6, "episode_return_mean": 89.64200000000024, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.64449617057625, "num_env_steps_trained_throughput_per_sec": 322.64449617057625, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 13215.587, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13215.537, "sample_time_ms": 2032.088, "learn_time_ms": 11167.427, "learn_throughput": 358.185, "synch_weights_time_ms": 13.658}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "e57b0_00000", "date": "2024-08-13_00-24-40", "timestamp": 1723523080, "time_this_iter_s": 12.460612058639526, "time_total_s": 853.4157938957214, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09c7790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 853.4157938957214, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 61.683333333333344, "ram_util_percent": 83.80555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9008090626152735, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5440252731376816, "policy_loss": -0.0001600249538015791, "vf_loss": 0.5440432045027298, "vf_explained_var": 0.20305071848410147, "kl": 0.007983691803605034, "entropy": 1.0609934372876686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43429856920151644, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.19026186705502884, "policy_loss": -0.003098935821640586, "vf_loss": 0.19319356866476556, "vf_explained_var": -0.0013368774028051466, "kl": 0.015856328044071433, "entropy": 0.6948508470777481, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 1009.5000000000019, "episode_reward_min": -208.79999999999998, "episode_reward_mean": 73.14000000000024, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1352.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 50.600000000000236, "predator_policy": 1398.0}, "policy_reward_mean": {"prey_policy": -88.97999999999998, "predator_policy": 125.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [83.40000000000029, 40.0000000000003, -0.7999999999998226, 509.10000000000093, 119.89999999999998, 158.19999999999928, 951.9000000000016, -208.79999999999998, -74.90000000000009, 51.70000000000049, 1009.5000000000019, 31.099999999999987, 527.5000000000006, -87.99999999999984, 499.90000000000043, 81.20000000000019, -52.79999999999974, 38.300000000000274, -13.5, 40.0000000000003, 38.90000000000045, -21.899999999999487, 21.299999999999994, -14.099999999999799, 58.500000000000504, 329.9000000000002, 48.10000000000043, 27.800000000000114, 32.700000000000195, 17.89999999999996, 19.500000000000004, 2.6999999999999895, -53.50000000000004, 63.40000000000053, 30.100000000000147, -15.799999999999848, 451.3000000000018, -32.199999999999655, 1.0000000000002356, 37.800000000000296, 40.90000000000031, -76.20000000000053, 42.700000000000344, 58.0000000000005, 12.50000000000003, 18.599999999999977, -146.60000000000045, 32.0000000000002, 44.40000000000037, 40.0000000000003, 40.400000000000304, 316.9000000000001, 38.90000000000028, 40.0000000000003, 190.69999999999987, 17.999999999999943, 40.0000000000003, -19.599999999999532, 30.800000000000146, 41.800000000000324, 3.100000000000159, 24.600000000000055, 11.699999999999937, 46.300000000000395, 45.40000000000038, 46.60000000000043, 40.0000000000003, 13.599999999999913, 11.000000000000092, 225.19999999999925, 76.69999999999925, 30.200000000000145, 58.00000000000054, 67.90000000000023, 40.0000000000003, -8.49999999999978, 48.60000000000045, 31.80000000000018, 37.80000000000027, 40.0000000000003, 49.90000000000047, 55.90000000000049, 37.20000000000026, 65.20000000000037, 27.900000000000126, 38.900000000000276, 44.30000000000037, 70.60000000000002, -23.999999999999567, 27.700000000000124, 36.60000000000025, 64.30000000000048, 64.80000000000042, 29.500000000000142, 44.30000000000036, 67.00000000000026, 40.0000000000003, 37.30000000000026, 56.10000000000051, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-248.60000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -143.79999999999987, -15.699999999999754, -779.2, -1352.9, -1135.2, 39.80000000000024, -451.5999999999999, 20.000000000000014, -1173.1, -592.1999999999999, -482.6, -511.1999999999998, -880.6999999999999, 20.000000000000014, 31.700000000000212, -1347.9, -13.599999999999783, -256.7999999999999, -162.10000000000005, 20.000000000000014, -648.5, -47.20000000000003, -131.80000000000004, 12.499999999999964, -850.6, -328.9999999999999, -372.8, -273.79999999999995, 20.000000000000014, 16.399999999999967, 17.899999999999988, -144.39999999999998, -1189.1, 20.000000000000014, 20.000000000000014, -24.100000000000048, 29.000000000000167, -19.899999999999743, -21.999999999999744, -15.699999999999747, 20.000000000000014, -600.6, 9.499999999999964, 21.80000000000004, 34.70000000000025, 20.000000000000014, -653.1, 20.000000000000014, 28.100000000000147, 6.499999999999972, -3.6999999999999584, 15.499999999999963, 3.1999999999999615, 20.000000000000014, -66.09999999999997, -0.9999999999999846, 9.499999999999964, -70.30000000000054, 16.999999999999975, -91.29999999999984, -105.20000000000005, 34.40000000000026, 29.000000000000163, 1.0999999999999865, 20.000000000000014, -11.500000000000014, -70.30000000000037, 37.10000000000024, -724.8, 15.799999999999946, -148.00000000000054, -5.1999999999999265, -17.79999999999975, 20.000000000000014, 15.799999999999946, 20.000000000000014, 20.90000000000003, -271.4999999999991, -78.70000000000027, 20.000000000000014, 13.699999999999973, 38.00000000000024, 20.000000000000014, -30.39999999999975, 17.899999999999988, 20.000000000000014, -51.39999999999977, -206.80000000000015, -143.80000000000032, -87.10000000000046, 25.1000000000001, 20.000000000000014, 19.40000000000001, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, -877.2, 7.0999999999999694, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -867.5, -332.7999999999997, 6.7999999999999705, -17.799999999999756, 20.000000000000014, 20.000000000000014, 7.399999999999968, -85.00000000000071, 27.50000000000014, -15.699999999999765, 21.80000000000004, 20.000000000000014, -55.60000000000031, 22.700000000000053, -9.399999999999862, 20.000000000000014, 13.699999999999966, -42.99999999999981, 21.80000000000004, 24.50000000000008, 20.000000000000014, 25.400000000000098, 39.80000000000025, -5.199999999999941, 20.000000000000014, 20.000000000000014, 5.299999999999965, -15.699999999999825, -0.9999999999999846, 1.9999999999999731, 16.69999999999997, -513.4999999999998, 23.900000000000077, -316.1999999999992, 17.899999999999988, 5.299999999999965, 29.000000000000163, 29.000000000000163, 30.800000000000196, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, -140.5000000000006, 40.700000000000244, -3.0999999999999615, 12.199999999999969, 11.599999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000183, 20.000000000000014, 22.700000000000053, 27.200000000000138, 1.0999999999999865, 22.100000000000044, 20.000000000000014, 45.20000000000022, -3.0999999999999863, 20.000000000000014, 17.899999999999988, 20.000000000000014, 25.4000000000001, 17.899999999999988, 20.000000000000014, 50.600000000000236, 20.000000000000014, -127.00000000000074, 21.800000000000043, -24.099999999999753, 8.599999999999968, 20.000000000000014, 38.000000000000256, 26.30000000000012, 47.000000000000234, 15.799999999999963, 20.000000000000014, -2.499999999999975, 25.400000000000098, 17.899999999999988, 47.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.299999999999969, 27.20000000000013, 23.900000000000077, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [154.0, 158.0, 0.0, 0.0, 79.0, 65.0, 685.0, 619.0, 1210.0, 1398.0, 297.0, 273.0, 1064.0, 1041.0, 829.0, 37.0, 876.0, 441.0, 0.0, 0.0, 1241.0, 1130.0, 219.0, 231.0, 574.0, 582.0, 17.0, 74.0, 654.0, 684.0, 405.0, 378.0, 191.0, 10.0, 3.0, 1.0, 247.0, 1073.0, 0.0, 0.0, 13.0, 21.0, 0.0, 20.0, 0.0, 17.0, 100.0, 477.0, 2.0, 0.0, 476.0, 487.0, 0.0, 0.0, 12.0, 13.0, 0.0, 14.0, 34.0, 30.0, 0.0, 11.0, 9.0, 47.0, 72.0, 71.0, 0.0, 0.0, 0.0, 9.0, 58.0, 8.0, 582.0, 557.0, 20.0, 80.0, 0.0, 24.0, 0.0, 2.0, 0.0, 0.0, 129.0, 145.0, 9.0, 0.0, 0.0, 0.0, 25.0, 0.0, 34.0, 16.0, 116.0, 88.0, 50.0, 44.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 537.0, 650.0, 0.0, 1.0, 0.0, 0.0, 670.0, 721.0, 15.0, 14.0, 0.0, 0.0, 50.0, 8.0, 3.0, 16.0, 0.0, 0.0, 36.0, 0.0, 10.0, 4.0, 15.0, 26.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 0.0, 3.0, 21.0, 10.0, 0.0, 340.0, 382.0, 172.0, 197.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 92.0, 20.0, 0.0, 11.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 13.0, 70.0, 9.0, 21.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.622160075380132, "mean_inference_ms": 4.317923694590672, "mean_action_processing_ms": 0.749625176122633, "mean_env_wait_ms": 0.5586634880274769, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018863201141357422, "StateBufferConnector_ms": 0.003371596336364746, "ViewRequirementAgentConnector_ms": 0.14130115509033203}, "num_episodes": 23, "episode_return_max": 1009.5000000000019, "episode_return_min": -208.79999999999998, "episode_return_mean": 73.14000000000024, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.7503271022975, "num_env_steps_trained_throughput_per_sec": 317.7503271022975, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 13331.611, "restore_workers_time_ms": 0.014, "training_step_time_ms": 13331.562, "sample_time_ms": 2065.382, "learn_time_ms": 11249.495, "learn_throughput": 355.572, "synch_weights_time_ms": 13.618}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "e57b0_00000", "date": "2024-08-13_00-24-53", "timestamp": 1723523093, "time_this_iter_s": 13.05989384651184, "time_total_s": 866.4756877422333, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09fb160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 866.4756877422333, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 65.8777777777778, "ram_util_percent": 83.88333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8554384152764681, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0210088145007532, "policy_loss": -0.0026717999151774814, "vf_loss": 1.0233323112209007, "vf_explained_var": 0.023697733595257713, "kl": 0.01956994769605401, "entropy": 1.0753787428613693, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43214652504988765, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9780069839386712, "policy_loss": -0.00034171758372356336, "vf_loss": 0.9783296335784216, "vf_explained_var": -0.0034094551568308834, "kl": 0.001807948096448675, "entropy": 0.6882564155513017, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 451.3000000000018, "episode_reward_min": -146.60000000000045, "episode_reward_mean": 42.76000000000022, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1189.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 50.600000000000236, "predator_policy": 1073.0}, "policy_reward_mean": {"prey_policy": -27.374999999999968, "predator_policy": 48.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.5, 40.0000000000003, 38.90000000000045, -21.899999999999487, 21.299999999999994, -14.099999999999799, 58.500000000000504, 329.9000000000002, 48.10000000000043, 27.800000000000114, 32.700000000000195, 17.89999999999996, 19.500000000000004, 2.6999999999999895, -53.50000000000004, 63.40000000000053, 30.100000000000147, -15.799999999999848, 451.3000000000018, -32.199999999999655, 1.0000000000002356, 37.800000000000296, 40.90000000000031, -76.20000000000053, 42.700000000000344, 58.0000000000005, 12.50000000000003, 18.599999999999977, -146.60000000000045, 32.0000000000002, 44.40000000000037, 40.0000000000003, 40.400000000000304, 316.9000000000001, 38.90000000000028, 40.0000000000003, 190.69999999999987, 17.999999999999943, 40.0000000000003, -19.599999999999532, 30.800000000000146, 41.800000000000324, 3.100000000000159, 24.600000000000055, 11.699999999999937, 46.300000000000395, 45.40000000000038, 46.60000000000043, 40.0000000000003, 13.599999999999913, 11.000000000000092, 225.19999999999925, 76.69999999999925, 30.200000000000145, 58.00000000000054, 67.90000000000023, 40.0000000000003, -8.49999999999978, 48.60000000000045, 31.80000000000018, 37.80000000000027, 40.0000000000003, 49.90000000000047, 55.90000000000049, 37.20000000000026, 65.20000000000037, 27.900000000000126, 38.900000000000276, 44.30000000000037, 70.60000000000002, -23.999999999999567, 27.700000000000124, 36.60000000000025, 64.30000000000048, 64.80000000000042, 29.500000000000142, 44.30000000000036, 67.00000000000026, 40.0000000000003, 37.30000000000026, 56.10000000000051, 40.0000000000003, 47.80000000000043, 40.0000000000003, 40.0000000000003, 18.49999999999995, 50.40000000000048, 29.000000000000128, 5.10000000000017, -8.699999999999743, 40.0000000000003, -21.399999999999643, 40.0000000000003, 24.40000000000004, 85.89999999999894, 46.30000000000041, 60.70000000000051, 72.49999999999987, 23.50000000000006, 44.40000000000037], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-144.39999999999998, -1189.1, 20.000000000000014, 20.000000000000014, -24.100000000000048, 29.000000000000167, -19.899999999999743, -21.999999999999744, -15.699999999999747, 20.000000000000014, -600.6, 9.499999999999964, 21.80000000000004, 34.70000000000025, 20.000000000000014, -653.1, 20.000000000000014, 28.100000000000147, 6.499999999999972, -3.6999999999999584, 15.499999999999963, 3.1999999999999615, 20.000000000000014, -66.09999999999997, -0.9999999999999846, 9.499999999999964, -70.30000000000054, 16.999999999999975, -91.29999999999984, -105.20000000000005, 34.40000000000026, 29.000000000000163, 1.0999999999999865, 20.000000000000014, -11.500000000000014, -70.30000000000037, 37.10000000000024, -724.8, 15.799999999999946, -148.00000000000054, -5.1999999999999265, -17.79999999999975, 20.000000000000014, 15.799999999999946, 20.000000000000014, 20.90000000000003, -271.4999999999991, -78.70000000000027, 20.000000000000014, 13.699999999999973, 38.00000000000024, 20.000000000000014, -30.39999999999975, 17.899999999999988, 20.000000000000014, -51.39999999999977, -206.80000000000015, -143.80000000000032, -87.10000000000046, 25.1000000000001, 20.000000000000014, 19.40000000000001, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, -877.2, 7.0999999999999694, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -867.5, -332.7999999999997, 6.7999999999999705, -17.799999999999756, 20.000000000000014, 20.000000000000014, 7.399999999999968, -85.00000000000071, 27.50000000000014, -15.699999999999765, 21.80000000000004, 20.000000000000014, -55.60000000000031, 22.700000000000053, -9.399999999999862, 20.000000000000014, 13.699999999999966, -42.99999999999981, 21.80000000000004, 24.50000000000008, 20.000000000000014, 25.400000000000098, 39.80000000000025, -5.199999999999941, 20.000000000000014, 20.000000000000014, 5.299999999999965, -15.699999999999825, -0.9999999999999846, 1.9999999999999731, 16.69999999999997, -513.4999999999998, 23.900000000000077, -316.1999999999992, 17.899999999999988, 5.299999999999965, 29.000000000000163, 29.000000000000163, 30.800000000000196, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, -140.5000000000006, 40.700000000000244, -3.0999999999999615, 12.199999999999969, 11.599999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000183, 20.000000000000014, 22.700000000000053, 27.200000000000138, 1.0999999999999865, 22.100000000000044, 20.000000000000014, 45.20000000000022, -3.0999999999999863, 20.000000000000014, 17.899999999999988, 20.000000000000014, 25.4000000000001, 17.899999999999988, 20.000000000000014, 50.600000000000236, 20.000000000000014, -127.00000000000074, 21.800000000000043, -24.099999999999753, 8.599999999999968, 20.000000000000014, 38.000000000000256, 26.30000000000012, 47.000000000000234, 15.799999999999963, 20.000000000000014, -2.499999999999975, 25.400000000000098, 17.899999999999988, 47.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.299999999999969, 27.20000000000013, 23.900000000000077, 20.000000000000014, 20.000000000000014, 26.300000000000118, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999768, 12.199999999999969, 28.400000000000155, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -13.59999999999979, 1.6999999999999622, -99.7000000000005, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 7.399999999999967, -101.80000000000061, 20.000000000000014, 20.000000000000014, -11.499999999999922, 20.90000000000003, 43.40000000000024, 42.50000000000025, 20.000000000000014, 26.300000000000118, 20.000000000000014, 40.70000000000025, 43.40000000000022, 25.100000000000097, -7.299999999999969, 15.799999999999963, 19.40000000000001, 20.000000000000014], "policy_predator_policy_reward": [247.0, 1073.0, 0.0, 0.0, 13.0, 21.0, 0.0, 20.0, 0.0, 17.0, 100.0, 477.0, 2.0, 0.0, 476.0, 487.0, 0.0, 0.0, 12.0, 13.0, 0.0, 14.0, 34.0, 30.0, 0.0, 11.0, 9.0, 47.0, 72.0, 71.0, 0.0, 0.0, 0.0, 9.0, 58.0, 8.0, 582.0, 557.0, 20.0, 80.0, 0.0, 24.0, 0.0, 2.0, 0.0, 0.0, 129.0, 145.0, 9.0, 0.0, 0.0, 0.0, 25.0, 0.0, 34.0, 16.0, 116.0, 88.0, 50.0, 44.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 537.0, 650.0, 0.0, 1.0, 0.0, 0.0, 670.0, 721.0, 15.0, 14.0, 0.0, 0.0, 50.0, 8.0, 3.0, 16.0, 0.0, 0.0, 36.0, 0.0, 10.0, 4.0, 15.0, 26.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 0.0, 3.0, 21.0, 10.0, 0.0, 340.0, 382.0, 172.0, 197.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 92.0, 20.0, 0.0, 11.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 13.0, 70.0, 9.0, 21.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 2.0, 0.0, 10.0, 0.0, 0.0, 17.0, 56.0, 36.0, 0.0, 0.0, 21.0, 52.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 2.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.6079269757987624, "mean_inference_ms": 4.28370906687097, "mean_action_processing_ms": 0.7425298864336922, "mean_env_wait_ms": 0.5538878329744632, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018425345420837402, "StateBufferConnector_ms": 0.0035474300384521484, "ViewRequirementAgentConnector_ms": 0.14077281951904297}, "num_episodes": 18, "episode_return_max": 451.3000000000018, "episode_return_min": -146.60000000000045, "episode_return_mean": 42.76000000000022, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.12017157577606, "num_env_steps_trained_throughput_per_sec": 292.12017157577606, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 13139.54, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13139.491, "sample_time_ms": 1959.765, "learn_time_ms": 11163.476, "learn_throughput": 358.311, "synch_weights_time_ms": 13.607}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "e57b0_00000", "date": "2024-08-13_00-25-07", "timestamp": 1723523107, "time_this_iter_s": 13.879687070846558, "time_total_s": 880.3553748130798, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12943a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 880.3553748130798, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 69.17499999999998, "ram_util_percent": 82.87}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9676542035210385, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0074246562426052, "policy_loss": -0.004348513017723918, "vf_loss": 1.0113255570095683, "vf_explained_var": 0.18111358382714488, "kl": 0.025149458900506877, "entropy": 1.033620362685471, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5019335767855404, "cur_kl_coeff": 0.0052734375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.572649896815025, "policy_loss": -0.0031774741048042577, "vf_loss": 0.5757797613568733, "vf_explained_var": -0.001891024497450975, "kl": 0.009027849713632448, "entropy": 0.7134277585953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 451.3000000000018, "episode_reward_min": -146.60000000000045, "episode_reward_mean": 45.25300000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -877.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.30000000000021, "predator_policy": 721.0}, "policy_reward_mean": {"prey_policy": -10.528499999999967, "predator_policy": 33.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [451.3000000000018, -32.199999999999655, 1.0000000000002356, 37.800000000000296, 40.90000000000031, -76.20000000000053, 42.700000000000344, 58.0000000000005, 12.50000000000003, 18.599999999999977, -146.60000000000045, 32.0000000000002, 44.40000000000037, 40.0000000000003, 40.400000000000304, 316.9000000000001, 38.90000000000028, 40.0000000000003, 190.69999999999987, 17.999999999999943, 40.0000000000003, -19.599999999999532, 30.800000000000146, 41.800000000000324, 3.100000000000159, 24.600000000000055, 11.699999999999937, 46.300000000000395, 45.40000000000038, 46.60000000000043, 40.0000000000003, 13.599999999999913, 11.000000000000092, 225.19999999999925, 76.69999999999925, 30.200000000000145, 58.00000000000054, 67.90000000000023, 40.0000000000003, -8.49999999999978, 48.60000000000045, 31.80000000000018, 37.80000000000027, 40.0000000000003, 49.90000000000047, 55.90000000000049, 37.20000000000026, 65.20000000000037, 27.900000000000126, 38.900000000000276, 44.30000000000037, 70.60000000000002, -23.999999999999567, 27.700000000000124, 36.60000000000025, 64.30000000000048, 64.80000000000042, 29.500000000000142, 44.30000000000036, 67.00000000000026, 40.0000000000003, 37.30000000000026, 56.10000000000051, 40.0000000000003, 47.80000000000043, 40.0000000000003, 40.0000000000003, 18.49999999999995, 50.40000000000048, 29.000000000000128, 5.10000000000017, -8.699999999999743, 40.0000000000003, -21.399999999999643, 40.0000000000003, 24.40000000000004, 85.89999999999894, 46.30000000000041, 60.70000000000051, 72.49999999999987, 23.50000000000006, 44.40000000000037, 38.10000000000027, 75.89999999999961, 54.00000000000051, 87.69999999999877, 40.0000000000003, 40.0000000000003, -2.5999999999997585, 38.90000000000028, 63.40000000000053, 80.49999999999929, -2.899999999999773, 51.300000000000445, 41.60000000000032, 63.4000000000005, 71.59999999999994, 94.99999999999837, 24.60000000000006, 0.8000000000001858], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [37.10000000000024, -724.8, 15.799999999999946, -148.00000000000054, -5.1999999999999265, -17.79999999999975, 20.000000000000014, 15.799999999999946, 20.000000000000014, 20.90000000000003, -271.4999999999991, -78.70000000000027, 20.000000000000014, 13.699999999999973, 38.00000000000024, 20.000000000000014, -30.39999999999975, 17.899999999999988, 20.000000000000014, -51.39999999999977, -206.80000000000015, -143.80000000000032, -87.10000000000046, 25.1000000000001, 20.000000000000014, 19.40000000000001, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, -877.2, 7.0999999999999694, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -867.5, -332.7999999999997, 6.7999999999999705, -17.799999999999756, 20.000000000000014, 20.000000000000014, 7.399999999999968, -85.00000000000071, 27.50000000000014, -15.699999999999765, 21.80000000000004, 20.000000000000014, -55.60000000000031, 22.700000000000053, -9.399999999999862, 20.000000000000014, 13.699999999999966, -42.99999999999981, 21.80000000000004, 24.50000000000008, 20.000000000000014, 25.400000000000098, 39.80000000000025, -5.199999999999941, 20.000000000000014, 20.000000000000014, 5.299999999999965, -15.699999999999825, -0.9999999999999846, 1.9999999999999731, 16.69999999999997, -513.4999999999998, 23.900000000000077, -316.1999999999992, 17.899999999999988, 5.299999999999965, 29.000000000000163, 29.000000000000163, 30.800000000000196, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, -140.5000000000006, 40.700000000000244, -3.0999999999999615, 12.199999999999969, 11.599999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000183, 20.000000000000014, 22.700000000000053, 27.200000000000138, 1.0999999999999865, 22.100000000000044, 20.000000000000014, 45.20000000000022, -3.0999999999999863, 20.000000000000014, 17.899999999999988, 20.000000000000014, 25.4000000000001, 17.899999999999988, 20.000000000000014, 50.600000000000236, 20.000000000000014, -127.00000000000074, 21.800000000000043, -24.099999999999753, 8.599999999999968, 20.000000000000014, 38.000000000000256, 26.30000000000012, 47.000000000000234, 15.799999999999963, 20.000000000000014, -2.499999999999975, 25.400000000000098, 17.899999999999988, 47.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.299999999999969, 27.20000000000013, 23.900000000000077, 20.000000000000014, 20.000000000000014, 26.300000000000118, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999768, 12.199999999999969, 28.400000000000155, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -13.59999999999979, 1.6999999999999622, -99.7000000000005, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 7.399999999999967, -101.80000000000061, 20.000000000000014, 20.000000000000014, -11.499999999999922, 20.90000000000003, 43.40000000000024, 42.50000000000025, 20.000000000000014, 26.300000000000118, 20.000000000000014, 40.70000000000025, 43.40000000000022, 25.100000000000097, -7.299999999999969, 15.799999999999963, 19.40000000000001, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 50.90000000000021, 20.000000000000014, 32.00000000000022, 56.00000000000022, 31.700000000000188, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999995, -5.199999999999941, 20.000000000000014, 17.899999999999988, 34.40000000000026, 29.000000000000163, 60.50000000000021, 20.000000000000014, 17.899999999999988, -59.800000000000566, -11.799999999999818, 43.10000000000022, 11.599999999999971, 20.000000000000014, 20.000000000000014, 43.40000000000025, 11.599999999999964, 56.00000000000023, 28.700000000000163, 62.30000000000021, -9.399999999999869, 20.000000000000014, -70.30000000000089, 28.100000000000147], "policy_predator_policy_reward": [582.0, 557.0, 20.0, 80.0, 0.0, 24.0, 0.0, 2.0, 0.0, 0.0, 129.0, 145.0, 9.0, 0.0, 0.0, 0.0, 25.0, 0.0, 34.0, 16.0, 116.0, 88.0, 50.0, 44.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 537.0, 650.0, 0.0, 1.0, 0.0, 0.0, 670.0, 721.0, 15.0, 14.0, 0.0, 0.0, 50.0, 8.0, 3.0, 16.0, 0.0, 0.0, 36.0, 0.0, 10.0, 4.0, 15.0, 26.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 0.0, 3.0, 21.0, 10.0, 0.0, 340.0, 382.0, 172.0, 197.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 92.0, 20.0, 0.0, 11.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 13.0, 70.0, 9.0, 21.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 2.0, 0.0, 10.0, 0.0, 0.0, 17.0, 56.0, 36.0, 0.0, 0.0, 21.0, 52.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 2.0, 5.0, 0.0, 0.0, 5.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 31.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 4.0, 16.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 14.0, 0.0, 43.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.5987687924602967, "mean_inference_ms": 4.260611969760052, "mean_action_processing_ms": 0.7374491659677528, "mean_env_wait_ms": 0.550354230637244, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020272493362426758, "StateBufferConnector_ms": 0.0038115978240966797, "ViewRequirementAgentConnector_ms": 0.1708623170852661}, "num_episodes": 18, "episode_return_max": 451.3000000000018, "episode_return_min": -146.60000000000045, "episode_return_mean": 45.25300000000019, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.2355219419288, "num_env_steps_trained_throughput_per_sec": 244.2355219419288, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 13485.218, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13485.167, "sample_time_ms": 2101.886, "learn_time_ms": 11366.934, "learn_throughput": 351.898, "synch_weights_time_ms": 13.604}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "e57b0_00000", "date": "2024-08-13_00-25-23", "timestamp": 1723523123, "time_this_iter_s": 16.41998529434204, "time_total_s": 896.7753601074219, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12945e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 896.7753601074219, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 78.16086956521738, "ram_util_percent": 82.69565217391303}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0334377927439553, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1727211823854498, "policy_loss": -0.003360815751169212, "vf_loss": 1.175632062018233, "vf_explained_var": 0.2992085414273398, "kl": 0.01685362041280285, "entropy": 0.9185318507845439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37461738339847045, "cur_kl_coeff": 0.0052734375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.29084652268855027, "policy_loss": -0.0009060431685712603, "vf_loss": 0.29174226485907284, "vf_explained_var": 0.02014338389906303, "kl": 0.0019530934113711896, "entropy": 0.6643487260770545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 225.19999999999925, "episode_reward_min": -23.999999999999567, "episode_reward_mean": 46.549000000000085, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -867.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 89.29999999999934, "predator_policy": 721.0}, "policy_reward_mean": {"prey_policy": 4.339500000000043, "predator_policy": 18.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [190.69999999999987, 17.999999999999943, 40.0000000000003, -19.599999999999532, 30.800000000000146, 41.800000000000324, 3.100000000000159, 24.600000000000055, 11.699999999999937, 46.300000000000395, 45.40000000000038, 46.60000000000043, 40.0000000000003, 13.599999999999913, 11.000000000000092, 225.19999999999925, 76.69999999999925, 30.200000000000145, 58.00000000000054, 67.90000000000023, 40.0000000000003, -8.49999999999978, 48.60000000000045, 31.80000000000018, 37.80000000000027, 40.0000000000003, 49.90000000000047, 55.90000000000049, 37.20000000000026, 65.20000000000037, 27.900000000000126, 38.900000000000276, 44.30000000000037, 70.60000000000002, -23.999999999999567, 27.700000000000124, 36.60000000000025, 64.30000000000048, 64.80000000000042, 29.500000000000142, 44.30000000000036, 67.00000000000026, 40.0000000000003, 37.30000000000026, 56.10000000000051, 40.0000000000003, 47.80000000000043, 40.0000000000003, 40.0000000000003, 18.49999999999995, 50.40000000000048, 29.000000000000128, 5.10000000000017, -8.699999999999743, 40.0000000000003, -21.399999999999643, 40.0000000000003, 24.40000000000004, 85.89999999999894, 46.30000000000041, 60.70000000000051, 72.49999999999987, 23.50000000000006, 44.40000000000037, 38.10000000000027, 75.89999999999961, 54.00000000000051, 87.69999999999877, 40.0000000000003, 40.0000000000003, -2.5999999999997585, 38.90000000000028, 63.40000000000053, 80.49999999999929, -2.899999999999773, 51.300000000000445, 41.60000000000032, 63.4000000000005, 71.59999999999994, 94.99999999999837, 24.60000000000006, 0.8000000000001858, 58.90000000000051, 108.49999999999864, 96.69999999999831, 65.20000000000044, 40.0000000000003, 62.30000000000036, 69.70000000000007, 9.400000000000095, 26.80000000000009, 109.29999999999863, 25.200000000000074, 32.30000000000018, 14.799999999999955, 41.80000000000033, 39.5000000000003, 140.69999999999865, 65.10000000000036, 83.799999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-867.5, -332.7999999999997, 6.7999999999999705, -17.799999999999756, 20.000000000000014, 20.000000000000014, 7.399999999999968, -85.00000000000071, 27.50000000000014, -15.699999999999765, 21.80000000000004, 20.000000000000014, -55.60000000000031, 22.700000000000053, -9.399999999999862, 20.000000000000014, 13.699999999999966, -42.99999999999981, 21.80000000000004, 24.50000000000008, 20.000000000000014, 25.400000000000098, 39.80000000000025, -5.199999999999941, 20.000000000000014, 20.000000000000014, 5.299999999999965, -15.699999999999825, -0.9999999999999846, 1.9999999999999731, 16.69999999999997, -513.4999999999998, 23.900000000000077, -316.1999999999992, 17.899999999999988, 5.299999999999965, 29.000000000000163, 29.000000000000163, 30.800000000000196, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, -140.5000000000006, 40.700000000000244, -3.0999999999999615, 12.199999999999969, 11.599999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000183, 20.000000000000014, 22.700000000000053, 27.200000000000138, 1.0999999999999865, 22.100000000000044, 20.000000000000014, 45.20000000000022, -3.0999999999999863, 20.000000000000014, 17.899999999999988, 20.000000000000014, 25.4000000000001, 17.899999999999988, 20.000000000000014, 50.600000000000236, 20.000000000000014, -127.00000000000074, 21.800000000000043, -24.099999999999753, 8.599999999999968, 20.000000000000014, 38.000000000000256, 26.30000000000012, 47.000000000000234, 15.799999999999963, 20.000000000000014, -2.499999999999975, 25.400000000000098, 17.899999999999988, 47.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.299999999999969, 27.20000000000013, 23.900000000000077, 20.000000000000014, 20.000000000000014, 26.300000000000118, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999768, 12.199999999999969, 28.400000000000155, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -13.59999999999979, 1.6999999999999622, -99.7000000000005, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 7.399999999999967, -101.80000000000061, 20.000000000000014, 20.000000000000014, -11.499999999999922, 20.90000000000003, 43.40000000000024, 42.50000000000025, 20.000000000000014, 26.300000000000118, 20.000000000000014, 40.70000000000025, 43.40000000000022, 25.100000000000097, -7.299999999999969, 15.799999999999963, 19.40000000000001, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 50.90000000000021, 20.000000000000014, 32.00000000000022, 56.00000000000022, 31.700000000000188, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999995, -5.199999999999941, 20.000000000000014, 17.899999999999988, 34.40000000000026, 29.000000000000163, 60.50000000000021, 20.000000000000014, 17.899999999999988, -59.800000000000566, -11.799999999999818, 43.10000000000022, 11.599999999999971, 20.000000000000014, 20.000000000000014, 43.40000000000025, 11.599999999999964, 56.00000000000023, 28.700000000000163, 62.30000000000021, -9.399999999999869, 20.000000000000014, -70.30000000000089, 28.100000000000147, 20.000000000000014, 38.900000000000254, 20.000000000000014, 84.49999999999935, 57.80000000000022, 38.900000000000254, 32.60000000000023, 32.60000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.300000000000175, 20.000000000000014, 49.70000000000023, -3.099999999999972, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 89.29999999999934, 20.000000000000014, -30.39999999999978, -0.40000000000002056, 15.799999999999963, 9.499999999999966, -51.400000000000034, 30.20000000000019, 20.000000000000014, 12.79999999999997, -59.80000000000062, 44.300000000000246, 61.10000000000017, 65.60000000000005, -36.69999999999976, 57.800000000000225, 40.70000000000022, 28.100000000000165], "policy_predator_policy_reward": [670.0, 721.0, 15.0, 14.0, 0.0, 0.0, 50.0, 8.0, 3.0, 16.0, 0.0, 0.0, 36.0, 0.0, 10.0, 4.0, 15.0, 26.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 0.0, 3.0, 21.0, 10.0, 0.0, 340.0, 382.0, 172.0, 197.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 92.0, 20.0, 0.0, 11.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 13.0, 70.0, 9.0, 21.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 2.0, 0.0, 10.0, 0.0, 0.0, 17.0, 56.0, 36.0, 0.0, 0.0, 21.0, 52.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 2.0, 5.0, 0.0, 0.0, 5.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 31.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 4.0, 16.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 14.0, 0.0, 43.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 22.0, 2.0, 12.0, 0.0, 0.0, 0.0, 32.0, 24.0, 7.0, 0.0, 36.0, 0.0, 9.0, 0.0, 38.0, 17.0, 0.0, 14.0, 27.0, 17.0, 0.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.5899379854010913, "mean_inference_ms": 4.23840426029433, "mean_action_processing_ms": 0.7326064207333832, "mean_env_wait_ms": 0.5468707737289656, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019744396209716797, "StateBufferConnector_ms": 0.003841996192932129, "ViewRequirementAgentConnector_ms": 0.1708887815475464}, "num_episodes": 18, "episode_return_max": 225.19999999999925, "episode_return_min": -23.999999999999567, "episode_return_mean": 46.549000000000085, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.7284965755624, "num_env_steps_trained_throughput_per_sec": 333.7284965755624, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 13407.406, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13407.355, "sample_time_ms": 2010.715, "learn_time_ms": 11380.153, "learn_throughput": 351.489, "synch_weights_time_ms": 13.736}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "e57b0_00000", "date": "2024-08-13_00-25-36", "timestamp": 1723523136, "time_this_iter_s": 12.045150995254517, "time_total_s": 908.8205111026764, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bbca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 908.8205111026764, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 62.152941176470584, "ram_util_percent": 81.59411764705882}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.10263080217299, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7537275181876288, "policy_loss": -0.0022100700102450827, "vf_loss": 1.7556302538624515, "vf_explained_var": 0.20374569993801217, "kl": 0.011512025642893019, "entropy": 0.8131075596683239, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4736506919164664, "cur_kl_coeff": 0.00263671875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.35339815913054046, "policy_loss": -0.0009001377245618237, "vf_loss": 0.35429173431879096, "vf_explained_var": 0.025085482679346884, "kl": 0.0024887190367422515, "entropy": 0.5994736714337868, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 151.99999999999878, "episode_reward_min": -23.999999999999567, "episode_reward_mean": 51.38500000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -127.00000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 101.89999999999938, "predator_policy": 70.0}, "policy_reward_mean": {"prey_policy": 20.112500000000033, "predator_policy": 5.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [48.60000000000045, 31.80000000000018, 37.80000000000027, 40.0000000000003, 49.90000000000047, 55.90000000000049, 37.20000000000026, 65.20000000000037, 27.900000000000126, 38.900000000000276, 44.30000000000037, 70.60000000000002, -23.999999999999567, 27.700000000000124, 36.60000000000025, 64.30000000000048, 64.80000000000042, 29.500000000000142, 44.30000000000036, 67.00000000000026, 40.0000000000003, 37.30000000000026, 56.10000000000051, 40.0000000000003, 47.80000000000043, 40.0000000000003, 40.0000000000003, 18.49999999999995, 50.40000000000048, 29.000000000000128, 5.10000000000017, -8.699999999999743, 40.0000000000003, -21.399999999999643, 40.0000000000003, 24.40000000000004, 85.89999999999894, 46.30000000000041, 60.70000000000051, 72.49999999999987, 23.50000000000006, 44.40000000000037, 38.10000000000027, 75.89999999999961, 54.00000000000051, 87.69999999999877, 40.0000000000003, 40.0000000000003, -2.5999999999997585, 38.90000000000028, 63.40000000000053, 80.49999999999929, -2.899999999999773, 51.300000000000445, 41.60000000000032, 63.4000000000005, 71.59999999999994, 94.99999999999837, 24.60000000000006, 0.8000000000001858, 58.90000000000051, 108.49999999999864, 96.69999999999831, 65.20000000000044, 40.0000000000003, 62.30000000000036, 69.70000000000007, 9.400000000000095, 26.80000000000009, 109.29999999999863, 25.200000000000074, 32.30000000000018, 14.799999999999955, 41.80000000000033, 39.5000000000003, 140.69999999999865, 65.10000000000036, 83.799999999999, 26.50000000000009, 121.89999999999864, 118.29999999999858, 96.99999999999876, 40.500000000000306, 151.99999999999878, 56.900000000000475, 43.000000000000355, 48.10000000000043, 41.800000000000324, 86.79999999999879, 101.69999999999868, 52.700000000000394, 48.10000000000043, 38.90000000000028, 29.4000000000002, 50.1000000000005, 89.49999999999909, 71.49999999999996, 35.10000000000022, 40.0000000000003, 127.29999999999839], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.700000000000244, -3.0999999999999615, 12.199999999999969, 11.599999999999964, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.900000000000183, 20.000000000000014, 22.700000000000053, 27.200000000000138, 1.0999999999999865, 22.100000000000044, 20.000000000000014, 45.20000000000022, -3.0999999999999863, 20.000000000000014, 17.899999999999988, 20.000000000000014, 25.4000000000001, 17.899999999999988, 20.000000000000014, 50.600000000000236, 20.000000000000014, -127.00000000000074, 21.800000000000043, -24.099999999999753, 8.599999999999968, 20.000000000000014, 38.000000000000256, 26.30000000000012, 47.000000000000234, 15.799999999999963, 20.000000000000014, -2.499999999999975, 25.400000000000098, 17.899999999999988, 47.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.299999999999969, 27.20000000000013, 23.900000000000077, 20.000000000000014, 20.000000000000014, 26.300000000000118, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999768, 12.199999999999969, 28.400000000000155, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -13.59999999999979, 1.6999999999999622, -99.7000000000005, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 7.399999999999967, -101.80000000000061, 20.000000000000014, 20.000000000000014, -11.499999999999922, 20.90000000000003, 43.40000000000024, 42.50000000000025, 20.000000000000014, 26.300000000000118, 20.000000000000014, 40.70000000000025, 43.40000000000022, 25.100000000000097, -7.299999999999969, 15.799999999999963, 19.40000000000001, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 50.90000000000021, 20.000000000000014, 32.00000000000022, 56.00000000000022, 31.700000000000188, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999995, -5.199999999999941, 20.000000000000014, 17.899999999999988, 34.40000000000026, 29.000000000000163, 60.50000000000021, 20.000000000000014, 17.899999999999988, -59.800000000000566, -11.799999999999818, 43.10000000000022, 11.599999999999971, 20.000000000000014, 20.000000000000014, 43.40000000000025, 11.599999999999964, 56.00000000000023, 28.700000000000163, 62.30000000000021, -9.399999999999869, 20.000000000000014, -70.30000000000089, 28.100000000000147, 20.000000000000014, 38.900000000000254, 20.000000000000014, 84.49999999999935, 57.80000000000022, 38.900000000000254, 32.60000000000023, 32.60000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.300000000000175, 20.000000000000014, 49.70000000000023, -3.099999999999972, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 89.29999999999934, 20.000000000000014, -30.39999999999978, -0.40000000000002056, 15.799999999999963, 9.499999999999966, -51.400000000000034, 30.20000000000019, 20.000000000000014, 12.79999999999997, -59.80000000000062, 44.300000000000246, 61.10000000000017, 65.60000000000005, -36.69999999999976, 57.800000000000225, 40.70000000000022, 28.100000000000165, -11.499999999999833, 20.000000000000014, 101.89999999999938, 20.000000000000014, 48.800000000000196, 54.500000000000156, 20.000000000000014, 73.99999999999943, 15.799999999999963, 22.700000000000053, 100.69999999999958, 35.30000000000022, 45.20000000000023, 1.6999999999999622, 36.200000000000216, -5.199999999999941, 28.100000000000147, 20.000000000000014, 21.80000000000004, 20.000000000000014, 57.80000000000018, 20.000000000000014, 83.89999999999935, 15.799999999999963, 14.299999999999995, 13.399999999999991, 28.100000000000147, 20.000000000000014, 17.899999999999988, 20.000000000000014, -45.09999999999979, 42.500000000000156, 23.300000000000068, 9.79999999999997, 37.100000000000115, 52.40000000000023, 51.500000000000234, 20.000000000000014, 4.099999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, 86.59999999999928], "policy_predator_policy_reward": [0.0, 11.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 13.0, 70.0, 9.0, 21.0, 8.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 2.0, 0.0, 10.0, 0.0, 0.0, 17.0, 56.0, 36.0, 0.0, 0.0, 21.0, 52.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 2.0, 5.0, 0.0, 0.0, 5.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 31.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 4.0, 16.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 14.0, 0.0, 43.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 22.0, 2.0, 12.0, 0.0, 0.0, 0.0, 32.0, 24.0, 7.0, 0.0, 36.0, 0.0, 9.0, 0.0, 38.0, 17.0, 0.0, 14.0, 27.0, 17.0, 0.0, 15.0, 8.0, 10.0, 0.0, 0.0, 0.0, 15.0, 1.0, 2.0, 0.0, 2.0, 16.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 2.0, 15.0, 10.0, 0.0, 0.0, 1.0, 0.0, 31.0, 1.0, 14.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.580952322723973, "mean_inference_ms": 4.213889875682646, "mean_action_processing_ms": 0.726997356439974, "mean_env_wait_ms": 0.5428570727440161, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007785677909851074, "StateBufferConnector_ms": 0.003950715065002441, "ViewRequirementAgentConnector_ms": 0.19392406940460205}, "num_episodes": 22, "episode_return_max": 151.99999999999878, "episode_return_min": -23.999999999999567, "episode_return_mean": 51.38500000000001, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.5329087434535, "num_env_steps_trained_throughput_per_sec": 287.5329087434535, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 13655.282, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13655.169, "sample_time_ms": 2114.836, "learn_time_ms": 11523.736, "learn_throughput": 347.11, "synch_weights_time_ms": 13.977}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "e57b0_00000", "date": "2024-08-13_00-25-50", "timestamp": 1723523150, "time_this_iter_s": 13.969558000564575, "time_total_s": 922.790069103241, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b513a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 922.790069103241, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 71.67999999999999, "ram_util_percent": 78.59999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8799695738881984, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.661694546099062, "policy_loss": -0.0003671782022273099, "vf_loss": 2.6619106507175183, "vf_explained_var": 0.15567023227454493, "kl": 0.005658852724141861, "entropy": 0.6942552347031851, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5002164176098569, "cur_kl_coeff": 0.001318359375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.373001601740166, "policy_loss": -0.001961289334391791, "vf_loss": 0.37495194876150145, "vf_explained_var": 0.03617776673306864, "kl": 0.008299648081807208, "entropy": 0.6624683246095344, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 289.3000000000006, "episode_reward_min": -21.399999999999643, "episode_reward_mean": 62.116999999999905, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -101.80000000000061, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 157.69999999999973, "predator_policy": 56.0}, "policy_reward_mean": {"prey_policy": 25.578500000000005, "predator_policy": 5.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 47.80000000000043, 40.0000000000003, 40.0000000000003, 18.49999999999995, 50.40000000000048, 29.000000000000128, 5.10000000000017, -8.699999999999743, 40.0000000000003, -21.399999999999643, 40.0000000000003, 24.40000000000004, 85.89999999999894, 46.30000000000041, 60.70000000000051, 72.49999999999987, 23.50000000000006, 44.40000000000037, 38.10000000000027, 75.89999999999961, 54.00000000000051, 87.69999999999877, 40.0000000000003, 40.0000000000003, -2.5999999999997585, 38.90000000000028, 63.40000000000053, 80.49999999999929, -2.899999999999773, 51.300000000000445, 41.60000000000032, 63.4000000000005, 71.59999999999994, 94.99999999999837, 24.60000000000006, 0.8000000000001858, 58.90000000000051, 108.49999999999864, 96.69999999999831, 65.20000000000044, 40.0000000000003, 62.30000000000036, 69.70000000000007, 9.400000000000095, 26.80000000000009, 109.29999999999863, 25.200000000000074, 32.30000000000018, 14.799999999999955, 41.80000000000033, 39.5000000000003, 140.69999999999865, 65.10000000000036, 83.799999999999, 26.50000000000009, 121.89999999999864, 118.29999999999858, 96.99999999999876, 40.500000000000306, 151.99999999999878, 56.900000000000475, 43.000000000000355, 48.10000000000043, 41.800000000000324, 86.79999999999879, 101.69999999999868, 52.700000000000394, 48.10000000000043, 38.90000000000028, 29.4000000000002, 50.1000000000005, 89.49999999999909, 71.49999999999996, 35.10000000000022, 40.0000000000003, 127.29999999999839, 93.09999999999846, 89.99999999999908, 32.400000000000176, 167.79999999999947, 267.7000000000014, 31.100000000000172, 38.90000000000028, 40.0000000000003, 69.70000000000009, 35.600000000000236, 35.30000000000023, 20.19999999999998, 14.799999999999976, 91.19999999999851, 31.000000000000163, 38.90000000000028, 289.3000000000006, 17.59999999999994, 56.40000000000047, 112.89999999999918, 134.69999999999894, 131.7999999999989, 224.49999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 26.300000000000118, 15.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999768, 12.199999999999969, 28.400000000000155, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -13.59999999999979, 1.6999999999999622, -99.7000000000005, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 7.399999999999967, -101.80000000000061, 20.000000000000014, 20.000000000000014, -11.499999999999922, 20.90000000000003, 43.40000000000024, 42.50000000000025, 20.000000000000014, 26.300000000000118, 20.000000000000014, 40.70000000000025, 43.40000000000022, 25.100000000000097, -7.299999999999969, 15.799999999999963, 19.40000000000001, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 50.90000000000021, 20.000000000000014, 32.00000000000022, 56.00000000000022, 31.700000000000188, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999995, -5.199999999999941, 20.000000000000014, 17.899999999999988, 34.40000000000026, 29.000000000000163, 60.50000000000021, 20.000000000000014, 17.899999999999988, -59.800000000000566, -11.799999999999818, 43.10000000000022, 11.599999999999971, 20.000000000000014, 20.000000000000014, 43.40000000000025, 11.599999999999964, 56.00000000000023, 28.700000000000163, 62.30000000000021, -9.399999999999869, 20.000000000000014, -70.30000000000089, 28.100000000000147, 20.000000000000014, 38.900000000000254, 20.000000000000014, 84.49999999999935, 57.80000000000022, 38.900000000000254, 32.60000000000023, 32.60000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.300000000000175, 20.000000000000014, 49.70000000000023, -3.099999999999972, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 89.29999999999934, 20.000000000000014, -30.39999999999978, -0.40000000000002056, 15.799999999999963, 9.499999999999966, -51.400000000000034, 30.20000000000019, 20.000000000000014, 12.79999999999997, -59.80000000000062, 44.300000000000246, 61.10000000000017, 65.60000000000005, -36.69999999999976, 57.800000000000225, 40.70000000000022, 28.100000000000165, -11.499999999999833, 20.000000000000014, 101.89999999999938, 20.000000000000014, 48.800000000000196, 54.500000000000156, 20.000000000000014, 73.99999999999943, 15.799999999999963, 22.700000000000053, 100.69999999999958, 35.30000000000022, 45.20000000000023, 1.6999999999999622, 36.200000000000216, -5.199999999999941, 28.100000000000147, 20.000000000000014, 21.80000000000004, 20.000000000000014, 57.80000000000018, 20.000000000000014, 83.89999999999935, 15.799999999999963, 14.299999999999995, 13.399999999999991, 28.100000000000147, 20.000000000000014, 17.899999999999988, 20.000000000000014, -45.09999999999979, 42.500000000000156, 23.300000000000068, 9.79999999999997, 37.100000000000115, 52.40000000000023, 51.500000000000234, 20.000000000000014, 4.099999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, 86.59999999999928, 73.09999999999955, 20.000000000000014, 67.99999999999983, 20.000000000000014, 20.000000000000014, -7.599999999999932, -1.0000000000000098, 150.79999999999995, 141.4999999999998, 126.19999999999953, 11.599999999999964, 9.499999999999968, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 11.599999999999966, 20.000000000000014, 20.000000000000014, 5.299999999999969, -17.799999999999756, 20.000000000000014, -1.0000000000000062, -5.199999999999951, 9.499999999999975, 76.69999999999929, 20.000000000000014, 1.9999999999999731, 17.899999999999988, 20.000000000000014, 131.6, 157.69999999999973, -45.09999999999979, 31.700000000000212, 28.400000000000162, 20.000000000000014, 20.000000000000014, 92.89999999999966, 3.199999999999967, 123.49999999999957, 20.000000000000014, 102.79999999999956, 97.39999999999952, 118.0999999999998], "policy_predator_policy_reward": [0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 2.0, 0.0, 10.0, 0.0, 0.0, 17.0, 56.0, 36.0, 0.0, 0.0, 21.0, 52.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 2.0, 5.0, 0.0, 0.0, 5.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 31.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 4.0, 16.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 14.0, 0.0, 43.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 22.0, 2.0, 12.0, 0.0, 0.0, 0.0, 32.0, 24.0, 7.0, 0.0, 36.0, 0.0, 9.0, 0.0, 38.0, 17.0, 0.0, 14.0, 27.0, 17.0, 0.0, 15.0, 8.0, 10.0, 0.0, 0.0, 0.0, 15.0, 1.0, 2.0, 0.0, 2.0, 16.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 2.0, 15.0, 10.0, 0.0, 0.0, 1.0, 0.0, 31.0, 1.0, 14.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 20.0, 8.0, 10.0, 0.0, 0.0, 6.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 0.0, 18.0, 7.0, 14.0, 0.0, 5.0, 0.0, 9.0, 1.0, 0.0, 0.0, 0.0, 31.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 9.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.571647480599165, "mean_inference_ms": 4.189651183545798, "mean_action_processing_ms": 0.7212449644458562, "mean_env_wait_ms": 0.538915557550415, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007028460502624512, "StateBufferConnector_ms": 0.004253983497619629, "ViewRequirementAgentConnector_ms": 0.19315123558044434}, "num_episodes": 23, "episode_return_max": 289.3000000000006, "episode_return_min": -21.399999999999643, "episode_return_mean": 62.116999999999905, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 185.85342323485057, "num_env_steps_trained_throughput_per_sec": 185.85342323485057, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 13915.948, "restore_workers_time_ms": 0.019, "training_step_time_ms": 13915.834, "sample_time_ms": 2128.765, "learn_time_ms": 11769.736, "learn_throughput": 339.855, "synch_weights_time_ms": 14.439}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "e57b0_00000", "date": "2024-08-13_00-26-11", "timestamp": 1723523171, "time_this_iter_s": 21.59837794303894, "time_total_s": 944.3884470462799, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0db5b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 944.3884470462799, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 88.30645161290323, "ram_util_percent": 81.47741935483872}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.850998596129594, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6638370654570362, "policy_loss": -0.0019454758781841193, "vf_loss": 2.6654936180543647, "vf_explained_var": 0.16583842133718824, "kl": 0.010822473270609236, "entropy": 0.5679359005241797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28309004570520113, "cur_kl_coeff": 0.001318359375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2343311930853854, "policy_loss": -0.0013612620867591687, "vf_loss": 0.2356712473911189, "vf_explained_var": -0.021373901575330704, "kl": 0.01608691124516478, "entropy": 0.5902918839896166, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 289.3000000000006, "episode_reward_min": -2.899999999999773, "episode_reward_mean": 76.00599999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -70.30000000000089, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 43.0}, "policy_reward_mean": {"prey_policy": 33.248, "predator_policy": 4.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.40000000000037, 38.10000000000027, 75.89999999999961, 54.00000000000051, 87.69999999999877, 40.0000000000003, 40.0000000000003, -2.5999999999997585, 38.90000000000028, 63.40000000000053, 80.49999999999929, -2.899999999999773, 51.300000000000445, 41.60000000000032, 63.4000000000005, 71.59999999999994, 94.99999999999837, 24.60000000000006, 0.8000000000001858, 58.90000000000051, 108.49999999999864, 96.69999999999831, 65.20000000000044, 40.0000000000003, 62.30000000000036, 69.70000000000007, 9.400000000000095, 26.80000000000009, 109.29999999999863, 25.200000000000074, 32.30000000000018, 14.799999999999955, 41.80000000000033, 39.5000000000003, 140.69999999999865, 65.10000000000036, 83.799999999999, 26.50000000000009, 121.89999999999864, 118.29999999999858, 96.99999999999876, 40.500000000000306, 151.99999999999878, 56.900000000000475, 43.000000000000355, 48.10000000000043, 41.800000000000324, 86.79999999999879, 101.69999999999868, 52.700000000000394, 48.10000000000043, 38.90000000000028, 29.4000000000002, 50.1000000000005, 89.49999999999909, 71.49999999999996, 35.10000000000022, 40.0000000000003, 127.29999999999839, 93.09999999999846, 89.99999999999908, 32.400000000000176, 167.79999999999947, 267.7000000000014, 31.100000000000172, 38.90000000000028, 40.0000000000003, 69.70000000000009, 35.600000000000236, 35.30000000000023, 20.19999999999998, 14.799999999999976, 91.19999999999851, 31.000000000000163, 38.90000000000028, 289.3000000000006, 17.59999999999994, 56.40000000000047, 112.89999999999918, 134.69999999999894, 131.7999999999989, 224.49999999999935, 114.89999999999897, 4.300000000000173, 152.0999999999991, 219.99999999999926, 166.49999999999886, 146.9999999999989, 31.20000000000017, 50.10000000000039, 183.59999999999943, 69.70000000000009, 36.70000000000025, 262.8000000000014, 203.99999999999932, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [19.40000000000001, 20.000000000000014, 9.499999999999964, 23.600000000000065, 20.000000000000014, 50.90000000000021, 20.000000000000014, 32.00000000000022, 56.00000000000022, 31.700000000000188, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -51.39999999999995, -5.199999999999941, 20.000000000000014, 17.899999999999988, 34.40000000000026, 29.000000000000163, 60.50000000000021, 20.000000000000014, 17.899999999999988, -59.800000000000566, -11.799999999999818, 43.10000000000022, 11.599999999999971, 20.000000000000014, 20.000000000000014, 43.40000000000025, 11.599999999999964, 56.00000000000023, 28.700000000000163, 62.30000000000021, -9.399999999999869, 20.000000000000014, -70.30000000000089, 28.100000000000147, 20.000000000000014, 38.900000000000254, 20.000000000000014, 84.49999999999935, 57.80000000000022, 38.900000000000254, 32.60000000000023, 32.60000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.300000000000175, 20.000000000000014, 49.70000000000023, -3.099999999999972, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 89.29999999999934, 20.000000000000014, -30.39999999999978, -0.40000000000002056, 15.799999999999963, 9.499999999999966, -51.400000000000034, 30.20000000000019, 20.000000000000014, 12.79999999999997, -59.80000000000062, 44.300000000000246, 61.10000000000017, 65.60000000000005, -36.69999999999976, 57.800000000000225, 40.70000000000022, 28.100000000000165, -11.499999999999833, 20.000000000000014, 101.89999999999938, 20.000000000000014, 48.800000000000196, 54.500000000000156, 20.000000000000014, 73.99999999999943, 15.799999999999963, 22.700000000000053, 100.69999999999958, 35.30000000000022, 45.20000000000023, 1.6999999999999622, 36.200000000000216, -5.199999999999941, 28.100000000000147, 20.000000000000014, 21.80000000000004, 20.000000000000014, 57.80000000000018, 20.000000000000014, 83.89999999999935, 15.799999999999963, 14.299999999999995, 13.399999999999991, 28.100000000000147, 20.000000000000014, 17.899999999999988, 20.000000000000014, -45.09999999999979, 42.500000000000156, 23.300000000000068, 9.79999999999997, 37.100000000000115, 52.40000000000023, 51.500000000000234, 20.000000000000014, 4.099999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, 86.59999999999928, 73.09999999999955, 20.000000000000014, 67.99999999999983, 20.000000000000014, 20.000000000000014, -7.599999999999932, -1.0000000000000098, 150.79999999999995, 141.4999999999998, 126.19999999999953, 11.599999999999964, 9.499999999999968, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 11.599999999999966, 20.000000000000014, 20.000000000000014, 5.299999999999969, -17.799999999999756, 20.000000000000014, -1.0000000000000062, -5.199999999999951, 9.499999999999975, 76.69999999999929, 20.000000000000014, 1.9999999999999731, 17.899999999999988, 20.000000000000014, 131.6, 157.69999999999973, -45.09999999999979, 31.700000000000212, 28.400000000000162, 20.000000000000014, 20.000000000000014, 92.89999999999966, 3.199999999999967, 123.49999999999957, 20.000000000000014, 102.79999999999956, 97.39999999999952, 118.0999999999998, 89.89999999999954, 20.000000000000014, -11.499999999999826, -5.199999999999948, -21.999999999999773, 154.09999999999974, 20.000000000000014, 200.0, 67.09999999999998, 97.39999999999962, 121.9999999999996, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 22.100000000000048, 20.000000000000014, 152.0, 11.599999999999966, 49.70000000000024, 20.000000000000014, 13.699999999999964, 20.000000000000014, 121.99999999999983, 129.79999999999967, 176.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [5.0, 0.0, 0.0, 5.0, 3.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 31.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 4.0, 16.0, 0.0, 10.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 14.0, 0.0, 43.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 22.0, 2.0, 12.0, 0.0, 0.0, 0.0, 32.0, 24.0, 7.0, 0.0, 36.0, 0.0, 9.0, 0.0, 38.0, 17.0, 0.0, 14.0, 27.0, 17.0, 0.0, 15.0, 8.0, 10.0, 0.0, 0.0, 0.0, 15.0, 1.0, 2.0, 0.0, 2.0, 16.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 2.0, 15.0, 10.0, 0.0, 0.0, 1.0, 0.0, 31.0, 1.0, 14.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 20.0, 8.0, 10.0, 0.0, 0.0, 6.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 0.0, 18.0, 7.0, 14.0, 0.0, 5.0, 0.0, 9.0, 1.0, 0.0, 0.0, 0.0, 31.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 9.0, 9.0, 0.0, 4.0, 1.0, 21.0, 0.0, 17.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 8.0, 0.0, 8.0, 0.0, 6.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.565073611314193, "mean_inference_ms": 4.1735272306457185, "mean_action_processing_ms": 0.7170078982916631, "mean_env_wait_ms": 0.5361016471526228, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007077455520629883, "StateBufferConnector_ms": 0.004082441329956055, "ViewRequirementAgentConnector_ms": 0.2071925401687622}, "num_episodes": 18, "episode_return_max": 289.3000000000006, "episode_return_min": -2.899999999999773, "episode_return_mean": 76.00599999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 274.56806328970134, "num_env_steps_trained_throughput_per_sec": 274.56806328970134, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 14193.67, "restore_workers_time_ms": 0.021, "training_step_time_ms": 14193.546, "sample_time_ms": 2190.215, "learn_time_ms": 11985.924, "learn_throughput": 333.725, "synch_weights_time_ms": 14.542}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "e57b0_00000", "date": "2024-08-13_00-26-26", "timestamp": 1723523186, "time_this_iter_s": 14.574867963790894, "time_total_s": 958.9633150100708, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dba5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 958.9633150100708, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 70.25238095238096, "ram_util_percent": 76.04285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9835223534238087, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5431251803403176, "policy_loss": -0.0012346782662447484, "vf_loss": 3.5442643316965254, "vf_explained_var": 0.19251427287777895, "kl": 0.003578241717987273, "entropy": 0.5889832323821134, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4044432306750899, "cur_kl_coeff": 0.001318359375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2687159010775821, "policy_loss": -0.001232368996977885, "vf_loss": 0.2699402359242196, "vf_explained_var": -0.01083211693814192, "kl": 0.0060939320979263014, "entropy": 0.6281630876833799, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 289.3000000000006, "episode_reward_min": -13.199999999999614, "episode_reward_mean": 89.26399999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -70.30000000000089, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 43.0}, "policy_reward_mean": {"prey_policy": 39.63199999999998, "predator_policy": 5.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.8000000000001858, 58.90000000000051, 108.49999999999864, 96.69999999999831, 65.20000000000044, 40.0000000000003, 62.30000000000036, 69.70000000000007, 9.400000000000095, 26.80000000000009, 109.29999999999863, 25.200000000000074, 32.30000000000018, 14.799999999999955, 41.80000000000033, 39.5000000000003, 140.69999999999865, 65.10000000000036, 83.799999999999, 26.50000000000009, 121.89999999999864, 118.29999999999858, 96.99999999999876, 40.500000000000306, 151.99999999999878, 56.900000000000475, 43.000000000000355, 48.10000000000043, 41.800000000000324, 86.79999999999879, 101.69999999999868, 52.700000000000394, 48.10000000000043, 38.90000000000028, 29.4000000000002, 50.1000000000005, 89.49999999999909, 71.49999999999996, 35.10000000000022, 40.0000000000003, 127.29999999999839, 93.09999999999846, 89.99999999999908, 32.400000000000176, 167.79999999999947, 267.7000000000014, 31.100000000000172, 38.90000000000028, 40.0000000000003, 69.70000000000009, 35.600000000000236, 35.30000000000023, 20.19999999999998, 14.799999999999976, 91.19999999999851, 31.000000000000163, 38.90000000000028, 289.3000000000006, 17.59999999999994, 56.40000000000047, 112.89999999999918, 134.69999999999894, 131.7999999999989, 224.49999999999935, 114.89999999999897, 4.300000000000173, 152.0999999999991, 219.99999999999926, 166.49999999999886, 146.9999999999989, 31.20000000000017, 50.10000000000039, 183.59999999999943, 69.70000000000009, 36.70000000000025, 262.8000000000014, 203.99999999999932, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 158.99999999999957, 138.99999999999966, 164.1999999999991, 148.2999999999998, 228.09999999999923, 136.2999999999997, 184.69999999999942, 180.399999999999, 73.69999999999975, 108.19999999999878, 72.39999999999989, 143.19999999999962, 88.59999999999872, 102.09999999999852, 35.20000000000023, 240.49999999999952, 40.0000000000003, -13.199999999999614], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-70.30000000000089, 28.100000000000147, 20.000000000000014, 38.900000000000254, 20.000000000000014, 84.49999999999935, 57.80000000000022, 38.900000000000254, 32.60000000000023, 32.60000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.300000000000175, 20.000000000000014, 49.70000000000023, -3.099999999999972, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 89.29999999999934, 20.000000000000014, -30.39999999999978, -0.40000000000002056, 15.799999999999963, 9.499999999999966, -51.400000000000034, 30.20000000000019, 20.000000000000014, 12.79999999999997, -59.80000000000062, 44.300000000000246, 61.10000000000017, 65.60000000000005, -36.69999999999976, 57.800000000000225, 40.70000000000022, 28.100000000000165, -11.499999999999833, 20.000000000000014, 101.89999999999938, 20.000000000000014, 48.800000000000196, 54.500000000000156, 20.000000000000014, 73.99999999999943, 15.799999999999963, 22.700000000000053, 100.69999999999958, 35.30000000000022, 45.20000000000023, 1.6999999999999622, 36.200000000000216, -5.199999999999941, 28.100000000000147, 20.000000000000014, 21.80000000000004, 20.000000000000014, 57.80000000000018, 20.000000000000014, 83.89999999999935, 15.799999999999963, 14.299999999999995, 13.399999999999991, 28.100000000000147, 20.000000000000014, 17.899999999999988, 20.000000000000014, -45.09999999999979, 42.500000000000156, 23.300000000000068, 9.79999999999997, 37.100000000000115, 52.40000000000023, 51.500000000000234, 20.000000000000014, 4.099999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, 86.59999999999928, 73.09999999999955, 20.000000000000014, 67.99999999999983, 20.000000000000014, 20.000000000000014, -7.599999999999932, -1.0000000000000098, 150.79999999999995, 141.4999999999998, 126.19999999999953, 11.599999999999964, 9.499999999999968, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 11.599999999999966, 20.000000000000014, 20.000000000000014, 5.299999999999969, -17.799999999999756, 20.000000000000014, -1.0000000000000062, -5.199999999999951, 9.499999999999975, 76.69999999999929, 20.000000000000014, 1.9999999999999731, 17.899999999999988, 20.000000000000014, 131.6, 157.69999999999973, -45.09999999999979, 31.700000000000212, 28.400000000000162, 20.000000000000014, 20.000000000000014, 92.89999999999966, 3.199999999999967, 123.49999999999957, 20.000000000000014, 102.79999999999956, 97.39999999999952, 118.0999999999998, 89.89999999999954, 20.000000000000014, -11.499999999999826, -5.199999999999948, -21.999999999999773, 154.09999999999974, 20.000000000000014, 200.0, 67.09999999999998, 97.39999999999962, 121.9999999999996, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 22.100000000000048, 20.000000000000014, 152.0, 11.599999999999966, 49.70000000000024, 20.000000000000014, 13.699999999999964, 20.000000000000014, 121.99999999999983, 129.79999999999967, 176.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 75.19999999999993, 118.99999999999999, 20.000000000000014, 20.000000000000014, 135.19999999999976, 139.39999999999998, -24.09999999999983, 28.100000000000147, 200.0, 20.000000000000014, 116.29999999999998, 146.3, 19.400000000000006, 160.39999999999975, 20.000000000000014, 5.299999999999965, 61.400000000000205, 20.000000000000014, 78.19999999999942, 52.40000000000023, 20.000000000000014, 109.1, 19.100000000000005, 68.59999999999988, 20.000000000000014, 82.09999999999926, 20.000000000000014, 9.49999999999997, 19.70000000000001, 100.70000000000002, 129.79999999999956, 20.000000000000014, 20.000000000000014, -1.0000000000000204, -47.1999999999998], "policy_predator_policy_reward": [43.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 22.0, 2.0, 12.0, 0.0, 0.0, 0.0, 32.0, 24.0, 7.0, 0.0, 36.0, 0.0, 9.0, 0.0, 38.0, 17.0, 0.0, 14.0, 27.0, 17.0, 0.0, 15.0, 8.0, 10.0, 0.0, 0.0, 0.0, 15.0, 1.0, 2.0, 0.0, 2.0, 16.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 2.0, 15.0, 10.0, 0.0, 0.0, 1.0, 0.0, 31.0, 1.0, 14.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 20.0, 8.0, 10.0, 0.0, 0.0, 6.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 0.0, 18.0, 7.0, 14.0, 0.0, 5.0, 0.0, 9.0, 1.0, 0.0, 0.0, 0.0, 31.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 9.0, 9.0, 0.0, 4.0, 1.0, 21.0, 0.0, 17.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 8.0, 0.0, 8.0, 0.0, 6.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 0.0, 9.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 35.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.5558987463982725, "mean_inference_ms": 4.149997052127253, "mean_action_processing_ms": 0.7116108315195971, "mean_env_wait_ms": 0.5324794740598174, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00594639778137207, "StateBufferConnector_ms": 0.00787341594696045, "ViewRequirementAgentConnector_ms": 0.19107866287231445}, "num_episodes": 18, "episode_return_max": 289.3000000000006, "episode_return_min": -13.199999999999614, "episode_return_mean": 89.26399999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 250.36995015483058, "num_env_steps_trained_throughput_per_sec": 250.36995015483058, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 14413.214, "restore_workers_time_ms": 0.021, "training_step_time_ms": 14413.088, "sample_time_ms": 2195.258, "learn_time_ms": 12199.581, "learn_throughput": 327.88, "synch_weights_time_ms": 15.279}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "e57b0_00000", "date": "2024-08-13_00-26-42", "timestamp": 1723523202, "time_this_iter_s": 16.034981966018677, "time_total_s": 974.9982969760895, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dbaf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 974.9982969760895, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 67.9304347826087, "ram_util_percent": 75.47391304347825}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1099351200122367, "cur_kl_coeff": 0.013348388671874996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0707920502102564, "policy_loss": -0.0011374907969699177, "vf_loss": 3.071906048532516, "vf_explained_var": 0.21110320898590895, "kl": 0.001759118801259947, "entropy": 0.6080962879001779, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49911318135166927, "cur_kl_coeff": 0.001318359375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2732960670664118, "policy_loss": -0.002378854496532647, "vf_loss": 0.2756643909946337, "vf_explained_var": -0.005420879491422542, "kl": 0.007988091095835054, "entropy": 0.6668688471985873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 387.4, "episode_reward_min": -13.199999999999614, "episode_reward_mean": 104.67499999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -47.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 45.0}, "policy_reward_mean": {"prey_policy": 48.25249999999996, "predator_policy": 4.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [96.99999999999876, 40.500000000000306, 151.99999999999878, 56.900000000000475, 43.000000000000355, 48.10000000000043, 41.800000000000324, 86.79999999999879, 101.69999999999868, 52.700000000000394, 48.10000000000043, 38.90000000000028, 29.4000000000002, 50.1000000000005, 89.49999999999909, 71.49999999999996, 35.10000000000022, 40.0000000000003, 127.29999999999839, 93.09999999999846, 89.99999999999908, 32.400000000000176, 167.79999999999947, 267.7000000000014, 31.100000000000172, 38.90000000000028, 40.0000000000003, 69.70000000000009, 35.600000000000236, 35.30000000000023, 20.19999999999998, 14.799999999999976, 91.19999999999851, 31.000000000000163, 38.90000000000028, 289.3000000000006, 17.59999999999994, 56.40000000000047, 112.89999999999918, 134.69999999999894, 131.7999999999989, 224.49999999999935, 114.89999999999897, 4.300000000000173, 152.0999999999991, 219.99999999999926, 166.49999999999886, 146.9999999999989, 31.20000000000017, 50.10000000000039, 183.59999999999943, 69.70000000000009, 36.70000000000025, 262.8000000000014, 203.99999999999932, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 158.99999999999957, 138.99999999999966, 164.1999999999991, 148.2999999999998, 228.09999999999923, 136.2999999999997, 184.69999999999942, 180.399999999999, 73.69999999999975, 108.19999999999878, 72.39999999999989, 143.19999999999962, 88.59999999999872, 102.09999999999852, 35.20000000000023, 240.49999999999952, 40.0000000000003, -13.199999999999614, 219.99999999999926, 27.90000000000011, 123.99999999999883, 40.0000000000003, 52.70000000000039, 40.0000000000003, 92.20000000000005, 196.69999999999936, 387.4, 40.0000000000003, 78.09999999999938, 368.5, 132.8999999999997, 29.00000000000013, 205.5999999999993, 40.0000000000003, 182.19999999999902, 199.99999999999935, 97.59999999999849, 118.59999999999982, 115.39999999999881, 109.79999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 73.99999999999943, 15.799999999999963, 22.700000000000053, 100.69999999999958, 35.30000000000022, 45.20000000000023, 1.6999999999999622, 36.200000000000216, -5.199999999999941, 28.100000000000147, 20.000000000000014, 21.80000000000004, 20.000000000000014, 57.80000000000018, 20.000000000000014, 83.89999999999935, 15.799999999999963, 14.299999999999995, 13.399999999999991, 28.100000000000147, 20.000000000000014, 17.899999999999988, 20.000000000000014, -45.09999999999979, 42.500000000000156, 23.300000000000068, 9.79999999999997, 37.100000000000115, 52.40000000000023, 51.500000000000234, 20.000000000000014, 4.099999999999978, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, 86.59999999999928, 73.09999999999955, 20.000000000000014, 67.99999999999983, 20.000000000000014, 20.000000000000014, -7.599999999999932, -1.0000000000000098, 150.79999999999995, 141.4999999999998, 126.19999999999953, 11.599999999999964, 9.499999999999968, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 11.599999999999966, 20.000000000000014, 20.000000000000014, 5.299999999999969, -17.799999999999756, 20.000000000000014, -1.0000000000000062, -5.199999999999951, 9.499999999999975, 76.69999999999929, 20.000000000000014, 1.9999999999999731, 17.899999999999988, 20.000000000000014, 131.6, 157.69999999999973, -45.09999999999979, 31.700000000000212, 28.400000000000162, 20.000000000000014, 20.000000000000014, 92.89999999999966, 3.199999999999967, 123.49999999999957, 20.000000000000014, 102.79999999999956, 97.39999999999952, 118.0999999999998, 89.89999999999954, 20.000000000000014, -11.499999999999826, -5.199999999999948, -21.999999999999773, 154.09999999999974, 20.000000000000014, 200.0, 67.09999999999998, 97.39999999999962, 121.9999999999996, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 22.100000000000048, 20.000000000000014, 152.0, 11.599999999999966, 49.70000000000024, 20.000000000000014, 13.699999999999964, 20.000000000000014, 121.99999999999983, 129.79999999999967, 176.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 75.19999999999993, 118.99999999999999, 20.000000000000014, 20.000000000000014, 135.19999999999976, 139.39999999999998, -24.09999999999983, 28.100000000000147, 200.0, 20.000000000000014, 116.29999999999998, 146.3, 19.400000000000006, 160.39999999999975, 20.000000000000014, 5.299999999999965, 61.400000000000205, 20.000000000000014, 78.19999999999942, 52.40000000000023, 20.000000000000014, 109.1, 19.100000000000005, 68.59999999999988, 20.000000000000014, 82.09999999999926, 20.000000000000014, 9.49999999999997, 19.70000000000001, 100.70000000000002, 129.79999999999956, 20.000000000000014, 20.000000000000014, -1.0000000000000204, -47.1999999999998, 200.0, 20.000000000000014, 20.000000000000014, -3.099999999999958, 107.2999999999995, 13.699999999999964, 20.000000000000014, 20.000000000000014, -7.299999999999908, 47.0000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.19999999999996, 170.0, 13.699999999999964, 187.4, 200.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 62.00000000000017, 168.5, 200.0, 121.69999999999999, 3.199999999999967, 20.000000000000014, -0.9999999999999952, 28.100000000000158, 168.5, 20.000000000000014, 20.000000000000014, 162.19999999999976, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 77.59999999999923, 32.599999999999824, 20.000000000000014, 20.000000000000014, 85.39999999999947, 91.99999999999997, 15.799999999999963], "policy_predator_policy_reward": [1.0, 2.0, 0.0, 2.0, 16.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 2.0, 15.0, 10.0, 0.0, 0.0, 1.0, 0.0, 31.0, 1.0, 14.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 20.0, 8.0, 10.0, 0.0, 0.0, 6.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 0.0, 18.0, 7.0, 14.0, 0.0, 5.0, 0.0, 9.0, 1.0, 0.0, 0.0, 0.0, 31.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 9.0, 9.0, 0.0, 4.0, 1.0, 21.0, 0.0, 17.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 8.0, 0.0, 8.0, 0.0, 6.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 0.0, 9.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 45.0, 21.0, 10.0, 0.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.5483568052239485, "mean_inference_ms": 4.122316914220302, "mean_action_processing_ms": 0.7052105016884244, "mean_env_wait_ms": 0.5292855411191788, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004807591438293457, "StateBufferConnector_ms": 0.007781863212585449, "ViewRequirementAgentConnector_ms": 0.18716764450073242}, "num_episodes": 22, "episode_return_max": 387.4, "episode_return_min": -13.199999999999614, "episode_return_mean": 104.67499999999974, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 273.6592833275836, "num_env_steps_trained_throughput_per_sec": 273.6592833275836, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 14763.836, "restore_workers_time_ms": 0.023, "training_step_time_ms": 14763.708, "sample_time_ms": 2242.313, "learn_time_ms": 12500.799, "learn_throughput": 319.98, "synch_weights_time_ms": 17.274}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "e57b0_00000", "date": "2024-08-13_00-26-57", "timestamp": 1723523217, "time_this_iter_s": 14.669672966003418, "time_total_s": 989.6679699420929, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0db5700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 989.6679699420929, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 67.52380952380952, "ram_util_percent": 79.06190476190477}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2556690446638241, "cur_kl_coeff": 0.006674194335937498, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.397219881304988, "policy_loss": -0.0009057540020279626, "vf_loss": 4.398098868163174, "vf_explained_var": 0.22772046617729955, "kl": 0.004011291074721315, "entropy": 0.5273513766823622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37206411204897066, "cur_kl_coeff": 0.001318359375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5382592162127218, "policy_loss": -0.002256284806404322, "vf_loss": 0.5404919724709418, "vf_explained_var": 0.012150804107151334, "kl": 0.01784690938041016, "entropy": 0.5765989958924591, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 387.4, "episode_reward_min": -13.199999999999614, "episode_reward_mean": 117.88999999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -57.70000000000041, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 45.0}, "policy_reward_mean": {"prey_policy": 54.67999999999994, "predator_policy": 4.265}, "custom_metrics": {}, "hist_stats": {"episode_reward": [127.29999999999839, 93.09999999999846, 89.99999999999908, 32.400000000000176, 167.79999999999947, 267.7000000000014, 31.100000000000172, 38.90000000000028, 40.0000000000003, 69.70000000000009, 35.600000000000236, 35.30000000000023, 20.19999999999998, 14.799999999999976, 91.19999999999851, 31.000000000000163, 38.90000000000028, 289.3000000000006, 17.59999999999994, 56.40000000000047, 112.89999999999918, 134.69999999999894, 131.7999999999989, 224.49999999999935, 114.89999999999897, 4.300000000000173, 152.0999999999991, 219.99999999999926, 166.49999999999886, 146.9999999999989, 31.20000000000017, 50.10000000000039, 183.59999999999943, 69.70000000000009, 36.70000000000025, 262.8000000000014, 203.99999999999932, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 158.99999999999957, 138.99999999999966, 164.1999999999991, 148.2999999999998, 228.09999999999923, 136.2999999999997, 184.69999999999942, 180.399999999999, 73.69999999999975, 108.19999999999878, 72.39999999999989, 143.19999999999962, 88.59999999999872, 102.09999999999852, 35.20000000000023, 240.49999999999952, 40.0000000000003, -13.199999999999614, 219.99999999999926, 27.90000000000011, 123.99999999999883, 40.0000000000003, 52.70000000000039, 40.0000000000003, 92.20000000000005, 196.69999999999936, 387.4, 40.0000000000003, 78.09999999999938, 368.5, 132.8999999999997, 29.00000000000013, 205.5999999999993, 40.0000000000003, 182.19999999999902, 199.99999999999935, 97.59999999999849, 118.59999999999982, 115.39999999999881, 109.79999999999987, 125.8999999999997, 210.29999999999927, 219.99999999999926, 118.49999999999976, 88.00000000000003, 185.79999999999941, 279.3, 29.000000000000142, 65.90000000000036, 186.29999999999941, 67.70000000000005, 144.39999999999964, 40.0000000000003, 40.0000000000003, 40.0000000000003, 192.9999999999991, 144.59999999999923, 265.9000000000017], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.70000000000025, 86.59999999999928, 73.09999999999955, 20.000000000000014, 67.99999999999983, 20.000000000000014, 20.000000000000014, -7.599999999999932, -1.0000000000000098, 150.79999999999995, 141.4999999999998, 126.19999999999953, 11.599999999999964, 9.499999999999968, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 11.599999999999966, 20.000000000000014, 20.000000000000014, 5.299999999999969, -17.799999999999756, 20.000000000000014, -1.0000000000000062, -5.199999999999951, 9.499999999999975, 76.69999999999929, 20.000000000000014, 1.9999999999999731, 17.899999999999988, 20.000000000000014, 131.6, 157.69999999999973, -45.09999999999979, 31.700000000000212, 28.400000000000162, 20.000000000000014, 20.000000000000014, 92.89999999999966, 3.199999999999967, 123.49999999999957, 20.000000000000014, 102.79999999999956, 97.39999999999952, 118.0999999999998, 89.89999999999954, 20.000000000000014, -11.499999999999826, -5.199999999999948, -21.999999999999773, 154.09999999999974, 20.000000000000014, 200.0, 67.09999999999998, 97.39999999999962, 121.9999999999996, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 22.100000000000048, 20.000000000000014, 152.0, 11.599999999999966, 49.70000000000024, 20.000000000000014, 13.699999999999964, 20.000000000000014, 121.99999999999983, 129.79999999999967, 176.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 75.19999999999993, 118.99999999999999, 20.000000000000014, 20.000000000000014, 135.19999999999976, 139.39999999999998, -24.09999999999983, 28.100000000000147, 200.0, 20.000000000000014, 116.29999999999998, 146.3, 19.400000000000006, 160.39999999999975, 20.000000000000014, 5.299999999999965, 61.400000000000205, 20.000000000000014, 78.19999999999942, 52.40000000000023, 20.000000000000014, 109.1, 19.100000000000005, 68.59999999999988, 20.000000000000014, 82.09999999999926, 20.000000000000014, 9.49999999999997, 19.70000000000001, 100.70000000000002, 129.79999999999956, 20.000000000000014, 20.000000000000014, -1.0000000000000204, -47.1999999999998, 200.0, 20.000000000000014, 20.000000000000014, -3.099999999999958, 107.2999999999995, 13.699999999999964, 20.000000000000014, 20.000000000000014, -7.299999999999908, 47.0000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.19999999999996, 170.0, 13.699999999999964, 187.4, 200.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 62.00000000000017, 168.5, 200.0, 121.69999999999999, 3.199999999999967, 20.000000000000014, -0.9999999999999952, 28.100000000000158, 168.5, 20.000000000000014, 20.000000000000014, 162.19999999999976, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 77.59999999999923, 32.599999999999824, 20.000000000000014, 20.000000000000014, 85.39999999999947, 91.99999999999997, 15.799999999999963, 20.000000000000014, 89.90000000000009, -57.70000000000041, 200.0, 200.0, 20.000000000000014, 90.49999999999997, 20.000000000000014, 15.799999999999963, 42.200000000000095, 20.000000000000014, 165.8, 93.19999999999942, 181.1, 20.000000000000014, -1.0000000000000062, 44.90000000000024, 20.000000000000014, 155.3, 20.000000000000014, 37.7, 20.000000000000014, 125.9, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 172.99999999999983, 122.89999999999976, 13.699999999999964, 126.19999999999953, 139.69999999999976], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 20.0, 8.0, 10.0, 0.0, 0.0, 6.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 0.0, 18.0, 7.0, 14.0, 0.0, 5.0, 0.0, 9.0, 1.0, 0.0, 0.0, 0.0, 31.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 9.0, 9.0, 0.0, 4.0, 1.0, 21.0, 0.0, 17.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 8.0, 0.0, 8.0, 0.0, 6.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 0.0, 9.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 45.0, 21.0, 10.0, 0.0, 2.0, 0.0, 0.0, 16.0, 31.0, 37.0, 0.0, 0.0, 5.0, 3.0, 30.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 1.0, 1.0, 10.0, 0.0, 10.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 5.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.5362799461795589, "mean_inference_ms": 4.105145869445937, "mean_action_processing_ms": 0.7004261334841114, "mean_env_wait_ms": 0.5250109287124929, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004227280616760254, "StateBufferConnector_ms": 0.007816791534423828, "ViewRequirementAgentConnector_ms": 0.1790686845779419}, "num_episodes": 18, "episode_return_max": 387.4, "episode_return_min": -13.199999999999614, "episode_return_mean": 117.88999999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 216.21143471457546, "num_env_steps_trained_throughput_per_sec": 216.21143471457546, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 15374.122, "restore_workers_time_ms": 0.023, "training_step_time_ms": 15373.96, "sample_time_ms": 2228.155, "learn_time_ms": 13125.437, "learn_throughput": 304.752, "synch_weights_time_ms": 16.972}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "e57b0_00000", "date": "2024-08-13_00-27-16", "timestamp": 1723523236, "time_this_iter_s": 18.54538607597351, "time_total_s": 1008.2133560180664, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0db5430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1008.2133560180664, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 77.66538461538462, "ram_util_percent": 82.88461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.867137372718444, "cur_kl_coeff": 0.003337097167968749, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9358602157976263, "policy_loss": -0.0006753887796390151, "vf_loss": 3.936524459167763, "vf_explained_var": 0.28688024790198713, "kl": 0.0033364035438293574, "entropy": 0.5435815801853856, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4967877245473641, "cur_kl_coeff": 0.001318359375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.42787764815111007, "policy_loss": -0.00078211637095563, "vf_loss": 0.4286568540232207, "vf_explained_var": 0.03268689806499178, "kl": 0.0022086044691871157, "entropy": 0.5661799434946958, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -13.199999999999614, "episode_reward_mean": 131.9979999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -61.000000000000654, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 45.0}, "policy_reward_mean": {"prey_policy": 61.15399999999996, "predator_policy": 4.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [224.49999999999935, 114.89999999999897, 4.300000000000173, 152.0999999999991, 219.99999999999926, 166.49999999999886, 146.9999999999989, 31.20000000000017, 50.10000000000039, 183.59999999999943, 69.70000000000009, 36.70000000000025, 262.8000000000014, 203.99999999999932, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 158.99999999999957, 138.99999999999966, 164.1999999999991, 148.2999999999998, 228.09999999999923, 136.2999999999997, 184.69999999999942, 180.399999999999, 73.69999999999975, 108.19999999999878, 72.39999999999989, 143.19999999999962, 88.59999999999872, 102.09999999999852, 35.20000000000023, 240.49999999999952, 40.0000000000003, -13.199999999999614, 219.99999999999926, 27.90000000000011, 123.99999999999883, 40.0000000000003, 52.70000000000039, 40.0000000000003, 92.20000000000005, 196.69999999999936, 387.4, 40.0000000000003, 78.09999999999938, 368.5, 132.8999999999997, 29.00000000000013, 205.5999999999993, 40.0000000000003, 182.19999999999902, 199.99999999999935, 97.59999999999849, 118.59999999999982, 115.39999999999881, 109.79999999999987, 125.8999999999997, 210.29999999999927, 219.99999999999926, 118.49999999999976, 88.00000000000003, 185.79999999999941, 279.3, 29.000000000000142, 65.90000000000036, 186.29999999999941, 67.70000000000005, 144.39999999999964, 40.0000000000003, 40.0000000000003, 40.0000000000003, 192.9999999999991, 144.59999999999923, 265.9000000000017, 208.99999999999932, 32.500000000000185, 27.90000000000011, 30.100000000000154, 148.5999999999997, 162.49999999999952, 211.1999999999993, 137.19999999999885, 85.49999999999928, 16.899999999999938, 40.0000000000003, 152.799999999999, 111.09999999999857, 13.00000000000026, 75.7999999999996, 40.0000000000003, 386.0, 110.79999999999984, 204.99999999999935, 400.0, 317.2, 203.99999999999932, 261.4000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [97.39999999999952, 118.0999999999998, 89.89999999999954, 20.000000000000014, -11.499999999999826, -5.199999999999948, -21.999999999999773, 154.09999999999974, 20.000000000000014, 200.0, 67.09999999999998, 97.39999999999962, 121.9999999999996, 20.000000000000014, 3.1999999999999633, 20.000000000000014, 22.100000000000048, 20.000000000000014, 152.0, 11.599999999999966, 49.70000000000024, 20.000000000000014, 13.699999999999964, 20.000000000000014, 121.99999999999983, 129.79999999999967, 176.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 75.19999999999993, 118.99999999999999, 20.000000000000014, 20.000000000000014, 135.19999999999976, 139.39999999999998, -24.09999999999983, 28.100000000000147, 200.0, 20.000000000000014, 116.29999999999998, 146.3, 19.400000000000006, 160.39999999999975, 20.000000000000014, 5.299999999999965, 61.400000000000205, 20.000000000000014, 78.19999999999942, 52.40000000000023, 20.000000000000014, 109.1, 19.100000000000005, 68.59999999999988, 20.000000000000014, 82.09999999999926, 20.000000000000014, 9.49999999999997, 19.70000000000001, 100.70000000000002, 129.79999999999956, 20.000000000000014, 20.000000000000014, -1.0000000000000204, -47.1999999999998, 200.0, 20.000000000000014, 20.000000000000014, -3.099999999999958, 107.2999999999995, 13.699999999999964, 20.000000000000014, 20.000000000000014, -7.299999999999908, 47.0000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.19999999999996, 170.0, 13.699999999999964, 187.4, 200.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 62.00000000000017, 168.5, 200.0, 121.69999999999999, 3.199999999999967, 20.000000000000014, -0.9999999999999952, 28.100000000000158, 168.5, 20.000000000000014, 20.000000000000014, 162.19999999999976, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 77.59999999999923, 32.599999999999824, 20.000000000000014, 20.000000000000014, 85.39999999999947, 91.99999999999997, 15.799999999999963, 20.000000000000014, 89.90000000000009, -57.70000000000041, 200.0, 200.0, 20.000000000000014, 90.49999999999997, 20.000000000000014, 15.799999999999963, 42.200000000000095, 20.000000000000014, 165.8, 93.19999999999942, 181.1, 20.000000000000014, -1.0000000000000062, 44.90000000000024, 20.000000000000014, 155.3, 20.000000000000014, 37.7, 20.000000000000014, 125.9, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 172.99999999999983, 122.89999999999976, 13.699999999999964, 126.19999999999953, 139.69999999999976, 200.0, -0.9999999999999992, 15.799999999999963, 13.699999999999964, 20.000000000000014, -3.0999999999999615, 1.0999999999999723, 20.000000000000014, 83.60000000000012, 47.0000000000002, 129.50000000000006, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 117.19999999999953, 20.000000000000014, 54.500000000000156, 20.000000000000014, -24.099999999999795, 20.000000000000014, 20.000000000000014, 145.99999999999966, -5.199999999999948, 20.000000000000014, 91.09999999999931, 20.000000000000014, -61.000000000000654, 45.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 57.80000000000001, 20.000000000000014, -5.1999999999999265, 198.2, 200.0, 200.0, 129.20000000000005, 173.0, 176.0, 20.000000000000014, 46.99999999999973, 178.39999999999986], "policy_predator_policy_reward": [9.0, 0.0, 4.0, 1.0, 21.0, 0.0, 17.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 8.0, 0.0, 8.0, 0.0, 6.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 0.0, 0.0, 9.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 45.0, 21.0, 10.0, 0.0, 2.0, 0.0, 0.0, 16.0, 31.0, 37.0, 0.0, 0.0, 5.0, 3.0, 30.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 1.0, 1.0, 10.0, 0.0, 10.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 5.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 11.0, 0.0, 9.0, 13.0, 5.0, 13.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 11.0, 3.0, 18.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 37.0, 17.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 0.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.5249883789604846, "mean_inference_ms": 4.081637465065134, "mean_action_processing_ms": 0.6944636813806132, "mean_env_wait_ms": 0.5207218971379012, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0044095516204833984, "StateBufferConnector_ms": 0.00771641731262207, "ViewRequirementAgentConnector_ms": 0.19497942924499512}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -13.199999999999614, "episode_return_mean": 131.9979999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.43314338462505, "num_env_steps_trained_throughput_per_sec": 202.43314338462505, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 16091.233, "restore_workers_time_ms": 0.023, "training_step_time_ms": 16091.071, "sample_time_ms": 2273.162, "learn_time_ms": 13798.338, "learn_throughput": 289.89, "synch_weights_time_ms": 17.003}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "e57b0_00000", "date": "2024-08-13_00-27-35", "timestamp": 1723523255, "time_this_iter_s": 19.899192810058594, "time_total_s": 1028.112548828125, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12940d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1028.112548828125, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 82.03571428571429, "ram_util_percent": 83.55357142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7944217490258987, "cur_kl_coeff": 0.0016685485839843745, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.400166798016381, "policy_loss": -0.0002861922771901523, "vf_loss": 4.400446331564081, "vf_explained_var": 0.30466527279722627, "kl": 0.003999912997973528, "entropy": 0.45782950547321766, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2828298794825083, "cur_kl_coeff": 0.0006591796875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.26623325621088345, "policy_loss": -0.001184374461364415, "vf_loss": 0.2674097733310653, "vf_explained_var": 0.022119040527040997, "kl": 0.011918516642457787, "entropy": 0.49790406105694945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -13.199999999999614, "episode_reward_mean": 137.8499999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -61.000000000000654, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 45.0}, "policy_reward_mean": {"prey_policy": 63.94999999999996, "predator_policy": 4.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 158.99999999999957, 138.99999999999966, 164.1999999999991, 148.2999999999998, 228.09999999999923, 136.2999999999997, 184.69999999999942, 180.399999999999, 73.69999999999975, 108.19999999999878, 72.39999999999989, 143.19999999999962, 88.59999999999872, 102.09999999999852, 35.20000000000023, 240.49999999999952, 40.0000000000003, -13.199999999999614, 219.99999999999926, 27.90000000000011, 123.99999999999883, 40.0000000000003, 52.70000000000039, 40.0000000000003, 92.20000000000005, 196.69999999999936, 387.4, 40.0000000000003, 78.09999999999938, 368.5, 132.8999999999997, 29.00000000000013, 205.5999999999993, 40.0000000000003, 182.19999999999902, 199.99999999999935, 97.59999999999849, 118.59999999999982, 115.39999999999881, 109.79999999999987, 125.8999999999997, 210.29999999999927, 219.99999999999926, 118.49999999999976, 88.00000000000003, 185.79999999999941, 279.3, 29.000000000000142, 65.90000000000036, 186.29999999999941, 67.70000000000005, 144.39999999999964, 40.0000000000003, 40.0000000000003, 40.0000000000003, 192.9999999999991, 144.59999999999923, 265.9000000000017, 208.99999999999932, 32.500000000000185, 27.90000000000011, 30.100000000000154, 148.5999999999997, 162.49999999999952, 211.1999999999993, 137.19999999999885, 85.49999999999928, 16.899999999999938, 40.0000000000003, 152.799999999999, 111.09999999999857, 13.00000000000026, 75.7999999999996, 40.0000000000003, 386.0, 110.79999999999984, 204.99999999999935, 400.0, 317.2, 203.99999999999932, 261.4000000000001, 14.100000000000032, 258.99999999999983, 115.59999999999891, 150.6999999999996, 40.0000000000003, 185.29999999999941, 289.2999999999997, 160.89999999999955, 25.700000000000074, 38.50000000000027, 40.0000000000003, 237.09999999999897, 146.1999999999996, 219.99999999999926, 299.5000000000008, 192.19999999999916, 322.0, 56.50000000000051], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 15.799999999999963, 75.19999999999993, 118.99999999999999, 20.000000000000014, 20.000000000000014, 135.19999999999976, 139.39999999999998, -24.09999999999983, 28.100000000000147, 200.0, 20.000000000000014, 116.29999999999998, 146.3, 19.400000000000006, 160.39999999999975, 20.000000000000014, 5.299999999999965, 61.400000000000205, 20.000000000000014, 78.19999999999942, 52.40000000000023, 20.000000000000014, 109.1, 19.100000000000005, 68.59999999999988, 20.000000000000014, 82.09999999999926, 20.000000000000014, 9.49999999999997, 19.70000000000001, 100.70000000000002, 129.79999999999956, 20.000000000000014, 20.000000000000014, -1.0000000000000204, -47.1999999999998, 200.0, 20.000000000000014, 20.000000000000014, -3.099999999999958, 107.2999999999995, 13.699999999999964, 20.000000000000014, 20.000000000000014, -7.299999999999908, 47.0000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.19999999999996, 170.0, 13.699999999999964, 187.4, 200.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 62.00000000000017, 168.5, 200.0, 121.69999999999999, 3.199999999999967, 20.000000000000014, -0.9999999999999952, 28.100000000000158, 168.5, 20.000000000000014, 20.000000000000014, 162.19999999999976, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 77.59999999999923, 32.599999999999824, 20.000000000000014, 20.000000000000014, 85.39999999999947, 91.99999999999997, 15.799999999999963, 20.000000000000014, 89.90000000000009, -57.70000000000041, 200.0, 200.0, 20.000000000000014, 90.49999999999997, 20.000000000000014, 15.799999999999963, 42.200000000000095, 20.000000000000014, 165.8, 93.19999999999942, 181.1, 20.000000000000014, -1.0000000000000062, 44.90000000000024, 20.000000000000014, 155.3, 20.000000000000014, 37.7, 20.000000000000014, 125.9, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 172.99999999999983, 122.89999999999976, 13.699999999999964, 126.19999999999953, 139.69999999999976, 200.0, -0.9999999999999992, 15.799999999999963, 13.699999999999964, 20.000000000000014, -3.0999999999999615, 1.0999999999999723, 20.000000000000014, 83.60000000000012, 47.0000000000002, 129.50000000000006, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 117.19999999999953, 20.000000000000014, 54.500000000000156, 20.000000000000014, -24.099999999999795, 20.000000000000014, 20.000000000000014, 145.99999999999966, -5.199999999999948, 20.000000000000014, 91.09999999999931, 20.000000000000014, -61.000000000000654, 45.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 57.80000000000001, 20.000000000000014, -5.1999999999999265, 198.2, 200.0, 200.0, 129.20000000000005, 173.0, 176.0, 20.000000000000014, 46.99999999999973, 178.39999999999986, 1.0999999999999865, -0.9999999999999917, 146.0, 88.99999999999977, 20.000000000000014, 86.59999999999951, 20.000000000000014, 130.7, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 200.0, 89.29999999999997, 20.000000000000014, 128.90000000000003, 20.000000000000014, -7.299999999999901, 20.000000000000014, 6.5000000000000195, 20.000000000000014, 20.000000000000014, 72.19999999999962, 164.89999999999978, 20.000000000000014, 126.19999999999999, 20.000000000000014, 200.0, 135.80000000000004, 148.69999999999968, 24.500000000000036, 151.69999999999985, 152.3, 157.7, 39.80000000000025, 13.699999999999964], "policy_predator_policy_reward": [0.0, 0.0, 33.0, 35.0, 0.0, 0.0, 9.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 45.0, 21.0, 10.0, 0.0, 2.0, 0.0, 0.0, 16.0, 31.0, 37.0, 0.0, 0.0, 5.0, 3.0, 30.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 1.0, 1.0, 10.0, 0.0, 10.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 5.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 11.0, 0.0, 9.0, 13.0, 5.0, 13.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 11.0, 3.0, 18.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 37.0, 17.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 0.0, 36.0, 14.0, 0.0, 8.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 12.0, 0.0, 10.0, 3.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 2.0, 8.0, 8.0, 12.0, 0.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.5163583722247558, "mean_inference_ms": 4.0640225047376735, "mean_action_processing_ms": 0.690010402642852, "mean_env_wait_ms": 0.5173849956270067, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045719146728515625, "StateBufferConnector_ms": 0.007874608039855957, "ViewRequirementAgentConnector_ms": 0.1940925121307373}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -13.199999999999614, "episode_return_mean": 137.8499999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.85546799258987, "num_env_steps_trained_throughput_per_sec": 276.85546799258987, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 16166.73, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16166.57, "sample_time_ms": 2324.154, "learn_time_ms": 13822.952, "learn_throughput": 289.374, "synch_weights_time_ms": 17.094}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "e57b0_00000", "date": "2024-08-13_00-27-50", "timestamp": 1723523270, "time_this_iter_s": 14.491628885269165, "time_total_s": 1042.6041777133942, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1294940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1042.6041777133942, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 62.17142857142858, "ram_util_percent": 83.84285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.33278796180452, "cur_kl_coeff": 0.0008342742919921872, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2953233529650974, "policy_loss": -0.0009569418431806659, "vf_loss": 3.2962768648036573, "vf_explained_var": 0.21480098833482733, "kl": 0.00411176373006958, "entropy": 0.4291040093337417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45019685741730786, "cur_kl_coeff": 0.0006591796875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3641241247337016, "policy_loss": -0.0007870666882289308, "vf_loss": 0.3649100514749686, "vf_explained_var": 0.005338171455595228, "kl": 0.0017304282378247107, "entropy": 0.508015049071539, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -25.999999999999545, "episode_reward_mean": 133.7669999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -106.0000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 60.0}, "policy_reward_mean": {"prey_policy": 61.848499999999966, "predator_policy": 5.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.199999999999614, 219.99999999999926, 27.90000000000011, 123.99999999999883, 40.0000000000003, 52.70000000000039, 40.0000000000003, 92.20000000000005, 196.69999999999936, 387.4, 40.0000000000003, 78.09999999999938, 368.5, 132.8999999999997, 29.00000000000013, 205.5999999999993, 40.0000000000003, 182.19999999999902, 199.99999999999935, 97.59999999999849, 118.59999999999982, 115.39999999999881, 109.79999999999987, 125.8999999999997, 210.29999999999927, 219.99999999999926, 118.49999999999976, 88.00000000000003, 185.79999999999941, 279.3, 29.000000000000142, 65.90000000000036, 186.29999999999941, 67.70000000000005, 144.39999999999964, 40.0000000000003, 40.0000000000003, 40.0000000000003, 192.9999999999991, 144.59999999999923, 265.9000000000017, 208.99999999999932, 32.500000000000185, 27.90000000000011, 30.100000000000154, 148.5999999999997, 162.49999999999952, 211.1999999999993, 137.19999999999885, 85.49999999999928, 16.899999999999938, 40.0000000000003, 152.799999999999, 111.09999999999857, 13.00000000000026, 75.7999999999996, 40.0000000000003, 386.0, 110.79999999999984, 204.99999999999935, 400.0, 317.2, 203.99999999999932, 261.4000000000001, 14.100000000000032, 258.99999999999983, 115.59999999999891, 150.6999999999996, 40.0000000000003, 185.29999999999941, 289.2999999999997, 160.89999999999955, 25.700000000000074, 38.50000000000027, 40.0000000000003, 237.09999999999897, 146.1999999999996, 219.99999999999926, 299.5000000000008, 192.19999999999916, 322.0, 56.50000000000051, 238.29999999999953, 200.89999999999935, 30.100000000000147, 27.00000000000009, 193.39999999999938, -25.999999999999545, 52.20000000000008, 120.09999999999863, 273.8000000000002, 30.10000000000016, 35.600000000000236, 90.59999999999991, 25.700000000000074, 40.0000000000003, 27.90000000000011, 219.99999999999926, 203.69999999999933, 92.19999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1.0000000000000204, -47.1999999999998, 200.0, 20.000000000000014, 20.000000000000014, -3.099999999999958, 107.2999999999995, 13.699999999999964, 20.000000000000014, 20.000000000000014, -7.299999999999908, 47.0000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 72.19999999999996, 170.0, 13.699999999999964, 187.4, 200.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 62.00000000000017, 168.5, 200.0, 121.69999999999999, 3.199999999999967, 20.000000000000014, -0.9999999999999952, 28.100000000000158, 168.5, 20.000000000000014, 20.000000000000014, 162.19999999999976, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 77.59999999999923, 32.599999999999824, 20.000000000000014, 20.000000000000014, 85.39999999999947, 91.99999999999997, 15.799999999999963, 20.000000000000014, 89.90000000000009, -57.70000000000041, 200.0, 200.0, 20.000000000000014, 90.49999999999997, 20.000000000000014, 15.799999999999963, 42.200000000000095, 20.000000000000014, 165.8, 93.19999999999942, 181.1, 20.000000000000014, -1.0000000000000062, 44.90000000000024, 20.000000000000014, 155.3, 20.000000000000014, 37.7, 20.000000000000014, 125.9, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 172.99999999999983, 122.89999999999976, 13.699999999999964, 126.19999999999953, 139.69999999999976, 200.0, -0.9999999999999992, 15.799999999999963, 13.699999999999964, 20.000000000000014, -3.0999999999999615, 1.0999999999999723, 20.000000000000014, 83.60000000000012, 47.0000000000002, 129.50000000000006, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 117.19999999999953, 20.000000000000014, 54.500000000000156, 20.000000000000014, -24.099999999999795, 20.000000000000014, 20.000000000000014, 145.99999999999966, -5.199999999999948, 20.000000000000014, 91.09999999999931, 20.000000000000014, -61.000000000000654, 45.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 57.80000000000001, 20.000000000000014, -5.1999999999999265, 198.2, 200.0, 200.0, 129.20000000000005, 173.0, 176.0, 20.000000000000014, 46.99999999999973, 178.39999999999986, 1.0999999999999865, -0.9999999999999917, 146.0, 88.99999999999977, 20.000000000000014, 86.59999999999951, 20.000000000000014, 130.7, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 200.0, 89.29999999999997, 20.000000000000014, 128.90000000000003, 20.000000000000014, -7.299999999999901, 20.000000000000014, 6.5000000000000195, 20.000000000000014, 20.000000000000014, 72.19999999999962, 164.89999999999978, 20.000000000000014, 126.19999999999999, 20.000000000000014, 200.0, 135.80000000000004, 148.69999999999968, 24.500000000000036, 151.69999999999985, 152.3, 157.7, 39.80000000000025, 13.699999999999964, 66.8000000000001, 159.49999999999974, 173.0, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 15.799999999999963, 23.300000000000075, 160.1, 20.000000000000014, -106.0000000000008, 21.200000000000024, 20.000000000000014, 100.09999999999937, 20.000000000000014, 159.19999999999993, 104.59999999999998, 1.0999999999999652, 20.000000000000014, 20.000000000000014, 11.599999999999964, 62.599999999999966, 20.000000000000014, 3.199999999999965, 9.499999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 185.0, 63.199999999999974, 20.000000000000014], "policy_predator_policy_reward": [0.0, 35.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 45.0, 21.0, 10.0, 0.0, 2.0, 0.0, 0.0, 16.0, 31.0, 37.0, 0.0, 0.0, 5.0, 3.0, 30.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 1.0, 1.0, 10.0, 0.0, 10.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 5.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 11.0, 0.0, 9.0, 13.0, 5.0, 13.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 11.0, 3.0, 18.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 37.0, 17.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 0.0, 36.0, 14.0, 0.0, 8.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 12.0, 0.0, 10.0, 3.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 2.0, 8.0, 8.0, 12.0, 0.0, 0.0, 3.0, 12.0, 0.0, 1.0, 9.0, 9.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 60.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.5091247929565654, "mean_inference_ms": 4.050116118190259, "mean_action_processing_ms": 0.6860376130489189, "mean_env_wait_ms": 0.5145766904177616, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005018711090087891, "StateBufferConnector_ms": 0.004397749900817871, "ViewRequirementAgentConnector_ms": 0.19142615795135498}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -25.999999999999545, "episode_return_mean": 133.7669999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 262.03416264872845, "num_env_steps_trained_throughput_per_sec": 262.03416264872845, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 16055.484, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16055.325, "sample_time_ms": 2219.929, "learn_time_ms": 13813.759, "learn_throughput": 289.566, "synch_weights_time_ms": 18.323}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "e57b0_00000", "date": "2024-08-13_00-28-05", "timestamp": 1723523285, "time_this_iter_s": 15.32692003250122, "time_total_s": 1057.9310977458954, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09cfc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1057.9310977458954, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 65.46818181818183, "ram_util_percent": 83.7090909090909}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3648670372784768, "cur_kl_coeff": 0.0004171371459960936, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.3617004974809275, "policy_loss": -0.0006427167419580714, "vf_loss": 4.362342243976694, "vf_explained_var": 0.21948612310268262, "kl": 0.0023136644101653925, "entropy": 0.3400280207553238, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42051416426778787, "cur_kl_coeff": 0.00032958984375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3067307518667014, "policy_loss": -0.003371195090816371, "vf_loss": 0.31008827675287315, "vf_explained_var": 0.038001990791351074, "kl": 0.04147714775525661, "entropy": 0.5923063481137866, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -31.499999999999524, "episode_reward_mean": 143.8489999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -106.0000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 60.0}, "policy_reward_mean": {"prey_policy": 66.90949999999995, "predator_policy": 5.015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [109.79999999999987, 125.8999999999997, 210.29999999999927, 219.99999999999926, 118.49999999999976, 88.00000000000003, 185.79999999999941, 279.3, 29.000000000000142, 65.90000000000036, 186.29999999999941, 67.70000000000005, 144.39999999999964, 40.0000000000003, 40.0000000000003, 40.0000000000003, 192.9999999999991, 144.59999999999923, 265.9000000000017, 208.99999999999932, 32.500000000000185, 27.90000000000011, 30.100000000000154, 148.5999999999997, 162.49999999999952, 211.1999999999993, 137.19999999999885, 85.49999999999928, 16.899999999999938, 40.0000000000003, 152.799999999999, 111.09999999999857, 13.00000000000026, 75.7999999999996, 40.0000000000003, 386.0, 110.79999999999984, 204.99999999999935, 400.0, 317.2, 203.99999999999932, 261.4000000000001, 14.100000000000032, 258.99999999999983, 115.59999999999891, 150.6999999999996, 40.0000000000003, 185.29999999999941, 289.2999999999997, 160.89999999999955, 25.700000000000074, 38.50000000000027, 40.0000000000003, 237.09999999999897, 146.1999999999996, 219.99999999999926, 299.5000000000008, 192.19999999999916, 322.0, 56.50000000000051, 238.29999999999953, 200.89999999999935, 30.100000000000147, 27.00000000000009, 193.39999999999938, -25.999999999999545, 52.20000000000008, 120.09999999999863, 273.8000000000002, 30.10000000000016, 35.600000000000236, 90.59999999999991, 25.700000000000074, 40.0000000000003, 27.90000000000011, 219.99999999999926, 203.69999999999933, 92.19999999999987, -31.499999999999524, 225.39999999999915, 154.29999999999885, 197.99999999999937, 43.600000000000364, 219.99999999999926, 40.0000000000003, 40.0000000000003, 219.99999999999926, 199.99999999999935, 219.99999999999926, 193.99999999999937, 219.99999999999926, 400.0, 30.100000000000147, 296.7000000000008, 176.59999999999948, 197.59999999999937, 156.99999999999957, 40.0000000000003, 224.79999999999987, 317.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [91.99999999999997, 15.799999999999963, 20.000000000000014, 89.90000000000009, -57.70000000000041, 200.0, 200.0, 20.000000000000014, 90.49999999999997, 20.000000000000014, 15.799999999999963, 42.200000000000095, 20.000000000000014, 165.8, 93.19999999999942, 181.1, 20.000000000000014, -1.0000000000000062, 44.90000000000024, 20.000000000000014, 155.3, 20.000000000000014, 37.7, 20.000000000000014, 125.9, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 172.99999999999983, 122.89999999999976, 13.699999999999964, 126.19999999999953, 139.69999999999976, 200.0, -0.9999999999999992, 15.799999999999963, 13.699999999999964, 20.000000000000014, -3.0999999999999615, 1.0999999999999723, 20.000000000000014, 83.60000000000012, 47.0000000000002, 129.50000000000006, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 117.19999999999953, 20.000000000000014, 54.500000000000156, 20.000000000000014, -24.099999999999795, 20.000000000000014, 20.000000000000014, 145.99999999999966, -5.199999999999948, 20.000000000000014, 91.09999999999931, 20.000000000000014, -61.000000000000654, 45.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 57.80000000000001, 20.000000000000014, -5.1999999999999265, 198.2, 200.0, 200.0, 129.20000000000005, 173.0, 176.0, 20.000000000000014, 46.99999999999973, 178.39999999999986, 1.0999999999999865, -0.9999999999999917, 146.0, 88.99999999999977, 20.000000000000014, 86.59999999999951, 20.000000000000014, 130.7, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 200.0, 89.29999999999997, 20.000000000000014, 128.90000000000003, 20.000000000000014, -7.299999999999901, 20.000000000000014, 6.5000000000000195, 20.000000000000014, 20.000000000000014, 72.19999999999962, 164.89999999999978, 20.000000000000014, 126.19999999999999, 20.000000000000014, 200.0, 135.80000000000004, 148.69999999999968, 24.500000000000036, 151.69999999999985, 152.3, 157.7, 39.80000000000025, 13.699999999999964, 66.8000000000001, 159.49999999999974, 173.0, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 15.799999999999963, 23.300000000000075, 160.1, 20.000000000000014, -106.0000000000008, 21.200000000000024, 20.000000000000014, 100.09999999999937, 20.000000000000014, 159.19999999999993, 104.59999999999998, 1.0999999999999652, 20.000000000000014, 20.000000000000014, 11.599999999999964, 62.599999999999966, 20.000000000000014, 3.199999999999965, 9.499999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 185.0, 63.199999999999974, 20.000000000000014, -101.80000000000081, 5.299999999999965, 31.700000000000212, 193.69999999999996, 134.29999999999959, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 23.600000000000076, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 1.0999999999999865, 20.000000000000014, 200.0, 70.69999999999985, 20.000000000000014, 146.60000000000002, 173.0, 11.599999999999964, 146.89999999999998, 1.099999999999983, 20.000000000000014, 20.000000000000014, 101.60000000000004, 111.19999999999989, 126.20000000000005, 170.0], "policy_predator_policy_reward": [2.0, 0.0, 0.0, 16.0, 31.0, 37.0, 0.0, 0.0, 5.0, 3.0, 30.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 1.0, 1.0, 10.0, 0.0, 10.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 5.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 11.0, 0.0, 9.0, 13.0, 5.0, 13.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 11.0, 3.0, 18.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 37.0, 17.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 0.0, 36.0, 14.0, 0.0, 8.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 12.0, 0.0, 10.0, 3.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 2.0, 8.0, 8.0, 12.0, 0.0, 0.0, 3.0, 12.0, 0.0, 1.0, 9.0, 9.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 60.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 7.0, 58.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 17.0, 9.0, 0.0, 10.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 3.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.500654132354456, "mean_inference_ms": 4.033776871596776, "mean_action_processing_ms": 0.6815948446933846, "mean_env_wait_ms": 0.5113159656580234, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005558609962463379, "StateBufferConnector_ms": 0.004883885383605957, "ViewRequirementAgentConnector_ms": 0.19734036922454834}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -31.499999999999524, "episode_return_mean": 143.8489999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 292.43263730020993, "num_env_steps_trained_throughput_per_sec": 292.43263730020993, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 16224.742, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16224.582, "sample_time_ms": 2295.978, "learn_time_ms": 13905.849, "learn_throughput": 287.649, "synch_weights_time_ms": 18.981}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "e57b0_00000", "date": "2024-08-13_00-28-19", "timestamp": 1723523299, "time_this_iter_s": 13.737322092056274, "time_total_s": 1071.6684198379517, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1294550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1071.6684198379517, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 62.32631578947369, "ram_util_percent": 83.2421052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9771097320018622, "cur_kl_coeff": 0.0002085685729980468, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.3183832545759815, "policy_loss": -0.0002622055210094288, "vf_loss": 4.318645019758315, "vf_explained_var": 0.20241947628202892, "kl": 0.0020991009108303703, "entropy": 0.4211739902773862, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6430513077725967, "cur_kl_coeff": 0.0004943847656249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6684099961525549, "policy_loss": -0.0021878047129287133, "vf_loss": 0.6705894369533453, "vf_explained_var": 0.001935035021847518, "kl": 0.0169163245487264, "entropy": 0.9826787745826459, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -31.499999999999524, "episode_reward_mean": 145.01299999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -109.00000000000028, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 103.0}, "policy_reward_mean": {"prey_policy": 66.80149999999996, "predator_policy": 5.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [148.5999999999997, 162.49999999999952, 211.1999999999993, 137.19999999999885, 85.49999999999928, 16.899999999999938, 40.0000000000003, 152.799999999999, 111.09999999999857, 13.00000000000026, 75.7999999999996, 40.0000000000003, 386.0, 110.79999999999984, 204.99999999999935, 400.0, 317.2, 203.99999999999932, 261.4000000000001, 14.100000000000032, 258.99999999999983, 115.59999999999891, 150.6999999999996, 40.0000000000003, 185.29999999999941, 289.2999999999997, 160.89999999999955, 25.700000000000074, 38.50000000000027, 40.0000000000003, 237.09999999999897, 146.1999999999996, 219.99999999999926, 299.5000000000008, 192.19999999999916, 322.0, 56.50000000000051, 238.29999999999953, 200.89999999999935, 30.100000000000147, 27.00000000000009, 193.39999999999938, -25.999999999999545, 52.20000000000008, 120.09999999999863, 273.8000000000002, 30.10000000000016, 35.600000000000236, 90.59999999999991, 25.700000000000074, 40.0000000000003, 27.90000000000011, 219.99999999999926, 203.69999999999933, 92.19999999999987, -31.499999999999524, 225.39999999999915, 154.29999999999885, 197.99999999999937, 43.600000000000364, 219.99999999999926, 40.0000000000003, 40.0000000000003, 219.99999999999926, 199.99999999999935, 219.99999999999926, 193.99999999999937, 219.99999999999926, 400.0, 30.100000000000147, 296.7000000000008, 176.59999999999948, 197.59999999999937, 156.99999999999957, 40.0000000000003, 224.79999999999987, 317.2, 38.90000000000028, 54.40000000000052, 165.99999999999952, 48.100000000000286, 50.60000000000016, 219.99999999999926, 71.10000000000016, 164.1999999999995, 123.09999999999974, 117.99999999999892, 304.70000000000005, 195.59999999999937, 34.50000000000022, 219.99999999999926, 203.99999999999935, 87.1999999999999, 199.99999999999935, 20.099999999999973, 199.99999999999935, 100.2999999999985, 40.0000000000003, 120.99999999999984, 188.4999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.60000000000012, 47.0000000000002, 129.50000000000006, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 117.19999999999953, 20.000000000000014, 54.500000000000156, 20.000000000000014, -24.099999999999795, 20.000000000000014, 20.000000000000014, 145.99999999999966, -5.199999999999948, 20.000000000000014, 91.09999999999931, 20.000000000000014, -61.000000000000654, 45.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 179.0, 57.80000000000001, 20.000000000000014, -5.1999999999999265, 198.2, 200.0, 200.0, 129.20000000000005, 173.0, 176.0, 20.000000000000014, 46.99999999999973, 178.39999999999986, 1.0999999999999865, -0.9999999999999917, 146.0, 88.99999999999977, 20.000000000000014, 86.59999999999951, 20.000000000000014, 130.7, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 200.0, 89.29999999999997, 20.000000000000014, 128.90000000000003, 20.000000000000014, -7.299999999999901, 20.000000000000014, 6.5000000000000195, 20.000000000000014, 20.000000000000014, 72.19999999999962, 164.89999999999978, 20.000000000000014, 126.19999999999999, 20.000000000000014, 200.0, 135.80000000000004, 148.69999999999968, 24.500000000000036, 151.69999999999985, 152.3, 157.7, 39.80000000000025, 13.699999999999964, 66.8000000000001, 159.49999999999974, 173.0, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 15.799999999999963, 23.300000000000075, 160.1, 20.000000000000014, -106.0000000000008, 21.200000000000024, 20.000000000000014, 100.09999999999937, 20.000000000000014, 159.19999999999993, 104.59999999999998, 1.0999999999999652, 20.000000000000014, 20.000000000000014, 11.599999999999964, 62.599999999999966, 20.000000000000014, 3.199999999999965, 9.499999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 185.0, 63.199999999999974, 20.000000000000014, -101.80000000000081, 5.299999999999965, 31.700000000000212, 193.69999999999996, 134.29999999999959, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 23.600000000000076, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 1.0999999999999865, 20.000000000000014, 200.0, 70.69999999999985, 20.000000000000014, 146.60000000000002, 173.0, 11.599999999999964, 146.89999999999998, 1.099999999999983, 20.000000000000014, 20.000000000000014, 101.60000000000004, 111.19999999999989, 126.20000000000005, 170.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 34.40000000000026, 155.9, 1.0999999999999865, 28.1, 20.000000000000014, 38.90000000000004, -7.299999999999908, 200.0, 20.000000000000014, 25.09999999999974, -109.00000000000028, 144.2, 20.000000000000014, 100.10000000000001, 20.000000000000014, 121.6999999999995, -27.69999999999979, 70.70000000000006, 200.0, 170.0, 11.599999999999964, 9.499999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 176.0, 17.899999999999984, 32.30000000000011, 170.0, 20.000000000000014, -0.9999999999999846, 1.0999999999999652, 20.000000000000014, 170.0, 20.000000000000014, 80.29999999999924, 20.000000000000014, 20.000000000000014, 98.29999999999998, 22.700000000000053, 20.000000000000014, 168.5], "policy_predator_policy_reward": [13.0, 5.0, 13.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 11.0, 3.0, 18.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 37.0, 17.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 0.0, 36.0, 14.0, 0.0, 8.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 12.0, 0.0, 10.0, 3.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 2.0, 8.0, 8.0, 12.0, 0.0, 0.0, 3.0, 12.0, 0.0, 1.0, 9.0, 9.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 60.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 7.0, 58.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 17.0, 9.0, 0.0, 10.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 3.0, 18.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 103.0, 52.0, 0.0, 0.0, 0.0, 3.0, 24.0, 0.0, 8.0, 26.0, 14.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 22.0, 15.0, 10.0, 0.0, 1.0, 19.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4952369016367468, "mean_inference_ms": 4.022446598244779, "mean_action_processing_ms": 0.6779507191763073, "mean_env_wait_ms": 0.5091037397687856, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00756525993347168, "StateBufferConnector_ms": 0.005392193794250488, "ViewRequirementAgentConnector_ms": 0.19794762134552002}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -31.499999999999524, "episode_return_mean": 145.01299999999975, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 257.84956782359154, "num_env_steps_trained_throughput_per_sec": 257.84956782359154, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 16384.833, "restore_workers_time_ms": 0.019, "training_step_time_ms": 16384.736, "sample_time_ms": 2328.802, "learn_time_ms": 14030.156, "learn_throughput": 285.1, "synch_weights_time_ms": 21.468}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "e57b0_00000", "date": "2024-08-13_00-28-35", "timestamp": 1723523315, "time_this_iter_s": 15.654189825057983, "time_total_s": 1087.3226096630096, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1294d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1087.3226096630096, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 73.21818181818182, "ram_util_percent": 83.51363636363637}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9322069234870098, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.063266292829362, "policy_loss": -0.0005171146695920951, "vf_loss": 3.063783283397634, "vf_explained_var": 0.31064872943535055, "kl": 0.0011127609632010074, "entropy": 0.45936664284537077, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4757200191019192, "cur_kl_coeff": 0.0004943847656249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.26135484320518104, "policy_loss": -0.0031488173056108057, "vf_loss": 0.26448654629734825, "vf_explained_var": 0.0058326844500486185, "kl": 0.03461944648084137, "entropy": 0.9359959423226655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -31.499999999999524, "episode_reward_mean": 136.2229999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -109.00000000000028, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 103.0}, "policy_reward_mean": {"prey_policy": 62.60149999999998, "predator_policy": 5.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [261.4000000000001, 14.100000000000032, 258.99999999999983, 115.59999999999891, 150.6999999999996, 40.0000000000003, 185.29999999999941, 289.2999999999997, 160.89999999999955, 25.700000000000074, 38.50000000000027, 40.0000000000003, 237.09999999999897, 146.1999999999996, 219.99999999999926, 299.5000000000008, 192.19999999999916, 322.0, 56.50000000000051, 238.29999999999953, 200.89999999999935, 30.100000000000147, 27.00000000000009, 193.39999999999938, -25.999999999999545, 52.20000000000008, 120.09999999999863, 273.8000000000002, 30.10000000000016, 35.600000000000236, 90.59999999999991, 25.700000000000074, 40.0000000000003, 27.90000000000011, 219.99999999999926, 203.69999999999933, 92.19999999999987, -31.499999999999524, 225.39999999999915, 154.29999999999885, 197.99999999999937, 43.600000000000364, 219.99999999999926, 40.0000000000003, 40.0000000000003, 219.99999999999926, 199.99999999999935, 219.99999999999926, 193.99999999999937, 219.99999999999926, 400.0, 30.100000000000147, 296.7000000000008, 176.59999999999948, 197.59999999999937, 156.99999999999957, 40.0000000000003, 224.79999999999987, 317.2, 38.90000000000028, 54.40000000000052, 165.99999999999952, 48.100000000000286, 50.60000000000016, 219.99999999999926, 71.10000000000016, 164.1999999999995, 123.09999999999974, 117.99999999999892, 304.70000000000005, 195.59999999999937, 34.50000000000022, 219.99999999999926, 203.99999999999935, 87.1999999999999, 199.99999999999935, 20.099999999999973, 199.99999999999935, 100.2999999999985, 40.0000000000003, 120.99999999999984, 188.4999999999994, 219.99999999999926, 36.70000000000025, 148.4999999999996, 62.50000000000051, 20.199999999999974, 152.79999999999959, 14.700000000000015, 30.300000000000146, 200.19999999999936, 199.29999999999936, 146.1999999999991, 189.69999999999936, 46.20000000000041, 217.59999999999926, 108.89999999999986, 32.30000000000018, 72.50000000000026, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.99999999999973, 178.39999999999986, 1.0999999999999865, -0.9999999999999917, 146.0, 88.99999999999977, 20.000000000000014, 86.59999999999951, 20.000000000000014, 130.7, 20.000000000000014, 20.000000000000014, 149.3, 20.000000000000014, 200.0, 89.29999999999997, 20.000000000000014, 128.90000000000003, 20.000000000000014, -7.299999999999901, 20.000000000000014, 6.5000000000000195, 20.000000000000014, 20.000000000000014, 72.19999999999962, 164.89999999999978, 20.000000000000014, 126.19999999999999, 20.000000000000014, 200.0, 135.80000000000004, 148.69999999999968, 24.500000000000036, 151.69999999999985, 152.3, 157.7, 39.80000000000025, 13.699999999999964, 66.8000000000001, 159.49999999999974, 173.0, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 15.799999999999963, 23.300000000000075, 160.1, 20.000000000000014, -106.0000000000008, 21.200000000000024, 20.000000000000014, 100.09999999999937, 20.000000000000014, 159.19999999999993, 104.59999999999998, 1.0999999999999652, 20.000000000000014, 20.000000000000014, 11.599999999999964, 62.599999999999966, 20.000000000000014, 3.199999999999965, 9.499999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 185.0, 63.199999999999974, 20.000000000000014, -101.80000000000081, 5.299999999999965, 31.700000000000212, 193.69999999999996, 134.29999999999959, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 23.600000000000076, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 1.0999999999999865, 20.000000000000014, 200.0, 70.69999999999985, 20.000000000000014, 146.60000000000002, 173.0, 11.599999999999964, 146.89999999999998, 1.099999999999983, 20.000000000000014, 20.000000000000014, 101.60000000000004, 111.19999999999989, 126.20000000000005, 170.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 34.40000000000026, 155.9, 1.0999999999999865, 28.1, 20.000000000000014, 38.90000000000004, -7.299999999999908, 200.0, 20.000000000000014, 25.09999999999974, -109.00000000000028, 144.2, 20.000000000000014, 100.10000000000001, 20.000000000000014, 121.6999999999995, -27.69999999999979, 70.70000000000006, 200.0, 170.0, 11.599999999999964, 9.499999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 176.0, 17.899999999999984, 32.30000000000011, 170.0, 20.000000000000014, -0.9999999999999846, 1.0999999999999652, 20.000000000000014, 170.0, 20.000000000000014, 80.29999999999924, 20.000000000000014, 20.000000000000014, 98.29999999999998, 22.700000000000053, 20.000000000000014, 168.5, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 136.4, 1.0999999999999865, 42.50000000000025, 20.000000000000014, 7.399999999999965, -5.199999999999944, -5.1999999999999265, 146.0, -13.599999999999783, 5.299999999999965, 9.499999999999964, 15.799999999999963, 200.0, -17.79999999999975, 179.3, 20.000000000000014, 20.000000000000014, 126.19999999999972, 96.50000000000011, 81.19999999999925, -9.399999999999855, 41.60000000000025, 11.599999999999964, 200.0, 20.000000000000014, 86.89999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 0.4999999999996305, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 36.0, 14.0, 0.0, 8.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 12.0, 0.0, 10.0, 3.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 2.0, 8.0, 8.0, 12.0, 0.0, 0.0, 3.0, 12.0, 0.0, 1.0, 9.0, 9.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 60.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 7.0, 58.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 17.0, 9.0, 0.0, 10.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 3.0, 18.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 103.0, 52.0, 0.0, 0.0, 0.0, 3.0, 24.0, 0.0, 8.0, 26.0, 14.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 22.0, 15.0, 10.0, 0.0, 1.0, 19.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 9.0, 0.0, 0.0, 0.0, 18.0, 0.0, 12.0, 16.0, 7.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 14.0, 2.0, 4.0, 0.0, 2.0, 7.0, 0.0, 29.0, 23.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.488826731038534, "mean_inference_ms": 4.010673137995342, "mean_action_processing_ms": 0.6739032441057077, "mean_env_wait_ms": 0.506798309855681, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007254123687744141, "StateBufferConnector_ms": 0.005119204521179199, "ViewRequirementAgentConnector_ms": 0.18516921997070312}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -31.499999999999524, "episode_return_mean": 136.2229999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.9690723133674, "num_env_steps_trained_throughput_per_sec": 304.9690723133674, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 15544.208, "restore_workers_time_ms": 0.019, "training_step_time_ms": 15544.111, "sample_time_ms": 2359.524, "learn_time_ms": 13159.56, "learn_throughput": 303.962, "synch_weights_time_ms": 20.988}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "e57b0_00000", "date": "2024-08-13_00-28-48", "timestamp": 1723523328, "time_this_iter_s": 13.163994073867798, "time_total_s": 1100.4866037368774, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0db50d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1100.4866037368774, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 62.478947368421046, "ram_util_percent": 83.53157894736842}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.117111068715652, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.119035318415001, "policy_loss": -0.0006543431004814843, "vf_loss": 3.1196894096319006, "vf_explained_var": 0.3688737973018929, "kl": 0.005231972008746807, "entropy": 0.4242024591517827, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5539362322824893, "cur_kl_coeff": 0.0007415771484375002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14843154715955573, "policy_loss": -0.003966436308325717, "vf_loss": 0.15238468218370352, "vf_explained_var": -0.0802646226668484, "kl": 0.01793586784530991, "entropy": 1.0063763704249469, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -31.499999999999524, "episode_reward_mean": 125.94399999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -109.00000000000028, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 103.0}, "policy_reward_mean": {"prey_policy": 57.67699999999997, "predator_policy": 5.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [56.50000000000051, 238.29999999999953, 200.89999999999935, 30.100000000000147, 27.00000000000009, 193.39999999999938, -25.999999999999545, 52.20000000000008, 120.09999999999863, 273.8000000000002, 30.10000000000016, 35.600000000000236, 90.59999999999991, 25.700000000000074, 40.0000000000003, 27.90000000000011, 219.99999999999926, 203.69999999999933, 92.19999999999987, -31.499999999999524, 225.39999999999915, 154.29999999999885, 197.99999999999937, 43.600000000000364, 219.99999999999926, 40.0000000000003, 40.0000000000003, 219.99999999999926, 199.99999999999935, 219.99999999999926, 193.99999999999937, 219.99999999999926, 400.0, 30.100000000000147, 296.7000000000008, 176.59999999999948, 197.59999999999937, 156.99999999999957, 40.0000000000003, 224.79999999999987, 317.2, 38.90000000000028, 54.40000000000052, 165.99999999999952, 48.100000000000286, 50.60000000000016, 219.99999999999926, 71.10000000000016, 164.1999999999995, 123.09999999999974, 117.99999999999892, 304.70000000000005, 195.59999999999937, 34.50000000000022, 219.99999999999926, 203.99999999999935, 87.1999999999999, 199.99999999999935, 20.099999999999973, 199.99999999999935, 100.2999999999985, 40.0000000000003, 120.99999999999984, 188.4999999999994, 219.99999999999926, 36.70000000000025, 148.4999999999996, 62.50000000000051, 20.199999999999974, 152.79999999999959, 14.700000000000015, 30.300000000000146, 200.19999999999936, 199.29999999999936, 146.1999999999991, 189.69999999999936, 46.20000000000041, 217.59999999999926, 108.89999999999986, 32.30000000000018, 72.50000000000026, 40.0000000000003, 40.0000000000003, 41.00000000000003, 219.99999999999926, 91.09999999999873, 164.6999999999995, 196.59999999999937, 89.7000000000001, 40.0000000000003, 208.89999999999938, 275.7999999999997, 34.50000000000022, 66.1000000000001, 150.7999999999996, 30.400000000000148, 209.8999999999993, 30.100000000000147, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [39.80000000000025, 13.699999999999964, 66.8000000000001, 159.49999999999974, 173.0, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 3.1999999999999615, 15.799999999999963, 23.300000000000075, 160.1, 20.000000000000014, -106.0000000000008, 21.200000000000024, 20.000000000000014, 100.09999999999937, 20.000000000000014, 159.19999999999993, 104.59999999999998, 1.0999999999999652, 20.000000000000014, 20.000000000000014, 11.599999999999964, 62.599999999999966, 20.000000000000014, 3.199999999999965, 9.499999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 185.0, 63.199999999999974, 20.000000000000014, -101.80000000000081, 5.299999999999965, 31.700000000000212, 193.69999999999996, 134.29999999999959, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 23.600000000000076, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 1.0999999999999865, 20.000000000000014, 200.0, 70.69999999999985, 20.000000000000014, 146.60000000000002, 173.0, 11.599999999999964, 146.89999999999998, 1.099999999999983, 20.000000000000014, 20.000000000000014, 101.60000000000004, 111.19999999999989, 126.20000000000005, 170.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 34.40000000000026, 155.9, 1.0999999999999865, 28.1, 20.000000000000014, 38.90000000000004, -7.299999999999908, 200.0, 20.000000000000014, 25.09999999999974, -109.00000000000028, 144.2, 20.000000000000014, 100.10000000000001, 20.000000000000014, 121.6999999999995, -27.69999999999979, 70.70000000000006, 200.0, 170.0, 11.599999999999964, 9.499999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 176.0, 17.899999999999984, 32.30000000000011, 170.0, 20.000000000000014, -0.9999999999999846, 1.0999999999999652, 20.000000000000014, 170.0, 20.000000000000014, 80.29999999999924, 20.000000000000014, 20.000000000000014, 98.29999999999998, 22.700000000000053, 20.000000000000014, 168.5, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 136.4, 1.0999999999999865, 42.50000000000025, 20.000000000000014, 7.399999999999965, -5.199999999999944, -5.1999999999999265, 146.0, -13.599999999999783, 5.299999999999965, 9.499999999999964, 15.799999999999963, 200.0, -17.79999999999975, 179.3, 20.000000000000014, 20.000000000000014, 126.19999999999972, 96.50000000000011, 81.19999999999925, -9.399999999999855, 41.60000000000025, 11.599999999999964, 200.0, 20.000000000000014, 86.89999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 0.4999999999996305, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.00000000000007, -0.9999999999999881, 200.0, 20.000000000000014, 13.699999999999964, 55.40000000000016, 142.7, 20.000000000000014, 176.6, 20.000000000000014, 34.69999999999971, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.000000000000064, 170.9, 79.39999999999924, 196.4, 20.000000000000014, 9.499999999999964, 37.09999999999996, 20.000000000000014, 13.699999999999964, 124.10000000000002, 13.699999999999964, 13.699999999999964, 17.899999999999984, 191.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 3.0, 12.0, 0.0, 1.0, 9.0, 9.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 60.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 7.0, 58.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 17.0, 9.0, 0.0, 10.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 3.0, 18.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 103.0, 52.0, 0.0, 0.0, 0.0, 3.0, 24.0, 0.0, 8.0, 26.0, 14.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 22.0, 15.0, 10.0, 0.0, 1.0, 19.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 9.0, 0.0, 0.0, 0.0, 18.0, 0.0, 12.0, 16.0, 7.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 14.0, 2.0, 4.0, 0.0, 2.0, 7.0, 0.0, 29.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 9.0, 13.0, 2.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 3.0, 10.0, 3.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4829266048433185, "mean_inference_ms": 3.998580689594758, "mean_action_processing_ms": 0.6701304589239763, "mean_env_wait_ms": 0.50457921143718, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00705564022064209, "StateBufferConnector_ms": 0.004930734634399414, "ViewRequirementAgentConnector_ms": 0.17664003372192383}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -31.499999999999524, "episode_return_mean": 125.94399999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.33225365791697, "num_env_steps_trained_throughput_per_sec": 276.33225365791697, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 15534.903, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15534.815, "sample_time_ms": 2327.174, "learn_time_ms": 13181.036, "learn_throughput": 303.466, "synch_weights_time_ms": 22.11}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "e57b0_00000", "date": "2024-08-13_00-29-03", "timestamp": 1723523343, "time_this_iter_s": 14.645753145217896, "time_total_s": 1115.1323568820953, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dba040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1115.1323568820953, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 65.70476190476191, "ram_util_percent": 83.37619047619049}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6327240648763204, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.713974436250313, "policy_loss": -0.0014454541633043575, "vf_loss": 3.7154198206290996, "vf_explained_var": 0.28249997953889233, "kl": 0.0018439417688306562, "entropy": 0.42541560499125686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7509223894940482, "cur_kl_coeff": 0.0007415771484375002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9564540806586149, "policy_loss": -0.00591085600154228, "vf_loss": 0.9623437709357373, "vf_explained_var": 0.007933734491388634, "kl": 0.02854261571862014, "entropy": 1.0315353893729113, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -2.40000000000002, "episode_reward_mean": 127.96099999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -109.00000000000028, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 103.0}, "policy_reward_mean": {"prey_policy": 58.09549999999997, "predator_policy": 5.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [197.99999999999937, 43.600000000000364, 219.99999999999926, 40.0000000000003, 40.0000000000003, 219.99999999999926, 199.99999999999935, 219.99999999999926, 193.99999999999937, 219.99999999999926, 400.0, 30.100000000000147, 296.7000000000008, 176.59999999999948, 197.59999999999937, 156.99999999999957, 40.0000000000003, 224.79999999999987, 317.2, 38.90000000000028, 54.40000000000052, 165.99999999999952, 48.100000000000286, 50.60000000000016, 219.99999999999926, 71.10000000000016, 164.1999999999995, 123.09999999999974, 117.99999999999892, 304.70000000000005, 195.59999999999937, 34.50000000000022, 219.99999999999926, 203.99999999999935, 87.1999999999999, 199.99999999999935, 20.099999999999973, 199.99999999999935, 100.2999999999985, 40.0000000000003, 120.99999999999984, 188.4999999999994, 219.99999999999926, 36.70000000000025, 148.4999999999996, 62.50000000000051, 20.199999999999974, 152.79999999999959, 14.700000000000015, 30.300000000000146, 200.19999999999936, 199.29999999999936, 146.1999999999991, 189.69999999999936, 46.20000000000041, 217.59999999999926, 108.89999999999986, 32.30000000000018, 72.50000000000026, 40.0000000000003, 40.0000000000003, 41.00000000000003, 219.99999999999926, 91.09999999999873, 164.6999999999995, 196.59999999999937, 89.7000000000001, 40.0000000000003, 208.89999999999938, 275.7999999999997, 34.50000000000022, 66.1000000000001, 150.7999999999996, 30.400000000000148, 209.8999999999993, 30.100000000000147, 40.0000000000003, 40.0000000000003, 57.10000000000027, 134.29999999999967, 10.400000000000198, 81.39999999999924, 219.99999999999926, 190.29999999999941, 219.99999999999926, 141.59999999999962, 12.000000000000053, 40.0000000000003, 101.30000000000007, -2.40000000000002, 147.59999999999854, 12.500000000000023, 172.8999999999995, 198.89999999999935, 223.59999999999923, 12.899999999999947, 41.80000000000033, 219.99999999999926, 215.69999999999928, 30.10000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 167.0, 20.000000000000014, 23.600000000000076, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 200.0, 161.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 1.0999999999999865, 20.000000000000014, 200.0, 70.69999999999985, 20.000000000000014, 146.60000000000002, 173.0, 11.599999999999964, 146.89999999999998, 1.099999999999983, 20.000000000000014, 20.000000000000014, 101.60000000000004, 111.19999999999989, 126.20000000000005, 170.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 34.40000000000026, 155.9, 1.0999999999999865, 28.1, 20.000000000000014, 38.90000000000004, -7.299999999999908, 200.0, 20.000000000000014, 25.09999999999974, -109.00000000000028, 144.2, 20.000000000000014, 100.10000000000001, 20.000000000000014, 121.6999999999995, -27.69999999999979, 70.70000000000006, 200.0, 170.0, 11.599999999999964, 9.499999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 176.0, 17.899999999999984, 32.30000000000011, 170.0, 20.000000000000014, -0.9999999999999846, 1.0999999999999652, 20.000000000000014, 170.0, 20.000000000000014, 80.29999999999924, 20.000000000000014, 20.000000000000014, 98.29999999999998, 22.700000000000053, 20.000000000000014, 168.5, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 136.4, 1.0999999999999865, 42.50000000000025, 20.000000000000014, 7.399999999999965, -5.199999999999944, -5.1999999999999265, 146.0, -13.599999999999783, 5.299999999999965, 9.499999999999964, 15.799999999999963, 200.0, -17.79999999999975, 179.3, 20.000000000000014, 20.000000000000014, 126.19999999999972, 96.50000000000011, 81.19999999999925, -9.399999999999855, 41.60000000000025, 11.599999999999964, 200.0, 20.000000000000014, 86.89999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 0.4999999999996305, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.00000000000007, -0.9999999999999881, 200.0, 20.000000000000014, 13.699999999999964, 55.40000000000016, 142.7, 20.000000000000014, 176.6, 20.000000000000014, 34.69999999999971, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.000000000000064, 170.9, 79.39999999999924, 196.4, 20.000000000000014, 9.499999999999964, 37.09999999999996, 20.000000000000014, 13.699999999999964, 124.10000000000002, 13.699999999999964, 13.699999999999964, 17.899999999999984, 191.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.09999999999999, 20.000000000000014, 104.30000000000004, 20.000000000000014, 24.500000000000007, -54.100000000000705, 20.000000000000014, 61.40000000000022, 20.000000000000014, 200.0, 200.0, -36.699999999999775, 200.0, 20.000000000000014, 15.799999999999963, 111.80000000000007, -0.9999999999999917, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.0000000000001, -3.099999999999958, -70.30000000000055, 65.30000000000007, 71.29999999999968, 20.000000000000014, -32.49999999999975, 146.89999999999998, 20.000000000000014, -24.099999999999767, 200.0, 23.600000000000065, 200.0, -103.90000000000074, 30.800000000000196, 21.800000000000047, 20.000000000000014, 20.000000000000014, 200.0, 7.699999999999967, 200.0, 1.0999999999999652, 20.000000000000014], "policy_predator_policy_reward": [4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 17.0, 9.0, 0.0, 10.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 3.0, 18.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 103.0, 52.0, 0.0, 0.0, 0.0, 3.0, 24.0, 0.0, 8.0, 26.0, 14.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 22.0, 15.0, 10.0, 0.0, 1.0, 19.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 9.0, 0.0, 0.0, 0.0, 18.0, 0.0, 12.0, 16.0, 7.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 14.0, 2.0, 4.0, 0.0, 2.0, 7.0, 0.0, 29.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 9.0, 13.0, 2.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 3.0, 10.0, 3.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 29.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 24.0, 7.0, 24.0, 47.0, 0.0, 11.0, 0.0, 25.0, 6.0, 0.0, 14.0, 9.0, 0.0, 0.0, 39.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4775046071210776, "mean_inference_ms": 3.9816081288048264, "mean_action_processing_ms": 0.6657874454592623, "mean_env_wait_ms": 0.5026690493647699, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007012724876403809, "StateBufferConnector_ms": 0.0044831037521362305, "ViewRequirementAgentConnector_ms": 0.1613529920578003}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -2.40000000000002, "episode_return_mean": 127.96099999999977, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 277.193433536167, "num_env_steps_trained_throughput_per_sec": 277.193433536167, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 15380.303, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15380.215, "sample_time_ms": 2435.261, "learn_time_ms": 12916.353, "learn_throughput": 309.685, "synch_weights_time_ms": 24.167}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "e57b0_00000", "date": "2024-08-13_00-29-17", "timestamp": 1723523357, "time_this_iter_s": 14.45808219909668, "time_total_s": 1129.590439081192, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b152b3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1129.590439081192, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 63.68571428571431, "ram_util_percent": 82.13809523809525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9077788463108756, "cur_kl_coeff": 2.607107162475585e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.240178223387905, "policy_loss": -0.000730036535896558, "vf_loss": 4.240908277350128, "vf_explained_var": 0.2885674877772256, "kl": 0.0011126427164260208, "entropy": 0.42635331380934943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6826163596498273, "cur_kl_coeff": 0.0011123657226562494, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.39925984111885543, "policy_loss": 4.506548595609804e-05, "vf_loss": 0.39920619481557945, "vf_explained_var": 0.004408578582541653, "kl": 0.0077138413727683595, "entropy": 0.9951800939267275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 317.2, "episode_reward_min": -16.199999999999612, "episode_reward_mean": 116.74399999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -109.00000000000028, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 103.0}, "policy_reward_mean": {"prey_policy": 52.11199999999999, "predator_policy": 6.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [317.2, 38.90000000000028, 54.40000000000052, 165.99999999999952, 48.100000000000286, 50.60000000000016, 219.99999999999926, 71.10000000000016, 164.1999999999995, 123.09999999999974, 117.99999999999892, 304.70000000000005, 195.59999999999937, 34.50000000000022, 219.99999999999926, 203.99999999999935, 87.1999999999999, 199.99999999999935, 20.099999999999973, 199.99999999999935, 100.2999999999985, 40.0000000000003, 120.99999999999984, 188.4999999999994, 219.99999999999926, 36.70000000000025, 148.4999999999996, 62.50000000000051, 20.199999999999974, 152.79999999999959, 14.700000000000015, 30.300000000000146, 200.19999999999936, 199.29999999999936, 146.1999999999991, 189.69999999999936, 46.20000000000041, 217.59999999999926, 108.89999999999986, 32.30000000000018, 72.50000000000026, 40.0000000000003, 40.0000000000003, 41.00000000000003, 219.99999999999926, 91.09999999999873, 164.6999999999995, 196.59999999999937, 89.7000000000001, 40.0000000000003, 208.89999999999938, 275.7999999999997, 34.50000000000022, 66.1000000000001, 150.7999999999996, 30.400000000000148, 209.8999999999993, 30.100000000000147, 40.0000000000003, 40.0000000000003, 57.10000000000027, 134.29999999999967, 10.400000000000198, 81.39999999999924, 219.99999999999926, 190.29999999999941, 219.99999999999926, 141.59999999999962, 12.000000000000053, 40.0000000000003, 101.30000000000007, -2.40000000000002, 147.59999999999854, 12.500000000000023, 172.8999999999995, 198.89999999999935, 223.59999999999923, 12.899999999999947, 41.80000000000033, 219.99999999999926, 215.69999999999928, 30.10000000000016, 217.60000000000002, 148.89999999999958, 286.9999999999998, 31.200000000000173, 214.60000000000002, -16.199999999999612, 133.2999999999998, 24.400000000000087, 40.0000000000003, 211.9999999999993, 44.90000000000002, 26.800000000000097, 215.59999999999928, 97.59999999999869, 40.0000000000003, 40.0000000000003, 136.89999999999966, 102.09999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [126.20000000000005, 170.0, 17.899999999999988, 20.000000000000014, 20.000000000000014, 34.40000000000026, 155.9, 1.0999999999999865, 28.1, 20.000000000000014, 38.90000000000004, -7.299999999999908, 200.0, 20.000000000000014, 25.09999999999974, -109.00000000000028, 144.2, 20.000000000000014, 100.10000000000001, 20.000000000000014, 121.6999999999995, -27.69999999999979, 70.70000000000006, 200.0, 170.0, 11.599999999999964, 9.499999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 176.0, 17.899999999999984, 32.30000000000011, 170.0, 20.000000000000014, -0.9999999999999846, 1.0999999999999652, 20.000000000000014, 170.0, 20.000000000000014, 80.29999999999924, 20.000000000000014, 20.000000000000014, 98.29999999999998, 22.700000000000053, 20.000000000000014, 168.5, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 136.4, 1.0999999999999865, 42.50000000000025, 20.000000000000014, 7.399999999999965, -5.199999999999944, -5.1999999999999265, 146.0, -13.599999999999783, 5.299999999999965, 9.499999999999964, 15.799999999999963, 200.0, -17.79999999999975, 179.3, 20.000000000000014, 20.000000000000014, 126.19999999999972, 96.50000000000011, 81.19999999999925, -9.399999999999855, 41.60000000000025, 11.599999999999964, 200.0, 20.000000000000014, 86.89999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 0.4999999999996305, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.00000000000007, -0.9999999999999881, 200.0, 20.000000000000014, 13.699999999999964, 55.40000000000016, 142.7, 20.000000000000014, 176.6, 20.000000000000014, 34.69999999999971, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.000000000000064, 170.9, 79.39999999999924, 196.4, 20.000000000000014, 9.499999999999964, 37.09999999999996, 20.000000000000014, 13.699999999999964, 124.10000000000002, 13.699999999999964, 13.699999999999964, 17.899999999999984, 191.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.09999999999999, 20.000000000000014, 104.30000000000004, 20.000000000000014, 24.500000000000007, -54.100000000000705, 20.000000000000014, 61.40000000000022, 20.000000000000014, 200.0, 200.0, -36.699999999999775, 200.0, 20.000000000000014, 15.799999999999963, 111.80000000000007, -0.9999999999999917, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.0000000000001, -3.099999999999958, -70.30000000000055, 65.30000000000007, 71.29999999999968, 20.000000000000014, -32.49999999999975, 146.89999999999998, 20.000000000000014, -24.099999999999767, 200.0, 23.600000000000065, 200.0, -103.90000000000074, 30.800000000000196, 21.800000000000047, 20.000000000000014, 20.000000000000014, 200.0, 7.699999999999967, 200.0, 1.0999999999999652, 20.000000000000014, 139.7, 65.90000000000009, 128.89999999999998, 20.000000000000014, 79.99999999999997, 200.0, 20.000000000000014, 3.199999999999965, 104.59999999999998, 109.99999999999997, -88.00000000000065, 15.799999999999962, 39.79999999999998, 60.50000000000022, 11.300000000000022, 1.0999999999999617, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, -0.099999999999838, 20.000000000000014, -5.199999999999941, 20.000000000000014, 200.0, 11.599999999999964, 20.000000000000014, 68.59999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.89999999999998, 82.09999999999997, 20.000000000000014], "policy_predator_policy_reward": [3.0, 18.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 103.0, 52.0, 0.0, 0.0, 0.0, 3.0, 24.0, 0.0, 8.0, 26.0, 14.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 22.0, 15.0, 10.0, 0.0, 1.0, 19.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 9.0, 0.0, 0.0, 0.0, 18.0, 0.0, 12.0, 16.0, 7.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 14.0, 2.0, 4.0, 0.0, 2.0, 7.0, 0.0, 29.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 9.0, 13.0, 2.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 3.0, 10.0, 3.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 29.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 24.0, 7.0, 24.0, 47.0, 0.0, 11.0, 0.0, 25.0, 6.0, 0.0, 14.0, 9.0, 0.0, 0.0, 39.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 56.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 25.0, 0.0, 12.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4706604340629275, "mean_inference_ms": 3.9759730540012526, "mean_action_processing_ms": 0.6627941771809744, "mean_env_wait_ms": 0.5003410580861781, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006773233413696289, "StateBufferConnector_ms": 0.0041506290435791016, "ViewRequirementAgentConnector_ms": 0.16815590858459473}, "num_episodes": 18, "episode_return_max": 317.2, "episode_return_min": -16.199999999999612, "episode_return_mean": 116.74399999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 271.09322360175054, "num_env_steps_trained_throughput_per_sec": 271.09322360175054, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 15394.139, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15394.054, "sample_time_ms": 2507.999, "learn_time_ms": 12859.254, "learn_throughput": 311.06, "synch_weights_time_ms": 22.486}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "e57b0_00000", "date": "2024-08-13_00-29-32", "timestamp": 1723523372, "time_this_iter_s": 14.79817509651184, "time_total_s": 1144.3886141777039, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dbaf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1144.3886141777039, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 67.38095238095238, "ram_util_percent": 82.87619047619049}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3188891925233066, "cur_kl_coeff": 1.3035535812377926e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.703796029217028, "policy_loss": -0.002582393675086596, "vf_loss": 4.706378433187172, "vf_explained_var": 0.36092915065074094, "kl": 0.0070159410263268525, "entropy": 0.3545053319325523, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5218606612965386, "cur_kl_coeff": 0.0011123657226562494, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3350500257636504, "policy_loss": -0.002327451587373775, "vf_loss": 0.3373607851021613, "vf_explained_var": 0.07398422127047544, "kl": 0.015006882267554946, "entropy": 0.9265663136250127, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 380.0, "episode_reward_min": -16.199999999999612, "episode_reward_mean": 121.52599999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -103.90000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 56.0}, "policy_reward_mean": {"prey_policy": 55.16299999999998, "predator_policy": 5.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [188.4999999999994, 219.99999999999926, 36.70000000000025, 148.4999999999996, 62.50000000000051, 20.199999999999974, 152.79999999999959, 14.700000000000015, 30.300000000000146, 200.19999999999936, 199.29999999999936, 146.1999999999991, 189.69999999999936, 46.20000000000041, 217.59999999999926, 108.89999999999986, 32.30000000000018, 72.50000000000026, 40.0000000000003, 40.0000000000003, 41.00000000000003, 219.99999999999926, 91.09999999999873, 164.6999999999995, 196.59999999999937, 89.7000000000001, 40.0000000000003, 208.89999999999938, 275.7999999999997, 34.50000000000022, 66.1000000000001, 150.7999999999996, 30.400000000000148, 209.8999999999993, 30.100000000000147, 40.0000000000003, 40.0000000000003, 57.10000000000027, 134.29999999999967, 10.400000000000198, 81.39999999999924, 219.99999999999926, 190.29999999999941, 219.99999999999926, 141.59999999999962, 12.000000000000053, 40.0000000000003, 101.30000000000007, -2.40000000000002, 147.59999999999854, 12.500000000000023, 172.8999999999995, 198.89999999999935, 223.59999999999923, 12.899999999999947, 41.80000000000033, 219.99999999999926, 215.69999999999928, 30.10000000000016, 217.60000000000002, 148.89999999999958, 286.9999999999998, 31.200000000000173, 214.60000000000002, -16.199999999999612, 133.2999999999998, 24.400000000000087, 40.0000000000003, 211.9999999999993, 44.90000000000002, 26.800000000000097, 215.59999999999928, 97.59999999999869, 40.0000000000003, 40.0000000000003, 136.89999999999966, 102.09999999999995, 324.3999999999999, 209.1999999999993, 40.0000000000003, 219.99999999999926, 83.69999999999911, 19.099999999999966, 219.99999999999926, 380.0, 40.0000000000003, 25.70000000000007, 211.9999999999993, 88.89999999999989, 208.99999999999932, 173.4999999999995, 198.09999999999937, 133.99999999999966, 133.89999999999887, 40.0000000000003, 184.29999999999941, 376.0, 37.80000000000027, 30.100000000000158, 197.49999999999937], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 168.5, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 136.4, 1.0999999999999865, 42.50000000000025, 20.000000000000014, 7.399999999999965, -5.199999999999944, -5.1999999999999265, 146.0, -13.599999999999783, 5.299999999999965, 9.499999999999964, 15.799999999999963, 200.0, -17.79999999999975, 179.3, 20.000000000000014, 20.000000000000014, 126.19999999999972, 96.50000000000011, 81.19999999999925, -9.399999999999855, 41.60000000000025, 11.599999999999964, 200.0, 20.000000000000014, 86.89999999999999, 20.000000000000014, 5.299999999999965, 20.000000000000014, 0.4999999999996305, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.00000000000007, -0.9999999999999881, 200.0, 20.000000000000014, 13.699999999999964, 55.40000000000016, 142.7, 20.000000000000014, 176.6, 20.000000000000014, 34.69999999999971, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.000000000000064, 170.9, 79.39999999999924, 196.4, 20.000000000000014, 9.499999999999964, 37.09999999999996, 20.000000000000014, 13.699999999999964, 124.10000000000002, 13.699999999999964, 13.699999999999964, 17.899999999999984, 191.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.09999999999999, 20.000000000000014, 104.30000000000004, 20.000000000000014, 24.500000000000007, -54.100000000000705, 20.000000000000014, 61.40000000000022, 20.000000000000014, 200.0, 200.0, -36.699999999999775, 200.0, 20.000000000000014, 15.799999999999963, 111.80000000000007, -0.9999999999999917, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.0000000000001, -3.099999999999958, -70.30000000000055, 65.30000000000007, 71.29999999999968, 20.000000000000014, -32.49999999999975, 146.89999999999998, 20.000000000000014, -24.099999999999767, 200.0, 23.600000000000065, 200.0, -103.90000000000074, 30.800000000000196, 21.800000000000047, 20.000000000000014, 20.000000000000014, 200.0, 7.699999999999967, 200.0, 1.0999999999999652, 20.000000000000014, 139.7, 65.90000000000009, 128.89999999999998, 20.000000000000014, 79.99999999999997, 200.0, 20.000000000000014, 3.199999999999965, 104.59999999999998, 109.99999999999997, -88.00000000000065, 15.799999999999962, 39.79999999999998, 60.50000000000022, 11.300000000000022, 1.0999999999999617, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, -0.099999999999838, 20.000000000000014, -5.199999999999941, 20.000000000000014, 200.0, 11.599999999999964, 20.000000000000014, 68.59999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.89999999999998, 82.09999999999997, 20.000000000000014, 124.39999999999998, 200.0, 189.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 61.70000000000012, -1.0000000000000027, 1.0999999999999865, 20.000000000000014, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, 188.0, 22.700000000000053, -2.800000000000324, 176.0, 20.000000000000014, 150.5, 20.000000000000014, 1.09999999999996, 182.0, 100.70000000000009, 5.299999999999965, 127.09999999999954, -5.199999999999934, 20.000000000000014, 20.000000000000014, 61.70000000000012, 95.59999999999945, 164.0, 200.0, 20.000000000000014, 15.799999999999962, 1.0999999999999652, 20.000000000000014, 177.5, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 9.0, 0.0, 0.0, 0.0, 18.0, 0.0, 12.0, 16.0, 7.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 14.0, 2.0, 4.0, 0.0, 2.0, 7.0, 0.0, 29.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 9.0, 13.0, 2.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 3.0, 10.0, 3.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 29.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 24.0, 7.0, 24.0, 47.0, 0.0, 11.0, 0.0, 25.0, 6.0, 0.0, 14.0, 9.0, 0.0, 0.0, 39.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 56.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 25.0, 0.0, 12.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 0.0, 4.0, 46.0, 23.0, 8.0, 5.0, 3.0, 0.0, 6.0, 9.0, 11.0, 17.0, 0.0, 12.0, 0.0, 0.0, 17.0, 10.0, 10.0, 2.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.46248266428156, "mean_inference_ms": 3.960482967743693, "mean_action_processing_ms": 0.658161553377452, "mean_env_wait_ms": 0.49750359106279274, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005832314491271973, "StateBufferConnector_ms": 0.0038753747940063477, "ViewRequirementAgentConnector_ms": 0.15595030784606934}, "num_episodes": 23, "episode_return_max": 380.0, "episode_return_min": -16.199999999999612, "episode_return_mean": 121.52599999999978, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.6582731097136, "num_env_steps_trained_throughput_per_sec": 300.6582731097136, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 14874.512, "restore_workers_time_ms": 0.02, "training_step_time_ms": 14874.451, "sample_time_ms": 2466.023, "learn_time_ms": 12381.718, "learn_throughput": 323.057, "synch_weights_time_ms": 22.51}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "e57b0_00000", "date": "2024-08-13_00-29-46", "timestamp": 1723523386, "time_this_iter_s": 13.361407995223999, "time_total_s": 1157.7500221729279, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dbab80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1157.7500221729279, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 64.11578947368422, "ram_util_percent": 79.27894736842104}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8661691577267394, "cur_kl_coeff": 1.3035535812377926e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0628637238154335, "policy_loss": -0.000930342137586897, "vf_loss": 4.0637940670447374, "vf_explained_var": 0.2178501357477178, "kl": 0.003453956648101144, "entropy": 0.347322242482314, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7557059347215626, "cur_kl_coeff": 0.0011123657226562494, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5693061042241949, "policy_loss": -0.0017804612523861347, "vf_loss": 0.5710569216986187, "vf_explained_var": 0.005063000967893651, "kl": 0.02664924611699435, "entropy": 0.8915174247411193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 380.0, "episode_reward_min": -16.199999999999612, "episode_reward_mean": 128.41299999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -103.90000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 56.0}, "policy_reward_mean": {"prey_policy": 59.12149999999999, "predator_policy": 5.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, 41.00000000000003, 219.99999999999926, 91.09999999999873, 164.6999999999995, 196.59999999999937, 89.7000000000001, 40.0000000000003, 208.89999999999938, 275.7999999999997, 34.50000000000022, 66.1000000000001, 150.7999999999996, 30.400000000000148, 209.8999999999993, 30.100000000000147, 40.0000000000003, 40.0000000000003, 57.10000000000027, 134.29999999999967, 10.400000000000198, 81.39999999999924, 219.99999999999926, 190.29999999999941, 219.99999999999926, 141.59999999999962, 12.000000000000053, 40.0000000000003, 101.30000000000007, -2.40000000000002, 147.59999999999854, 12.500000000000023, 172.8999999999995, 198.89999999999935, 223.59999999999923, 12.899999999999947, 41.80000000000033, 219.99999999999926, 215.69999999999928, 30.10000000000016, 217.60000000000002, 148.89999999999958, 286.9999999999998, 31.200000000000173, 214.60000000000002, -16.199999999999612, 133.2999999999998, 24.400000000000087, 40.0000000000003, 211.9999999999993, 44.90000000000002, 26.800000000000097, 215.59999999999928, 97.59999999999869, 40.0000000000003, 40.0000000000003, 136.89999999999966, 102.09999999999995, 324.3999999999999, 209.1999999999993, 40.0000000000003, 219.99999999999926, 83.69999999999911, 19.099999999999966, 219.99999999999926, 380.0, 40.0000000000003, 25.70000000000007, 211.9999999999993, 88.89999999999989, 208.99999999999932, 173.4999999999995, 198.09999999999937, 133.99999999999966, 133.89999999999887, 40.0000000000003, 184.29999999999941, 376.0, 37.80000000000027, 30.100000000000158, 197.49999999999937, 107.19999999999982, 34.50000000000022, 243.3999999999991, 40.0000000000003, 152.49999999999957, 206.99999999999932, 155.19999999999845, 219.99999999999926, 192.0999999999994, 29.000000000000128, 152.49999999999883, 40.0000000000003, 219.99999999999926, 178.89999999999947, 30.100000000000165, 219.99999999999926, 219.99999999999926, 333.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.00000000000007, -0.9999999999999881, 200.0, 20.000000000000014, 13.699999999999964, 55.40000000000016, 142.7, 20.000000000000014, 176.6, 20.000000000000014, 34.69999999999971, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.000000000000064, 170.9, 79.39999999999924, 196.4, 20.000000000000014, 9.499999999999964, 37.09999999999996, 20.000000000000014, 13.699999999999964, 124.10000000000002, 13.699999999999964, 13.699999999999964, 17.899999999999984, 191.0, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.09999999999999, 20.000000000000014, 104.30000000000004, 20.000000000000014, 24.500000000000007, -54.100000000000705, 20.000000000000014, 61.40000000000022, 20.000000000000014, 200.0, 200.0, -36.699999999999775, 200.0, 20.000000000000014, 15.799999999999963, 111.80000000000007, -0.9999999999999917, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.0000000000001, -3.099999999999958, -70.30000000000055, 65.30000000000007, 71.29999999999968, 20.000000000000014, -32.49999999999975, 146.89999999999998, 20.000000000000014, -24.099999999999767, 200.0, 23.600000000000065, 200.0, -103.90000000000074, 30.800000000000196, 21.800000000000047, 20.000000000000014, 20.000000000000014, 200.0, 7.699999999999967, 200.0, 1.0999999999999652, 20.000000000000014, 139.7, 65.90000000000009, 128.89999999999998, 20.000000000000014, 79.99999999999997, 200.0, 20.000000000000014, 3.199999999999965, 104.59999999999998, 109.99999999999997, -88.00000000000065, 15.799999999999962, 39.79999999999998, 60.50000000000022, 11.300000000000022, 1.0999999999999617, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, -0.099999999999838, 20.000000000000014, -5.199999999999941, 20.000000000000014, 200.0, 11.599999999999964, 20.000000000000014, 68.59999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.89999999999998, 82.09999999999997, 20.000000000000014, 124.39999999999998, 200.0, 189.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 61.70000000000012, -1.0000000000000027, 1.0999999999999865, 20.000000000000014, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, 188.0, 22.700000000000053, -2.800000000000324, 176.0, 20.000000000000014, 150.5, 20.000000000000014, 1.09999999999996, 182.0, 100.70000000000009, 5.299999999999965, 127.09999999999954, -5.199999999999934, 20.000000000000014, 20.000000000000014, 61.70000000000012, 95.59999999999945, 164.0, 200.0, 20.000000000000014, 15.799999999999962, 1.0999999999999652, 20.000000000000014, 177.5, 20.000000000000014, 20.000000000000014, 72.2000000000001, 11.599999999999964, 17.899999999999988, 200.0, 43.40000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.5, 20.000000000000014, 167.0, 55.10000000000023, 100.09999999999937, 20.000000000000014, 200.0, 1.099999999999983, 182.0, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 132.49999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -3.0999999999999615, 1.09999999999996, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 133.39999999999998], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 10.0, 12.0, 0.0, 0.0, 9.0, 13.0, 2.0, 0.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 3.0, 10.0, 3.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 29.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 24.0, 7.0, 24.0, 47.0, 0.0, 11.0, 0.0, 25.0, 6.0, 0.0, 14.0, 9.0, 0.0, 0.0, 39.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 56.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 25.0, 0.0, 12.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 0.0, 4.0, 46.0, 23.0, 8.0, 5.0, 3.0, 0.0, 6.0, 9.0, 11.0, 17.0, 0.0, 12.0, 0.0, 0.0, 17.0, 10.0, 10.0, 2.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 6.0, 9.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4551145947766697, "mean_inference_ms": 3.945535203709228, "mean_action_processing_ms": 0.6543055733288952, "mean_env_wait_ms": 0.494759932715353, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006715297698974609, "StateBufferConnector_ms": 0.00390017032623291, "ViewRequirementAgentConnector_ms": 0.1465914249420166}, "num_episodes": 18, "episode_return_max": 380.0, "episode_return_min": -16.199999999999612, "episode_return_mean": 128.41299999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.992223185323, "num_env_steps_trained_throughput_per_sec": 365.992223185323, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 13991.47, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13991.411, "sample_time_ms": 2359.904, "learn_time_ms": 11605.115, "learn_throughput": 344.676, "synch_weights_time_ms": 22.416}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "e57b0_00000", "date": "2024-08-13_00-29-56", "timestamp": 1723523396, "time_this_iter_s": 10.933214902877808, "time_total_s": 1168.6832370758057, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b41040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1168.6832370758057, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 44.42666666666666, "ram_util_percent": 77.99333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9338330682662745, "cur_kl_coeff": 6.517767906188963e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.333364896294932, "policy_loss": -0.0010966171107683626, "vf_loss": 4.33446151705646, "vf_explained_var": 0.16952808846241582, "kl": 0.001037061471233295, "entropy": 0.3311669971577074, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0325495807109055, "cur_kl_coeff": 0.0016685485839843745, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7368062052461836, "policy_loss": -0.0029204227298833233, "vf_loss": 0.7397025059770654, "vf_explained_var": 0.0020703594835977707, "kl": 0.014456781172153838, "entropy": 0.9531281381372422, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -24.89999999999967, "episode_reward_mean": 133.22299999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -282.3999999999987, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 109.0}, "policy_reward_mean": {"prey_policy": 59.54149999999998, "predator_policy": 7.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 57.10000000000027, 134.29999999999967, 10.400000000000198, 81.39999999999924, 219.99999999999926, 190.29999999999941, 219.99999999999926, 141.59999999999962, 12.000000000000053, 40.0000000000003, 101.30000000000007, -2.40000000000002, 147.59999999999854, 12.500000000000023, 172.8999999999995, 198.89999999999935, 223.59999999999923, 12.899999999999947, 41.80000000000033, 219.99999999999926, 215.69999999999928, 30.10000000000016, 217.60000000000002, 148.89999999999958, 286.9999999999998, 31.200000000000173, 214.60000000000002, -16.199999999999612, 133.2999999999998, 24.400000000000087, 40.0000000000003, 211.9999999999993, 44.90000000000002, 26.800000000000097, 215.59999999999928, 97.59999999999869, 40.0000000000003, 40.0000000000003, 136.89999999999966, 102.09999999999995, 324.3999999999999, 209.1999999999993, 40.0000000000003, 219.99999999999926, 83.69999999999911, 19.099999999999966, 219.99999999999926, 380.0, 40.0000000000003, 25.70000000000007, 211.9999999999993, 88.89999999999989, 208.99999999999932, 173.4999999999995, 198.09999999999937, 133.99999999999966, 133.89999999999887, 40.0000000000003, 184.29999999999941, 376.0, 37.80000000000027, 30.100000000000158, 197.49999999999937, 107.19999999999982, 34.50000000000022, 243.3999999999991, 40.0000000000003, 152.49999999999957, 206.99999999999932, 155.19999999999845, 219.99999999999926, 192.0999999999994, 29.000000000000128, 152.49999999999883, 40.0000000000003, 219.99999999999926, 178.89999999999947, 30.100000000000165, 219.99999999999926, 219.99999999999926, 333.4, -24.89999999999967, 64.60000000000005, 221.39999999999924, 40.0000000000003, 130.19999999999973, 216.69999999999928, 35.600000000000236, 346.9000000000001, 219.99999999999926, 213.9999999999993, 219.99999999999926, 24.000000000000064, 12.700000000000294, 11.39999999999992, 22.40000000000002, 400.0, 93.19999999999987, 202.39999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 37.09999999999999, 20.000000000000014, 104.30000000000004, 20.000000000000014, 24.500000000000007, -54.100000000000705, 20.000000000000014, 61.40000000000022, 20.000000000000014, 200.0, 200.0, -36.699999999999775, 200.0, 20.000000000000014, 15.799999999999963, 111.80000000000007, -0.9999999999999917, -0.9999999999999992, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.0000000000001, -3.099999999999958, -70.30000000000055, 65.30000000000007, 71.29999999999968, 20.000000000000014, -32.49999999999975, 146.89999999999998, 20.000000000000014, -24.099999999999767, 200.0, 23.600000000000065, 200.0, -103.90000000000074, 30.800000000000196, 21.800000000000047, 20.000000000000014, 20.000000000000014, 200.0, 7.699999999999967, 200.0, 1.0999999999999652, 20.000000000000014, 139.7, 65.90000000000009, 128.89999999999998, 20.000000000000014, 79.99999999999997, 200.0, 20.000000000000014, 3.199999999999965, 104.59999999999998, 109.99999999999997, -88.00000000000065, 15.799999999999962, 39.79999999999998, 60.50000000000022, 11.300000000000022, 1.0999999999999617, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, -0.099999999999838, 20.000000000000014, -5.199999999999941, 20.000000000000014, 200.0, 11.599999999999964, 20.000000000000014, 68.59999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.89999999999998, 82.09999999999997, 20.000000000000014, 124.39999999999998, 200.0, 189.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 61.70000000000012, -1.0000000000000027, 1.0999999999999865, 20.000000000000014, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, 188.0, 22.700000000000053, -2.800000000000324, 176.0, 20.000000000000014, 150.5, 20.000000000000014, 1.09999999999996, 182.0, 100.70000000000009, 5.299999999999965, 127.09999999999954, -5.199999999999934, 20.000000000000014, 20.000000000000014, 61.70000000000012, 95.59999999999945, 164.0, 200.0, 20.000000000000014, 15.799999999999962, 1.0999999999999652, 20.000000000000014, 177.5, 20.000000000000014, 20.000000000000014, 72.2000000000001, 11.599999999999964, 17.899999999999988, 200.0, 43.40000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.5, 20.000000000000014, 167.0, 55.10000000000023, 100.09999999999937, 20.000000000000014, 200.0, 1.099999999999983, 182.0, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 132.49999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -3.0999999999999615, 1.09999999999996, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 133.39999999999998, -103.90000000000057, 20.000000000000014, 200.0, -282.3999999999987, 200.0, 19.40000000000001, 20.000000000000014, 20.000000000000014, -85.0000000000008, 126.19999999999999, 200.0, 13.699999999999964, 20.000000000000014, 11.599999999999964, 200.0, 146.89999999999998, 20.000000000000014, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, -139.6000000000007, 86.59999999999997, -101.80000000000068, 45.500000000000036, 20.000000000000014, -34.599999999999824, 5.299999999999965, 1.0999999999999635, 200.0, 200.0, 3.1999999999999615, 68.00000000000011, 200.0, -13.599999999999797], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 29.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 14.0, 14.0, 0.0, 0.0, 0.0, 24.0, 7.0, 24.0, 47.0, 0.0, 11.0, 0.0, 25.0, 6.0, 0.0, 14.0, 9.0, 0.0, 0.0, 39.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 56.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 25.0, 0.0, 12.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 0.0, 4.0, 46.0, 23.0, 8.0, 5.0, 3.0, 0.0, 6.0, 9.0, 11.0, 17.0, 0.0, 12.0, 0.0, 0.0, 17.0, 10.0, 10.0, 2.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 6.0, 9.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 19.0, 38.0, 109.0, 1.0, 1.0, 0.0, 0.0, 49.0, 40.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 32.0, 58.0, 11.0, 0.0, 26.0, 0.0, 16.0, 0.0, 0.0, 8.0, 14.0, 6.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4473096074320457, "mean_inference_ms": 3.928684336199532, "mean_action_processing_ms": 0.650374503634992, "mean_env_wait_ms": 0.49187276606600716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007238984107971191, "StateBufferConnector_ms": 0.004001259803771973, "ViewRequirementAgentConnector_ms": 0.14288711547851562}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -24.89999999999967, "episode_return_mean": 133.22299999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 400.54819747753146, "num_env_steps_trained_throughput_per_sec": 400.54819747753146, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 13545.305, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13545.246, "sample_time_ms": 2244.903, "learn_time_ms": 11274.159, "learn_throughput": 354.794, "synch_weights_time_ms": 22.19}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "e57b0_00000", "date": "2024-08-13_00-30-07", "timestamp": 1723523407, "time_this_iter_s": 9.992614984512329, "time_total_s": 1178.675852060318, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09bbca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1178.675852060318, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 46.04285714285714, "ram_util_percent": 78.54999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6623138153718577, "cur_kl_coeff": 3.2588839530944814e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3863721218058673, "policy_loss": -0.0003726377673003645, "vf_loss": 3.3867447623500118, "vf_explained_var": 0.22058798276558125, "kl": 0.001245972403760407, "entropy": 0.43618506555834774, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8448738282851914, "cur_kl_coeff": 0.0016685485839843745, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.27853136053161015, "policy_loss": -0.0025047298942116043, "vf_loss": 0.28098742430406026, "vf_explained_var": -0.017217588077777277, "kl": 0.02916665224023921, "entropy": 0.8639207588932502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.099999999999717, "episode_reward_mean": 130.7689999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -282.3999999999987, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 109.0}, "policy_reward_mean": {"prey_policy": 59.39449999999998, "predator_policy": 5.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.10000000000016, 217.60000000000002, 148.89999999999958, 286.9999999999998, 31.200000000000173, 214.60000000000002, -16.199999999999612, 133.2999999999998, 24.400000000000087, 40.0000000000003, 211.9999999999993, 44.90000000000002, 26.800000000000097, 215.59999999999928, 97.59999999999869, 40.0000000000003, 40.0000000000003, 136.89999999999966, 102.09999999999995, 324.3999999999999, 209.1999999999993, 40.0000000000003, 219.99999999999926, 83.69999999999911, 19.099999999999966, 219.99999999999926, 380.0, 40.0000000000003, 25.70000000000007, 211.9999999999993, 88.89999999999989, 208.99999999999932, 173.4999999999995, 198.09999999999937, 133.99999999999966, 133.89999999999887, 40.0000000000003, 184.29999999999941, 376.0, 37.80000000000027, 30.100000000000158, 197.49999999999937, 107.19999999999982, 34.50000000000022, 243.3999999999991, 40.0000000000003, 152.49999999999957, 206.99999999999932, 155.19999999999845, 219.99999999999926, 192.0999999999994, 29.000000000000128, 152.49999999999883, 40.0000000000003, 219.99999999999926, 178.89999999999947, 30.100000000000165, 219.99999999999926, 219.99999999999926, 333.4, -24.89999999999967, 64.60000000000005, 221.39999999999924, 40.0000000000003, 130.19999999999973, 216.69999999999928, 35.600000000000236, 346.9000000000001, 219.99999999999926, 213.9999999999993, 219.99999999999926, 24.000000000000064, 12.700000000000294, 11.39999999999992, 22.40000000000002, 400.0, 93.19999999999987, 202.39999999999935, 188.9999999999994, 86.6999999999999, 40.0000000000003, 58.00000000000048, 40.0000000000003, 40.0000000000003, 40.0000000000003, 59.40000000000016, -27.099999999999717, 40.0000000000003, 40.0000000000003, 35.600000000000236, 219.99999999999926, 112.19999999999933, 219.99999999999926, 236.19999999999936, 50.00000000000047, 224.49999999999923, 103.19999999999948, 32.30000000000018, 38.90000000000028, 367.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999652, 20.000000000000014, 139.7, 65.90000000000009, 128.89999999999998, 20.000000000000014, 79.99999999999997, 200.0, 20.000000000000014, 3.199999999999965, 104.59999999999998, 109.99999999999997, -88.00000000000065, 15.799999999999962, 39.79999999999998, 60.50000000000022, 11.300000000000022, 1.0999999999999617, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, -0.099999999999838, 20.000000000000014, -5.199999999999941, 20.000000000000014, 200.0, 11.599999999999964, 20.000000000000014, 68.59999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.89999999999998, 82.09999999999997, 20.000000000000014, 124.39999999999998, 200.0, 189.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 61.70000000000012, -1.0000000000000027, 1.0999999999999865, 20.000000000000014, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, 188.0, 22.700000000000053, -2.800000000000324, 176.0, 20.000000000000014, 150.5, 20.000000000000014, 1.09999999999996, 182.0, 100.70000000000009, 5.299999999999965, 127.09999999999954, -5.199999999999934, 20.000000000000014, 20.000000000000014, 61.70000000000012, 95.59999999999945, 164.0, 200.0, 20.000000000000014, 15.799999999999962, 1.0999999999999652, 20.000000000000014, 177.5, 20.000000000000014, 20.000000000000014, 72.2000000000001, 11.599999999999964, 17.899999999999988, 200.0, 43.40000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.5, 20.000000000000014, 167.0, 55.10000000000023, 100.09999999999937, 20.000000000000014, 200.0, 1.099999999999983, 182.0, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 132.49999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -3.0999999999999615, 1.09999999999996, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 133.39999999999998, -103.90000000000057, 20.000000000000014, 200.0, -282.3999999999987, 200.0, 19.40000000000001, 20.000000000000014, 20.000000000000014, -85.0000000000008, 126.19999999999999, 200.0, 13.699999999999964, 20.000000000000014, 11.599999999999964, 200.0, 146.89999999999998, 20.000000000000014, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, -139.6000000000007, 86.59999999999997, -101.80000000000068, 45.500000000000036, 20.000000000000014, -34.599999999999824, 5.299999999999965, 1.0999999999999635, 200.0, 200.0, 3.1999999999999615, 68.00000000000011, 200.0, -13.599999999999797, 149.0, 20.000000000000014, 3.1999999999999615, 75.49999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.400000000000162, 20.000000000000014, -108.10000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 200.0, 97.39999999999974, 6.799999999999967, 200.0, 20.000000000000014, 36.19999999999999, 200.0, 20.000000000000014, 26.000000000000114, 200.0, 24.50000000000008, 91.99999999999979, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 167.6], "policy_predator_policy_reward": [0.0, 9.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 56.0, 0.0, 33.0, 0.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 25.0, 0.0, 12.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 0.0, 4.0, 46.0, 23.0, 8.0, 5.0, 3.0, 0.0, 6.0, 9.0, 11.0, 17.0, 0.0, 12.0, 0.0, 0.0, 17.0, 10.0, 10.0, 2.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 6.0, 9.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 19.0, 38.0, 109.0, 1.0, 1.0, 0.0, 0.0, 49.0, 40.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 32.0, 58.0, 11.0, 0.0, 26.0, 0.0, 16.0, 0.0, 0.0, 8.0, 14.0, 6.0, 10.0, 10.0, 10.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4365032265782718, "mean_inference_ms": 3.9026076735025232, "mean_action_processing_ms": 0.6448974508856299, "mean_env_wait_ms": 0.4876767546184243, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008105754852294922, "StateBufferConnector_ms": 0.0038366317749023438, "ViewRequirementAgentConnector_ms": 0.1296290159225464}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -27.099999999999717, "episode_return_mean": 130.7689999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 393.62481011724503, "num_env_steps_trained_throughput_per_sec": 393.62481011724503, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 13034.982, "restore_workers_time_ms": 0.02, "training_step_time_ms": 13034.926, "sample_time_ms": 2120.054, "learn_time_ms": 10890.912, "learn_throughput": 367.279, "synch_weights_time_ms": 21.039}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "e57b0_00000", "date": "2024-08-13_00-30-17", "timestamp": 1723523417, "time_this_iter_s": 10.168239116668701, "time_total_s": 1188.8440911769867, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b152b160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1188.8440911769867, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 43.94666666666667, "ram_util_percent": 78.76666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9799992320004594, "cur_kl_coeff": 1.6294419765472407e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7391438247034787, "policy_loss": -0.0003925964647716788, "vf_loss": 3.739536420504252, "vf_explained_var": 0.2999700000677159, "kl": 0.0029825488103759163, "entropy": 0.46203506435982133, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8160740106203963, "cur_kl_coeff": 0.002502822875976563, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2954767581489351, "policy_loss": -0.0009826990211550047, "vf_loss": 0.2964373784454582, "vf_explained_var": -0.003527415776378894, "kl": 0.008821989513726954, "entropy": 0.7686327328757634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.099999999999717, "episode_reward_mean": 133.68799999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -282.3999999999987, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 109.0}, "policy_reward_mean": {"prey_policy": 60.82399999999998, "predator_policy": 6.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [83.69999999999911, 19.099999999999966, 219.99999999999926, 380.0, 40.0000000000003, 25.70000000000007, 211.9999999999993, 88.89999999999989, 208.99999999999932, 173.4999999999995, 198.09999999999937, 133.99999999999966, 133.89999999999887, 40.0000000000003, 184.29999999999941, 376.0, 37.80000000000027, 30.100000000000158, 197.49999999999937, 107.19999999999982, 34.50000000000022, 243.3999999999991, 40.0000000000003, 152.49999999999957, 206.99999999999932, 155.19999999999845, 219.99999999999926, 192.0999999999994, 29.000000000000128, 152.49999999999883, 40.0000000000003, 219.99999999999926, 178.89999999999947, 30.100000000000165, 219.99999999999926, 219.99999999999926, 333.4, -24.89999999999967, 64.60000000000005, 221.39999999999924, 40.0000000000003, 130.19999999999973, 216.69999999999928, 35.600000000000236, 346.9000000000001, 219.99999999999926, 213.9999999999993, 219.99999999999926, 24.000000000000064, 12.700000000000294, 11.39999999999992, 22.40000000000002, 400.0, 93.19999999999987, 202.39999999999935, 188.9999999999994, 86.6999999999999, 40.0000000000003, 58.00000000000048, 40.0000000000003, 40.0000000000003, 40.0000000000003, 59.40000000000016, -27.099999999999717, 40.0000000000003, 40.0000000000003, 35.600000000000236, 219.99999999999926, 112.19999999999933, 219.99999999999926, 236.19999999999936, 50.00000000000047, 224.49999999999923, 103.19999999999948, 32.30000000000018, 38.90000000000028, 367.6, 219.99999999999926, 219.99999999999926, 87.19999999999993, 57.10000000000052, 15.100000000000007, 105.9999999999998, 24.60000000000005, 40.0000000000003, 40.0000000000003, 244.29999999999941, 358.2, 215.9999999999993, 35.20000000000023, 199.99999999999935, 154.09999999999906, 226.29999999999922, 40.0000000000003, 199.99999999999937, 40.0000000000003, 139.89999999999876, 201.09999999999914, 185.19999999999945, 61.99999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 61.70000000000012, -1.0000000000000027, 1.0999999999999865, 20.000000000000014, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -7.299999999999891, 20.000000000000014, 188.0, 22.700000000000053, -2.800000000000324, 176.0, 20.000000000000014, 150.5, 20.000000000000014, 1.09999999999996, 182.0, 100.70000000000009, 5.299999999999965, 127.09999999999954, -5.199999999999934, 20.000000000000014, 20.000000000000014, 61.70000000000012, 95.59999999999945, 164.0, 200.0, 20.000000000000014, 15.799999999999962, 1.0999999999999652, 20.000000000000014, 177.5, 20.000000000000014, 20.000000000000014, 72.2000000000001, 11.599999999999964, 17.899999999999988, 200.0, 43.40000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.5, 20.000000000000014, 167.0, 55.10000000000023, 100.09999999999937, 20.000000000000014, 200.0, 1.099999999999983, 182.0, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 132.49999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -3.0999999999999615, 1.09999999999996, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 133.39999999999998, -103.90000000000057, 20.000000000000014, 200.0, -282.3999999999987, 200.0, 19.40000000000001, 20.000000000000014, 20.000000000000014, -85.0000000000008, 126.19999999999999, 200.0, 13.699999999999964, 20.000000000000014, 11.599999999999964, 200.0, 146.89999999999998, 20.000000000000014, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, -139.6000000000007, 86.59999999999997, -101.80000000000068, 45.500000000000036, 20.000000000000014, -34.599999999999824, 5.299999999999965, 1.0999999999999635, 200.0, 200.0, 3.1999999999999615, 68.00000000000011, 200.0, -13.599999999999797, 149.0, 20.000000000000014, 3.1999999999999615, 75.49999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.400000000000162, 20.000000000000014, -108.10000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 200.0, 97.39999999999974, 6.799999999999967, 200.0, 20.000000000000014, 36.19999999999999, 200.0, 20.000000000000014, 26.000000000000114, 200.0, 24.50000000000008, 91.99999999999979, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 167.6, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 74.89999999999996, 5.299999999999965, 37.10000000000026, 20.000000000000014, 1.0999999999999759, -0.9999999999999881, 29.90000000000018, 46.100000000000094, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.299999999999976, 200.0, 147.20000000000002, 200.0, 20.000000000000014, 194.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 170.0, 124.09999999999971, 20.000000000000014, 200.0, 26.300000000000114, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 82.99999999999926, 118.09999999999998, 13.699999999999964, 168.5, 91.99999999999997, -109.00000000000043], "policy_predator_policy_reward": [0.0, 2.0, 9.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 0.0, 4.0, 46.0, 23.0, 8.0, 5.0, 3.0, 0.0, 6.0, 9.0, 11.0, 17.0, 0.0, 12.0, 0.0, 0.0, 17.0, 10.0, 10.0, 2.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 6.0, 9.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 19.0, 38.0, 109.0, 1.0, 1.0, 0.0, 0.0, 49.0, 40.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 32.0, 58.0, 11.0, 0.0, 26.0, 0.0, 16.0, 0.0, 0.0, 8.0, 14.0, 6.0, 10.0, 10.0, 10.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 15.0, 0.0, 2.0, 28.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 2.0, 0.0, 4.0, 8.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 40.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4255977150152541, "mean_inference_ms": 3.8760604315994245, "mean_action_processing_ms": 0.6396051315797822, "mean_env_wait_ms": 0.4836558049514222, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008511900901794434, "StateBufferConnector_ms": 0.0037953853607177734, "ViewRequirementAgentConnector_ms": 0.11876630783081055}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -27.099999999999717, "episode_return_mean": 133.68799999999973, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.5650652379424, "num_env_steps_trained_throughput_per_sec": 355.5650652379424, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 12792.115, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12792.061, "sample_time_ms": 2042.545, "learn_time_ms": 10726.907, "learn_throughput": 372.894, "synch_weights_time_ms": 20.091}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "e57b0_00000", "date": "2024-08-13_00-30-28", "timestamp": 1723523428, "time_this_iter_s": 11.253798961639404, "time_total_s": 1200.097890138626, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b127f8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1200.097890138626, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 45.987500000000004, "ram_util_percent": 79.2875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.637078922048763, "cur_kl_coeff": 8.147209882736204e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.082041522687074, "policy_loss": -0.002603745233839151, "vf_loss": 5.084645265372342, "vf_explained_var": 0.2607935269673665, "kl": 0.004010768147940513, "entropy": 0.4169177778025784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6991363004953773, "cur_kl_coeff": 0.002502822875976563, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8038706973273918, "policy_loss": -0.0019136630735365015, "vf_loss": 0.8057465829152278, "vf_explained_var": 0.0037866394986551277, "kl": 0.015093076702670034, "entropy": 0.6763634713238509, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.099999999999717, "episode_reward_mean": 134.38099999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -282.3999999999987, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 109.0}, "policy_reward_mean": {"prey_policy": 59.850499999999975, "predator_policy": 7.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [197.49999999999937, 107.19999999999982, 34.50000000000022, 243.3999999999991, 40.0000000000003, 152.49999999999957, 206.99999999999932, 155.19999999999845, 219.99999999999926, 192.0999999999994, 29.000000000000128, 152.49999999999883, 40.0000000000003, 219.99999999999926, 178.89999999999947, 30.100000000000165, 219.99999999999926, 219.99999999999926, 333.4, -24.89999999999967, 64.60000000000005, 221.39999999999924, 40.0000000000003, 130.19999999999973, 216.69999999999928, 35.600000000000236, 346.9000000000001, 219.99999999999926, 213.9999999999993, 219.99999999999926, 24.000000000000064, 12.700000000000294, 11.39999999999992, 22.40000000000002, 400.0, 93.19999999999987, 202.39999999999935, 188.9999999999994, 86.6999999999999, 40.0000000000003, 58.00000000000048, 40.0000000000003, 40.0000000000003, 40.0000000000003, 59.40000000000016, -27.099999999999717, 40.0000000000003, 40.0000000000003, 35.600000000000236, 219.99999999999926, 112.19999999999933, 219.99999999999926, 236.19999999999936, 50.00000000000047, 224.49999999999923, 103.19999999999948, 32.30000000000018, 38.90000000000028, 367.6, 219.99999999999926, 219.99999999999926, 87.19999999999993, 57.10000000000052, 15.100000000000007, 105.9999999999998, 24.60000000000005, 40.0000000000003, 40.0000000000003, 244.29999999999941, 358.2, 215.9999999999993, 35.20000000000023, 199.99999999999935, 154.09999999999906, 226.29999999999922, 40.0000000000003, 199.99999999999937, 40.0000000000003, 139.89999999999876, 201.09999999999914, 185.19999999999945, 61.99999999999976, 40.0000000000003, 189.19999999999987, 261.39999999999924, 0.4000000000001077, 236.19999999999914, 80.5000000000002, 40.0000000000003, 199.99999999999935, 170.4999999999995, 83.19999999999914, 213.3999999999993, 33.90000000000009, 236.59999999999965, 82.29999999999995, 219.99999999999926, 288.9, 217.29999999999956, 61.600000000000506], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [177.5, 20.000000000000014, 20.000000000000014, 72.2000000000001, 11.599999999999964, 17.899999999999988, 200.0, 43.40000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 132.5, 20.000000000000014, 167.0, 55.10000000000023, 100.09999999999937, 20.000000000000014, 200.0, 1.099999999999983, 182.0, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 132.49999999999957, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 170.0, -3.0999999999999615, 1.09999999999996, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 133.39999999999998, -103.90000000000057, 20.000000000000014, 200.0, -282.3999999999987, 200.0, 19.40000000000001, 20.000000000000014, 20.000000000000014, -85.0000000000008, 126.19999999999999, 200.0, 13.699999999999964, 20.000000000000014, 11.599999999999964, 200.0, 146.89999999999998, 20.000000000000014, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, -139.6000000000007, 86.59999999999997, -101.80000000000068, 45.500000000000036, 20.000000000000014, -34.599999999999824, 5.299999999999965, 1.0999999999999635, 200.0, 200.0, 3.1999999999999615, 68.00000000000011, 200.0, -13.599999999999797, 149.0, 20.000000000000014, 3.1999999999999615, 75.49999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.400000000000162, 20.000000000000014, -108.10000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 200.0, 97.39999999999974, 6.799999999999967, 200.0, 20.000000000000014, 36.19999999999999, 200.0, 20.000000000000014, 26.000000000000114, 200.0, 24.50000000000008, 91.99999999999979, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 167.6, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 74.89999999999996, 5.299999999999965, 37.10000000000026, 20.000000000000014, 1.0999999999999759, -0.9999999999999881, 29.90000000000018, 46.100000000000094, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.299999999999976, 200.0, 147.20000000000002, 200.0, 20.000000000000014, 194.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 170.0, 124.09999999999971, 20.000000000000014, 200.0, 26.300000000000114, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 82.99999999999926, 118.09999999999998, 13.699999999999964, 168.5, 91.99999999999997, -109.00000000000043, 20.000000000000014, 20.000000000000014, -74.80000000000035, 200.0, 61.40000000000022, 200.0, -55.60000000000015, 20.000000000000014, 36.20000000000026, 200.0, -45.10000000000019, 29.599999999999994, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 150.5, 20.000000000000014, 28.100000000000147, 55.10000000000023, 7.399999999999972, 200.0, 20.000000000000014, -117.10000000000042, 195.5, 1.100000000000172, 20.000000000000014, 53.29999999999998, 200.0, 20.000000000000014, 68.90000000000012, 200.0, 200.0, -72.70000000000064, 20.000000000000014, 41.60000000000025], "policy_predator_policy_reward": [0.0, 0.0, 6.0, 9.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 19.0, 38.0, 109.0, 1.0, 1.0, 0.0, 0.0, 49.0, 40.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 32.0, 58.0, 11.0, 0.0, 26.0, 0.0, 16.0, 0.0, 0.0, 8.0, 14.0, 6.0, 10.0, 10.0, 10.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 15.0, 0.0, 2.0, 28.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 2.0, 0.0, 4.0, 8.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 42.0, 54.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 67.0, 64.0, 30.0, 10.0, 0.0, 9.0, 0.0, 0.0, 2.0, 18.0, 54.0, 36.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.414561759643961, "mean_inference_ms": 3.8496531998354624, "mean_action_processing_ms": 0.6342546068039562, "mean_env_wait_ms": 0.4795744715495448, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007465720176696777, "StateBufferConnector_ms": 0.003409147262573242, "ViewRequirementAgentConnector_ms": 0.10690593719482422}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -27.099999999999717, "episode_return_mean": 134.38099999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.08688271385006, "num_env_steps_trained_throughput_per_sec": 320.08688271385006, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 12490.484, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12490.414, "sample_time_ms": 2010.879, "learn_time_ms": 10459.67, "learn_throughput": 382.421, "synch_weights_time_ms": 17.75}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "e57b0_00000", "date": "2024-08-13_00-30-41", "timestamp": 1723523441, "time_this_iter_s": 12.560456991195679, "time_total_s": 1212.6583471298218, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09cfc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1212.6583471298218, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 54.172222222222224, "ram_util_percent": 78.93333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6178480037857614, "cur_kl_coeff": 4.073604941368102e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4847645096047213, "policy_loss": -0.0007915102733821465, "vf_loss": 3.4855560148834552, "vf_explained_var": 0.3164388702029274, "kl": 0.003397094430272499, "entropy": 0.4349024799134996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3302231028262112, "cur_kl_coeff": 0.002502822875976563, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1496841763746161, "policy_loss": -0.0020242077478320984, "vf_loss": 0.15167006028127544, "vf_explained_var": -0.08905778814245154, "kl": 0.015312406666508993, "entropy": 0.5455087844499205, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.099999999999717, "episode_reward_mean": 130.3459999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -282.3999999999987, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 109.0}, "policy_reward_mean": {"prey_policy": 58.10299999999997, "predator_policy": 7.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [333.4, -24.89999999999967, 64.60000000000005, 221.39999999999924, 40.0000000000003, 130.19999999999973, 216.69999999999928, 35.600000000000236, 346.9000000000001, 219.99999999999926, 213.9999999999993, 219.99999999999926, 24.000000000000064, 12.700000000000294, 11.39999999999992, 22.40000000000002, 400.0, 93.19999999999987, 202.39999999999935, 188.9999999999994, 86.6999999999999, 40.0000000000003, 58.00000000000048, 40.0000000000003, 40.0000000000003, 40.0000000000003, 59.40000000000016, -27.099999999999717, 40.0000000000003, 40.0000000000003, 35.600000000000236, 219.99999999999926, 112.19999999999933, 219.99999999999926, 236.19999999999936, 50.00000000000047, 224.49999999999923, 103.19999999999948, 32.30000000000018, 38.90000000000028, 367.6, 219.99999999999926, 219.99999999999926, 87.19999999999993, 57.10000000000052, 15.100000000000007, 105.9999999999998, 24.60000000000005, 40.0000000000003, 40.0000000000003, 244.29999999999941, 358.2, 215.9999999999993, 35.20000000000023, 199.99999999999935, 154.09999999999906, 226.29999999999922, 40.0000000000003, 199.99999999999937, 40.0000000000003, 139.89999999999876, 201.09999999999914, 185.19999999999945, 61.99999999999976, 40.0000000000003, 189.19999999999987, 261.39999999999924, 0.4000000000001077, 236.19999999999914, 80.5000000000002, 40.0000000000003, 199.99999999999935, 170.4999999999995, 83.19999999999914, 213.3999999999993, 33.90000000000009, 236.59999999999965, 82.29999999999995, 219.99999999999926, 288.9, 217.29999999999956, 61.600000000000506, 40.0000000000003, 34.60000000000022, 37.80000000000026, 40.0000000000003, 123.49999999999866, 297.5000000000005, 118.69999999999975, 273.9999999999996, 119.19999999999877, 82.29999999999917, 30.100000000000147, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 219.99999999999926, 49.900000000000475, 68.80000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 133.39999999999998, -103.90000000000057, 20.000000000000014, 200.0, -282.3999999999987, 200.0, 19.40000000000001, 20.000000000000014, 20.000000000000014, -85.0000000000008, 126.19999999999999, 200.0, 13.699999999999964, 20.000000000000014, 11.599999999999964, 200.0, 146.89999999999998, 20.000000000000014, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, -139.6000000000007, 86.59999999999997, -101.80000000000068, 45.500000000000036, 20.000000000000014, -34.599999999999824, 5.299999999999965, 1.0999999999999635, 200.0, 200.0, 3.1999999999999615, 68.00000000000011, 200.0, -13.599999999999797, 149.0, 20.000000000000014, 3.1999999999999615, 75.49999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.400000000000162, 20.000000000000014, -108.10000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 200.0, 97.39999999999974, 6.799999999999967, 200.0, 20.000000000000014, 36.19999999999999, 200.0, 20.000000000000014, 26.000000000000114, 200.0, 24.50000000000008, 91.99999999999979, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 167.6, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 74.89999999999996, 5.299999999999965, 37.10000000000026, 20.000000000000014, 1.0999999999999759, -0.9999999999999881, 29.90000000000018, 46.100000000000094, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.299999999999976, 200.0, 147.20000000000002, 200.0, 20.000000000000014, 194.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 170.0, 124.09999999999971, 20.000000000000014, 200.0, 26.300000000000114, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 82.99999999999926, 118.09999999999998, 13.699999999999964, 168.5, 91.99999999999997, -109.00000000000043, 20.000000000000014, 20.000000000000014, -74.80000000000035, 200.0, 61.40000000000022, 200.0, -55.60000000000015, 20.000000000000014, 36.20000000000026, 200.0, -45.10000000000019, 29.599999999999994, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 150.5, 20.000000000000014, 28.100000000000147, 55.10000000000023, 7.399999999999972, 200.0, 20.000000000000014, -117.10000000000042, 195.5, 1.100000000000172, 20.000000000000014, 53.29999999999998, 200.0, 20.000000000000014, 68.90000000000012, 200.0, 200.0, -72.70000000000064, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 17.899999999999988, 104.5999999999994, 200.0, 93.49999999999943, 91.69999999999996, 20.000000000000014, 73.99999999999997, 200.0, 70.39999999999975, 48.79999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.900000000000187, 20.000000000000014, 20.000000000000014, 48.79999999999997], "policy_predator_policy_reward": [0.0, 0.0, 40.0, 19.0, 38.0, 109.0, 1.0, 1.0, 0.0, 0.0, 49.0, 40.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 32.0, 58.0, 11.0, 0.0, 26.0, 0.0, 16.0, 0.0, 0.0, 8.0, 14.0, 6.0, 10.0, 10.0, 10.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 15.0, 0.0, 2.0, 28.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 2.0, 0.0, 4.0, 8.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 42.0, 54.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 67.0, 64.0, 30.0, 10.0, 0.0, 9.0, 0.0, 0.0, 2.0, 18.0, 54.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.40548507468298, "mean_inference_ms": 3.828025252083329, "mean_action_processing_ms": 0.6298079349946962, "mean_env_wait_ms": 0.47622813970704414, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007001042366027832, "StateBufferConnector_ms": 0.0035049915313720703, "ViewRequirementAgentConnector_ms": 0.11294698715209961}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -27.099999999999717, "episode_return_mean": 130.3459999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.38090661566105, "num_env_steps_trained_throughput_per_sec": 356.38090661566105, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 12301.27, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12301.201, "sample_time_ms": 1921.882, "learn_time_ms": 10359.541, "learn_throughput": 386.117, "synch_weights_time_ms": 17.702}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "e57b0_00000", "date": "2024-08-13_00-30-52", "timestamp": 1723523452, "time_this_iter_s": 11.229414224624634, "time_total_s": 1223.8877613544464, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09cfca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1223.8877613544464, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 45.7, "ram_util_percent": 78.86875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2844032659338267, "cur_kl_coeff": 2.036802470684051e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5137960903228276, "policy_loss": -0.0019893094857849143, "vf_loss": 3.515785400829618, "vf_explained_var": 0.2987968100126458, "kl": 0.004147824289289356, "entropy": 0.36787368150615185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.20379678782065788, "cur_kl_coeff": 0.002502822875976563, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.12367762696372453, "policy_loss": -0.0006525433563169033, "vf_loss": 0.12430634177305303, "vf_explained_var": -0.06390685704019335, "kl": 0.00952067263460492, "entropy": 0.43356541563909523, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 367.6, "episode_reward_min": -27.099999999999717, "episode_reward_mean": 125.89099999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -117.10000000000042, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 67.0}, "policy_reward_mean": {"prey_policy": 58.03549999999998, "predator_policy": 4.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.00000000000048, 40.0000000000003, 40.0000000000003, 40.0000000000003, 59.40000000000016, -27.099999999999717, 40.0000000000003, 40.0000000000003, 35.600000000000236, 219.99999999999926, 112.19999999999933, 219.99999999999926, 236.19999999999936, 50.00000000000047, 224.49999999999923, 103.19999999999948, 32.30000000000018, 38.90000000000028, 367.6, 219.99999999999926, 219.99999999999926, 87.19999999999993, 57.10000000000052, 15.100000000000007, 105.9999999999998, 24.60000000000005, 40.0000000000003, 40.0000000000003, 244.29999999999941, 358.2, 215.9999999999993, 35.20000000000023, 199.99999999999935, 154.09999999999906, 226.29999999999922, 40.0000000000003, 199.99999999999937, 40.0000000000003, 139.89999999999876, 201.09999999999914, 185.19999999999945, 61.99999999999976, 40.0000000000003, 189.19999999999987, 261.39999999999924, 0.4000000000001077, 236.19999999999914, 80.5000000000002, 40.0000000000003, 199.99999999999935, 170.4999999999995, 83.19999999999914, 213.3999999999993, 33.90000000000009, 236.59999999999965, 82.29999999999995, 219.99999999999926, 288.9, 217.29999999999956, 61.600000000000506, 40.0000000000003, 34.60000000000022, 37.80000000000026, 40.0000000000003, 123.49999999999866, 297.5000000000005, 118.69999999999975, 273.9999999999996, 119.19999999999877, 82.29999999999917, 30.100000000000147, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 219.99999999999926, 49.900000000000475, 68.80000000000022, 203.09999999999934, 219.99999999999926, 181.09999999999914, 14.300000000000114, 219.99999999999926, 93.10000000000002, 36.70000000000025, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 281.2000000000023, 40.0000000000003, 30.100000000000147, 113.19999999999982, 210.0999999999993, 40.0000000000003, 43.60000000000036, 40.0000000000003, 164.19999999999996, 163.49999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 38.00000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.400000000000162, 20.000000000000014, -108.10000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 200.0, 97.39999999999974, 6.799999999999967, 200.0, 20.000000000000014, 36.19999999999999, 200.0, 20.000000000000014, 26.000000000000114, 200.0, 24.50000000000008, 91.99999999999979, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 17.899999999999988, 20.000000000000014, 200.0, 167.6, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 74.89999999999996, 5.299999999999965, 37.10000000000026, 20.000000000000014, 1.0999999999999759, -0.9999999999999881, 29.90000000000018, 46.100000000000094, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.299999999999976, 200.0, 147.20000000000002, 200.0, 20.000000000000014, 194.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 170.0, 124.09999999999971, 20.000000000000014, 200.0, 26.300000000000114, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 82.99999999999926, 118.09999999999998, 13.699999999999964, 168.5, 91.99999999999997, -109.00000000000043, 20.000000000000014, 20.000000000000014, -74.80000000000035, 200.0, 61.40000000000022, 200.0, -55.60000000000015, 20.000000000000014, 36.20000000000026, 200.0, -45.10000000000019, 29.599999999999994, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 150.5, 20.000000000000014, 28.100000000000147, 55.10000000000023, 7.399999999999972, 200.0, 20.000000000000014, -117.10000000000042, 195.5, 1.100000000000172, 20.000000000000014, 53.29999999999998, 200.0, 20.000000000000014, 68.90000000000012, 200.0, 200.0, -72.70000000000064, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 17.899999999999988, 104.5999999999994, 200.0, 93.49999999999943, 91.69999999999996, 20.000000000000014, 73.99999999999997, 200.0, 70.39999999999975, 48.79999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.900000000000187, 20.000000000000014, 20.000000000000014, 48.79999999999997, 3.199999999999967, 191.9, 200.0, 20.000000000000014, -0.9999999999999881, 172.09999999999982, 13.699999999999964, -51.40000000000001, 200.0, 20.000000000000014, 73.09999999999997, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 157.69999999999973, 123.49999999999952, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, 90.19999999999999, 20.000000000000014, 1.0999999999999688, 200.0, 20.000000000000014, 20.000000000000014, 21.80000000000004, 15.799999999999963, 20.000000000000014, 20.000000000000014, 88.39999999999998, 66.79999999999998, 125.60000000000005, 17.899999999999988], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 15.0, 0.0, 2.0, 28.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 2.0, 0.0, 4.0, 8.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 42.0, 54.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 67.0, 64.0, 30.0, 10.0, 0.0, 9.0, 0.0, 0.0, 2.0, 18.0, 54.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 49.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 11.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3964360062786936, "mean_inference_ms": 3.800362419485347, "mean_action_processing_ms": 0.6245863191820968, "mean_env_wait_ms": 0.47284608027092984, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006596565246582031, "StateBufferConnector_ms": 0.003462553024291992, "ViewRequirementAgentConnector_ms": 0.11363697052001953}, "num_episodes": 22, "episode_return_max": 367.6, "episode_return_min": -27.099999999999717, "episode_return_mean": 125.89099999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.99250129620503, "num_env_steps_trained_throughput_per_sec": 317.99250129620503, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 12111.629, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12111.56, "sample_time_ms": 1869.621, "learn_time_ms": 10223.379, "learn_throughput": 391.26, "synch_weights_time_ms": 16.955}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "e57b0_00000", "date": "2024-08-13_00-31-05", "timestamp": 1723523465, "time_this_iter_s": 12.753421068191528, "time_total_s": 1236.641182422638, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0db5700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1236.641182422638, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 51.45555555555555, "ram_util_percent": 79.19444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.421546430223518, "cur_kl_coeff": 1.0184012353420254e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.066798491957327, "policy_loss": -0.0006105553112411625, "vf_loss": 4.0674090438418915, "vf_explained_var": 0.2675161491626154, "kl": 0.0030107377932740882, "entropy": 0.3269696159179879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5408713262725287, "cur_kl_coeff": 0.002502822875976563, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.32771140669704113, "policy_loss": -0.000477871880989778, "vf_loss": 0.3281739101128002, "vf_explained_var": 0.00906472783240061, "kl": 0.006140290966520507, "entropy": 0.4476845393735896, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 0.4000000000001077, "episode_reward_mean": 135.2049999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -117.10000000000042, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 67.0}, "policy_reward_mean": {"prey_policy": 62.41249999999998, "predator_policy": 5.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [367.6, 219.99999999999926, 219.99999999999926, 87.19999999999993, 57.10000000000052, 15.100000000000007, 105.9999999999998, 24.60000000000005, 40.0000000000003, 40.0000000000003, 244.29999999999941, 358.2, 215.9999999999993, 35.20000000000023, 199.99999999999935, 154.09999999999906, 226.29999999999922, 40.0000000000003, 199.99999999999937, 40.0000000000003, 139.89999999999876, 201.09999999999914, 185.19999999999945, 61.99999999999976, 40.0000000000003, 189.19999999999987, 261.39999999999924, 0.4000000000001077, 236.19999999999914, 80.5000000000002, 40.0000000000003, 199.99999999999935, 170.4999999999995, 83.19999999999914, 213.3999999999993, 33.90000000000009, 236.59999999999965, 82.29999999999995, 219.99999999999926, 288.9, 217.29999999999956, 61.600000000000506, 40.0000000000003, 34.60000000000022, 37.80000000000026, 40.0000000000003, 123.49999999999866, 297.5000000000005, 118.69999999999975, 273.9999999999996, 119.19999999999877, 82.29999999999917, 30.100000000000147, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 219.99999999999926, 49.900000000000475, 68.80000000000022, 203.09999999999934, 219.99999999999926, 181.09999999999914, 14.300000000000114, 219.99999999999926, 93.10000000000002, 36.70000000000025, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 281.2000000000023, 40.0000000000003, 30.100000000000147, 113.19999999999982, 210.0999999999993, 40.0000000000003, 43.60000000000036, 40.0000000000003, 164.19999999999996, 163.49999999999952, 146.09999999999962, 19.09999999999996, 156.99999999999955, 214.4999999999993, 400.0, 199.99999999999935, 74.60000000000011, 138.59999999999965, 147.0999999999991, 75.90000000000009, 40.0000000000003, 40.0000000000003, 380.0, 40.0000000000003, 134.4999999999997, 64.10000000000008, 183.09999999999883, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 167.6, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 74.89999999999996, 5.299999999999965, 37.10000000000026, 20.000000000000014, 1.0999999999999759, -0.9999999999999881, 29.90000000000018, 46.100000000000094, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 44.299999999999976, 200.0, 147.20000000000002, 200.0, 20.000000000000014, 194.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 170.0, 124.09999999999971, 20.000000000000014, 200.0, 26.300000000000114, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 82.99999999999926, 118.09999999999998, 13.699999999999964, 168.5, 91.99999999999997, -109.00000000000043, 20.000000000000014, 20.000000000000014, -74.80000000000035, 200.0, 61.40000000000022, 200.0, -55.60000000000015, 20.000000000000014, 36.20000000000026, 200.0, -45.10000000000019, 29.599999999999994, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 150.5, 20.000000000000014, 28.100000000000147, 55.10000000000023, 7.399999999999972, 200.0, 20.000000000000014, -117.10000000000042, 195.5, 1.100000000000172, 20.000000000000014, 53.29999999999998, 200.0, 20.000000000000014, 68.90000000000012, 200.0, 200.0, -72.70000000000064, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 17.899999999999988, 104.5999999999994, 200.0, 93.49999999999943, 91.69999999999996, 20.000000000000014, 73.99999999999997, 200.0, 70.39999999999975, 48.79999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.900000000000187, 20.000000000000014, 20.000000000000014, 48.79999999999997, 3.199999999999967, 191.9, 200.0, 20.000000000000014, -0.9999999999999881, 172.09999999999982, 13.699999999999964, -51.40000000000001, 200.0, 20.000000000000014, 73.09999999999997, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 157.69999999999973, 123.49999999999952, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, 90.19999999999999, 20.000000000000014, 1.0999999999999688, 200.0, 20.000000000000014, 20.000000000000014, 21.80000000000004, 15.799999999999963, 20.000000000000014, 20.000000000000014, 88.39999999999998, 66.79999999999998, 125.60000000000005, 17.899999999999988, 170.0, -82.90000000000074, -19.899999999999743, 20.000000000000014, 137.0, 20.000000000000014, 200.0, 9.499999999999964, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 23.600000000000122, 5.299999999999965, 122.29999999999998, 125.89999999999972, 3.199999999999965, 9.499999999999964, 61.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 114.49999999999999, 20.000000000000014, 20.000000000000014, 34.10000000000001, 149.59999999999968, 33.50000000000024, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 15.0, 0.0, 2.0, 28.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 2.0, 0.0, 4.0, 8.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 42.0, 54.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 67.0, 64.0, 30.0, 10.0, 0.0, 9.0, 0.0, 0.0, 2.0, 18.0, 54.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 49.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 11.0, 9.0, 10.0, 49.0, 9.0, 10.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 30.0, 1.0, 7.0, 4.0, 10.0, 8.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3875697729769618, "mean_inference_ms": 3.7859873591117967, "mean_action_processing_ms": 0.6208734625525034, "mean_env_wait_ms": 0.4696318453209781, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054776668548583984, "StateBufferConnector_ms": 0.003638625144958496, "ViewRequirementAgentConnector_ms": 0.12843239307403564}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 0.4000000000001077, "episode_return_mean": 135.2049999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.16702349312146, "num_env_steps_trained_throughput_per_sec": 324.16702349312146, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 11902.525, "restore_workers_time_ms": 0.019, "training_step_time_ms": 11902.458, "sample_time_ms": 1782.155, "learn_time_ms": 10104.247, "learn_throughput": 395.873, "synch_weights_time_ms": 14.494}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "e57b0_00000", "date": "2024-08-13_00-31-17", "timestamp": 1723523477, "time_this_iter_s": 12.347396850585938, "time_total_s": 1248.9885792732239, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b5c670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1248.9885792732239, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 52.55294117647059, "ram_util_percent": 79.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.21251214507711, "cur_kl_coeff": 5.092006176710127e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9887516912329133, "policy_loss": -0.000447074420966957, "vf_loss": 3.9891987669404854, "vf_explained_var": 0.14879634001898387, "kl": 0.0014991048887185725, "entropy": 0.36856830304577237, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.647211522630677, "cur_kl_coeff": 0.002502822875976563, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8010391028627517, "policy_loss": -0.001298205299726712, "vf_loss": 0.8023210774890329, "vf_explained_var": 0.0015297488245383773, "kl": 0.006485395337005718, "entropy": 0.5216875406642439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -63.400000000000986, "episode_reward_mean": 129.8329999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 58.07149999999998, "predator_policy": 6.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [61.99999999999976, 40.0000000000003, 189.19999999999987, 261.39999999999924, 0.4000000000001077, 236.19999999999914, 80.5000000000002, 40.0000000000003, 199.99999999999935, 170.4999999999995, 83.19999999999914, 213.3999999999993, 33.90000000000009, 236.59999999999965, 82.29999999999995, 219.99999999999926, 288.9, 217.29999999999956, 61.600000000000506, 40.0000000000003, 34.60000000000022, 37.80000000000026, 40.0000000000003, 123.49999999999866, 297.5000000000005, 118.69999999999975, 273.9999999999996, 119.19999999999877, 82.29999999999917, 30.100000000000147, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 219.99999999999926, 49.900000000000475, 68.80000000000022, 203.09999999999934, 219.99999999999926, 181.09999999999914, 14.300000000000114, 219.99999999999926, 93.10000000000002, 36.70000000000025, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 281.2000000000023, 40.0000000000003, 30.100000000000147, 113.19999999999982, 210.0999999999993, 40.0000000000003, 43.60000000000036, 40.0000000000003, 164.19999999999996, 163.49999999999952, 146.09999999999962, 19.09999999999996, 156.99999999999955, 214.4999999999993, 400.0, 199.99999999999935, 74.60000000000011, 138.59999999999965, 147.0999999999991, 75.90000000000009, 40.0000000000003, 40.0000000000003, 380.0, 40.0000000000003, 134.4999999999997, 64.10000000000008, 183.09999999999883, 40.0000000000003, 317.0000000000001, 128.6999999999997, 40.0000000000003, 157.89999999999918, 33.400000000000205, 34.50000000000022, 30.100000000000147, 40.0000000000003, 240.6999999999994, 69.70000000000022, 211.9999999999993, 35.600000000000236, 40.0000000000003, 294.50000000000045, 216.69999999999928, 235.99999999999937, 199.99999999999935, 94.09999999999876, 219.99999999999926, -63.400000000000986, 198.99999999999935, 136.29999999999967, -32.099999999999795], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [91.99999999999997, -109.00000000000043, 20.000000000000014, 20.000000000000014, -74.80000000000035, 200.0, 61.40000000000022, 200.0, -55.60000000000015, 20.000000000000014, 36.20000000000026, 200.0, -45.10000000000019, 29.599999999999994, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 150.5, 20.000000000000014, 28.100000000000147, 55.10000000000023, 7.399999999999972, 200.0, 20.000000000000014, -117.10000000000042, 195.5, 1.100000000000172, 20.000000000000014, 53.29999999999998, 200.0, 20.000000000000014, 68.90000000000012, 200.0, 200.0, -72.70000000000064, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 17.899999999999988, 104.5999999999994, 200.0, 93.49999999999943, 91.69999999999996, 20.000000000000014, 73.99999999999997, 200.0, 70.39999999999975, 48.79999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.900000000000187, 20.000000000000014, 20.000000000000014, 48.79999999999997, 3.199999999999967, 191.9, 200.0, 20.000000000000014, -0.9999999999999881, 172.09999999999982, 13.699999999999964, -51.40000000000001, 200.0, 20.000000000000014, 73.09999999999997, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 157.69999999999973, 123.49999999999952, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, 90.19999999999999, 20.000000000000014, 1.0999999999999688, 200.0, 20.000000000000014, 20.000000000000014, 21.80000000000004, 15.799999999999963, 20.000000000000014, 20.000000000000014, 88.39999999999998, 66.79999999999998, 125.60000000000005, 17.899999999999988, 170.0, -82.90000000000074, -19.899999999999743, 20.000000000000014, 137.0, 20.000000000000014, 200.0, 9.499999999999964, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 23.600000000000122, 5.299999999999965, 122.29999999999998, 125.89999999999972, 3.199999999999965, 9.499999999999964, 61.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 114.49999999999999, 20.000000000000014, 20.000000000000014, 34.10000000000001, 149.59999999999968, 33.50000000000024, 20.000000000000014, 20.000000000000014, 200.0, 106.99999999999997, 20.000000000000014, 97.70000000000007, 20.000000000000014, 20.000000000000014, 136.6999999999998, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 9.499999999999964, 20.000000000000014, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 40.70000000000012, 49.69999999999997, 20.000000000000014, 182.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999946, 170.0, 13.699999999999964, 200.0, 37.999999999999986, 197.0, 20.000000000000014, 170.0, -21.999999999999815, 94.09999999999937, 200.0, 20.000000000000014, 20.000000000000014, -177.4000000000005, 161.0, 20.000000000000014, 116.29999999999998, 20.000000000000014, -276.09999999999957, 20.000000000000014], "policy_predator_policy_reward": [40.0, 39.0, 0.0, 0.0, 0.0, 64.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 42.0, 54.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 67.0, 64.0, 30.0, 10.0, 0.0, 9.0, 0.0, 0.0, 2.0, 18.0, 54.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 49.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 11.0, 9.0, 10.0, 49.0, 9.0, 10.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 30.0, 1.0, 7.0, 4.0, 10.0, 8.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 0.0, 1.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 94.0, 0.0, 8.0, 10.0, 0.0, 0.0, 141.0, 83.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.378613772303912, "mean_inference_ms": 3.7652724876473602, "mean_action_processing_ms": 0.6162025589251628, "mean_env_wait_ms": 0.4662211298072204, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004966616630554199, "StateBufferConnector_ms": 0.004011988639831543, "ViewRequirementAgentConnector_ms": 0.14784669876098633}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -63.400000000000986, "episode_return_mean": 129.8329999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 288.78499319194316, "num_env_steps_trained_throughput_per_sec": 288.78499319194316, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 11812.131, "restore_workers_time_ms": 0.019, "training_step_time_ms": 11812.064, "sample_time_ms": 1695.561, "learn_time_ms": 10100.676, "learn_throughput": 396.013, "synch_weights_time_ms": 14.434}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "e57b0_00000", "date": "2024-08-13_00-31-31", "timestamp": 1723523491, "time_this_iter_s": 13.92422604560852, "time_total_s": 1262.9128053188324, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b155c3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1262.9128053188324, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 68.19, "ram_util_percent": 81.195}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3725673795258873, "cur_kl_coeff": 2.5460030883550636e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.760027301248419, "policy_loss": -0.0004576969334964084, "vf_loss": 3.7604849961699633, "vf_explained_var": 0.21246091111627205, "kl": 0.0023150333022838956, "entropy": 0.3957307531562432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4245787557032176, "cur_kl_coeff": 0.002502822875976563, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.47446906293037705, "policy_loss": -0.00045130633670225663, "vf_loss": 0.4749098091903506, "vf_explained_var": 0.002288839899042927, "kl": 0.004218564084779873, "entropy": 0.4754298849869027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -63.400000000000986, "episode_reward_mean": 122.14599999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 56.04799999999997, "predator_policy": 5.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [61.600000000000506, 40.0000000000003, 34.60000000000022, 37.80000000000026, 40.0000000000003, 123.49999999999866, 297.5000000000005, 118.69999999999975, 273.9999999999996, 119.19999999999877, 82.29999999999917, 30.100000000000147, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 219.99999999999926, 49.900000000000475, 68.80000000000022, 203.09999999999934, 219.99999999999926, 181.09999999999914, 14.300000000000114, 219.99999999999926, 93.10000000000002, 36.70000000000025, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 281.2000000000023, 40.0000000000003, 30.100000000000147, 113.19999999999982, 210.0999999999993, 40.0000000000003, 43.60000000000036, 40.0000000000003, 164.19999999999996, 163.49999999999952, 146.09999999999962, 19.09999999999996, 156.99999999999955, 214.4999999999993, 400.0, 199.99999999999935, 74.60000000000011, 138.59999999999965, 147.0999999999991, 75.90000000000009, 40.0000000000003, 40.0000000000003, 380.0, 40.0000000000003, 134.4999999999997, 64.10000000000008, 183.09999999999883, 40.0000000000003, 317.0000000000001, 128.6999999999997, 40.0000000000003, 157.89999999999918, 33.400000000000205, 34.50000000000022, 30.100000000000147, 40.0000000000003, 240.6999999999994, 69.70000000000022, 211.9999999999993, 35.600000000000236, 40.0000000000003, 294.50000000000045, 216.69999999999928, 235.99999999999937, 199.99999999999935, 94.09999999999876, 219.99999999999926, -63.400000000000986, 198.99999999999935, 136.29999999999967, -32.099999999999795, 139.89999999999876, 40.0000000000003, 32.60000000000012, 135.5999999999997, 197.99999999999937, 171.4000000000001, 198.19999999999936, 30.10000000000015, 35.600000000000236, 40.0000000000003, 207.99999999999932, 219.99999999999926, 40.0000000000003, 85.00000000000009, 219.99999999999926, -20.499999999999574, 73.20000000000024, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 13.699999999999964, 17.899999999999988, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.000000000000014, 17.899999999999988, 104.5999999999994, 200.0, 93.49999999999943, 91.69999999999996, 20.000000000000014, 73.99999999999997, 200.0, 70.39999999999975, 48.79999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 29.900000000000187, 20.000000000000014, 20.000000000000014, 48.79999999999997, 3.199999999999967, 191.9, 200.0, 20.000000000000014, -0.9999999999999881, 172.09999999999982, 13.699999999999964, -51.40000000000001, 200.0, 20.000000000000014, 73.09999999999997, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 157.69999999999973, 123.49999999999952, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, 90.19999999999999, 20.000000000000014, 1.0999999999999688, 200.0, 20.000000000000014, 20.000000000000014, 21.80000000000004, 15.799999999999963, 20.000000000000014, 20.000000000000014, 88.39999999999998, 66.79999999999998, 125.60000000000005, 17.899999999999988, 170.0, -82.90000000000074, -19.899999999999743, 20.000000000000014, 137.0, 20.000000000000014, 200.0, 9.499999999999964, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 23.600000000000122, 5.299999999999965, 122.29999999999998, 125.89999999999972, 3.199999999999965, 9.499999999999964, 61.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 114.49999999999999, 20.000000000000014, 20.000000000000014, 34.10000000000001, 149.59999999999968, 33.50000000000024, 20.000000000000014, 20.000000000000014, 200.0, 106.99999999999997, 20.000000000000014, 97.70000000000007, 20.000000000000014, 20.000000000000014, 136.6999999999998, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 9.499999999999964, 20.000000000000014, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 40.70000000000012, 49.69999999999997, 20.000000000000014, 182.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999946, 170.0, 13.699999999999964, 200.0, 37.999999999999986, 197.0, 20.000000000000014, 170.0, -21.999999999999815, 94.09999999999937, 200.0, 20.000000000000014, 20.000000000000014, -177.4000000000005, 161.0, 20.000000000000014, 116.29999999999998, 20.000000000000014, -276.09999999999957, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 20.000000000000014, 2.6000000000000116, 20.000000000000014, -111.40000000000026, 176.0, 20.000000000000014, 167.0, 98.29999999999998, 73.09999999999997, 20.000000000000014, 168.2, 20.000000000000014, 1.0999999999999794, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 64.99999999999997, 20.000000000000014, 20.000000000000014, 200.0, -95.50000000000077, 20.000000000000014, 98.29999999999998, -66.1000000000009, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 49.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 11.0, 9.0, 10.0, 49.0, 9.0, 10.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 30.0, 1.0, 7.0, 4.0, 10.0, 8.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 0.0, 1.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 94.0, 0.0, 8.0, 10.0, 0.0, 0.0, 141.0, 83.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 48.0, 23.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 41.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3720723792015819, "mean_inference_ms": 3.7510738896742555, "mean_action_processing_ms": 0.6127640414008806, "mean_env_wait_ms": 0.46371020202556307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005002498626708984, "StateBufferConnector_ms": 0.0039730072021484375, "ViewRequirementAgentConnector_ms": 0.1672971248626709}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -63.400000000000986, "episode_return_mean": 122.14599999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.65398867654122, "num_env_steps_trained_throughput_per_sec": 233.65398867654122, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 12193.676, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12193.591, "sample_time_ms": 1835.311, "learn_time_ms": 10342.906, "learn_throughput": 386.738, "synch_weights_time_ms": 13.995}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "e57b0_00000", "date": "2024-08-13_00-31-48", "timestamp": 1723523508, "time_this_iter_s": 17.134393215179443, "time_total_s": 1280.0471985340118, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b155cf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1280.0471985340118, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 77.128, "ram_util_percent": 82.572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.137102948897888, "cur_kl_coeff": 1.2730015441775318e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.347612666957593, "policy_loss": -0.0004401730125888236, "vf_loss": 4.348052838492015, "vf_explained_var": 0.21870256741210897, "kl": 0.0011766304462809394, "entropy": 0.36622145384077043, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37378402824991597, "cur_kl_coeff": 0.0012514114379882815, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2943602893008757, "policy_loss": -0.00037831971569666784, "vf_loss": 0.29473341064511155, "vf_explained_var": -0.01063039845259732, "kl": 0.004154510356244773, "entropy": 0.3539284402415866, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -65.60000000000096, "episode_reward_mean": 126.65299999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 57.171499999999966, "predator_policy": 6.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.300000000000114, 219.99999999999926, 93.10000000000002, 36.70000000000025, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 281.2000000000023, 40.0000000000003, 30.100000000000147, 113.19999999999982, 210.0999999999993, 40.0000000000003, 43.60000000000036, 40.0000000000003, 164.19999999999996, 163.49999999999952, 146.09999999999962, 19.09999999999996, 156.99999999999955, 214.4999999999993, 400.0, 199.99999999999935, 74.60000000000011, 138.59999999999965, 147.0999999999991, 75.90000000000009, 40.0000000000003, 40.0000000000003, 380.0, 40.0000000000003, 134.4999999999997, 64.10000000000008, 183.09999999999883, 40.0000000000003, 317.0000000000001, 128.6999999999997, 40.0000000000003, 157.89999999999918, 33.400000000000205, 34.50000000000022, 30.100000000000147, 40.0000000000003, 240.6999999999994, 69.70000000000022, 211.9999999999993, 35.600000000000236, 40.0000000000003, 294.50000000000045, 216.69999999999928, 235.99999999999937, 199.99999999999935, 94.09999999999876, 219.99999999999926, -63.400000000000986, 198.99999999999935, 136.29999999999967, -32.099999999999795, 139.89999999999876, 40.0000000000003, 32.60000000000012, 135.5999999999997, 197.99999999999937, 171.4000000000001, 198.19999999999936, 30.10000000000015, 35.600000000000236, 40.0000000000003, 207.99999999999932, 219.99999999999926, 40.0000000000003, 85.00000000000009, 219.99999999999926, -20.499999999999574, 73.20000000000024, 40.0000000000003, -56.80000000000072, 40.0000000000003, 40.0000000000003, 287.50000000000045, 308.1999999999998, -65.60000000000096, 40.0000000000003, 210.0999999999993, 14.799999999999958, 235.09999999999957, 78.70000000000014, 351.1000000000005, 138.99999999999966, 40.0000000000003, 219.99999999999926, 215.9999999999993, 219.99999999999926, 400.0, 208.99999999999932, 219.99999999999926, 31.200000000000166, 174.59999999999948], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, -51.40000000000001, 200.0, 20.000000000000014, 73.09999999999997, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 157.69999999999973, 123.49999999999952, 20.000000000000014, 20.000000000000014, 1.099999999999983, 20.000000000000014, 90.19999999999999, 20.000000000000014, 1.0999999999999688, 200.0, 20.000000000000014, 20.000000000000014, 21.80000000000004, 15.799999999999963, 20.000000000000014, 20.000000000000014, 88.39999999999998, 66.79999999999998, 125.60000000000005, 17.899999999999988, 170.0, -82.90000000000074, -19.899999999999743, 20.000000000000014, 137.0, 20.000000000000014, 200.0, 9.499999999999964, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 23.600000000000122, 5.299999999999965, 122.29999999999998, 125.89999999999972, 3.199999999999965, 9.499999999999964, 61.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 114.49999999999999, 20.000000000000014, 20.000000000000014, 34.10000000000001, 149.59999999999968, 33.50000000000024, 20.000000000000014, 20.000000000000014, 200.0, 106.99999999999997, 20.000000000000014, 97.70000000000007, 20.000000000000014, 20.000000000000014, 136.6999999999998, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 9.499999999999964, 20.000000000000014, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 40.70000000000012, 49.69999999999997, 20.000000000000014, 182.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999946, 170.0, 13.699999999999964, 200.0, 37.999999999999986, 197.0, 20.000000000000014, 170.0, -21.999999999999815, 94.09999999999937, 200.0, 20.000000000000014, 20.000000000000014, -177.4000000000005, 161.0, 20.000000000000014, 116.29999999999998, 20.000000000000014, -276.09999999999957, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 20.000000000000014, 2.6000000000000116, 20.000000000000014, -111.40000000000026, 176.0, 20.000000000000014, 167.0, 98.29999999999998, 73.09999999999997, 20.000000000000014, 168.2, 20.000000000000014, 1.0999999999999794, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 64.99999999999997, 20.000000000000014, 20.000000000000014, 200.0, -95.50000000000077, 20.000000000000014, 98.29999999999998, -66.1000000000009, 20.000000000000014, 20.000000000000014, -152.20000000000059, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 132.49999999999957, 200.0, 108.19999999999999, -181.60000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.099999999999983, 7.399999999999968, -13.599999999999808, 152.8999999999999, 72.19999999999996, 20.000000000000014, 58.69999999999996, 166.09999999999988, 170.0, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 200.0, 200.0, 200.0, -0.9999999999999846, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 143.60000000000002, 20.000000000000014], "policy_predator_policy_reward": [49.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 11.0, 9.0, 10.0, 49.0, 9.0, 10.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 30.0, 1.0, 7.0, 4.0, 10.0, 8.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 0.0, 1.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 94.0, 0.0, 8.0, 10.0, 0.0, 0.0, 141.0, 83.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 48.0, 23.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 41.0, 0.0, 0.0, 0.0, 82.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 0.0, 9.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3659502558154966, "mean_inference_ms": 3.731989638775245, "mean_action_processing_ms": 0.608670689738002, "mean_env_wait_ms": 0.4613166339686561, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004733562469482422, "StateBufferConnector_ms": 0.003985762596130371, "ViewRequirementAgentConnector_ms": 0.17332279682159424}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -65.60000000000096, "episode_return_mean": 126.65299999999986, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.81459889365965, "num_env_steps_trained_throughput_per_sec": 363.81459889365965, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 12200.218, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12200.133, "sample_time_ms": 1850.513, "learn_time_ms": 10334.603, "learn_throughput": 387.049, "synch_weights_time_ms": 13.683}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "e57b0_00000", "date": "2024-08-13_00-31-59", "timestamp": 1723523519, "time_this_iter_s": 11.00039291381836, "time_total_s": 1291.0475914478302, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b127fa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1291.0475914478302, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 45.28666666666667, "ram_util_percent": 74.27999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2091689361623987, "cur_kl_coeff": 6.365007720887659e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4421563263292665, "policy_loss": 0.001147316677111482, "vf_loss": 3.4410090054153764, "vf_explained_var": 0.22693182252071523, "kl": 0.0036313010749950587, "entropy": 0.34142517745494844, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2961000191742584, "cur_kl_coeff": 0.0006257057189941408, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2653256007800342, "policy_loss": -0.001169479649178881, "vf_loss": 0.2664925125907218, "vf_explained_var": 0.013199000919937457, "kl": 0.004102158057921342, "entropy": 0.3511415218707746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -65.60000000000096, "episode_reward_mean": 131.76999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 59.41999999999997, "predator_policy": 6.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [163.49999999999952, 146.09999999999962, 19.09999999999996, 156.99999999999955, 214.4999999999993, 400.0, 199.99999999999935, 74.60000000000011, 138.59999999999965, 147.0999999999991, 75.90000000000009, 40.0000000000003, 40.0000000000003, 380.0, 40.0000000000003, 134.4999999999997, 64.10000000000008, 183.09999999999883, 40.0000000000003, 317.0000000000001, 128.6999999999997, 40.0000000000003, 157.89999999999918, 33.400000000000205, 34.50000000000022, 30.100000000000147, 40.0000000000003, 240.6999999999994, 69.70000000000022, 211.9999999999993, 35.600000000000236, 40.0000000000003, 294.50000000000045, 216.69999999999928, 235.99999999999937, 199.99999999999935, 94.09999999999876, 219.99999999999926, -63.400000000000986, 198.99999999999935, 136.29999999999967, -32.099999999999795, 139.89999999999876, 40.0000000000003, 32.60000000000012, 135.5999999999997, 197.99999999999937, 171.4000000000001, 198.19999999999936, 30.10000000000015, 35.600000000000236, 40.0000000000003, 207.99999999999932, 219.99999999999926, 40.0000000000003, 85.00000000000009, 219.99999999999926, -20.499999999999574, 73.20000000000024, 40.0000000000003, -56.80000000000072, 40.0000000000003, 40.0000000000003, 287.50000000000045, 308.1999999999998, -65.60000000000096, 40.0000000000003, 210.0999999999993, 14.799999999999958, 235.09999999999957, 78.70000000000014, 351.1000000000005, 138.99999999999966, 40.0000000000003, 219.99999999999926, 215.9999999999993, 219.99999999999926, 400.0, 208.99999999999932, 219.99999999999926, 31.200000000000166, 174.59999999999948, 160.09999999999954, 165.99999999999886, 198.59999999999937, 27.90000000000011, 40.0000000000003, 163.59999999999954, 32.30000000000018, 199.99999999999935, 193.39999999999938, 40.0000000000003, 40.0000000000003, 199.99999999999935, 26.800000000000093, 109.39999999999995, 89.29999999999866, 93.09999999999846, 258.70000000000005, 359.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [125.60000000000005, 17.899999999999988, 170.0, -82.90000000000074, -19.899999999999743, 20.000000000000014, 137.0, 20.000000000000014, 200.0, 9.499999999999964, 200.0, 200.0, 170.0, 20.000000000000014, 20.000000000000014, 23.600000000000122, 5.299999999999965, 122.29999999999998, 125.89999999999972, 3.199999999999965, 9.499999999999964, 61.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 114.49999999999999, 20.000000000000014, 20.000000000000014, 34.10000000000001, 149.59999999999968, 33.50000000000024, 20.000000000000014, 20.000000000000014, 200.0, 106.99999999999997, 20.000000000000014, 97.70000000000007, 20.000000000000014, 20.000000000000014, 136.6999999999998, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 9.499999999999964, 20.000000000000014, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 40.70000000000012, 49.69999999999997, 20.000000000000014, 182.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999946, 170.0, 13.699999999999964, 200.0, 37.999999999999986, 197.0, 20.000000000000014, 170.0, -21.999999999999815, 94.09999999999937, 200.0, 20.000000000000014, 20.000000000000014, -177.4000000000005, 161.0, 20.000000000000014, 116.29999999999998, 20.000000000000014, -276.09999999999957, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 20.000000000000014, 2.6000000000000116, 20.000000000000014, -111.40000000000026, 176.0, 20.000000000000014, 167.0, 98.29999999999998, 73.09999999999997, 20.000000000000014, 168.2, 20.000000000000014, 1.0999999999999794, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 64.99999999999997, 20.000000000000014, 20.000000000000014, 200.0, -95.50000000000077, 20.000000000000014, 98.29999999999998, -66.1000000000009, 20.000000000000014, 20.000000000000014, -152.20000000000059, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 132.49999999999957, 200.0, 108.19999999999999, -181.60000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.099999999999983, 7.399999999999968, -13.599999999999808, 152.8999999999999, 72.19999999999996, 20.000000000000014, 58.69999999999996, 166.09999999999988, 170.0, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 200.0, 200.0, 200.0, -0.9999999999999846, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 143.60000000000002, 20.000000000000014, 20.000000000000014, 124.10000000000002, 23.600000000000065, 142.39999999999964, 170.6, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 5.299999999999965, 170.0, 20.000000000000014, 7.399999999999965, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -5.199999999999934, 20.000000000000014, 58.40000000000007, 20.000000000000014, 59.300000000000175, 20.000000000000014, 73.09999999999955, 113.59999999999998, 145.1, 170.0, 170.0], "policy_predator_policy_reward": [11.0, 9.0, 10.0, 49.0, 9.0, 10.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 0.0, 30.0, 1.0, 7.0, 4.0, 10.0, 8.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 0.0, 1.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 94.0, 0.0, 8.0, 10.0, 0.0, 0.0, 141.0, 83.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 48.0, 23.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 41.0, 0.0, 0.0, 0.0, 82.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 0.0, 9.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 9.0, 7.0, 0.0, 0.0, 8.0, 0.0, 1.0, 10.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 10.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.359110822260493, "mean_inference_ms": 3.7228896313408963, "mean_action_processing_ms": 0.605760895388032, "mean_env_wait_ms": 0.4587089561209007, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004546403884887695, "StateBufferConnector_ms": 0.0039681196212768555, "ViewRequirementAgentConnector_ms": 0.17881464958190918}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -65.60000000000096, "episode_return_mean": 131.76999999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.6259659432802, "num_env_steps_trained_throughput_per_sec": 341.6259659432802, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 12372.458, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12372.373, "sample_time_ms": 1891.62, "learn_time_ms": 10465.436, "learn_throughput": 382.211, "synch_weights_time_ms": 13.979}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "e57b0_00000", "date": "2024-08-13_00-32-11", "timestamp": 1723523531, "time_this_iter_s": 11.714010000228882, "time_total_s": 1302.761601448059, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b127f9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1302.761601448059, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 49.94117647058823, "ram_util_percent": 76.89411764705882}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.009373822260313, "cur_kl_coeff": 3.1825038604438295e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.09805261685104, "policy_loss": -0.0007253489331416194, "vf_loss": 4.098777961478662, "vf_explained_var": 0.2609355670119089, "kl": 0.004289247241013458, "entropy": 0.3592166586685433, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2316582360733596, "cur_kl_coeff": 0.0003128528594970704, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2994385295877696, "policy_loss": -0.0005682654454614277, "vf_loss": 0.30000614759580924, "vf_explained_var": 0.005125366159217068, "kl": 0.002067765619342177, "entropy": 0.2852322488628998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -65.60000000000096, "episode_reward_mean": 135.8439999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 61.83199999999997, "predator_policy": 6.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.400000000000205, 34.50000000000022, 30.100000000000147, 40.0000000000003, 240.6999999999994, 69.70000000000022, 211.9999999999993, 35.600000000000236, 40.0000000000003, 294.50000000000045, 216.69999999999928, 235.99999999999937, 199.99999999999935, 94.09999999999876, 219.99999999999926, -63.400000000000986, 198.99999999999935, 136.29999999999967, -32.099999999999795, 139.89999999999876, 40.0000000000003, 32.60000000000012, 135.5999999999997, 197.99999999999937, 171.4000000000001, 198.19999999999936, 30.10000000000015, 35.600000000000236, 40.0000000000003, 207.99999999999932, 219.99999999999926, 40.0000000000003, 85.00000000000009, 219.99999999999926, -20.499999999999574, 73.20000000000024, 40.0000000000003, -56.80000000000072, 40.0000000000003, 40.0000000000003, 287.50000000000045, 308.1999999999998, -65.60000000000096, 40.0000000000003, 210.0999999999993, 14.799999999999958, 235.09999999999957, 78.70000000000014, 351.1000000000005, 138.99999999999966, 40.0000000000003, 219.99999999999926, 215.9999999999993, 219.99999999999926, 400.0, 208.99999999999932, 219.99999999999926, 31.200000000000166, 174.59999999999948, 160.09999999999954, 165.99999999999886, 198.59999999999937, 27.90000000000011, 40.0000000000003, 163.59999999999954, 32.30000000000018, 199.99999999999935, 193.39999999999938, 40.0000000000003, 40.0000000000003, 199.99999999999935, 26.800000000000093, 109.39999999999995, 89.29999999999866, 93.09999999999846, 258.70000000000005, 359.0, 216.39999999999924, 40.0000000000003, 175.79999999999947, 210.0999999999993, 82.99999999999909, 198.89999999999935, 400.0, 199.99999999999935, 40.0000000000003, 201.99999999999935, 219.99999999999926, 199.99999999999935, 29.00000000000013, 247.89999999999944, 176.599999999999, 199.99999999999935, 95.6, 30.100000000000154, 219.99999999999926, 199.99999999999935, 40.0000000000003, 94.6999999999986, 188.9999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 7.399999999999965, 9.499999999999964, 20.000000000000014, 1.099999999999983, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 40.70000000000012, 49.69999999999997, 20.000000000000014, 182.0, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 114.49999999999946, 170.0, 13.699999999999964, 200.0, 37.999999999999986, 197.0, 20.000000000000014, 170.0, -21.999999999999815, 94.09999999999937, 200.0, 20.000000000000014, 20.000000000000014, -177.4000000000005, 161.0, 20.000000000000014, 116.29999999999998, 20.000000000000014, -276.09999999999957, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 20.000000000000014, 2.6000000000000116, 20.000000000000014, -111.40000000000026, 176.0, 20.000000000000014, 167.0, 98.29999999999998, 73.09999999999997, 20.000000000000014, 168.2, 20.000000000000014, 1.0999999999999794, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 64.99999999999997, 20.000000000000014, 20.000000000000014, 200.0, -95.50000000000077, 20.000000000000014, 98.29999999999998, -66.1000000000009, 20.000000000000014, 20.000000000000014, -152.20000000000059, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 132.49999999999957, 200.0, 108.19999999999999, -181.60000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.099999999999983, 7.399999999999968, -13.599999999999808, 152.8999999999999, 72.19999999999996, 20.000000000000014, 58.69999999999996, 166.09999999999988, 170.0, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 200.0, 200.0, 200.0, -0.9999999999999846, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 143.60000000000002, 20.000000000000014, 20.000000000000014, 124.10000000000002, 23.600000000000065, 142.39999999999964, 170.6, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 5.299999999999965, 170.0, 20.000000000000014, 7.399999999999965, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -5.199999999999934, 20.000000000000014, 58.40000000000007, 20.000000000000014, 59.300000000000175, 20.000000000000014, 73.09999999999955, 113.59999999999998, 145.1, 170.0, 170.0, 196.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -26.19999999999977, 200.0, 1.0999999999999865, -0.9999999999999917, 73.99999999999949, 17.899999999999988, 170.0, 200.0, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 47.89999999999997, 200.0, 20.000000000000014, 155.59999999999974, 20.000000000000014, 170.0, 74.59999999999998, 20.000000000000014, 1.0999999999999759, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 85.69999999999928, 149.0, 20.000000000000014], "policy_predator_policy_reward": [6.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 3.0, 0.0, 0.0, 1.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 94.0, 0.0, 8.0, 10.0, 0.0, 0.0, 141.0, 83.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 48.0, 23.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 41.0, 0.0, 0.0, 0.0, 82.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 0.0, 9.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 9.0, 7.0, 0.0, 0.0, 8.0, 0.0, 1.0, 10.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 10.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 1.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3535155703493162, "mean_inference_ms": 3.711018851780688, "mean_action_processing_ms": 0.6027247370512131, "mean_env_wait_ms": 0.4564684112634496, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004224538803100586, "StateBufferConnector_ms": 0.003747224807739258, "ViewRequirementAgentConnector_ms": 0.16556525230407715}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -65.60000000000096, "episode_return_mean": 135.8439999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.15925795158154, "num_env_steps_trained_throughput_per_sec": 348.15925795158154, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 12505.161, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12505.076, "sample_time_ms": 1893.356, "learn_time_ms": 10595.487, "learn_throughput": 377.519, "synch_weights_time_ms": 14.89}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "e57b0_00000", "date": "2024-08-13_00-32-22", "timestamp": 1723523542, "time_this_iter_s": 11.501152753829956, "time_total_s": 1314.262754201889, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dbab80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1314.262754201889, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 46.73125, "ram_util_percent": 76.80625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0890594314527573, "cur_kl_coeff": 1.5912519302219147e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.310164472287294, "policy_loss": -0.00043949889063480356, "vf_loss": 3.3106039698161775, "vf_explained_var": 0.21378194983043367, "kl": 0.0034546430535933323, "entropy": 0.38904664396608946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2264066692855623, "cur_kl_coeff": 0.0001564264297485352, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15707853729959834, "policy_loss": -0.00028888234602553506, "vf_loss": 0.15736708321358794, "vf_explained_var": -0.03491693378756286, "kl": 0.0021554697790707135, "entropy": 0.280115330227153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -65.60000000000096, "episode_reward_mean": 133.5029999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 141.0}, "policy_reward_mean": {"prey_policy": 60.906499999999966, "predator_policy": 5.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.099999999999795, 139.89999999999876, 40.0000000000003, 32.60000000000012, 135.5999999999997, 197.99999999999937, 171.4000000000001, 198.19999999999936, 30.10000000000015, 35.600000000000236, 40.0000000000003, 207.99999999999932, 219.99999999999926, 40.0000000000003, 85.00000000000009, 219.99999999999926, -20.499999999999574, 73.20000000000024, 40.0000000000003, -56.80000000000072, 40.0000000000003, 40.0000000000003, 287.50000000000045, 308.1999999999998, -65.60000000000096, 40.0000000000003, 210.0999999999993, 14.799999999999958, 235.09999999999957, 78.70000000000014, 351.1000000000005, 138.99999999999966, 40.0000000000003, 219.99999999999926, 215.9999999999993, 219.99999999999926, 400.0, 208.99999999999932, 219.99999999999926, 31.200000000000166, 174.59999999999948, 160.09999999999954, 165.99999999999886, 198.59999999999937, 27.90000000000011, 40.0000000000003, 163.59999999999954, 32.30000000000018, 199.99999999999935, 193.39999999999938, 40.0000000000003, 40.0000000000003, 199.99999999999935, 26.800000000000093, 109.39999999999995, 89.29999999999866, 93.09999999999846, 258.70000000000005, 359.0, 216.39999999999924, 40.0000000000003, 175.79999999999947, 210.0999999999993, 82.99999999999909, 198.89999999999935, 400.0, 199.99999999999935, 40.0000000000003, 201.99999999999935, 219.99999999999926, 199.99999999999935, 29.00000000000013, 247.89999999999944, 176.599999999999, 199.99999999999935, 95.6, 30.100000000000154, 219.99999999999926, 199.99999999999935, 40.0000000000003, 94.6999999999986, 188.9999999999994, 93.10000000000002, 156.09999999999954, 138.09999999999962, 219.99999999999926, 40.0000000000003, 219.99999999999926, 31.30000000000018, 74.40000000000003, 40.0000000000003, 40.0000000000003, 87.49999999999989, 40.0000000000003, 219.99999999999926, 205.99999999999932, 40.0000000000003, 136.2999999999997, 219.99999999999926, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-276.09999999999957, 20.000000000000014, 20.000000000000014, 119.8999999999995, 20.000000000000014, 20.000000000000014, 2.6000000000000116, 20.000000000000014, -111.40000000000026, 176.0, 20.000000000000014, 167.0, 98.29999999999998, 73.09999999999997, 20.000000000000014, 168.2, 20.000000000000014, 1.0999999999999794, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 64.99999999999997, 20.000000000000014, 20.000000000000014, 200.0, -95.50000000000077, 20.000000000000014, 98.29999999999998, -66.1000000000009, 20.000000000000014, 20.000000000000014, -152.20000000000059, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 132.49999999999957, 200.0, 108.19999999999999, -181.60000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.099999999999983, 7.399999999999968, -13.599999999999808, 152.8999999999999, 72.19999999999996, 20.000000000000014, 58.69999999999996, 166.09999999999988, 170.0, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 200.0, 200.0, 200.0, -0.9999999999999846, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 143.60000000000002, 20.000000000000014, 20.000000000000014, 124.10000000000002, 23.600000000000065, 142.39999999999964, 170.6, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 5.299999999999965, 170.0, 20.000000000000014, 7.399999999999965, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -5.199999999999934, 20.000000000000014, 58.40000000000007, 20.000000000000014, 59.300000000000175, 20.000000000000014, 73.09999999999955, 113.59999999999998, 145.1, 170.0, 170.0, 196.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -26.19999999999977, 200.0, 1.0999999999999865, -0.9999999999999917, 73.99999999999949, 17.899999999999988, 170.0, 200.0, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 47.89999999999997, 200.0, 20.000000000000014, 155.59999999999974, 20.000000000000014, 170.0, 74.59999999999998, 20.000000000000014, 1.0999999999999759, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 85.69999999999928, 149.0, 20.000000000000014, 20.000000000000014, 73.09999999999997, 20.000000000000014, 136.1, 20.000000000000014, 118.09999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -99.70000000000081, 20.000000000000014, 63.19999999999996, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.50000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965], "policy_predator_policy_reward": [141.0, 83.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 48.0, 23.0, 0.0, 11.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 0.0, 41.0, 0.0, 0.0, 0.0, 82.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 0.0, 9.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 9.0, 7.0, 0.0, 0.0, 8.0, 0.0, 1.0, 10.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 10.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 1.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 57.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3460822160584942, "mean_inference_ms": 3.694712924357006, "mean_action_processing_ms": 0.5989914252041291, "mean_env_wait_ms": 0.45372577280552234, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004293680191040039, "StateBufferConnector_ms": 0.003554224967956543, "ViewRequirementAgentConnector_ms": 0.173406720161438}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -65.60000000000096, "episode_return_mean": 133.5029999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.0870652830105, "num_env_steps_trained_throughput_per_sec": 307.0870652830105, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 12682.754, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12682.667, "sample_time_ms": 2011.649, "learn_time_ms": 10654.148, "learn_throughput": 375.441, "synch_weights_time_ms": 15.575}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "e57b0_00000", "date": "2024-08-13_00-32-36", "timestamp": 1723523556, "time_this_iter_s": 13.033458948135376, "time_total_s": 1327.2962131500244, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09cf820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1327.2962131500244, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 55.25789473684211, "ram_util_percent": 77.21578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.294738296592835, "cur_kl_coeff": 7.956259651109574e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.24490923288638, "policy_loss": 0.00013709128341543928, "vf_loss": 4.2447721414465125, "vf_explained_var": 0.24252221631625343, "kl": 0.012541388122484587, "entropy": 0.4524847428319315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2592779800951205, "cur_kl_coeff": 7.82132148742676e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3031264932185569, "policy_loss": -0.000890860141368297, "vf_loss": 0.3040171948554753, "vf_explained_var": -0.002541353841307302, "kl": 0.0020300143134851212, "entropy": 0.2675437678893407, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -65.60000000000096, "episode_reward_mean": 138.7189999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -181.60000000000045, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 96.0}, "policy_reward_mean": {"prey_policy": 64.71949999999997, "predator_policy": 4.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -56.80000000000072, 40.0000000000003, 40.0000000000003, 287.50000000000045, 308.1999999999998, -65.60000000000096, 40.0000000000003, 210.0999999999993, 14.799999999999958, 235.09999999999957, 78.70000000000014, 351.1000000000005, 138.99999999999966, 40.0000000000003, 219.99999999999926, 215.9999999999993, 219.99999999999926, 400.0, 208.99999999999932, 219.99999999999926, 31.200000000000166, 174.59999999999948, 160.09999999999954, 165.99999999999886, 198.59999999999937, 27.90000000000011, 40.0000000000003, 163.59999999999954, 32.30000000000018, 199.99999999999935, 193.39999999999938, 40.0000000000003, 40.0000000000003, 199.99999999999935, 26.800000000000093, 109.39999999999995, 89.29999999999866, 93.09999999999846, 258.70000000000005, 359.0, 216.39999999999924, 40.0000000000003, 175.79999999999947, 210.0999999999993, 82.99999999999909, 198.89999999999935, 400.0, 199.99999999999935, 40.0000000000003, 201.99999999999935, 219.99999999999926, 199.99999999999935, 29.00000000000013, 247.89999999999944, 176.599999999999, 199.99999999999935, 95.6, 30.100000000000154, 219.99999999999926, 199.99999999999935, 40.0000000000003, 94.6999999999986, 188.9999999999994, 93.10000000000002, 156.09999999999954, 138.09999999999962, 219.99999999999926, 40.0000000000003, 219.99999999999926, 31.30000000000018, 74.40000000000003, 40.0000000000003, 40.0000000000003, 87.49999999999989, 40.0000000000003, 219.99999999999926, 205.99999999999932, 40.0000000000003, 136.2999999999997, 219.99999999999926, 32.30000000000018, 33.400000000000205, 40.0000000000003, 207.99999999999932, 46.1, 207.99999999999932, 40.0000000000003, 219.99999999999926, 174.29999999999947, 113.79999999999859, 40.0000000000003, 170.2999999999995, 110.89999999999978, 119.29999999999981, 400.0, 59.40000000000007, 40.0000000000003, 40.0000000000003, 273.0999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -152.20000000000059, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 132.49999999999957, 200.0, 108.19999999999999, -181.60000000000045, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 1.099999999999983, 7.399999999999968, -13.599999999999808, 152.8999999999999, 72.19999999999996, 20.000000000000014, 58.69999999999996, 166.09999999999988, 170.0, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 194.0, 20.000000000000014, 200.0, 200.0, 200.0, 200.0, -0.9999999999999846, 20.000000000000014, 200.0, 3.1999999999999615, 20.000000000000014, 143.60000000000002, 20.000000000000014, 20.000000000000014, 124.10000000000002, 23.600000000000065, 142.39999999999964, 170.6, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 5.299999999999965, 170.0, 20.000000000000014, 7.399999999999965, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -5.199999999999934, 20.000000000000014, 58.40000000000007, 20.000000000000014, 59.300000000000175, 20.000000000000014, 73.09999999999955, 113.59999999999998, 145.1, 170.0, 170.0, 196.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -26.19999999999977, 200.0, 1.0999999999999865, -0.9999999999999917, 73.99999999999949, 17.899999999999988, 170.0, 200.0, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 47.89999999999997, 200.0, 20.000000000000014, 155.59999999999974, 20.000000000000014, 170.0, 74.59999999999998, 20.000000000000014, 1.0999999999999759, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 85.69999999999928, 149.0, 20.000000000000014, 20.000000000000014, 73.09999999999997, 20.000000000000014, 136.1, 20.000000000000014, 118.09999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -99.70000000000081, 20.000000000000014, 63.19999999999996, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.50000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, -98.50000000000063, 41.59999999999998, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 146.29999999999998, 20.000000000000014, 93.79999999999933, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.3, 71.90000000000012, 20.000000000000014, 16.099999999999962, 81.19999999999996, 200.0, 200.0, -3.0999999999999757, 51.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999955, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 82.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 0.0, 0.0, 0.0, 9.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 9.0, 7.0, 0.0, 0.0, 8.0, 0.0, 1.0, 10.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 10.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 1.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 57.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 38.0, 65.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 10.0, 15.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.339560525343432, "mean_inference_ms": 3.67995143497682, "mean_action_processing_ms": 0.5958482541134668, "mean_env_wait_ms": 0.4513160321933228, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004271507263183594, "StateBufferConnector_ms": 0.0036661624908447266, "ViewRequirementAgentConnector_ms": 0.15794026851654053}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -65.60000000000096, "episode_return_mean": 138.7189999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.533660238659, "num_env_steps_trained_throughput_per_sec": 338.533660238659, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 12614.659, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12614.588, "sample_time_ms": 1921.236, "learn_time_ms": 10676.916, "learn_throughput": 374.64, "synch_weights_time_ms": 15.299}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "e57b0_00000", "date": "2024-08-13_00-32-47", "timestamp": 1723523567, "time_this_iter_s": 11.844598054885864, "time_total_s": 1339.1408112049103, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b152bee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1339.1408112049103, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 49.94117647058824, "ram_util_percent": 76.74117647058823}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.507044896396695, "cur_kl_coeff": 7.956259651109574e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.53682699165647, "policy_loss": -0.0016726732271275034, "vf_loss": 3.5384996686662946, "vf_explained_var": 0.26623678037098475, "kl": 0.004534143227601725, "entropy": 0.46980666803619847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3014904038000004, "cur_kl_coeff": 3.91066074371338e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23172000659797243, "policy_loss": -0.0007882755836126981, "vf_loss": 0.232508195124964, "vf_explained_var": -0.006729690801529657, "kl": 0.00223051747762077, "entropy": 0.27831373463074366, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 26.800000000000093, "episode_reward_mean": 136.7539999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -99.70000000000081, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 65.0}, "policy_reward_mean": {"prey_policy": 64.39699999999998, "predator_policy": 3.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [174.59999999999948, 160.09999999999954, 165.99999999999886, 198.59999999999937, 27.90000000000011, 40.0000000000003, 163.59999999999954, 32.30000000000018, 199.99999999999935, 193.39999999999938, 40.0000000000003, 40.0000000000003, 199.99999999999935, 26.800000000000093, 109.39999999999995, 89.29999999999866, 93.09999999999846, 258.70000000000005, 359.0, 216.39999999999924, 40.0000000000003, 175.79999999999947, 210.0999999999993, 82.99999999999909, 198.89999999999935, 400.0, 199.99999999999935, 40.0000000000003, 201.99999999999935, 219.99999999999926, 199.99999999999935, 29.00000000000013, 247.89999999999944, 176.599999999999, 199.99999999999935, 95.6, 30.100000000000154, 219.99999999999926, 199.99999999999935, 40.0000000000003, 94.6999999999986, 188.9999999999994, 93.10000000000002, 156.09999999999954, 138.09999999999962, 219.99999999999926, 40.0000000000003, 219.99999999999926, 31.30000000000018, 74.40000000000003, 40.0000000000003, 40.0000000000003, 87.49999999999989, 40.0000000000003, 219.99999999999926, 205.99999999999932, 40.0000000000003, 136.2999999999997, 219.99999999999926, 32.30000000000018, 33.400000000000205, 40.0000000000003, 207.99999999999932, 46.1, 207.99999999999932, 40.0000000000003, 219.99999999999926, 174.29999999999947, 113.79999999999859, 40.0000000000003, 170.2999999999995, 110.89999999999978, 119.29999999999981, 400.0, 59.40000000000007, 40.0000000000003, 40.0000000000003, 273.0999999999996, 274.00000000000006, 40.0000000000003, 170.59999999999948, 219.99999999999926, 40.0000000000003, 102.99999999999994, 183.19999999999945, 219.99999999999926, 40.0000000000003, 200.19999999999936, 172.59999999999903, 78.69999999999943, 229.99999999999946, 31.900000000000144, 40.0000000000003, 209.9999999999993, 244.29999999999941, 111.99999999999979, 38.50000000000028, 45.5000000000004, 287.3000000000005, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [143.60000000000002, 20.000000000000014, 20.000000000000014, 124.10000000000002, 23.600000000000065, 142.39999999999964, 170.6, 20.000000000000014, 20.000000000000014, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 5.299999999999965, 170.0, 20.000000000000014, 7.399999999999965, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, -5.199999999999934, 20.000000000000014, 58.40000000000007, 20.000000000000014, 59.300000000000175, 20.000000000000014, 73.09999999999955, 113.59999999999998, 145.1, 170.0, 170.0, 196.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -26.19999999999977, 200.0, 1.0999999999999865, -0.9999999999999917, 73.99999999999949, 17.899999999999988, 170.0, 200.0, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 47.89999999999997, 200.0, 20.000000000000014, 155.59999999999974, 20.000000000000014, 170.0, 74.59999999999998, 20.000000000000014, 1.0999999999999759, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 85.69999999999928, 149.0, 20.000000000000014, 20.000000000000014, 73.09999999999997, 20.000000000000014, 136.1, 20.000000000000014, 118.09999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -99.70000000000081, 20.000000000000014, 63.19999999999996, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.50000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, -98.50000000000063, 41.59999999999998, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 146.29999999999998, 20.000000000000014, 93.79999999999933, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.3, 71.90000000000012, 20.000000000000014, 16.099999999999962, 81.19999999999996, 200.0, 200.0, -3.0999999999999757, 51.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999955, 200.0, 137.8999999999996, 136.1, 20.000000000000014, 20.000000000000014, 11.599999999999964, 146.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 82.99999999999997, 165.5, 13.699999999999964, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -17.799999999999756, 20.000000000000014, 149.59999999999974, 58.70000000000022, 20.000000000000014, 200.0, 11.000000000000183, 20.000000000000014, 2.8999999999999866, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999881, 114.49999999999946, 129.79999999999998, 56.900000000000226, 55.09999999999996, 20.000000000000014, 9.499999999999964, 23.000000000000064, 9.499999999999973, 108.80000000000001, 150.4999999999997, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [11.0, 0.0, 9.0, 7.0, 0.0, 0.0, 8.0, 0.0, 1.0, 10.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 10.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 1.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 57.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 38.0, 65.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 10.0, 15.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 10.0, 9.0, 0.0, 9.0, 0.0, 0.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 13.0, 0.0, 28.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3316169758106164, "mean_inference_ms": 3.662136746593571, "mean_action_processing_ms": 0.5920129660030565, "mean_env_wait_ms": 0.448390418189049, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004299283027648926, "StateBufferConnector_ms": 0.0035747289657592773, "ViewRequirementAgentConnector_ms": 0.1460028886795044}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 26.800000000000093, "episode_return_mean": 136.7539999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.93748312022313, "num_env_steps_trained_throughput_per_sec": 357.93748312022313, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 12609.778, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12609.708, "sample_time_ms": 1920.752, "learn_time_ms": 10672.316, "learn_throughput": 374.801, "synch_weights_time_ms": 15.507}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "e57b0_00000", "date": "2024-08-13_00-32-59", "timestamp": 1723523579, "time_this_iter_s": 11.180957078933716, "time_total_s": 1350.321768283844, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09f6c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1350.321768283844, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 45.693749999999994, "ram_util_percent": 76.86250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6886880342646564, "cur_kl_coeff": 3.978129825554787e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8600522836049396, "policy_loss": -0.0012691460266492512, "vf_loss": 2.861321439503362, "vf_explained_var": 0.27655495335816077, "kl": 0.0020089684760066723, "entropy": 0.5245004394697764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37576877510017426, "cur_kl_coeff": 1.95533037185669e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3173251756442287, "policy_loss": -8.792305493323261e-05, "vf_loss": 0.3174130696051867, "vf_explained_var": -0.011541923234071681, "kl": 0.0015538221814321, "entropy": 0.29001888530279596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -44.700000000000024, "episode_reward_mean": 131.58699999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -137.5000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 75.0}, "policy_reward_mean": {"prey_policy": 61.488499999999966, "predator_policy": 4.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [359.0, 216.39999999999924, 40.0000000000003, 175.79999999999947, 210.0999999999993, 82.99999999999909, 198.89999999999935, 400.0, 199.99999999999935, 40.0000000000003, 201.99999999999935, 219.99999999999926, 199.99999999999935, 29.00000000000013, 247.89999999999944, 176.599999999999, 199.99999999999935, 95.6, 30.100000000000154, 219.99999999999926, 199.99999999999935, 40.0000000000003, 94.6999999999986, 188.9999999999994, 93.10000000000002, 156.09999999999954, 138.09999999999962, 219.99999999999926, 40.0000000000003, 219.99999999999926, 31.30000000000018, 74.40000000000003, 40.0000000000003, 40.0000000000003, 87.49999999999989, 40.0000000000003, 219.99999999999926, 205.99999999999932, 40.0000000000003, 136.2999999999997, 219.99999999999926, 32.30000000000018, 33.400000000000205, 40.0000000000003, 207.99999999999932, 46.1, 207.99999999999932, 40.0000000000003, 219.99999999999926, 174.29999999999947, 113.79999999999859, 40.0000000000003, 170.2999999999995, 110.89999999999978, 119.29999999999981, 400.0, 59.40000000000007, 40.0000000000003, 40.0000000000003, 273.0999999999996, 274.00000000000006, 40.0000000000003, 170.59999999999948, 219.99999999999926, 40.0000000000003, 102.99999999999994, 183.19999999999945, 219.99999999999926, 40.0000000000003, 200.19999999999936, 172.59999999999903, 78.69999999999943, 229.99999999999946, 31.900000000000144, 40.0000000000003, 209.9999999999993, 244.29999999999941, 111.99999999999979, 38.50000000000028, 45.5000000000004, 287.3000000000005, 40.0000000000003, 67.90000000000023, 87.69999999999872, 197.99999999999937, 34.50000000000022, 24.70000000000005, 40.0000000000003, -44.700000000000024, 31.200000000000166, 153.39999999999884, 40.0000000000003, 191.19999999999945, 97.09999999999985, 40.0000000000003, 40.0000000000003, 283.90000000000003, 177.39999999999947, 194.7999999999994, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.0, 170.0, 196.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, -26.19999999999977, 200.0, 1.0999999999999865, -0.9999999999999917, 73.99999999999949, 17.899999999999988, 170.0, 200.0, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 200.0, 170.0, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 47.89999999999997, 200.0, 20.000000000000014, 155.59999999999974, 20.000000000000014, 170.0, 74.59999999999998, 20.000000000000014, 1.0999999999999759, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, -0.9999999999999992, 85.69999999999928, 149.0, 20.000000000000014, 20.000000000000014, 73.09999999999997, 20.000000000000014, 136.1, 20.000000000000014, 118.09999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -99.70000000000081, 20.000000000000014, 63.19999999999996, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.50000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, -98.50000000000063, 41.59999999999998, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 146.29999999999998, 20.000000000000014, 93.79999999999933, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.3, 71.90000000000012, 20.000000000000014, 16.099999999999962, 81.19999999999996, 200.0, 200.0, -3.0999999999999757, 51.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999955, 200.0, 137.8999999999996, 136.1, 20.000000000000014, 20.000000000000014, 11.599999999999964, 146.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 82.99999999999997, 165.5, 13.699999999999964, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -17.799999999999756, 20.000000000000014, 149.59999999999974, 58.70000000000022, 20.000000000000014, 200.0, 11.000000000000183, 20.000000000000014, 2.8999999999999866, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999881, 114.49999999999946, 129.79999999999998, 56.900000000000226, 55.09999999999996, 20.000000000000014, 9.499999999999964, 23.000000000000064, 9.499999999999973, 108.80000000000001, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.89999999999997, 20.000000000000014, 67.69999999999992, -21.99999999999975, 200.0, 20.000000000000014, 9.49999999999997, 11.599999999999964, 4.099999999999966, 20.000000000000014, 20.000000000000014, -137.5000000000007, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 133.39999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.200000000000035, 170.0, 17.899999999999988, 54.200000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 50.89999999999972, 20.000000000000014, 151.39999999999998, 1.0999999999999865, 184.7, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 9.0, 0.0, 10.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 10.0, 0.0, 1.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 57.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 38.0, 65.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 10.0, 15.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 10.0, 9.0, 0.0, 9.0, 0.0, 0.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 13.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 5.0, 0.0, 9.0, 0.0, 0.0, 75.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 1.0, 24.0, 0.0, 0.0, 0.0, 0.0, 35.0, 1.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3250262628401623, "mean_inference_ms": 3.647553498227194, "mean_action_processing_ms": 0.5889209670488772, "mean_env_wait_ms": 0.4460363570686141, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004340171813964844, "StateBufferConnector_ms": 0.003580451011657715, "ViewRequirementAgentConnector_ms": 0.1544666290283203}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -44.700000000000024, "episode_return_mean": 131.58699999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 303.07300545773677, "num_env_steps_trained_throughput_per_sec": 303.07300545773677, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 12671.701, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12671.63, "sample_time_ms": 1933.313, "learn_time_ms": 10722.101, "learn_throughput": 373.061, "synch_weights_time_ms": 15.065}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "e57b0_00000", "date": "2024-08-13_00-33-12", "timestamp": 1723523592, "time_this_iter_s": 13.227339029312134, "time_total_s": 1363.5491073131561, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09f6e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1363.5491073131561, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 56.72222222222222, "ram_util_percent": 77.67222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9417781669114316, "cur_kl_coeff": 1.9890649127773934e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2955115964803747, "policy_loss": -0.0003127441872108393, "vf_loss": 3.295824344132943, "vf_explained_var": 0.33346779217164985, "kl": 0.001611658537415575, "entropy": 0.48855646189558444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.22599943197140146, "cur_kl_coeff": 9.77665185928345e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18642935256360385, "policy_loss": -0.0007666310894169978, "vf_loss": 0.18719585604277975, "vf_explained_var": -0.03394208960432224, "kl": 0.01307317636124735, "entropy": 0.34076746325328866, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -44.700000000000024, "episode_reward_mean": 120.82099999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -137.5000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 75.0}, "policy_reward_mean": {"prey_policy": 56.02549999999997, "predator_policy": 4.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [188.9999999999994, 93.10000000000002, 156.09999999999954, 138.09999999999962, 219.99999999999926, 40.0000000000003, 219.99999999999926, 31.30000000000018, 74.40000000000003, 40.0000000000003, 40.0000000000003, 87.49999999999989, 40.0000000000003, 219.99999999999926, 205.99999999999932, 40.0000000000003, 136.2999999999997, 219.99999999999926, 32.30000000000018, 33.400000000000205, 40.0000000000003, 207.99999999999932, 46.1, 207.99999999999932, 40.0000000000003, 219.99999999999926, 174.29999999999947, 113.79999999999859, 40.0000000000003, 170.2999999999995, 110.89999999999978, 119.29999999999981, 400.0, 59.40000000000007, 40.0000000000003, 40.0000000000003, 273.0999999999996, 274.00000000000006, 40.0000000000003, 170.59999999999948, 219.99999999999926, 40.0000000000003, 102.99999999999994, 183.19999999999945, 219.99999999999926, 40.0000000000003, 200.19999999999936, 172.59999999999903, 78.69999999999943, 229.99999999999946, 31.900000000000144, 40.0000000000003, 209.9999999999993, 244.29999999999941, 111.99999999999979, 38.50000000000028, 45.5000000000004, 287.3000000000005, 40.0000000000003, 67.90000000000023, 87.69999999999872, 197.99999999999937, 34.50000000000022, 24.70000000000005, 40.0000000000003, -44.700000000000024, 31.200000000000166, 153.39999999999884, 40.0000000000003, 191.19999999999945, 97.09999999999985, 40.0000000000003, 40.0000000000003, 283.90000000000003, 177.39999999999947, 194.7999999999994, 40.0000000000003, 102.09999999999995, 40.0000000000003, 85.20000000000019, 89.29999999999988, 40.0000000000003, 207.99999999999932, 40.0000000000003, 199.99999999999935, 298.2999999999997, 40.0000000000003, 31.200000000000166, 40.0000000000003, 322.6000000000013, 193.5999999999994, 164.99999999999955, 111.09999999999869, 248.49999999999937, 40.0000000000003, 40.0000000000003, 40.0000000000003, 229.70000000000002, 157.89999999999955, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [149.0, 20.000000000000014, 20.000000000000014, 73.09999999999997, 20.000000000000014, 136.1, 20.000000000000014, 118.09999999999997, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, -99.70000000000081, 20.000000000000014, 63.19999999999996, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.50000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 116.29999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, -98.50000000000063, 41.59999999999998, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 146.29999999999998, 20.000000000000014, 93.79999999999933, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.3, 71.90000000000012, 20.000000000000014, 16.099999999999962, 81.19999999999996, 200.0, 200.0, -3.0999999999999757, 51.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999955, 200.0, 137.8999999999996, 136.1, 20.000000000000014, 20.000000000000014, 11.599999999999964, 146.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 82.99999999999997, 165.5, 13.699999999999964, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -17.799999999999756, 20.000000000000014, 149.59999999999974, 58.70000000000022, 20.000000000000014, 200.0, 11.000000000000183, 20.000000000000014, 2.8999999999999866, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999881, 114.49999999999946, 129.79999999999998, 56.900000000000226, 55.09999999999996, 20.000000000000014, 9.499999999999964, 23.000000000000064, 9.499999999999973, 108.80000000000001, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.89999999999997, 20.000000000000014, 67.69999999999992, -21.99999999999975, 200.0, 20.000000000000014, 9.49999999999997, 11.599999999999964, 4.099999999999966, 20.000000000000014, 20.000000000000014, -137.5000000000007, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 133.39999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.200000000000035, 170.0, 17.899999999999988, 54.200000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 50.89999999999972, 20.000000000000014, 151.39999999999998, 1.0999999999999865, 184.7, 20.000000000000014, 20.000000000000014, 82.09999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 49.10000000000011, 80.29999999999997, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 98.29999999999998, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 122.59999999999951, 200.0, -30.39999999999977, 200.0, -85.00000000000085, 100.99999999999937, 1.0999999999999723, 69.49999999999976, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.5, 69.2, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [10.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.0, 57.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 38.0, 65.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 10.0, 15.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 10.0, 9.0, 0.0, 9.0, 0.0, 0.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 13.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 5.0, 0.0, 9.0, 0.0, 0.0, 75.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 1.0, 24.0, 0.0, 0.0, 0.0, 0.0, 35.0, 1.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 9.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 50.0, 0.0, 9.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3179521531847649, "mean_inference_ms": 3.633048789947361, "mean_action_processing_ms": 0.5854531867866009, "mean_env_wait_ms": 0.44345003413304984, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005347847938537598, "StateBufferConnector_ms": 0.004368305206298828, "ViewRequirementAgentConnector_ms": 0.1890469789505005}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -44.700000000000024, "episode_return_mean": 120.82099999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 277.6260647621767, "num_env_steps_trained_throughput_per_sec": 277.6260647621767, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 12878.556, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12878.483, "sample_time_ms": 1975.588, "learn_time_ms": 10886.594, "learn_throughput": 367.424, "synch_weights_time_ms": 14.855}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "e57b0_00000", "date": "2024-08-13_00-33-26", "timestamp": 1723523606, "time_this_iter_s": 14.46181583404541, "time_total_s": 1378.0109231472015, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b71a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1378.0109231472015, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 63.63333333333333, "ram_util_percent": 80.75238095238095}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3668217926429063, "cur_kl_coeff": 9.945324563886967e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.592383187410062, "policy_loss": -0.000547906702689866, "vf_loss": 4.592931090082441, "vf_explained_var": 0.3584152017636274, "kl": 0.0031623335261983646, "entropy": 0.36919986009597777, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3749027368676647, "cur_kl_coeff": 9.77665185928345e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.12138054885867017, "policy_loss": -0.0009000369000233829, "vf_loss": 0.12228050661060334, "vf_explained_var": -0.07376172675026788, "kl": 0.008101596236628735, "entropy": 0.953598520553932, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -44.700000000000024, "episode_reward_mean": 129.10599999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -137.5000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 75.0}, "policy_reward_mean": {"prey_policy": 60.592999999999975, "predator_policy": 3.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, 33.400000000000205, 40.0000000000003, 207.99999999999932, 46.1, 207.99999999999932, 40.0000000000003, 219.99999999999926, 174.29999999999947, 113.79999999999859, 40.0000000000003, 170.2999999999995, 110.89999999999978, 119.29999999999981, 400.0, 59.40000000000007, 40.0000000000003, 40.0000000000003, 273.0999999999996, 274.00000000000006, 40.0000000000003, 170.59999999999948, 219.99999999999926, 40.0000000000003, 102.99999999999994, 183.19999999999945, 219.99999999999926, 40.0000000000003, 200.19999999999936, 172.59999999999903, 78.69999999999943, 229.99999999999946, 31.900000000000144, 40.0000000000003, 209.9999999999993, 244.29999999999941, 111.99999999999979, 38.50000000000028, 45.5000000000004, 287.3000000000005, 40.0000000000003, 67.90000000000023, 87.69999999999872, 197.99999999999937, 34.50000000000022, 24.70000000000005, 40.0000000000003, -44.700000000000024, 31.200000000000166, 153.39999999999884, 40.0000000000003, 191.19999999999945, 97.09999999999985, 40.0000000000003, 40.0000000000003, 283.90000000000003, 177.39999999999947, 194.7999999999994, 40.0000000000003, 102.09999999999995, 40.0000000000003, 85.20000000000019, 89.29999999999988, 40.0000000000003, 207.99999999999932, 40.0000000000003, 199.99999999999935, 298.2999999999997, 40.0000000000003, 31.200000000000166, 40.0000000000003, 322.6000000000013, 193.5999999999994, 164.99999999999955, 111.09999999999869, 248.49999999999937, 40.0000000000003, 40.0000000000003, 40.0000000000003, 229.70000000000002, 157.89999999999955, 40.0000000000003, 40.0000000000003, 283.30000000000007, 219.99999999999926, 36.70000000000025, 219.99999999999926, 219.99999999999926, 224.49999999999923, 199.99999999999935, 27.600000000000104, 389.0, 110.19999999999989, 40.0000000000003, 400.0, 213.49999999999926, 124.59999999999866, 40.0000000000003, 197.59999999999937, 33.3000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 5.299999999999965, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, -98.50000000000063, 41.59999999999998, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 146.29999999999998, 20.000000000000014, 93.79999999999933, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.3, 71.90000000000012, 20.000000000000014, 16.099999999999962, 81.19999999999996, 200.0, 200.0, -3.0999999999999757, 51.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999955, 200.0, 137.8999999999996, 136.1, 20.000000000000014, 20.000000000000014, 11.599999999999964, 146.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 82.99999999999997, 165.5, 13.699999999999964, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -17.799999999999756, 20.000000000000014, 149.59999999999974, 58.70000000000022, 20.000000000000014, 200.0, 11.000000000000183, 20.000000000000014, 2.8999999999999866, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999881, 114.49999999999946, 129.79999999999998, 56.900000000000226, 55.09999999999996, 20.000000000000014, 9.499999999999964, 23.000000000000064, 9.499999999999973, 108.80000000000001, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.89999999999997, 20.000000000000014, 67.69999999999992, -21.99999999999975, 200.0, 20.000000000000014, 9.49999999999997, 11.599999999999964, 4.099999999999966, 20.000000000000014, 20.000000000000014, -137.5000000000007, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 133.39999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.200000000000035, 170.0, 17.899999999999988, 54.200000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 50.89999999999972, 20.000000000000014, 151.39999999999998, 1.0999999999999865, 184.7, 20.000000000000014, 20.000000000000014, 82.09999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 49.10000000000011, 80.29999999999997, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 98.29999999999998, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 122.59999999999951, 200.0, -30.39999999999977, 200.0, -85.00000000000085, 100.99999999999937, 1.0999999999999723, 69.49999999999976, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.5, 69.2, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 95.29999999999941, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 24.50000000000008, 200.0, 170.0, 20.000000000000014, 20.000000000000014, -9.399999999999855, 197.0, 188.0, 20.000000000000014, 90.19999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 170.0, 33.500000000000234, 20.000000000000014, 104.5999999999994, 20.000000000000014, 20.000000000000014, 11.599999999999964, 173.0, 20.000000000000014, 5.299999999999965], "policy_predator_policy_reward": [0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 38.0, 65.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 10.0, 15.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 10.0, 9.0, 0.0, 9.0, 0.0, 0.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 13.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 5.0, 0.0, 9.0, 0.0, 0.0, 75.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 1.0, 24.0, 0.0, 0.0, 0.0, 0.0, 35.0, 1.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 9.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 50.0, 0.0, 9.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 7.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.312103776414916, "mean_inference_ms": 3.6200581261893445, "mean_action_processing_ms": 0.5825504885610695, "mean_env_wait_ms": 0.44132795003495245, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054198503494262695, "StateBufferConnector_ms": 0.004302501678466797, "ViewRequirementAgentConnector_ms": 0.16663849353790283}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -44.700000000000024, "episode_return_mean": 129.10599999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.46913273328386, "num_env_steps_trained_throughput_per_sec": 311.46913273328386, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 12777.678, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12777.606, "sample_time_ms": 1980.44, "learn_time_ms": 10778.435, "learn_throughput": 371.111, "synch_weights_time_ms": 17.182}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "e57b0_00000", "date": "2024-08-13_00-33-39", "timestamp": 1723523619, "time_this_iter_s": 12.908501863479614, "time_total_s": 1390.9194250106812, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0b5cca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1390.9194250106812, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 53.71666666666666, "ram_util_percent": 81.03333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2767066920205714, "cur_kl_coeff": 4.9726622819434836e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.520391488201404, "policy_loss": -0.0010023122463651277, "vf_loss": 4.521393788554681, "vf_explained_var": 0.255495527560118, "kl": 0.0008699904139059262, "entropy": 0.3622458304046954, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8885931677603848, "cur_kl_coeff": 9.77665185928345e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3314267221069525, "policy_loss": -0.0015609745613777292, "vf_loss": 0.33298759892742735, "vf_explained_var": -0.005888172432228371, "kl": 0.009909106658965385, "entropy": 0.9100363941735061, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -60.10000000000088, "episode_reward_mean": 136.99999999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.10000000000056, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 91.0}, "policy_reward_mean": {"prey_policy": 64.47499999999997, "predator_policy": 4.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 40.0000000000003, 102.99999999999994, 183.19999999999945, 219.99999999999926, 40.0000000000003, 200.19999999999936, 172.59999999999903, 78.69999999999943, 229.99999999999946, 31.900000000000144, 40.0000000000003, 209.9999999999993, 244.29999999999941, 111.99999999999979, 38.50000000000028, 45.5000000000004, 287.3000000000005, 40.0000000000003, 67.90000000000023, 87.69999999999872, 197.99999999999937, 34.50000000000022, 24.70000000000005, 40.0000000000003, -44.700000000000024, 31.200000000000166, 153.39999999999884, 40.0000000000003, 191.19999999999945, 97.09999999999985, 40.0000000000003, 40.0000000000003, 283.90000000000003, 177.39999999999947, 194.7999999999994, 40.0000000000003, 102.09999999999995, 40.0000000000003, 85.20000000000019, 89.29999999999988, 40.0000000000003, 207.99999999999932, 40.0000000000003, 199.99999999999935, 298.2999999999997, 40.0000000000003, 31.200000000000166, 40.0000000000003, 322.6000000000013, 193.5999999999994, 164.99999999999955, 111.09999999999869, 248.49999999999937, 40.0000000000003, 40.0000000000003, 40.0000000000003, 229.70000000000002, 157.89999999999955, 40.0000000000003, 40.0000000000003, 283.30000000000007, 219.99999999999926, 36.70000000000025, 219.99999999999926, 219.99999999999926, 224.49999999999923, 199.99999999999935, 27.600000000000104, 389.0, 110.19999999999989, 40.0000000000003, 400.0, 213.49999999999926, 124.59999999999866, 40.0000000000003, 197.59999999999937, 33.3000000000002, 282.50000000000017, 175.9999999999995, 36.50000000000025, 125.4999999999992, 40.0000000000003, 122.39999999999917, 249.49999999999966, -60.10000000000088, 219.99999999999926, 96.49999999999986, 334.3000000000016, 356.79999999999984, 79.79999999999926, 197.99999999999937, 32.30000000000018, 55.300000000000495, 228.6999999999994, 219.99999999999926, 400.0, 219.99999999999926, 40.0000000000003, 188.8999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 82.99999999999997, 165.5, 13.699999999999964, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -17.799999999999756, 20.000000000000014, 149.59999999999974, 58.70000000000022, 20.000000000000014, 200.0, 11.000000000000183, 20.000000000000014, 2.8999999999999866, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999881, 114.49999999999946, 129.79999999999998, 56.900000000000226, 55.09999999999996, 20.000000000000014, 9.499999999999964, 23.000000000000064, 9.499999999999973, 108.80000000000001, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.89999999999997, 20.000000000000014, 67.69999999999992, -21.99999999999975, 200.0, 20.000000000000014, 9.49999999999997, 11.599999999999964, 4.099999999999966, 20.000000000000014, 20.000000000000014, -137.5000000000007, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 133.39999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.200000000000035, 170.0, 17.899999999999988, 54.200000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 50.89999999999972, 20.000000000000014, 151.39999999999998, 1.0999999999999865, 184.7, 20.000000000000014, 20.000000000000014, 82.09999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 49.10000000000011, 80.29999999999997, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 98.29999999999998, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 122.59999999999951, 200.0, -30.39999999999977, 200.0, -85.00000000000085, 100.99999999999937, 1.0999999999999723, 69.49999999999976, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.5, 69.2, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 95.29999999999941, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 24.50000000000008, 200.0, 170.0, 20.000000000000014, 20.000000000000014, -9.399999999999855, 197.0, 188.0, 20.000000000000014, 90.19999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 170.0, 33.500000000000234, 20.000000000000014, 104.5999999999994, 20.000000000000014, 20.000000000000014, 11.599999999999964, 173.0, 20.000000000000014, 5.299999999999965, 170.0, 102.49999999999946, -64.00000000000072, 200.0, 12.499999999999964, 20.000000000000014, 20.000000000000014, 105.49999999999972, 20.000000000000014, 20.000000000000014, -3.099999999999965, 114.49999999999969, 112.39999999999964, 127.1, -171.10000000000056, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 66.50000000000003, 134.29999999999959, 200.0, 156.80000000000004, 200.0, 57.50000000000017, 5.2999999999999705, 20.000000000000014, 167.0, 5.299999999999965, 20.000000000000014, 20.000000000000014, 35.300000000000246, 22.69999999999997, 200.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, -13.599999999999783, 186.5], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 3.0, 0.0, 0.0, 10.0, 9.0, 0.0, 9.0, 0.0, 0.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 13.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 5.0, 0.0, 9.0, 0.0, 0.0, 75.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 1.0, 24.0, 0.0, 0.0, 0.0, 0.0, 35.0, 1.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 9.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 50.0, 0.0, 9.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 7.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 7.0, 0.0, 10.0, 0.0, 40.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 91.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3064565828276344, "mean_inference_ms": 3.6016926587459945, "mean_action_processing_ms": 0.5791618844573964, "mean_env_wait_ms": 0.43923076404351347, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006102919578552246, "StateBufferConnector_ms": 0.004220366477966309, "ViewRequirementAgentConnector_ms": 0.16202116012573242}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -60.10000000000088, "episode_return_mean": 136.99999999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.0664700683821, "num_env_steps_trained_throughput_per_sec": 334.0664700683821, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 12263.086, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12263.04, "sample_time_ms": 1829.54, "learn_time_ms": 10414.482, "learn_throughput": 384.081, "synch_weights_time_ms": 17.403}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "e57b0_00000", "date": "2024-08-13_00-33-51", "timestamp": 1723523631, "time_this_iter_s": 12.03349781036377, "time_total_s": 1402.952922821045, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b127fd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1402.952922821045, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 50.45294117647059, "ram_util_percent": 81.27058823529411}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4873364022287427, "cur_kl_coeff": 2.4863311409717418e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.453264891659772, "policy_loss": -0.000936769323408722, "vf_loss": 5.454201674839807, "vf_explained_var": 0.23654567633987103, "kl": 0.0026954876957398575, "entropy": 0.32473796561123836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0160938126641132, "cur_kl_coeff": 9.77665185928345e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4407571883507507, "policy_loss": -0.0011029337333249194, "vf_loss": 0.44186007373808595, "vf_explained_var": 0.0008024945460930072, "kl": 0.004895689682956181, "entropy": 0.8930611373570861, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -60.10000000000088, "episode_reward_mean": 144.1379999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -250.90000000000038, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 129.0}, "policy_reward_mean": {"prey_policy": 67.27399999999996, "predator_policy": 4.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 67.90000000000023, 87.69999999999872, 197.99999999999937, 34.50000000000022, 24.70000000000005, 40.0000000000003, -44.700000000000024, 31.200000000000166, 153.39999999999884, 40.0000000000003, 191.19999999999945, 97.09999999999985, 40.0000000000003, 40.0000000000003, 283.90000000000003, 177.39999999999947, 194.7999999999994, 40.0000000000003, 102.09999999999995, 40.0000000000003, 85.20000000000019, 89.29999999999988, 40.0000000000003, 207.99999999999932, 40.0000000000003, 199.99999999999935, 298.2999999999997, 40.0000000000003, 31.200000000000166, 40.0000000000003, 322.6000000000013, 193.5999999999994, 164.99999999999955, 111.09999999999869, 248.49999999999937, 40.0000000000003, 40.0000000000003, 40.0000000000003, 229.70000000000002, 157.89999999999955, 40.0000000000003, 40.0000000000003, 283.30000000000007, 219.99999999999926, 36.70000000000025, 219.99999999999926, 219.99999999999926, 224.49999999999923, 199.99999999999935, 27.600000000000104, 389.0, 110.19999999999989, 40.0000000000003, 400.0, 213.49999999999926, 124.59999999999866, 40.0000000000003, 197.59999999999937, 33.3000000000002, 282.50000000000017, 175.9999999999995, 36.50000000000025, 125.4999999999992, 40.0000000000003, 122.39999999999917, 249.49999999999966, -60.10000000000088, 219.99999999999926, 96.49999999999986, 334.3000000000016, 356.79999999999984, 79.79999999999926, 197.99999999999937, 32.30000000000018, 55.300000000000495, 228.6999999999994, 219.99999999999926, 400.0, 219.99999999999926, 40.0000000000003, 188.8999999999994, 40.0000000000003, 78.1, 33.400000000000205, 360.0, -14.999999999999543, 176.39999999999947, 236.19999999999985, 311.79999999999984, 219.99999999999926, 203.99999999999935, 276.99999999999966, 208.99999999999932, 400.0, 219.99999999999926, 40.0000000000003, 219.99999999999926, 10.000000000000089, 190.0999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 47.89999999999997, 20.000000000000014, 67.69999999999992, -21.99999999999975, 200.0, 20.000000000000014, 9.49999999999997, 11.599999999999964, 4.099999999999966, 20.000000000000014, 20.000000000000014, -137.5000000000007, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 133.39999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 6.200000000000035, 170.0, 17.899999999999988, 54.200000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 197.0, 50.89999999999972, 20.000000000000014, 151.39999999999998, 1.0999999999999865, 184.7, 20.000000000000014, 20.000000000000014, 82.09999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 49.10000000000011, 80.29999999999997, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 98.29999999999998, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 122.59999999999951, 200.0, -30.39999999999977, 200.0, -85.00000000000085, 100.99999999999937, 1.0999999999999723, 69.49999999999976, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.5, 69.2, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 95.29999999999941, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 24.50000000000008, 200.0, 170.0, 20.000000000000014, 20.000000000000014, -9.399999999999855, 197.0, 188.0, 20.000000000000014, 90.19999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 170.0, 33.500000000000234, 20.000000000000014, 104.5999999999994, 20.000000000000014, 20.000000000000014, 11.599999999999964, 173.0, 20.000000000000014, 5.299999999999965, 170.0, 102.49999999999946, -64.00000000000072, 200.0, 12.499999999999964, 20.000000000000014, 20.000000000000014, 105.49999999999972, 20.000000000000014, 20.000000000000014, -3.099999999999965, 114.49999999999969, 112.39999999999964, 127.1, -171.10000000000056, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 66.50000000000003, 134.29999999999959, 200.0, 156.80000000000004, 200.0, 57.50000000000017, 5.2999999999999705, 20.000000000000014, 167.0, 5.299999999999965, 20.000000000000014, 20.000000000000014, 35.300000000000246, 22.69999999999997, 200.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, -13.599999999999783, 186.5, 20.000000000000014, 20.000000000000014, -250.90000000000038, 200.0, 20.000000000000014, 7.399999999999965, 200.0, 140.0, 9.499999999999964, -74.50000000000087, 20.000000000000014, 145.40000000000003, 146.9, 80.29999999999998, 200.0, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 176.0, 191.0, 82.99999999999997, 200.0, -0.9999999999999992, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999917, -0.9999999999999952, 160.1, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 5.0, 0.0, 9.0, 0.0, 0.0, 75.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 1.0, 24.0, 0.0, 0.0, 0.0, 0.0, 35.0, 1.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 9.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 50.0, 0.0, 9.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 7.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 7.0, 0.0, 10.0, 0.0, 40.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 91.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 129.0, 0.0, 6.0, 0.0, 10.0, 10.0, 45.0, 5.0, 1.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3003760960921968, "mean_inference_ms": 3.594182394310307, "mean_action_processing_ms": 0.5767505049234449, "mean_env_wait_ms": 0.4371265247264992, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00742185115814209, "StateBufferConnector_ms": 0.0043964385986328125, "ViewRequirementAgentConnector_ms": 0.17769575119018555}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -60.10000000000088, "episode_return_mean": 144.1379999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.43754023230906, "num_env_steps_trained_throughput_per_sec": 306.43754023230906, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 12468.948, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12468.902, "sample_time_ms": 1890.722, "learn_time_ms": 10558.516, "learn_throughput": 378.841, "synch_weights_time_ms": 17.977}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "e57b0_00000", "date": "2024-08-13_00-34-04", "timestamp": 1723523644, "time_this_iter_s": 13.091325998306274, "time_total_s": 1416.0442488193512, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b155c820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1416.0442488193512, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 54.084210526315786, "ram_util_percent": 81.31052631578946}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.55552196623314, "cur_kl_coeff": 1.2431655704858709e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.960160259468846, "policy_loss": 0.00011906005373155629, "vf_loss": 4.960041188436842, "vf_explained_var": 0.36970367548326966, "kl": 0.002515612517671805, "entropy": 0.3466947692254233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.39750257092946895, "cur_kl_coeff": 4.888325929641725e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18073477439998734, "policy_loss": -0.00010695637292450383, "vf_loss": 0.18084171614651234, "vf_explained_var": -0.017437258283927958, "kl": 0.0031275623600629187, "entropy": 0.8612063881896791, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -60.10000000000088, "episode_reward_mean": 168.29599999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -250.90000000000038, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 129.0}, "policy_reward_mean": {"prey_policy": 79.97299999999997, "predator_policy": 4.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 207.99999999999932, 40.0000000000003, 199.99999999999935, 298.2999999999997, 40.0000000000003, 31.200000000000166, 40.0000000000003, 322.6000000000013, 193.5999999999994, 164.99999999999955, 111.09999999999869, 248.49999999999937, 40.0000000000003, 40.0000000000003, 40.0000000000003, 229.70000000000002, 157.89999999999955, 40.0000000000003, 40.0000000000003, 283.30000000000007, 219.99999999999926, 36.70000000000025, 219.99999999999926, 219.99999999999926, 224.49999999999923, 199.99999999999935, 27.600000000000104, 389.0, 110.19999999999989, 40.0000000000003, 400.0, 213.49999999999926, 124.59999999999866, 40.0000000000003, 197.59999999999937, 33.3000000000002, 282.50000000000017, 175.9999999999995, 36.50000000000025, 125.4999999999992, 40.0000000000003, 122.39999999999917, 249.49999999999966, -60.10000000000088, 219.99999999999926, 96.49999999999986, 334.3000000000016, 356.79999999999984, 79.79999999999926, 197.99999999999937, 32.30000000000018, 55.300000000000495, 228.6999999999994, 219.99999999999926, 400.0, 219.99999999999926, 40.0000000000003, 188.8999999999994, 40.0000000000003, 78.1, 33.400000000000205, 360.0, -14.999999999999543, 176.39999999999947, 236.19999999999985, 311.79999999999984, 219.99999999999926, 203.99999999999935, 276.99999999999966, 208.99999999999932, 400.0, 219.99999999999926, 40.0000000000003, 219.99999999999926, 10.000000000000089, 190.0999999999994, 219.99999999999926, 217.29999999999927, 400.0, 264.9, 199.99999999999935, 215.99999999999926, 271.29999999999956, 128.19999999999973, 219.99999999999926, 394.6, 40.0000000000003, 151.39999999999904, 145.29999999999964, 219.99999999999926, 307.1000000000006, 40.0000000000003, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 51.70000000000017, 187.59999999999906, 94.10000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 98.29999999999998, 200.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 122.59999999999951, 200.0, -30.39999999999977, 200.0, -85.00000000000085, 100.99999999999937, 1.0999999999999723, 69.49999999999976, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.5, 69.2, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 95.29999999999941, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 24.50000000000008, 200.0, 170.0, 20.000000000000014, 20.000000000000014, -9.399999999999855, 197.0, 188.0, 20.000000000000014, 90.19999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 170.0, 33.500000000000234, 20.000000000000014, 104.5999999999994, 20.000000000000014, 20.000000000000014, 11.599999999999964, 173.0, 20.000000000000014, 5.299999999999965, 170.0, 102.49999999999946, -64.00000000000072, 200.0, 12.499999999999964, 20.000000000000014, 20.000000000000014, 105.49999999999972, 20.000000000000014, 20.000000000000014, -3.099999999999965, 114.49999999999969, 112.39999999999964, 127.1, -171.10000000000056, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 66.50000000000003, 134.29999999999959, 200.0, 156.80000000000004, 200.0, 57.50000000000017, 5.2999999999999705, 20.000000000000014, 167.0, 5.299999999999965, 20.000000000000014, 20.000000000000014, 35.300000000000246, 22.69999999999997, 200.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, -13.599999999999783, 186.5, 20.000000000000014, 20.000000000000014, -250.90000000000038, 200.0, 20.000000000000014, 7.399999999999965, 200.0, 140.0, 9.499999999999964, -74.50000000000087, 20.000000000000014, 145.40000000000003, 146.9, 80.29999999999998, 200.0, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 176.0, 191.0, 82.99999999999997, 200.0, -0.9999999999999992, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999917, -0.9999999999999952, 160.1, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, 170.0, 77.90000000000006, 20.000000000000014, 170.0, 194.0, 20.000000000000014, 71.29999999999968, 200.0, 108.19999999999999, 20.000000000000014, 20.000000000000014, 200.0, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 121.40000000000008, 20.000000000000014, 101.30000000000004, 20.000000000000014, 200.0, 127.09999999999985, 170.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 18.200000000000195, 18.49999999999996, 167.5999999999998, 20.000000000000014, 43.10000000000009, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 50.0, 0.0, 9.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 7.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 7.0, 0.0, 10.0, 0.0, 40.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 91.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 129.0, 0.0, 6.0, 0.0, 10.0, 10.0, 45.0, 5.0, 1.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 17.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 13.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 31.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2969766035791321, "mean_inference_ms": 3.5881779522824235, "mean_action_processing_ms": 0.5749485941693037, "mean_env_wait_ms": 0.4358186122880451, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00811147689819336, "StateBufferConnector_ms": 0.00455784797668457, "ViewRequirementAgentConnector_ms": 0.18963241577148438}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -60.10000000000088, "episode_return_mean": 168.29599999999976, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.42168217484584, "num_env_steps_trained_throughput_per_sec": 310.42168217484584, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 12586.646, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12586.598, "sample_time_ms": 1909.679, "learn_time_ms": 10646.786, "learn_throughput": 375.7, "synch_weights_time_ms": 27.207}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "e57b0_00000", "date": "2024-08-13_00-34-18", "timestamp": 1723523658, "time_this_iter_s": 13.227385997772217, "time_total_s": 1429.2716348171234, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b15835e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1429.2716348171234, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 56.199999999999996, "ram_util_percent": 82.00526315789475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.678217492276241, "cur_kl_coeff": 6.2158278524293545e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.982489594580636, "policy_loss": -0.00022976614125861378, "vf_loss": 4.982719359196052, "vf_explained_var": 0.3734497410279733, "kl": 0.004367981330103303, "entropy": 0.4490894091350061, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.909840592249203, "cur_kl_coeff": 2.4441629648208623e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4890032433249332, "policy_loss": -0.0020296272661576354, "vf_loss": 0.49103285607921265, "vf_explained_var": 0.005041222786777234, "kl": 0.007806256458758515, "entropy": 0.8143037645274369, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -60.10000000000088, "episode_reward_mean": 174.7599999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -250.90000000000038, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 129.0}, "policy_reward_mean": {"prey_policy": 83.34499999999997, "predator_policy": 4.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, 283.30000000000007, 219.99999999999926, 36.70000000000025, 219.99999999999926, 219.99999999999926, 224.49999999999923, 199.99999999999935, 27.600000000000104, 389.0, 110.19999999999989, 40.0000000000003, 400.0, 213.49999999999926, 124.59999999999866, 40.0000000000003, 197.59999999999937, 33.3000000000002, 282.50000000000017, 175.9999999999995, 36.50000000000025, 125.4999999999992, 40.0000000000003, 122.39999999999917, 249.49999999999966, -60.10000000000088, 219.99999999999926, 96.49999999999986, 334.3000000000016, 356.79999999999984, 79.79999999999926, 197.99999999999937, 32.30000000000018, 55.300000000000495, 228.6999999999994, 219.99999999999926, 400.0, 219.99999999999926, 40.0000000000003, 188.8999999999994, 40.0000000000003, 78.1, 33.400000000000205, 360.0, -14.999999999999543, 176.39999999999947, 236.19999999999985, 311.79999999999984, 219.99999999999926, 203.99999999999935, 276.99999999999966, 208.99999999999932, 400.0, 219.99999999999926, 40.0000000000003, 219.99999999999926, 10.000000000000089, 190.0999999999994, 219.99999999999926, 217.29999999999927, 400.0, 264.9, 199.99999999999935, 215.99999999999926, 271.29999999999956, 128.19999999999973, 219.99999999999926, 394.6, 40.0000000000003, 151.39999999999904, 145.29999999999964, 219.99999999999926, 307.1000000000006, 40.0000000000003, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 51.70000000000017, 187.59999999999906, 94.10000000000005, 300.80000000000064, 135.3999999999997, 119.19999999999982, 15.30000000000002, 40.0000000000003, 211.9999999999993, 390.0, 165.0999999999995, 219.99999999999926, 203.7999999999994, 329.8000000000015, 199.99999999999935, 211.9999999999993, 105.2999999999999, 200.09999999999937, 117.39999999999975, 31.200000000000166, 94.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 95.29999999999941, 182.0, 20.000000000000014, 200.0, 20.000000000000014, 13.699999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 24.50000000000008, 200.0, 170.0, 20.000000000000014, 20.000000000000014, -9.399999999999855, 197.0, 188.0, 20.000000000000014, 90.19999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 170.0, 33.500000000000234, 20.000000000000014, 104.5999999999994, 20.000000000000014, 20.000000000000014, 11.599999999999964, 173.0, 20.000000000000014, 5.299999999999965, 170.0, 102.49999999999946, -64.00000000000072, 200.0, 12.499999999999964, 20.000000000000014, 20.000000000000014, 105.49999999999972, 20.000000000000014, 20.000000000000014, -3.099999999999965, 114.49999999999969, 112.39999999999964, 127.1, -171.10000000000056, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 66.50000000000003, 134.29999999999959, 200.0, 156.80000000000004, 200.0, 57.50000000000017, 5.2999999999999705, 20.000000000000014, 167.0, 5.299999999999965, 20.000000000000014, 20.000000000000014, 35.300000000000246, 22.69999999999997, 200.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, -13.599999999999783, 186.5, 20.000000000000014, 20.000000000000014, -250.90000000000038, 200.0, 20.000000000000014, 7.399999999999965, 200.0, 140.0, 9.499999999999964, -74.50000000000087, 20.000000000000014, 145.40000000000003, 146.9, 80.29999999999998, 200.0, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 176.0, 191.0, 82.99999999999997, 200.0, -0.9999999999999992, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999917, -0.9999999999999952, 160.1, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, 170.0, 77.90000000000006, 20.000000000000014, 170.0, 194.0, 20.000000000000014, 71.29999999999968, 200.0, 108.19999999999999, 20.000000000000014, 20.000000000000014, 200.0, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 121.40000000000008, 20.000000000000014, 101.30000000000004, 20.000000000000014, 200.0, 127.09999999999985, 170.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 18.200000000000195, 18.49999999999996, 167.5999999999998, 20.000000000000014, 43.10000000000009, 20.000000000000014, 170.0, 120.7999999999995, 20.000000000000014, 115.39999999999998, 99.19999999999997, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 191.0, 194.0, 20.000000000000014, 145.1, 20.000000000000014, 200.0, 178.4, 25.400000000000006, 200.0, 129.79999999999956, 170.0, 20.000000000000014, 188.0, 20.000000000000014, 56.300000000000054, 20.000000000000014, 20.000000000000014, 175.1, 20.000000000000014, 79.40000000000009, 3.1999999999999615, 20.000000000000014, 74.89999999999996, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 7.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 7.0, 0.0, 10.0, 0.0, 40.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 91.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 129.0, 0.0, 6.0, 0.0, 10.0, 10.0, 45.0, 5.0, 1.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 17.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 13.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 29.0, 0.0, 5.0, 0.0, 0.0, 18.0, 0.0, 8.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2917975541724442, "mean_inference_ms": 3.5760277467830788, "mean_action_processing_ms": 0.5720916035792969, "mean_env_wait_ms": 0.4339945620931682, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01014101505279541, "StateBufferConnector_ms": 0.007582545280456543, "ViewRequirementAgentConnector_ms": 0.18364059925079346}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -60.10000000000088, "episode_return_mean": 174.7599999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 188.30130069438255, "num_env_steps_trained_throughput_per_sec": 188.30130069438255, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 13562.091, "restore_workers_time_ms": 0.027, "training_step_time_ms": 13561.938, "sample_time_ms": 2178.856, "learn_time_ms": 11353.561, "learn_throughput": 352.312, "synch_weights_time_ms": 26.541}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "e57b0_00000", "date": "2024-08-13_00-34-39", "timestamp": 1723523679, "time_this_iter_s": 21.264885902404785, "time_total_s": 1450.5365207195282, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b155c700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1450.5365207195282, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 91.74, "ram_util_percent": 83.49666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.999159664104855, "cur_kl_coeff": 3.1079139262146772e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.96238543659291, "policy_loss": 0.0007187362942627813, "vf_loss": 4.961666698809023, "vf_explained_var": 0.2615838626705149, "kl": 0.001929422175228139, "entropy": 0.49929288907971964, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5931467963096799, "cur_kl_coeff": 2.4441629648208623e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.677844309002634, "policy_loss": -0.001715338770447979, "vf_loss": 0.6795596315757071, "vf_explained_var": 0.0005292364213832472, "kl": 0.009426665790677677, "entropy": 0.6269742666728912, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -132.5000000000009, "episode_reward_mean": 168.12699999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -250.90000000000038, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 129.0}, "policy_reward_mean": {"prey_policy": 78.34849999999997, "predator_policy": 5.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.3000000000002, 282.50000000000017, 175.9999999999995, 36.50000000000025, 125.4999999999992, 40.0000000000003, 122.39999999999917, 249.49999999999966, -60.10000000000088, 219.99999999999926, 96.49999999999986, 334.3000000000016, 356.79999999999984, 79.79999999999926, 197.99999999999937, 32.30000000000018, 55.300000000000495, 228.6999999999994, 219.99999999999926, 400.0, 219.99999999999926, 40.0000000000003, 188.8999999999994, 40.0000000000003, 78.1, 33.400000000000205, 360.0, -14.999999999999543, 176.39999999999947, 236.19999999999985, 311.79999999999984, 219.99999999999926, 203.99999999999935, 276.99999999999966, 208.99999999999932, 400.0, 219.99999999999926, 40.0000000000003, 219.99999999999926, 10.000000000000089, 190.0999999999994, 219.99999999999926, 217.29999999999927, 400.0, 264.9, 199.99999999999935, 215.99999999999926, 271.29999999999956, 128.19999999999973, 219.99999999999926, 394.6, 40.0000000000003, 151.39999999999904, 145.29999999999964, 219.99999999999926, 307.1000000000006, 40.0000000000003, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 51.70000000000017, 187.59999999999906, 94.10000000000005, 300.80000000000064, 135.3999999999997, 119.19999999999982, 15.30000000000002, 40.0000000000003, 211.9999999999993, 390.0, 165.0999999999995, 219.99999999999926, 203.7999999999994, 329.8000000000015, 199.99999999999935, 211.9999999999993, 105.2999999999999, 200.09999999999937, 117.39999999999975, 31.200000000000166, 94.9, 102.89999999999992, 27.900000000000123, 31.200000000000166, 99.69999999999983, 40.0000000000003, 40.0000000000003, 190.70000000000007, 123.69999999999979, 199.99999999999935, -132.5000000000009, 362.20000000000005, 107.4999999999998, 400.0, 163.29999999999953, 211.40000000000003, 15.600000000000133, 340.1, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 5.299999999999965, 170.0, 102.49999999999946, -64.00000000000072, 200.0, 12.499999999999964, 20.000000000000014, 20.000000000000014, 105.49999999999972, 20.000000000000014, 20.000000000000014, -3.099999999999965, 114.49999999999969, 112.39999999999964, 127.1, -171.10000000000056, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 66.50000000000003, 134.29999999999959, 200.0, 156.80000000000004, 200.0, 57.50000000000017, 5.2999999999999705, 20.000000000000014, 167.0, 5.299999999999965, 20.000000000000014, 20.000000000000014, 35.300000000000246, 22.69999999999997, 200.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, -13.599999999999783, 186.5, 20.000000000000014, 20.000000000000014, -250.90000000000038, 200.0, 20.000000000000014, 7.399999999999965, 200.0, 140.0, 9.499999999999964, -74.50000000000087, 20.000000000000014, 145.40000000000003, 146.9, 80.29999999999998, 200.0, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 176.0, 191.0, 82.99999999999997, 200.0, -0.9999999999999992, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999917, -0.9999999999999952, 160.1, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, 170.0, 77.90000000000006, 20.000000000000014, 170.0, 194.0, 20.000000000000014, 71.29999999999968, 200.0, 108.19999999999999, 20.000000000000014, 20.000000000000014, 200.0, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 121.40000000000008, 20.000000000000014, 101.30000000000004, 20.000000000000014, 200.0, 127.09999999999985, 170.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 18.200000000000195, 18.49999999999996, 167.5999999999998, 20.000000000000014, 43.10000000000009, 20.000000000000014, 170.0, 120.7999999999995, 20.000000000000014, 115.39999999999998, 99.19999999999997, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 191.0, 194.0, 20.000000000000014, 145.1, 20.000000000000014, 200.0, 178.4, 25.400000000000006, 200.0, 129.79999999999956, 170.0, 20.000000000000014, 188.0, 20.000000000000014, 56.300000000000054, 20.000000000000014, 20.000000000000014, 175.1, 20.000000000000014, 79.40000000000009, 3.1999999999999615, 20.000000000000014, 74.89999999999996, 20.000000000000014, 97.40000000000003, -53.49999999999987, -3.0999999999999828, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 67.7000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.00000000000007, 100.70000000000007, 20.000000000000014, 103.69999999999997, 20.000000000000014, 170.0, -171.70000000000007, -80.80000000000085, 162.2, 200.0, 78.49999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 143.3, -67.60000000000014, 200.0, -36.39999999999979, 20.000000000000014, 170.0, 154.1, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [1.0, 7.0, 0.0, 10.0, 0.0, 40.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 10.0, 0.0, 91.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 0.0, 129.0, 0.0, 6.0, 0.0, 10.0, 10.0, 45.0, 5.0, 1.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 17.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 13.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 29.0, 0.0, 5.0, 0.0, 0.0, 18.0, 0.0, 8.0, 0.0, 0.0, 35.0, 24.0, 0.0, 11.0, 0.0, 8.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 27.0, 16.0, 0.0, 0.0, 0.0, 10.0, 2.0, 118.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 32.0, 0.0, 10.0, 6.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.289152023533174, "mean_inference_ms": 3.5712979412228636, "mean_action_processing_ms": 0.5705120786127583, "mean_env_wait_ms": 0.4328902821011434, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010309576988220215, "StateBufferConnector_ms": 0.007988214492797852, "ViewRequirementAgentConnector_ms": 0.22571122646331787}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -132.5000000000009, "episode_return_mean": 168.12699999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 309.3634140034256, "num_env_steps_trained_throughput_per_sec": 309.3634140034256, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 13552.507, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13552.353, "sample_time_ms": 2146.048, "learn_time_ms": 11377.187, "learn_throughput": 351.581, "synch_weights_time_ms": 26.164}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "e57b0_00000", "date": "2024-08-13_00-34-52", "timestamp": 1723523692, "time_this_iter_s": 12.935048341751099, "time_total_s": 1463.4715690612793, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0dba160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1463.4715690612793, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 54.35, "ram_util_percent": 76.17777777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.684453306958158, "cur_kl_coeff": 1.5539569631073386e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.454939574034756, "policy_loss": -0.0008222155477457418, "vf_loss": 4.455761793429259, "vf_explained_var": 0.36848716795759856, "kl": 0.0027941035811508527, "entropy": 0.5140999861179836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5520058501856746, "cur_kl_coeff": 2.4441629648208623e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3995855868335754, "policy_loss": -0.0004829657921892783, "vf_loss": 0.40006854268685277, "vf_explained_var": 0.005905968581557904, "kl": 0.005370178448161868, "entropy": 0.6804087167063718, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -132.5000000000009, "episode_reward_mean": 164.66399999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -250.90000000000038, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 129.0}, "policy_reward_mean": {"prey_policy": 75.88699999999999, "predator_policy": 6.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [188.8999999999994, 40.0000000000003, 78.1, 33.400000000000205, 360.0, -14.999999999999543, 176.39999999999947, 236.19999999999985, 311.79999999999984, 219.99999999999926, 203.99999999999935, 276.99999999999966, 208.99999999999932, 400.0, 219.99999999999926, 40.0000000000003, 219.99999999999926, 10.000000000000089, 190.0999999999994, 219.99999999999926, 217.29999999999927, 400.0, 264.9, 199.99999999999935, 215.99999999999926, 271.29999999999956, 128.19999999999973, 219.99999999999926, 394.6, 40.0000000000003, 151.39999999999904, 145.29999999999964, 219.99999999999926, 307.1000000000006, 40.0000000000003, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 51.70000000000017, 187.59999999999906, 94.10000000000005, 300.80000000000064, 135.3999999999997, 119.19999999999982, 15.30000000000002, 40.0000000000003, 211.9999999999993, 390.0, 165.0999999999995, 219.99999999999926, 203.7999999999994, 329.8000000000015, 199.99999999999935, 211.9999999999993, 105.2999999999999, 200.09999999999937, 117.39999999999975, 31.200000000000166, 94.9, 102.89999999999992, 27.900000000000123, 31.200000000000166, 99.69999999999983, 40.0000000000003, 40.0000000000003, 190.70000000000007, 123.69999999999979, 199.99999999999935, -132.5000000000009, 362.20000000000005, 107.4999999999998, 400.0, 163.29999999999953, 211.40000000000003, 15.600000000000133, 340.1, 40.0000000000003, 40.90000000000025, 191.1999999999994, 285.5, -21.90000000000021, 359.50000000000006, 95.89999999999988, 219.99999999999926, 38.90000000000028, 102.09999999999835, 40.90000000000031, 201.99999999999935, 213.3999999999993, 40.0000000000003, 40.0000000000003, 70.40000000000009, 219.99999999999926, 219.99999999999926, 117.99999999999987, 214.59999999999923, 140.09999999999894, 269.49999999999955, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-13.599999999999783, 186.5, 20.000000000000014, 20.000000000000014, -250.90000000000038, 200.0, 20.000000000000014, 7.399999999999965, 200.0, 140.0, 9.499999999999964, -74.50000000000087, 20.000000000000014, 145.40000000000003, 146.9, 80.29999999999998, 200.0, 111.79999999999998, 20.000000000000014, 200.0, 20.000000000000014, 176.0, 191.0, 82.99999999999997, 200.0, -0.9999999999999992, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999917, -0.9999999999999952, 160.1, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, 170.0, 77.90000000000006, 20.000000000000014, 170.0, 194.0, 20.000000000000014, 71.29999999999968, 200.0, 108.19999999999999, 20.000000000000014, 20.000000000000014, 200.0, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 121.40000000000008, 20.000000000000014, 101.30000000000004, 20.000000000000014, 200.0, 127.09999999999985, 170.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 18.200000000000195, 18.49999999999996, 167.5999999999998, 20.000000000000014, 43.10000000000009, 20.000000000000014, 170.0, 120.7999999999995, 20.000000000000014, 115.39999999999998, 99.19999999999997, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 191.0, 194.0, 20.000000000000014, 145.1, 20.000000000000014, 200.0, 178.4, 25.400000000000006, 200.0, 129.79999999999956, 170.0, 20.000000000000014, 188.0, 20.000000000000014, 56.300000000000054, 20.000000000000014, 20.000000000000014, 175.1, 20.000000000000014, 79.40000000000009, 3.1999999999999615, 20.000000000000014, 74.89999999999996, 20.000000000000014, 97.40000000000003, -53.49999999999987, -3.0999999999999828, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 67.7000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.00000000000007, 100.70000000000007, 20.000000000000014, 103.69999999999997, 20.000000000000014, 170.0, -171.70000000000007, -80.80000000000085, 162.2, 200.0, 78.49999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 143.3, -67.60000000000014, 200.0, -36.39999999999979, 20.000000000000014, 170.0, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.1000000000004, 20.000000000000014, 162.2, 87.5000000000001, 179.0, 20.000000000000014, -121.90000000000049, 200.0, 159.5, 53.90000000000011, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 70.39999999999975, 31.700000000000212, 20.000000000000014, 20.90000000000003, 20.000000000000014, 173.0, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -91.60000000000025, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 65.00000000000004, 20.000000000000014, 194.59999999999997, 20.000000000000014, 106.0999999999996, 200.0, 69.49999999999982, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [10.0, 6.0, 0.0, 0.0, 129.0, 0.0, 6.0, 0.0, 10.0, 10.0, 45.0, 5.0, 1.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 10.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 17.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 13.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 29.0, 0.0, 5.0, 0.0, 0.0, 18.0, 0.0, 8.0, 0.0, 0.0, 35.0, 24.0, 0.0, 11.0, 0.0, 8.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 27.0, 16.0, 0.0, 0.0, 0.0, 10.0, 2.0, 118.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 32.0, 0.0, 10.0, 6.0, 0.0, 0.0, 36.0, 0.0, 9.0, 0.0, 19.0, 0.0, 79.0, 1.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 83.0, 59.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2862681008998025, "mean_inference_ms": 3.5663338265927456, "mean_action_processing_ms": 0.5687706335887793, "mean_env_wait_ms": 0.4315925999186759, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010669589042663574, "StateBufferConnector_ms": 0.008043169975280762, "ViewRequirementAgentConnector_ms": 0.23024535179138184}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -132.5000000000009, "episode_return_mean": 164.66399999999976, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.3782970282388, "num_env_steps_trained_throughput_per_sec": 320.3782970282388, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 13619.464, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13619.312, "sample_time_ms": 2160.937, "learn_time_ms": 11428.779, "learn_throughput": 349.994, "synch_weights_time_ms": 26.638}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "e57b0_00000", "date": "2024-08-13_00-35-05", "timestamp": 1723523705, "time_this_iter_s": 12.492360830307007, "time_total_s": 1475.9639298915863, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09cf820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1475.9639298915863, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 52.1, "ram_util_percent": 74.51666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.238250869827927, "cur_kl_coeff": 7.769784815536693e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7256374272089157, "policy_loss": -0.003410585400914507, "vf_loss": 3.7290480097765646, "vf_explained_var": 0.46941526409179446, "kl": 0.012425184824821939, "entropy": 0.6546868634917749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7406915492511221, "cur_kl_coeff": 2.4441629648208623e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.30246263920630095, "policy_loss": -0.0002023337615860833, "vf_loss": 0.30266496314589864, "vf_explained_var": -0.0017883542984250991, "kl": 0.004997270586041037, "entropy": 0.8203660668519439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -132.5000000000009, "episode_reward_mean": 157.54599999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.70000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 72.72799999999998, "predator_policy": 6.045}, "custom_metrics": {}, "hist_stats": {"episode_reward": [190.0999999999994, 219.99999999999926, 217.29999999999927, 400.0, 264.9, 199.99999999999935, 215.99999999999926, 271.29999999999956, 128.19999999999973, 219.99999999999926, 394.6, 40.0000000000003, 151.39999999999904, 145.29999999999964, 219.99999999999926, 307.1000000000006, 40.0000000000003, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 51.70000000000017, 187.59999999999906, 94.10000000000005, 300.80000000000064, 135.3999999999997, 119.19999999999982, 15.30000000000002, 40.0000000000003, 211.9999999999993, 390.0, 165.0999999999995, 219.99999999999926, 203.7999999999994, 329.8000000000015, 199.99999999999935, 211.9999999999993, 105.2999999999999, 200.09999999999937, 117.39999999999975, 31.200000000000166, 94.9, 102.89999999999992, 27.900000000000123, 31.200000000000166, 99.69999999999983, 40.0000000000003, 40.0000000000003, 190.70000000000007, 123.69999999999979, 199.99999999999935, -132.5000000000009, 362.20000000000005, 107.4999999999998, 400.0, 163.29999999999953, 211.40000000000003, 15.600000000000133, 340.1, 40.0000000000003, 40.90000000000025, 191.1999999999994, 285.5, -21.90000000000021, 359.50000000000006, 95.89999999999988, 219.99999999999926, 38.90000000000028, 102.09999999999835, 40.90000000000031, 201.99999999999935, 213.3999999999993, 40.0000000000003, 40.0000000000003, 70.40000000000009, 219.99999999999926, 219.99999999999926, 117.99999999999987, 214.59999999999923, 140.09999999999894, 269.49999999999955, 40.0000000000003, 201.99999999999935, 219.79999999999936, 217.99999999999926, 196.39999999999938, 20.199999999999978, 172.4999999999995, -7.29999999999972, 202.89999999999938, 128.19999999999973, 40.0000000000003, 40.0000000000003, 40.0000000000003, 212.2999999999999, 40.0000000000003, 314.4999999999999, 18.50000000000001, 219.99999999999926, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [160.1, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, 170.0, 77.90000000000006, 20.000000000000014, 170.0, 194.0, 20.000000000000014, 71.29999999999968, 200.0, 108.19999999999999, 20.000000000000014, 20.000000000000014, 200.0, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 121.40000000000008, 20.000000000000014, 101.30000000000004, 20.000000000000014, 200.0, 127.09999999999985, 170.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 18.200000000000195, 18.49999999999996, 167.5999999999998, 20.000000000000014, 43.10000000000009, 20.000000000000014, 170.0, 120.7999999999995, 20.000000000000014, 115.39999999999998, 99.19999999999997, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 191.0, 194.0, 20.000000000000014, 145.1, 20.000000000000014, 200.0, 178.4, 25.400000000000006, 200.0, 129.79999999999956, 170.0, 20.000000000000014, 188.0, 20.000000000000014, 56.300000000000054, 20.000000000000014, 20.000000000000014, 175.1, 20.000000000000014, 79.40000000000009, 3.1999999999999615, 20.000000000000014, 74.89999999999996, 20.000000000000014, 97.40000000000003, -53.49999999999987, -3.0999999999999828, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 67.7000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.00000000000007, 100.70000000000007, 20.000000000000014, 103.69999999999997, 20.000000000000014, 170.0, -171.70000000000007, -80.80000000000085, 162.2, 200.0, 78.49999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 143.3, -67.60000000000014, 200.0, -36.39999999999979, 20.000000000000014, 170.0, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.1000000000004, 20.000000000000014, 162.2, 87.5000000000001, 179.0, 20.000000000000014, -121.90000000000049, 200.0, 159.5, 53.90000000000011, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 70.39999999999975, 31.700000000000212, 20.000000000000014, 20.90000000000003, 20.000000000000014, 173.0, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -91.60000000000025, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 65.00000000000004, 20.000000000000014, 194.59999999999997, 20.000000000000014, 106.0999999999996, 200.0, 69.49999999999982, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 125.90000000000003, 83.89999999999932, 197.0, 20.000000000000014, 20.000000000000014, 166.4, -0.9999999999999992, 3.1999999999999615, 170.0, -32.49999999999982, -70.30000000000081, 20.000000000000014, 134.29999999999998, 68.59999999999988, 108.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, -22.300000000000452, 20.000000000000014, 20.000000000000014, 114.49999999999999, 200.0, -0.9999999999999846, 9.499999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014], "policy_predator_policy_reward": [10.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 17.0, 0.0, 10.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 13.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 29.0, 0.0, 5.0, 0.0, 0.0, 18.0, 0.0, 8.0, 0.0, 0.0, 35.0, 24.0, 0.0, 11.0, 0.0, 8.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 27.0, 16.0, 0.0, 0.0, 0.0, 10.0, 2.0, 118.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 32.0, 0.0, 10.0, 6.0, 0.0, 0.0, 36.0, 0.0, 9.0, 0.0, 19.0, 0.0, 79.0, 1.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 83.0, 59.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 10.0, 0.0, 18.0, 0.0, 10.0, 25.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2838321178296896, "mean_inference_ms": 3.561429684221963, "mean_action_processing_ms": 0.5671821569667382, "mean_env_wait_ms": 0.4304643805737402, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009866714477539062, "StateBufferConnector_ms": 0.007935285568237305, "ViewRequirementAgentConnector_ms": 0.21843492984771729}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -132.5000000000009, "episode_return_mean": 157.54599999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 239.74344737664785, "num_env_steps_trained_throughput_per_sec": 239.74344737664785, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 14170.401, "restore_workers_time_ms": 0.026, "training_step_time_ms": 14170.244, "sample_time_ms": 2200.95, "learn_time_ms": 11936.97, "learn_throughput": 335.093, "synch_weights_time_ms": 29.008}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "e57b0_00000", "date": "2024-08-13_00-35-21", "timestamp": 1723523721, "time_this_iter_s": 16.825812101364136, "time_total_s": 1492.7897419929504, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09fb430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1492.7897419929504, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 77.4375, "ram_util_percent": 78.425}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.666975237728742, "cur_kl_coeff": 7.769784815536693e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.141524234524479, "policy_loss": -0.002339081629179418, "vf_loss": 5.143863315178604, "vf_explained_var": 0.43674995523911936, "kl": 0.005292770707843562, "entropy": 0.6245099191943174, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7502351319821423, "cur_kl_coeff": 1.2220814824104312e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4492482997753002, "policy_loss": -0.00019646873143279835, "vf_loss": 0.44944476749324214, "vf_explained_var": 0.008066623898410293, "kl": 0.0034746332931871455, "entropy": 0.8480066899269346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -132.5000000000009, "episode_reward_mean": 152.9309999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.70000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 70.24549999999998, "predator_policy": 6.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [94.10000000000005, 300.80000000000064, 135.3999999999997, 119.19999999999982, 15.30000000000002, 40.0000000000003, 211.9999999999993, 390.0, 165.0999999999995, 219.99999999999926, 203.7999999999994, 329.8000000000015, 199.99999999999935, 211.9999999999993, 105.2999999999999, 200.09999999999937, 117.39999999999975, 31.200000000000166, 94.9, 102.89999999999992, 27.900000000000123, 31.200000000000166, 99.69999999999983, 40.0000000000003, 40.0000000000003, 190.70000000000007, 123.69999999999979, 199.99999999999935, -132.5000000000009, 362.20000000000005, 107.4999999999998, 400.0, 163.29999999999953, 211.40000000000003, 15.600000000000133, 340.1, 40.0000000000003, 40.90000000000025, 191.1999999999994, 285.5, -21.90000000000021, 359.50000000000006, 95.89999999999988, 219.99999999999926, 38.90000000000028, 102.09999999999835, 40.90000000000031, 201.99999999999935, 213.3999999999993, 40.0000000000003, 40.0000000000003, 70.40000000000009, 219.99999999999926, 219.99999999999926, 117.99999999999987, 214.59999999999923, 140.09999999999894, 269.49999999999955, 40.0000000000003, 201.99999999999935, 219.79999999999936, 217.99999999999926, 196.39999999999938, 20.199999999999978, 172.4999999999995, -7.29999999999972, 202.89999999999938, 128.19999999999973, 40.0000000000003, 40.0000000000003, 40.0000000000003, 212.2999999999999, 40.0000000000003, 314.4999999999999, 18.50000000000001, 219.99999999999926, 219.99999999999926, 32.30000000000018, 317.8000000000001, 163.90000000000003, 322.7, 211.1999999999993, 219.99999999999926, 333.4, 40.0000000000003, 40.0000000000003, 199.99999999999935, 60.70000000000051, 40.0000000000003, 40.0000000000003, 29.000000000000128, 394.0, 288.9999999999998, 326.7, 199.99999999999935, 217.79999999999927, 269.5000000000001, 152.6999999999996, 163.2999999999995, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [43.10000000000009, 20.000000000000014, 170.0, 120.7999999999995, 20.000000000000014, 115.39999999999998, 99.19999999999997, 20.000000000000014, 5.299999999999965, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 188.0, 20.000000000000014, 191.0, 194.0, 20.000000000000014, 145.1, 20.000000000000014, 200.0, 178.4, 25.400000000000006, 200.0, 129.79999999999956, 170.0, 20.000000000000014, 188.0, 20.000000000000014, 56.300000000000054, 20.000000000000014, 20.000000000000014, 175.1, 20.000000000000014, 79.40000000000009, 3.1999999999999615, 20.000000000000014, 74.89999999999996, 20.000000000000014, 97.40000000000003, -53.49999999999987, -3.0999999999999828, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 67.7000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.00000000000007, 100.70000000000007, 20.000000000000014, 103.69999999999997, 20.000000000000014, 170.0, -171.70000000000007, -80.80000000000085, 162.2, 200.0, 78.49999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 143.3, -67.60000000000014, 200.0, -36.39999999999979, 20.000000000000014, 170.0, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.1000000000004, 20.000000000000014, 162.2, 87.5000000000001, 179.0, 20.000000000000014, -121.90000000000049, 200.0, 159.5, 53.90000000000011, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 70.39999999999975, 31.700000000000212, 20.000000000000014, 20.90000000000003, 20.000000000000014, 173.0, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -91.60000000000025, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 65.00000000000004, 20.000000000000014, 194.59999999999997, 20.000000000000014, 106.0999999999996, 200.0, 69.49999999999982, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 125.90000000000003, 83.89999999999932, 197.0, 20.000000000000014, 20.000000000000014, 166.4, -0.9999999999999992, 3.1999999999999615, 170.0, -32.49999999999982, -70.30000000000081, 20.000000000000014, 134.29999999999998, 68.59999999999988, 108.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, -22.300000000000452, 20.000000000000014, 20.000000000000014, 114.49999999999999, 200.0, -0.9999999999999846, 9.499999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, 139.40000000000003, 163.39999999999998, 77.89999999999996, 62.00000000000013, 188.0, 130.7, 200.0, 3.1999999999999633, 20.000000000000014, 200.0, 200.0, 133.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 17.899999999999988, 200.0, 191.0, 101.90000000000006, 172.1, 170.0, 136.70000000000005, 170.0, 20.000000000000014, 15.799999999999963, 200.0, 160.4, 100.09999999999978, 3.1999999999999633, 141.5, 20.000000000000014, 143.29999999999998, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [31.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 29.0, 0.0, 5.0, 0.0, 0.0, 18.0, 0.0, 8.0, 0.0, 0.0, 35.0, 24.0, 0.0, 11.0, 0.0, 8.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 27.0, 16.0, 0.0, 0.0, 0.0, 10.0, 2.0, 118.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 32.0, 0.0, 10.0, 6.0, 0.0, 0.0, 36.0, 0.0, 9.0, 0.0, 19.0, 0.0, 79.0, 1.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 83.0, 59.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 10.0, 0.0, 18.0, 0.0, 10.0, 25.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 5.0, 16.0, 8.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 5.0, 10.0, 10.0, 10.0, 0.0, 10.0, 2.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.284889516147598, "mean_inference_ms": 3.5676097109510185, "mean_action_processing_ms": 0.5668522508814765, "mean_env_wait_ms": 0.431153475226298, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013164997100830078, "StateBufferConnector_ms": 0.008091330528259277, "ViewRequirementAgentConnector_ms": 0.23039615154266357}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -132.5000000000009, "episode_return_mean": 152.9309999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.66677963159913, "num_env_steps_trained_throughput_per_sec": 199.66677963159913, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 14853.93, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14853.761, "sample_time_ms": 2684.143, "learn_time_ms": 12137.141, "learn_throughput": 329.567, "synch_weights_time_ms": 28.998}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "e57b0_00000", "date": "2024-08-13_00-35-42", "timestamp": 1723523742, "time_this_iter_s": 20.146839141845703, "time_total_s": 1512.9365811347961, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12c7ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1512.9365811347961, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 77.18928571428572, "ram_util_percent": 83.68571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.094920329426332, "cur_kl_coeff": 7.769784815536693e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.530331947689965, "policy_loss": -0.00012535079328156022, "vf_loss": 4.530457299979275, "vf_explained_var": 0.5131528788773471, "kl": 0.002040943567050502, "entropy": 0.7020518876257397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5666998148388254, "cur_kl_coeff": 6.110407412052156e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.21688742566282157, "policy_loss": -0.0007669020890105496, "vf_loss": 0.2176543273348466, "vf_explained_var": -0.02871674661913877, "kl": 0.005066001720667288, "entropy": 0.9849366902043579, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -132.5000000000009, "episode_reward_mean": 152.09499999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.70000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 69.05749999999998, "predator_policy": 6.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [94.9, 102.89999999999992, 27.900000000000123, 31.200000000000166, 99.69999999999983, 40.0000000000003, 40.0000000000003, 190.70000000000007, 123.69999999999979, 199.99999999999935, -132.5000000000009, 362.20000000000005, 107.4999999999998, 400.0, 163.29999999999953, 211.40000000000003, 15.600000000000133, 340.1, 40.0000000000003, 40.90000000000025, 191.1999999999994, 285.5, -21.90000000000021, 359.50000000000006, 95.89999999999988, 219.99999999999926, 38.90000000000028, 102.09999999999835, 40.90000000000031, 201.99999999999935, 213.3999999999993, 40.0000000000003, 40.0000000000003, 70.40000000000009, 219.99999999999926, 219.99999999999926, 117.99999999999987, 214.59999999999923, 140.09999999999894, 269.49999999999955, 40.0000000000003, 201.99999999999935, 219.79999999999936, 217.99999999999926, 196.39999999999938, 20.199999999999978, 172.4999999999995, -7.29999999999972, 202.89999999999938, 128.19999999999973, 40.0000000000003, 40.0000000000003, 40.0000000000003, 212.2999999999999, 40.0000000000003, 314.4999999999999, 18.50000000000001, 219.99999999999926, 219.99999999999926, 32.30000000000018, 317.8000000000001, 163.90000000000003, 322.7, 211.1999999999993, 219.99999999999926, 333.4, 40.0000000000003, 40.0000000000003, 199.99999999999935, 60.70000000000051, 40.0000000000003, 40.0000000000003, 29.000000000000128, 394.0, 288.9999999999998, 326.7, 199.99999999999935, 217.79999999999927, 269.5000000000001, 152.6999999999996, 163.2999999999995, 40.0000000000003, 98.69999999999992, 160.59999999999954, 153.39999999999904, 329.80000000000143, 137.59999999999968, 144.69999999999962, 394.0, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 136.89999999999966, 207.99999999999932, 167.7999999999995, 40.0000000000003, 191.1999999999994, 322.40000000000003, 182.79999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [74.89999999999996, 20.000000000000014, 97.40000000000003, -53.49999999999987, -3.0999999999999828, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 67.7000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 47.00000000000007, 100.70000000000007, 20.000000000000014, 103.69999999999997, 20.000000000000014, 170.0, -171.70000000000007, -80.80000000000085, 162.2, 200.0, 78.49999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 143.3, -67.60000000000014, 200.0, -36.39999999999979, 20.000000000000014, 170.0, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.1000000000004, 20.000000000000014, 162.2, 87.5000000000001, 179.0, 20.000000000000014, -121.90000000000049, 200.0, 159.5, 53.90000000000011, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 70.39999999999975, 31.700000000000212, 20.000000000000014, 20.90000000000003, 20.000000000000014, 173.0, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -91.60000000000025, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 65.00000000000004, 20.000000000000014, 194.59999999999997, 20.000000000000014, 106.0999999999996, 200.0, 69.49999999999982, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 125.90000000000003, 83.89999999999932, 197.0, 20.000000000000014, 20.000000000000014, 166.4, -0.9999999999999992, 3.1999999999999615, 170.0, -32.49999999999982, -70.30000000000081, 20.000000000000014, 134.29999999999998, 68.59999999999988, 108.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, -22.300000000000452, 20.000000000000014, 20.000000000000014, 114.49999999999999, 200.0, -0.9999999999999846, 9.499999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, 139.40000000000003, 163.39999999999998, 77.89999999999996, 62.00000000000013, 188.0, 130.7, 200.0, 3.1999999999999633, 20.000000000000014, 200.0, 200.0, 133.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 17.899999999999988, 200.0, 191.0, 101.90000000000006, 172.1, 170.0, 136.70000000000005, 170.0, 20.000000000000014, 15.799999999999963, 200.0, 160.4, 100.09999999999978, 3.1999999999999633, 141.5, 20.000000000000014, 143.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -46.30000000000021, 140.6, 20.000000000000014, 133.3999999999997, 20.000000000000014, 129.79999999999956, 200.0, 20.000000000000014, 50.59999999999977, 20.000000000000014, 97.70000000000007, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.90000000000006, 182.0, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 171.2, 20.000000000000014, 142.39999999999998, 170.0, 144.8, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 35.0, 24.0, 0.0, 11.0, 0.0, 8.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 27.0, 16.0, 0.0, 0.0, 0.0, 10.0, 2.0, 118.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 32.0, 0.0, 10.0, 6.0, 0.0, 0.0, 36.0, 0.0, 9.0, 0.0, 19.0, 0.0, 79.0, 1.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 83.0, 59.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 10.0, 0.0, 18.0, 0.0, 10.0, 25.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 5.0, 16.0, 8.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 5.0, 10.0, 10.0, 10.0, 0.0, 10.0, 2.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 69.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 32.0, 19.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.283977350528536, "mean_inference_ms": 3.5685443345818224, "mean_action_processing_ms": 0.5661577353003736, "mean_env_wait_ms": 0.43129875679334234, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013353466987609863, "StateBufferConnector_ms": 0.0044814348220825195, "ViewRequirementAgentConnector_ms": 0.24937820434570312}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -132.5000000000009, "episode_return_mean": 152.09499999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.602793861704, "num_env_steps_trained_throughput_per_sec": 321.602793861704, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 14656.913, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14656.747, "sample_time_ms": 2674.993, "learn_time_ms": 11949.395, "learn_throughput": 334.745, "synch_weights_time_ms": 29.204}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "e57b0_00000", "date": "2024-08-13_00-35-54", "timestamp": 1723523754, "time_this_iter_s": 12.444762945175171, "time_total_s": 1525.3813440799713, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b12c7ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1525.3813440799713, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 52.11764705882352, "ram_util_percent": 75.70588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.304539064487452, "cur_kl_coeff": 3.8848924077683466e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.418713484239326, "policy_loss": -0.001321615696091343, "vf_loss": 4.420035106290585, "vf_explained_var": 0.6270360371738515, "kl": 0.0037183112541822297, "entropy": 0.66242567385946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4670435933061141, "cur_kl_coeff": 6.110407412052156e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15581348441521484, "policy_loss": -0.0011354111191673726, "vf_loss": 0.1569488889611435, "vf_explained_var": -0.07129728488190465, "kl": 0.01165783513178122, "entropy": 0.7444888714129332, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 394.0, "episode_reward_min": -21.90000000000021, "episode_reward_mean": 161.8949999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -121.90000000000049, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 83.0}, "policy_reward_mean": {"prey_policy": 75.67249999999996, "predator_policy": 5.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-21.90000000000021, 359.50000000000006, 95.89999999999988, 219.99999999999926, 38.90000000000028, 102.09999999999835, 40.90000000000031, 201.99999999999935, 213.3999999999993, 40.0000000000003, 40.0000000000003, 70.40000000000009, 219.99999999999926, 219.99999999999926, 117.99999999999987, 214.59999999999923, 140.09999999999894, 269.49999999999955, 40.0000000000003, 201.99999999999935, 219.79999999999936, 217.99999999999926, 196.39999999999938, 20.199999999999978, 172.4999999999995, -7.29999999999972, 202.89999999999938, 128.19999999999973, 40.0000000000003, 40.0000000000003, 40.0000000000003, 212.2999999999999, 40.0000000000003, 314.4999999999999, 18.50000000000001, 219.99999999999926, 219.99999999999926, 32.30000000000018, 317.8000000000001, 163.90000000000003, 322.7, 211.1999999999993, 219.99999999999926, 333.4, 40.0000000000003, 40.0000000000003, 199.99999999999935, 60.70000000000051, 40.0000000000003, 40.0000000000003, 29.000000000000128, 394.0, 288.9999999999998, 326.7, 199.99999999999935, 217.79999999999927, 269.5000000000001, 152.6999999999996, 163.2999999999995, 40.0000000000003, 98.69999999999992, 160.59999999999954, 153.39999999999904, 329.80000000000143, 137.59999999999968, 144.69999999999962, 394.0, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 136.89999999999966, 207.99999999999932, 167.7999999999995, 40.0000000000003, 191.1999999999994, 322.40000000000003, 182.79999999999944, 70.60000000000002, 120.79999999999887, 40.0000000000003, 132.0999999999997, 128.2999999999989, 40.0000000000003, 323.29999999999984, 219.99999999999926, 215.99999999999926, 42.700000000000344, 297.2000000000021, 34.50000000000022, 278.2999999999999, 217.79999999999927, 84.99999999999898, 208.99999999999932, 380.2000000000005, 192.49999999999937, 330.70000000000005, 205.59999999999934, 35.600000000000236, 356.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -121.90000000000049, 200.0, 159.5, 53.90000000000011, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 70.39999999999975, 31.700000000000212, 20.000000000000014, 20.90000000000003, 20.000000000000014, 173.0, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -91.60000000000025, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 65.00000000000004, 20.000000000000014, 194.59999999999997, 20.000000000000014, 106.0999999999996, 200.0, 69.49999999999982, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 125.90000000000003, 83.89999999999932, 197.0, 20.000000000000014, 20.000000000000014, 166.4, -0.9999999999999992, 3.1999999999999615, 170.0, -32.49999999999982, -70.30000000000081, 20.000000000000014, 134.29999999999998, 68.59999999999988, 108.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, -22.300000000000452, 20.000000000000014, 20.000000000000014, 114.49999999999999, 200.0, -0.9999999999999846, 9.499999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, 139.40000000000003, 163.39999999999998, 77.89999999999996, 62.00000000000013, 188.0, 130.7, 200.0, 3.1999999999999633, 20.000000000000014, 200.0, 200.0, 133.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 17.899999999999988, 200.0, 191.0, 101.90000000000006, 172.1, 170.0, 136.70000000000005, 170.0, 20.000000000000014, 15.799999999999963, 200.0, 160.4, 100.09999999999978, 3.1999999999999633, 141.5, 20.000000000000014, 143.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -46.30000000000021, 140.6, 20.000000000000014, 133.3999999999997, 20.000000000000014, 129.79999999999956, 200.0, 20.000000000000014, 50.59999999999977, 20.000000000000014, 97.70000000000007, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.90000000000006, 182.0, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 171.2, 20.000000000000014, 142.39999999999998, 170.0, 144.8, 20.000000000000014, 20.90000000000003, 49.70000000000024, 90.79999999999951, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.10000000000008, 112.09999999999954, 3.199999999999965, 20.000000000000014, 20.000000000000014, 164.59999999999982, 157.7, 20.000000000000014, 200.0, 194.0, 20.000000000000014, 13.69999999999997, 20.000000000000014, 145.99999999999966, 141.19999999999982, 20.000000000000014, 9.499999999999964, 197.0, 80.2999999999993, 15.799999999999963, 200.0, 20.000000000000014, 65.00000000000014, -0.9999999999999952, 200.0, 200.0, 180.19999999999987, 165.5, 20.000000000000014, 200.0, 112.70000000000005, 20.000000000000014, 185.6, 20.000000000000014, 11.599999999999966, 170.0, 170.0], "policy_predator_policy_reward": [79.0, 1.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 83.0, 59.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 10.0, 0.0, 18.0, 0.0, 10.0, 25.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 5.0, 16.0, 8.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 5.0, 10.0, 10.0, 10.0, 0.0, 10.0, 2.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 69.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 32.0, 19.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 12.0, 0.0, 13.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 0.0, 10.0, 5.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 4.0, 0.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2838531018268409, "mean_inference_ms": 3.565212204508996, "mean_action_processing_ms": 0.5651381335948535, "mean_env_wait_ms": 0.43172884776570586, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012736082077026367, "StateBufferConnector_ms": 0.0040531158447265625, "ViewRequirementAgentConnector_ms": 0.20517301559448242}, "num_episodes": 22, "episode_return_max": 394.0, "episode_return_min": -21.90000000000021, "episode_return_mean": 161.8949999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.0433085868561, "num_env_steps_trained_throughput_per_sec": 346.0433085868561, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 14528.602, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14528.436, "sample_time_ms": 2656.708, "learn_time_ms": 11841.644, "learn_throughput": 337.791, "synch_weights_time_ms": 27.052}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "e57b0_00000", "date": "2024-08-13_00-36-06", "timestamp": 1723523766, "time_this_iter_s": 11.56536602973938, "time_total_s": 1536.9467101097107, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1294e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1536.9467101097107, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 44.78235294117647, "ram_util_percent": 73.38823529411764}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.997377843863118, "cur_kl_coeff": 1.9424462038841733e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.477345602096073, "policy_loss": -0.0009642825999036037, "vf_loss": 4.478309889571377, "vf_explained_var": 0.6198012363973748, "kl": 0.0035512434152800156, "entropy": 0.685628587543649, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5219832804113154, "cur_kl_coeff": 6.110407412052156e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3523850854821306, "policy_loss": -0.000985481478914461, "vf_loss": 0.3533705679123553, "vf_explained_var": 0.013230225680366395, "kl": 0.005758555977770348, "entropy": 0.8395890815232797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 394.0, "episode_reward_min": -7.29999999999972, "episode_reward_mean": 162.74599999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -70.30000000000081, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 69.0}, "policy_reward_mean": {"prey_policy": 77.10799999999996, "predator_policy": 4.265}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 201.99999999999935, 219.79999999999936, 217.99999999999926, 196.39999999999938, 20.199999999999978, 172.4999999999995, -7.29999999999972, 202.89999999999938, 128.19999999999973, 40.0000000000003, 40.0000000000003, 40.0000000000003, 212.2999999999999, 40.0000000000003, 314.4999999999999, 18.50000000000001, 219.99999999999926, 219.99999999999926, 32.30000000000018, 317.8000000000001, 163.90000000000003, 322.7, 211.1999999999993, 219.99999999999926, 333.4, 40.0000000000003, 40.0000000000003, 199.99999999999935, 60.70000000000051, 40.0000000000003, 40.0000000000003, 29.000000000000128, 394.0, 288.9999999999998, 326.7, 199.99999999999935, 217.79999999999927, 269.5000000000001, 152.6999999999996, 163.2999999999995, 40.0000000000003, 98.69999999999992, 160.59999999999954, 153.39999999999904, 329.80000000000143, 137.59999999999968, 144.69999999999962, 394.0, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 136.89999999999966, 207.99999999999932, 167.7999999999995, 40.0000000000003, 191.1999999999994, 322.40000000000003, 182.79999999999944, 70.60000000000002, 120.79999999999887, 40.0000000000003, 132.0999999999997, 128.2999999999989, 40.0000000000003, 323.29999999999984, 219.99999999999926, 215.99999999999926, 42.700000000000344, 297.2000000000021, 34.50000000000022, 278.2999999999999, 217.79999999999927, 84.99999999999898, 208.99999999999932, 380.2000000000005, 192.49999999999937, 330.70000000000005, 205.59999999999934, 35.600000000000236, 356.0, 145.09999999999962, 111.99999999999858, 132.8999999999988, 99.0, 207.99999999999932, 306.3999999999999, 40.0000000000003, 184.40000000000003, 102.99999999999852, 219.99999999999926, 4.200000000000202, 183.99999999999903, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 189.4999999999994, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 125.90000000000003, 83.89999999999932, 197.0, 20.000000000000014, 20.000000000000014, 166.4, -0.9999999999999992, 3.1999999999999615, 170.0, -32.49999999999982, -70.30000000000081, 20.000000000000014, 134.29999999999998, 68.59999999999988, 108.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, -22.300000000000452, 20.000000000000014, 20.000000000000014, 114.49999999999999, 200.0, -0.9999999999999846, 9.499999999999964, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, 139.40000000000003, 163.39999999999998, 77.89999999999996, 62.00000000000013, 188.0, 130.7, 200.0, 3.1999999999999633, 20.000000000000014, 200.0, 200.0, 133.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 17.899999999999988, 200.0, 191.0, 101.90000000000006, 172.1, 170.0, 136.70000000000005, 170.0, 20.000000000000014, 15.799999999999963, 200.0, 160.4, 100.09999999999978, 3.1999999999999633, 141.5, 20.000000000000014, 143.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -46.30000000000021, 140.6, 20.000000000000014, 133.3999999999997, 20.000000000000014, 129.79999999999956, 200.0, 20.000000000000014, 50.59999999999977, 20.000000000000014, 97.70000000000007, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.90000000000006, 182.0, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 171.2, 20.000000000000014, 142.39999999999998, 170.0, 144.8, 20.000000000000014, 20.90000000000003, 49.70000000000024, 90.79999999999951, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.10000000000008, 112.09999999999954, 3.199999999999965, 20.000000000000014, 20.000000000000014, 164.59999999999982, 157.7, 20.000000000000014, 200.0, 194.0, 20.000000000000014, 13.69999999999997, 20.000000000000014, 145.99999999999966, 141.19999999999982, 20.000000000000014, 9.499999999999964, 197.0, 80.2999999999993, 15.799999999999963, 200.0, 20.000000000000014, 65.00000000000014, -0.9999999999999952, 200.0, 200.0, 180.19999999999987, 165.5, 20.000000000000014, 200.0, 112.70000000000005, 20.000000000000014, 185.6, 20.000000000000014, 11.599999999999966, 170.0, 170.0, 136.1, -0.9999999999999846, 91.99999999999932, 20.000000000000014, 3.199999999999965, 121.6999999999995, 20.000000000000014, 50.000000000000085, 182.0, 20.000000000000014, 200.0, 97.39999999999999, 20.000000000000014, 20.000000000000014, 98.90000000000009, 69.49999999999997, 82.99999999999926, 20.000000000000014, 200.0, 20.000000000000014, -28.29999999999975, 9.499999999999964, 20.000000000000014, 163.99999999999977, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 165.5, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 10.0, 0.0, 18.0, 0.0, 10.0, 25.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.0, 23.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 5.0, 16.0, 8.0, 4.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 5.0, 10.0, 10.0, 10.0, 0.0, 10.0, 2.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 69.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 32.0, 19.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 12.0, 0.0, 13.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 0.0, 10.0, 5.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 4.0, 0.0, 16.0, 10.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2811581824461369, "mean_inference_ms": 3.566924806556999, "mean_action_processing_ms": 0.5642979204599571, "mean_env_wait_ms": 0.43145415995187825, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011772394180297852, "StateBufferConnector_ms": 0.004068493843078613, "ViewRequirementAgentConnector_ms": 0.19538307189941406}, "num_episodes": 18, "episode_return_max": 394.0, "episode_return_min": -7.29999999999972, "episode_return_mean": 162.74599999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 394.46572906494794, "num_env_steps_trained_throughput_per_sec": 394.46572906494794, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 14345.265, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14345.101, "sample_time_ms": 2632.989, "learn_time_ms": 11682.602, "learn_throughput": 342.389, "synch_weights_time_ms": 26.666}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "e57b0_00000", "date": "2024-08-13_00-36-16", "timestamp": 1723523776, "time_this_iter_s": 10.144218921661377, "time_total_s": 1547.090929031372, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b09cf820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1547.090929031372, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 42.0642857142857, "ram_util_percent": 72.98571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.169308249344901, "cur_kl_coeff": 9.712231019420866e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.305316250917142, "policy_loss": -0.0010454546206842654, "vf_loss": 5.306361707051595, "vf_explained_var": 0.6502102574974141, "kl": 0.005068192757093208, "entropy": 0.601077520863089, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5459402480532253, "cur_kl_coeff": 6.110407412052156e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3137458639564338, "policy_loss": -0.0022931268409131064, "vf_loss": 0.31603898996445373, "vf_explained_var": 0.013398560455867223, "kl": 0.009771277958732902, "entropy": 0.8599860371420623, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 4.200000000000202, "episode_reward_mean": 170.4609999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -46.30000000000021, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 69.0}, "policy_reward_mean": {"prey_policy": 80.85049999999997, "predator_policy": 4.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [211.1999999999993, 219.99999999999926, 333.4, 40.0000000000003, 40.0000000000003, 199.99999999999935, 60.70000000000051, 40.0000000000003, 40.0000000000003, 29.000000000000128, 394.0, 288.9999999999998, 326.7, 199.99999999999935, 217.79999999999927, 269.5000000000001, 152.6999999999996, 163.2999999999995, 40.0000000000003, 98.69999999999992, 160.59999999999954, 153.39999999999904, 329.80000000000143, 137.59999999999968, 144.69999999999962, 394.0, 219.99999999999926, 40.0000000000003, 40.0000000000003, 40.0000000000003, 136.89999999999966, 207.99999999999932, 167.7999999999995, 40.0000000000003, 191.1999999999994, 322.40000000000003, 182.79999999999944, 70.60000000000002, 120.79999999999887, 40.0000000000003, 132.0999999999997, 128.2999999999989, 40.0000000000003, 323.29999999999984, 219.99999999999926, 215.99999999999926, 42.700000000000344, 297.2000000000021, 34.50000000000022, 278.2999999999999, 217.79999999999927, 84.99999999999898, 208.99999999999932, 380.2000000000005, 192.49999999999937, 330.70000000000005, 205.59999999999934, 35.600000000000236, 356.0, 145.09999999999962, 111.99999999999858, 132.8999999999988, 99.0, 207.99999999999932, 306.3999999999999, 40.0000000000003, 184.40000000000003, 102.99999999999852, 219.99999999999926, 4.200000000000202, 183.99999999999903, 219.99999999999926, 219.99999999999926, 219.99999999999926, 40.0000000000003, 189.4999999999994, 40.0000000000003, 219.99999999999926, 94.59999999999998, 207.89999999999932, 40.0000000000003, 251.69999999999956, 37.80000000000027, 326.19999999999993, 400.0, 178.19999999999948, 40.0000000000003, 398.0, 30.800000000000168, 19.400000000000095, 384.0, 184.19999999999945, 273.0999999999997, 151.0999999999996, 266.9, 131.4999999999997, 268.5999999999999, 72.19999999999982, 137.69999999999965, 32.30000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 3.1999999999999633, 20.000000000000014, 200.0, 200.0, 133.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.099999999999983, 17.899999999999988, 200.0, 191.0, 101.90000000000006, 172.1, 170.0, 136.70000000000005, 170.0, 20.000000000000014, 15.799999999999963, 200.0, 160.4, 100.09999999999978, 3.1999999999999633, 141.5, 20.000000000000014, 143.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, -46.30000000000021, 140.6, 20.000000000000014, 133.3999999999997, 20.000000000000014, 129.79999999999956, 200.0, 20.000000000000014, 50.59999999999977, 20.000000000000014, 97.70000000000007, 200.0, 191.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.90000000000006, 182.0, 20.000000000000014, 20.000000000000014, 147.8, 20.000000000000014, 20.000000000000014, 171.2, 20.000000000000014, 142.39999999999998, 170.0, 144.8, 20.000000000000014, 20.90000000000003, 49.70000000000024, 90.79999999999951, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.10000000000008, 112.09999999999954, 3.199999999999965, 20.000000000000014, 20.000000000000014, 164.59999999999982, 157.7, 20.000000000000014, 200.0, 194.0, 20.000000000000014, 13.69999999999997, 20.000000000000014, 145.99999999999966, 141.19999999999982, 20.000000000000014, 9.499999999999964, 197.0, 80.2999999999993, 15.799999999999963, 200.0, 20.000000000000014, 65.00000000000014, -0.9999999999999952, 200.0, 200.0, 180.19999999999987, 165.5, 20.000000000000014, 200.0, 112.70000000000005, 20.000000000000014, 185.6, 20.000000000000014, 11.599999999999966, 170.0, 170.0, 136.1, -0.9999999999999846, 91.99999999999932, 20.000000000000014, 3.199999999999965, 121.6999999999995, 20.000000000000014, 50.000000000000085, 182.0, 20.000000000000014, 200.0, 97.39999999999999, 20.000000000000014, 20.000000000000014, 98.90000000000009, 69.49999999999997, 82.99999999999926, 20.000000000000014, 200.0, 20.000000000000014, -28.29999999999975, 9.499999999999964, 20.000000000000014, 163.99999999999977, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 165.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 38.60000000000011, 20.000000000000014, 200.0, -3.099999999999965, 20.000000000000014, 20.000000000000014, 43.69999999999996, 200.0, 20.000000000000014, 15.799999999999963, 200.0, 126.19999999999999, 200.0, 200.0, 122.30000000000003, 35.90000000000021, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, -26.19999999999976, 1.0999999999999652, 8.299999999999976, 200.0, 176.0, 3.1999999999999615, 170.0, 200.0, 73.09999999999955, 20.000000000000014, 124.09999999999998, 122.89999999999999, 131.0, 118.09999999999998, 7.399999999999965, 26.599999999999703, 173.0, 52.100000000000186, 1.0999999999999723, 20.000000000000014, 115.7, 5.2999999999999705, 20.000000000000014], "policy_predator_policy_reward": [8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 5.0, 10.0, 10.0, 10.0, 0.0, 10.0, 2.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 69.0, 56.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 32.0, 19.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 12.0, 0.0, 13.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 0.0, 10.0, 5.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 4.0, 0.0, 16.0, 10.0, 0.0, 0.0, 0.0, 0.0, 8.0, 29.0, 0.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 11.0, 0.0, 0.0, 8.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 1.0, 0.0, 15.0, 22.0, 1.0, 9.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 7.0, 0.0, 13.0, 0.0, 0.0, 6.0, 32.0, 37.0, 9.0, 10.0, 2.0, 0.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.281265927833501, "mean_inference_ms": 3.5711724501711357, "mean_action_processing_ms": 0.5640404093543238, "mean_env_wait_ms": 0.43198817405251594, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010921835899353027, "StateBufferConnector_ms": 0.005638718605041504, "ViewRequirementAgentConnector_ms": 0.16355860233306885}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 4.200000000000202, "episode_return_mean": 170.4609999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 283.151161652473, "num_env_steps_trained_throughput_per_sec": 283.151161652473, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 14452.614, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14452.452, "sample_time_ms": 2568.655, "learn_time_ms": 11854.119, "learn_throughput": 337.435, "synch_weights_time_ms": 26.756}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "e57b0_00000", "date": "2024-08-13_00-36-30", "timestamp": 1723523790, "time_this_iter_s": 14.13395094871521, "time_total_s": 1561.2248799800873, "pid": 66204, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b15838b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1561.2248799800873, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 55.815, "ram_util_percent": 72.64000000000001}}
