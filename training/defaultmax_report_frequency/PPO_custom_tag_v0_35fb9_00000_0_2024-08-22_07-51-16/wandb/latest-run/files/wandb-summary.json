{"num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 82.20278963777822, "num_env_steps_trained_throughput_per_sec": 82.20278963777822, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "training_iteration": 100, "timestamp": 1724299468, "time_this_iter_s": 48.7075469493866, "time_total_s": 6044.347722291946, "time_since_restore": 6044.347722291946, "iterations_since_restore": 100, "info/num_env_steps_sampled": 400000, "info/num_env_steps_trained": 400000, "info/num_agent_steps_sampled": 1600000, "info/num_agent_steps_trained": 1600000, "env_runners/episode_reward_max": 701.8176855550084, "env_runners/episode_reward_min": -49.92973053157165, "env_runners/episode_reward_mean": 201.6764318059315, "env_runners/episode_len_mean": 400.0, "env_runners/episodes_timesteps_total": 40000, "env_runners/num_faulty_episodes": 0, "env_runners/num_episodes": 10, "env_runners/episode_return_max": 701.8176855550084, "env_runners/episode_return_min": -49.92973053157165, "env_runners/episode_return_mean": 201.6764318059315, "env_runners/episodes_this_iter": 10, "timers/training_iteration_time_ms": 49148.887, "timers/restore_workers_time_ms": 0.015, "timers/training_step_time_ms": 49148.817, "timers/sample_time_ms": 2490.46, "timers/learn_time_ms": 46637.719, "timers/learn_throughput": 85.767, "timers/synch_weights_time_ms": 16.0, "counters/num_env_steps_sampled": 400000, "counters/num_env_steps_trained": 400000, "counters/num_agent_steps_sampled": 1600000, "counters/num_agent_steps_trained": 1600000, "perf/cpu_util_percent": 40.550000000000004, "perf/ram_util_percent": 82.79411764705881, "info/learner/prey_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/prey_policy/num_grad_updates_lifetime": 188055.5, "info/learner/prey_policy/diff_num_grad_updates_vs_sampler_policy": 944.5, "info/learner/predator_policy/num_agent_steps_trained": 126.98412698412699, "info/learner/predator_policy/num_grad_updates_lifetime": 188055.5, "info/learner/predator_policy/diff_num_grad_updates_vs_sampler_policy": 944.5, "info/learner/prey_policy/learner_stats/allreduce_latency": 0.0, "info/learner/prey_policy/learner_stats/grad_gnorm": 25.838768147791505, "info/learner/prey_policy/learner_stats/cur_kl_coeff": 0.2, "info/learner/prey_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/prey_policy/learner_stats/total_loss": 3.4121768304279874, "info/learner/prey_policy/learner_stats/policy_loss": -0.018711041082953295, "info/learner/prey_policy/learner_stats/vf_loss": 3.428661135138658, "info/learner/prey_policy/learner_stats/vf_explained_var": 0.5980250506804734, "info/learner/prey_policy/learner_stats/kl": 0.011133653800762085, "info/learner/prey_policy/learner_stats/entropy": 0.9638429328247353, "info/learner/prey_policy/learner_stats/entropy_coeff": 0.0, "info/learner/predator_policy/learner_stats/allreduce_latency": 0.0, "info/learner/predator_policy/learner_stats/grad_gnorm": 14.205216839893785, "info/learner/predator_policy/learner_stats/cur_kl_coeff": 0.2, "info/learner/predator_policy/learner_stats/cur_lr": 0.00010000000000000003, "info/learner/predator_policy/learner_stats/total_loss": 2.9209025485174998, "info/learner/predator_policy/learner_stats/policy_loss": -0.026811517364710137, "info/learner/predator_policy/learner_stats/vf_loss": 2.944804536980927, "info/learner/predator_policy/learner_stats/vf_explained_var": 0.18404591644882526, "info/learner/predator_policy/learner_stats/kl": 0.01454767724745488, "info/learner/predator_policy/learner_stats/entropy": 0.5979956605762401, "info/learner/predator_policy/learner_stats/entropy_coeff": 0.0, "_timestamp": 1724299468.320527, "_runtime": 6042.962826967239, "_step": 99, "env_runners/policy_reward_min/prey_policy": -809.3646033359919, "env_runners/policy_reward_min/predator_policy": 0.0, "env_runners/policy_reward_max/prey_policy": 391.9448276621356, "env_runners/policy_reward_max/predator_policy": 833.9200465959464, "env_runners/policy_reward_mean/prey_policy": -100.0398185707875, "env_runners/policy_reward_mean/predator_policy": 200.87803447375327, "env_runners/sampler_perf/mean_raw_obs_processing_ms": 4.908851314715242, "env_runners/sampler_perf/mean_inference_ms": 4.53586346189933, "env_runners/sampler_perf/mean_action_processing_ms": 1.495823470506138, "env_runners/sampler_perf/mean_env_wait_ms": 10.620282763767593, "env_runners/sampler_perf/mean_env_render_ms": 0.0, "env_runners/connector_metrics/ObsPreprocessorConnector_ms": 0.006043076515197754, "env_runners/connector_metrics/StateBufferConnector_ms": 0.01749706268310547, "env_runners/connector_metrics/ViewRequirementAgentConnector_ms": 0.12426185607910156}