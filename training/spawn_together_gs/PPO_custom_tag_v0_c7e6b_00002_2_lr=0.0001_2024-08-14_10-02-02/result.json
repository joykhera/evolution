{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.690304826854398, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.51425615744616, "policy_loss": -0.003143498028022429, "vf_loss": 8.515940021080945, "vf_explained_var": -0.0029469690310261237, "kl": 0.007298155868317769, "entropy": 1.6022077731354527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.367917710952658, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.564372134839417, "policy_loss": -0.009243577389076116, "vf_loss": 7.571028623379097, "vf_explained_var": -0.005062117936119201, "kl": 0.012935449759979314, "entropy": 1.596521354730798, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 53.40000000000014, "episode_reward_min": -222.10000000000028, "episode_reward_mean": -81.22222222222237, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 11.0}, "policy_reward_max": {"prey_policy": 97.09999999999971, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -133.69444444444454, "predator_policy": 93.08333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.999999999999913, -218.50000000000014, -129.60000000000082, -194.40000000000077, -33.19999999999974, -222.10000000000028, -153.00000000000009, -187.1000000000007, -89.5000000000004, 0.9000000000000056, 39.10000000000007, -44.59999999999993, -55.000000000000284, -57.20000000000034, 53.40000000000014, -45.99999999999984, -56.69999999999986, -61.49999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999828, -30.099999999999834, -158.50000000000014, -352.0, -28.299999999999773, -275.30000000000035, -223.60000000000048, -206.8000000000003, 21.800000000000047, -261.9999999999992, -90.70000000000024, -372.4, -85.00000000000001, -168.99999999999986, -189.99999999999994, -219.10000000000045, -49.00000000000003, -242.50000000000043, -381.0999999999999, 80.0, 97.09999999999971, -397.0, -165.4, -32.19999999999999, 23.900000000000027, -229.9000000000003, -238.30000000000015, 37.09999999999999, -54.99999999999996, 25.400000000000098, -22.299999999999933, -165.70000000000027, -192.1000000000004, -1.5999999999999996, -198.40000000000038, -45.10000000000003], "policy_predator_policy_reward": [11.0, 32.0, 135.0, 157.0, 23.0, 151.0, 120.0, 116.0, 88.0, 119.0, 179.0, 62.0, 81.0, 20.0, 142.0, 80.0, 129.0, 73.0, 128.0, 174.0, 175.0, 164.0, 117.0, 36.0, 128.0, 23.0, 24.0, 120.0, 65.0, 18.0, 115.0, 27.0, 29.0, 108.0, 84.0, 98.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5449381600368716, "mean_inference_ms": 1.46836125379441, "mean_action_processing_ms": 0.23994671575192467, "mean_env_wait_ms": 0.18530531503992126, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005471044116550022, "StateBufferConnector_ms": 0.002825922436184353, "ViewRequirementAgentConnector_ms": 0.09750591384039985}, "num_episodes": 18, "episode_return_max": 53.40000000000014, "episode_return_min": -222.10000000000028, "episode_return_mean": -81.22222222222237, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 417.34560221234847, "num_env_steps_trained_throughput_per_sec": 417.34560221234847, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 9584.391, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9584.347, "sample_time_ms": 1181.158, "learn_time_ms": 8385.352, "learn_throughput": 477.022, "synch_weights_time_ms": 16.678}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-24-46", "timestamp": 1723645486, "time_this_iter_s": 9.601379156112671, "time_total_s": 9.601379156112671, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d6700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9.601379156112671, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 29.314285714285713, "ram_util_percent": 81.94285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1936948900184934, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.853037995131558, "policy_loss": -0.00380535805548625, "vf_loss": 7.8550247813028005, "vf_explained_var": 0.006590168785165857, "kl": 0.009092866602033426, "entropy": 1.5937486520519963, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.39633962404791, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.74033520133407, "policy_loss": -0.006247706108765982, "vf_loss": 5.744807816813232, "vf_explained_var": 0.004197599427409904, "kl": 0.008875423303596022, "entropy": 1.593391251311731, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 245.89999999999947, "episode_reward_min": -310.9999999999989, "episode_reward_mean": -49.76944444444459, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 143.59999999999997, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -104.4402777777779, "predator_policy": 79.55555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.999999999999913, -218.50000000000014, -129.60000000000082, -194.40000000000077, -33.19999999999974, -222.10000000000028, -153.00000000000009, -187.1000000000007, -89.5000000000004, 0.9000000000000056, 39.10000000000007, -44.59999999999993, -55.000000000000284, -57.20000000000034, 53.40000000000014, -45.99999999999984, -56.69999999999986, -61.49999999999982, -124.90000000000055, 245.89999999999947, 37.000000000000256, -119.20000000000073, 167.89999999999947, -111.40000000000013, 48.200000000000145, 42.30000000000034, 18.89999999999958, -117.50000000000054, 155.5999999999994, 1.0999999999997112, -7.099999999999746, -21.39999999999985, -112.30000000000015, -83.50000000000037, -310.9999999999989, -38.29999999999988], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999828, -30.099999999999834, -158.50000000000014, -352.0, -28.299999999999773, -275.30000000000035, -223.60000000000048, -206.8000000000003, 21.800000000000047, -261.9999999999992, -90.70000000000024, -372.4, -85.00000000000001, -168.99999999999986, -189.99999999999994, -219.10000000000045, -49.00000000000003, -242.50000000000043, -381.0999999999999, 80.0, 97.09999999999971, -397.0, -165.4, -32.19999999999999, 23.900000000000027, -229.9000000000003, -238.30000000000015, 37.09999999999999, -54.99999999999996, 25.400000000000098, -22.299999999999933, -165.70000000000027, -192.1000000000004, -1.5999999999999996, -198.40000000000038, -45.10000000000003, -227.80000000000015, -51.099999999999916, 71.29999999999963, 143.59999999999997, 20.000000000000014, -0.9999999999999846, -299.70000000000016, -5.499999999999924, 20.000000000000014, 128.9, -182.2, -86.2000000000008, -120.70000000000076, 35.90000000000002, -29.199999999999783, 18.500000000000057, -17.200000000000188, -151.90000000000015, -173.2000000000005, -151.30000000000004, 58.10000000000006, 27.500000000000107, -171.1000000000006, 42.200000000000124, 29.90000000000009, -135.00000000000063, -129.7000000000005, 5.300000000000004, -309.70000000000005, 7.399999999999956, -187.30000000000007, -68.20000000000027, -301.60000000000014, -240.40000000000043, -265.9, -9.399999999999968], "policy_predator_policy_reward": [11.0, 32.0, 135.0, 157.0, 23.0, 151.0, 120.0, 116.0, 88.0, 119.0, 179.0, 62.0, 81.0, 20.0, 142.0, 80.0, 129.0, 73.0, 128.0, 174.0, 175.0, 164.0, 117.0, 36.0, 128.0, 23.0, 24.0, 120.0, 65.0, 18.0, 115.0, 27.0, 29.0, 108.0, 84.0, 98.0, 96.0, 58.0, 17.0, 14.0, 9.0, 9.0, 162.0, 24.0, 1.0, 18.0, 136.0, 21.0, 89.0, 44.0, 27.0, 26.0, 83.0, 105.0, 115.0, 92.0, 35.0, 35.0, 35.0, 95.0, 79.0, 19.0, 38.0, 65.0, 34.0, 156.0, 103.0, 69.0, 145.0, 86.0, 141.0, 96.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5338503251611788, "mean_inference_ms": 1.4161924969848951, "mean_action_processing_ms": 0.23204464115034748, "mean_env_wait_ms": 0.18104589487175934, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0059780147340562605, "StateBufferConnector_ms": 0.0027447938919067383, "ViewRequirementAgentConnector_ms": 0.09107689062754314}, "num_episodes": 18, "episode_return_max": 245.89999999999947, "episode_return_min": -310.9999999999989, "episode_return_mean": -49.76944444444459, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 429.1841901191135, "num_env_steps_trained_throughput_per_sec": 429.1841901191135, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 9452.21, "restore_workers_time_ms": 0.023, "training_step_time_ms": 9452.147, "sample_time_ms": 1094.337, "learn_time_ms": 8342.788, "learn_throughput": 479.456, "synch_weights_time_ms": 13.978}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-24-58", "timestamp": 1723645498, "time_this_iter_s": 9.36446499824524, "time_total_s": 18.96584415435791, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ad369d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 18.96584415435791, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 28.0625, "ram_util_percent": 83.36875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7492855092205066, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.364147861672457, "policy_loss": -0.0020765192267144955, "vf_loss": 6.364674474070312, "vf_explained_var": -0.0026745764351395703, "kl": 0.00774953985910611, "entropy": 1.5827961641644674, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.702706004639782, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.9673276073718196, "policy_loss": -0.007833480760923257, "vf_loss": 3.9731969699657785, "vf_explained_var": 0.03228298993337722, "kl": 0.009820615843066033, "entropy": 1.5796993249938602, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 245.89999999999947, "episode_reward_min": -310.9999999999989, "episode_reward_mean": -36.44259259259273, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.49999999999974, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -89.0916666666668, "predator_policy": 70.87037037037037}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.999999999999913, -218.50000000000014, -129.60000000000082, -194.40000000000077, -33.19999999999974, -222.10000000000028, -153.00000000000009, -187.1000000000007, -89.5000000000004, 0.9000000000000056, 39.10000000000007, -44.59999999999993, -55.000000000000284, -57.20000000000034, 53.40000000000014, -45.99999999999984, -56.69999999999986, -61.49999999999982, -124.90000000000055, 245.89999999999947, 37.000000000000256, -119.20000000000073, 167.89999999999947, -111.40000000000013, 48.200000000000145, 42.30000000000034, 18.89999999999958, -117.50000000000054, 155.5999999999994, 1.0999999999997112, -7.099999999999746, -21.39999999999985, -112.30000000000015, -83.50000000000037, -310.9999999999989, -38.29999999999988, -75.00000000000117, -48.59999999999974, 36.70000000000002, 70.89999999999984, 1.6999999999999698, 67.20000000000012, -58.99999999999961, -48.50000000000001, -74.90000000000055, -17.199999999999598, -93.69999999999993, 195.59999999999974, -41.80000000000015, -28.99999999999971, 112.09999999999985, 53.10000000000042, -99.30000000000095, -126.50000000000091], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999828, -30.099999999999834, -158.50000000000014, -352.0, -28.299999999999773, -275.30000000000035, -223.60000000000048, -206.8000000000003, 21.800000000000047, -261.9999999999992, -90.70000000000024, -372.4, -85.00000000000001, -168.99999999999986, -189.99999999999994, -219.10000000000045, -49.00000000000003, -242.50000000000043, -381.0999999999999, 80.0, 97.09999999999971, -397.0, -165.4, -32.19999999999999, 23.900000000000027, -229.9000000000003, -238.30000000000015, 37.09999999999999, -54.99999999999996, 25.400000000000098, -22.299999999999933, -165.70000000000027, -192.1000000000004, -1.5999999999999996, -198.40000000000038, -45.10000000000003, -227.80000000000015, -51.099999999999916, 71.29999999999963, 143.59999999999997, 20.000000000000014, -0.9999999999999846, -299.70000000000016, -5.499999999999924, 20.000000000000014, 128.9, -182.2, -86.2000000000008, -120.70000000000076, 35.90000000000002, -29.199999999999783, 18.500000000000057, -17.200000000000188, -151.90000000000015, -173.2000000000005, -151.30000000000004, 58.10000000000006, 27.500000000000107, -171.1000000000006, 42.200000000000124, 29.90000000000009, -135.00000000000063, -129.7000000000005, 5.300000000000004, -309.70000000000005, 7.399999999999956, -187.30000000000007, -68.20000000000027, -301.60000000000014, -240.40000000000043, -265.9, -9.399999999999968, -196.6000000000004, -66.40000000000076, -93.4000000000008, -38.19999999999976, -34.29999999999978, 29.00000000000007, 20.000000000000014, 2.900000000000005, 44.3000000000001, -151.6000000000006, -48.099999999999824, 59.30000000000019, -76.59999999999995, -72.40000000000089, -173.20000000000059, -34.29999999999982, -157.30000000000027, -55.59999999999982, 20.000000000000014, -131.20000000000073, -238.80000000000035, -19.899999999999743, -94.90000000000012, 150.49999999999974, -39.399999999999764, -120.40000000000049, -68.80000000000078, -11.19999999999992, -97.8000000000007, 128.89999999999995, 20.000000000000014, 1.09999999999999, -68.20000000000043, -198.1000000000005, -125.50000000000048, -166.0000000000001], "policy_predator_policy_reward": [11.0, 32.0, 135.0, 157.0, 23.0, 151.0, 120.0, 116.0, 88.0, 119.0, 179.0, 62.0, 81.0, 20.0, 142.0, 80.0, 129.0, 73.0, 128.0, 174.0, 175.0, 164.0, 117.0, 36.0, 128.0, 23.0, 24.0, 120.0, 65.0, 18.0, 115.0, 27.0, 29.0, 108.0, 84.0, 98.0, 96.0, 58.0, 17.0, 14.0, 9.0, 9.0, 162.0, 24.0, 1.0, 18.0, 136.0, 21.0, 89.0, 44.0, 27.0, 26.0, 83.0, 105.0, 115.0, 92.0, 35.0, 35.0, 35.0, 95.0, 79.0, 19.0, 38.0, 65.0, 34.0, 156.0, 103.0, 69.0, 145.0, 86.0, 141.0, 96.0, 99.0, 89.0, 61.0, 22.0, 11.0, 31.0, 19.0, 29.0, 27.0, 82.0, 15.0, 41.0, 44.0, 46.0, 80.0, 79.0, 57.0, 81.0, 68.0, 26.0, 62.0, 103.0, 73.0, 67.0, 61.0, 57.0, 51.0, 0.0, 12.0, 69.0, 14.0, 18.0, 53.0, 114.0, 123.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5333890064894455, "mean_inference_ms": 1.3979825261006482, "mean_action_processing_ms": 0.2293951812213952, "mean_env_wait_ms": 0.17961596987717757, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005793571472167969, "StateBufferConnector_ms": 0.0027449042708785447, "ViewRequirementAgentConnector_ms": 0.08840759595235188}, "num_episodes": 18, "episode_return_max": 245.89999999999947, "episode_return_min": -310.9999999999989, "episode_return_mean": -36.44259259259273, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 427.9281326693276, "num_env_steps_trained_throughput_per_sec": 427.9281326693276, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 9417.264, "restore_workers_time_ms": 0.02, "training_step_time_ms": 9417.209, "sample_time_ms": 1100.059, "learn_time_ms": 8303.023, "learn_throughput": 481.752, "synch_weights_time_ms": 13.131}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-25-07", "timestamp": 1723645507, "time_this_iter_s": 9.350589990615845, "time_total_s": 28.316434144973755, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ad36940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 28.316434144973755, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 29.77857142857143, "ram_util_percent": 83.13571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.087739723258548, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.475166697350759, "policy_loss": -0.002299953995410491, "vf_loss": 5.47614262999681, "vf_explained_var": 0.0049257946077478, "kl": 0.006620029481501858, "entropy": 1.5955157132375808, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.671878034696377, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.367792969027524, "policy_loss": -0.012310237143676551, "vf_loss": 3.3773968258232037, "vf_explained_var": 0.05989395928761316, "kl": 0.013531885614599755, "entropy": 1.570842711761515, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 245.89999999999947, "episode_reward_min": -310.9999999999989, "episode_reward_mean": -25.779166666666793, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.49999999999974, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -78.27847222222238, "predator_policy": 65.38888888888889}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.999999999999913, -218.50000000000014, -129.60000000000082, -194.40000000000077, -33.19999999999974, -222.10000000000028, -153.00000000000009, -187.1000000000007, -89.5000000000004, 0.9000000000000056, 39.10000000000007, -44.59999999999993, -55.000000000000284, -57.20000000000034, 53.40000000000014, -45.99999999999984, -56.69999999999986, -61.49999999999982, -124.90000000000055, 245.89999999999947, 37.000000000000256, -119.20000000000073, 167.89999999999947, -111.40000000000013, 48.200000000000145, 42.30000000000034, 18.89999999999958, -117.50000000000054, 155.5999999999994, 1.0999999999997112, -7.099999999999746, -21.39999999999985, -112.30000000000015, -83.50000000000037, -310.9999999999989, -38.29999999999988, -75.00000000000117, -48.59999999999974, 36.70000000000002, 70.89999999999984, 1.6999999999999698, 67.20000000000012, -58.99999999999961, -48.50000000000001, -74.90000000000055, -17.199999999999598, -93.69999999999993, 195.59999999999974, -41.80000000000015, -28.99999999999971, 112.09999999999985, 53.10000000000042, -99.30000000000095, -126.50000000000091, 103.09999999999923, -164.40000000000123, -53.90000000000016, 39.10000000000014, 32.20000000000006, 9.2000000000001, -108.20000000000093, 13.700000000000042, 44.50000000000019, 79.3999999999999, 67.29999999999995, 6.400000000000077, -49.699999999999804, 41.10000000000016, 17.100000000000062, 30.40000000000031, -11.299999999999898, 15.800000000000075], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999828, -30.099999999999834, -158.50000000000014, -352.0, -28.299999999999773, -275.30000000000035, -223.60000000000048, -206.8000000000003, 21.800000000000047, -261.9999999999992, -90.70000000000024, -372.4, -85.00000000000001, -168.99999999999986, -189.99999999999994, -219.10000000000045, -49.00000000000003, -242.50000000000043, -381.0999999999999, 80.0, 97.09999999999971, -397.0, -165.4, -32.19999999999999, 23.900000000000027, -229.9000000000003, -238.30000000000015, 37.09999999999999, -54.99999999999996, 25.400000000000098, -22.299999999999933, -165.70000000000027, -192.1000000000004, -1.5999999999999996, -198.40000000000038, -45.10000000000003, -227.80000000000015, -51.099999999999916, 71.29999999999963, 143.59999999999997, 20.000000000000014, -0.9999999999999846, -299.70000000000016, -5.499999999999924, 20.000000000000014, 128.9, -182.2, -86.2000000000008, -120.70000000000076, 35.90000000000002, -29.199999999999783, 18.500000000000057, -17.200000000000188, -151.90000000000015, -173.2000000000005, -151.30000000000004, 58.10000000000006, 27.500000000000107, -171.1000000000006, 42.200000000000124, 29.90000000000009, -135.00000000000063, -129.7000000000005, 5.300000000000004, -309.70000000000005, 7.399999999999956, -187.30000000000007, -68.20000000000027, -301.60000000000014, -240.40000000000043, -265.9, -9.399999999999968, -196.6000000000004, -66.40000000000076, -93.4000000000008, -38.19999999999976, -34.29999999999978, 29.00000000000007, 20.000000000000014, 2.900000000000005, 44.3000000000001, -151.6000000000006, -48.099999999999824, 59.30000000000019, -76.59999999999995, -72.40000000000089, -173.20000000000059, -34.29999999999982, -157.30000000000027, -55.59999999999982, 20.000000000000014, -131.20000000000073, -238.80000000000035, -19.899999999999743, -94.90000000000012, 150.49999999999974, -39.399999999999764, -120.40000000000049, -68.80000000000078, -11.19999999999992, -97.8000000000007, 128.89999999999995, 20.000000000000014, 1.09999999999999, -68.20000000000043, -198.1000000000005, -125.50000000000048, -166.0000000000001, -68.20000000000051, 125.29999999999966, -221.1000000000005, -157.30000000000072, -131.2000000000005, -45.7000000000001, 23.600000000000083, -11.499999999999819, 81.19999999999997, -160.00000000000006, -91.90000000000069, 37.100000000000115, -198.40000000000032, -65.80000000000064, -57.1000000000003, 9.799999999999958, 20.000000000000014, -20.499999999999844, 80.29999999999964, -82.9000000000008, 20.000000000000014, -0.6999999999999318, 50.600000000000115, -131.20000000000073, -349.59999999999957, 53.900000000000006, -10.299999999999999, -55.60000000000028, 39.80000000000006, -105.70000000000064, 93.79999999999933, -156.4000000000004, 59.90000000000019, -161.20000000000024, -32.49999999999975, -30.699999999999896], "policy_predator_policy_reward": [11.0, 32.0, 135.0, 157.0, 23.0, 151.0, 120.0, 116.0, 88.0, 119.0, 179.0, 62.0, 81.0, 20.0, 142.0, 80.0, 129.0, 73.0, 128.0, 174.0, 175.0, 164.0, 117.0, 36.0, 128.0, 23.0, 24.0, 120.0, 65.0, 18.0, 115.0, 27.0, 29.0, 108.0, 84.0, 98.0, 96.0, 58.0, 17.0, 14.0, 9.0, 9.0, 162.0, 24.0, 1.0, 18.0, 136.0, 21.0, 89.0, 44.0, 27.0, 26.0, 83.0, 105.0, 115.0, 92.0, 35.0, 35.0, 35.0, 95.0, 79.0, 19.0, 38.0, 65.0, 34.0, 156.0, 103.0, 69.0, 145.0, 86.0, 141.0, 96.0, 99.0, 89.0, 61.0, 22.0, 11.0, 31.0, 19.0, 29.0, 27.0, 82.0, 15.0, 41.0, 44.0, 46.0, 80.0, 79.0, 57.0, 81.0, 68.0, 26.0, 62.0, 103.0, 73.0, 67.0, 61.0, 57.0, 51.0, 0.0, 12.0, 69.0, 14.0, 18.0, 53.0, 114.0, 123.0, 42.0, 6.0, 40.0, 77.0, 137.0, 72.0, 51.0, 24.0, 3.0, 99.0, 12.0, 21.0, 43.0, 106.0, 50.0, 21.0, 40.0, 35.0, 10.0, 52.0, 30.0, 34.0, 14.0, 83.0, 4.0, 149.0, 97.0, 40.0, 67.0, 65.0, 18.0, 79.0, 14.0, 2.0, 88.0, 39.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5303523070049267, "mean_inference_ms": 1.3821554091477728, "mean_action_processing_ms": 0.226893129526216, "mean_env_wait_ms": 0.17781222970080307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005694395966000027, "StateBufferConnector_ms": 0.0027323762575785318, "ViewRequirementAgentConnector_ms": 0.08607059717178345}, "num_episodes": 18, "episode_return_max": 245.89999999999947, "episode_return_min": -310.9999999999989, "episode_return_mean": -25.779166666666793, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 431.347662434036, "num_env_steps_trained_throughput_per_sec": 431.347662434036, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 9381.266, "restore_workers_time_ms": 0.018, "training_step_time_ms": 9381.215, "sample_time_ms": 1073.275, "learn_time_ms": 8293.898, "learn_throughput": 482.282, "synch_weights_time_ms": 12.985}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-25-16", "timestamp": 1723645516, "time_this_iter_s": 9.309750080108643, "time_total_s": 37.6261842250824, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39aef93a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 37.6261842250824, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 29.96153846153846, "ram_util_percent": 83.29230769230769}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1820768762360174, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.649382286223155, "policy_loss": -0.0059080578082502284, "vf_loss": 6.652779203243356, "vf_explained_var": 0.02755225937833231, "kl": 0.01255577395698991, "entropy": 1.5905918561592305, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9949454699874556, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.4332857264412775, "policy_loss": -0.007247254084771075, "vf_loss": 4.438696711782425, "vf_explained_var": 0.04472587824498535, "kl": 0.009181397616073752, "entropy": 1.5572566016641243, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 245.89999999999947, "episode_reward_min": -310.9999999999989, "episode_reward_mean": -20.8020202020204, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -397.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.0, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": -70.54747474747491, "predator_policy": 60.14646464646464}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.999999999999913, -218.50000000000014, -129.60000000000082, -194.40000000000077, -33.19999999999974, -222.10000000000028, -153.00000000000009, -187.1000000000007, -89.5000000000004, 0.9000000000000056, 39.10000000000007, -44.59999999999993, -55.000000000000284, -57.20000000000034, 53.40000000000014, -45.99999999999984, -56.69999999999986, -61.49999999999982, -124.90000000000055, 245.89999999999947, 37.000000000000256, -119.20000000000073, 167.89999999999947, -111.40000000000013, 48.200000000000145, 42.30000000000034, 18.89999999999958, -117.50000000000054, 155.5999999999994, 1.0999999999997112, -7.099999999999746, -21.39999999999985, -112.30000000000015, -83.50000000000037, -310.9999999999989, -38.29999999999988, -75.00000000000117, -48.59999999999974, 36.70000000000002, 70.89999999999984, 1.6999999999999698, 67.20000000000012, -58.99999999999961, -48.50000000000001, -74.90000000000055, -17.199999999999598, -93.69999999999993, 195.59999999999974, -41.80000000000015, -28.99999999999971, 112.09999999999985, 53.10000000000042, -99.30000000000095, -126.50000000000091, 103.09999999999923, -164.40000000000123, -53.90000000000016, 39.10000000000014, 32.20000000000006, 9.2000000000001, -108.20000000000093, 13.700000000000042, 44.50000000000019, 79.3999999999999, 67.29999999999995, 6.400000000000077, -49.699999999999804, 41.10000000000016, 17.100000000000062, 30.40000000000031, -11.299999999999898, 15.800000000000075, -13.49999999999986, -54.89999999999998, 124.9999999999986, -3.399999999999956, -52.99999999999993, -158.40000000000123, 103.09999999999981, -36.59999999999994, -26.099999999999568, -33.90000000000025, 21.29999999999999, -17.19999999999991, -16.499999999999808, 121.79999999999917, -118.30000000000138, -160.70000000000113, 86.39999999999982, 116.19999999999945, -61.400000000001256, -12.699999999999612, 100.89999999999986, 15.399999999999972, 186.8999999999993, -85.20000000000024, -222.70000000000041, 115.89999999999961, -121.70000000000113], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999828, -30.099999999999834, -158.50000000000014, -352.0, -28.299999999999773, -275.30000000000035, -223.60000000000048, -206.8000000000003, 21.800000000000047, -261.9999999999992, -90.70000000000024, -372.4, -85.00000000000001, -168.99999999999986, -189.99999999999994, -219.10000000000045, -49.00000000000003, -242.50000000000043, -381.0999999999999, 80.0, 97.09999999999971, -397.0, -165.4, -32.19999999999999, 23.900000000000027, -229.9000000000003, -238.30000000000015, 37.09999999999999, -54.99999999999996, 25.400000000000098, -22.299999999999933, -165.70000000000027, -192.1000000000004, -1.5999999999999996, -198.40000000000038, -45.10000000000003, -227.80000000000015, -51.099999999999916, 71.29999999999963, 143.59999999999997, 20.000000000000014, -0.9999999999999846, -299.70000000000016, -5.499999999999924, 20.000000000000014, 128.9, -182.2, -86.2000000000008, -120.70000000000076, 35.90000000000002, -29.199999999999783, 18.500000000000057, -17.200000000000188, -151.90000000000015, -173.2000000000005, -151.30000000000004, 58.10000000000006, 27.500000000000107, -171.1000000000006, 42.200000000000124, 29.90000000000009, -135.00000000000063, -129.7000000000005, 5.300000000000004, -309.70000000000005, 7.399999999999956, -187.30000000000007, -68.20000000000027, -301.60000000000014, -240.40000000000043, -265.9, -9.399999999999968, -196.6000000000004, -66.40000000000076, -93.4000000000008, -38.19999999999976, -34.29999999999978, 29.00000000000007, 20.000000000000014, 2.900000000000005, 44.3000000000001, -151.6000000000006, -48.099999999999824, 59.30000000000019, -76.59999999999995, -72.40000000000089, -173.20000000000059, -34.29999999999982, -157.30000000000027, -55.59999999999982, 20.000000000000014, -131.20000000000073, -238.80000000000035, -19.899999999999743, -94.90000000000012, 150.49999999999974, -39.399999999999764, -120.40000000000049, -68.80000000000078, -11.19999999999992, -97.8000000000007, 128.89999999999995, 20.000000000000014, 1.09999999999999, -68.20000000000043, -198.1000000000005, -125.50000000000048, -166.0000000000001, -68.20000000000051, 125.29999999999966, -221.1000000000005, -157.30000000000072, -131.2000000000005, -45.7000000000001, 23.600000000000083, -11.499999999999819, 81.19999999999997, -160.00000000000006, -91.90000000000069, 37.100000000000115, -198.40000000000032, -65.80000000000064, -57.1000000000003, 9.799999999999958, 20.000000000000014, -20.499999999999844, 80.29999999999964, -82.9000000000008, 20.000000000000014, -0.6999999999999318, 50.600000000000115, -131.20000000000073, -349.59999999999957, 53.900000000000006, -10.299999999999999, -55.60000000000028, 39.80000000000006, -105.70000000000064, 93.79999999999933, -156.4000000000004, 59.90000000000019, -161.20000000000024, -32.49999999999975, -30.699999999999896, -28.59999999999989, -97.89999999999998, -54.99999999999986, -148.89999999999995, 42.200000000000216, 60.80000000000015, -7.899999999999952, -116.49999999999997, -179.80000000000018, -2.1999999999999758, -208.90000000000052, -71.50000000000063, 82.99999999999996, 7.099999999999973, -45.69999999999987, -82.8999999999998, -19.899999999999764, -62.2000000000007, -54.70000000000024, -26.199999999999818, -39.399999999999764, 22.700000000000063, 14.600000000000042, -185.79999999999993, -5.1999999999999265, -70.3000000000002, -12.09999999999988, 107.89999999999972, -144.30000000000067, -127.00000000000063, -89.2000000000007, -242.50000000000043, -79.30000000000084, 85.69999999999993, 23.30000000000001, -3.100000000000008, -38.19999999999982, -98.20000000000068, 13.399999999999956, -87.1000000000007, 173.0, -180.1000000000005, -13.599999999999854, -21.999999999999744, 39.500000000000135, 115.39999999999993, -233.50000000000017, -0.7000000000000134, -156.70000000000047, -253.00000000000003, 17.000000000000036, 47.90000000000009, -123.10000000000068, -136.60000000000045], "policy_predator_policy_reward": [11.0, 32.0, 135.0, 157.0, 23.0, 151.0, 120.0, 116.0, 88.0, 119.0, 179.0, 62.0, 81.0, 20.0, 142.0, 80.0, 129.0, 73.0, 128.0, 174.0, 175.0, 164.0, 117.0, 36.0, 128.0, 23.0, 24.0, 120.0, 65.0, 18.0, 115.0, 27.0, 29.0, 108.0, 84.0, 98.0, 96.0, 58.0, 17.0, 14.0, 9.0, 9.0, 162.0, 24.0, 1.0, 18.0, 136.0, 21.0, 89.0, 44.0, 27.0, 26.0, 83.0, 105.0, 115.0, 92.0, 35.0, 35.0, 35.0, 95.0, 79.0, 19.0, 38.0, 65.0, 34.0, 156.0, 103.0, 69.0, 145.0, 86.0, 141.0, 96.0, 99.0, 89.0, 61.0, 22.0, 11.0, 31.0, 19.0, 29.0, 27.0, 82.0, 15.0, 41.0, 44.0, 46.0, 80.0, 79.0, 57.0, 81.0, 68.0, 26.0, 62.0, 103.0, 73.0, 67.0, 61.0, 57.0, 51.0, 0.0, 12.0, 69.0, 14.0, 18.0, 53.0, 114.0, 123.0, 42.0, 6.0, 40.0, 77.0, 137.0, 72.0, 51.0, 24.0, 3.0, 99.0, 12.0, 21.0, 43.0, 106.0, 50.0, 21.0, 40.0, 35.0, 10.0, 52.0, 30.0, 34.0, 14.0, 83.0, 4.0, 149.0, 97.0, 40.0, 67.0, 65.0, 18.0, 79.0, 14.0, 2.0, 88.0, 39.0, 40.0, 10.0, 103.0, 45.0, 104.0, 11.0, 11.0, 29.0, 92.0, 10.0, 119.0, 90.0, 32.0, 13.0, 0.0, 55.0, 37.0, 1.0, 55.0, 1.0, 46.0, 30.0, 8.0, 96.0, 58.0, 17.0, 42.0, 6.0, 20.0, 103.0, 50.0, 51.0, 120.0, 31.0, 49.0, 26.0, 70.0, 5.0, 70.0, 49.0, 12.0, 86.0, 22.0, 26.0, 25.0, 15.0, 17.0, 136.0, 13.0, 15.0, 172.0, 46.0, 5.0, 93.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5277383231872474, "mean_inference_ms": 1.3664588628926686, "mean_action_processing_ms": 0.22452332397909608, "mean_env_wait_ms": 0.1760185581824762, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006776265423707288, "StateBufferConnector_ms": 0.0028506673947729247, "ViewRequirementAgentConnector_ms": 0.09010572626133158}, "num_episodes": 27, "episode_return_max": 245.89999999999947, "episode_return_min": -310.9999999999989, "episode_return_mean": -20.8020202020204, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 436.28081955871374, "num_env_steps_trained_throughput_per_sec": 436.28081955871374, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 9338.695, "restore_workers_time_ms": 0.017, "training_step_time_ms": 9338.648, "sample_time_ms": 1064.011, "learn_time_ms": 8260.85, "learn_throughput": 484.212, "synch_weights_time_ms": 12.772}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-25-25", "timestamp": 1723645525, "time_this_iter_s": 9.171487092971802, "time_total_s": 46.7976713180542, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 46.7976713180542, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 26.96153846153846, "ram_util_percent": 83.5153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7344875178639851, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.753656924212421, "policy_loss": -0.011569489449849008, "vf_loss": 7.7616210147817295, "vf_explained_var": 0.02114923713068483, "kl": 0.018026975332701093, "entropy": 1.5811159511091848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0984664486198827, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.4014472509818106, "policy_loss": -0.006838008230699907, "vf_loss": 6.406439188548497, "vf_explained_var": -0.01008807685640123, "kl": 0.009230373946054986, "entropy": 1.5690081056463656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 245.89999999999947, "episode_reward_min": -310.9999999999989, "episode_reward_mean": -9.367000000000207, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.29999999999993, "predator_policy": 172.0}, "policy_reward_mean": {"prey_policy": -60.823500000000166, "predator_policy": 56.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-61.49999999999982, -124.90000000000055, 245.89999999999947, 37.000000000000256, -119.20000000000073, 167.89999999999947, -111.40000000000013, 48.200000000000145, 42.30000000000034, 18.89999999999958, -117.50000000000054, 155.5999999999994, 1.0999999999997112, -7.099999999999746, -21.39999999999985, -112.30000000000015, -83.50000000000037, -310.9999999999989, -38.29999999999988, -75.00000000000117, -48.59999999999974, 36.70000000000002, 70.89999999999984, 1.6999999999999698, 67.20000000000012, -58.99999999999961, -48.50000000000001, -74.90000000000055, -17.199999999999598, -93.69999999999993, 195.59999999999974, -41.80000000000015, -28.99999999999971, 112.09999999999985, 53.10000000000042, -99.30000000000095, -126.50000000000091, 103.09999999999923, -164.40000000000123, -53.90000000000016, 39.10000000000014, 32.20000000000006, 9.2000000000001, -108.20000000000093, 13.700000000000042, 44.50000000000019, 79.3999999999999, 67.29999999999995, 6.400000000000077, -49.699999999999804, 41.10000000000016, 17.100000000000062, 30.40000000000031, -11.299999999999898, 15.800000000000075, -13.49999999999986, -54.89999999999998, 124.9999999999986, -3.399999999999956, -52.99999999999993, -158.40000000000123, 103.09999999999981, -36.59999999999994, -26.099999999999568, -33.90000000000025, 21.29999999999999, -17.19999999999991, -16.499999999999808, 121.79999999999917, -118.30000000000138, -160.70000000000113, 86.39999999999982, 116.19999999999945, -61.400000000001256, -12.699999999999612, 100.89999999999986, 15.399999999999972, 186.8999999999993, -85.20000000000024, -222.70000000000041, 115.89999999999961, -121.70000000000113, 0.3999999999998205, 8.199999999999916, 142.69999999999953, -239.10000000000073, 54.600000000000314, -123.10000000000015, -182.70000000000041, -85.6000000000002, 31.600000000000122, 105.09999999999985, -93.70000000000037, -63.800000000001205, -141.6000000000005, -57.29999999999989, 80.49999999999994, 45.100000000000115, 86.89999999999995, 153.99999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-198.40000000000038, -45.10000000000003, -227.80000000000015, -51.099999999999916, 71.29999999999963, 143.59999999999997, 20.000000000000014, -0.9999999999999846, -299.70000000000016, -5.499999999999924, 20.000000000000014, 128.9, -182.2, -86.2000000000008, -120.70000000000076, 35.90000000000002, -29.199999999999783, 18.500000000000057, -17.200000000000188, -151.90000000000015, -173.2000000000005, -151.30000000000004, 58.10000000000006, 27.500000000000107, -171.1000000000006, 42.200000000000124, 29.90000000000009, -135.00000000000063, -129.7000000000005, 5.300000000000004, -309.70000000000005, 7.399999999999956, -187.30000000000007, -68.20000000000027, -301.60000000000014, -240.40000000000043, -265.9, -9.399999999999968, -196.6000000000004, -66.40000000000076, -93.4000000000008, -38.19999999999976, -34.29999999999978, 29.00000000000007, 20.000000000000014, 2.900000000000005, 44.3000000000001, -151.6000000000006, -48.099999999999824, 59.30000000000019, -76.59999999999995, -72.40000000000089, -173.20000000000059, -34.29999999999982, -157.30000000000027, -55.59999999999982, 20.000000000000014, -131.20000000000073, -238.80000000000035, -19.899999999999743, -94.90000000000012, 150.49999999999974, -39.399999999999764, -120.40000000000049, -68.80000000000078, -11.19999999999992, -97.8000000000007, 128.89999999999995, 20.000000000000014, 1.09999999999999, -68.20000000000043, -198.1000000000005, -125.50000000000048, -166.0000000000001, -68.20000000000051, 125.29999999999966, -221.1000000000005, -157.30000000000072, -131.2000000000005, -45.7000000000001, 23.600000000000083, -11.499999999999819, 81.19999999999997, -160.00000000000006, -91.90000000000069, 37.100000000000115, -198.40000000000032, -65.80000000000064, -57.1000000000003, 9.799999999999958, 20.000000000000014, -20.499999999999844, 80.29999999999964, -82.9000000000008, 20.000000000000014, -0.6999999999999318, 50.600000000000115, -131.20000000000073, -349.59999999999957, 53.900000000000006, -10.299999999999999, -55.60000000000028, 39.80000000000006, -105.70000000000064, 93.79999999999933, -156.4000000000004, 59.90000000000019, -161.20000000000024, -32.49999999999975, -30.699999999999896, -28.59999999999989, -97.89999999999998, -54.99999999999986, -148.89999999999995, 42.200000000000216, 60.80000000000015, -7.899999999999952, -116.49999999999997, -179.80000000000018, -2.1999999999999758, -208.90000000000052, -71.50000000000063, 82.99999999999996, 7.099999999999973, -45.69999999999987, -82.8999999999998, -19.899999999999764, -62.2000000000007, -54.70000000000024, -26.199999999999818, -39.399999999999764, 22.700000000000063, 14.600000000000042, -185.79999999999993, -5.1999999999999265, -70.3000000000002, -12.09999999999988, 107.89999999999972, -144.30000000000067, -127.00000000000063, -89.2000000000007, -242.50000000000043, -79.30000000000084, 85.69999999999993, 23.30000000000001, -3.100000000000008, -38.19999999999982, -98.20000000000068, 13.399999999999956, -87.1000000000007, 173.0, -180.1000000000005, -13.599999999999854, -21.999999999999744, 39.500000000000135, 115.39999999999993, -233.50000000000017, -0.7000000000000134, -156.70000000000047, -253.00000000000003, 17.000000000000036, 47.90000000000009, -123.10000000000068, -136.60000000000045, -52.59999999999995, -89.0000000000004, 36.5000000000001, -118.30000000000045, 17.899999999999988, 93.80000000000001, -133.9000000000007, -383.1999999999998, 69.80000000000015, -68.20000000000039, -254.20000000000007, -103.90000000000009, -135.1000000000003, -274.60000000000014, -175.29999999999998, -64.30000000000067, 11.59999999999998, -67.00000000000074, 173.29999999999993, -194.20000000000053, -112.00000000000044, -216.70000000000002, -52.59999999999979, -152.20000000000056, -199.9000000000003, -105.70000000000046, 50.30000000000013, -277.6000000000002, -80.50000000000011, 70.99999999999962, -31.90000000000009, -45.99999999999994, 74.6, -54.69999999999986, 154.99999999999994, -76.0000000000001], "policy_predator_policy_reward": [84.0, 98.0, 96.0, 58.0, 17.0, 14.0, 9.0, 9.0, 162.0, 24.0, 1.0, 18.0, 136.0, 21.0, 89.0, 44.0, 27.0, 26.0, 83.0, 105.0, 115.0, 92.0, 35.0, 35.0, 35.0, 95.0, 79.0, 19.0, 38.0, 65.0, 34.0, 156.0, 103.0, 69.0, 145.0, 86.0, 141.0, 96.0, 99.0, 89.0, 61.0, 22.0, 11.0, 31.0, 19.0, 29.0, 27.0, 82.0, 15.0, 41.0, 44.0, 46.0, 80.0, 79.0, 57.0, 81.0, 68.0, 26.0, 62.0, 103.0, 73.0, 67.0, 61.0, 57.0, 51.0, 0.0, 12.0, 69.0, 14.0, 18.0, 53.0, 114.0, 123.0, 42.0, 6.0, 40.0, 77.0, 137.0, 72.0, 51.0, 24.0, 3.0, 99.0, 12.0, 21.0, 43.0, 106.0, 50.0, 21.0, 40.0, 35.0, 10.0, 52.0, 30.0, 34.0, 14.0, 83.0, 4.0, 149.0, 97.0, 40.0, 67.0, 65.0, 18.0, 79.0, 14.0, 2.0, 88.0, 39.0, 40.0, 10.0, 103.0, 45.0, 104.0, 11.0, 11.0, 29.0, 92.0, 10.0, 119.0, 90.0, 32.0, 13.0, 0.0, 55.0, 37.0, 1.0, 55.0, 1.0, 46.0, 30.0, 8.0, 96.0, 58.0, 17.0, 42.0, 6.0, 20.0, 103.0, 50.0, 51.0, 120.0, 31.0, 49.0, 26.0, 70.0, 5.0, 70.0, 49.0, 12.0, 86.0, 22.0, 26.0, 25.0, 15.0, 17.0, 136.0, 13.0, 15.0, 172.0, 46.0, 5.0, 93.0, 45.0, 107.0, 35.0, 4.0, 86.0, 30.0, 1.0, 144.0, 134.0, 11.0, 42.0, 123.0, 112.0, 103.0, 124.0, 105.0, 49.0, 57.0, 30.0, 73.0, 53.0, 101.0, 134.0, 63.0, 78.0, 119.0, 45.0, 50.0, 120.0, 47.0, 43.0, 49.0, 74.0, 27.0, 40.0, 65.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5241268540585621, "mean_inference_ms": 1.343115121340894, "mean_action_processing_ms": 0.2206437080179311, "mean_env_wait_ms": 0.1733624226448053, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006450772285461426, "StateBufferConnector_ms": 0.0028380155563354492, "ViewRequirementAgentConnector_ms": 0.08847451210021973}, "num_episodes": 18, "episode_return_max": 245.89999999999947, "episode_return_min": -310.9999999999989, "episode_return_mean": -9.367000000000207, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 434.55517994916676, "num_env_steps_trained_throughput_per_sec": 434.55517994916676, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 9316.383, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9316.338, "sample_time_ms": 1074.478, "learn_time_ms": 8228.342, "learn_throughput": 486.125, "synch_weights_time_ms": 12.551}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-25-35", "timestamp": 1723645535, "time_this_iter_s": 9.208203077316284, "time_total_s": 56.00587439537048, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 56.00587439537048, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 27.56923076923077, "ram_util_percent": 83.58461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.017213143211193, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.774434462552348, "policy_loss": -0.008272002259436896, "vf_loss": 5.780119109279895, "vf_explained_var": 0.02855979875912742, "kl": 0.012936839982696121, "entropy": 1.5519856382299353, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9503069817073762, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.272377879279, "policy_loss": -0.010687051102317002, "vf_loss": 4.280237041579353, "vf_explained_var": -0.010092752131204757, "kl": 0.01413947959766139, "entropy": 1.57276873468722, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 270.5999999999999, "episode_reward_min": -239.10000000000073, "episode_reward_mean": -0.2900000000001828, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.29999999999993, "predator_policy": 172.0}, "policy_reward_mean": {"prey_policy": -53.66500000000016, "predator_policy": 53.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.29999999999988, -75.00000000000117, -48.59999999999974, 36.70000000000002, 70.89999999999984, 1.6999999999999698, 67.20000000000012, -58.99999999999961, -48.50000000000001, -74.90000000000055, -17.199999999999598, -93.69999999999993, 195.59999999999974, -41.80000000000015, -28.99999999999971, 112.09999999999985, 53.10000000000042, -99.30000000000095, -126.50000000000091, 103.09999999999923, -164.40000000000123, -53.90000000000016, 39.10000000000014, 32.20000000000006, 9.2000000000001, -108.20000000000093, 13.700000000000042, 44.50000000000019, 79.3999999999999, 67.29999999999995, 6.400000000000077, -49.699999999999804, 41.10000000000016, 17.100000000000062, 30.40000000000031, -11.299999999999898, 15.800000000000075, -13.49999999999986, -54.89999999999998, 124.9999999999986, -3.399999999999956, -52.99999999999993, -158.40000000000123, 103.09999999999981, -36.59999999999994, -26.099999999999568, -33.90000000000025, 21.29999999999999, -17.19999999999991, -16.499999999999808, 121.79999999999917, -118.30000000000138, -160.70000000000113, 86.39999999999982, 116.19999999999945, -61.400000000001256, -12.699999999999612, 100.89999999999986, 15.399999999999972, 186.8999999999993, -85.20000000000024, -222.70000000000041, 115.89999999999961, -121.70000000000113, 0.3999999999998205, 8.199999999999916, 142.69999999999953, -239.10000000000073, 54.600000000000314, -123.10000000000015, -182.70000000000041, -85.6000000000002, 31.600000000000122, 105.09999999999985, -93.70000000000037, -63.800000000001205, -141.6000000000005, -57.29999999999989, 80.49999999999994, 45.100000000000115, 86.89999999999995, 153.99999999999952, 7.499999999999319, 20.9, 91.10000000000012, 46.90000000000031, -41.89999999999971, 120.59999999999974, 32.300000000000175, 120.19999999999962, -98.1000000000001, 75.0999999999995, 16.500000000000234, 29.000000000000128, -62.39999999999972, 270.5999999999999, -7.1999999999998305, -22.799999999999798, 64.50000000000023, -107.99999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-265.9, -9.399999999999968, -196.6000000000004, -66.40000000000076, -93.4000000000008, -38.19999999999976, -34.29999999999978, 29.00000000000007, 20.000000000000014, 2.900000000000005, 44.3000000000001, -151.6000000000006, -48.099999999999824, 59.30000000000019, -76.59999999999995, -72.40000000000089, -173.20000000000059, -34.29999999999982, -157.30000000000027, -55.59999999999982, 20.000000000000014, -131.20000000000073, -238.80000000000035, -19.899999999999743, -94.90000000000012, 150.49999999999974, -39.399999999999764, -120.40000000000049, -68.80000000000078, -11.19999999999992, -97.8000000000007, 128.89999999999995, 20.000000000000014, 1.09999999999999, -68.20000000000043, -198.1000000000005, -125.50000000000048, -166.0000000000001, -68.20000000000051, 125.29999999999966, -221.1000000000005, -157.30000000000072, -131.2000000000005, -45.7000000000001, 23.600000000000083, -11.499999999999819, 81.19999999999997, -160.00000000000006, -91.90000000000069, 37.100000000000115, -198.40000000000032, -65.80000000000064, -57.1000000000003, 9.799999999999958, 20.000000000000014, -20.499999999999844, 80.29999999999964, -82.9000000000008, 20.000000000000014, -0.6999999999999318, 50.600000000000115, -131.20000000000073, -349.59999999999957, 53.900000000000006, -10.299999999999999, -55.60000000000028, 39.80000000000006, -105.70000000000064, 93.79999999999933, -156.4000000000004, 59.90000000000019, -161.20000000000024, -32.49999999999975, -30.699999999999896, -28.59999999999989, -97.89999999999998, -54.99999999999986, -148.89999999999995, 42.200000000000216, 60.80000000000015, -7.899999999999952, -116.49999999999997, -179.80000000000018, -2.1999999999999758, -208.90000000000052, -71.50000000000063, 82.99999999999996, 7.099999999999973, -45.69999999999987, -82.8999999999998, -19.899999999999764, -62.2000000000007, -54.70000000000024, -26.199999999999818, -39.399999999999764, 22.700000000000063, 14.600000000000042, -185.79999999999993, -5.1999999999999265, -70.3000000000002, -12.09999999999988, 107.89999999999972, -144.30000000000067, -127.00000000000063, -89.2000000000007, -242.50000000000043, -79.30000000000084, 85.69999999999993, 23.30000000000001, -3.100000000000008, -38.19999999999982, -98.20000000000068, 13.399999999999956, -87.1000000000007, 173.0, -180.1000000000005, -13.599999999999854, -21.999999999999744, 39.500000000000135, 115.39999999999993, -233.50000000000017, -0.7000000000000134, -156.70000000000047, -253.00000000000003, 17.000000000000036, 47.90000000000009, -123.10000000000068, -136.60000000000045, -52.59999999999995, -89.0000000000004, 36.5000000000001, -118.30000000000045, 17.899999999999988, 93.80000000000001, -133.9000000000007, -383.1999999999998, 69.80000000000015, -68.20000000000039, -254.20000000000007, -103.90000000000009, -135.1000000000003, -274.60000000000014, -175.29999999999998, -64.30000000000067, 11.59999999999998, -67.00000000000074, 173.29999999999993, -194.20000000000053, -112.00000000000044, -216.70000000000002, -52.59999999999979, -152.20000000000056, -199.9000000000003, -105.70000000000046, 50.30000000000013, -277.6000000000002, -80.50000000000011, 70.99999999999962, -31.90000000000009, -45.99999999999994, 74.6, -54.69999999999986, 154.99999999999994, -76.0000000000001, -87.10000000000079, -9.400000000000261, 5.299999999999965, -30.399999999999892, 3.1999999999999615, 38.89999999999998, 6.199999999999973, -49.299999999999855, -72.40000000000089, -104.50000000000037, 104.29999999999998, -90.70000000000081, 58.10000000000006, -125.80000000000058, 30.200000000000003, 20.000000000000014, -299.5000000000001, -31.60000000000005, -34.9, 20.000000000000014, -64.00000000000077, 0.4999999999997726, 3.1999999999999615, 15.799999999999962, -110.79999999999993, -55.59999999999977, 74.0, 131.5999999999999, -32.49999999999975, -90.70000000000003, -62.80000000000018, -85.00000000000085, 20.000000000000014, 27.500000000000064, -199.3, -165.70000000000024], "policy_predator_policy_reward": [141.0, 96.0, 99.0, 89.0, 61.0, 22.0, 11.0, 31.0, 19.0, 29.0, 27.0, 82.0, 15.0, 41.0, 44.0, 46.0, 80.0, 79.0, 57.0, 81.0, 68.0, 26.0, 62.0, 103.0, 73.0, 67.0, 61.0, 57.0, 51.0, 0.0, 12.0, 69.0, 14.0, 18.0, 53.0, 114.0, 123.0, 42.0, 6.0, 40.0, 77.0, 137.0, 72.0, 51.0, 24.0, 3.0, 99.0, 12.0, 21.0, 43.0, 106.0, 50.0, 21.0, 40.0, 35.0, 10.0, 52.0, 30.0, 34.0, 14.0, 83.0, 4.0, 149.0, 97.0, 40.0, 67.0, 65.0, 18.0, 79.0, 14.0, 2.0, 88.0, 39.0, 40.0, 10.0, 103.0, 45.0, 104.0, 11.0, 11.0, 29.0, 92.0, 10.0, 119.0, 90.0, 32.0, 13.0, 0.0, 55.0, 37.0, 1.0, 55.0, 1.0, 46.0, 30.0, 8.0, 96.0, 58.0, 17.0, 42.0, 6.0, 20.0, 103.0, 50.0, 51.0, 120.0, 31.0, 49.0, 26.0, 70.0, 5.0, 70.0, 49.0, 12.0, 86.0, 22.0, 26.0, 25.0, 15.0, 17.0, 136.0, 13.0, 15.0, 172.0, 46.0, 5.0, 93.0, 45.0, 107.0, 35.0, 4.0, 86.0, 30.0, 1.0, 144.0, 134.0, 11.0, 42.0, 123.0, 112.0, 103.0, 124.0, 105.0, 49.0, 57.0, 30.0, 73.0, 53.0, 101.0, 134.0, 63.0, 78.0, 119.0, 45.0, 50.0, 120.0, 47.0, 43.0, 49.0, 74.0, 27.0, 40.0, 65.0, 10.0, 50.0, 54.0, 39.0, 7.0, 13.0, 36.0, 38.0, 52.0, 66.0, 69.0, 62.0, 45.0, 58.0, 42.0, 48.0, 22.0, 125.0, 108.0, 78.0, 12.0, 19.0, 61.0, 8.0, 2.0, 26.0, 78.0, 45.0, 20.0, 61.0, 55.0, 50.0, 75.0, 2.0, 15.0, 91.0, 166.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5235386330600992, "mean_inference_ms": 1.3334101283392903, "mean_action_processing_ms": 0.21923118853675505, "mean_env_wait_ms": 0.17203504808728107, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0058689117431640625, "StateBufferConnector_ms": 0.0028458833694458008, "ViewRequirementAgentConnector_ms": 0.08829271793365479}, "num_episodes": 18, "episode_return_max": 270.5999999999999, "episode_return_min": -239.10000000000073, "episode_return_mean": -0.2900000000001828, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 436.69490375513476, "num_env_steps_trained_throughput_per_sec": 436.69490375513476, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 9294.003, "restore_workers_time_ms": 0.018, "training_step_time_ms": 9293.957, "sample_time_ms": 1062.517, "learn_time_ms": 8218.115, "learn_throughput": 486.73, "synch_weights_time_ms": 12.303}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-25-44", "timestamp": 1723645544, "time_this_iter_s": 9.200130224227905, "time_total_s": 65.20600461959839, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 65.20600461959839, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 26.91538461538461, "ram_util_percent": 83.57692307692308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7886642115456717, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.3433020352055784, "policy_loss": -0.0038860473633995133, "vf_loss": 6.345340268069474, "vf_explained_var": 0.053195409642325504, "kl": 0.00923903264569729, "entropy": 1.5572865768715187, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.984540038354813, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.8852853189700496, "policy_loss": -0.009300925768542266, "vf_loss": 3.8922533648354665, "vf_explained_var": 0.018415340229316995, "kl": 0.011664436373014042, "entropy": 1.5543672460727591, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 270.5999999999999, "episode_reward_min": -239.10000000000073, "episode_reward_mean": 6.28099999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.29999999999993, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -49.69450000000013, "predator_policy": 52.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-126.50000000000091, 103.09999999999923, -164.40000000000123, -53.90000000000016, 39.10000000000014, 32.20000000000006, 9.2000000000001, -108.20000000000093, 13.700000000000042, 44.50000000000019, 79.3999999999999, 67.29999999999995, 6.400000000000077, -49.699999999999804, 41.10000000000016, 17.100000000000062, 30.40000000000031, -11.299999999999898, 15.800000000000075, -13.49999999999986, -54.89999999999998, 124.9999999999986, -3.399999999999956, -52.99999999999993, -158.40000000000123, 103.09999999999981, -36.59999999999994, -26.099999999999568, -33.90000000000025, 21.29999999999999, -17.19999999999991, -16.499999999999808, 121.79999999999917, -118.30000000000138, -160.70000000000113, 86.39999999999982, 116.19999999999945, -61.400000000001256, -12.699999999999612, 100.89999999999986, 15.399999999999972, 186.8999999999993, -85.20000000000024, -222.70000000000041, 115.89999999999961, -121.70000000000113, 0.3999999999998205, 8.199999999999916, 142.69999999999953, -239.10000000000073, 54.600000000000314, -123.10000000000015, -182.70000000000041, -85.6000000000002, 31.600000000000122, 105.09999999999985, -93.70000000000037, -63.800000000001205, -141.6000000000005, -57.29999999999989, 80.49999999999994, 45.100000000000115, 86.89999999999995, 153.99999999999952, 7.499999999999319, 20.9, 91.10000000000012, 46.90000000000031, -41.89999999999971, 120.59999999999974, 32.300000000000175, 120.19999999999962, -98.1000000000001, 75.0999999999995, 16.500000000000234, 29.000000000000128, -62.39999999999972, 270.5999999999999, -7.1999999999998305, -22.799999999999798, 64.50000000000023, -107.99999999999991, 52.399999999999714, 36.500000000000085, 195.5, -68.70000000000016, 112.29999999999981, 70.90000000000012, 137.29999999999959, -13.099999999999865, -51.69999999999976, 73.29999999999976, -23.999999999999687, 208.89999999999998, 118.79999999999944, -56.90000000000013, 19.80000000000005, -167.80000000000118, 55.700000000000195, -130.10000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-125.50000000000048, -166.0000000000001, -68.20000000000051, 125.29999999999966, -221.1000000000005, -157.30000000000072, -131.2000000000005, -45.7000000000001, 23.600000000000083, -11.499999999999819, 81.19999999999997, -160.00000000000006, -91.90000000000069, 37.100000000000115, -198.40000000000032, -65.80000000000064, -57.1000000000003, 9.799999999999958, 20.000000000000014, -20.499999999999844, 80.29999999999964, -82.9000000000008, 20.000000000000014, -0.6999999999999318, 50.600000000000115, -131.20000000000073, -349.59999999999957, 53.900000000000006, -10.299999999999999, -55.60000000000028, 39.80000000000006, -105.70000000000064, 93.79999999999933, -156.4000000000004, 59.90000000000019, -161.20000000000024, -32.49999999999975, -30.699999999999896, -28.59999999999989, -97.89999999999998, -54.99999999999986, -148.89999999999995, 42.200000000000216, 60.80000000000015, -7.899999999999952, -116.49999999999997, -179.80000000000018, -2.1999999999999758, -208.90000000000052, -71.50000000000063, 82.99999999999996, 7.099999999999973, -45.69999999999987, -82.8999999999998, -19.899999999999764, -62.2000000000007, -54.70000000000024, -26.199999999999818, -39.399999999999764, 22.700000000000063, 14.600000000000042, -185.79999999999993, -5.1999999999999265, -70.3000000000002, -12.09999999999988, 107.89999999999972, -144.30000000000067, -127.00000000000063, -89.2000000000007, -242.50000000000043, -79.30000000000084, 85.69999999999993, 23.30000000000001, -3.100000000000008, -38.19999999999982, -98.20000000000068, 13.399999999999956, -87.1000000000007, 173.0, -180.1000000000005, -13.599999999999854, -21.999999999999744, 39.500000000000135, 115.39999999999993, -233.50000000000017, -0.7000000000000134, -156.70000000000047, -253.00000000000003, 17.000000000000036, 47.90000000000009, -123.10000000000068, -136.60000000000045, -52.59999999999995, -89.0000000000004, 36.5000000000001, -118.30000000000045, 17.899999999999988, 93.80000000000001, -133.9000000000007, -383.1999999999998, 69.80000000000015, -68.20000000000039, -254.20000000000007, -103.90000000000009, -135.1000000000003, -274.60000000000014, -175.29999999999998, -64.30000000000067, 11.59999999999998, -67.00000000000074, 173.29999999999993, -194.20000000000053, -112.00000000000044, -216.70000000000002, -52.59999999999979, -152.20000000000056, -199.9000000000003, -105.70000000000046, 50.30000000000013, -277.6000000000002, -80.50000000000011, 70.99999999999962, -31.90000000000009, -45.99999999999994, 74.6, -54.69999999999986, 154.99999999999994, -76.0000000000001, -87.10000000000079, -9.400000000000261, 5.299999999999965, -30.399999999999892, 3.1999999999999615, 38.89999999999998, 6.199999999999973, -49.299999999999855, -72.40000000000089, -104.50000000000037, 104.29999999999998, -90.70000000000081, 58.10000000000006, -125.80000000000058, 30.200000000000003, 20.000000000000014, -299.5000000000001, -31.60000000000005, -34.9, 20.000000000000014, -64.00000000000077, 0.4999999999997726, 3.1999999999999615, 15.799999999999962, -110.79999999999993, -55.59999999999977, 74.0, 131.5999999999999, -32.49999999999975, -90.70000000000003, -62.80000000000018, -85.00000000000085, 20.000000000000014, 27.500000000000064, -199.3, -165.70000000000024, -26.199999999999747, -3.4000000000000004, 42.20000000000006, -192.70000000000016, 45.50000000000005, 56.0, -253.1000000000003, 7.399999999999967, 20.000000000000014, 44.29999999999997, -53.50000000000009, 37.400000000000006, -51.39999999999996, 142.69999999999996, -123.09999999999991, 20.000000000000014, 25.100000000000115, -170.80000000000058, 61.40000000000019, -24.099999999999753, -173.80000000000035, 36.80000000000021, 36.5, 85.40000000000002, 85.4, -13.599999999999783, -109.90000000000032, -64.00000000000081, -101.20000000000061, 20.000000000000014, -263.49999999999955, -91.3000000000003, -31.900000000000006, -3.400000000000035, -325.0, 17.899999999999988], "policy_predator_policy_reward": [123.0, 42.0, 6.0, 40.0, 77.0, 137.0, 72.0, 51.0, 24.0, 3.0, 99.0, 12.0, 21.0, 43.0, 106.0, 50.0, 21.0, 40.0, 35.0, 10.0, 52.0, 30.0, 34.0, 14.0, 83.0, 4.0, 149.0, 97.0, 40.0, 67.0, 65.0, 18.0, 79.0, 14.0, 2.0, 88.0, 39.0, 40.0, 10.0, 103.0, 45.0, 104.0, 11.0, 11.0, 29.0, 92.0, 10.0, 119.0, 90.0, 32.0, 13.0, 0.0, 55.0, 37.0, 1.0, 55.0, 1.0, 46.0, 30.0, 8.0, 96.0, 58.0, 17.0, 42.0, 6.0, 20.0, 103.0, 50.0, 51.0, 120.0, 31.0, 49.0, 26.0, 70.0, 5.0, 70.0, 49.0, 12.0, 86.0, 22.0, 26.0, 25.0, 15.0, 17.0, 136.0, 13.0, 15.0, 172.0, 46.0, 5.0, 93.0, 45.0, 107.0, 35.0, 4.0, 86.0, 30.0, 1.0, 144.0, 134.0, 11.0, 42.0, 123.0, 112.0, 103.0, 124.0, 105.0, 49.0, 57.0, 30.0, 73.0, 53.0, 101.0, 134.0, 63.0, 78.0, 119.0, 45.0, 50.0, 120.0, 47.0, 43.0, 49.0, 74.0, 27.0, 40.0, 65.0, 10.0, 50.0, 54.0, 39.0, 7.0, 13.0, 36.0, 38.0, 52.0, 66.0, 69.0, 62.0, 45.0, 58.0, 42.0, 48.0, 22.0, 125.0, 108.0, 78.0, 12.0, 19.0, 61.0, 8.0, 2.0, 26.0, 78.0, 45.0, 20.0, 61.0, 55.0, 50.0, 75.0, 2.0, 15.0, 91.0, 166.0, 58.0, 24.0, 127.0, 60.0, 64.0, 30.0, 157.0, 20.0, 42.0, 6.0, 6.0, 81.0, 15.0, 31.0, 90.0, 0.0, 27.0, 67.0, 14.0, 22.0, 103.0, 10.0, 34.0, 53.0, 16.0, 31.0, 31.0, 86.0, 41.0, 60.0, 53.0, 134.0, 42.0, 49.0, 175.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5211880825784806, "mean_inference_ms": 1.325027424825925, "mean_action_processing_ms": 0.21773419488050294, "mean_env_wait_ms": 0.17078400207672473, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054585933685302734, "StateBufferConnector_ms": 0.0028411149978637695, "ViewRequirementAgentConnector_ms": 0.08838808536529541}, "num_episodes": 18, "episode_return_max": 270.5999999999999, "episode_return_min": -239.10000000000073, "episode_return_mean": 6.28099999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 432.3533441779773, "num_env_steps_trained_throughput_per_sec": 432.3533441779773, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 9288.715, "restore_workers_time_ms": 0.017, "training_step_time_ms": 9288.67, "sample_time_ms": 1057.751, "learn_time_ms": 8217.681, "learn_throughput": 486.755, "synch_weights_time_ms": 12.26}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-25-53", "timestamp": 1723645553, "time_this_iter_s": 9.2548189163208, "time_total_s": 74.46082353591919, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 74.46082353591919, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 27.638461538461538, "ram_util_percent": 83.4923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9876457538554277, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.538221294413168, "policy_loss": -0.008729106720004763, "vf_loss": 7.544374345597767, "vf_explained_var": 0.07094955718706525, "kl": 0.012880299521551808, "entropy": 1.5475114660288292, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.781842611706446, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.1966385847677, "policy_loss": -0.008805381946965422, "vf_loss": 4.203429167611258, "vf_explained_var": 0.02989437460268616, "kl": 0.01007396340912391, "entropy": 1.5432384091710287, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 270.5999999999999, "episode_reward_min": -239.10000000000073, "episode_reward_mean": 25.5439999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -39.96800000000012, "predator_policy": 52.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.399999999999956, -52.99999999999993, -158.40000000000123, 103.09999999999981, -36.59999999999994, -26.099999999999568, -33.90000000000025, 21.29999999999999, -17.19999999999991, -16.499999999999808, 121.79999999999917, -118.30000000000138, -160.70000000000113, 86.39999999999982, 116.19999999999945, -61.400000000001256, -12.699999999999612, 100.89999999999986, 15.399999999999972, 186.8999999999993, -85.20000000000024, -222.70000000000041, 115.89999999999961, -121.70000000000113, 0.3999999999998205, 8.199999999999916, 142.69999999999953, -239.10000000000073, 54.600000000000314, -123.10000000000015, -182.70000000000041, -85.6000000000002, 31.600000000000122, 105.09999999999985, -93.70000000000037, -63.800000000001205, -141.6000000000005, -57.29999999999989, 80.49999999999994, 45.100000000000115, 86.89999999999995, 153.99999999999952, 7.499999999999319, 20.9, 91.10000000000012, 46.90000000000031, -41.89999999999971, 120.59999999999974, 32.300000000000175, 120.19999999999962, -98.1000000000001, 75.0999999999995, 16.500000000000234, 29.000000000000128, -62.39999999999972, 270.5999999999999, -7.1999999999998305, -22.799999999999798, 64.50000000000023, -107.99999999999991, 52.399999999999714, 36.500000000000085, 195.5, -68.70000000000016, 112.29999999999981, 70.90000000000012, 137.29999999999959, -13.099999999999865, -51.69999999999976, 73.29999999999976, -23.999999999999687, 208.89999999999998, 118.79999999999944, -56.90000000000013, 19.80000000000005, -167.80000000000118, 55.700000000000195, -130.10000000000036, 248.7, 105.49999999999994, 239.50000000000006, 167.2999999999994, 49.5, -93.40000000000029, 99.19999999999996, 2.900000000000035, -84.00000000000006, 27.200000000000102, 44.40000000000032, 148.39999999999927, 242.79999999999993, -40.49999999999999, 181.69999999999945, 129.89999999999972, 219.19999999999973, 249.39999999999992, -152.8000000000011, 255.39999999999995, -67.40000000000057, -4.699999999999736], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-7.899999999999952, -116.49999999999997, -179.80000000000018, -2.1999999999999758, -208.90000000000052, -71.50000000000063, 82.99999999999996, 7.099999999999973, -45.69999999999987, -82.8999999999998, -19.899999999999764, -62.2000000000007, -54.70000000000024, -26.199999999999818, -39.399999999999764, 22.700000000000063, 14.600000000000042, -185.79999999999993, -5.1999999999999265, -70.3000000000002, -12.09999999999988, 107.89999999999972, -144.30000000000067, -127.00000000000063, -89.2000000000007, -242.50000000000043, -79.30000000000084, 85.69999999999993, 23.30000000000001, -3.100000000000008, -38.19999999999982, -98.20000000000068, 13.399999999999956, -87.1000000000007, 173.0, -180.1000000000005, -13.599999999999854, -21.999999999999744, 39.500000000000135, 115.39999999999993, -233.50000000000017, -0.7000000000000134, -156.70000000000047, -253.00000000000003, 17.000000000000036, 47.90000000000009, -123.10000000000068, -136.60000000000045, -52.59999999999995, -89.0000000000004, 36.5000000000001, -118.30000000000045, 17.899999999999988, 93.80000000000001, -133.9000000000007, -383.1999999999998, 69.80000000000015, -68.20000000000039, -254.20000000000007, -103.90000000000009, -135.1000000000003, -274.60000000000014, -175.29999999999998, -64.30000000000067, 11.59999999999998, -67.00000000000074, 173.29999999999993, -194.20000000000053, -112.00000000000044, -216.70000000000002, -52.59999999999979, -152.20000000000056, -199.9000000000003, -105.70000000000046, 50.30000000000013, -277.6000000000002, -80.50000000000011, 70.99999999999962, -31.90000000000009, -45.99999999999994, 74.6, -54.69999999999986, 154.99999999999994, -76.0000000000001, -87.10000000000079, -9.400000000000261, 5.299999999999965, -30.399999999999892, 3.1999999999999615, 38.89999999999998, 6.199999999999973, -49.299999999999855, -72.40000000000089, -104.50000000000037, 104.29999999999998, -90.70000000000081, 58.10000000000006, -125.80000000000058, 30.200000000000003, 20.000000000000014, -299.5000000000001, -31.60000000000005, -34.9, 20.000000000000014, -64.00000000000077, 0.4999999999997726, 3.1999999999999615, 15.799999999999962, -110.79999999999993, -55.59999999999977, 74.0, 131.5999999999999, -32.49999999999975, -90.70000000000003, -62.80000000000018, -85.00000000000085, 20.000000000000014, 27.500000000000064, -199.3, -165.70000000000024, -26.199999999999747, -3.4000000000000004, 42.20000000000006, -192.70000000000016, 45.50000000000005, 56.0, -253.1000000000003, 7.399999999999967, 20.000000000000014, 44.29999999999997, -53.50000000000009, 37.400000000000006, -51.39999999999996, 142.69999999999996, -123.09999999999991, 20.000000000000014, 25.100000000000115, -170.80000000000058, 61.40000000000019, -24.099999999999753, -173.80000000000035, 36.80000000000021, 36.5, 85.40000000000002, 85.4, -13.599999999999783, -109.90000000000032, -64.00000000000081, -101.20000000000061, 20.000000000000014, -263.49999999999955, -91.3000000000003, -31.900000000000006, -3.400000000000035, -325.0, 17.899999999999988, 97.1, 83.6, 87.50000000000001, -73.0, 99.50000000000006, 80.0, 72.20000000000002, 55.10000000000018, -58.6, -67.89999999999995, -91.9, -221.50000000000034, 86.30000000000001, -60.100000000000286, -150.10000000000068, 8.0, 3.500000000000078, -320.4999999999997, 60.80000000000021, -133.60000000000025, 37.7, -61.30000000000037, 126.4999999999998, -3.099999999999958, 125.89999999999995, 77.90000000000002, -148.50000000000006, -124.0, -51.400000000000006, 199.1, 96.50000000000003, -13.599999999999783, 176.6, 15.600000000000163, 122.29999999999998, 67.10000000000005, -91.29999999999995, -221.50000000000048, 174.19999999999993, 9.199999999999932, -255.40000000000003, 20.000000000000014, -78.70000000000086, 20.000000000000014], "policy_predator_policy_reward": [29.0, 92.0, 10.0, 119.0, 90.0, 32.0, 13.0, 0.0, 55.0, 37.0, 1.0, 55.0, 1.0, 46.0, 30.0, 8.0, 96.0, 58.0, 17.0, 42.0, 6.0, 20.0, 103.0, 50.0, 51.0, 120.0, 31.0, 49.0, 26.0, 70.0, 5.0, 70.0, 49.0, 12.0, 86.0, 22.0, 26.0, 25.0, 15.0, 17.0, 136.0, 13.0, 15.0, 172.0, 46.0, 5.0, 93.0, 45.0, 107.0, 35.0, 4.0, 86.0, 30.0, 1.0, 144.0, 134.0, 11.0, 42.0, 123.0, 112.0, 103.0, 124.0, 105.0, 49.0, 57.0, 30.0, 73.0, 53.0, 101.0, 134.0, 63.0, 78.0, 119.0, 45.0, 50.0, 120.0, 47.0, 43.0, 49.0, 74.0, 27.0, 40.0, 65.0, 10.0, 50.0, 54.0, 39.0, 7.0, 13.0, 36.0, 38.0, 52.0, 66.0, 69.0, 62.0, 45.0, 58.0, 42.0, 48.0, 22.0, 125.0, 108.0, 78.0, 12.0, 19.0, 61.0, 8.0, 2.0, 26.0, 78.0, 45.0, 20.0, 61.0, 55.0, 50.0, 75.0, 2.0, 15.0, 91.0, 166.0, 58.0, 24.0, 127.0, 60.0, 64.0, 30.0, 157.0, 20.0, 42.0, 6.0, 6.0, 81.0, 15.0, 31.0, 90.0, 0.0, 27.0, 67.0, 14.0, 22.0, 103.0, 10.0, 34.0, 53.0, 16.0, 31.0, 31.0, 86.0, 41.0, 60.0, 53.0, 134.0, 42.0, 49.0, 175.0, 2.0, 25.0, 43.0, 0.0, 91.0, 40.0, 20.0, 9.0, 31.0, 97.0, 79.0, 97.0, 123.0, 34.0, 39.0, 20.0, 125.0, 150.0, 83.0, 98.0, 2.0, 1.0, 67.0, 11.0, 14.0, 12.0, 27.0, 170.0, 62.0, 0.0, 34.0, 17.0, 30.0, 0.0, 27.0, 44.0, 16.0, 18.0, 142.0, 12.0, 60.0, 18.0, 150.0, 47.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5199222748500356, "mean_inference_ms": 1.3206421397708765, "mean_action_processing_ms": 0.2170236451221835, "mean_env_wait_ms": 0.169814778540734, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004883170127868652, "StateBufferConnector_ms": 0.002879500389099121, "ViewRequirementAgentConnector_ms": 0.09039020538330078}, "num_episodes": 22, "episode_return_max": 270.5999999999999, "episode_return_min": -239.10000000000073, "episode_return_mean": 25.5439999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 433.9204128255881, "num_env_steps_trained_throughput_per_sec": 433.9204128255881, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 9280.89, "restore_workers_time_ms": 0.017, "training_step_time_ms": 9280.845, "sample_time_ms": 1049.449, "learn_time_ms": 8218.169, "learn_throughput": 486.726, "synch_weights_time_ms": 12.231}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-26-02", "timestamp": 1723645562, "time_this_iter_s": 9.26146411895752, "time_total_s": 83.72228765487671, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39aef9820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 83.72228765487671, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 27.200000000000003, "ram_util_percent": 83.64615384615385}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3170442248463, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.110874850409372, "policy_loss": -0.003291788429425901, "vf_loss": 8.112367123649234, "vf_explained_var": 0.12731747557877232, "kl": 0.008997630739442809, "entropy": 1.5390917875779369, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.102751781133117, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.719763269626275, "policy_loss": -0.009429626905719045, "vf_loss": 4.726903132282237, "vf_explained_var": 0.020984221482403063, "kl": 0.011448832158180485, "entropy": 1.5376217396801741, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 330.2, "episode_reward_min": -239.10000000000073, "episode_reward_mean": 51.989999999999846, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -26.440000000000115, "predator_policy": 52.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-121.70000000000113, 0.3999999999998205, 8.199999999999916, 142.69999999999953, -239.10000000000073, 54.600000000000314, -123.10000000000015, -182.70000000000041, -85.6000000000002, 31.600000000000122, 105.09999999999985, -93.70000000000037, -63.800000000001205, -141.6000000000005, -57.29999999999989, 80.49999999999994, 45.100000000000115, 86.89999999999995, 153.99999999999952, 7.499999999999319, 20.9, 91.10000000000012, 46.90000000000031, -41.89999999999971, 120.59999999999974, 32.300000000000175, 120.19999999999962, -98.1000000000001, 75.0999999999995, 16.500000000000234, 29.000000000000128, -62.39999999999972, 270.5999999999999, -7.1999999999998305, -22.799999999999798, 64.50000000000023, -107.99999999999991, 52.399999999999714, 36.500000000000085, 195.5, -68.70000000000016, 112.29999999999981, 70.90000000000012, 137.29999999999959, -13.099999999999865, -51.69999999999976, 73.29999999999976, -23.999999999999687, 208.89999999999998, 118.79999999999944, -56.90000000000013, 19.80000000000005, -167.80000000000118, 55.700000000000195, -130.10000000000036, 248.7, 105.49999999999994, 239.50000000000006, 167.2999999999994, 49.5, -93.40000000000029, 99.19999999999996, 2.900000000000035, -84.00000000000006, 27.200000000000102, 44.40000000000032, 148.39999999999927, 242.79999999999993, -40.49999999999999, 181.69999999999945, 129.89999999999972, 219.19999999999973, 249.39999999999992, -152.8000000000011, 255.39999999999995, -67.40000000000057, -4.699999999999736, 159.4999999999995, 32.39999999999988, 119.29999999999953, 133.5999999999999, 64.30000000000004, 130.09999999999988, 330.2, 69.99999999999997, 151.79999999999964, 178.3999999999994, 37.50000000000009, -39.79999999999976, 211.09999999999928, 268.8000000000001, -65.20000000000054, -8.899999999999842, 144.70000000000007, 12.099999999999953, -18.70000000000016, -18.399999999999842, 133.7999999999997, 218.19999999999965, 261.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-123.10000000000068, -136.60000000000045, -52.59999999999995, -89.0000000000004, 36.5000000000001, -118.30000000000045, 17.899999999999988, 93.80000000000001, -133.9000000000007, -383.1999999999998, 69.80000000000015, -68.20000000000039, -254.20000000000007, -103.90000000000009, -135.1000000000003, -274.60000000000014, -175.29999999999998, -64.30000000000067, 11.59999999999998, -67.00000000000074, 173.29999999999993, -194.20000000000053, -112.00000000000044, -216.70000000000002, -52.59999999999979, -152.20000000000056, -199.9000000000003, -105.70000000000046, 50.30000000000013, -277.6000000000002, -80.50000000000011, 70.99999999999962, -31.90000000000009, -45.99999999999994, 74.6, -54.69999999999986, 154.99999999999994, -76.0000000000001, -87.10000000000079, -9.400000000000261, 5.299999999999965, -30.399999999999892, 3.1999999999999615, 38.89999999999998, 6.199999999999973, -49.299999999999855, -72.40000000000089, -104.50000000000037, 104.29999999999998, -90.70000000000081, 58.10000000000006, -125.80000000000058, 30.200000000000003, 20.000000000000014, -299.5000000000001, -31.60000000000005, -34.9, 20.000000000000014, -64.00000000000077, 0.4999999999997726, 3.1999999999999615, 15.799999999999962, -110.79999999999993, -55.59999999999977, 74.0, 131.5999999999999, -32.49999999999975, -90.70000000000003, -62.80000000000018, -85.00000000000085, 20.000000000000014, 27.500000000000064, -199.3, -165.70000000000024, -26.199999999999747, -3.4000000000000004, 42.20000000000006, -192.70000000000016, 45.50000000000005, 56.0, -253.1000000000003, 7.399999999999967, 20.000000000000014, 44.29999999999997, -53.50000000000009, 37.400000000000006, -51.39999999999996, 142.69999999999996, -123.09999999999991, 20.000000000000014, 25.100000000000115, -170.80000000000058, 61.40000000000019, -24.099999999999753, -173.80000000000035, 36.80000000000021, 36.5, 85.40000000000002, 85.4, -13.599999999999783, -109.90000000000032, -64.00000000000081, -101.20000000000061, 20.000000000000014, -263.49999999999955, -91.3000000000003, -31.900000000000006, -3.400000000000035, -325.0, 17.899999999999988, 97.1, 83.6, 87.50000000000001, -73.0, 99.50000000000006, 80.0, 72.20000000000002, 55.10000000000018, -58.6, -67.89999999999995, -91.9, -221.50000000000034, 86.30000000000001, -60.100000000000286, -150.10000000000068, 8.0, 3.500000000000078, -320.4999999999997, 60.80000000000021, -133.60000000000025, 37.7, -61.30000000000037, 126.4999999999998, -3.099999999999958, 125.89999999999995, 77.90000000000002, -148.50000000000006, -124.0, -51.400000000000006, 199.1, 96.50000000000003, -13.599999999999783, 176.6, 15.600000000000163, 122.29999999999998, 67.10000000000005, -91.29999999999995, -221.50000000000048, 174.19999999999993, 9.199999999999932, -255.40000000000003, 20.000000000000014, -78.70000000000086, 20.000000000000014, 154.99999999999977, -98.50000000000037, -76.00000000000074, -4.600000000000023, -26.199999999999747, 87.49999999999997, 11.0, 2.599999999999916, 165.50000000000003, -236.20000000000041, 28.099999999999994, -16.0, 155.89999999999984, 158.29999999999998, 1.0999999999999943, -6.099999999999973, 11.599999999999964, 99.2, 145.7, 13.699999999999966, 25.400000000000084, -97.9, -24.099999999999987, -165.70000000000024, 183.49999999999997, 23.60000000000008, 45.800000000000004, 169.99999999999994, -66.4000000000002, -170.80000000000038, -99.70000000000036, -14.199999999999909, -3.4000000000000554, 70.09999999999997, -190.00000000000054, 100.09999999999948, -67.30000000000001, -93.4000000000008, -157.90000000000012, -2.50000000000003, 22.400000000000063, 76.4000000000001, 77.3000000000001, 83.9, 134.5999999999999, 65.0], "policy_predator_policy_reward": [93.0, 45.0, 107.0, 35.0, 4.0, 86.0, 30.0, 1.0, 144.0, 134.0, 11.0, 42.0, 123.0, 112.0, 103.0, 124.0, 105.0, 49.0, 57.0, 30.0, 73.0, 53.0, 101.0, 134.0, 63.0, 78.0, 119.0, 45.0, 50.0, 120.0, 47.0, 43.0, 49.0, 74.0, 27.0, 40.0, 65.0, 10.0, 50.0, 54.0, 39.0, 7.0, 13.0, 36.0, 38.0, 52.0, 66.0, 69.0, 62.0, 45.0, 58.0, 42.0, 48.0, 22.0, 125.0, 108.0, 78.0, 12.0, 19.0, 61.0, 8.0, 2.0, 26.0, 78.0, 45.0, 20.0, 61.0, 55.0, 50.0, 75.0, 2.0, 15.0, 91.0, 166.0, 58.0, 24.0, 127.0, 60.0, 64.0, 30.0, 157.0, 20.0, 42.0, 6.0, 6.0, 81.0, 15.0, 31.0, 90.0, 0.0, 27.0, 67.0, 14.0, 22.0, 103.0, 10.0, 34.0, 53.0, 16.0, 31.0, 31.0, 86.0, 41.0, 60.0, 53.0, 134.0, 42.0, 49.0, 175.0, 2.0, 25.0, 43.0, 0.0, 91.0, 40.0, 20.0, 9.0, 31.0, 97.0, 79.0, 97.0, 123.0, 34.0, 39.0, 20.0, 125.0, 150.0, 83.0, 98.0, 2.0, 1.0, 67.0, 11.0, 14.0, 12.0, 27.0, 170.0, 62.0, 0.0, 34.0, 17.0, 30.0, 0.0, 27.0, 44.0, 16.0, 18.0, 142.0, 12.0, 60.0, 18.0, 150.0, 47.0, 7.0, 40.0, 63.0, 50.0, 63.0, 16.0, 42.0, 48.0, 72.0, 122.0, 13.0, 94.0, 24.0, 3.0, 13.0, 11.0, 64.0, 33.0, 8.0, 16.0, 3.0, 103.0, 7.0, 76.0, 74.0, 4.0, 0.0, 4.0, 49.0, 95.0, 77.0, 63.0, 42.0, 13.0, 65.0, 0.0, 102.0, 55.0, 87.0, 32.0, 110.0, 19.0, 16.0, 36.0, 21.0, 21.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5186355901840587, "mean_inference_ms": 1.315746307090037, "mean_action_processing_ms": 0.21591137874799327, "mean_env_wait_ms": 0.1695767006685852, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003595113754272461, "StateBufferConnector_ms": 0.0030819177627563477, "ViewRequirementAgentConnector_ms": 0.08987760543823242}, "num_episodes": 23, "episode_return_max": 330.2, "episode_return_min": -239.10000000000073, "episode_return_mean": 51.989999999999846, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 424.8907345634855, "num_env_steps_trained_throughput_per_sec": 424.8907345634855, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 9294.22, "restore_workers_time_ms": 0.017, "training_step_time_ms": 9294.176, "sample_time_ms": 1049.181, "learn_time_ms": 8231.804, "learn_throughput": 485.92, "synch_weights_time_ms": 12.222}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-26-12", "timestamp": 1723645572, "time_this_iter_s": 9.417752027511597, "time_total_s": 93.1400396823883, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39aef9430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 93.1400396823883, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 27.823076923076922, "ram_util_percent": 83.23076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1588831851722072, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 9.09945873028387, "policy_loss": -0.004528051563267591, "vf_loss": 9.102467507155485, "vf_explained_var": 0.06362282485558242, "kl": 0.007596451799218214, "entropy": 1.522064308262376, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.901774245185196, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.161972958827145, "policy_loss": -0.011310094938904204, "vf_loss": 5.170605163725596, "vf_explained_var": 0.03581199727991902, "kl": 0.013389491105603347, "entropy": 1.5218072754996164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 330.2, "episode_reward_min": -223.7000000000004, "episode_reward_mean": 64.96499999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -356.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -19.17750000000008, "predator_policy": 51.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [153.99999999999952, 7.499999999999319, 20.9, 91.10000000000012, 46.90000000000031, -41.89999999999971, 120.59999999999974, 32.300000000000175, 120.19999999999962, -98.1000000000001, 75.0999999999995, 16.500000000000234, 29.000000000000128, -62.39999999999972, 270.5999999999999, -7.1999999999998305, -22.799999999999798, 64.50000000000023, -107.99999999999991, 52.399999999999714, 36.500000000000085, 195.5, -68.70000000000016, 112.29999999999981, 70.90000000000012, 137.29999999999959, -13.099999999999865, -51.69999999999976, 73.29999999999976, -23.999999999999687, 208.89999999999998, 118.79999999999944, -56.90000000000013, 19.80000000000005, -167.80000000000118, 55.700000000000195, -130.10000000000036, 248.7, 105.49999999999994, 239.50000000000006, 167.2999999999994, 49.5, -93.40000000000029, 99.19999999999996, 2.900000000000035, -84.00000000000006, 27.200000000000102, 44.40000000000032, 148.39999999999927, 242.79999999999993, -40.49999999999999, 181.69999999999945, 129.89999999999972, 219.19999999999973, 249.39999999999992, -152.8000000000011, 255.39999999999995, -67.40000000000057, -4.699999999999736, 159.4999999999995, 32.39999999999988, 119.29999999999953, 133.5999999999999, 64.30000000000004, 130.09999999999988, 330.2, 69.99999999999997, 151.79999999999964, 178.3999999999994, 37.50000000000009, -39.79999999999976, 211.09999999999928, 268.8000000000001, -65.20000000000054, -8.899999999999842, 144.70000000000007, 12.099999999999953, -18.70000000000016, -18.399999999999842, 133.7999999999997, 218.19999999999965, 261.6, -223.7000000000004, 58.3000000000001, -32.8999999999999, 278.5999999999998, -172.00000000000006, -66.60000000000008, 171.49999999999932, -49.500000000000846, 189.89999999999984, 20.79999999999965, -65.00000000000036, 159.59999999999957, -44.70000000000046, 131.90000000000012, -45.90000000000006, 203.70000000000002, 63.199999999999996, 166.79999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [154.99999999999994, -76.0000000000001, -87.10000000000079, -9.400000000000261, 5.299999999999965, -30.399999999999892, 3.1999999999999615, 38.89999999999998, 6.199999999999973, -49.299999999999855, -72.40000000000089, -104.50000000000037, 104.29999999999998, -90.70000000000081, 58.10000000000006, -125.80000000000058, 30.200000000000003, 20.000000000000014, -299.5000000000001, -31.60000000000005, -34.9, 20.000000000000014, -64.00000000000077, 0.4999999999997726, 3.1999999999999615, 15.799999999999962, -110.79999999999993, -55.59999999999977, 74.0, 131.5999999999999, -32.49999999999975, -90.70000000000003, -62.80000000000018, -85.00000000000085, 20.000000000000014, 27.500000000000064, -199.3, -165.70000000000024, -26.199999999999747, -3.4000000000000004, 42.20000000000006, -192.70000000000016, 45.50000000000005, 56.0, -253.1000000000003, 7.399999999999967, 20.000000000000014, 44.29999999999997, -53.50000000000009, 37.400000000000006, -51.39999999999996, 142.69999999999996, -123.09999999999991, 20.000000000000014, 25.100000000000115, -170.80000000000058, 61.40000000000019, -24.099999999999753, -173.80000000000035, 36.80000000000021, 36.5, 85.40000000000002, 85.4, -13.599999999999783, -109.90000000000032, -64.00000000000081, -101.20000000000061, 20.000000000000014, -263.49999999999955, -91.3000000000003, -31.900000000000006, -3.400000000000035, -325.0, 17.899999999999988, 97.1, 83.6, 87.50000000000001, -73.0, 99.50000000000006, 80.0, 72.20000000000002, 55.10000000000018, -58.6, -67.89999999999995, -91.9, -221.50000000000034, 86.30000000000001, -60.100000000000286, -150.10000000000068, 8.0, 3.500000000000078, -320.4999999999997, 60.80000000000021, -133.60000000000025, 37.7, -61.30000000000037, 126.4999999999998, -3.099999999999958, 125.89999999999995, 77.90000000000002, -148.50000000000006, -124.0, -51.400000000000006, 199.1, 96.50000000000003, -13.599999999999783, 176.6, 15.600000000000163, 122.29999999999998, 67.10000000000005, -91.29999999999995, -221.50000000000048, 174.19999999999993, 9.199999999999932, -255.40000000000003, 20.000000000000014, -78.70000000000086, 20.000000000000014, 154.99999999999977, -98.50000000000037, -76.00000000000074, -4.600000000000023, -26.199999999999747, 87.49999999999997, 11.0, 2.599999999999916, 165.50000000000003, -236.20000000000041, 28.099999999999994, -16.0, 155.89999999999984, 158.29999999999998, 1.0999999999999943, -6.099999999999973, 11.599999999999964, 99.2, 145.7, 13.699999999999966, 25.400000000000084, -97.9, -24.099999999999987, -165.70000000000024, 183.49999999999997, 23.60000000000008, 45.800000000000004, 169.99999999999994, -66.4000000000002, -170.80000000000038, -99.70000000000036, -14.199999999999909, -3.4000000000000554, 70.09999999999997, -190.00000000000054, 100.09999999999948, -67.30000000000001, -93.4000000000008, -157.90000000000012, -2.50000000000003, 22.400000000000063, 76.4000000000001, 77.3000000000001, 83.9, 134.5999999999999, 65.0, -318.0999999999997, -100.60000000000016, -68.19999999999985, 39.50000000000005, -199.60000000000036, 34.700000000000045, 84.2, 139.40000000000003, -122.80000000000001, -356.1999999999998, -157.9000000000001, -108.69999999999999, 160.99999999999991, -11.499999999999819, -181.0, -26.49999999999978, 29.000000000000007, 98.90000000000003, -47.800000000000296, -87.40000000000015, -170.50000000000003, -89.50000000000033, -91.30000000000081, 191.9, -11.5, -247.2000000000005, 106.39999999999998, -86.50000000000009, -111.10000000000005, -92.80000000000001, 116.6, 1.0999999999997954, -94.60000000000005, 42.8, 62.00000000000007, 21.79999999999984], "policy_predator_policy_reward": [65.0, 10.0, 50.0, 54.0, 39.0, 7.0, 13.0, 36.0, 38.0, 52.0, 66.0, 69.0, 62.0, 45.0, 58.0, 42.0, 48.0, 22.0, 125.0, 108.0, 78.0, 12.0, 19.0, 61.0, 8.0, 2.0, 26.0, 78.0, 45.0, 20.0, 61.0, 55.0, 50.0, 75.0, 2.0, 15.0, 91.0, 166.0, 58.0, 24.0, 127.0, 60.0, 64.0, 30.0, 157.0, 20.0, 42.0, 6.0, 6.0, 81.0, 15.0, 31.0, 90.0, 0.0, 27.0, 67.0, 14.0, 22.0, 103.0, 10.0, 34.0, 53.0, 16.0, 31.0, 31.0, 86.0, 41.0, 60.0, 53.0, 134.0, 42.0, 49.0, 175.0, 2.0, 25.0, 43.0, 0.0, 91.0, 40.0, 20.0, 9.0, 31.0, 97.0, 79.0, 97.0, 123.0, 34.0, 39.0, 20.0, 125.0, 150.0, 83.0, 98.0, 2.0, 1.0, 67.0, 11.0, 14.0, 12.0, 27.0, 170.0, 62.0, 0.0, 34.0, 17.0, 30.0, 0.0, 27.0, 44.0, 16.0, 18.0, 142.0, 12.0, 60.0, 18.0, 150.0, 47.0, 7.0, 40.0, 63.0, 50.0, 63.0, 16.0, 42.0, 48.0, 72.0, 122.0, 13.0, 94.0, 24.0, 3.0, 13.0, 11.0, 64.0, 33.0, 8.0, 16.0, 3.0, 103.0, 7.0, 76.0, 74.0, 4.0, 0.0, 4.0, 49.0, 95.0, 77.0, 63.0, 42.0, 13.0, 65.0, 0.0, 102.0, 55.0, 87.0, 32.0, 110.0, 19.0, 16.0, 36.0, 21.0, 21.0, 41.0, 146.0, 49.0, 57.0, 30.0, 109.0, 23.0, 15.0, 40.0, 153.0, 154.0, 62.0, 138.0, 7.0, 15.0, 127.0, 31.0, 4.0, 58.0, 99.0, 57.0, 106.0, 89.0, 6.0, 53.0, 66.0, 148.0, 57.0, 55.0, 43.0, 115.0, 32.0, 54.0, 94.0, 21.0, 41.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5163817921439341, "mean_inference_ms": 1.311136446409073, "mean_action_processing_ms": 0.21514974972647632, "mean_env_wait_ms": 0.16918774705923836, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0034607648849487305, "StateBufferConnector_ms": 0.0030661821365356445, "ViewRequirementAgentConnector_ms": 0.08728182315826416}, "num_episodes": 18, "episode_return_max": 330.2, "episode_return_min": -223.7000000000004, "episode_return_mean": 64.96499999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 434.0539151303964, "num_env_steps_trained_throughput_per_sec": 434.0539151303964, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 9257.327, "restore_workers_time_ms": 0.017, "training_step_time_ms": 9257.283, "sample_time_ms": 1033.366, "learn_time_ms": 8211.3, "learn_throughput": 487.134, "synch_weights_time_ms": 11.674}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-26-21", "timestamp": 1723645581, "time_this_iter_s": 9.221658945083618, "time_total_s": 102.36169862747192, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ad361f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 102.36169862747192, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 29.284615384615385, "ram_util_percent": 83.63846153846154}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8974588507540011, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 9.614874985609106, "policy_loss": -0.004865710526980736, "vf_loss": 9.61754360955859, "vf_explained_var": -0.012198337833717387, "kl": 0.01098548567042048, "entropy": 1.52589956881508, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9829681488256605, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.3522516058866305, "policy_loss": -0.012969930131215031, "vf_loss": 7.362413200247225, "vf_explained_var": 0.045477998130535956, "kl": 0.014041630382658054, "entropy": 1.5015964612758979, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 330.2, "episode_reward_min": -353.40000000000003, "episode_reward_mean": 47.71899999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -36.86550000000007, "predator_policy": 60.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-107.99999999999991, 52.399999999999714, 36.500000000000085, 195.5, -68.70000000000016, 112.29999999999981, 70.90000000000012, 137.29999999999959, -13.099999999999865, -51.69999999999976, 73.29999999999976, -23.999999999999687, 208.89999999999998, 118.79999999999944, -56.90000000000013, 19.80000000000005, -167.80000000000118, 55.700000000000195, -130.10000000000036, 248.7, 105.49999999999994, 239.50000000000006, 167.2999999999994, 49.5, -93.40000000000029, 99.19999999999996, 2.900000000000035, -84.00000000000006, 27.200000000000102, 44.40000000000032, 148.39999999999927, 242.79999999999993, -40.49999999999999, 181.69999999999945, 129.89999999999972, 219.19999999999973, 249.39999999999992, -152.8000000000011, 255.39999999999995, -67.40000000000057, -4.699999999999736, 159.4999999999995, 32.39999999999988, 119.29999999999953, 133.5999999999999, 64.30000000000004, 130.09999999999988, 330.2, 69.99999999999997, 151.79999999999964, 178.3999999999994, 37.50000000000009, -39.79999999999976, 211.09999999999928, 268.8000000000001, -65.20000000000054, -8.899999999999842, 144.70000000000007, 12.099999999999953, -18.70000000000016, -18.399999999999842, 133.7999999999997, 218.19999999999965, 261.6, -223.7000000000004, 58.3000000000001, -32.8999999999999, 278.5999999999998, -172.00000000000006, -66.60000000000008, 171.49999999999932, -49.500000000000846, 189.89999999999984, 20.79999999999965, -65.00000000000036, 159.59999999999957, -44.70000000000046, 131.90000000000012, -45.90000000000006, 203.70000000000002, 63.199999999999996, 166.79999999999993, -2.0999999999999943, -179.10000000000016, -64.40000000000083, 256.80000000000007, -124.20000000000007, -6.900000000000011, 57.20000000000008, -353.40000000000003, -143.2, -198.60000000000002, -231.40000000000006, 294.7, 132.20000000000005, -36.89999999999982, -178.70000000000005, -183.89999999999998, -120.19999999999996, 174.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-199.3, -165.70000000000024, -26.199999999999747, -3.4000000000000004, 42.20000000000006, -192.70000000000016, 45.50000000000005, 56.0, -253.1000000000003, 7.399999999999967, 20.000000000000014, 44.29999999999997, -53.50000000000009, 37.400000000000006, -51.39999999999996, 142.69999999999996, -123.09999999999991, 20.000000000000014, 25.100000000000115, -170.80000000000058, 61.40000000000019, -24.099999999999753, -173.80000000000035, 36.80000000000021, 36.5, 85.40000000000002, 85.4, -13.599999999999783, -109.90000000000032, -64.00000000000081, -101.20000000000061, 20.000000000000014, -263.49999999999955, -91.3000000000003, -31.900000000000006, -3.400000000000035, -325.0, 17.899999999999988, 97.1, 83.6, 87.50000000000001, -73.0, 99.50000000000006, 80.0, 72.20000000000002, 55.10000000000018, -58.6, -67.89999999999995, -91.9, -221.50000000000034, 86.30000000000001, -60.100000000000286, -150.10000000000068, 8.0, 3.500000000000078, -320.4999999999997, 60.80000000000021, -133.60000000000025, 37.7, -61.30000000000037, 126.4999999999998, -3.099999999999958, 125.89999999999995, 77.90000000000002, -148.50000000000006, -124.0, -51.400000000000006, 199.1, 96.50000000000003, -13.599999999999783, 176.6, 15.600000000000163, 122.29999999999998, 67.10000000000005, -91.29999999999995, -221.50000000000048, 174.19999999999993, 9.199999999999932, -255.40000000000003, 20.000000000000014, -78.70000000000086, 20.000000000000014, 154.99999999999977, -98.50000000000037, -76.00000000000074, -4.600000000000023, -26.199999999999747, 87.49999999999997, 11.0, 2.599999999999916, 165.50000000000003, -236.20000000000041, 28.099999999999994, -16.0, 155.89999999999984, 158.29999999999998, 1.0999999999999943, -6.099999999999973, 11.599999999999964, 99.2, 145.7, 13.699999999999966, 25.400000000000084, -97.9, -24.099999999999987, -165.70000000000024, 183.49999999999997, 23.60000000000008, 45.800000000000004, 169.99999999999994, -66.4000000000002, -170.80000000000038, -99.70000000000036, -14.199999999999909, -3.4000000000000554, 70.09999999999997, -190.00000000000054, 100.09999999999948, -67.30000000000001, -93.4000000000008, -157.90000000000012, -2.50000000000003, 22.400000000000063, 76.4000000000001, 77.3000000000001, 83.9, 134.5999999999999, 65.0, -318.0999999999997, -100.60000000000016, -68.19999999999985, 39.50000000000005, -199.60000000000036, 34.700000000000045, 84.2, 139.40000000000003, -122.80000000000001, -356.1999999999998, -157.9000000000001, -108.69999999999999, 160.99999999999991, -11.499999999999819, -181.0, -26.49999999999978, 29.000000000000007, 98.90000000000003, -47.800000000000296, -87.40000000000015, -170.50000000000003, -89.50000000000033, -91.30000000000081, 191.9, -11.5, -247.2000000000005, 106.39999999999998, -86.50000000000009, -111.10000000000005, -92.80000000000001, 116.6, 1.0999999999997954, -94.60000000000005, 42.8, 62.00000000000007, 21.79999999999984, -32.19999999999999, -142.9, -251.50000000000003, -184.60000000000014, -157.90000000000063, -53.50000000000037, 85.1, 112.6999999999999, -161.79999999999998, -303.40000000000015, -138.7, 6.7999999999999865, -211.30000000000027, 138.5, -337.0, -249.40000000000003, -176.19999999999996, -271.00000000000006, -391.0, -163.60000000000002, -235.89999999999998, -305.5000000000002, 119.9, 147.79999999999998, 58.39999999999999, -17.19999999999999, 55.10000000000007, -358.0, -204.10000000000002, -196.60000000000002, -173.8, -159.1, -136.0, -134.2, 97.69999999999999, -12.399999999999991], "policy_predator_policy_reward": [91.0, 166.0, 58.0, 24.0, 127.0, 60.0, 64.0, 30.0, 157.0, 20.0, 42.0, 6.0, 6.0, 81.0, 15.0, 31.0, 90.0, 0.0, 27.0, 67.0, 14.0, 22.0, 103.0, 10.0, 34.0, 53.0, 16.0, 31.0, 31.0, 86.0, 41.0, 60.0, 53.0, 134.0, 42.0, 49.0, 175.0, 2.0, 25.0, 43.0, 0.0, 91.0, 40.0, 20.0, 9.0, 31.0, 97.0, 79.0, 97.0, 123.0, 34.0, 39.0, 20.0, 125.0, 150.0, 83.0, 98.0, 2.0, 1.0, 67.0, 11.0, 14.0, 12.0, 27.0, 170.0, 62.0, 0.0, 34.0, 17.0, 30.0, 0.0, 27.0, 44.0, 16.0, 18.0, 142.0, 12.0, 60.0, 18.0, 150.0, 47.0, 7.0, 40.0, 63.0, 50.0, 63.0, 16.0, 42.0, 48.0, 72.0, 122.0, 13.0, 94.0, 24.0, 3.0, 13.0, 11.0, 64.0, 33.0, 8.0, 16.0, 3.0, 103.0, 7.0, 76.0, 74.0, 4.0, 0.0, 4.0, 49.0, 95.0, 77.0, 63.0, 42.0, 13.0, 65.0, 0.0, 102.0, 55.0, 87.0, 32.0, 110.0, 19.0, 16.0, 36.0, 21.0, 21.0, 41.0, 146.0, 49.0, 57.0, 30.0, 109.0, 23.0, 15.0, 40.0, 153.0, 154.0, 62.0, 138.0, 7.0, 15.0, 127.0, 31.0, 4.0, 58.0, 99.0, 57.0, 106.0, 89.0, 6.0, 53.0, 66.0, 148.0, 57.0, 55.0, 43.0, 115.0, 32.0, 54.0, 94.0, 21.0, 41.0, 42.0, 37.0, 136.0, 90.0, 167.0, 86.0, 61.0, 19.0, 40.0, 158.0, 183.0, 104.0, 21.0, 111.0, 19.0, 55.0, 178.0, 153.0, 151.0, 186.0, 170.0, 155.0, 155.0, 24.0, 3.0, 39.0, 52.0, 177.0, 89.0, 96.0, 126.0, 119.0, 30.0, 148.0, 2.0, 32.0, 57.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5154203212040285, "mean_inference_ms": 1.3117881638936384, "mean_action_processing_ms": 0.21490418354497337, "mean_env_wait_ms": 0.16984521468675765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003439784049987793, "StateBufferConnector_ms": 0.0030535459518432617, "ViewRequirementAgentConnector_ms": 0.08604872226715088}, "num_episodes": 18, "episode_return_max": 330.2, "episode_return_min": -353.40000000000003, "episode_return_mean": 47.71899999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 419.2423907498682, "num_env_steps_trained_throughput_per_sec": 419.2423907498682, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 9279.427, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9279.387, "sample_time_ms": 1052.378, "learn_time_ms": 8214.339, "learn_throughput": 486.953, "synch_weights_time_ms": 11.718}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-26-31", "timestamp": 1723645591, "time_this_iter_s": 9.549983978271484, "time_total_s": 111.91168260574341, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39af081f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 111.91168260574341, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 29.88571428571428, "ram_util_percent": 83.2642857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1225767102191058, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 9.464162144332967, "policy_loss": -0.01209318952575799, "vf_loss": 9.472129365123768, "vf_explained_var": 0.012886501462371261, "kl": 0.020629887446077452, "entropy": 1.5224216431537003, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.900170668596944, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.87799807452651, "policy_loss": -0.010304188925561017, "vf_loss": 8.886063417555794, "vf_explained_var": 0.007829856052600517, "kl": 0.011194179925524173, "entropy": 1.4838594036127524, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 330.2, "episode_reward_min": -398.1, "episode_reward_mean": 24.35299999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -60.683500000000066, "predator_policy": 72.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-130.10000000000036, 248.7, 105.49999999999994, 239.50000000000006, 167.2999999999994, 49.5, -93.40000000000029, 99.19999999999996, 2.900000000000035, -84.00000000000006, 27.200000000000102, 44.40000000000032, 148.39999999999927, 242.79999999999993, -40.49999999999999, 181.69999999999945, 129.89999999999972, 219.19999999999973, 249.39999999999992, -152.8000000000011, 255.39999999999995, -67.40000000000057, -4.699999999999736, 159.4999999999995, 32.39999999999988, 119.29999999999953, 133.5999999999999, 64.30000000000004, 130.09999999999988, 330.2, 69.99999999999997, 151.79999999999964, 178.3999999999994, 37.50000000000009, -39.79999999999976, 211.09999999999928, 268.8000000000001, -65.20000000000054, -8.899999999999842, 144.70000000000007, 12.099999999999953, -18.70000000000016, -18.399999999999842, 133.7999999999997, 218.19999999999965, 261.6, -223.7000000000004, 58.3000000000001, -32.8999999999999, 278.5999999999998, -172.00000000000006, -66.60000000000008, 171.49999999999932, -49.500000000000846, 189.89999999999984, 20.79999999999965, -65.00000000000036, 159.59999999999957, -44.70000000000046, 131.90000000000012, -45.90000000000006, 203.70000000000002, 63.199999999999996, 166.79999999999993, -2.0999999999999943, -179.10000000000016, -64.40000000000083, 256.80000000000007, -124.20000000000007, -6.900000000000011, 57.20000000000008, -353.40000000000003, -143.2, -198.60000000000002, -231.40000000000006, 294.7, 132.20000000000005, -36.89999999999982, -178.70000000000005, -183.89999999999998, -120.19999999999996, 174.29999999999995, -329.40000000000003, -13.499999999999952, 180.9, -1.5999999999999694, 185.39999999999998, 18.6, -157.99999999999994, -38.499999999999964, -241.0, 29.500000000000014, -144.1, -398.1, -289.69999999999993, -164.8, -90.0, -33.8, -315.20000000000005, 57.89999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-325.0, 17.899999999999988, 97.1, 83.6, 87.50000000000001, -73.0, 99.50000000000006, 80.0, 72.20000000000002, 55.10000000000018, -58.6, -67.89999999999995, -91.9, -221.50000000000034, 86.30000000000001, -60.100000000000286, -150.10000000000068, 8.0, 3.500000000000078, -320.4999999999997, 60.80000000000021, -133.60000000000025, 37.7, -61.30000000000037, 126.4999999999998, -3.099999999999958, 125.89999999999995, 77.90000000000002, -148.50000000000006, -124.0, -51.400000000000006, 199.1, 96.50000000000003, -13.599999999999783, 176.6, 15.600000000000163, 122.29999999999998, 67.10000000000005, -91.29999999999995, -221.50000000000048, 174.19999999999993, 9.199999999999932, -255.40000000000003, 20.000000000000014, -78.70000000000086, 20.000000000000014, 154.99999999999977, -98.50000000000037, -76.00000000000074, -4.600000000000023, -26.199999999999747, 87.49999999999997, 11.0, 2.599999999999916, 165.50000000000003, -236.20000000000041, 28.099999999999994, -16.0, 155.89999999999984, 158.29999999999998, 1.0999999999999943, -6.099999999999973, 11.599999999999964, 99.2, 145.7, 13.699999999999966, 25.400000000000084, -97.9, -24.099999999999987, -165.70000000000024, 183.49999999999997, 23.60000000000008, 45.800000000000004, 169.99999999999994, -66.4000000000002, -170.80000000000038, -99.70000000000036, -14.199999999999909, -3.4000000000000554, 70.09999999999997, -190.00000000000054, 100.09999999999948, -67.30000000000001, -93.4000000000008, -157.90000000000012, -2.50000000000003, 22.400000000000063, 76.4000000000001, 77.3000000000001, 83.9, 134.5999999999999, 65.0, -318.0999999999997, -100.60000000000016, -68.19999999999985, 39.50000000000005, -199.60000000000036, 34.700000000000045, 84.2, 139.40000000000003, -122.80000000000001, -356.1999999999998, -157.9000000000001, -108.69999999999999, 160.99999999999991, -11.499999999999819, -181.0, -26.49999999999978, 29.000000000000007, 98.90000000000003, -47.800000000000296, -87.40000000000015, -170.50000000000003, -89.50000000000033, -91.30000000000081, 191.9, -11.5, -247.2000000000005, 106.39999999999998, -86.50000000000009, -111.10000000000005, -92.80000000000001, 116.6, 1.0999999999997954, -94.60000000000005, 42.8, 62.00000000000007, 21.79999999999984, -32.19999999999999, -142.9, -251.50000000000003, -184.60000000000014, -157.90000000000063, -53.50000000000037, 85.1, 112.6999999999999, -161.79999999999998, -303.40000000000015, -138.7, 6.7999999999999865, -211.30000000000027, 138.5, -337.0, -249.40000000000003, -176.19999999999996, -271.00000000000006, -391.0, -163.60000000000002, -235.89999999999998, -305.5000000000002, 119.9, 147.79999999999998, 58.39999999999999, -17.19999999999999, 55.10000000000007, -358.0, -204.10000000000002, -196.60000000000002, -173.8, -159.1, -136.0, -134.2, 97.69999999999999, -12.399999999999991, -242.8, -325.5999999999999, -95.5, -52.00000000000024, -9.100000000000222, 116.0, -299.5, 20.9, 92.0, -49.60000000000001, -8.800000000000006, -181.6, -290.80000000000007, -59.2, 72.5, -376.0, -181.0, -301.0, -39.10000000000002, -246.39999999999998, -309.4, -93.7, -397.9, -353.2, -172.9, -374.79999999999995, -323.8, -118.0, -58.900000000000006, -333.1, -329.8, -28.0, -269.8, -369.40000000000003, -100.6, -23.5], "policy_predator_policy_reward": [175.0, 2.0, 25.0, 43.0, 0.0, 91.0, 40.0, 20.0, 9.0, 31.0, 97.0, 79.0, 97.0, 123.0, 34.0, 39.0, 20.0, 125.0, 150.0, 83.0, 98.0, 2.0, 1.0, 67.0, 11.0, 14.0, 12.0, 27.0, 170.0, 62.0, 0.0, 34.0, 17.0, 30.0, 0.0, 27.0, 44.0, 16.0, 18.0, 142.0, 12.0, 60.0, 18.0, 150.0, 47.0, 7.0, 40.0, 63.0, 50.0, 63.0, 16.0, 42.0, 48.0, 72.0, 122.0, 13.0, 94.0, 24.0, 3.0, 13.0, 11.0, 64.0, 33.0, 8.0, 16.0, 3.0, 103.0, 7.0, 76.0, 74.0, 4.0, 0.0, 4.0, 49.0, 95.0, 77.0, 63.0, 42.0, 13.0, 65.0, 0.0, 102.0, 55.0, 87.0, 32.0, 110.0, 19.0, 16.0, 36.0, 21.0, 21.0, 41.0, 146.0, 49.0, 57.0, 30.0, 109.0, 23.0, 15.0, 40.0, 153.0, 154.0, 62.0, 138.0, 7.0, 15.0, 127.0, 31.0, 4.0, 58.0, 99.0, 57.0, 106.0, 89.0, 6.0, 53.0, 66.0, 148.0, 57.0, 55.0, 43.0, 115.0, 32.0, 54.0, 94.0, 21.0, 41.0, 42.0, 37.0, 136.0, 90.0, 167.0, 86.0, 61.0, 19.0, 40.0, 158.0, 183.0, 104.0, 21.0, 111.0, 19.0, 55.0, 178.0, 153.0, 151.0, 186.0, 170.0, 155.0, 155.0, 24.0, 3.0, 39.0, 52.0, 177.0, 89.0, 96.0, 126.0, 119.0, 30.0, 148.0, 2.0, 32.0, 57.0, 185.0, 54.0, 34.0, 100.0, 5.0, 69.0, 138.0, 139.0, 58.0, 85.0, 116.0, 93.0, 19.0, 173.0, 162.0, 103.0, 130.0, 111.0, 171.0, 144.0, 82.0, 177.0, 155.0, 198.0, 199.0, 59.0, 168.0, 109.0, 147.0, 155.0, 162.0, 162.0, 142.0, 182.0, 114.0, 68.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5146325707294418, "mean_inference_ms": 1.3121821223085297, "mean_action_processing_ms": 0.21469902047680364, "mean_env_wait_ms": 0.17033801051056371, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003459930419921875, "StateBufferConnector_ms": 0.003063201904296875, "ViewRequirementAgentConnector_ms": 0.08619654178619385}, "num_episodes": 18, "episode_return_max": 330.2, "episode_return_min": -398.1, "episode_return_mean": 24.35299999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 431.6670937312232, "num_env_steps_trained_throughput_per_sec": 431.6670937312232, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 9271.33, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9271.29, "sample_time_ms": 1044.562, "learn_time_ms": 8214.038, "learn_throughput": 486.971, "synch_weights_time_ms": 11.702}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-26-40", "timestamp": 1723645600, "time_this_iter_s": 9.27109694480896, "time_total_s": 121.18277955055237, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39af08b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 121.18277955055237, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 26.961538461538467, "ram_util_percent": 83.34615384615384}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.970173220848911, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 8.333749500910441, "policy_loss": -0.009200387252445416, "vf_loss": 8.33879232658911, "vf_explained_var": 0.06618040371193457, "kl": 0.01385852162718601, "entropy": 1.5124317548893116, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6395269791600566, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.657485546132244, "policy_loss": -0.010464921611898317, "vf_loss": 7.665203443153826, "vf_explained_var": 0.04278592375851182, "kl": 0.013735155904509945, "entropy": 1.470598785965531, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 330.2, "episode_reward_min": -398.1, "episode_reward_mean": -5.168000000000081, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.9, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -88.09400000000005, "predator_policy": 85.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [64.30000000000004, 130.09999999999988, 330.2, 69.99999999999997, 151.79999999999964, 178.3999999999994, 37.50000000000009, -39.79999999999976, 211.09999999999928, 268.8000000000001, -65.20000000000054, -8.899999999999842, 144.70000000000007, 12.099999999999953, -18.70000000000016, -18.399999999999842, 133.7999999999997, 218.19999999999965, 261.6, -223.7000000000004, 58.3000000000001, -32.8999999999999, 278.5999999999998, -172.00000000000006, -66.60000000000008, 171.49999999999932, -49.500000000000846, 189.89999999999984, 20.79999999999965, -65.00000000000036, 159.59999999999957, -44.70000000000046, 131.90000000000012, -45.90000000000006, 203.70000000000002, 63.199999999999996, 166.79999999999993, -2.0999999999999943, -179.10000000000016, -64.40000000000083, 256.80000000000007, -124.20000000000007, -6.900000000000011, 57.20000000000008, -353.40000000000003, -143.2, -198.60000000000002, -231.40000000000006, 294.7, 132.20000000000005, -36.89999999999982, -178.70000000000005, -183.89999999999998, -120.19999999999996, 174.29999999999995, -329.40000000000003, -13.499999999999952, 180.9, -1.5999999999999694, 185.39999999999998, 18.6, -157.99999999999994, -38.499999999999964, -241.0, 29.500000000000014, -144.1, -398.1, -289.69999999999993, -164.8, -90.0, -33.8, -315.20000000000005, 57.89999999999998, 103.90000000000003, 314.50000000000057, -10.500000000000151, -148.5, 170.69999999999985, -54.60000000000007, -227.3, -17.999999999999865, 104.60000000000001, -160.2, 31.70000000000004, 5.0, -355.2999999999999, -180.1000000000002, 5.6000000000000085, -88.80000000000022, -84.79999999999995, 5.100000000000168, -42.099999999999994, 214.59999999999994, -66.89999999999996, -245.9, 91.59999999999957, 203.89999999999998, -119.0000000000009, -43.899999999999864, -74.50000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [165.50000000000003, -236.20000000000041, 28.099999999999994, -16.0, 155.89999999999984, 158.29999999999998, 1.0999999999999943, -6.099999999999973, 11.599999999999964, 99.2, 145.7, 13.699999999999966, 25.400000000000084, -97.9, -24.099999999999987, -165.70000000000024, 183.49999999999997, 23.60000000000008, 45.800000000000004, 169.99999999999994, -66.4000000000002, -170.80000000000038, -99.70000000000036, -14.199999999999909, -3.4000000000000554, 70.09999999999997, -190.00000000000054, 100.09999999999948, -67.30000000000001, -93.4000000000008, -157.90000000000012, -2.50000000000003, 22.400000000000063, 76.4000000000001, 77.3000000000001, 83.9, 134.5999999999999, 65.0, -318.0999999999997, -100.60000000000016, -68.19999999999985, 39.50000000000005, -199.60000000000036, 34.700000000000045, 84.2, 139.40000000000003, -122.80000000000001, -356.1999999999998, -157.9000000000001, -108.69999999999999, 160.99999999999991, -11.499999999999819, -181.0, -26.49999999999978, 29.000000000000007, 98.90000000000003, -47.800000000000296, -87.40000000000015, -170.50000000000003, -89.50000000000033, -91.30000000000081, 191.9, -11.5, -247.2000000000005, 106.39999999999998, -86.50000000000009, -111.10000000000005, -92.80000000000001, 116.6, 1.0999999999997954, -94.60000000000005, 42.8, 62.00000000000007, 21.79999999999984, -32.19999999999999, -142.9, -251.50000000000003, -184.60000000000014, -157.90000000000063, -53.50000000000037, 85.1, 112.6999999999999, -161.79999999999998, -303.40000000000015, -138.7, 6.7999999999999865, -211.30000000000027, 138.5, -337.0, -249.40000000000003, -176.19999999999996, -271.00000000000006, -391.0, -163.60000000000002, -235.89999999999998, -305.5000000000002, 119.9, 147.79999999999998, 58.39999999999999, -17.19999999999999, 55.10000000000007, -358.0, -204.10000000000002, -196.60000000000002, -173.8, -159.1, -136.0, -134.2, 97.69999999999999, -12.399999999999991, -242.8, -325.5999999999999, -95.5, -52.00000000000024, -9.100000000000222, 116.0, -299.5, 20.9, 92.0, -49.60000000000001, -8.800000000000006, -181.6, -290.80000000000007, -59.2, 72.5, -376.0, -181.0, -301.0, -39.10000000000002, -246.39999999999998, -309.4, -93.7, -397.9, -353.2, -172.9, -374.79999999999995, -323.8, -118.0, -58.900000000000006, -333.1, -329.8, -28.0, -269.8, -369.40000000000003, -100.6, -23.5, 13.70000000000001, -47.800000000000026, 161.2999999999998, 105.2, -144.10000000000005, 11.599999999999968, -128.50000000000003, -223.0, 96.79999999999998, -36.099999999999966, -6.099999999999968, -254.49999999999994, -200.5, -314.79999999999995, -247.0, 20.000000000000014, -180.70000000000002, 113.30000000000001, -202.0, -227.2, -22.0, -142.29999999999998, -154.0, -46.0, -361.00000000000006, -298.30000000000007, -228.40000000000012, -222.70000000000007, 83.60000000000002, -247.0, -365.8, -45.999999999999886, -286.6000000000001, -68.19999999999999, 16.699999999999996, -97.60000000000053, -102.7, -207.40000000000003, 59.00000000000004, 95.60000000000002, 43.099999999999994, -382.0, -307.0, -250.9, -24.4, 20.000000000000014, 59.30000000000004, 77.60000000000001, -338.5, -32.49999999999975, -87.40000000000077, -206.5, -103.9, -97.60000000000082], "policy_predator_policy_reward": [122.0, 13.0, 94.0, 24.0, 3.0, 13.0, 11.0, 64.0, 33.0, 8.0, 16.0, 3.0, 103.0, 7.0, 76.0, 74.0, 4.0, 0.0, 4.0, 49.0, 95.0, 77.0, 63.0, 42.0, 13.0, 65.0, 0.0, 102.0, 55.0, 87.0, 32.0, 110.0, 19.0, 16.0, 36.0, 21.0, 21.0, 41.0, 146.0, 49.0, 57.0, 30.0, 109.0, 23.0, 15.0, 40.0, 153.0, 154.0, 62.0, 138.0, 7.0, 15.0, 127.0, 31.0, 4.0, 58.0, 99.0, 57.0, 106.0, 89.0, 6.0, 53.0, 66.0, 148.0, 57.0, 55.0, 43.0, 115.0, 32.0, 54.0, 94.0, 21.0, 41.0, 42.0, 37.0, 136.0, 90.0, 167.0, 86.0, 61.0, 19.0, 40.0, 158.0, 183.0, 104.0, 21.0, 111.0, 19.0, 55.0, 178.0, 153.0, 151.0, 186.0, 170.0, 155.0, 155.0, 24.0, 3.0, 39.0, 52.0, 177.0, 89.0, 96.0, 126.0, 119.0, 30.0, 148.0, 2.0, 32.0, 57.0, 185.0, 54.0, 34.0, 100.0, 5.0, 69.0, 138.0, 139.0, 58.0, 85.0, 116.0, 93.0, 19.0, 173.0, 162.0, 103.0, 130.0, 111.0, 171.0, 144.0, 82.0, 177.0, 155.0, 198.0, 199.0, 59.0, 168.0, 109.0, 147.0, 155.0, 162.0, 162.0, 142.0, 182.0, 114.0, 68.0, 87.0, 51.0, 14.0, 34.0, 10.0, 112.0, 171.0, 32.0, 73.0, 37.0, 125.0, 81.0, 153.0, 135.0, 74.0, 135.0, 79.0, 93.0, 155.0, 114.0, 116.0, 80.0, 112.0, 93.0, 157.0, 147.0, 159.0, 112.0, 13.0, 156.0, 142.0, 181.0, 109.0, 161.0, 45.0, 41.0, 120.0, 148.0, 40.0, 20.0, 111.0, 161.0, 163.0, 149.0, 32.0, 64.0, 49.0, 18.0, 76.0, 176.0, 144.0, 106.0, 39.0, 88.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5143895608785237, "mean_inference_ms": 1.3161987767096668, "mean_action_processing_ms": 0.2146881199554228, "mean_env_wait_ms": 0.17106934377545993, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003816366195678711, "StateBufferConnector_ms": 0.003099799156188965, "ViewRequirementAgentConnector_ms": 0.08855676651000977}, "num_episodes": 27, "episode_return_max": 330.2, "episode_return_min": -398.1, "episode_return_mean": -5.168000000000081, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 389.92644948125945, "num_env_steps_trained_throughput_per_sec": 389.92644948125945, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 9369.839, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9369.797, "sample_time_ms": 1050.136, "learn_time_ms": 8306.107, "learn_throughput": 481.573, "synch_weights_time_ms": 12.314}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-26-50", "timestamp": 1723645610, "time_this_iter_s": 10.331147193908691, "time_total_s": 131.51392674446106, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b08baf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 131.51392674446106, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 43.535714285714285, "ram_util_percent": 82.82142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6859178679960745, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 8.253692689522234, "policy_loss": -0.00928724026837184, "vf_loss": 8.259316363914934, "vf_explained_var": 0.20464460638465073, "kl": 0.012211905533532233, "entropy": 1.4829036889883576, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0142993155925994, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.801695040294102, "policy_loss": -0.005837465215858722, "vf_loss": 5.805137393588112, "vf_explained_var": 0.003115057976788314, "kl": 0.011975612753823915, "entropy": 1.46958582407583, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 319.10000000000025, "episode_reward_min": -398.1, "episode_reward_mean": 6.092999999999913, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 191.9, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -83.73350000000006, "predator_policy": 86.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [261.6, -223.7000000000004, 58.3000000000001, -32.8999999999999, 278.5999999999998, -172.00000000000006, -66.60000000000008, 171.49999999999932, -49.500000000000846, 189.89999999999984, 20.79999999999965, -65.00000000000036, 159.59999999999957, -44.70000000000046, 131.90000000000012, -45.90000000000006, 203.70000000000002, 63.199999999999996, 166.79999999999993, -2.0999999999999943, -179.10000000000016, -64.40000000000083, 256.80000000000007, -124.20000000000007, -6.900000000000011, 57.20000000000008, -353.40000000000003, -143.2, -198.60000000000002, -231.40000000000006, 294.7, 132.20000000000005, -36.89999999999982, -178.70000000000005, -183.89999999999998, -120.19999999999996, 174.29999999999995, -329.40000000000003, -13.499999999999952, 180.9, -1.5999999999999694, 185.39999999999998, 18.6, -157.99999999999994, -38.499999999999964, -241.0, 29.500000000000014, -144.1, -398.1, -289.69999999999993, -164.8, -90.0, -33.8, -315.20000000000005, 57.89999999999998, 103.90000000000003, 314.50000000000057, -10.500000000000151, -148.5, 170.69999999999985, -54.60000000000007, -227.3, -17.999999999999865, 104.60000000000001, -160.2, 31.70000000000004, 5.0, -355.2999999999999, -180.1000000000002, 5.6000000000000085, -88.80000000000022, -84.79999999999995, 5.100000000000168, -42.099999999999994, 214.59999999999994, -66.89999999999996, -245.9, 91.59999999999957, 203.89999999999998, -119.0000000000009, -43.899999999999864, -74.50000000000082, -25.100000000000144, 126.09999999999937, 250.39999999999975, -161.20000000000027, 300.7999999999999, 215.3999999999998, 191.79999999999987, 224.49999999999974, 273.99999999999994, 319.10000000000025, 160.89999999999986, 38.50000000000018, 186.2999999999998, 259.90000000000003, 180.6999999999999, 197.89999999999978, 119.1, 67.00000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [134.5999999999999, 65.0, -318.0999999999997, -100.60000000000016, -68.19999999999985, 39.50000000000005, -199.60000000000036, 34.700000000000045, 84.2, 139.40000000000003, -122.80000000000001, -356.1999999999998, -157.9000000000001, -108.69999999999999, 160.99999999999991, -11.499999999999819, -181.0, -26.49999999999978, 29.000000000000007, 98.90000000000003, -47.800000000000296, -87.40000000000015, -170.50000000000003, -89.50000000000033, -91.30000000000081, 191.9, -11.5, -247.2000000000005, 106.39999999999998, -86.50000000000009, -111.10000000000005, -92.80000000000001, 116.6, 1.0999999999997954, -94.60000000000005, 42.8, 62.00000000000007, 21.79999999999984, -32.19999999999999, -142.9, -251.50000000000003, -184.60000000000014, -157.90000000000063, -53.50000000000037, 85.1, 112.6999999999999, -161.79999999999998, -303.40000000000015, -138.7, 6.7999999999999865, -211.30000000000027, 138.5, -337.0, -249.40000000000003, -176.19999999999996, -271.00000000000006, -391.0, -163.60000000000002, -235.89999999999998, -305.5000000000002, 119.9, 147.79999999999998, 58.39999999999999, -17.19999999999999, 55.10000000000007, -358.0, -204.10000000000002, -196.60000000000002, -173.8, -159.1, -136.0, -134.2, 97.69999999999999, -12.399999999999991, -242.8, -325.5999999999999, -95.5, -52.00000000000024, -9.100000000000222, 116.0, -299.5, 20.9, 92.0, -49.60000000000001, -8.800000000000006, -181.6, -290.80000000000007, -59.2, 72.5, -376.0, -181.0, -301.0, -39.10000000000002, -246.39999999999998, -309.4, -93.7, -397.9, -353.2, -172.9, -374.79999999999995, -323.8, -118.0, -58.900000000000006, -333.1, -329.8, -28.0, -269.8, -369.40000000000003, -100.6, -23.5, 13.70000000000001, -47.800000000000026, 161.2999999999998, 105.2, -144.10000000000005, 11.599999999999968, -128.50000000000003, -223.0, 96.79999999999998, -36.099999999999966, -6.099999999999968, -254.49999999999994, -200.5, -314.79999999999995, -247.0, 20.000000000000014, -180.70000000000002, 113.30000000000001, -202.0, -227.2, -22.0, -142.29999999999998, -154.0, -46.0, -361.00000000000006, -298.30000000000007, -228.40000000000012, -222.70000000000007, 83.60000000000002, -247.0, -365.8, -45.999999999999886, -286.6000000000001, -68.19999999999999, 16.699999999999996, -97.60000000000053, -102.7, -207.40000000000003, 59.00000000000004, 95.60000000000002, 43.099999999999994, -382.0, -307.0, -250.9, -24.4, 20.000000000000014, 59.30000000000004, 77.60000000000001, -338.5, -32.49999999999975, -87.40000000000077, -206.5, -103.9, -97.60000000000082, -89.20000000000039, -76.90000000000063, 49.10000000000003, 20.000000000000014, 87.19999999999999, 84.20000000000007, -191.50000000000014, -273.70000000000016, 163.9999999999999, 117.79999999999987, 83.60000000000001, 96.79999999999991, 98.00000000000003, -11.200000000000003, -26.20000000000011, 157.6999999999999, 146.29999999999995, 88.70000000000005, 110.59999999999997, 186.49999999999997, -184.0, 137.89999999999984, 5.299999999999965, -56.79999999999998, 41.600000000000016, 64.69999999999997, 108.49999999999997, 106.4, 82.1, 14.600000000000014, -150.4000000000001, 161.29999999999976, -43.000000000000085, 13.100000000000044, 20.000000000000014, -24.999999999999922], "policy_predator_policy_reward": [21.0, 41.0, 146.0, 49.0, 57.0, 30.0, 109.0, 23.0, 15.0, 40.0, 153.0, 154.0, 62.0, 138.0, 7.0, 15.0, 127.0, 31.0, 4.0, 58.0, 99.0, 57.0, 106.0, 89.0, 6.0, 53.0, 66.0, 148.0, 57.0, 55.0, 43.0, 115.0, 32.0, 54.0, 94.0, 21.0, 41.0, 42.0, 37.0, 136.0, 90.0, 167.0, 86.0, 61.0, 19.0, 40.0, 158.0, 183.0, 104.0, 21.0, 111.0, 19.0, 55.0, 178.0, 153.0, 151.0, 186.0, 170.0, 155.0, 155.0, 24.0, 3.0, 39.0, 52.0, 177.0, 89.0, 96.0, 126.0, 119.0, 30.0, 148.0, 2.0, 32.0, 57.0, 185.0, 54.0, 34.0, 100.0, 5.0, 69.0, 138.0, 139.0, 58.0, 85.0, 116.0, 93.0, 19.0, 173.0, 162.0, 103.0, 130.0, 111.0, 171.0, 144.0, 82.0, 177.0, 155.0, 198.0, 199.0, 59.0, 168.0, 109.0, 147.0, 155.0, 162.0, 162.0, 142.0, 182.0, 114.0, 68.0, 87.0, 51.0, 14.0, 34.0, 10.0, 112.0, 171.0, 32.0, 73.0, 37.0, 125.0, 81.0, 153.0, 135.0, 74.0, 135.0, 79.0, 93.0, 155.0, 114.0, 116.0, 80.0, 112.0, 93.0, 157.0, 147.0, 159.0, 112.0, 13.0, 156.0, 142.0, 181.0, 109.0, 161.0, 45.0, 41.0, 120.0, 148.0, 40.0, 20.0, 111.0, 161.0, 163.0, 149.0, 32.0, 64.0, 49.0, 18.0, 76.0, 176.0, 144.0, 106.0, 39.0, 88.0, 78.0, 63.0, 38.0, 19.0, 44.0, 35.0, 141.0, 163.0, 13.0, 6.0, 23.0, 12.0, 57.0, 48.0, 51.0, 42.0, 19.0, 20.0, 19.0, 3.0, 103.0, 104.0, 47.0, 43.0, 52.0, 28.0, 29.0, 16.0, 26.0, 58.0, 86.0, 101.0, 72.0, 77.0, 21.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5185954715222961, "mean_inference_ms": 1.3290641665994545, "mean_action_processing_ms": 0.21634609740935531, "mean_env_wait_ms": 0.17349855013808507, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004299640655517578, "StateBufferConnector_ms": 0.00291597843170166, "ViewRequirementAgentConnector_ms": 0.09817790985107422}, "num_episodes": 18, "episode_return_max": 319.10000000000025, "episode_return_min": -398.1, "episode_return_mean": 6.092999999999913, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.1651169767737, "num_env_steps_trained_throughput_per_sec": 378.1651169767737, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 9510.737, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9510.692, "sample_time_ms": 1127.516, "learn_time_ms": 8369.532, "learn_throughput": 477.924, "synch_weights_time_ms": 12.384}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-27-01", "timestamp": 1723645621, "time_this_iter_s": 10.582921266555786, "time_total_s": 142.09684801101685, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b08b9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 142.09684801101685, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 58.260000000000005, "ram_util_percent": 77.40666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6155403563269863, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 7.817281563067563, "policy_loss": -0.006228112141360287, "vf_loss": 7.820784853879736, "vf_explained_var": 0.0490305103006817, "kl": 0.009082805191737573, "entropy": 1.477357879202202, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.419976603259485, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.588049256360089, "policy_loss": -0.012613679263642225, "vf_loss": 5.597955403504549, "vf_explained_var": 0.06237772841932912, "kl": 0.013537690636897639, "entropy": 1.4150763851624948, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 319.10000000000025, "episode_reward_min": -398.1, "episode_reward_mean": 16.016999999999925, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 186.49999999999997, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -76.84150000000004, "predator_policy": 84.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [166.79999999999993, -2.0999999999999943, -179.10000000000016, -64.40000000000083, 256.80000000000007, -124.20000000000007, -6.900000000000011, 57.20000000000008, -353.40000000000003, -143.2, -198.60000000000002, -231.40000000000006, 294.7, 132.20000000000005, -36.89999999999982, -178.70000000000005, -183.89999999999998, -120.19999999999996, 174.29999999999995, -329.40000000000003, -13.499999999999952, 180.9, -1.5999999999999694, 185.39999999999998, 18.6, -157.99999999999994, -38.499999999999964, -241.0, 29.500000000000014, -144.1, -398.1, -289.69999999999993, -164.8, -90.0, -33.8, -315.20000000000005, 57.89999999999998, 103.90000000000003, 314.50000000000057, -10.500000000000151, -148.5, 170.69999999999985, -54.60000000000007, -227.3, -17.999999999999865, 104.60000000000001, -160.2, 31.70000000000004, 5.0, -355.2999999999999, -180.1000000000002, 5.6000000000000085, -88.80000000000022, -84.79999999999995, 5.100000000000168, -42.099999999999994, 214.59999999999994, -66.89999999999996, -245.9, 91.59999999999957, 203.89999999999998, -119.0000000000009, -43.899999999999864, -74.50000000000082, -25.100000000000144, 126.09999999999937, 250.39999999999975, -161.20000000000027, 300.7999999999999, 215.3999999999998, 191.79999999999987, 224.49999999999974, 273.99999999999994, 319.10000000000025, 160.89999999999986, 38.50000000000018, 186.2999999999998, 259.90000000000003, 180.6999999999999, 197.89999999999978, 119.1, 67.00000000000013, -41.4999999999998, 244.49999999999997, 81.39999999999979, 135.29999999999964, -94.00000000000001, 177.89999999999992, 120.89999999999978, 31.300000000000004, 183.7999999999997, 153.59999999999917, 163.69999999999993, 74.89999999999966, 41.20000000000014, 45.200000000000145, 166.29999999999944, 9.5, 232.09999999999985, 105.09999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [62.00000000000007, 21.79999999999984, -32.19999999999999, -142.9, -251.50000000000003, -184.60000000000014, -157.90000000000063, -53.50000000000037, 85.1, 112.6999999999999, -161.79999999999998, -303.40000000000015, -138.7, 6.7999999999999865, -211.30000000000027, 138.5, -337.0, -249.40000000000003, -176.19999999999996, -271.00000000000006, -391.0, -163.60000000000002, -235.89999999999998, -305.5000000000002, 119.9, 147.79999999999998, 58.39999999999999, -17.19999999999999, 55.10000000000007, -358.0, -204.10000000000002, -196.60000000000002, -173.8, -159.1, -136.0, -134.2, 97.69999999999999, -12.399999999999991, -242.8, -325.5999999999999, -95.5, -52.00000000000024, -9.100000000000222, 116.0, -299.5, 20.9, 92.0, -49.60000000000001, -8.800000000000006, -181.6, -290.80000000000007, -59.2, 72.5, -376.0, -181.0, -301.0, -39.10000000000002, -246.39999999999998, -309.4, -93.7, -397.9, -353.2, -172.9, -374.79999999999995, -323.8, -118.0, -58.900000000000006, -333.1, -329.8, -28.0, -269.8, -369.40000000000003, -100.6, -23.5, 13.70000000000001, -47.800000000000026, 161.2999999999998, 105.2, -144.10000000000005, 11.599999999999968, -128.50000000000003, -223.0, 96.79999999999998, -36.099999999999966, -6.099999999999968, -254.49999999999994, -200.5, -314.79999999999995, -247.0, 20.000000000000014, -180.70000000000002, 113.30000000000001, -202.0, -227.2, -22.0, -142.29999999999998, -154.0, -46.0, -361.00000000000006, -298.30000000000007, -228.40000000000012, -222.70000000000007, 83.60000000000002, -247.0, -365.8, -45.999999999999886, -286.6000000000001, -68.19999999999999, 16.699999999999996, -97.60000000000053, -102.7, -207.40000000000003, 59.00000000000004, 95.60000000000002, 43.099999999999994, -382.0, -307.0, -250.9, -24.4, 20.000000000000014, 59.30000000000004, 77.60000000000001, -338.5, -32.49999999999975, -87.40000000000077, -206.5, -103.9, -97.60000000000082, -89.20000000000039, -76.90000000000063, 49.10000000000003, 20.000000000000014, 87.19999999999999, 84.20000000000007, -191.50000000000014, -273.70000000000016, 163.9999999999999, 117.79999999999987, 83.60000000000001, 96.79999999999991, 98.00000000000003, -11.200000000000003, -26.20000000000011, 157.6999999999999, 146.29999999999995, 88.70000000000005, 110.59999999999997, 186.49999999999997, -184.0, 137.89999999999984, 5.299999999999965, -56.79999999999998, 41.600000000000016, 64.69999999999997, 108.49999999999997, 106.4, 82.1, 14.600000000000014, -150.4000000000001, 161.29999999999976, -43.000000000000085, 13.100000000000044, 20.000000000000014, -24.999999999999922, -160.59999999999997, -94.8999999999999, -37.599999999999994, 178.09999999999994, -44.50000000000014, 26.900000000000006, -35.799999999999976, 79.09999999999985, -148.6, -138.4000000000001, 41.89999999999999, 35.00000000000001, -53.500000000000064, 40.40000000000003, 11.0, -171.70000000000005, -114.40000000000015, 141.19999999999982, 142.69999999999982, -3.099999999999958, -49.6, 83.3, -0.099999999999973, 20.000000000000014, 7.399999999999965, -44.19999999999998, 20.000000000000014, -122.80000000000018, 164.29999999999998, -21.999999999999744, -56.49999999999999, -70.00000000000013, 95.6, 81.5, 20.000000000000014, 22.10000000000006], "policy_predator_policy_reward": [41.0, 42.0, 37.0, 136.0, 90.0, 167.0, 86.0, 61.0, 19.0, 40.0, 158.0, 183.0, 104.0, 21.0, 111.0, 19.0, 55.0, 178.0, 153.0, 151.0, 186.0, 170.0, 155.0, 155.0, 24.0, 3.0, 39.0, 52.0, 177.0, 89.0, 96.0, 126.0, 119.0, 30.0, 148.0, 2.0, 32.0, 57.0, 185.0, 54.0, 34.0, 100.0, 5.0, 69.0, 138.0, 139.0, 58.0, 85.0, 116.0, 93.0, 19.0, 173.0, 162.0, 103.0, 130.0, 111.0, 171.0, 144.0, 82.0, 177.0, 155.0, 198.0, 199.0, 59.0, 168.0, 109.0, 147.0, 155.0, 162.0, 162.0, 142.0, 182.0, 114.0, 68.0, 87.0, 51.0, 14.0, 34.0, 10.0, 112.0, 171.0, 32.0, 73.0, 37.0, 125.0, 81.0, 153.0, 135.0, 74.0, 135.0, 79.0, 93.0, 155.0, 114.0, 116.0, 80.0, 112.0, 93.0, 157.0, 147.0, 159.0, 112.0, 13.0, 156.0, 142.0, 181.0, 109.0, 161.0, 45.0, 41.0, 120.0, 148.0, 40.0, 20.0, 111.0, 161.0, 163.0, 149.0, 32.0, 64.0, 49.0, 18.0, 76.0, 176.0, 144.0, 106.0, 39.0, 88.0, 78.0, 63.0, 38.0, 19.0, 44.0, 35.0, 141.0, 163.0, 13.0, 6.0, 23.0, 12.0, 57.0, 48.0, 51.0, 42.0, 19.0, 20.0, 19.0, 3.0, 103.0, 104.0, 47.0, 43.0, 52.0, 28.0, 29.0, 16.0, 26.0, 58.0, 86.0, 101.0, 72.0, 77.0, 21.0, 51.0, 86.0, 128.0, 34.0, 70.0, 21.0, 78.0, 24.0, 68.0, 117.0, 76.0, 61.0, 40.0, 54.0, 80.0, 86.0, 106.0, 95.0, 62.0, 12.0, 2.0, 35.0, 95.0, 22.0, 33.0, 16.0, 62.0, 91.0, 57.0, 4.0, 20.0, 18.0, 118.0, 38.0, 17.0, 44.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.523173194779365, "mean_inference_ms": 1.3435300597783675, "mean_action_processing_ms": 0.21806461177565567, "mean_env_wait_ms": 0.17585534821616888, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004414200782775879, "StateBufferConnector_ms": 0.0031027793884277344, "ViewRequirementAgentConnector_ms": 0.10211503505706787}, "num_episodes": 18, "episode_return_max": 319.10000000000025, "episode_return_min": -398.1, "episode_return_mean": 16.016999999999925, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 400.6711663120727, "num_env_steps_trained_throughput_per_sec": 400.6711663120727, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 9588.581, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9588.533, "sample_time_ms": 1128.214, "learn_time_ms": 8445.846, "learn_throughput": 473.606, "synch_weights_time_ms": 12.619}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-27-11", "timestamp": 1723645631, "time_this_iter_s": 10.026352167129517, "time_total_s": 152.12320017814636, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ad360d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 152.12320017814636, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 39.693333333333335, "ram_util_percent": 79.76666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2800114651836414, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 8.206328119802727, "policy_loss": -0.0025283393048479287, "vf_loss": 8.206726891906174, "vf_explained_var": -0.06508122017143896, "kl": 0.007098502939364377, "entropy": 1.4961848952782848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2431048503628483, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.654995206298021, "policy_loss": -0.009802335251625332, "vf_loss": 7.662608417632088, "vf_explained_var": 0.11901274487455055, "kl": 0.010945505890332344, "entropy": 1.3586282846158144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 319.10000000000025, "episode_reward_min": -398.1, "episode_reward_mean": 32.94799999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 186.49999999999997, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -63.36100000000005, "predator_policy": 79.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [174.29999999999995, -329.40000000000003, -13.499999999999952, 180.9, -1.5999999999999694, 185.39999999999998, 18.6, -157.99999999999994, -38.499999999999964, -241.0, 29.500000000000014, -144.1, -398.1, -289.69999999999993, -164.8, -90.0, -33.8, -315.20000000000005, 57.89999999999998, 103.90000000000003, 314.50000000000057, -10.500000000000151, -148.5, 170.69999999999985, -54.60000000000007, -227.3, -17.999999999999865, 104.60000000000001, -160.2, 31.70000000000004, 5.0, -355.2999999999999, -180.1000000000002, 5.6000000000000085, -88.80000000000022, -84.79999999999995, 5.100000000000168, -42.099999999999994, 214.59999999999994, -66.89999999999996, -245.9, 91.59999999999957, 203.89999999999998, -119.0000000000009, -43.899999999999864, -74.50000000000082, -25.100000000000144, 126.09999999999937, 250.39999999999975, -161.20000000000027, 300.7999999999999, 215.3999999999998, 191.79999999999987, 224.49999999999974, 273.99999999999994, 319.10000000000025, 160.89999999999986, 38.50000000000018, 186.2999999999998, 259.90000000000003, 180.6999999999999, 197.89999999999978, 119.1, 67.00000000000013, -41.4999999999998, 244.49999999999997, 81.39999999999979, 135.29999999999964, -94.00000000000001, 177.89999999999992, 120.89999999999978, 31.300000000000004, 183.7999999999997, 153.59999999999917, 163.69999999999993, 74.89999999999966, 41.20000000000014, 45.200000000000145, 166.29999999999944, 9.5, 232.09999999999985, 105.09999999999994, 125.49999999999957, 189.49999999999974, 265.5999999999999, -153.10000000000042, 180.99999999999991, 38.899999999999814, -315.09999999999957, -10.299999999999878, 46.90000000000007, 69.20000000000019, 187.59999999999988, 90.59999999999984, 34.50000000000007, -237.5999999999993, 145.3999999999993, -202.40000000000018, 255.19999999999982, 66.39999999999941], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [97.69999999999999, -12.399999999999991, -242.8, -325.5999999999999, -95.5, -52.00000000000024, -9.100000000000222, 116.0, -299.5, 20.9, 92.0, -49.60000000000001, -8.800000000000006, -181.6, -290.80000000000007, -59.2, 72.5, -376.0, -181.0, -301.0, -39.10000000000002, -246.39999999999998, -309.4, -93.7, -397.9, -353.2, -172.9, -374.79999999999995, -323.8, -118.0, -58.900000000000006, -333.1, -329.8, -28.0, -269.8, -369.40000000000003, -100.6, -23.5, 13.70000000000001, -47.800000000000026, 161.2999999999998, 105.2, -144.10000000000005, 11.599999999999968, -128.50000000000003, -223.0, 96.79999999999998, -36.099999999999966, -6.099999999999968, -254.49999999999994, -200.5, -314.79999999999995, -247.0, 20.000000000000014, -180.70000000000002, 113.30000000000001, -202.0, -227.2, -22.0, -142.29999999999998, -154.0, -46.0, -361.00000000000006, -298.30000000000007, -228.40000000000012, -222.70000000000007, 83.60000000000002, -247.0, -365.8, -45.999999999999886, -286.6000000000001, -68.19999999999999, 16.699999999999996, -97.60000000000053, -102.7, -207.40000000000003, 59.00000000000004, 95.60000000000002, 43.099999999999994, -382.0, -307.0, -250.9, -24.4, 20.000000000000014, 59.30000000000004, 77.60000000000001, -338.5, -32.49999999999975, -87.40000000000077, -206.5, -103.9, -97.60000000000082, -89.20000000000039, -76.90000000000063, 49.10000000000003, 20.000000000000014, 87.19999999999999, 84.20000000000007, -191.50000000000014, -273.70000000000016, 163.9999999999999, 117.79999999999987, 83.60000000000001, 96.79999999999991, 98.00000000000003, -11.200000000000003, -26.20000000000011, 157.6999999999999, 146.29999999999995, 88.70000000000005, 110.59999999999997, 186.49999999999997, -184.0, 137.89999999999984, 5.299999999999965, -56.79999999999998, 41.600000000000016, 64.69999999999997, 108.49999999999997, 106.4, 82.1, 14.600000000000014, -150.4000000000001, 161.29999999999976, -43.000000000000085, 13.100000000000044, 20.000000000000014, -24.999999999999922, -160.59999999999997, -94.8999999999999, -37.599999999999994, 178.09999999999994, -44.50000000000014, 26.900000000000006, -35.799999999999976, 79.09999999999985, -148.6, -138.4000000000001, 41.89999999999999, 35.00000000000001, -53.500000000000064, 40.40000000000003, 11.0, -171.70000000000005, -114.40000000000015, 141.19999999999982, 142.69999999999982, -3.099999999999958, -49.6, 83.3, -0.099999999999973, 20.000000000000014, 7.399999999999965, -44.19999999999998, 20.000000000000014, -122.80000000000018, 164.29999999999998, -21.999999999999744, -56.49999999999999, -70.00000000000013, 95.6, 81.5, 20.000000000000014, 22.10000000000006, -24.099999999999945, 26.59999999999995, -18.100000000000122, 125.59999999999985, 79.39999999999996, 153.19999999999996, -124.00000000000028, -222.10000000000016, -100.00000000000011, 137.0, -86.20000000000002, 1.099999999999993, -269.8, -286.29999999999984, 17.899999999999988, -134.20000000000005, -83.80000000000004, 22.700000000000053, 20.000000000000014, -17.799999999999926, 104.29999999999995, -33.69999999999998, -70.00000000000017, 53.60000000000003, -226.9, 28.400000000000055, -243.99999999999986, -232.59999999999988, 135.49999999999986, -45.09999999999976, -237.7000000000001, -222.70000000000007, 127.69999999999979, 93.49999999999991, -88.60000000000004, -0.9999999999999992], "policy_predator_policy_reward": [32.0, 57.0, 185.0, 54.0, 34.0, 100.0, 5.0, 69.0, 138.0, 139.0, 58.0, 85.0, 116.0, 93.0, 19.0, 173.0, 162.0, 103.0, 130.0, 111.0, 171.0, 144.0, 82.0, 177.0, 155.0, 198.0, 199.0, 59.0, 168.0, 109.0, 147.0, 155.0, 162.0, 162.0, 142.0, 182.0, 114.0, 68.0, 87.0, 51.0, 14.0, 34.0, 10.0, 112.0, 171.0, 32.0, 73.0, 37.0, 125.0, 81.0, 153.0, 135.0, 74.0, 135.0, 79.0, 93.0, 155.0, 114.0, 116.0, 80.0, 112.0, 93.0, 157.0, 147.0, 159.0, 112.0, 13.0, 156.0, 142.0, 181.0, 109.0, 161.0, 45.0, 41.0, 120.0, 148.0, 40.0, 20.0, 111.0, 161.0, 163.0, 149.0, 32.0, 64.0, 49.0, 18.0, 76.0, 176.0, 144.0, 106.0, 39.0, 88.0, 78.0, 63.0, 38.0, 19.0, 44.0, 35.0, 141.0, 163.0, 13.0, 6.0, 23.0, 12.0, 57.0, 48.0, 51.0, 42.0, 19.0, 20.0, 19.0, 3.0, 103.0, 104.0, 47.0, 43.0, 52.0, 28.0, 29.0, 16.0, 26.0, 58.0, 86.0, 101.0, 72.0, 77.0, 21.0, 51.0, 86.0, 128.0, 34.0, 70.0, 21.0, 78.0, 24.0, 68.0, 117.0, 76.0, 61.0, 40.0, 54.0, 80.0, 86.0, 106.0, 95.0, 62.0, 12.0, 2.0, 35.0, 95.0, 22.0, 33.0, 16.0, 62.0, 91.0, 57.0, 4.0, 20.0, 18.0, 118.0, 38.0, 17.0, 44.0, 19.0, 46.0, 77.0, 32.0, 50.0, 13.0, 20.0, 87.0, 106.0, 91.0, 53.0, 72.0, 52.0, 181.0, 60.0, 23.0, 83.0, 76.0, 32.0, 35.0, 32.0, 63.0, 54.0, 45.0, 62.0, 113.0, 120.0, 147.0, 92.0, 10.0, 45.0, 99.0, 159.0, 17.0, 17.0, 73.0, 83.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.52981487735445, "mean_inference_ms": 1.3616743485781244, "mean_action_processing_ms": 0.22034975457191905, "mean_env_wait_ms": 0.17822021582025116, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008704662322998047, "StateBufferConnector_ms": 0.0032227039337158203, "ViewRequirementAgentConnector_ms": 0.11443567276000977}, "num_episodes": 18, "episode_return_max": 319.10000000000025, "episode_return_min": -398.1, "episode_return_mean": 32.94799999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 394.0954979966855, "num_env_steps_trained_throughput_per_sec": 394.0954979966855, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 9687.592, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9687.544, "sample_time_ms": 1185.538, "learn_time_ms": 8487.112, "learn_throughput": 471.303, "synch_weights_time_ms": 12.934}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-27-21", "timestamp": 1723645641, "time_this_iter_s": 10.190540075302124, "time_total_s": 162.3137402534485, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 162.3137402534485, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 41.307142857142864, "ram_util_percent": 83.33571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9133028090000153, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 7.065527173451015, "policy_loss": -0.00796824848198051, "vf_loss": 7.070272464348526, "vf_explained_var": -0.20285476124475874, "kl": 0.010743219910946405, "entropy": 1.5073947273864947, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.999014829012452, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.231351573126657, "policy_loss": -0.00855888487160127, "vf_loss": 8.238144575098834, "vf_explained_var": 0.06803610195558538, "kl": 0.008829397990671723, "entropy": 1.365594753449556, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 319.10000000000025, "episode_reward_min": -355.2999999999999, "episode_reward_mean": 25.992999999999878, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -382.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.49999999999997, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": -65.10850000000005, "predator_policy": 78.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-148.5, 170.69999999999985, -54.60000000000007, -227.3, -17.999999999999865, 104.60000000000001, -160.2, 31.70000000000004, 5.0, -355.2999999999999, -180.1000000000002, 5.6000000000000085, -88.80000000000022, -84.79999999999995, 5.100000000000168, -42.099999999999994, 214.59999999999994, -66.89999999999996, -245.9, 91.59999999999957, 203.89999999999998, -119.0000000000009, -43.899999999999864, -74.50000000000082, -25.100000000000144, 126.09999999999937, 250.39999999999975, -161.20000000000027, 300.7999999999999, 215.3999999999998, 191.79999999999987, 224.49999999999974, 273.99999999999994, 319.10000000000025, 160.89999999999986, 38.50000000000018, 186.2999999999998, 259.90000000000003, 180.6999999999999, 197.89999999999978, 119.1, 67.00000000000013, -41.4999999999998, 244.49999999999997, 81.39999999999979, 135.29999999999964, -94.00000000000001, 177.89999999999992, 120.89999999999978, 31.300000000000004, 183.7999999999997, 153.59999999999917, 163.69999999999993, 74.89999999999966, 41.20000000000014, 45.200000000000145, 166.29999999999944, 9.5, 232.09999999999985, 105.09999999999994, 125.49999999999957, 189.49999999999974, 265.5999999999999, -153.10000000000042, 180.99999999999991, 38.899999999999814, -315.09999999999957, -10.299999999999878, 46.90000000000007, 69.20000000000019, 187.59999999999988, 90.59999999999984, 34.50000000000007, -237.5999999999993, 145.3999999999993, -202.40000000000018, 255.19999999999982, 66.39999999999941, -139.4, -84.40000000000056, 20.900000000000016, 72.19999999999999, 33.90000000000017, -74.80000000000018, -88.59999999999997, -193.2000000000001, -221.60000000000005, 11.300000000000058, -261.1000000000002, -83.00000000000182, -98.10000000000008, -5.999999999999778, -145.10000000000085, -151.10000000000002, -71.40000000000003, -287.70000000000005, -49.09999999999999, 103.1999999999999, -160.1, 14.500000000000174], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-128.50000000000003, -223.0, 96.79999999999998, -36.099999999999966, -6.099999999999968, -254.49999999999994, -200.5, -314.79999999999995, -247.0, 20.000000000000014, -180.70000000000002, 113.30000000000001, -202.0, -227.2, -22.0, -142.29999999999998, -154.0, -46.0, -361.00000000000006, -298.30000000000007, -228.40000000000012, -222.70000000000007, 83.60000000000002, -247.0, -365.8, -45.999999999999886, -286.6000000000001, -68.19999999999999, 16.699999999999996, -97.60000000000053, -102.7, -207.40000000000003, 59.00000000000004, 95.60000000000002, 43.099999999999994, -382.0, -307.0, -250.9, -24.4, 20.000000000000014, 59.30000000000004, 77.60000000000001, -338.5, -32.49999999999975, -87.40000000000077, -206.5, -103.9, -97.60000000000082, -89.20000000000039, -76.90000000000063, 49.10000000000003, 20.000000000000014, 87.19999999999999, 84.20000000000007, -191.50000000000014, -273.70000000000016, 163.9999999999999, 117.79999999999987, 83.60000000000001, 96.79999999999991, 98.00000000000003, -11.200000000000003, -26.20000000000011, 157.6999999999999, 146.29999999999995, 88.70000000000005, 110.59999999999997, 186.49999999999997, -184.0, 137.89999999999984, 5.299999999999965, -56.79999999999998, 41.600000000000016, 64.69999999999997, 108.49999999999997, 106.4, 82.1, 14.600000000000014, -150.4000000000001, 161.29999999999976, -43.000000000000085, 13.100000000000044, 20.000000000000014, -24.999999999999922, -160.59999999999997, -94.8999999999999, -37.599999999999994, 178.09999999999994, -44.50000000000014, 26.900000000000006, -35.799999999999976, 79.09999999999985, -148.6, -138.4000000000001, 41.89999999999999, 35.00000000000001, -53.500000000000064, 40.40000000000003, 11.0, -171.70000000000005, -114.40000000000015, 141.19999999999982, 142.69999999999982, -3.099999999999958, -49.6, 83.3, -0.099999999999973, 20.000000000000014, 7.399999999999965, -44.19999999999998, 20.000000000000014, -122.80000000000018, 164.29999999999998, -21.999999999999744, -56.49999999999999, -70.00000000000013, 95.6, 81.5, 20.000000000000014, 22.10000000000006, -24.099999999999945, 26.59999999999995, -18.100000000000122, 125.59999999999985, 79.39999999999996, 153.19999999999996, -124.00000000000028, -222.10000000000016, -100.00000000000011, 137.0, -86.20000000000002, 1.099999999999993, -269.8, -286.29999999999984, 17.899999999999988, -134.20000000000005, -83.80000000000004, 22.700000000000053, 20.000000000000014, -17.799999999999926, 104.29999999999995, -33.69999999999998, -70.00000000000017, 53.60000000000003, -226.9, 28.400000000000055, -243.99999999999986, -232.59999999999988, 135.49999999999986, -45.09999999999976, -237.7000000000001, -222.70000000000007, 127.69999999999979, 93.49999999999991, -88.60000000000004, -0.9999999999999992, -156.70000000000002, -192.70000000000013, -236.20000000000013, -5.1999999999999265, -13.599999999999783, 15.499999999999963, 65.29999999999987, -66.1000000000009, 3.1999999999999615, -61.30000000000001, -43.000000000000014, -260.79999999999967, -305.80000000000007, -38.799999999999756, -222.40000000000003, -236.80000000000007, -330.40000000000003, -212.20000000000002, -54.40000000000003, -115.30000000000001, -238.60000000000014, -326.4999999999998, -53.50000000000019, -74.50000000000088, -42.10000000000002, -316.0, -124.30000000000015, 5.299999999999965, -133.9000000000007, -332.19999999999976, -322.6, -176.50000000000003, -63.999999999999964, -237.4000000000002, -306.69999999999993, -289.0, -76.9, -143.2, -10.900000000000006, -46.899999999999984, -192.1, -229.00000000000009, -79.6000000000002, 1.0999999999999865], "policy_predator_policy_reward": [171.0, 32.0, 73.0, 37.0, 125.0, 81.0, 153.0, 135.0, 74.0, 135.0, 79.0, 93.0, 155.0, 114.0, 116.0, 80.0, 112.0, 93.0, 157.0, 147.0, 159.0, 112.0, 13.0, 156.0, 142.0, 181.0, 109.0, 161.0, 45.0, 41.0, 120.0, 148.0, 40.0, 20.0, 111.0, 161.0, 163.0, 149.0, 32.0, 64.0, 49.0, 18.0, 76.0, 176.0, 144.0, 106.0, 39.0, 88.0, 78.0, 63.0, 38.0, 19.0, 44.0, 35.0, 141.0, 163.0, 13.0, 6.0, 23.0, 12.0, 57.0, 48.0, 51.0, 42.0, 19.0, 20.0, 19.0, 3.0, 103.0, 104.0, 47.0, 43.0, 52.0, 28.0, 29.0, 16.0, 26.0, 58.0, 86.0, 101.0, 72.0, 77.0, 21.0, 51.0, 86.0, 128.0, 34.0, 70.0, 21.0, 78.0, 24.0, 68.0, 117.0, 76.0, 61.0, 40.0, 54.0, 80.0, 86.0, 106.0, 95.0, 62.0, 12.0, 2.0, 35.0, 95.0, 22.0, 33.0, 16.0, 62.0, 91.0, 57.0, 4.0, 20.0, 18.0, 118.0, 38.0, 17.0, 44.0, 19.0, 46.0, 77.0, 32.0, 50.0, 13.0, 20.0, 87.0, 106.0, 91.0, 53.0, 72.0, 52.0, 181.0, 60.0, 23.0, 83.0, 76.0, 32.0, 35.0, 32.0, 63.0, 54.0, 45.0, 62.0, 113.0, 120.0, 147.0, 92.0, 10.0, 45.0, 99.0, 159.0, 17.0, 17.0, 73.0, 83.0, 61.0, 149.0, 125.0, 32.0, 3.0, 16.0, 61.0, 12.0, 72.0, 20.0, 141.0, 88.0, 145.0, 111.0, 132.0, 134.0, 181.0, 140.0, 76.0, 105.0, 137.0, 167.0, 45.0, 0.0, 97.0, 163.0, 23.0, 90.0, 153.0, 168.0, 175.0, 173.0, 153.0, 77.0, 160.0, 148.0, 73.0, 98.0, 51.0, 110.0, 151.0, 110.0, 39.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5378782977653187, "mean_inference_ms": 1.3840330933810256, "mean_action_processing_ms": 0.22309937190285242, "mean_env_wait_ms": 0.18092674908785975, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008736491203308105, "StateBufferConnector_ms": 0.0032520294189453125, "ViewRequirementAgentConnector_ms": 0.11638760566711426}, "num_episodes": 22, "episode_return_max": 319.10000000000025, "episode_return_min": -355.2999999999999, "episode_return_mean": 25.992999999999878, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 430.88892136359163, "num_env_steps_trained_throughput_per_sec": 430.88892136359163, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 9690.737, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9690.688, "sample_time_ms": 1186.696, "learn_time_ms": 8489.21, "learn_throughput": 471.186, "synch_weights_time_ms": 12.83}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-27-31", "timestamp": 1723645651, "time_this_iter_s": 9.286256313323975, "time_total_s": 171.59999656677246, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0983a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 171.59999656677246, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 27.66923076923077, "ram_util_percent": 83.24615384615385}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0762843294433817, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 7.06004492643649, "policy_loss": -0.007043471060589784, "vf_loss": 7.064500112129898, "vf_explained_var": -0.22117997975576492, "kl": 0.008627621587337797, "entropy": 1.5130837532578323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6165256534303936, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.578250367553146, "policy_loss": -0.01094227822216612, "vf_loss": 8.586832043985842, "vf_explained_var": 0.033062468477027124, "kl": 0.011802929942574298, "entropy": 1.3666923167844298, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 319.10000000000025, "episode_reward_min": -361.19999999999993, "episode_reward_mean": 17.89299999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.49999999999997, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -67.47850000000005, "predator_policy": 76.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-74.50000000000082, -25.100000000000144, 126.09999999999937, 250.39999999999975, -161.20000000000027, 300.7999999999999, 215.3999999999998, 191.79999999999987, 224.49999999999974, 273.99999999999994, 319.10000000000025, 160.89999999999986, 38.50000000000018, 186.2999999999998, 259.90000000000003, 180.6999999999999, 197.89999999999978, 119.1, 67.00000000000013, -41.4999999999998, 244.49999999999997, 81.39999999999979, 135.29999999999964, -94.00000000000001, 177.89999999999992, 120.89999999999978, 31.300000000000004, 183.7999999999997, 153.59999999999917, 163.69999999999993, 74.89999999999966, 41.20000000000014, 45.200000000000145, 166.29999999999944, 9.5, 232.09999999999985, 105.09999999999994, 125.49999999999957, 189.49999999999974, 265.5999999999999, -153.10000000000042, 180.99999999999991, 38.899999999999814, -315.09999999999957, -10.299999999999878, 46.90000000000007, 69.20000000000019, 187.59999999999988, 90.59999999999984, 34.50000000000007, -237.5999999999993, 145.3999999999993, -202.40000000000018, 255.19999999999982, 66.39999999999941, -139.4, -84.40000000000056, 20.900000000000016, 72.19999999999999, 33.90000000000017, -74.80000000000018, -88.59999999999997, -193.2000000000001, -221.60000000000005, 11.300000000000058, -261.1000000000002, -83.00000000000182, -98.10000000000008, -5.999999999999778, -145.10000000000085, -151.10000000000002, -71.40000000000003, -287.70000000000005, -49.09999999999999, 103.1999999999999, -160.1, 14.500000000000174, -225.80000000000015, -98.20000000000061, -135.7000000000001, -262.4999999999994, 67.60000000000007, -105.80000000000013, 93.69999999999959, -25.699999999999942, 115.69999999999982, -104.4000000000002, -83.1, -45.799999999999834, 33.400000000000205, 6.900000000000121, -71.19999999999985, -245.0, -49.299999999999756, -151.60000000000016, -361.19999999999993, 55.69999999999998, -167.60000000000002, -10.299999999999926, -42.39999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-103.9, -97.60000000000082, -89.20000000000039, -76.90000000000063, 49.10000000000003, 20.000000000000014, 87.19999999999999, 84.20000000000007, -191.50000000000014, -273.70000000000016, 163.9999999999999, 117.79999999999987, 83.60000000000001, 96.79999999999991, 98.00000000000003, -11.200000000000003, -26.20000000000011, 157.6999999999999, 146.29999999999995, 88.70000000000005, 110.59999999999997, 186.49999999999997, -184.0, 137.89999999999984, 5.299999999999965, -56.79999999999998, 41.600000000000016, 64.69999999999997, 108.49999999999997, 106.4, 82.1, 14.600000000000014, -150.4000000000001, 161.29999999999976, -43.000000000000085, 13.100000000000044, 20.000000000000014, -24.999999999999922, -160.59999999999997, -94.8999999999999, -37.599999999999994, 178.09999999999994, -44.50000000000014, 26.900000000000006, -35.799999999999976, 79.09999999999985, -148.6, -138.4000000000001, 41.89999999999999, 35.00000000000001, -53.500000000000064, 40.40000000000003, 11.0, -171.70000000000005, -114.40000000000015, 141.19999999999982, 142.69999999999982, -3.099999999999958, -49.6, 83.3, -0.099999999999973, 20.000000000000014, 7.399999999999965, -44.19999999999998, 20.000000000000014, -122.80000000000018, 164.29999999999998, -21.999999999999744, -56.49999999999999, -70.00000000000013, 95.6, 81.5, 20.000000000000014, 22.10000000000006, -24.099999999999945, 26.59999999999995, -18.100000000000122, 125.59999999999985, 79.39999999999996, 153.19999999999996, -124.00000000000028, -222.10000000000016, -100.00000000000011, 137.0, -86.20000000000002, 1.099999999999993, -269.8, -286.29999999999984, 17.899999999999988, -134.20000000000005, -83.80000000000004, 22.700000000000053, 20.000000000000014, -17.799999999999926, 104.29999999999995, -33.69999999999998, -70.00000000000017, 53.60000000000003, -226.9, 28.400000000000055, -243.99999999999986, -232.59999999999988, 135.49999999999986, -45.09999999999976, -237.7000000000001, -222.70000000000007, 127.69999999999979, 93.49999999999991, -88.60000000000004, -0.9999999999999992, -156.70000000000002, -192.70000000000013, -236.20000000000013, -5.1999999999999265, -13.599999999999783, 15.499999999999963, 65.29999999999987, -66.1000000000009, 3.1999999999999615, -61.30000000000001, -43.000000000000014, -260.79999999999967, -305.80000000000007, -38.799999999999756, -222.40000000000003, -236.80000000000007, -330.40000000000003, -212.20000000000002, -54.40000000000003, -115.30000000000001, -238.60000000000014, -326.4999999999998, -53.50000000000019, -74.50000000000088, -42.10000000000002, -316.0, -124.30000000000015, 5.299999999999965, -133.9000000000007, -332.19999999999976, -322.6, -176.50000000000003, -63.999999999999964, -237.4000000000002, -306.69999999999993, -289.0, -76.9, -143.2, -10.900000000000006, -46.899999999999984, -192.1, -229.00000000000009, -79.6000000000002, 1.0999999999999865, -260.19999999999976, -256.6000000000001, 1.0999999999999865, -322.30000000000007, -137.20000000000027, -251.50000000000003, -238.60000000000014, -265.89999999999986, -55.600000000000264, 30.20000000000001, -252.4000000000001, -99.40000000000003, 9.200000000000017, -32.49999999999975, -39.39999999999999, -112.30000000000078, -0.9999999999999846, 64.70000000000003, -138.10000000000005, -190.30000000000015, -44.19999999999999, -301.90000000000003, 20.000000000000014, -212.80000000000007, 20.000000000000014, 7.399999999999965, 20.000000000000014, -45.09999999999976, -242.50000000000006, -15.699999999999747, -264.1, -256.9, -332.20000000000005, -24.099999999999746, -122.50000000000014, -336.0999999999999, -321.69999999999993, -329.5, -55.29999999999999, 20.000000000000014, -132.1, -389.4999999999999, 20.30000000000001, -196.6, -291.39999999999986, 20.000000000000014], "policy_predator_policy_reward": [39.0, 88.0, 78.0, 63.0, 38.0, 19.0, 44.0, 35.0, 141.0, 163.0, 13.0, 6.0, 23.0, 12.0, 57.0, 48.0, 51.0, 42.0, 19.0, 20.0, 19.0, 3.0, 103.0, 104.0, 47.0, 43.0, 52.0, 28.0, 29.0, 16.0, 26.0, 58.0, 86.0, 101.0, 72.0, 77.0, 21.0, 51.0, 86.0, 128.0, 34.0, 70.0, 21.0, 78.0, 24.0, 68.0, 117.0, 76.0, 61.0, 40.0, 54.0, 80.0, 86.0, 106.0, 95.0, 62.0, 12.0, 2.0, 35.0, 95.0, 22.0, 33.0, 16.0, 62.0, 91.0, 57.0, 4.0, 20.0, 18.0, 118.0, 38.0, 17.0, 44.0, 19.0, 46.0, 77.0, 32.0, 50.0, 13.0, 20.0, 87.0, 106.0, 91.0, 53.0, 72.0, 52.0, 181.0, 60.0, 23.0, 83.0, 76.0, 32.0, 35.0, 32.0, 63.0, 54.0, 45.0, 62.0, 113.0, 120.0, 147.0, 92.0, 10.0, 45.0, 99.0, 159.0, 17.0, 17.0, 73.0, 83.0, 61.0, 149.0, 125.0, 32.0, 3.0, 16.0, 61.0, 12.0, 72.0, 20.0, 141.0, 88.0, 145.0, 111.0, 132.0, 134.0, 181.0, 140.0, 76.0, 105.0, 137.0, 167.0, 45.0, 0.0, 97.0, 163.0, 23.0, 90.0, 153.0, 168.0, 175.0, 173.0, 153.0, 77.0, 160.0, 148.0, 73.0, 98.0, 51.0, 110.0, 151.0, 110.0, 39.0, 54.0, 123.0, 168.0, 110.0, 113.0, 106.0, 147.0, 87.0, 155.0, 50.0, 43.0, 160.0, 86.0, 40.0, 77.0, 32.0, 94.0, 11.0, 41.0, 121.0, 103.0, 94.0, 169.0, 16.0, 131.0, 4.0, 2.0, 31.0, 1.0, 112.0, 75.0, 104.0, 172.0, 175.0, 132.0, 124.0, 183.0, 192.0, 98.0, 61.0, 30.0, 180.0, 174.0, 122.0, 44.0, 146.0, 83.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5455262342839101, "mean_inference_ms": 1.4047235596162075, "mean_action_processing_ms": 0.22564756793544188, "mean_env_wait_ms": 0.18380683818918775, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008442878723144531, "StateBufferConnector_ms": 0.0032444000244140625, "ViewRequirementAgentConnector_ms": 0.1153113842010498}, "num_episodes": 23, "episode_return_max": 319.10000000000025, "episode_return_min": -361.19999999999993, "episode_return_mean": 17.89299999999989, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 427.9117499554355, "num_env_steps_trained_throughput_per_sec": 427.9117499554355, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 9703.681, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9703.633, "sample_time_ms": 1198.102, "learn_time_ms": 8490.707, "learn_throughput": 471.103, "synch_weights_time_ms": 12.872}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-27-40", "timestamp": 1723645660, "time_this_iter_s": 9.352102994918823, "time_total_s": 180.95209956169128, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b098e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 180.95209956169128, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 26.7, "ram_util_percent": 83.15714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8263597729660215, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 6.000756620477747, "policy_loss": -0.006244847923024464, "vf_loss": 6.004232268358664, "vf_explained_var": -0.2771036850712287, "kl": 0.00923066847132428, "entropy": 1.4959619537863151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9988390423633433, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.369239348961562, "policy_loss": -0.011428178464698176, "vf_loss": 8.377922689094746, "vf_explained_var": 0.01993670633860997, "kl": 0.013724164862166075, "entropy": 1.4122185172227324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 265.5999999999999, "episode_reward_min": -361.19999999999993, "episode_reward_mean": -24.1020000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.09999999999994, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -97.32100000000003, "predator_policy": 85.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [67.00000000000013, -41.4999999999998, 244.49999999999997, 81.39999999999979, 135.29999999999964, -94.00000000000001, 177.89999999999992, 120.89999999999978, 31.300000000000004, 183.7999999999997, 153.59999999999917, 163.69999999999993, 74.89999999999966, 41.20000000000014, 45.200000000000145, 166.29999999999944, 9.5, 232.09999999999985, 105.09999999999994, 125.49999999999957, 189.49999999999974, 265.5999999999999, -153.10000000000042, 180.99999999999991, 38.899999999999814, -315.09999999999957, -10.299999999999878, 46.90000000000007, 69.20000000000019, 187.59999999999988, 90.59999999999984, 34.50000000000007, -237.5999999999993, 145.3999999999993, -202.40000000000018, 255.19999999999982, 66.39999999999941, -139.4, -84.40000000000056, 20.900000000000016, 72.19999999999999, 33.90000000000017, -74.80000000000018, -88.59999999999997, -193.2000000000001, -221.60000000000005, 11.300000000000058, -261.1000000000002, -83.00000000000182, -98.10000000000008, -5.999999999999778, -145.10000000000085, -151.10000000000002, -71.40000000000003, -287.70000000000005, -49.09999999999999, 103.1999999999999, -160.1, 14.500000000000174, -225.80000000000015, -98.20000000000061, -135.7000000000001, -262.4999999999994, 67.60000000000007, -105.80000000000013, 93.69999999999959, -25.699999999999942, 115.69999999999982, -104.4000000000002, -83.1, -45.799999999999834, 33.400000000000205, 6.900000000000121, -71.19999999999985, -245.0, -49.299999999999756, -151.60000000000016, -361.19999999999993, 55.69999999999998, -167.60000000000002, -10.299999999999926, -42.39999999999972, -173.60000000000065, -55.59999999999987, -85.70000000000002, 24.200000000000188, -83.90000000000092, -92.50000000000009, -60.49999999999978, -3.499999999999919, -3.5999999999999126, -6.099999999999682, -23.899999999999967, -261.5, -46.999999999999964, -73.90000000000045, -200.00000000000009, -138.70000000000027, -117.40000000000074, -11.699999999999605], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -24.999999999999922, -160.59999999999997, -94.8999999999999, -37.599999999999994, 178.09999999999994, -44.50000000000014, 26.900000000000006, -35.799999999999976, 79.09999999999985, -148.6, -138.4000000000001, 41.89999999999999, 35.00000000000001, -53.500000000000064, 40.40000000000003, 11.0, -171.70000000000005, -114.40000000000015, 141.19999999999982, 142.69999999999982, -3.099999999999958, -49.6, 83.3, -0.099999999999973, 20.000000000000014, 7.399999999999965, -44.19999999999998, 20.000000000000014, -122.80000000000018, 164.29999999999998, -21.999999999999744, -56.49999999999999, -70.00000000000013, 95.6, 81.5, 20.000000000000014, 22.10000000000006, -24.099999999999945, 26.59999999999995, -18.100000000000122, 125.59999999999985, 79.39999999999996, 153.19999999999996, -124.00000000000028, -222.10000000000016, -100.00000000000011, 137.0, -86.20000000000002, 1.099999999999993, -269.8, -286.29999999999984, 17.899999999999988, -134.20000000000005, -83.80000000000004, 22.700000000000053, 20.000000000000014, -17.799999999999926, 104.29999999999995, -33.69999999999998, -70.00000000000017, 53.60000000000003, -226.9, 28.400000000000055, -243.99999999999986, -232.59999999999988, 135.49999999999986, -45.09999999999976, -237.7000000000001, -222.70000000000007, 127.69999999999979, 93.49999999999991, -88.60000000000004, -0.9999999999999992, -156.70000000000002, -192.70000000000013, -236.20000000000013, -5.1999999999999265, -13.599999999999783, 15.499999999999963, 65.29999999999987, -66.1000000000009, 3.1999999999999615, -61.30000000000001, -43.000000000000014, -260.79999999999967, -305.80000000000007, -38.799999999999756, -222.40000000000003, -236.80000000000007, -330.40000000000003, -212.20000000000002, -54.40000000000003, -115.30000000000001, -238.60000000000014, -326.4999999999998, -53.50000000000019, -74.50000000000088, -42.10000000000002, -316.0, -124.30000000000015, 5.299999999999965, -133.9000000000007, -332.19999999999976, -322.6, -176.50000000000003, -63.999999999999964, -237.4000000000002, -306.69999999999993, -289.0, -76.9, -143.2, -10.900000000000006, -46.899999999999984, -192.1, -229.00000000000009, -79.6000000000002, 1.0999999999999865, -260.19999999999976, -256.6000000000001, 1.0999999999999865, -322.30000000000007, -137.20000000000027, -251.50000000000003, -238.60000000000014, -265.89999999999986, -55.600000000000264, 30.20000000000001, -252.4000000000001, -99.40000000000003, 9.200000000000017, -32.49999999999975, -39.39999999999999, -112.30000000000078, -0.9999999999999846, 64.70000000000003, -138.10000000000005, -190.30000000000015, -44.19999999999999, -301.90000000000003, 20.000000000000014, -212.80000000000007, 20.000000000000014, 7.399999999999965, 20.000000000000014, -45.09999999999976, -242.50000000000006, -15.699999999999747, -264.1, -256.9, -332.20000000000005, -24.099999999999746, -122.50000000000014, -336.0999999999999, -321.69999999999993, -329.5, -55.29999999999999, 20.000000000000014, -132.1, -389.4999999999999, 20.30000000000001, -196.6, -291.39999999999986, 20.000000000000014, -287.20000000000005, -162.4000000000006, 17.899999999999988, -281.5, -249.10000000000005, -121.6, -33.69999999999996, -3.0999999999999757, -9.399999999999855, -233.5000000000003, -15.699999999999747, -236.79999999999998, -333.70000000000005, 3.1999999999999633, 20.000000000000014, -194.50000000000003, -0.9999999999999917, -106.60000000000008, -11.499999999999826, -34.59999999999976, -3.0999999999999943, -236.80000000000007, -243.10000000000005, -357.39999999999986, 8.000000000000004, -253.00000000000003, -373.9000000000001, 20.000000000000014, -238.30000000000004, -315.6999999999999, -161.20000000000007, -257.5000000000001, -308.79999999999984, 7.399999999999965, -78.70000000000087, 20.000000000000014], "policy_predator_policy_reward": [21.0, 51.0, 86.0, 128.0, 34.0, 70.0, 21.0, 78.0, 24.0, 68.0, 117.0, 76.0, 61.0, 40.0, 54.0, 80.0, 86.0, 106.0, 95.0, 62.0, 12.0, 2.0, 35.0, 95.0, 22.0, 33.0, 16.0, 62.0, 91.0, 57.0, 4.0, 20.0, 18.0, 118.0, 38.0, 17.0, 44.0, 19.0, 46.0, 77.0, 32.0, 50.0, 13.0, 20.0, 87.0, 106.0, 91.0, 53.0, 72.0, 52.0, 181.0, 60.0, 23.0, 83.0, 76.0, 32.0, 35.0, 32.0, 63.0, 54.0, 45.0, 62.0, 113.0, 120.0, 147.0, 92.0, 10.0, 45.0, 99.0, 159.0, 17.0, 17.0, 73.0, 83.0, 61.0, 149.0, 125.0, 32.0, 3.0, 16.0, 61.0, 12.0, 72.0, 20.0, 141.0, 88.0, 145.0, 111.0, 132.0, 134.0, 181.0, 140.0, 76.0, 105.0, 137.0, 167.0, 45.0, 0.0, 97.0, 163.0, 23.0, 90.0, 153.0, 168.0, 175.0, 173.0, 153.0, 77.0, 160.0, 148.0, 73.0, 98.0, 51.0, 110.0, 151.0, 110.0, 39.0, 54.0, 123.0, 168.0, 110.0, 113.0, 106.0, 147.0, 87.0, 155.0, 50.0, 43.0, 160.0, 86.0, 40.0, 77.0, 32.0, 94.0, 11.0, 41.0, 121.0, 103.0, 94.0, 169.0, 16.0, 131.0, 4.0, 2.0, 31.0, 1.0, 112.0, 75.0, 104.0, 172.0, 175.0, 132.0, 124.0, 183.0, 192.0, 98.0, 61.0, 30.0, 180.0, 174.0, 122.0, 44.0, 146.0, 83.0, 116.0, 160.0, 55.0, 153.0, 138.0, 147.0, 50.0, 11.0, 117.0, 42.0, 139.0, 21.0, 147.0, 123.0, 100.0, 71.0, 40.0, 64.0, 28.0, 12.0, 138.0, 78.0, 154.0, 185.0, 31.0, 167.0, 104.0, 176.0, 180.0, 174.0, 138.0, 142.0, 66.0, 118.0, 47.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5471202106966857, "mean_inference_ms": 1.4088921402263452, "mean_action_processing_ms": 0.2261741523670195, "mean_env_wait_ms": 0.18414267640388712, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008099794387817383, "StateBufferConnector_ms": 0.003163456916809082, "ViewRequirementAgentConnector_ms": 0.10274171829223633}, "num_episodes": 18, "episode_return_max": 265.5999999999999, "episode_return_min": -361.19999999999993, "episode_return_mean": -24.1020000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 424.22696459792286, "num_env_steps_trained_throughput_per_sec": 424.22696459792286, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 9705.154, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9705.106, "sample_time_ms": 1194.747, "learn_time_ms": 8495.498, "learn_throughput": 470.838, "synch_weights_time_ms": 12.867}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-27-49", "timestamp": 1723645669, "time_this_iter_s": 9.432538986206055, "time_total_s": 190.38463854789734, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 190.38463854789734, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 29.469230769230776, "ram_util_percent": 83.06923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.258914636083381, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 4.161427655926457, "policy_loss": -0.008725923445770547, "vf_loss": 4.167645174611813, "vf_explained_var": -0.21625706875135028, "kl": 0.008361345125558585, "entropy": 1.5006425920617643, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.546702495643071, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.455690056937081, "policy_loss": -0.009396252354173355, "vf_loss": 7.462630348861532, "vf_explained_var": -0.005132914787877804, "kl": 0.01227975390877374, "entropy": 1.398699874032742, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 265.5999999999999, "episode_reward_min": -361.19999999999993, "episode_reward_mean": -44.97300000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 153.19999999999996, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -110.38150000000002, "predator_policy": 87.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [105.09999999999994, 125.49999999999957, 189.49999999999974, 265.5999999999999, -153.10000000000042, 180.99999999999991, 38.899999999999814, -315.09999999999957, -10.299999999999878, 46.90000000000007, 69.20000000000019, 187.59999999999988, 90.59999999999984, 34.50000000000007, -237.5999999999993, 145.3999999999993, -202.40000000000018, 255.19999999999982, 66.39999999999941, -139.4, -84.40000000000056, 20.900000000000016, 72.19999999999999, 33.90000000000017, -74.80000000000018, -88.59999999999997, -193.2000000000001, -221.60000000000005, 11.300000000000058, -261.1000000000002, -83.00000000000182, -98.10000000000008, -5.999999999999778, -145.10000000000085, -151.10000000000002, -71.40000000000003, -287.70000000000005, -49.09999999999999, 103.1999999999999, -160.1, 14.500000000000174, -225.80000000000015, -98.20000000000061, -135.7000000000001, -262.4999999999994, 67.60000000000007, -105.80000000000013, 93.69999999999959, -25.699999999999942, 115.69999999999982, -104.4000000000002, -83.1, -45.799999999999834, 33.400000000000205, 6.900000000000121, -71.19999999999985, -245.0, -49.299999999999756, -151.60000000000016, -361.19999999999993, 55.69999999999998, -167.60000000000002, -10.299999999999926, -42.39999999999972, -173.60000000000065, -55.59999999999987, -85.70000000000002, 24.200000000000188, -83.90000000000092, -92.50000000000009, -60.49999999999978, -3.499999999999919, -3.5999999999999126, -6.099999999999682, -23.899999999999967, -261.5, -46.999999999999964, -73.90000000000045, -200.00000000000009, -138.70000000000027, -117.40000000000074, -11.699999999999605, 38.10000000000027, -4.39999999999967, 8.60000000000006, -25.49999999999968, 14.800000000000008, -108.70000000000049, -111.00000000000057, 45.20000000000013, -304.1999999999986, -35.80000000000054, -3.999999999999703, 47.00000000000035, 143.89999999999964, 10.30000000000006, 17.700000000000188, -67.20000000000039, 22.50000000000004, 18.700000000000244], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 22.10000000000006, -24.099999999999945, 26.59999999999995, -18.100000000000122, 125.59999999999985, 79.39999999999996, 153.19999999999996, -124.00000000000028, -222.10000000000016, -100.00000000000011, 137.0, -86.20000000000002, 1.099999999999993, -269.8, -286.29999999999984, 17.899999999999988, -134.20000000000005, -83.80000000000004, 22.700000000000053, 20.000000000000014, -17.799999999999926, 104.29999999999995, -33.69999999999998, -70.00000000000017, 53.60000000000003, -226.9, 28.400000000000055, -243.99999999999986, -232.59999999999988, 135.49999999999986, -45.09999999999976, -237.7000000000001, -222.70000000000007, 127.69999999999979, 93.49999999999991, -88.60000000000004, -0.9999999999999992, -156.70000000000002, -192.70000000000013, -236.20000000000013, -5.1999999999999265, -13.599999999999783, 15.499999999999963, 65.29999999999987, -66.1000000000009, 3.1999999999999615, -61.30000000000001, -43.000000000000014, -260.79999999999967, -305.80000000000007, -38.799999999999756, -222.40000000000003, -236.80000000000007, -330.40000000000003, -212.20000000000002, -54.40000000000003, -115.30000000000001, -238.60000000000014, -326.4999999999998, -53.50000000000019, -74.50000000000088, -42.10000000000002, -316.0, -124.30000000000015, 5.299999999999965, -133.9000000000007, -332.19999999999976, -322.6, -176.50000000000003, -63.999999999999964, -237.4000000000002, -306.69999999999993, -289.0, -76.9, -143.2, -10.900000000000006, -46.899999999999984, -192.1, -229.00000000000009, -79.6000000000002, 1.0999999999999865, -260.19999999999976, -256.6000000000001, 1.0999999999999865, -322.30000000000007, -137.20000000000027, -251.50000000000003, -238.60000000000014, -265.89999999999986, -55.600000000000264, 30.20000000000001, -252.4000000000001, -99.40000000000003, 9.200000000000017, -32.49999999999975, -39.39999999999999, -112.30000000000078, -0.9999999999999846, 64.70000000000003, -138.10000000000005, -190.30000000000015, -44.19999999999999, -301.90000000000003, 20.000000000000014, -212.80000000000007, 20.000000000000014, 7.399999999999965, 20.000000000000014, -45.09999999999976, -242.50000000000006, -15.699999999999747, -264.1, -256.9, -332.20000000000005, -24.099999999999746, -122.50000000000014, -336.0999999999999, -321.69999999999993, -329.5, -55.29999999999999, 20.000000000000014, -132.1, -389.4999999999999, 20.30000000000001, -196.6, -291.39999999999986, 20.000000000000014, -287.20000000000005, -162.4000000000006, 17.899999999999988, -281.5, -249.10000000000005, -121.6, -33.69999999999996, -3.0999999999999757, -9.399999999999855, -233.5000000000003, -15.699999999999747, -236.79999999999998, -333.70000000000005, 3.1999999999999633, 20.000000000000014, -194.50000000000003, -0.9999999999999917, -106.60000000000008, -11.499999999999826, -34.59999999999976, -3.0999999999999943, -236.80000000000007, -243.10000000000005, -357.39999999999986, 8.000000000000004, -253.00000000000003, -373.9000000000001, 20.000000000000014, -238.30000000000004, -315.6999999999999, -161.20000000000007, -257.5000000000001, -308.79999999999984, 7.399999999999965, -78.70000000000087, 20.000000000000014, -19.899999999999743, 20.000000000000014, -109.89999999999992, -53.50000000000019, -151.30000000000007, -3.099999999999972, 3.1999999999999615, -255.69999999999982, -19.899999999999743, 13.699999999999964, -253.0000000000002, -15.699999999999747, -170.20000000000056, -251.8, 20.000000000000014, -77.80000000000011, -386.8, -231.40000000000038, -24.099999999999746, -150.70000000000024, -42.99999999999976, -0.9999999999999881, -9.999999999999895, 20.000000000000014, 65.00000000000003, -21.099999999999973, -26.199999999999754, 9.499999999999964, -230.5, 3.1999999999999615, -5.1999999999999265, -298.00000000000017, -21.999999999999794, -32.49999999999975, -45.09999999999976, -62.200000000000074], "policy_predator_policy_reward": [44.0, 19.0, 46.0, 77.0, 32.0, 50.0, 13.0, 20.0, 87.0, 106.0, 91.0, 53.0, 72.0, 52.0, 181.0, 60.0, 23.0, 83.0, 76.0, 32.0, 35.0, 32.0, 63.0, 54.0, 45.0, 62.0, 113.0, 120.0, 147.0, 92.0, 10.0, 45.0, 99.0, 159.0, 17.0, 17.0, 73.0, 83.0, 61.0, 149.0, 125.0, 32.0, 3.0, 16.0, 61.0, 12.0, 72.0, 20.0, 141.0, 88.0, 145.0, 111.0, 132.0, 134.0, 181.0, 140.0, 76.0, 105.0, 137.0, 167.0, 45.0, 0.0, 97.0, 163.0, 23.0, 90.0, 153.0, 168.0, 175.0, 173.0, 153.0, 77.0, 160.0, 148.0, 73.0, 98.0, 51.0, 110.0, 151.0, 110.0, 39.0, 54.0, 123.0, 168.0, 110.0, 113.0, 106.0, 147.0, 87.0, 155.0, 50.0, 43.0, 160.0, 86.0, 40.0, 77.0, 32.0, 94.0, 11.0, 41.0, 121.0, 103.0, 94.0, 169.0, 16.0, 131.0, 4.0, 2.0, 31.0, 1.0, 112.0, 75.0, 104.0, 172.0, 175.0, 132.0, 124.0, 183.0, 192.0, 98.0, 61.0, 30.0, 180.0, 174.0, 122.0, 44.0, 146.0, 83.0, 116.0, 160.0, 55.0, 153.0, 138.0, 147.0, 50.0, 11.0, 117.0, 42.0, 139.0, 21.0, 147.0, 123.0, 100.0, 71.0, 40.0, 64.0, 28.0, 12.0, 138.0, 78.0, 154.0, 185.0, 31.0, 167.0, 104.0, 176.0, 180.0, 174.0, 138.0, 142.0, 66.0, 118.0, 47.0, 0.0, 19.0, 19.0, 86.0, 73.0, 95.0, 68.0, 141.0, 86.0, 19.0, 2.0, 136.0, 24.0, 155.0, 156.0, 38.0, 65.0, 190.0, 124.0, 36.0, 103.0, 30.0, 10.0, 18.0, 19.0, 70.0, 30.0, 2.0, 25.0, 127.0, 118.0, 144.0, 92.0, 39.0, 38.0, 76.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5481201301920013, "mean_inference_ms": 1.411403245499826, "mean_action_processing_ms": 0.22644439446577314, "mean_env_wait_ms": 0.18421305062282825, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007981419563293457, "StateBufferConnector_ms": 0.0029529333114624023, "ViewRequirementAgentConnector_ms": 0.09893357753753662}, "num_episodes": 18, "episode_return_max": 265.5999999999999, "episode_return_min": -361.19999999999993, "episode_return_mean": -44.97300000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 424.9028835761587, "num_env_steps_trained_throughput_per_sec": 424.9028835761587, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 9725.0, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9724.953, "sample_time_ms": 1202.447, "learn_time_ms": 8507.621, "learn_throughput": 470.167, "synch_weights_time_ms": 12.894}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-27-59", "timestamp": 1723645679, "time_this_iter_s": 9.420529842376709, "time_total_s": 199.80516839027405, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 199.80516839027405, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 27.015384615384612, "ram_util_percent": 83.4076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.24098982211774, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 4.8387828483783375, "policy_loss": -0.011763692679494698, "vf_loss": 4.846173368812238, "vf_explained_var": -0.1336563808262033, "kl": 0.014577244687006006, "entropy": 1.4934354396093459, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6680240515678646, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.599365883529502, "policy_loss": -0.007021423724662296, "vf_loss": 6.604229423230287, "vf_explained_var": 0.02368432923599526, "kl": 0.010789410636710661, "entropy": 1.4377177525449683, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 143.89999999999964, "episode_reward_min": -361.19999999999993, "episode_reward_mean": -55.17800000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 65.29999999999987, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -114.78400000000003, "predator_policy": 87.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.39999999999941, -139.4, -84.40000000000056, 20.900000000000016, 72.19999999999999, 33.90000000000017, -74.80000000000018, -88.59999999999997, -193.2000000000001, -221.60000000000005, 11.300000000000058, -261.1000000000002, -83.00000000000182, -98.10000000000008, -5.999999999999778, -145.10000000000085, -151.10000000000002, -71.40000000000003, -287.70000000000005, -49.09999999999999, 103.1999999999999, -160.1, 14.500000000000174, -225.80000000000015, -98.20000000000061, -135.7000000000001, -262.4999999999994, 67.60000000000007, -105.80000000000013, 93.69999999999959, -25.699999999999942, 115.69999999999982, -104.4000000000002, -83.1, -45.799999999999834, 33.400000000000205, 6.900000000000121, -71.19999999999985, -245.0, -49.299999999999756, -151.60000000000016, -361.19999999999993, 55.69999999999998, -167.60000000000002, -10.299999999999926, -42.39999999999972, -173.60000000000065, -55.59999999999987, -85.70000000000002, 24.200000000000188, -83.90000000000092, -92.50000000000009, -60.49999999999978, -3.499999999999919, -3.5999999999999126, -6.099999999999682, -23.899999999999967, -261.5, -46.999999999999964, -73.90000000000045, -200.00000000000009, -138.70000000000027, -117.40000000000074, -11.699999999999605, 38.10000000000027, -4.39999999999967, 8.60000000000006, -25.49999999999968, 14.800000000000008, -108.70000000000049, -111.00000000000057, 45.20000000000013, -304.1999999999986, -35.80000000000054, -3.999999999999703, 47.00000000000035, 143.89999999999964, 10.30000000000006, 17.700000000000188, -67.20000000000039, 22.50000000000004, 18.700000000000244, 18.89999999999999, -24.299999999999784, 17.999999999999982, 5.500000000000169, 34.50000000000022, 87.39999999999964, 80.79999999999973, -37.30000000000026, -94.90000000000049, 33.0000000000002, -2.199999999999918, -117.5000000000004, -17.09999999999968, 28.800000000000157, -65.50000000000037, -166.10000000000056, -5.199999999999756, 19.199999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-88.60000000000004, -0.9999999999999992, -156.70000000000002, -192.70000000000013, -236.20000000000013, -5.1999999999999265, -13.599999999999783, 15.499999999999963, 65.29999999999987, -66.1000000000009, 3.1999999999999615, -61.30000000000001, -43.000000000000014, -260.79999999999967, -305.80000000000007, -38.799999999999756, -222.40000000000003, -236.80000000000007, -330.40000000000003, -212.20000000000002, -54.40000000000003, -115.30000000000001, -238.60000000000014, -326.4999999999998, -53.50000000000019, -74.50000000000088, -42.10000000000002, -316.0, -124.30000000000015, 5.299999999999965, -133.9000000000007, -332.19999999999976, -322.6, -176.50000000000003, -63.999999999999964, -237.4000000000002, -306.69999999999993, -289.0, -76.9, -143.2, -10.900000000000006, -46.899999999999984, -192.1, -229.00000000000009, -79.6000000000002, 1.0999999999999865, -260.19999999999976, -256.6000000000001, 1.0999999999999865, -322.30000000000007, -137.20000000000027, -251.50000000000003, -238.60000000000014, -265.89999999999986, -55.600000000000264, 30.20000000000001, -252.4000000000001, -99.40000000000003, 9.200000000000017, -32.49999999999975, -39.39999999999999, -112.30000000000078, -0.9999999999999846, 64.70000000000003, -138.10000000000005, -190.30000000000015, -44.19999999999999, -301.90000000000003, 20.000000000000014, -212.80000000000007, 20.000000000000014, 7.399999999999965, 20.000000000000014, -45.09999999999976, -242.50000000000006, -15.699999999999747, -264.1, -256.9, -332.20000000000005, -24.099999999999746, -122.50000000000014, -336.0999999999999, -321.69999999999993, -329.5, -55.29999999999999, 20.000000000000014, -132.1, -389.4999999999999, 20.30000000000001, -196.6, -291.39999999999986, 20.000000000000014, -287.20000000000005, -162.4000000000006, 17.899999999999988, -281.5, -249.10000000000005, -121.6, -33.69999999999996, -3.0999999999999757, -9.399999999999855, -233.5000000000003, -15.699999999999747, -236.79999999999998, -333.70000000000005, 3.1999999999999633, 20.000000000000014, -194.50000000000003, -0.9999999999999917, -106.60000000000008, -11.499999999999826, -34.59999999999976, -3.0999999999999943, -236.80000000000007, -243.10000000000005, -357.39999999999986, 8.000000000000004, -253.00000000000003, -373.9000000000001, 20.000000000000014, -238.30000000000004, -315.6999999999999, -161.20000000000007, -257.5000000000001, -308.79999999999984, 7.399999999999965, -78.70000000000087, 20.000000000000014, -19.899999999999743, 20.000000000000014, -109.89999999999992, -53.50000000000019, -151.30000000000007, -3.099999999999972, 3.1999999999999615, -255.69999999999982, -19.899999999999743, 13.699999999999964, -253.0000000000002, -15.699999999999747, -170.20000000000056, -251.8, 20.000000000000014, -77.80000000000011, -386.8, -231.40000000000038, -24.099999999999746, -150.70000000000024, -42.99999999999976, -0.9999999999999881, -9.999999999999895, 20.000000000000014, 65.00000000000003, -21.099999999999973, -26.199999999999754, 9.499999999999964, -230.5, 3.1999999999999615, -5.1999999999999265, -298.00000000000017, -21.999999999999794, -32.49999999999975, -45.09999999999976, -62.200000000000074, -32.7999999999998, 13.699999999999964, -202.30000000000027, -85.00000000000063, 13.699999999999964, -15.699999999999747, -34.59999999999975, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 18.200000000000024, 12.200000000000042, 7.100000000000042, 4.7, -51.099999999999916, -89.20000000000067, -248.2000000000001, -84.70000000000059, -17.79999999999974, -20.199999999999775, -107.20000000000066, -0.9999999999999846, -88.60000000000022, -250.89999999999986, -181.60000000000036, 9.499999999999964, -42.9999999999998, -50.19999999999992, -261.69999999999993, -80.80000000000035, -75.1, -355.0, -60.100000000000456, -24.099999999999746, 20.000000000000014, -59.80000000000061], "policy_predator_policy_reward": [73.0, 83.0, 61.0, 149.0, 125.0, 32.0, 3.0, 16.0, 61.0, 12.0, 72.0, 20.0, 141.0, 88.0, 145.0, 111.0, 132.0, 134.0, 181.0, 140.0, 76.0, 105.0, 137.0, 167.0, 45.0, 0.0, 97.0, 163.0, 23.0, 90.0, 153.0, 168.0, 175.0, 173.0, 153.0, 77.0, 160.0, 148.0, 73.0, 98.0, 51.0, 110.0, 151.0, 110.0, 39.0, 54.0, 123.0, 168.0, 110.0, 113.0, 106.0, 147.0, 87.0, 155.0, 50.0, 43.0, 160.0, 86.0, 40.0, 77.0, 32.0, 94.0, 11.0, 41.0, 121.0, 103.0, 94.0, 169.0, 16.0, 131.0, 4.0, 2.0, 31.0, 1.0, 112.0, 75.0, 104.0, 172.0, 175.0, 132.0, 124.0, 183.0, 192.0, 98.0, 61.0, 30.0, 180.0, 174.0, 122.0, 44.0, 146.0, 83.0, 116.0, 160.0, 55.0, 153.0, 138.0, 147.0, 50.0, 11.0, 117.0, 42.0, 139.0, 21.0, 147.0, 123.0, 100.0, 71.0, 40.0, 64.0, 28.0, 12.0, 138.0, 78.0, 154.0, 185.0, 31.0, 167.0, 104.0, 176.0, 180.0, 174.0, 138.0, 142.0, 66.0, 118.0, 47.0, 0.0, 19.0, 19.0, 86.0, 73.0, 95.0, 68.0, 141.0, 86.0, 19.0, 2.0, 136.0, 24.0, 155.0, 156.0, 38.0, 65.0, 190.0, 124.0, 36.0, 103.0, 30.0, 10.0, 18.0, 19.0, 70.0, 30.0, 2.0, 25.0, 127.0, 118.0, 144.0, 92.0, 39.0, 38.0, 76.0, 50.0, 0.0, 38.0, 133.0, 130.0, 17.0, 3.0, 26.0, 13.0, 0.0, 5.0, 25.0, 32.0, 30.0, 39.0, 58.0, 45.0, 146.0, 92.0, 34.0, 37.0, 35.0, 71.0, 102.0, 120.0, 92.0, 63.0, 64.0, 58.0, 142.0, 135.0, 170.0, 94.0, 31.0, 48.0, 22.0, 37.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5464767812062121, "mean_inference_ms": 1.4068081039318503, "mean_action_processing_ms": 0.22581289036617774, "mean_env_wait_ms": 0.18346051616373885, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037039518356323242, "StateBufferConnector_ms": 0.0028482675552368164, "ViewRequirementAgentConnector_ms": 0.0886542797088623}, "num_episodes": 18, "episode_return_max": 143.89999999999964, "episode_return_min": -361.19999999999993, "episode_return_mean": -55.17800000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 421.5601005499734, "num_env_steps_trained_throughput_per_sec": 421.5601005499734, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 9719.755, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9719.706, "sample_time_ms": 1187.283, "learn_time_ms": 8517.573, "learn_throughput": 469.617, "synch_weights_time_ms": 12.888}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-28-08", "timestamp": 1723645688, "time_this_iter_s": 9.491931915283203, "time_total_s": 209.29710030555725, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b08b9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 209.29710030555725, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 27.55714285714286, "ram_util_percent": 83.13571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9002732551917827, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.176652087042571, "policy_loss": -0.008424238928978051, "vf_loss": 3.1829371445393435, "vf_explained_var": -0.10779224296726247, "kl": 0.007130609705681509, "entropy": 1.503552438973119, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.67382485412416, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.036678641813773, "policy_loss": -0.011982970571923981, "vf_loss": 4.0455805511070935, "vf_explained_var": 0.04676609297908803, "kl": 0.015405241879750578, "entropy": 1.4430039418437492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 143.89999999999964, "episode_reward_min": -361.19999999999993, "episode_reward_mean": -31.065999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.4999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 96.19999999999992, "predator_policy": 192.0}, "policy_reward_mean": {"prey_policy": -86.68300000000004, "predator_policy": 71.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [67.60000000000007, -105.80000000000013, 93.69999999999959, -25.699999999999942, 115.69999999999982, -104.4000000000002, -83.1, -45.799999999999834, 33.400000000000205, 6.900000000000121, -71.19999999999985, -245.0, -49.299999999999756, -151.60000000000016, -361.19999999999993, 55.69999999999998, -167.60000000000002, -10.299999999999926, -42.39999999999972, -173.60000000000065, -55.59999999999987, -85.70000000000002, 24.200000000000188, -83.90000000000092, -92.50000000000009, -60.49999999999978, -3.499999999999919, -3.5999999999999126, -6.099999999999682, -23.899999999999967, -261.5, -46.999999999999964, -73.90000000000045, -200.00000000000009, -138.70000000000027, -117.40000000000074, -11.699999999999605, 38.10000000000027, -4.39999999999967, 8.60000000000006, -25.49999999999968, 14.800000000000008, -108.70000000000049, -111.00000000000057, 45.20000000000013, -304.1999999999986, -35.80000000000054, -3.999999999999703, 47.00000000000035, 143.89999999999964, 10.30000000000006, 17.700000000000188, -67.20000000000039, 22.50000000000004, 18.700000000000244, 18.89999999999999, -24.299999999999784, 17.999999999999982, 5.500000000000169, 34.50000000000022, 87.39999999999964, 80.79999999999973, -37.30000000000026, -94.90000000000049, 33.0000000000002, -2.199999999999918, -117.5000000000004, -17.09999999999968, 28.800000000000157, -65.50000000000037, -166.10000000000056, -5.199999999999756, 19.199999999999974, 10.800000000000068, 5.800000000000022, 6.500000000000059, -79.70000000000019, -141.00000000000068, 53.20000000000048, 54.40000000000011, -7.299999999999677, -18.899999999999785, 29.600000000000172, -47.99999999999971, 5.792588630981754e-14, 0.5000000000003498, -9.799999999999775, -30.39999999999951, 36.60000000000025, 31.200000000000166, 5.999999999999911, -47.69999999999986, 2.200000000000106, 26.7000000000001, -13.59999999999969, -14.399999999999816, 0.4000000000002427, 17.59999999999998, 18.199999999999964, 7.799999999999969], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-55.600000000000264, 30.20000000000001, -252.4000000000001, -99.40000000000003, 9.200000000000017, -32.49999999999975, -39.39999999999999, -112.30000000000078, -0.9999999999999846, 64.70000000000003, -138.10000000000005, -190.30000000000015, -44.19999999999999, -301.90000000000003, 20.000000000000014, -212.80000000000007, 20.000000000000014, 7.399999999999965, 20.000000000000014, -45.09999999999976, -242.50000000000006, -15.699999999999747, -264.1, -256.9, -332.20000000000005, -24.099999999999746, -122.50000000000014, -336.0999999999999, -321.69999999999993, -329.5, -55.29999999999999, 20.000000000000014, -132.1, -389.4999999999999, 20.30000000000001, -196.6, -291.39999999999986, 20.000000000000014, -287.20000000000005, -162.4000000000006, 17.899999999999988, -281.5, -249.10000000000005, -121.6, -33.69999999999996, -3.0999999999999757, -9.399999999999855, -233.5000000000003, -15.699999999999747, -236.79999999999998, -333.70000000000005, 3.1999999999999633, 20.000000000000014, -194.50000000000003, -0.9999999999999917, -106.60000000000008, -11.499999999999826, -34.59999999999976, -3.0999999999999943, -236.80000000000007, -243.10000000000005, -357.39999999999986, 8.000000000000004, -253.00000000000003, -373.9000000000001, 20.000000000000014, -238.30000000000004, -315.6999999999999, -161.20000000000007, -257.5000000000001, -308.79999999999984, 7.399999999999965, -78.70000000000087, 20.000000000000014, -19.899999999999743, 20.000000000000014, -109.89999999999992, -53.50000000000019, -151.30000000000007, -3.099999999999972, 3.1999999999999615, -255.69999999999982, -19.899999999999743, 13.699999999999964, -253.0000000000002, -15.699999999999747, -170.20000000000056, -251.8, 20.000000000000014, -77.80000000000011, -386.8, -231.40000000000038, -24.099999999999746, -150.70000000000024, -42.99999999999976, -0.9999999999999881, -9.999999999999895, 20.000000000000014, 65.00000000000003, -21.099999999999973, -26.199999999999754, 9.499999999999964, -230.5, 3.1999999999999615, -5.1999999999999265, -298.00000000000017, -21.999999999999794, -32.49999999999975, -45.09999999999976, -62.200000000000074, -32.7999999999998, 13.699999999999964, -202.30000000000027, -85.00000000000063, 13.699999999999964, -15.699999999999747, -34.59999999999975, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 18.200000000000024, 12.200000000000042, 7.100000000000042, 4.7, -51.099999999999916, -89.20000000000067, -248.2000000000001, -84.70000000000059, -17.79999999999974, -20.199999999999775, -107.20000000000066, -0.9999999999999846, -88.60000000000022, -250.89999999999986, -181.60000000000036, 9.499999999999964, -42.9999999999998, -50.19999999999992, -261.69999999999993, -80.80000000000035, -75.1, -355.0, -60.100000000000456, -24.099999999999746, 20.000000000000014, -59.80000000000061, -42.99999999999976, -95.19999999999993, 35.30000000000009, -98.50000000000065, -26.799999999999883, -48.6999999999999, -196.9000000000005, 3.199999999999965, -225.10000000000014, -97.90000000000052, 40.700000000000244, -53.50000000000018, -227.80000000000038, 96.19999999999992, -70.30000000000085, 20.000000000000014, -46.59999999999988, -40.299999999999855, -80.50000000000081, -34.90000000000007, -205.0000000000005, 20.000000000000014, -73.30000000000064, 5.299999999999965, -86.50000000000037, -0.9999999999999846, -38.799999999999756, -85.00000000000058, -15.699999999999747, -57.700000000000465, -30.39999999999975, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -8.499999999999876, -32.49999999999987, 13.699999999999966, -276.39999999999986, -68.20000000000087, 25.400000000000098, 9.499999999999977, 3.1999999999999615, -54.69999999999986, -40.89999999999976, -39.09999999999976, -61.30000000000013, -40.89999999999976, 5.299999999999965, 10.699999999999974, -105.10000000000045, -17.19999999999976, 7.399999999999965, -49.299999999999905, -43.899999999999814], "policy_predator_policy_reward": [50.0, 43.0, 160.0, 86.0, 40.0, 77.0, 32.0, 94.0, 11.0, 41.0, 121.0, 103.0, 94.0, 169.0, 16.0, 131.0, 4.0, 2.0, 31.0, 1.0, 112.0, 75.0, 104.0, 172.0, 175.0, 132.0, 124.0, 183.0, 192.0, 98.0, 61.0, 30.0, 180.0, 174.0, 122.0, 44.0, 146.0, 83.0, 116.0, 160.0, 55.0, 153.0, 138.0, 147.0, 50.0, 11.0, 117.0, 42.0, 139.0, 21.0, 147.0, 123.0, 100.0, 71.0, 40.0, 64.0, 28.0, 12.0, 138.0, 78.0, 154.0, 185.0, 31.0, 167.0, 104.0, 176.0, 180.0, 174.0, 138.0, 142.0, 66.0, 118.0, 47.0, 0.0, 19.0, 19.0, 86.0, 73.0, 95.0, 68.0, 141.0, 86.0, 19.0, 2.0, 136.0, 24.0, 155.0, 156.0, 38.0, 65.0, 190.0, 124.0, 36.0, 103.0, 30.0, 10.0, 18.0, 19.0, 70.0, 30.0, 2.0, 25.0, 127.0, 118.0, 144.0, 92.0, 39.0, 38.0, 76.0, 50.0, 0.0, 38.0, 133.0, 130.0, 17.0, 3.0, 26.0, 13.0, 0.0, 5.0, 25.0, 32.0, 30.0, 39.0, 58.0, 45.0, 146.0, 92.0, 34.0, 37.0, 35.0, 71.0, 102.0, 120.0, 92.0, 63.0, 64.0, 58.0, 142.0, 135.0, 170.0, 94.0, 31.0, 48.0, 22.0, 37.0, 95.0, 54.0, 5.0, 64.0, 48.0, 34.0, 67.0, 47.0, 75.0, 107.0, 34.0, 32.0, 93.0, 93.0, 43.0, 0.0, 24.0, 44.0, 51.0, 94.0, 43.0, 94.0, 28.0, 40.0, 27.0, 61.0, 38.0, 76.0, 5.0, 38.0, 23.0, 24.0, 8.0, 0.0, 19.0, 28.0, 119.0, 96.0, 42.0, 3.0, 13.0, 1.0, 21.0, 61.0, 30.0, 56.0, 29.0, 7.0, 42.0, 70.0, 12.0, 16.0, 40.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5448757204880901, "mean_inference_ms": 1.4035191727829162, "mean_action_processing_ms": 0.22493659083347206, "mean_env_wait_ms": 0.1820834707610386, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003888845443725586, "StateBufferConnector_ms": 0.002815723419189453, "ViewRequirementAgentConnector_ms": 0.09097957611083984}, "num_episodes": 27, "episode_return_max": 143.89999999999964, "episode_return_min": -361.19999999999993, "episode_return_mean": -31.065999999999978, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 424.51137666733126, "num_env_steps_trained_throughput_per_sec": 424.51137666733126, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 9735.376, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9735.325, "sample_time_ms": 1200.195, "learn_time_ms": 8520.239, "learn_throughput": 469.47, "synch_weights_time_ms": 12.961}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-28-18", "timestamp": 1723645698, "time_this_iter_s": 9.427648067474365, "time_total_s": 218.72474837303162, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39af080d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 218.72474837303162, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 28.900000000000002, "ram_util_percent": 83.28461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.958850439326473, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.1516093286256943, "policy_loss": -0.009447355471580984, "vf_loss": 3.158027663621953, "vf_explained_var": -0.05035994913842943, "kl": 0.010096720456830452, "entropy": 1.4881320944538823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8733079712857643, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.8878184380354703, "policy_loss": -0.010286261840531278, "vf_loss": 3.895291288819893, "vf_explained_var": 0.032260255712680715, "kl": 0.01406706004595032, "entropy": 1.4492371132764867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 143.89999999999964, "episode_reward_min": -304.1999999999986, "episode_reward_mean": -19.222999999999967, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 96.19999999999992, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -70.60150000000006, "predator_policy": 60.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.39999999999972, -173.60000000000065, -55.59999999999987, -85.70000000000002, 24.200000000000188, -83.90000000000092, -92.50000000000009, -60.49999999999978, -3.499999999999919, -3.5999999999999126, -6.099999999999682, -23.899999999999967, -261.5, -46.999999999999964, -73.90000000000045, -200.00000000000009, -138.70000000000027, -117.40000000000074, -11.699999999999605, 38.10000000000027, -4.39999999999967, 8.60000000000006, -25.49999999999968, 14.800000000000008, -108.70000000000049, -111.00000000000057, 45.20000000000013, -304.1999999999986, -35.80000000000054, -3.999999999999703, 47.00000000000035, 143.89999999999964, 10.30000000000006, 17.700000000000188, -67.20000000000039, 22.50000000000004, 18.700000000000244, 18.89999999999999, -24.299999999999784, 17.999999999999982, 5.500000000000169, 34.50000000000022, 87.39999999999964, 80.79999999999973, -37.30000000000026, -94.90000000000049, 33.0000000000002, -2.199999999999918, -117.5000000000004, -17.09999999999968, 28.800000000000157, -65.50000000000037, -166.10000000000056, -5.199999999999756, 19.199999999999974, 10.800000000000068, 5.800000000000022, 6.500000000000059, -79.70000000000019, -141.00000000000068, 53.20000000000048, 54.40000000000011, -7.299999999999677, -18.899999999999785, 29.600000000000172, -47.99999999999971, 5.792588630981754e-14, 0.5000000000003498, -9.799999999999775, -30.39999999999951, 36.60000000000025, 31.200000000000166, 5.999999999999911, -47.69999999999986, 2.200000000000106, 26.7000000000001, -13.59999999999969, -14.399999999999816, 0.4000000000002427, 17.59999999999998, 18.199999999999964, 7.799999999999969, -3.8999999999997383, 63.000000000000405, 40.400000000000304, 76.89999999999952, -32.59999999999963, -7.799999999999647, 32.300000000000196, -137.90000000000128, 63.80000000000029, 33.30000000000021, -22.29999999999966, -97.20000000000088, 24.400000000000055, 47.10000000000023, 3.1000000000000454, 9.2, 45.000000000000504, -0.49999999999979283], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-291.39999999999986, 20.000000000000014, -287.20000000000005, -162.4000000000006, 17.899999999999988, -281.5, -249.10000000000005, -121.6, -33.69999999999996, -3.0999999999999757, -9.399999999999855, -233.5000000000003, -15.699999999999747, -236.79999999999998, -333.70000000000005, 3.1999999999999633, 20.000000000000014, -194.50000000000003, -0.9999999999999917, -106.60000000000008, -11.499999999999826, -34.59999999999976, -3.0999999999999943, -236.80000000000007, -243.10000000000005, -357.39999999999986, 8.000000000000004, -253.00000000000003, -373.9000000000001, 20.000000000000014, -238.30000000000004, -315.6999999999999, -161.20000000000007, -257.5000000000001, -308.79999999999984, 7.399999999999965, -78.70000000000087, 20.000000000000014, -19.899999999999743, 20.000000000000014, -109.89999999999992, -53.50000000000019, -151.30000000000007, -3.099999999999972, 3.1999999999999615, -255.69999999999982, -19.899999999999743, 13.699999999999964, -253.0000000000002, -15.699999999999747, -170.20000000000056, -251.8, 20.000000000000014, -77.80000000000011, -386.8, -231.40000000000038, -24.099999999999746, -150.70000000000024, -42.99999999999976, -0.9999999999999881, -9.999999999999895, 20.000000000000014, 65.00000000000003, -21.099999999999973, -26.199999999999754, 9.499999999999964, -230.5, 3.1999999999999615, -5.1999999999999265, -298.00000000000017, -21.999999999999794, -32.49999999999975, -45.09999999999976, -62.200000000000074, -32.7999999999998, 13.699999999999964, -202.30000000000027, -85.00000000000063, 13.699999999999964, -15.699999999999747, -34.59999999999975, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 18.200000000000024, 12.200000000000042, 7.100000000000042, 4.7, -51.099999999999916, -89.20000000000067, -248.2000000000001, -84.70000000000059, -17.79999999999974, -20.199999999999775, -107.20000000000066, -0.9999999999999846, -88.60000000000022, -250.89999999999986, -181.60000000000036, 9.499999999999964, -42.9999999999998, -50.19999999999992, -261.69999999999993, -80.80000000000035, -75.1, -355.0, -60.100000000000456, -24.099999999999746, 20.000000000000014, -59.80000000000061, -42.99999999999976, -95.19999999999993, 35.30000000000009, -98.50000000000065, -26.799999999999883, -48.6999999999999, -196.9000000000005, 3.199999999999965, -225.10000000000014, -97.90000000000052, 40.700000000000244, -53.50000000000018, -227.80000000000038, 96.19999999999992, -70.30000000000085, 20.000000000000014, -46.59999999999988, -40.299999999999855, -80.50000000000081, -34.90000000000007, -205.0000000000005, 20.000000000000014, -73.30000000000064, 5.299999999999965, -86.50000000000037, -0.9999999999999846, -38.799999999999756, -85.00000000000058, -15.699999999999747, -57.700000000000465, -30.39999999999975, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -8.499999999999876, -32.49999999999987, 13.699999999999966, -276.39999999999986, -68.20000000000087, 25.400000000000098, 9.499999999999977, 3.1999999999999615, -54.69999999999986, -40.89999999999976, -39.09999999999976, -61.30000000000013, -40.89999999999976, 5.299999999999965, 10.699999999999974, -105.10000000000045, -17.19999999999976, 7.399999999999965, -49.299999999999905, -43.899999999999814, -11.499999999999819, -51.39999999999998, 20.00000000000001, 8.0, -32.49999999999975, 29.90000000000018, 24.20000000000007, 4.69999999999999, 11.599999999999964, -182.20000000000056, -31.899999999999757, -19.899999999999743, -59.50000000000025, 30.800000000000203, -76.60000000000085, -235.30000000000044, 27.20000000000011, -9.400000000000018, 20.000000000000014, 5.299999999999965, -121.30000000000061, 20.000000000000014, -145.00000000000034, -140.2000000000006, 11.599999999999964, -26.199999999999847, 20.000000000000014, -10.899999999999906, -145.9000000000007, 20.000000000000014, -68.20000000000084, 22.400000000000087, 8.000000000000009, 20.000000000000014, 20.000000000000014, -71.50000000000088], "policy_predator_policy_reward": [146.0, 83.0, 116.0, 160.0, 55.0, 153.0, 138.0, 147.0, 50.0, 11.0, 117.0, 42.0, 139.0, 21.0, 147.0, 123.0, 100.0, 71.0, 40.0, 64.0, 28.0, 12.0, 138.0, 78.0, 154.0, 185.0, 31.0, 167.0, 104.0, 176.0, 180.0, 174.0, 138.0, 142.0, 66.0, 118.0, 47.0, 0.0, 19.0, 19.0, 86.0, 73.0, 95.0, 68.0, 141.0, 86.0, 19.0, 2.0, 136.0, 24.0, 155.0, 156.0, 38.0, 65.0, 190.0, 124.0, 36.0, 103.0, 30.0, 10.0, 18.0, 19.0, 70.0, 30.0, 2.0, 25.0, 127.0, 118.0, 144.0, 92.0, 39.0, 38.0, 76.0, 50.0, 0.0, 38.0, 133.0, 130.0, 17.0, 3.0, 26.0, 13.0, 0.0, 5.0, 25.0, 32.0, 30.0, 39.0, 58.0, 45.0, 146.0, 92.0, 34.0, 37.0, 35.0, 71.0, 102.0, 120.0, 92.0, 63.0, 64.0, 58.0, 142.0, 135.0, 170.0, 94.0, 31.0, 48.0, 22.0, 37.0, 95.0, 54.0, 5.0, 64.0, 48.0, 34.0, 67.0, 47.0, 75.0, 107.0, 34.0, 32.0, 93.0, 93.0, 43.0, 0.0, 24.0, 44.0, 51.0, 94.0, 43.0, 94.0, 28.0, 40.0, 27.0, 61.0, 38.0, 76.0, 5.0, 38.0, 23.0, 24.0, 8.0, 0.0, 19.0, 28.0, 119.0, 96.0, 42.0, 3.0, 13.0, 1.0, 21.0, 61.0, 30.0, 56.0, 29.0, 7.0, 42.0, 70.0, 12.0, 16.0, 40.0, 61.0, 42.0, 17.0, 17.0, 18.0, 18.0, 25.0, 23.0, 25.0, 45.0, 93.0, 27.0, 17.0, 33.0, 28.0, 122.0, 52.0, 14.0, 32.0, 5.0, 3.0, 63.0, 16.0, 121.0, 67.0, 18.0, 21.0, 19.0, 19.0, 77.0, 52.0, 1.0, 54.0, 7.0, 10.0, 44.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5432509503659749, "mean_inference_ms": 1.3987739118182845, "mean_action_processing_ms": 0.22456635390357665, "mean_env_wait_ms": 0.1818341084122334, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004214167594909668, "StateBufferConnector_ms": 0.002787351608276367, "ViewRequirementAgentConnector_ms": 0.0891503095626831}, "num_episodes": 18, "episode_return_max": 143.89999999999964, "episode_return_min": -304.1999999999986, "episode_return_mean": -19.222999999999967, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 435.72101758207896, "num_env_steps_trained_throughput_per_sec": 435.72101758207896, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 9627.56, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9627.509, "sample_time_ms": 1199.592, "learn_time_ms": 8413.633, "learn_throughput": 475.419, "synch_weights_time_ms": 12.426}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-28-27", "timestamp": 1723645707, "time_this_iter_s": 9.192715883255005, "time_total_s": 227.91746425628662, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39aef94c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 227.91746425628662, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 26.9, "ram_util_percent": 83.25384615384617}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5662857364725185, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.0925910577256843, "policy_loss": -0.009663267794222863, "vf_loss": 2.1003085829593515, "vf_explained_var": -0.017134414810352223, "kl": 0.0064858065251914366, "entropy": 1.4703246677994097, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5529768326925852, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.8113424873225905, "policy_loss": -0.007928074984293845, "vf_loss": 2.8171920394140577, "vf_explained_var": 0.07658893365077872, "kl": 0.01039256728172092, "entropy": 1.416003575337627, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 143.89999999999964, "episode_reward_min": -304.1999999999986, "episode_reward_mean": -8.165999999999963, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 96.19999999999992, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -52.408000000000094, "predator_policy": 48.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.699999999999605, 38.10000000000027, -4.39999999999967, 8.60000000000006, -25.49999999999968, 14.800000000000008, -108.70000000000049, -111.00000000000057, 45.20000000000013, -304.1999999999986, -35.80000000000054, -3.999999999999703, 47.00000000000035, 143.89999999999964, 10.30000000000006, 17.700000000000188, -67.20000000000039, 22.50000000000004, 18.700000000000244, 18.89999999999999, -24.299999999999784, 17.999999999999982, 5.500000000000169, 34.50000000000022, 87.39999999999964, 80.79999999999973, -37.30000000000026, -94.90000000000049, 33.0000000000002, -2.199999999999918, -117.5000000000004, -17.09999999999968, 28.800000000000157, -65.50000000000037, -166.10000000000056, -5.199999999999756, 19.199999999999974, 10.800000000000068, 5.800000000000022, 6.500000000000059, -79.70000000000019, -141.00000000000068, 53.20000000000048, 54.40000000000011, -7.299999999999677, -18.899999999999785, 29.600000000000172, -47.99999999999971, 5.792588630981754e-14, 0.5000000000003498, -9.799999999999775, -30.39999999999951, 36.60000000000025, 31.200000000000166, 5.999999999999911, -47.69999999999986, 2.200000000000106, 26.7000000000001, -13.59999999999969, -14.399999999999816, 0.4000000000002427, 17.59999999999998, 18.199999999999964, 7.799999999999969, -3.8999999999997383, 63.000000000000405, 40.400000000000304, 76.89999999999952, -32.59999999999963, -7.799999999999647, 32.300000000000196, -137.90000000000128, 63.80000000000029, 33.30000000000021, -22.29999999999966, -97.20000000000088, 24.400000000000055, 47.10000000000023, 3.1000000000000454, 9.2, 45.000000000000504, -0.49999999999979283, 38.70000000000029, 46.900000000000446, -63.4000000000011, -28.799999999999592, -19.599999999999774, -32.29999999999957, -42.90000000000009, 16.199999999999907, -18.299999999999507, -8.599999999999659, -60.90000000000149, 18.399999999999974, -12.799999999999558, 25.000000000000103, -55.70000000000076, 46.000000000000384, -50.20000000000002, -137.6000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-78.70000000000087, 20.000000000000014, -19.899999999999743, 20.000000000000014, -109.89999999999992, -53.50000000000019, -151.30000000000007, -3.099999999999972, 3.1999999999999615, -255.69999999999982, -19.899999999999743, 13.699999999999964, -253.0000000000002, -15.699999999999747, -170.20000000000056, -251.8, 20.000000000000014, -77.80000000000011, -386.8, -231.40000000000038, -24.099999999999746, -150.70000000000024, -42.99999999999976, -0.9999999999999881, -9.999999999999895, 20.000000000000014, 65.00000000000003, -21.099999999999973, -26.199999999999754, 9.499999999999964, -230.5, 3.1999999999999615, -5.1999999999999265, -298.00000000000017, -21.999999999999794, -32.49999999999975, -45.09999999999976, -62.200000000000074, -32.7999999999998, 13.699999999999964, -202.30000000000027, -85.00000000000063, 13.699999999999964, -15.699999999999747, -34.59999999999975, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 18.200000000000024, 12.200000000000042, 7.100000000000042, 4.7, -51.099999999999916, -89.20000000000067, -248.2000000000001, -84.70000000000059, -17.79999999999974, -20.199999999999775, -107.20000000000066, -0.9999999999999846, -88.60000000000022, -250.89999999999986, -181.60000000000036, 9.499999999999964, -42.9999999999998, -50.19999999999992, -261.69999999999993, -80.80000000000035, -75.1, -355.0, -60.100000000000456, -24.099999999999746, 20.000000000000014, -59.80000000000061, -42.99999999999976, -95.19999999999993, 35.30000000000009, -98.50000000000065, -26.799999999999883, -48.6999999999999, -196.9000000000005, 3.199999999999965, -225.10000000000014, -97.90000000000052, 40.700000000000244, -53.50000000000018, -227.80000000000038, 96.19999999999992, -70.30000000000085, 20.000000000000014, -46.59999999999988, -40.299999999999855, -80.50000000000081, -34.90000000000007, -205.0000000000005, 20.000000000000014, -73.30000000000064, 5.299999999999965, -86.50000000000037, -0.9999999999999846, -38.799999999999756, -85.00000000000058, -15.699999999999747, -57.700000000000465, -30.39999999999975, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -8.499999999999876, -32.49999999999987, 13.699999999999966, -276.39999999999986, -68.20000000000087, 25.400000000000098, 9.499999999999977, 3.1999999999999615, -54.69999999999986, -40.89999999999976, -39.09999999999976, -61.30000000000013, -40.89999999999976, 5.299999999999965, 10.699999999999974, -105.10000000000045, -17.19999999999976, 7.399999999999965, -49.299999999999905, -43.899999999999814, -11.499999999999819, -51.39999999999998, 20.00000000000001, 8.0, -32.49999999999975, 29.90000000000018, 24.20000000000007, 4.69999999999999, 11.599999999999964, -182.20000000000056, -31.899999999999757, -19.899999999999743, -59.50000000000025, 30.800000000000203, -76.60000000000085, -235.30000000000044, 27.20000000000011, -9.400000000000018, 20.000000000000014, 5.299999999999965, -121.30000000000061, 20.000000000000014, -145.00000000000034, -140.2000000000006, 11.599999999999964, -26.199999999999847, 20.000000000000014, -10.899999999999906, -145.9000000000007, 20.000000000000014, -68.20000000000084, 22.400000000000087, 8.000000000000009, 20.000000000000014, 20.000000000000014, -71.50000000000088, 38.00000000000024, -28.299999999999763, 20.000000000000014, 11.899999999999975, -190.00000000000057, -9.399999999999855, -42.99999999999976, -68.80000000000057, -22.299999999999798, -70.30000000000047, -30.399999999999757, -79.90000000000074, -74.50000000000082, -51.399999999999764, 1.9999999999999731, -17.79999999999975, -49.299999999999905, -21.999999999999744, 18.799999999999997, -72.40000000000082, -70.30000000000084, -76.60000000000088, -76.60000000000085, 20.000000000000014, -53.50000000000002, -7.299999999999891, -41.79999999999984, 15.799999999999963, -38.799999999999756, -103.90000000000072, 24.500000000000103, -11.499999999999819, -5.200000000000051, -127.00000000000074, -110.20000000000078, -219.40000000000043], "policy_predator_policy_reward": [47.0, 0.0, 19.0, 19.0, 86.0, 73.0, 95.0, 68.0, 141.0, 86.0, 19.0, 2.0, 136.0, 24.0, 155.0, 156.0, 38.0, 65.0, 190.0, 124.0, 36.0, 103.0, 30.0, 10.0, 18.0, 19.0, 70.0, 30.0, 2.0, 25.0, 127.0, 118.0, 144.0, 92.0, 39.0, 38.0, 76.0, 50.0, 0.0, 38.0, 133.0, 130.0, 17.0, 3.0, 26.0, 13.0, 0.0, 5.0, 25.0, 32.0, 30.0, 39.0, 58.0, 45.0, 146.0, 92.0, 34.0, 37.0, 35.0, 71.0, 102.0, 120.0, 92.0, 63.0, 64.0, 58.0, 142.0, 135.0, 170.0, 94.0, 31.0, 48.0, 22.0, 37.0, 95.0, 54.0, 5.0, 64.0, 48.0, 34.0, 67.0, 47.0, 75.0, 107.0, 34.0, 32.0, 93.0, 93.0, 43.0, 0.0, 24.0, 44.0, 51.0, 94.0, 43.0, 94.0, 28.0, 40.0, 27.0, 61.0, 38.0, 76.0, 5.0, 38.0, 23.0, 24.0, 8.0, 0.0, 19.0, 28.0, 119.0, 96.0, 42.0, 3.0, 13.0, 1.0, 21.0, 61.0, 30.0, 56.0, 29.0, 7.0, 42.0, 70.0, 12.0, 16.0, 40.0, 61.0, 42.0, 17.0, 17.0, 18.0, 18.0, 25.0, 23.0, 25.0, 45.0, 93.0, 27.0, 17.0, 33.0, 28.0, 122.0, 52.0, 14.0, 32.0, 5.0, 3.0, 63.0, 16.0, 121.0, 67.0, 18.0, 21.0, 19.0, 19.0, 77.0, 52.0, 1.0, 54.0, 7.0, 10.0, 44.0, 7.0, 29.0, 0.0, 6.0, 9.0, 36.0, 100.0, 53.0, 30.0, 17.0, 56.0, 54.0, 24.0, 46.0, 37.0, 26.0, 6.0, 20.0, 33.0, 44.0, 1.0, 40.0, 46.0, 46.0, 29.0, 23.0, 25.0, 41.0, 10.0, 28.0, 59.0, 8.0, 25.0, 12.0, 70.0, 129.0, 63.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5426667116867051, "mean_inference_ms": 1.3974798739834287, "mean_action_processing_ms": 0.22430663003075074, "mean_env_wait_ms": 0.1813586214716362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043277740478515625, "StateBufferConnector_ms": 0.0029186010360717773, "ViewRequirementAgentConnector_ms": 0.0901341438293457}, "num_episodes": 18, "episode_return_max": 143.89999999999964, "episode_return_min": -304.1999999999986, "episode_return_mean": -8.165999999999963, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 431.47874273800176, "num_env_steps_trained_throughput_per_sec": 431.47874273800176, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 9496.865, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9496.816, "sample_time_ms": 1138.394, "learn_time_ms": 8344.184, "learn_throughput": 479.376, "synch_weights_time_ms": 12.355}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-28-36", "timestamp": 1723645716, "time_this_iter_s": 9.275660037994385, "time_total_s": 237.193124294281, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ad9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 237.193124294281, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 29.438461538461542, "ram_util_percent": 83.41538461538461}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4714685066509499, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.4458979300090244, "policy_loss": -0.005715797899325413, "vf_loss": 3.4497293942819827, "vf_explained_var": -0.003183606913480809, "kl": 0.006281090744008138, "entropy": 1.4670317287167545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.381783954334007, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.536667454431927, "policy_loss": -0.015292270682387487, "vf_loss": 2.5494754380019256, "vf_explained_var": 0.1985549466319816, "kl": 0.012421441424951258, "entropy": 1.4454935937962203, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 87.39999999999964, "episode_reward_min": -261.70000000000005, "episode_reward_mean": -11.721999999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 96.19999999999992, "predator_policy": 170.0}, "policy_reward_mean": {"prey_policy": -48.13600000000011, "predator_policy": 42.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.700000000000244, 18.89999999999999, -24.299999999999784, 17.999999999999982, 5.500000000000169, 34.50000000000022, 87.39999999999964, 80.79999999999973, -37.30000000000026, -94.90000000000049, 33.0000000000002, -2.199999999999918, -117.5000000000004, -17.09999999999968, 28.800000000000157, -65.50000000000037, -166.10000000000056, -5.199999999999756, 19.199999999999974, 10.800000000000068, 5.800000000000022, 6.500000000000059, -79.70000000000019, -141.00000000000068, 53.20000000000048, 54.40000000000011, -7.299999999999677, -18.899999999999785, 29.600000000000172, -47.99999999999971, 5.792588630981754e-14, 0.5000000000003498, -9.799999999999775, -30.39999999999951, 36.60000000000025, 31.200000000000166, 5.999999999999911, -47.69999999999986, 2.200000000000106, 26.7000000000001, -13.59999999999969, -14.399999999999816, 0.4000000000002427, 17.59999999999998, 18.199999999999964, 7.799999999999969, -3.8999999999997383, 63.000000000000405, 40.400000000000304, 76.89999999999952, -32.59999999999963, -7.799999999999647, 32.300000000000196, -137.90000000000128, 63.80000000000029, 33.30000000000021, -22.29999999999966, -97.20000000000088, 24.400000000000055, 47.10000000000023, 3.1000000000000454, 9.2, 45.000000000000504, -0.49999999999979283, 38.70000000000029, 46.900000000000446, -63.4000000000011, -28.799999999999592, -19.599999999999774, -32.29999999999957, -42.90000000000009, 16.199999999999907, -18.299999999999507, -8.599999999999659, -60.90000000000149, 18.399999999999974, -12.799999999999558, 25.000000000000103, -55.70000000000076, 46.000000000000384, -50.20000000000002, -137.6000000000012, -12.19999999999961, -261.70000000000005, 18.099999999999966, -72.3000000000017, -9.799999999999573, 34.8000000000002, 35.20000000000023, 42.40000000000044, 23.500000000000032, 39.60000000000029, -55.000000000000725, -144.40000000000006, 25.70000000000011, -53.10000000000081, -32.79999999999998, -195.00000000000014, -19.39999999999951, -43.599999999999575], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-45.09999999999976, -62.200000000000074, -32.7999999999998, 13.699999999999964, -202.30000000000027, -85.00000000000063, 13.699999999999964, -15.699999999999747, -34.59999999999975, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 18.200000000000024, 12.200000000000042, 7.100000000000042, 4.7, -51.099999999999916, -89.20000000000067, -248.2000000000001, -84.70000000000059, -17.79999999999974, -20.199999999999775, -107.20000000000066, -0.9999999999999846, -88.60000000000022, -250.89999999999986, -181.60000000000036, 9.499999999999964, -42.9999999999998, -50.19999999999992, -261.69999999999993, -80.80000000000035, -75.1, -355.0, -60.100000000000456, -24.099999999999746, 20.000000000000014, -59.80000000000061, -42.99999999999976, -95.19999999999993, 35.30000000000009, -98.50000000000065, -26.799999999999883, -48.6999999999999, -196.9000000000005, 3.199999999999965, -225.10000000000014, -97.90000000000052, 40.700000000000244, -53.50000000000018, -227.80000000000038, 96.19999999999992, -70.30000000000085, 20.000000000000014, -46.59999999999988, -40.299999999999855, -80.50000000000081, -34.90000000000007, -205.0000000000005, 20.000000000000014, -73.30000000000064, 5.299999999999965, -86.50000000000037, -0.9999999999999846, -38.799999999999756, -85.00000000000058, -15.699999999999747, -57.700000000000465, -30.39999999999975, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -8.499999999999876, -32.49999999999987, 13.699999999999966, -276.39999999999986, -68.20000000000087, 25.400000000000098, 9.499999999999977, 3.1999999999999615, -54.69999999999986, -40.89999999999976, -39.09999999999976, -61.30000000000013, -40.89999999999976, 5.299999999999965, 10.699999999999974, -105.10000000000045, -17.19999999999976, 7.399999999999965, -49.299999999999905, -43.899999999999814, -11.499999999999819, -51.39999999999998, 20.00000000000001, 8.0, -32.49999999999975, 29.90000000000018, 24.20000000000007, 4.69999999999999, 11.599999999999964, -182.20000000000056, -31.899999999999757, -19.899999999999743, -59.50000000000025, 30.800000000000203, -76.60000000000085, -235.30000000000044, 27.20000000000011, -9.400000000000018, 20.000000000000014, 5.299999999999965, -121.30000000000061, 20.000000000000014, -145.00000000000034, -140.2000000000006, 11.599999999999964, -26.199999999999847, 20.000000000000014, -10.899999999999906, -145.9000000000007, 20.000000000000014, -68.20000000000084, 22.400000000000087, 8.000000000000009, 20.000000000000014, 20.000000000000014, -71.50000000000088, 38.00000000000024, -28.299999999999763, 20.000000000000014, 11.899999999999975, -190.00000000000057, -9.399999999999855, -42.99999999999976, -68.80000000000057, -22.299999999999798, -70.30000000000047, -30.399999999999757, -79.90000000000074, -74.50000000000082, -51.399999999999764, 1.9999999999999731, -17.79999999999975, -49.299999999999905, -21.999999999999744, 18.799999999999997, -72.40000000000082, -70.30000000000084, -76.60000000000088, -76.60000000000085, 20.000000000000014, -53.50000000000002, -7.299999999999891, -41.79999999999984, 15.799999999999963, -38.799999999999756, -103.90000000000072, 24.500000000000103, -11.499999999999819, -5.200000000000051, -127.00000000000074, -110.20000000000078, -219.40000000000043, 13.699999999999964, -103.9000000000008, -305.49999999999955, -131.20000000000005, -30.999999999999815, -40.89999999999976, -66.1000000000009, -71.20000000000014, -57.10000000000041, -6.699999999999854, -5.1999999999999265, 23.000000000000114, 5.299999999999965, 17.899999999999988, 10.099999999999996, -15.699999999999754, -11.499999999999819, 20.000000000000014, 20.000000000000014, 11.599999999999964, -55.60000000000002, -69.40000000000074, -145.09999999999982, -120.30000000000004, -70.30000000000089, 20.000000000000014, -57.70000000000034, -72.40000000000083, -38.49999999999978, -70.30000000000089, -226.59999999999997, -90.40000000000006, -57.700000000000166, -15.699999999999747, -89.20000000000078, -30.399999999999928], "policy_predator_policy_reward": [76.0, 50.0, 0.0, 38.0, 133.0, 130.0, 17.0, 3.0, 26.0, 13.0, 0.0, 5.0, 25.0, 32.0, 30.0, 39.0, 58.0, 45.0, 146.0, 92.0, 34.0, 37.0, 35.0, 71.0, 102.0, 120.0, 92.0, 63.0, 64.0, 58.0, 142.0, 135.0, 170.0, 94.0, 31.0, 48.0, 22.0, 37.0, 95.0, 54.0, 5.0, 64.0, 48.0, 34.0, 67.0, 47.0, 75.0, 107.0, 34.0, 32.0, 93.0, 93.0, 43.0, 0.0, 24.0, 44.0, 51.0, 94.0, 43.0, 94.0, 28.0, 40.0, 27.0, 61.0, 38.0, 76.0, 5.0, 38.0, 23.0, 24.0, 8.0, 0.0, 19.0, 28.0, 119.0, 96.0, 42.0, 3.0, 13.0, 1.0, 21.0, 61.0, 30.0, 56.0, 29.0, 7.0, 42.0, 70.0, 12.0, 16.0, 40.0, 61.0, 42.0, 17.0, 17.0, 18.0, 18.0, 25.0, 23.0, 25.0, 45.0, 93.0, 27.0, 17.0, 33.0, 28.0, 122.0, 52.0, 14.0, 32.0, 5.0, 3.0, 63.0, 16.0, 121.0, 67.0, 18.0, 21.0, 19.0, 19.0, 77.0, 52.0, 1.0, 54.0, 7.0, 10.0, 44.0, 7.0, 29.0, 0.0, 6.0, 9.0, 36.0, 100.0, 53.0, 30.0, 17.0, 56.0, 54.0, 24.0, 46.0, 37.0, 26.0, 6.0, 20.0, 33.0, 44.0, 1.0, 40.0, 46.0, 46.0, 29.0, 23.0, 25.0, 41.0, 10.0, 28.0, 59.0, 8.0, 25.0, 12.0, 70.0, 129.0, 63.0, 55.0, 23.0, 163.0, 12.0, 41.0, 49.0, 1.0, 64.0, 41.0, 13.0, 12.0, 5.0, 8.0, 4.0, 14.0, 34.0, 0.0, 15.0, 4.0, 4.0, 42.0, 28.0, 101.0, 20.0, 38.0, 38.0, 48.0, 29.0, 43.0, 33.0, 104.0, 18.0, 17.0, 37.0, 76.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.542435639678639, "mean_inference_ms": 1.3970475719569264, "mean_action_processing_ms": 0.2241752705372483, "mean_env_wait_ms": 0.18106723497081578, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004856228828430176, "StateBufferConnector_ms": 0.0029965639114379883, "ViewRequirementAgentConnector_ms": 0.09083104133605957}, "num_episodes": 18, "episode_return_max": 87.39999999999964, "episode_return_min": -261.70000000000005, "episode_return_mean": -11.721999999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 438.1827598446204, "num_env_steps_trained_throughput_per_sec": 438.1827598446204, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 9411.402, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9411.354, "sample_time_ms": 1134.738, "learn_time_ms": 8263.098, "learn_throughput": 484.08, "synch_weights_time_ms": 12.226}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-28-46", "timestamp": 1723645726, "time_this_iter_s": 9.13171672821045, "time_total_s": 246.32484102249146, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ad700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 246.32484102249146, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 27.73846153846154, "ram_util_percent": 83.26923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.56486691526635, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 4.8266351760379855, "policy_loss": -0.003826138533888355, "vf_loss": 4.82894161428724, "vf_explained_var": 0.00046716250439800283, "kl": 0.005065681209641829, "entropy": 1.4580517246609643, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.357747807609972, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.888142505650798, "policy_loss": -0.011646075923951766, "vf_loss": 3.8978957241805143, "vf_explained_var": 0.18102296013680716, "kl": 0.009464280162221058, "entropy": 1.402948368352557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 100.19999999999933, "episode_reward_min": -396.0, "episode_reward_mean": -24.03799999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 96.19999999999992, "predator_policy": 237.0}, "policy_reward_mean": {"prey_policy": -51.08400000000012, "predator_policy": 39.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-79.70000000000019, -141.00000000000068, 53.20000000000048, 54.40000000000011, -7.299999999999677, -18.899999999999785, 29.600000000000172, -47.99999999999971, 5.792588630981754e-14, 0.5000000000003498, -9.799999999999775, -30.39999999999951, 36.60000000000025, 31.200000000000166, 5.999999999999911, -47.69999999999986, 2.200000000000106, 26.7000000000001, -13.59999999999969, -14.399999999999816, 0.4000000000002427, 17.59999999999998, 18.199999999999964, 7.799999999999969, -3.8999999999997383, 63.000000000000405, 40.400000000000304, 76.89999999999952, -32.59999999999963, -7.799999999999647, 32.300000000000196, -137.90000000000128, 63.80000000000029, 33.30000000000021, -22.29999999999966, -97.20000000000088, 24.400000000000055, 47.10000000000023, 3.1000000000000454, 9.2, 45.000000000000504, -0.49999999999979283, 38.70000000000029, 46.900000000000446, -63.4000000000011, -28.799999999999592, -19.599999999999774, -32.29999999999957, -42.90000000000009, 16.199999999999907, -18.299999999999507, -8.599999999999659, -60.90000000000149, 18.399999999999974, -12.799999999999558, 25.000000000000103, -55.70000000000076, 46.000000000000384, -50.20000000000002, -137.6000000000012, -12.19999999999961, -261.70000000000005, 18.099999999999966, -72.3000000000017, -9.799999999999573, 34.8000000000002, 35.20000000000023, 42.40000000000044, 23.500000000000032, 39.60000000000029, -55.000000000000725, -144.40000000000006, 25.70000000000011, -53.10000000000081, -32.79999999999998, -195.00000000000014, -19.39999999999951, -43.599999999999575, 14.700000000000001, -128.29999999999993, -363.3, 22.70000000000002, -51.29999999999956, -100.8000000000003, 29.10000000000013, 32.800000000000196, -59.600000000000065, -144.90000000000006, 7.699999999999969, -396.0, 100.19999999999933, 22.40000000000004, 2.600000000000162, -107.70000000000005, 10.500000000000066, -372.90000000000003, -28.299999999999734, 16.49999999999991, 69.50000000000006, 30.60000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-196.9000000000005, 3.199999999999965, -225.10000000000014, -97.90000000000052, 40.700000000000244, -53.50000000000018, -227.80000000000038, 96.19999999999992, -70.30000000000085, 20.000000000000014, -46.59999999999988, -40.299999999999855, -80.50000000000081, -34.90000000000007, -205.0000000000005, 20.000000000000014, -73.30000000000064, 5.299999999999965, -86.50000000000037, -0.9999999999999846, -38.799999999999756, -85.00000000000058, -15.699999999999747, -57.700000000000465, -30.39999999999975, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -8.499999999999876, -32.49999999999987, 13.699999999999966, -276.39999999999986, -68.20000000000087, 25.400000000000098, 9.499999999999977, 3.1999999999999615, -54.69999999999986, -40.89999999999976, -39.09999999999976, -61.30000000000013, -40.89999999999976, 5.299999999999965, 10.699999999999974, -105.10000000000045, -17.19999999999976, 7.399999999999965, -49.299999999999905, -43.899999999999814, -11.499999999999819, -51.39999999999998, 20.00000000000001, 8.0, -32.49999999999975, 29.90000000000018, 24.20000000000007, 4.69999999999999, 11.599999999999964, -182.20000000000056, -31.899999999999757, -19.899999999999743, -59.50000000000025, 30.800000000000203, -76.60000000000085, -235.30000000000044, 27.20000000000011, -9.400000000000018, 20.000000000000014, 5.299999999999965, -121.30000000000061, 20.000000000000014, -145.00000000000034, -140.2000000000006, 11.599999999999964, -26.199999999999847, 20.000000000000014, -10.899999999999906, -145.9000000000007, 20.000000000000014, -68.20000000000084, 22.400000000000087, 8.000000000000009, 20.000000000000014, 20.000000000000014, -71.50000000000088, 38.00000000000024, -28.299999999999763, 20.000000000000014, 11.899999999999975, -190.00000000000057, -9.399999999999855, -42.99999999999976, -68.80000000000057, -22.299999999999798, -70.30000000000047, -30.399999999999757, -79.90000000000074, -74.50000000000082, -51.399999999999764, 1.9999999999999731, -17.79999999999975, -49.299999999999905, -21.999999999999744, 18.799999999999997, -72.40000000000082, -70.30000000000084, -76.60000000000088, -76.60000000000085, 20.000000000000014, -53.50000000000002, -7.299999999999891, -41.79999999999984, 15.799999999999963, -38.799999999999756, -103.90000000000072, 24.500000000000103, -11.499999999999819, -5.200000000000051, -127.00000000000074, -110.20000000000078, -219.40000000000043, 13.699999999999964, -103.9000000000008, -305.49999999999955, -131.20000000000005, -30.999999999999815, -40.89999999999976, -66.1000000000009, -71.20000000000014, -57.10000000000041, -6.699999999999854, -5.1999999999999265, 23.000000000000114, 5.299999999999965, 17.899999999999988, 10.099999999999996, -15.699999999999754, -11.499999999999819, 20.000000000000014, 20.000000000000014, 11.599999999999964, -55.60000000000002, -69.40000000000074, -145.09999999999982, -120.30000000000004, -70.30000000000089, 20.000000000000014, -57.70000000000034, -72.40000000000083, -38.49999999999978, -70.30000000000089, -226.59999999999997, -90.40000000000006, -57.700000000000166, -15.699999999999747, -89.20000000000078, -30.399999999999928, -26.199999999999747, 17.899999999999988, -201.89999999999984, -82.39999999999982, -390.00000000000017, -217.29999999999998, 6.799999999999967, -3.099999999999958, -137.5000000000007, 3.199999999999986, -24.09999999999998, -183.70000000000047, 9.499999999999964, 5.599999999999968, 20.000000000000014, -23.199999999999747, -80.80000000000004, -35.80000000000002, -55.599999999999994, -265.29999999999984, -70.30000000000072, 20.000000000000014, -351.30000000000007, -349.69999999999993, 20.000000000000014, 75.1999999999997, -13.899999999999796, 14.299999999999965, -63.400000000000816, 20.000000000000014, -241.30000000000044, -30.39999999999975, -53.50000000000019, -0.9999999999999917, -198.00000000000003, -400.9, -163.3000000000006, 20.000000000000014, -32.49999999999975, 20.000000000000014, 20.000000000000014, 48.50000000000021, 20.000000000000014, -9.399999999999855], "policy_predator_policy_reward": [67.0, 47.0, 75.0, 107.0, 34.0, 32.0, 93.0, 93.0, 43.0, 0.0, 24.0, 44.0, 51.0, 94.0, 43.0, 94.0, 28.0, 40.0, 27.0, 61.0, 38.0, 76.0, 5.0, 38.0, 23.0, 24.0, 8.0, 0.0, 19.0, 28.0, 119.0, 96.0, 42.0, 3.0, 13.0, 1.0, 21.0, 61.0, 30.0, 56.0, 29.0, 7.0, 42.0, 70.0, 12.0, 16.0, 40.0, 61.0, 42.0, 17.0, 17.0, 18.0, 18.0, 25.0, 23.0, 25.0, 45.0, 93.0, 27.0, 17.0, 33.0, 28.0, 122.0, 52.0, 14.0, 32.0, 5.0, 3.0, 63.0, 16.0, 121.0, 67.0, 18.0, 21.0, 19.0, 19.0, 77.0, 52.0, 1.0, 54.0, 7.0, 10.0, 44.0, 7.0, 29.0, 0.0, 6.0, 9.0, 36.0, 100.0, 53.0, 30.0, 17.0, 56.0, 54.0, 24.0, 46.0, 37.0, 26.0, 6.0, 20.0, 33.0, 44.0, 1.0, 40.0, 46.0, 46.0, 29.0, 23.0, 25.0, 41.0, 10.0, 28.0, 59.0, 8.0, 25.0, 12.0, 70.0, 129.0, 63.0, 55.0, 23.0, 163.0, 12.0, 41.0, 49.0, 1.0, 64.0, 41.0, 13.0, 12.0, 5.0, 8.0, 4.0, 14.0, 34.0, 0.0, 15.0, 4.0, 4.0, 42.0, 28.0, 101.0, 20.0, 38.0, 38.0, 48.0, 29.0, 43.0, 33.0, 104.0, 18.0, 17.0, 37.0, 76.0, 0.0, 22.0, 1.0, 27.0, 129.0, 7.0, 237.0, 11.0, 8.0, 8.0, 75.0, 6.0, 101.0, 5.0, 9.0, 19.0, 17.0, 50.0, 7.0, 21.0, 155.0, 43.0, 15.0, 83.0, 222.0, 5.0, 0.0, 13.0, 9.0, 7.0, 39.0, 140.0, 24.0, 33.0, 32.0, 0.0, 226.0, 88.0, 27.0, 25.0, 4.0, 1.0, 0.0, 14.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5423243069408377, "mean_inference_ms": 1.3980103515953988, "mean_action_processing_ms": 0.22411887948417053, "mean_env_wait_ms": 0.18079089897697956, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005343317985534668, "StateBufferConnector_ms": 0.0030177831649780273, "ViewRequirementAgentConnector_ms": 0.09005558490753174}, "num_episodes": 22, "episode_return_max": 100.19999999999933, "episode_return_min": -396.0, "episode_return_mean": -24.03799999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 439.67426733145896, "num_env_steps_trained_throughput_per_sec": 439.67426733145896, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 9306.184, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9306.137, "sample_time_ms": 1083.399, "learn_time_ms": 8209.625, "learn_throughput": 487.233, "synch_weights_time_ms": 11.982}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-28-55", "timestamp": 1723645735, "time_this_iter_s": 9.100924968719482, "time_total_s": 255.42576599121094, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ad790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 255.42576599121094, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 26.746153846153845, "ram_util_percent": 83.36153846153844}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7776706320268136, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 6.139988793267144, "policy_loss": -0.0043640073603166945, "vf_loss": 6.1421864156369805, "vf_explained_var": 0.004593431287341647, "kl": 0.007221283123135018, "entropy": 1.45152998481478, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.772716097163145, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.700484695888701, "policy_loss": -0.013803533901504817, "vf_loss": 5.711327827796734, "vf_explained_var": 0.13080068568073253, "kl": 0.014802030506582567, "entropy": 1.3758795579274496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 100.19999999999933, "episode_reward_min": -406.4999999999999, "episode_reward_mean": -37.31400000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -547.3999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 75.1999999999997, "predator_policy": 406.0}, "policy_reward_mean": {"prey_policy": -64.0120000000001, "predator_policy": 45.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.799999999999969, -3.8999999999997383, 63.000000000000405, 40.400000000000304, 76.89999999999952, -32.59999999999963, -7.799999999999647, 32.300000000000196, -137.90000000000128, 63.80000000000029, 33.30000000000021, -22.29999999999966, -97.20000000000088, 24.400000000000055, 47.10000000000023, 3.1000000000000454, 9.2, 45.000000000000504, -0.49999999999979283, 38.70000000000029, 46.900000000000446, -63.4000000000011, -28.799999999999592, -19.599999999999774, -32.29999999999957, -42.90000000000009, 16.199999999999907, -18.299999999999507, -8.599999999999659, -60.90000000000149, 18.399999999999974, -12.799999999999558, 25.000000000000103, -55.70000000000076, 46.000000000000384, -50.20000000000002, -137.6000000000012, -12.19999999999961, -261.70000000000005, 18.099999999999966, -72.3000000000017, -9.799999999999573, 34.8000000000002, 35.20000000000023, 42.40000000000044, 23.500000000000032, 39.60000000000029, -55.000000000000725, -144.40000000000006, 25.70000000000011, -53.10000000000081, -32.79999999999998, -195.00000000000014, -19.39999999999951, -43.599999999999575, 14.700000000000001, -128.29999999999993, -363.3, 22.70000000000002, -51.29999999999956, -100.8000000000003, 29.10000000000013, 32.800000000000196, -59.600000000000065, -144.90000000000006, 7.699999999999969, -396.0, 100.19999999999933, 22.40000000000004, 2.600000000000162, -107.70000000000005, 10.500000000000066, -372.90000000000003, -28.299999999999734, 16.49999999999991, 69.50000000000006, 30.60000000000016, -282.7, -27.099999999999696, -26.1000000000006, -181.79999999999987, -406.4999999999999, 36.50000000000025, -84.0999999999998, -59.40000000000042, -95.70000000000147, 24.300000000000065, -15.199999999999996, -17.199999999999505, -95.59999999999997, -6.699999999999829, -11.099999999999735, 31.70000000000018, 14.899999999999993, -201.7000000000007, 17.900000000000226, -1.8999999999996628, 38.90000000000028, -133.89999999999966, 20.699999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-49.299999999999905, -43.899999999999814, -11.499999999999819, -51.39999999999998, 20.00000000000001, 8.0, -32.49999999999975, 29.90000000000018, 24.20000000000007, 4.69999999999999, 11.599999999999964, -182.20000000000056, -31.899999999999757, -19.899999999999743, -59.50000000000025, 30.800000000000203, -76.60000000000085, -235.30000000000044, 27.20000000000011, -9.400000000000018, 20.000000000000014, 5.299999999999965, -121.30000000000061, 20.000000000000014, -145.00000000000034, -140.2000000000006, 11.599999999999964, -26.199999999999847, 20.000000000000014, -10.899999999999906, -145.9000000000007, 20.000000000000014, -68.20000000000084, 22.400000000000087, 8.000000000000009, 20.000000000000014, 20.000000000000014, -71.50000000000088, 38.00000000000024, -28.299999999999763, 20.000000000000014, 11.899999999999975, -190.00000000000057, -9.399999999999855, -42.99999999999976, -68.80000000000057, -22.299999999999798, -70.30000000000047, -30.399999999999757, -79.90000000000074, -74.50000000000082, -51.399999999999764, 1.9999999999999731, -17.79999999999975, -49.299999999999905, -21.999999999999744, 18.799999999999997, -72.40000000000082, -70.30000000000084, -76.60000000000088, -76.60000000000085, 20.000000000000014, -53.50000000000002, -7.299999999999891, -41.79999999999984, 15.799999999999963, -38.799999999999756, -103.90000000000072, 24.500000000000103, -11.499999999999819, -5.200000000000051, -127.00000000000074, -110.20000000000078, -219.40000000000043, 13.699999999999964, -103.9000000000008, -305.49999999999955, -131.20000000000005, -30.999999999999815, -40.89999999999976, -66.1000000000009, -71.20000000000014, -57.10000000000041, -6.699999999999854, -5.1999999999999265, 23.000000000000114, 5.299999999999965, 17.899999999999988, 10.099999999999996, -15.699999999999754, -11.499999999999819, 20.000000000000014, 20.000000000000014, 11.599999999999964, -55.60000000000002, -69.40000000000074, -145.09999999999982, -120.30000000000004, -70.30000000000089, 20.000000000000014, -57.70000000000034, -72.40000000000083, -38.49999999999978, -70.30000000000089, -226.59999999999997, -90.40000000000006, -57.700000000000166, -15.699999999999747, -89.20000000000078, -30.399999999999928, -26.199999999999747, 17.899999999999988, -201.89999999999984, -82.39999999999982, -390.00000000000017, -217.29999999999998, 6.799999999999967, -3.099999999999958, -137.5000000000007, 3.199999999999986, -24.09999999999998, -183.70000000000047, 9.499999999999964, 5.599999999999968, 20.000000000000014, -23.199999999999747, -80.80000000000004, -35.80000000000002, -55.599999999999994, -265.29999999999984, -70.30000000000072, 20.000000000000014, -351.30000000000007, -349.69999999999993, 20.000000000000014, 75.1999999999997, -13.899999999999796, 14.299999999999965, -63.400000000000816, 20.000000000000014, -241.30000000000044, -30.39999999999975, -53.50000000000019, -0.9999999999999917, -198.00000000000003, -400.9, -163.3000000000006, 20.000000000000014, -32.49999999999975, 20.000000000000014, 20.000000000000014, 48.50000000000021, 20.000000000000014, -9.399999999999855, -547.3999999999999, -386.29999999999995, -36.69999999999985, -51.399999999999764, -24.099999999999746, -521.0000000000001, -92.59999999999995, -281.2000000000004, -287.8999999999999, -315.59999999999997, 20.000000000000014, 9.499999999999964, -5.1999999999999265, -280.89999999999986, -3.0999999999999934, -186.30000000000038, -68.20000000000057, -116.50000000000077, -57.70000000000048, 20.000000000000014, -37.899999999999956, -60.29999999999984, -32.49999999999975, -36.699999999999754, -288.0, -76.60000000000004, -7.300000000000004, -50.39999999999978, -87.10000000000085, 20.000000000000014, 3.799999999999985, 17.900000000000013, 5.899999999999967, -21.99999999999976, -447.2, -53.499999999999766, 10.400000000000023, -8.500000000000028, -108.20000000000002, -3.6999999999999957, 17.899999999999988, 20.000000000000014, -80.20000000000006, -132.70000000000007, -64.30000000000089, 20.000000000000014], "policy_predator_policy_reward": [40.0, 61.0, 42.0, 17.0, 17.0, 18.0, 18.0, 25.0, 23.0, 25.0, 45.0, 93.0, 27.0, 17.0, 33.0, 28.0, 122.0, 52.0, 14.0, 32.0, 5.0, 3.0, 63.0, 16.0, 121.0, 67.0, 18.0, 21.0, 19.0, 19.0, 77.0, 52.0, 1.0, 54.0, 7.0, 10.0, 44.0, 7.0, 29.0, 0.0, 6.0, 9.0, 36.0, 100.0, 53.0, 30.0, 17.0, 56.0, 54.0, 24.0, 46.0, 37.0, 26.0, 6.0, 20.0, 33.0, 44.0, 1.0, 40.0, 46.0, 46.0, 29.0, 23.0, 25.0, 41.0, 10.0, 28.0, 59.0, 8.0, 25.0, 12.0, 70.0, 129.0, 63.0, 55.0, 23.0, 163.0, 12.0, 41.0, 49.0, 1.0, 64.0, 41.0, 13.0, 12.0, 5.0, 8.0, 4.0, 14.0, 34.0, 0.0, 15.0, 4.0, 4.0, 42.0, 28.0, 101.0, 20.0, 38.0, 38.0, 48.0, 29.0, 43.0, 33.0, 104.0, 18.0, 17.0, 37.0, 76.0, 0.0, 22.0, 1.0, 27.0, 129.0, 7.0, 237.0, 11.0, 8.0, 8.0, 75.0, 6.0, 101.0, 5.0, 9.0, 19.0, 17.0, 50.0, 7.0, 21.0, 155.0, 43.0, 15.0, 83.0, 222.0, 5.0, 0.0, 13.0, 9.0, 7.0, 39.0, 140.0, 24.0, 33.0, 32.0, 0.0, 226.0, 88.0, 27.0, 25.0, 4.0, 1.0, 0.0, 14.0, 6.0, 406.0, 245.0, 36.0, 25.0, 222.0, 297.0, 177.0, 15.0, 182.0, 15.0, 5.0, 2.0, 190.0, 12.0, 11.0, 119.0, 13.0, 76.0, 27.0, 35.0, 70.0, 13.0, 27.0, 25.0, 181.0, 88.0, 35.0, 16.0, 11.0, 45.0, 1.0, 9.0, 23.0, 8.0, 264.0, 35.0, 9.0, 7.0, 110.0, 0.0, 1.0, 0.0, 35.0, 44.0, 26.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5425054870831116, "mean_inference_ms": 1.3978763657863147, "mean_action_processing_ms": 0.22852143346190146, "mean_env_wait_ms": 0.1805385543053447, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005523324012756348, "StateBufferConnector_ms": 0.003124713897705078, "ViewRequirementAgentConnector_ms": 0.08609163761138916}, "num_episodes": 23, "episode_return_max": 100.19999999999933, "episode_return_min": -406.4999999999999, "episode_return_mean": -37.31400000000001, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 396.32893153321004, "num_env_steps_trained_throughput_per_sec": 396.32893153321004, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 9387.133, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9387.086, "sample_time_ms": 1131.151, "learn_time_ms": 8242.366, "learn_throughput": 485.298, "synch_weights_time_ms": 12.342}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-29-05", "timestamp": 1723645745, "time_this_iter_s": 10.132909059524536, "time_total_s": 265.5586750507355, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0adf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 265.5586750507355, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 32.778571428571425, "ram_util_percent": 82.85000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.506025175363929, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 7.977516073650784, "policy_loss": -0.009778879807581978, "vf_loss": 7.983897626210773, "vf_explained_var": 0.009979925962982986, "kl": 0.011324445939613867, "entropy": 1.4618922448662854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2783261620178425, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.513647771764685, "policy_loss": -0.012182600863977636, "vf_loss": 7.522901581456422, "vf_explained_var": 0.05662528386822453, "kl": 0.014643855787345186, "entropy": 1.3452094955419107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 100.19999999999933, "episode_reward_min": -452.8999999999999, "episode_reward_mean": -70.16000000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -816.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 75.1999999999997, "predator_policy": 533.0}, "policy_reward_mean": {"prey_policy": -109.8350000000001, "predator_policy": 74.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.49999999999979283, 38.70000000000029, 46.900000000000446, -63.4000000000011, -28.799999999999592, -19.599999999999774, -32.29999999999957, -42.90000000000009, 16.199999999999907, -18.299999999999507, -8.599999999999659, -60.90000000000149, 18.399999999999974, -12.799999999999558, 25.000000000000103, -55.70000000000076, 46.000000000000384, -50.20000000000002, -137.6000000000012, -12.19999999999961, -261.70000000000005, 18.099999999999966, -72.3000000000017, -9.799999999999573, 34.8000000000002, 35.20000000000023, 42.40000000000044, 23.500000000000032, 39.60000000000029, -55.000000000000725, -144.40000000000006, 25.70000000000011, -53.10000000000081, -32.79999999999998, -195.00000000000014, -19.39999999999951, -43.599999999999575, 14.700000000000001, -128.29999999999993, -363.3, 22.70000000000002, -51.29999999999956, -100.8000000000003, 29.10000000000013, 32.800000000000196, -59.600000000000065, -144.90000000000006, 7.699999999999969, -396.0, 100.19999999999933, 22.40000000000004, 2.600000000000162, -107.70000000000005, 10.500000000000066, -372.90000000000003, -28.299999999999734, 16.49999999999991, 69.50000000000006, 30.60000000000016, -282.7, -27.099999999999696, -26.1000000000006, -181.79999999999987, -406.4999999999999, 36.50000000000025, -84.0999999999998, -59.40000000000042, -95.70000000000147, 24.300000000000065, -15.199999999999996, -17.199999999999505, -95.59999999999997, -6.699999999999829, -11.099999999999735, 31.70000000000018, 14.899999999999993, -201.7000000000007, 17.900000000000226, -1.8999999999996628, 38.90000000000028, -133.89999999999966, 20.699999999999996, -27.199999999999967, -293.2999999999997, -452.8999999999999, -14.400000000000034, -37.29999999999974, -259.0999999999999, -288.8999999999999, -65.80000000000166, -76.79999999999973, -28.199999999999527, -277.6, -37.49999999999997, -287.49999999999994, -301.6, -242.5, 84.20000000000002, -370.2999999999999, -163.2999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -71.50000000000088, 38.00000000000024, -28.299999999999763, 20.000000000000014, 11.899999999999975, -190.00000000000057, -9.399999999999855, -42.99999999999976, -68.80000000000057, -22.299999999999798, -70.30000000000047, -30.399999999999757, -79.90000000000074, -74.50000000000082, -51.399999999999764, 1.9999999999999731, -17.79999999999975, -49.299999999999905, -21.999999999999744, 18.799999999999997, -72.40000000000082, -70.30000000000084, -76.60000000000088, -76.60000000000085, 20.000000000000014, -53.50000000000002, -7.299999999999891, -41.79999999999984, 15.799999999999963, -38.799999999999756, -103.90000000000072, 24.500000000000103, -11.499999999999819, -5.200000000000051, -127.00000000000074, -110.20000000000078, -219.40000000000043, 13.699999999999964, -103.9000000000008, -305.49999999999955, -131.20000000000005, -30.999999999999815, -40.89999999999976, -66.1000000000009, -71.20000000000014, -57.10000000000041, -6.699999999999854, -5.1999999999999265, 23.000000000000114, 5.299999999999965, 17.899999999999988, 10.099999999999996, -15.699999999999754, -11.499999999999819, 20.000000000000014, 20.000000000000014, 11.599999999999964, -55.60000000000002, -69.40000000000074, -145.09999999999982, -120.30000000000004, -70.30000000000089, 20.000000000000014, -57.70000000000034, -72.40000000000083, -38.49999999999978, -70.30000000000089, -226.59999999999997, -90.40000000000006, -57.700000000000166, -15.699999999999747, -89.20000000000078, -30.399999999999928, -26.199999999999747, 17.899999999999988, -201.89999999999984, -82.39999999999982, -390.00000000000017, -217.29999999999998, 6.799999999999967, -3.099999999999958, -137.5000000000007, 3.199999999999986, -24.09999999999998, -183.70000000000047, 9.499999999999964, 5.599999999999968, 20.000000000000014, -23.199999999999747, -80.80000000000004, -35.80000000000002, -55.599999999999994, -265.29999999999984, -70.30000000000072, 20.000000000000014, -351.30000000000007, -349.69999999999993, 20.000000000000014, 75.1999999999997, -13.899999999999796, 14.299999999999965, -63.400000000000816, 20.000000000000014, -241.30000000000044, -30.39999999999975, -53.50000000000019, -0.9999999999999917, -198.00000000000003, -400.9, -163.3000000000006, 20.000000000000014, -32.49999999999975, 20.000000000000014, 20.000000000000014, 48.50000000000021, 20.000000000000014, -9.399999999999855, -547.3999999999999, -386.29999999999995, -36.69999999999985, -51.399999999999764, -24.099999999999746, -521.0000000000001, -92.59999999999995, -281.2000000000004, -287.8999999999999, -315.59999999999997, 20.000000000000014, 9.499999999999964, -5.1999999999999265, -280.89999999999986, -3.0999999999999934, -186.30000000000038, -68.20000000000057, -116.50000000000077, -57.70000000000048, 20.000000000000014, -37.899999999999956, -60.29999999999984, -32.49999999999975, -36.699999999999754, -288.0, -76.60000000000004, -7.300000000000004, -50.39999999999978, -87.10000000000085, 20.000000000000014, 3.799999999999985, 17.900000000000013, 5.899999999999967, -21.99999999999976, -447.2, -53.499999999999766, 10.400000000000023, -8.500000000000028, -108.20000000000002, -3.6999999999999957, 17.899999999999988, 20.000000000000014, -80.20000000000006, -132.70000000000007, -64.30000000000089, 20.000000000000014, -27.100000000000012, -87.10000000000076, -271.8, -313.4999999999999, -385.8, -581.1, -47.19999999999976, -79.20000000000002, -110.20000000000049, -3.099999999999965, -423.6, -422.5000000000002, -507.1, -342.8, -47.19999999999976, -97.60000000000082, -125.89999999999993, -102.90000000000002, -51.39999999999977, -38.799999999999756, -489.79999999999995, -684.8, -368.49999999999966, 20.000000000000014, -498.30000000000007, -356.2, -400.0, -565.6000000000001, -694.4, -517.1, -816.0, -38.800000000000026, -280.2999999999999, -269.0, -164.39999999999992, -132.8999999999999], "policy_predator_policy_reward": [44.0, 7.0, 29.0, 0.0, 6.0, 9.0, 36.0, 100.0, 53.0, 30.0, 17.0, 56.0, 54.0, 24.0, 46.0, 37.0, 26.0, 6.0, 20.0, 33.0, 44.0, 1.0, 40.0, 46.0, 46.0, 29.0, 23.0, 25.0, 41.0, 10.0, 28.0, 59.0, 8.0, 25.0, 12.0, 70.0, 129.0, 63.0, 55.0, 23.0, 163.0, 12.0, 41.0, 49.0, 1.0, 64.0, 41.0, 13.0, 12.0, 5.0, 8.0, 4.0, 14.0, 34.0, 0.0, 15.0, 4.0, 4.0, 42.0, 28.0, 101.0, 20.0, 38.0, 38.0, 48.0, 29.0, 43.0, 33.0, 104.0, 18.0, 17.0, 37.0, 76.0, 0.0, 22.0, 1.0, 27.0, 129.0, 7.0, 237.0, 11.0, 8.0, 8.0, 75.0, 6.0, 101.0, 5.0, 9.0, 19.0, 17.0, 50.0, 7.0, 21.0, 155.0, 43.0, 15.0, 83.0, 222.0, 5.0, 0.0, 13.0, 9.0, 7.0, 39.0, 140.0, 24.0, 33.0, 32.0, 0.0, 226.0, 88.0, 27.0, 25.0, 4.0, 1.0, 0.0, 14.0, 6.0, 406.0, 245.0, 36.0, 25.0, 222.0, 297.0, 177.0, 15.0, 182.0, 15.0, 5.0, 2.0, 190.0, 12.0, 11.0, 119.0, 13.0, 76.0, 27.0, 35.0, 70.0, 13.0, 27.0, 25.0, 181.0, 88.0, 35.0, 16.0, 11.0, 45.0, 1.0, 9.0, 23.0, 8.0, 264.0, 35.0, 9.0, 7.0, 110.0, 0.0, 1.0, 0.0, 35.0, 44.0, 26.0, 39.0, 43.0, 44.0, 0.0, 292.0, 8.0, 506.0, 76.0, 36.0, 9.0, 67.0, 296.0, 291.0, 480.0, 81.0, 22.0, 57.0, 65.0, 87.0, 19.0, 43.0, 439.0, 458.0, 129.0, 182.0, 119.0, 448.0, 290.0, 374.0, 436.0, 533.0, 457.0, 482.0, 28.0, 151.0, 32.0, 102.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5439428344455475, "mean_inference_ms": 1.4021282110055375, "mean_action_processing_ms": 0.2319175456258613, "mean_env_wait_ms": 0.18079221272866838, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005352377891540527, "StateBufferConnector_ms": 0.0032486915588378906, "ViewRequirementAgentConnector_ms": 0.08917391300201416}, "num_episodes": 18, "episode_return_max": 100.19999999999933, "episode_return_min": -452.8999999999999, "episode_return_mean": -70.16000000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 379.22139438433624, "num_env_steps_trained_throughput_per_sec": 379.22139438433624, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 9507.155, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9507.105, "sample_time_ms": 1165.497, "learn_time_ms": 8328.009, "learn_throughput": 480.307, "synch_weights_time_ms": 12.386}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-29-15", "timestamp": 1723645755, "time_this_iter_s": 10.562860012054443, "time_total_s": 276.1215350627899, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39aef9790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 276.1215350627899, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 39.10666666666667, "ram_util_percent": 83.43999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6633643375502691, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 7.189710377889966, "policy_loss": -0.008625586378442312, "vf_loss": 7.195441552066298, "vf_explained_var": 0.027775670643205994, "kl": 0.009647999912421773, "entropy": 1.4731452799347973, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.087044198267044, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.153886802360494, "policy_loss": -0.012949090404435992, "vf_loss": 8.163653980234944, "vf_explained_var": 0.036490488367736655, "kl": 0.015909559768047386, "entropy": 1.2855293333845794, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 235.59999999999957, "episode_reward_min": -509.39999999999986, "episode_reward_mean": -86.39200000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -848.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 75.1999999999997, "predator_policy": 595.0}, "policy_reward_mean": {"prey_policy": -150.07600000000005, "predator_policy": 106.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-137.6000000000012, -12.19999999999961, -261.70000000000005, 18.099999999999966, -72.3000000000017, -9.799999999999573, 34.8000000000002, 35.20000000000023, 42.40000000000044, 23.500000000000032, 39.60000000000029, -55.000000000000725, -144.40000000000006, 25.70000000000011, -53.10000000000081, -32.79999999999998, -195.00000000000014, -19.39999999999951, -43.599999999999575, 14.700000000000001, -128.29999999999993, -363.3, 22.70000000000002, -51.29999999999956, -100.8000000000003, 29.10000000000013, 32.800000000000196, -59.600000000000065, -144.90000000000006, 7.699999999999969, -396.0, 100.19999999999933, 22.40000000000004, 2.600000000000162, -107.70000000000005, 10.500000000000066, -372.90000000000003, -28.299999999999734, 16.49999999999991, 69.50000000000006, 30.60000000000016, -282.7, -27.099999999999696, -26.1000000000006, -181.79999999999987, -406.4999999999999, 36.50000000000025, -84.0999999999998, -59.40000000000042, -95.70000000000147, 24.300000000000065, -15.199999999999996, -17.199999999999505, -95.59999999999997, -6.699999999999829, -11.099999999999735, 31.70000000000018, 14.899999999999993, -201.7000000000007, 17.900000000000226, -1.8999999999996628, 38.90000000000028, -133.89999999999966, 20.699999999999996, -27.199999999999967, -293.2999999999997, -452.8999999999999, -14.400000000000034, -37.29999999999974, -259.0999999999999, -288.8999999999999, -65.80000000000166, -76.79999999999973, -28.199999999999527, -277.6, -37.49999999999997, -287.49999999999994, -301.6, -242.5, 84.20000000000002, -370.2999999999999, -163.2999999999998, -100.30000000000027, 57.100000000000264, -81.89999999999986, -29.799999999999585, -362.8000000000003, -94.40000000000128, -373.6, -141.20000000000007, -201.49999999999997, -77.70000000000044, 116.20000000000013, 6.999999999999909, -81.69999999999996, 235.59999999999957, 31.799999999999983, -101.89999999999992, -509.39999999999986, -117.49999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-110.20000000000078, -219.40000000000043, 13.699999999999964, -103.9000000000008, -305.49999999999955, -131.20000000000005, -30.999999999999815, -40.89999999999976, -66.1000000000009, -71.20000000000014, -57.10000000000041, -6.699999999999854, -5.1999999999999265, 23.000000000000114, 5.299999999999965, 17.899999999999988, 10.099999999999996, -15.699999999999754, -11.499999999999819, 20.000000000000014, 20.000000000000014, 11.599999999999964, -55.60000000000002, -69.40000000000074, -145.09999999999982, -120.30000000000004, -70.30000000000089, 20.000000000000014, -57.70000000000034, -72.40000000000083, -38.49999999999978, -70.30000000000089, -226.59999999999997, -90.40000000000006, -57.700000000000166, -15.699999999999747, -89.20000000000078, -30.399999999999928, -26.199999999999747, 17.899999999999988, -201.89999999999984, -82.39999999999982, -390.00000000000017, -217.29999999999998, 6.799999999999967, -3.099999999999958, -137.5000000000007, 3.199999999999986, -24.09999999999998, -183.70000000000047, 9.499999999999964, 5.599999999999968, 20.000000000000014, -23.199999999999747, -80.80000000000004, -35.80000000000002, -55.599999999999994, -265.29999999999984, -70.30000000000072, 20.000000000000014, -351.30000000000007, -349.69999999999993, 20.000000000000014, 75.1999999999997, -13.899999999999796, 14.299999999999965, -63.400000000000816, 20.000000000000014, -241.30000000000044, -30.39999999999975, -53.50000000000019, -0.9999999999999917, -198.00000000000003, -400.9, -163.3000000000006, 20.000000000000014, -32.49999999999975, 20.000000000000014, 20.000000000000014, 48.50000000000021, 20.000000000000014, -9.399999999999855, -547.3999999999999, -386.29999999999995, -36.69999999999985, -51.399999999999764, -24.099999999999746, -521.0000000000001, -92.59999999999995, -281.2000000000004, -287.8999999999999, -315.59999999999997, 20.000000000000014, 9.499999999999964, -5.1999999999999265, -280.89999999999986, -3.0999999999999934, -186.30000000000038, -68.20000000000057, -116.50000000000077, -57.70000000000048, 20.000000000000014, -37.899999999999956, -60.29999999999984, -32.49999999999975, -36.699999999999754, -288.0, -76.60000000000004, -7.300000000000004, -50.39999999999978, -87.10000000000085, 20.000000000000014, 3.799999999999985, 17.900000000000013, 5.899999999999967, -21.99999999999976, -447.2, -53.499999999999766, 10.400000000000023, -8.500000000000028, -108.20000000000002, -3.6999999999999957, 17.899999999999988, 20.000000000000014, -80.20000000000006, -132.70000000000007, -64.30000000000089, 20.000000000000014, -27.100000000000012, -87.10000000000076, -271.8, -313.4999999999999, -385.8, -581.1, -47.19999999999976, -79.20000000000002, -110.20000000000049, -3.099999999999965, -423.6, -422.5000000000002, -507.1, -342.8, -47.19999999999976, -97.60000000000082, -125.89999999999993, -102.90000000000002, -51.39999999999977, -38.799999999999756, -489.79999999999995, -684.8, -368.49999999999966, 20.000000000000014, -498.30000000000007, -356.2, -400.0, -565.6000000000001, -694.4, -517.1, -816.0, -38.800000000000026, -280.2999999999999, -269.0, -164.39999999999992, -132.8999999999999, -276.3, -57.99999999999979, -42.99999999999976, -569.9, -366.79999999999984, -24.099999999999746, -87.10000000000085, -45.6999999999998, -421.99999999999994, -280.8000000000004, -311.50000000000034, -40.89999999999976, -536.0, -479.6, -358.5000000000002, -68.70000000000002, -627.5000000000001, -396.0, 11.599999999999964, -376.3000000000003, -661.3, 3.499999999999968, -9.400000000000027, -13.599999999999783, -82.90000000000043, -159.79999999999995, -848.9, 24.500000000000096, -26.799999999999756, -288.4, -83.80000000000004, -163.09999999999982, -623.6, -518.7999999999998, -243.0000000000003, -338.49999999999994], "policy_predator_policy_reward": [129.0, 63.0, 55.0, 23.0, 163.0, 12.0, 41.0, 49.0, 1.0, 64.0, 41.0, 13.0, 12.0, 5.0, 8.0, 4.0, 14.0, 34.0, 0.0, 15.0, 4.0, 4.0, 42.0, 28.0, 101.0, 20.0, 38.0, 38.0, 48.0, 29.0, 43.0, 33.0, 104.0, 18.0, 17.0, 37.0, 76.0, 0.0, 22.0, 1.0, 27.0, 129.0, 7.0, 237.0, 11.0, 8.0, 8.0, 75.0, 6.0, 101.0, 5.0, 9.0, 19.0, 17.0, 50.0, 7.0, 21.0, 155.0, 43.0, 15.0, 83.0, 222.0, 5.0, 0.0, 13.0, 9.0, 7.0, 39.0, 140.0, 24.0, 33.0, 32.0, 0.0, 226.0, 88.0, 27.0, 25.0, 4.0, 1.0, 0.0, 14.0, 6.0, 406.0, 245.0, 36.0, 25.0, 222.0, 297.0, 177.0, 15.0, 182.0, 15.0, 5.0, 2.0, 190.0, 12.0, 11.0, 119.0, 13.0, 76.0, 27.0, 35.0, 70.0, 13.0, 27.0, 25.0, 181.0, 88.0, 35.0, 16.0, 11.0, 45.0, 1.0, 9.0, 23.0, 8.0, 264.0, 35.0, 9.0, 7.0, 110.0, 0.0, 1.0, 0.0, 35.0, 44.0, 26.0, 39.0, 43.0, 44.0, 0.0, 292.0, 8.0, 506.0, 76.0, 36.0, 9.0, 67.0, 296.0, 291.0, 480.0, 81.0, 22.0, 57.0, 65.0, 87.0, 19.0, 43.0, 439.0, 458.0, 129.0, 182.0, 119.0, 448.0, 290.0, 374.0, 436.0, 533.0, 457.0, 482.0, 28.0, 151.0, 32.0, 102.0, 22.0, 212.0, 341.0, 329.0, 288.0, 21.0, 59.0, 44.0, 244.0, 96.0, 130.0, 128.0, 289.0, 353.0, 183.0, 103.0, 508.0, 314.0, 121.0, 166.0, 357.0, 417.0, 4.0, 26.0, 5.0, 156.0, 465.0, 595.0, 232.0, 115.0, 128.0, 17.0, 567.0, 66.0, 147.0, 317.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5452622425719514, "mean_inference_ms": 1.4059962483447561, "mean_action_processing_ms": 0.2351680523636608, "mean_env_wait_ms": 0.1811332344442706, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005354523658752441, "StateBufferConnector_ms": 0.003163933753967285, "ViewRequirementAgentConnector_ms": 0.09077417850494385}, "num_episodes": 18, "episode_return_max": 235.59999999999957, "episode_return_min": -509.39999999999986, "episode_return_mean": -86.39200000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.96887208323704, "num_env_steps_trained_throughput_per_sec": 339.96887208323704, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 9740.842, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9740.79, "sample_time_ms": 1181.393, "learn_time_ms": 8545.551, "learn_throughput": 468.08, "synch_weights_time_ms": 12.443}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-29-27", "timestamp": 1723645767, "time_this_iter_s": 11.782036066055298, "time_total_s": 287.9035711288452, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b098f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 287.9035711288452, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 46.93529411764706, "ram_util_percent": 83.57647058823531}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7388237757026834, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 5.9781858434122075, "policy_loss": -0.008933495339277205, "vf_loss": 5.984345117700163, "vf_explained_var": 0.06169974229953907, "kl": 0.009247407828139743, "entropy": 1.4722466238592036, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.23868550998824, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 8.002388029754478, "policy_loss": -0.007640609177317293, "vf_loss": 8.008307418369112, "vf_explained_var": 0.003965818598156884, "kl": 0.008605936716698636, "entropy": 1.298426657126694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 235.59999999999957, "episode_reward_min": -509.39999999999986, "episode_reward_mean": -88.15599999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -848.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 75.1999999999997, "predator_policy": 595.0}, "policy_reward_mean": {"prey_policy": -170.29800000000003, "predator_policy": 126.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.599999999999575, 14.700000000000001, -128.29999999999993, -363.3, 22.70000000000002, -51.29999999999956, -100.8000000000003, 29.10000000000013, 32.800000000000196, -59.600000000000065, -144.90000000000006, 7.699999999999969, -396.0, 100.19999999999933, 22.40000000000004, 2.600000000000162, -107.70000000000005, 10.500000000000066, -372.90000000000003, -28.299999999999734, 16.49999999999991, 69.50000000000006, 30.60000000000016, -282.7, -27.099999999999696, -26.1000000000006, -181.79999999999987, -406.4999999999999, 36.50000000000025, -84.0999999999998, -59.40000000000042, -95.70000000000147, 24.300000000000065, -15.199999999999996, -17.199999999999505, -95.59999999999997, -6.699999999999829, -11.099999999999735, 31.70000000000018, 14.899999999999993, -201.7000000000007, 17.900000000000226, -1.8999999999996628, 38.90000000000028, -133.89999999999966, 20.699999999999996, -27.199999999999967, -293.2999999999997, -452.8999999999999, -14.400000000000034, -37.29999999999974, -259.0999999999999, -288.8999999999999, -65.80000000000166, -76.79999999999973, -28.199999999999527, -277.6, -37.49999999999997, -287.49999999999994, -301.6, -242.5, 84.20000000000002, -370.2999999999999, -163.2999999999998, -100.30000000000027, 57.100000000000264, -81.89999999999986, -29.799999999999585, -362.8000000000003, -94.40000000000128, -373.6, -141.20000000000007, -201.49999999999997, -77.70000000000044, 116.20000000000013, 6.999999999999909, -81.69999999999996, 235.59999999999957, 31.799999999999983, -101.89999999999992, -509.39999999999986, -117.49999999999994, -22.09999999999964, -31.099999999999554, -391.69999999999993, -55.19999999999993, 6.19999999999998, -5.4999999999997655, 90.49999999999955, 2.6000000000002155, -70.90000000000018, 33.00000000000009, 105.99999999999966, 24.200000000000003, -348.5999999999999, 13.00000000000015, -34.6999999999997, 5.099999999999987, -161.70000000000115, -109.50000000000037], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-89.20000000000078, -30.399999999999928, -26.199999999999747, 17.899999999999988, -201.89999999999984, -82.39999999999982, -390.00000000000017, -217.29999999999998, 6.799999999999967, -3.099999999999958, -137.5000000000007, 3.199999999999986, -24.09999999999998, -183.70000000000047, 9.499999999999964, 5.599999999999968, 20.000000000000014, -23.199999999999747, -80.80000000000004, -35.80000000000002, -55.599999999999994, -265.29999999999984, -70.30000000000072, 20.000000000000014, -351.30000000000007, -349.69999999999993, 20.000000000000014, 75.1999999999997, -13.899999999999796, 14.299999999999965, -63.400000000000816, 20.000000000000014, -241.30000000000044, -30.39999999999975, -53.50000000000019, -0.9999999999999917, -198.00000000000003, -400.9, -163.3000000000006, 20.000000000000014, -32.49999999999975, 20.000000000000014, 20.000000000000014, 48.50000000000021, 20.000000000000014, -9.399999999999855, -547.3999999999999, -386.29999999999995, -36.69999999999985, -51.399999999999764, -24.099999999999746, -521.0000000000001, -92.59999999999995, -281.2000000000004, -287.8999999999999, -315.59999999999997, 20.000000000000014, 9.499999999999964, -5.1999999999999265, -280.89999999999986, -3.0999999999999934, -186.30000000000038, -68.20000000000057, -116.50000000000077, -57.70000000000048, 20.000000000000014, -37.899999999999956, -60.29999999999984, -32.49999999999975, -36.699999999999754, -288.0, -76.60000000000004, -7.300000000000004, -50.39999999999978, -87.10000000000085, 20.000000000000014, 3.799999999999985, 17.900000000000013, 5.899999999999967, -21.99999999999976, -447.2, -53.499999999999766, 10.400000000000023, -8.500000000000028, -108.20000000000002, -3.6999999999999957, 17.899999999999988, 20.000000000000014, -80.20000000000006, -132.70000000000007, -64.30000000000089, 20.000000000000014, -27.100000000000012, -87.10000000000076, -271.8, -313.4999999999999, -385.8, -581.1, -47.19999999999976, -79.20000000000002, -110.20000000000049, -3.099999999999965, -423.6, -422.5000000000002, -507.1, -342.8, -47.19999999999976, -97.60000000000082, -125.89999999999993, -102.90000000000002, -51.39999999999977, -38.799999999999756, -489.79999999999995, -684.8, -368.49999999999966, 20.000000000000014, -498.30000000000007, -356.2, -400.0, -565.6000000000001, -694.4, -517.1, -816.0, -38.800000000000026, -280.2999999999999, -269.0, -164.39999999999992, -132.8999999999999, -276.3, -57.99999999999979, -42.99999999999976, -569.9, -366.79999999999984, -24.099999999999746, -87.10000000000085, -45.6999999999998, -421.99999999999994, -280.8000000000004, -311.50000000000034, -40.89999999999976, -536.0, -479.6, -358.5000000000002, -68.70000000000002, -627.5000000000001, -396.0, 11.599999999999964, -376.3000000000003, -661.3, 3.499999999999968, -9.400000000000027, -13.599999999999783, -82.90000000000043, -159.79999999999995, -848.9, 24.500000000000096, -26.799999999999756, -288.4, -83.80000000000004, -163.09999999999982, -623.6, -518.7999999999998, -243.0000000000003, -338.49999999999994, 11.899999999999947, -238.00000000000057, -93.40000000000035, -9.699999999999918, -349.69999999999993, -624.0, -9.399999999999855, -254.8, -324.6, 15.799999999999963, 17.899999999999977, -114.40000000000077, 45.200000000000244, -604.7, -28.29999999999975, -3.099999999999958, -47.19999999999976, -194.7000000000001, -458.4, -34.59999999999987, -779.8, -71.20000000000003, -249.8, -27.99999999999976, -351.0999999999999, -348.5, -3.099999999999958, -145.90000000000035, -66.09999999999994, -34.59999999999987, -38.799999999999905, -3.100000000000047, -174.40000000000055, -172.3000000000006, -259.70000000000005, -143.80000000000024], "policy_predator_policy_reward": [76.0, 0.0, 22.0, 1.0, 27.0, 129.0, 7.0, 237.0, 11.0, 8.0, 8.0, 75.0, 6.0, 101.0, 5.0, 9.0, 19.0, 17.0, 50.0, 7.0, 21.0, 155.0, 43.0, 15.0, 83.0, 222.0, 5.0, 0.0, 13.0, 9.0, 7.0, 39.0, 140.0, 24.0, 33.0, 32.0, 0.0, 226.0, 88.0, 27.0, 25.0, 4.0, 1.0, 0.0, 14.0, 6.0, 406.0, 245.0, 36.0, 25.0, 222.0, 297.0, 177.0, 15.0, 182.0, 15.0, 5.0, 2.0, 190.0, 12.0, 11.0, 119.0, 13.0, 76.0, 27.0, 35.0, 70.0, 13.0, 27.0, 25.0, 181.0, 88.0, 35.0, 16.0, 11.0, 45.0, 1.0, 9.0, 23.0, 8.0, 264.0, 35.0, 9.0, 7.0, 110.0, 0.0, 1.0, 0.0, 35.0, 44.0, 26.0, 39.0, 43.0, 44.0, 0.0, 292.0, 8.0, 506.0, 76.0, 36.0, 9.0, 67.0, 296.0, 291.0, 480.0, 81.0, 22.0, 57.0, 65.0, 87.0, 19.0, 43.0, 439.0, 458.0, 129.0, 182.0, 119.0, 448.0, 290.0, 374.0, 436.0, 533.0, 457.0, 482.0, 28.0, 151.0, 32.0, 102.0, 22.0, 212.0, 341.0, 329.0, 288.0, 21.0, 59.0, 44.0, 244.0, 96.0, 130.0, 128.0, 289.0, 353.0, 183.0, 103.0, 508.0, 314.0, 121.0, 166.0, 357.0, 417.0, 4.0, 26.0, 5.0, 156.0, 465.0, 595.0, 232.0, 115.0, 128.0, 17.0, 567.0, 66.0, 147.0, 317.0, 151.0, 53.0, 36.0, 36.0, 533.0, 49.0, 175.0, 34.0, 99.0, 216.0, 38.0, 53.0, 367.0, 283.0, 23.0, 11.0, 43.0, 128.0, 287.0, 239.0, 455.0, 502.0, 160.0, 142.0, 289.0, 62.0, 69.0, 93.0, 22.0, 44.0, 23.0, 24.0, 70.0, 115.0, 142.0, 152.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5470322770942321, "mean_inference_ms": 1.4108888636075643, "mean_action_processing_ms": 0.23845297491272036, "mean_env_wait_ms": 0.18160827957200443, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0048972368240356445, "StateBufferConnector_ms": 0.0031703710556030273, "ViewRequirementAgentConnector_ms": 0.09382152557373047}, "num_episodes": 18, "episode_return_max": 235.59999999999957, "episode_return_min": -509.39999999999986, "episode_return_mean": -88.15599999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.4210909797677, "num_env_steps_trained_throughput_per_sec": 364.4210909797677, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 9897.082, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9897.03, "sample_time_ms": 1194.617, "learn_time_ms": 8688.512, "learn_throughput": 460.378, "synch_weights_time_ms": 12.485}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-29-38", "timestamp": 1723645778, "time_this_iter_s": 11.015173196792603, "time_total_s": 298.9187443256378, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b09b1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 298.9187443256378, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 40.85, "ram_util_percent": 83.2375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.12963320776899, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.901378556407949, "policy_loss": -0.01188893183873641, "vf_loss": 3.9098031051575193, "vf_explained_var": 0.0730474781422388, "kl": 0.01154789092606823, "entropy": 1.4671651948696722, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0037432440689633, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.8344071037554865, "policy_loss": -0.004387428586139644, "vf_loss": 4.836904997548098, "vf_explained_var": -0.0003091750636933342, "kl": 0.00944766620977755, "entropy": 1.3121755944357978, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 235.59999999999957, "episode_reward_min": -509.39999999999986, "episode_reward_mean": -73.91400000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -848.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.200000000000244, "predator_policy": 595.0}, "policy_reward_mean": {"prey_policy": -165.687, "predator_policy": 128.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-406.4999999999999, 36.50000000000025, -84.0999999999998, -59.40000000000042, -95.70000000000147, 24.300000000000065, -15.199999999999996, -17.199999999999505, -95.59999999999997, -6.699999999999829, -11.099999999999735, 31.70000000000018, 14.899999999999993, -201.7000000000007, 17.900000000000226, -1.8999999999996628, 38.90000000000028, -133.89999999999966, 20.699999999999996, -27.199999999999967, -293.2999999999997, -452.8999999999999, -14.400000000000034, -37.29999999999974, -259.0999999999999, -288.8999999999999, -65.80000000000166, -76.79999999999973, -28.199999999999527, -277.6, -37.49999999999997, -287.49999999999994, -301.6, -242.5, 84.20000000000002, -370.2999999999999, -163.2999999999998, -100.30000000000027, 57.100000000000264, -81.89999999999986, -29.799999999999585, -362.8000000000003, -94.40000000000128, -373.6, -141.20000000000007, -201.49999999999997, -77.70000000000044, 116.20000000000013, 6.999999999999909, -81.69999999999996, 235.59999999999957, 31.799999999999983, -101.89999999999992, -509.39999999999986, -117.49999999999994, -22.09999999999964, -31.099999999999554, -391.69999999999993, -55.19999999999993, 6.19999999999998, -5.4999999999997655, 90.49999999999955, 2.6000000000002155, -70.90000000000018, 33.00000000000009, 105.99999999999966, 24.200000000000003, -348.5999999999999, 13.00000000000015, -34.6999999999997, 5.099999999999987, -161.70000000000115, -109.50000000000037, -53.60000000000015, 26.300000000000093, 25.800000000000075, -242.19999999999982, -142.90000000000023, 15.999999999999932, -36.199999999999726, -3.1000000000000827, 19.999999999999982, -122.0000000000008, -39.89999999999994, 1.5000000000001934, -6.499999999999847, 27.000000000000117, 38.90000000000028, 29.7000000000004, -104.70000000000155, -17.999999999999666, 124.39999999999978, -16.8999999999995, -8.199999999999823, -13.899999999999778, 34.50000000000022, 9.200000000000035, -100.70000000000007, 21.400000000000006, 3.2000000000001068], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-287.8999999999999, -315.59999999999997, 20.000000000000014, 9.499999999999964, -5.1999999999999265, -280.89999999999986, -3.0999999999999934, -186.30000000000038, -68.20000000000057, -116.50000000000077, -57.70000000000048, 20.000000000000014, -37.899999999999956, -60.29999999999984, -32.49999999999975, -36.699999999999754, -288.0, -76.60000000000004, -7.300000000000004, -50.39999999999978, -87.10000000000085, 20.000000000000014, 3.799999999999985, 17.900000000000013, 5.899999999999967, -21.99999999999976, -447.2, -53.499999999999766, 10.400000000000023, -8.500000000000028, -108.20000000000002, -3.6999999999999957, 17.899999999999988, 20.000000000000014, -80.20000000000006, -132.70000000000007, -64.30000000000089, 20.000000000000014, -27.100000000000012, -87.10000000000076, -271.8, -313.4999999999999, -385.8, -581.1, -47.19999999999976, -79.20000000000002, -110.20000000000049, -3.099999999999965, -423.6, -422.5000000000002, -507.1, -342.8, -47.19999999999976, -97.60000000000082, -125.89999999999993, -102.90000000000002, -51.39999999999977, -38.799999999999756, -489.79999999999995, -684.8, -368.49999999999966, 20.000000000000014, -498.30000000000007, -356.2, -400.0, -565.6000000000001, -694.4, -517.1, -816.0, -38.800000000000026, -280.2999999999999, -269.0, -164.39999999999992, -132.8999999999999, -276.3, -57.99999999999979, -42.99999999999976, -569.9, -366.79999999999984, -24.099999999999746, -87.10000000000085, -45.6999999999998, -421.99999999999994, -280.8000000000004, -311.50000000000034, -40.89999999999976, -536.0, -479.6, -358.5000000000002, -68.70000000000002, -627.5000000000001, -396.0, 11.599999999999964, -376.3000000000003, -661.3, 3.499999999999968, -9.400000000000027, -13.599999999999783, -82.90000000000043, -159.79999999999995, -848.9, 24.500000000000096, -26.799999999999756, -288.4, -83.80000000000004, -163.09999999999982, -623.6, -518.7999999999998, -243.0000000000003, -338.49999999999994, 11.899999999999947, -238.00000000000057, -93.40000000000035, -9.699999999999918, -349.69999999999993, -624.0, -9.399999999999855, -254.8, -324.6, 15.799999999999963, 17.899999999999977, -114.40000000000077, 45.200000000000244, -604.7, -28.29999999999975, -3.099999999999958, -47.19999999999976, -194.7000000000001, -458.4, -34.59999999999987, -779.8, -71.20000000000003, -249.8, -27.99999999999976, -351.0999999999999, -348.5, -3.099999999999958, -145.90000000000035, -66.09999999999994, -34.59999999999987, -38.799999999999905, -3.100000000000047, -174.40000000000055, -172.3000000000006, -259.70000000000005, -143.80000000000024, -34.599999999999916, -106.00000000000057, -26.199999999999747, 9.499999999999975, 5.299999999999969, -227.49999999999997, -193.00000000000003, -269.2, -38.799999999999756, -300.1000000000001, 13.100000000000032, -42.09999999999976, -51.399999999999764, -133.7999999999999, -19.899999999999995, -26.199999999999747, 20.000000000000014, -42.99999999999976, -28.29999999999975, -270.70000000000016, -47.19999999999976, -308.7, -7.299999999999962, -26.199999999999747, -43.59999999999978, -49.899999999999835, -21.99999999999978, -21.999999999999744, -3.099999999999958, 20.000000000000014, 39.80000000000025, -171.10000000000045, -152.20000000000067, -74.50000000000088, -7.899999999999949, -66.10000000000034, -336.59999999999985, 20.000000000000014, -32.49999999999975, -30.39999999999975, -11.49999999999999, -36.69999999999976, -34.59999999999975, -257.3000000000002, -47.19999999999977, 43.70000000000024, -30.399999999999757, -6.399999999999958, -229.10000000000016, -623.6, 22.700000000000053, -28.29999999999975, -197.70000000000027, 17.899999999999988], "policy_predator_policy_reward": [182.0, 15.0, 5.0, 2.0, 190.0, 12.0, 11.0, 119.0, 13.0, 76.0, 27.0, 35.0, 70.0, 13.0, 27.0, 25.0, 181.0, 88.0, 35.0, 16.0, 11.0, 45.0, 1.0, 9.0, 23.0, 8.0, 264.0, 35.0, 9.0, 7.0, 110.0, 0.0, 1.0, 0.0, 35.0, 44.0, 26.0, 39.0, 43.0, 44.0, 0.0, 292.0, 8.0, 506.0, 76.0, 36.0, 9.0, 67.0, 296.0, 291.0, 480.0, 81.0, 22.0, 57.0, 65.0, 87.0, 19.0, 43.0, 439.0, 458.0, 129.0, 182.0, 119.0, 448.0, 290.0, 374.0, 436.0, 533.0, 457.0, 482.0, 28.0, 151.0, 32.0, 102.0, 22.0, 212.0, 341.0, 329.0, 288.0, 21.0, 59.0, 44.0, 244.0, 96.0, 130.0, 128.0, 289.0, 353.0, 183.0, 103.0, 508.0, 314.0, 121.0, 166.0, 357.0, 417.0, 4.0, 26.0, 5.0, 156.0, 465.0, 595.0, 232.0, 115.0, 128.0, 17.0, 567.0, 66.0, 147.0, 317.0, 151.0, 53.0, 36.0, 36.0, 533.0, 49.0, 175.0, 34.0, 99.0, 216.0, 38.0, 53.0, 367.0, 283.0, 23.0, 11.0, 43.0, 128.0, 287.0, 239.0, 455.0, 502.0, 160.0, 142.0, 289.0, 62.0, 69.0, 93.0, 22.0, 44.0, 23.0, 24.0, 70.0, 115.0, 142.0, 152.0, 33.0, 54.0, 21.0, 22.0, 103.0, 145.0, 197.0, 23.0, 28.0, 168.0, 10.0, 35.0, 61.0, 88.0, 41.0, 2.0, 30.0, 13.0, 23.0, 154.0, 204.0, 112.0, 11.0, 24.0, 57.0, 30.0, 38.0, 33.0, 11.0, 11.0, 77.0, 84.0, 62.0, 60.0, 21.0, 35.0, 256.0, 185.0, 11.0, 35.0, 21.0, 19.0, 120.0, 158.0, 13.0, 25.0, 29.0, 17.0, 366.0, 386.0, 13.0, 14.0, 65.0, 118.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5503186115436131, "mean_inference_ms": 1.4201500879992919, "mean_action_processing_ms": 0.24284178406175158, "mean_env_wait_ms": 0.18230256144017104, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00480043888092041, "StateBufferConnector_ms": 0.003931403160095215, "ViewRequirementAgentConnector_ms": 0.09973156452178955}, "num_episodes": 27, "episode_return_max": 235.59999999999957, "episode_return_min": -509.39999999999986, "episode_return_mean": -73.91400000000002, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.70138418055996, "num_env_steps_trained_throughput_per_sec": 404.70138418055996, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 9936.609, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9936.558, "sample_time_ms": 1206.751, "learn_time_ms": 8715.793, "learn_throughput": 458.937, "synch_weights_time_ms": 12.598}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-29-48", "timestamp": 1723645788, "time_this_iter_s": 9.889137983322144, "time_total_s": 308.80788230895996, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b09bb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 308.80788230895996, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 34.16428571428572, "ram_util_percent": 82.93571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5544376414131236, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.087092954456491, "policy_loss": -0.00981399344832257, "vf_loss": 3.095063557574358, "vf_explained_var": 0.06261199469919558, "kl": 0.006144610397584397, "entropy": 1.4708556703789524, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.550021604633836, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.1799969284622756, "policy_loss": -0.004774305685521867, "vf_loss": 3.1831207195917766, "vf_explained_var": 0.01001887387699551, "kl": 0.008252564055147274, "entropy": 1.298925229796657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 235.59999999999957, "episode_reward_min": -509.39999999999986, "episode_reward_mean": -65.34200000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -848.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 45.200000000000244, "predator_policy": 595.0}, "policy_reward_mean": {"prey_policy": -160.51600000000002, "predator_policy": 127.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.699999999999996, -27.199999999999967, -293.2999999999997, -452.8999999999999, -14.400000000000034, -37.29999999999974, -259.0999999999999, -288.8999999999999, -65.80000000000166, -76.79999999999973, -28.199999999999527, -277.6, -37.49999999999997, -287.49999999999994, -301.6, -242.5, 84.20000000000002, -370.2999999999999, -163.2999999999998, -100.30000000000027, 57.100000000000264, -81.89999999999986, -29.799999999999585, -362.8000000000003, -94.40000000000128, -373.6, -141.20000000000007, -201.49999999999997, -77.70000000000044, 116.20000000000013, 6.999999999999909, -81.69999999999996, 235.59999999999957, 31.799999999999983, -101.89999999999992, -509.39999999999986, -117.49999999999994, -22.09999999999964, -31.099999999999554, -391.69999999999993, -55.19999999999993, 6.19999999999998, -5.4999999999997655, 90.49999999999955, 2.6000000000002155, -70.90000000000018, 33.00000000000009, 105.99999999999966, 24.200000000000003, -348.5999999999999, 13.00000000000015, -34.6999999999997, 5.099999999999987, -161.70000000000115, -109.50000000000037, -53.60000000000015, 26.300000000000093, 25.800000000000075, -242.19999999999982, -142.90000000000023, 15.999999999999932, -36.199999999999726, -3.1000000000000827, 19.999999999999982, -122.0000000000008, -39.89999999999994, 1.5000000000001934, -6.499999999999847, 27.000000000000117, 38.90000000000028, 29.7000000000004, -104.70000000000155, -17.999999999999666, 124.39999999999978, -16.8999999999995, -8.199999999999823, -13.899999999999778, 34.50000000000022, 9.200000000000035, -100.70000000000007, 21.400000000000006, 3.2000000000001068, 24.300000000000065, -62.600000000001344, 46.800000000000445, -64.69999999999959, -6.099999999999724, 27.400000000000116, -58.600000000000634, -2.8999999999998014, -5.199999999999685, 18.599999999999962, -18.29999999999967, 53.80000000000025, -18.299999999999507, -116.20000000000073, 40.80000000000031, 34.00000000000021, -27.199999999999903, 26.800000000000114], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-64.30000000000089, 20.000000000000014, -27.100000000000012, -87.10000000000076, -271.8, -313.4999999999999, -385.8, -581.1, -47.19999999999976, -79.20000000000002, -110.20000000000049, -3.099999999999965, -423.6, -422.5000000000002, -507.1, -342.8, -47.19999999999976, -97.60000000000082, -125.89999999999993, -102.90000000000002, -51.39999999999977, -38.799999999999756, -489.79999999999995, -684.8, -368.49999999999966, 20.000000000000014, -498.30000000000007, -356.2, -400.0, -565.6000000000001, -694.4, -517.1, -816.0, -38.800000000000026, -280.2999999999999, -269.0, -164.39999999999992, -132.8999999999999, -276.3, -57.99999999999979, -42.99999999999976, -569.9, -366.79999999999984, -24.099999999999746, -87.10000000000085, -45.6999999999998, -421.99999999999994, -280.8000000000004, -311.50000000000034, -40.89999999999976, -536.0, -479.6, -358.5000000000002, -68.70000000000002, -627.5000000000001, -396.0, 11.599999999999964, -376.3000000000003, -661.3, 3.499999999999968, -9.400000000000027, -13.599999999999783, -82.90000000000043, -159.79999999999995, -848.9, 24.500000000000096, -26.799999999999756, -288.4, -83.80000000000004, -163.09999999999982, -623.6, -518.7999999999998, -243.0000000000003, -338.49999999999994, 11.899999999999947, -238.00000000000057, -93.40000000000035, -9.699999999999918, -349.69999999999993, -624.0, -9.399999999999855, -254.8, -324.6, 15.799999999999963, 17.899999999999977, -114.40000000000077, 45.200000000000244, -604.7, -28.29999999999975, -3.099999999999958, -47.19999999999976, -194.7000000000001, -458.4, -34.59999999999987, -779.8, -71.20000000000003, -249.8, -27.99999999999976, -351.0999999999999, -348.5, -3.099999999999958, -145.90000000000035, -66.09999999999994, -34.59999999999987, -38.799999999999905, -3.100000000000047, -174.40000000000055, -172.3000000000006, -259.70000000000005, -143.80000000000024, -34.599999999999916, -106.00000000000057, -26.199999999999747, 9.499999999999975, 5.299999999999969, -227.49999999999997, -193.00000000000003, -269.2, -38.799999999999756, -300.1000000000001, 13.100000000000032, -42.09999999999976, -51.399999999999764, -133.7999999999999, -19.899999999999995, -26.199999999999747, 20.000000000000014, -42.99999999999976, -28.29999999999975, -270.70000000000016, -47.19999999999976, -308.7, -7.299999999999962, -26.199999999999747, -43.59999999999978, -49.899999999999835, -21.99999999999978, -21.999999999999744, -3.099999999999958, 20.000000000000014, 39.80000000000025, -171.10000000000045, -152.20000000000067, -74.50000000000088, -7.899999999999949, -66.10000000000034, -336.59999999999985, 20.000000000000014, -32.49999999999975, -30.39999999999975, -11.49999999999999, -36.69999999999976, -34.59999999999975, -257.3000000000002, -47.19999999999977, 43.70000000000024, -30.399999999999757, -6.399999999999958, -229.10000000000016, -623.6, 22.700000000000053, -28.29999999999975, -197.70000000000027, 17.899999999999988, -5.499999999999957, -5.1999999999999265, -51.39999999999985, -89.20000000000084, 33.50000000000024, -36.699999999999754, -82.90000000000079, -80.7999999999999, -47.19999999999976, -40.899999999999785, 4.699999999999967, -31.299999999999777, -133.3000000000007, -31.299999999999763, 15.799999999999963, -57.70000000000034, -19.599999999999753, -13.599999999999783, -47.1999999999998, 30.8000000000002, -49.299999999999905, -21.999999999999744, -533.5, -15.699999999999747, -64.00000000000057, -7.299999999999891, -57.699999999999775, -200.50000000000028, 9.499999999999964, 23.30000000000006, -0.9999999999999846, 20.000000000000014, -15.100000000000017, -66.09999999999982, -26.199999999999747, 20.000000000000014], "policy_predator_policy_reward": [26.0, 39.0, 43.0, 44.0, 0.0, 292.0, 8.0, 506.0, 76.0, 36.0, 9.0, 67.0, 296.0, 291.0, 480.0, 81.0, 22.0, 57.0, 65.0, 87.0, 19.0, 43.0, 439.0, 458.0, 129.0, 182.0, 119.0, 448.0, 290.0, 374.0, 436.0, 533.0, 457.0, 482.0, 28.0, 151.0, 32.0, 102.0, 22.0, 212.0, 341.0, 329.0, 288.0, 21.0, 59.0, 44.0, 244.0, 96.0, 130.0, 128.0, 289.0, 353.0, 183.0, 103.0, 508.0, 314.0, 121.0, 166.0, 357.0, 417.0, 4.0, 26.0, 5.0, 156.0, 465.0, 595.0, 232.0, 115.0, 128.0, 17.0, 567.0, 66.0, 147.0, 317.0, 151.0, 53.0, 36.0, 36.0, 533.0, 49.0, 175.0, 34.0, 99.0, 216.0, 38.0, 53.0, 367.0, 283.0, 23.0, 11.0, 43.0, 128.0, 287.0, 239.0, 455.0, 502.0, 160.0, 142.0, 289.0, 62.0, 69.0, 93.0, 22.0, 44.0, 23.0, 24.0, 70.0, 115.0, 142.0, 152.0, 33.0, 54.0, 21.0, 22.0, 103.0, 145.0, 197.0, 23.0, 28.0, 168.0, 10.0, 35.0, 61.0, 88.0, 41.0, 2.0, 30.0, 13.0, 23.0, 154.0, 204.0, 112.0, 11.0, 24.0, 57.0, 30.0, 38.0, 33.0, 11.0, 11.0, 77.0, 84.0, 62.0, 60.0, 21.0, 35.0, 256.0, 185.0, 11.0, 35.0, 21.0, 19.0, 120.0, 158.0, 13.0, 25.0, 29.0, 17.0, 366.0, 386.0, 13.0, 14.0, 65.0, 118.0, 25.0, 10.0, 36.0, 42.0, 26.0, 24.0, 30.0, 69.0, 35.0, 47.0, 37.0, 17.0, 50.0, 56.0, 37.0, 2.0, 4.0, 24.0, 18.0, 17.0, 22.0, 31.0, 286.0, 317.0, 19.0, 34.0, 19.0, 123.0, 4.0, 4.0, 10.0, 5.0, 26.0, 28.0, 21.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5527036310746347, "mean_inference_ms": 1.4243885680135464, "mean_action_processing_ms": 0.2424514573113221, "mean_env_wait_ms": 0.18334326685011554, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004697203636169434, "StateBufferConnector_ms": 0.0038846731185913086, "ViewRequirementAgentConnector_ms": 0.10066545009613037}, "num_episodes": 18, "episode_return_max": 235.59999999999957, "episode_return_min": -509.39999999999986, "episode_return_mean": -65.34200000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.65427296691934, "num_env_steps_trained_throughput_per_sec": 295.65427296691934, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 10347.279, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10347.23, "sample_time_ms": 1225.9, "learn_time_ms": 9106.583, "learn_throughput": 439.243, "synch_weights_time_ms": 13.067}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-30-02", "timestamp": 1723645802, "time_this_iter_s": 13.58413577079773, "time_total_s": 322.3920180797577, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b098c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 322.3920180797577, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 80.4421052631579, "ram_util_percent": 83.71578947368423}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.540035755072952, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.6528548974839468, "policy_loss": -0.011666240077465773, "vf_loss": 2.6618101347691168, "vf_explained_var": 6.958873814375943e-05, "kl": 0.00903668865129663, "entropy": 1.4449586797012854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9906605690244645, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.5740945865237523, "policy_loss": -0.013391747480140083, "vf_loss": 2.585320326512453, "vf_explained_var": 0.10602919544492449, "kl": 0.01083008167340253, "entropy": 1.2880448892633751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 235.59999999999957, "episode_reward_min": -509.39999999999986, "episode_reward_mean": -37.441999999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -848.9, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 52.700000000000216, "predator_policy": 595.0}, "policy_reward_mean": {"prey_policy": -116.48100000000001, "predator_policy": 97.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-163.2999999999998, -100.30000000000027, 57.100000000000264, -81.89999999999986, -29.799999999999585, -362.8000000000003, -94.40000000000128, -373.6, -141.20000000000007, -201.49999999999997, -77.70000000000044, 116.20000000000013, 6.999999999999909, -81.69999999999996, 235.59999999999957, 31.799999999999983, -101.89999999999992, -509.39999999999986, -117.49999999999994, -22.09999999999964, -31.099999999999554, -391.69999999999993, -55.19999999999993, 6.19999999999998, -5.4999999999997655, 90.49999999999955, 2.6000000000002155, -70.90000000000018, 33.00000000000009, 105.99999999999966, 24.200000000000003, -348.5999999999999, 13.00000000000015, -34.6999999999997, 5.099999999999987, -161.70000000000115, -109.50000000000037, -53.60000000000015, 26.300000000000093, 25.800000000000075, -242.19999999999982, -142.90000000000023, 15.999999999999932, -36.199999999999726, -3.1000000000000827, 19.999999999999982, -122.0000000000008, -39.89999999999994, 1.5000000000001934, -6.499999999999847, 27.000000000000117, 38.90000000000028, 29.7000000000004, -104.70000000000155, -17.999999999999666, 124.39999999999978, -16.8999999999995, -8.199999999999823, -13.899999999999778, 34.50000000000022, 9.200000000000035, -100.70000000000007, 21.400000000000006, 3.2000000000001068, 24.300000000000065, -62.600000000001344, 46.800000000000445, -64.69999999999959, -6.099999999999724, 27.400000000000116, -58.600000000000634, -2.8999999999998014, -5.199999999999685, 18.599999999999962, -18.29999999999967, 53.80000000000025, -18.299999999999507, -116.20000000000073, 40.80000000000031, 34.00000000000021, -27.199999999999903, 26.800000000000114, 18.299999999999994, 52.40000000000044, 15.799999999999923, 19.999999999999975, -124.20000000000007, 40.500000000000306, -25.999999999999517, 27.600000000000104, 36.10000000000024, -51.29999999999987, -66.19999999999996, -17.699999999999562, 23.40000000000004, 16.89999999999995, -95.90000000000137, -29.19999999999952, 26.30000000000013, -32.799999999999756], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-164.39999999999992, -132.8999999999999, -276.3, -57.99999999999979, -42.99999999999976, -569.9, -366.79999999999984, -24.099999999999746, -87.10000000000085, -45.6999999999998, -421.99999999999994, -280.8000000000004, -311.50000000000034, -40.89999999999976, -536.0, -479.6, -358.5000000000002, -68.70000000000002, -627.5000000000001, -396.0, 11.599999999999964, -376.3000000000003, -661.3, 3.499999999999968, -9.400000000000027, -13.599999999999783, -82.90000000000043, -159.79999999999995, -848.9, 24.500000000000096, -26.799999999999756, -288.4, -83.80000000000004, -163.09999999999982, -623.6, -518.7999999999998, -243.0000000000003, -338.49999999999994, 11.899999999999947, -238.00000000000057, -93.40000000000035, -9.699999999999918, -349.69999999999993, -624.0, -9.399999999999855, -254.8, -324.6, 15.799999999999963, 17.899999999999977, -114.40000000000077, 45.200000000000244, -604.7, -28.29999999999975, -3.099999999999958, -47.19999999999976, -194.7000000000001, -458.4, -34.59999999999987, -779.8, -71.20000000000003, -249.8, -27.99999999999976, -351.0999999999999, -348.5, -3.099999999999958, -145.90000000000035, -66.09999999999994, -34.59999999999987, -38.799999999999905, -3.100000000000047, -174.40000000000055, -172.3000000000006, -259.70000000000005, -143.80000000000024, -34.599999999999916, -106.00000000000057, -26.199999999999747, 9.499999999999975, 5.299999999999969, -227.49999999999997, -193.00000000000003, -269.2, -38.799999999999756, -300.1000000000001, 13.100000000000032, -42.09999999999976, -51.399999999999764, -133.7999999999999, -19.899999999999995, -26.199999999999747, 20.000000000000014, -42.99999999999976, -28.29999999999975, -270.70000000000016, -47.19999999999976, -308.7, -7.299999999999962, -26.199999999999747, -43.59999999999978, -49.899999999999835, -21.99999999999978, -21.999999999999744, -3.099999999999958, 20.000000000000014, 39.80000000000025, -171.10000000000045, -152.20000000000067, -74.50000000000088, -7.899999999999949, -66.10000000000034, -336.59999999999985, 20.000000000000014, -32.49999999999975, -30.39999999999975, -11.49999999999999, -36.69999999999976, -34.59999999999975, -257.3000000000002, -47.19999999999977, 43.70000000000024, -30.399999999999757, -6.399999999999958, -229.10000000000016, -623.6, 22.700000000000053, -28.29999999999975, -197.70000000000027, 17.899999999999988, -5.499999999999957, -5.1999999999999265, -51.39999999999985, -89.20000000000084, 33.50000000000024, -36.699999999999754, -82.90000000000079, -80.7999999999999, -47.19999999999976, -40.899999999999785, 4.699999999999967, -31.299999999999777, -133.3000000000007, -31.299999999999763, 15.799999999999963, -57.70000000000034, -19.599999999999753, -13.599999999999783, -47.1999999999998, 30.8000000000002, -49.299999999999905, -21.999999999999744, -533.5, -15.699999999999747, -64.00000000000057, -7.299999999999891, -57.699999999999775, -200.50000000000028, 9.499999999999964, 23.30000000000006, -0.9999999999999846, 20.000000000000014, -15.100000000000017, -66.09999999999982, -26.199999999999747, 20.000000000000014, 4.6999999999999655, -9.399999999999855, -70.30000000000089, 52.700000000000216, -66.10000000000082, 38.900000000000254, -42.99999999999976, 20.000000000000014, -72.40000000000003, -143.8000000000001, 38.000000000000256, -32.49999999999975, -42.99999999999976, -42.99999999999976, -24.099999999999746, 13.699999999999964, 1.0999999999999865, 20.000000000000014, 5.299999999999972, -139.6000000000001, -78.10000000000056, -87.0999999999999, -55.600000000000335, -54.099999999999945, 20.000000000000014, -55.600000000000335, -21.99999999999975, -0.09999999999996162, -147.30000000000055, -97.60000000000082, -34.59999999999976, -34.59999999999976, -18.699999999999818, 20.000000000000014, -103.90000000000063, -19.89999999999987], "policy_predator_policy_reward": [32.0, 102.0, 22.0, 212.0, 341.0, 329.0, 288.0, 21.0, 59.0, 44.0, 244.0, 96.0, 130.0, 128.0, 289.0, 353.0, 183.0, 103.0, 508.0, 314.0, 121.0, 166.0, 357.0, 417.0, 4.0, 26.0, 5.0, 156.0, 465.0, 595.0, 232.0, 115.0, 128.0, 17.0, 567.0, 66.0, 147.0, 317.0, 151.0, 53.0, 36.0, 36.0, 533.0, 49.0, 175.0, 34.0, 99.0, 216.0, 38.0, 53.0, 367.0, 283.0, 23.0, 11.0, 43.0, 128.0, 287.0, 239.0, 455.0, 502.0, 160.0, 142.0, 289.0, 62.0, 69.0, 93.0, 22.0, 44.0, 23.0, 24.0, 70.0, 115.0, 142.0, 152.0, 33.0, 54.0, 21.0, 22.0, 103.0, 145.0, 197.0, 23.0, 28.0, 168.0, 10.0, 35.0, 61.0, 88.0, 41.0, 2.0, 30.0, 13.0, 23.0, 154.0, 204.0, 112.0, 11.0, 24.0, 57.0, 30.0, 38.0, 33.0, 11.0, 11.0, 77.0, 84.0, 62.0, 60.0, 21.0, 35.0, 256.0, 185.0, 11.0, 35.0, 21.0, 19.0, 120.0, 158.0, 13.0, 25.0, 29.0, 17.0, 366.0, 386.0, 13.0, 14.0, 65.0, 118.0, 25.0, 10.0, 36.0, 42.0, 26.0, 24.0, 30.0, 69.0, 35.0, 47.0, 37.0, 17.0, 50.0, 56.0, 37.0, 2.0, 4.0, 24.0, 18.0, 17.0, 22.0, 31.0, 286.0, 317.0, 19.0, 34.0, 19.0, 123.0, 4.0, 4.0, 10.0, 5.0, 26.0, 28.0, 21.0, 12.0, 9.0, 14.0, 26.0, 44.0, 31.0, 12.0, 13.0, 30.0, 6.0, 86.0, 21.0, 14.0, 19.0, 41.0, 17.0, 21.0, 9.0, 6.0, 11.0, 72.0, 18.0, 81.0, 21.0, 71.0, 25.0, 34.0, 16.0, 23.0, 56.0, 93.0, 14.0, 26.0, 17.0, 8.0, 37.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5552856323561975, "mean_inference_ms": 1.4306611508623561, "mean_action_processing_ms": 0.24276795842174181, "mean_env_wait_ms": 0.18424425393590677, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004889369010925293, "StateBufferConnector_ms": 0.0040171146392822266, "ViewRequirementAgentConnector_ms": 0.10345888137817383}, "num_episodes": 18, "episode_return_max": 235.59999999999957, "episode_return_min": -509.39999999999986, "episode_return_mean": -37.441999999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.209822320783, "num_env_steps_trained_throughput_per_sec": 366.209822320783, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 10521.53, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10521.482, "sample_time_ms": 1281.741, "learn_time_ms": 9225.01, "learn_throughput": 433.604, "synch_weights_time_ms": 13.238}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-30-13", "timestamp": 1723645813, "time_this_iter_s": 10.987072944641113, "time_total_s": 333.3790910243988, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b09baf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 333.3790910243988, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 40.681250000000006, "ram_util_percent": 83.57499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5224040468849203, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.530913776947708, "policy_loss": -0.006070863130802988, "vf_loss": 3.535237187430972, "vf_explained_var": -0.0026440435931796118, "kl": 0.005824852807341649, "entropy": 1.4474071688752956, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8576705882473596, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.0031925703482654, "policy_loss": -0.010233403316565923, "vf_loss": 3.012023548789756, "vf_explained_var": 0.1601895757137783, "kl": 0.0070121223247251235, "entropy": 1.1587441829146532, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 124.39999999999978, "episode_reward_min": -391.69999999999993, "episode_reward_mean": -22.199999999999964, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -779.8, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 52.700000000000216, "predator_policy": 533.0}, "policy_reward_mean": {"prey_policy": -79.21000000000002, "predator_policy": 68.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-117.49999999999994, -22.09999999999964, -31.099999999999554, -391.69999999999993, -55.19999999999993, 6.19999999999998, -5.4999999999997655, 90.49999999999955, 2.6000000000002155, -70.90000000000018, 33.00000000000009, 105.99999999999966, 24.200000000000003, -348.5999999999999, 13.00000000000015, -34.6999999999997, 5.099999999999987, -161.70000000000115, -109.50000000000037, -53.60000000000015, 26.300000000000093, 25.800000000000075, -242.19999999999982, -142.90000000000023, 15.999999999999932, -36.199999999999726, -3.1000000000000827, 19.999999999999982, -122.0000000000008, -39.89999999999994, 1.5000000000001934, -6.499999999999847, 27.000000000000117, 38.90000000000028, 29.7000000000004, -104.70000000000155, -17.999999999999666, 124.39999999999978, -16.8999999999995, -8.199999999999823, -13.899999999999778, 34.50000000000022, 9.200000000000035, -100.70000000000007, 21.400000000000006, 3.2000000000001068, 24.300000000000065, -62.600000000001344, 46.800000000000445, -64.69999999999959, -6.099999999999724, 27.400000000000116, -58.600000000000634, -2.8999999999998014, -5.199999999999685, 18.599999999999962, -18.29999999999967, 53.80000000000025, -18.299999999999507, -116.20000000000073, 40.80000000000031, 34.00000000000021, -27.199999999999903, 26.800000000000114, 18.299999999999994, 52.40000000000044, 15.799999999999923, 19.999999999999975, -124.20000000000007, 40.500000000000306, -25.999999999999517, 27.600000000000104, 36.10000000000024, -51.29999999999987, -66.19999999999996, -17.699999999999562, 23.40000000000004, 16.89999999999995, -95.90000000000137, -29.19999999999952, 26.30000000000013, -32.799999999999756, 10.100000000000241, -58.60000000000069, 25.50000000000007, 1.499999999999946, -73.60000000000116, -91.99999999999991, -18.799999999999564, -77.60000000000005, 37.60000000000035, -46.79999999999987, 15.199999999999916, 9.599999999999964, 24.90000000000006, -43.39999999999958, -9.399999999999634, -17.199999999999505, -17.199999999999513, -17.400000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-243.0000000000003, -338.49999999999994, 11.899999999999947, -238.00000000000057, -93.40000000000035, -9.699999999999918, -349.69999999999993, -624.0, -9.399999999999855, -254.8, -324.6, 15.799999999999963, 17.899999999999977, -114.40000000000077, 45.200000000000244, -604.7, -28.29999999999975, -3.099999999999958, -47.19999999999976, -194.7000000000001, -458.4, -34.59999999999987, -779.8, -71.20000000000003, -249.8, -27.99999999999976, -351.0999999999999, -348.5, -3.099999999999958, -145.90000000000035, -66.09999999999994, -34.59999999999987, -38.799999999999905, -3.100000000000047, -174.40000000000055, -172.3000000000006, -259.70000000000005, -143.80000000000024, -34.599999999999916, -106.00000000000057, -26.199999999999747, 9.499999999999975, 5.299999999999969, -227.49999999999997, -193.00000000000003, -269.2, -38.799999999999756, -300.1000000000001, 13.100000000000032, -42.09999999999976, -51.399999999999764, -133.7999999999999, -19.899999999999995, -26.199999999999747, 20.000000000000014, -42.99999999999976, -28.29999999999975, -270.70000000000016, -47.19999999999976, -308.7, -7.299999999999962, -26.199999999999747, -43.59999999999978, -49.899999999999835, -21.99999999999978, -21.999999999999744, -3.099999999999958, 20.000000000000014, 39.80000000000025, -171.10000000000045, -152.20000000000067, -74.50000000000088, -7.899999999999949, -66.10000000000034, -336.59999999999985, 20.000000000000014, -32.49999999999975, -30.39999999999975, -11.49999999999999, -36.69999999999976, -34.59999999999975, -257.3000000000002, -47.19999999999977, 43.70000000000024, -30.399999999999757, -6.399999999999958, -229.10000000000016, -623.6, 22.700000000000053, -28.29999999999975, -197.70000000000027, 17.899999999999988, -5.499999999999957, -5.1999999999999265, -51.39999999999985, -89.20000000000084, 33.50000000000024, -36.699999999999754, -82.90000000000079, -80.7999999999999, -47.19999999999976, -40.899999999999785, 4.699999999999967, -31.299999999999777, -133.3000000000007, -31.299999999999763, 15.799999999999963, -57.70000000000034, -19.599999999999753, -13.599999999999783, -47.1999999999998, 30.8000000000002, -49.299999999999905, -21.999999999999744, -533.5, -15.699999999999747, -64.00000000000057, -7.299999999999891, -57.699999999999775, -200.50000000000028, 9.499999999999964, 23.30000000000006, -0.9999999999999846, 20.000000000000014, -15.100000000000017, -66.09999999999982, -26.199999999999747, 20.000000000000014, 4.6999999999999655, -9.399999999999855, -70.30000000000089, 52.700000000000216, -66.10000000000082, 38.900000000000254, -42.99999999999976, 20.000000000000014, -72.40000000000003, -143.8000000000001, 38.000000000000256, -32.49999999999975, -42.99999999999976, -42.99999999999976, -24.099999999999746, 13.699999999999964, 1.0999999999999865, 20.000000000000014, 5.299999999999972, -139.6000000000001, -78.10000000000056, -87.0999999999999, -55.600000000000335, -54.099999999999945, 20.000000000000014, -55.600000000000335, -21.99999999999975, -0.09999999999996162, -147.30000000000055, -97.60000000000082, -34.59999999999976, -34.59999999999976, -18.699999999999818, 20.000000000000014, -103.90000000000063, -19.89999999999987, -114.3999999999999, 33.50000000000019, -160.60000000000062, -21.999999999999744, 20.000000000000014, -29.49999999999975, -53.499999999999766, 7.9999999999999725, -217.30000000000044, -7.299999999999891, -13.60000000000003, -177.4000000000002, -66.1000000000009, -15.69999999999979, -130.80000000000007, -38.80000000000002, 9.499999999999964, -34.8999999999998, -38.79999999999983, -85.00000000000063, -45.39999999999978, 11.59999999999997, -70.60000000000086, -14.799999999999953, 20.000000000000014, -12.099999999999817, -143.8000000000007, 7.399999999999947, -63.70000000000085, 5.299999999999965, -26.199999999999747, -42.99999999999976, -15.699999999999754, -53.499999999999766, -93.39999999999984, 20.000000000000014], "policy_predator_policy_reward": [147.0, 317.0, 151.0, 53.0, 36.0, 36.0, 533.0, 49.0, 175.0, 34.0, 99.0, 216.0, 38.0, 53.0, 367.0, 283.0, 23.0, 11.0, 43.0, 128.0, 287.0, 239.0, 455.0, 502.0, 160.0, 142.0, 289.0, 62.0, 69.0, 93.0, 22.0, 44.0, 23.0, 24.0, 70.0, 115.0, 142.0, 152.0, 33.0, 54.0, 21.0, 22.0, 103.0, 145.0, 197.0, 23.0, 28.0, 168.0, 10.0, 35.0, 61.0, 88.0, 41.0, 2.0, 30.0, 13.0, 23.0, 154.0, 204.0, 112.0, 11.0, 24.0, 57.0, 30.0, 38.0, 33.0, 11.0, 11.0, 77.0, 84.0, 62.0, 60.0, 21.0, 35.0, 256.0, 185.0, 11.0, 35.0, 21.0, 19.0, 120.0, 158.0, 13.0, 25.0, 29.0, 17.0, 366.0, 386.0, 13.0, 14.0, 65.0, 118.0, 25.0, 10.0, 36.0, 42.0, 26.0, 24.0, 30.0, 69.0, 35.0, 47.0, 37.0, 17.0, 50.0, 56.0, 37.0, 2.0, 4.0, 24.0, 18.0, 17.0, 22.0, 31.0, 286.0, 317.0, 19.0, 34.0, 19.0, 123.0, 4.0, 4.0, 10.0, 5.0, 26.0, 28.0, 21.0, 12.0, 9.0, 14.0, 26.0, 44.0, 31.0, 12.0, 13.0, 30.0, 6.0, 86.0, 21.0, 14.0, 19.0, 41.0, 17.0, 21.0, 9.0, 6.0, 11.0, 72.0, 18.0, 81.0, 21.0, 71.0, 25.0, 34.0, 16.0, 23.0, 56.0, 93.0, 14.0, 26.0, 17.0, 8.0, 37.0, 54.0, 63.0, 28.0, 61.0, 63.0, 11.0, 24.0, 19.0, 28.0, 38.0, 113.0, 94.0, 5.0, 39.0, 24.0, 12.0, 80.0, 40.0, 23.0, 31.0, 46.0, 14.0, 35.0, 61.0, 34.0, 8.0, 9.0, 78.0, 15.0, 7.0, 42.0, 30.0, 22.0, 20.0, 32.0, 32.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5581308775581075, "mean_inference_ms": 1.4381565487042354, "mean_action_processing_ms": 0.24328134266881615, "mean_env_wait_ms": 0.18526848440291302, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004690051078796387, "StateBufferConnector_ms": 0.004244327545166016, "ViewRequirementAgentConnector_ms": 0.10929012298583984}, "num_episodes": 18, "episode_return_max": 124.39999999999978, "episode_return_min": -391.69999999999993, "episode_return_mean": -22.199999999999964, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.96308050935625, "num_env_steps_trained_throughput_per_sec": 373.96308050935625, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 10664.11, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10664.063, "sample_time_ms": 1303.087, "learn_time_ms": 9345.984, "learn_throughput": 427.991, "synch_weights_time_ms": 13.554}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-30-24", "timestamp": 1723645824, "time_this_iter_s": 10.701996088027954, "time_total_s": 344.08108711242676, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b098550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 344.08108711242676, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 37.82000000000001, "ram_util_percent": 83.85999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4110832863383822, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.394734856470552, "policy_loss": -0.012803609642968882, "vf_loss": 2.4056760623972253, "vf_explained_var": 0.0020028267587934223, "kl": 0.006208023528520173, "entropy": 1.4470542924744743, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9282907528221291, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.293397057056427, "policy_loss": -0.010628175123954418, "vf_loss": 2.3025335214756155, "vf_explained_var": 0.12837322549845176, "kl": 0.007458577293514442, "entropy": 1.188288058616497, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 124.39999999999978, "episode_reward_min": -242.19999999999982, "episode_reward_mean": -12.492999999999936, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -623.6, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 52.700000000000216, "predator_policy": 386.0}, "policy_reward_mean": {"prey_policy": -49.85650000000001, "predator_policy": 43.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-242.19999999999982, -142.90000000000023, 15.999999999999932, -36.199999999999726, -3.1000000000000827, 19.999999999999982, -122.0000000000008, -39.89999999999994, 1.5000000000001934, -6.499999999999847, 27.000000000000117, 38.90000000000028, 29.7000000000004, -104.70000000000155, -17.999999999999666, 124.39999999999978, -16.8999999999995, -8.199999999999823, -13.899999999999778, 34.50000000000022, 9.200000000000035, -100.70000000000007, 21.400000000000006, 3.2000000000001068, 24.300000000000065, -62.600000000001344, 46.800000000000445, -64.69999999999959, -6.099999999999724, 27.400000000000116, -58.600000000000634, -2.8999999999998014, -5.199999999999685, 18.599999999999962, -18.29999999999967, 53.80000000000025, -18.299999999999507, -116.20000000000073, 40.80000000000031, 34.00000000000021, -27.199999999999903, 26.800000000000114, 18.299999999999994, 52.40000000000044, 15.799999999999923, 19.999999999999975, -124.20000000000007, 40.500000000000306, -25.999999999999517, 27.600000000000104, 36.10000000000024, -51.29999999999987, -66.19999999999996, -17.699999999999562, 23.40000000000004, 16.89999999999995, -95.90000000000137, -29.19999999999952, 26.30000000000013, -32.799999999999756, 10.100000000000241, -58.60000000000069, 25.50000000000007, 1.499999999999946, -73.60000000000116, -91.99999999999991, -18.799999999999564, -77.60000000000005, 37.60000000000035, -46.79999999999987, 15.199999999999916, 9.599999999999964, 24.90000000000006, -43.39999999999958, -9.399999999999634, -17.199999999999505, -17.199999999999513, -17.400000000000006, -40.20000000000003, -34.09999999999954, 6.899999999999979, -33.19999999999954, 5.799999999999951, 59.30000000000047, -45.7999999999997, -64.50000000000165, 17.000000000000004, -6.199999999999688, 12.499999999999957, -2.899999999999957, 13.60000000000004, -7.8999999999996895, -42.69999999999982, 35.500000000000234, 6.5000000000001155, -33.89999999999954, 17.49999999999994, 2.9000000000001163, 52.200000000000465, -16.999999999999503], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-193.00000000000003, -269.2, -38.799999999999756, -300.1000000000001, 13.100000000000032, -42.09999999999976, -51.399999999999764, -133.7999999999999, -19.899999999999995, -26.199999999999747, 20.000000000000014, -42.99999999999976, -28.29999999999975, -270.70000000000016, -47.19999999999976, -308.7, -7.299999999999962, -26.199999999999747, -43.59999999999978, -49.899999999999835, -21.99999999999978, -21.999999999999744, -3.099999999999958, 20.000000000000014, 39.80000000000025, -171.10000000000045, -152.20000000000067, -74.50000000000088, -7.899999999999949, -66.10000000000034, -336.59999999999985, 20.000000000000014, -32.49999999999975, -30.39999999999975, -11.49999999999999, -36.69999999999976, -34.59999999999975, -257.3000000000002, -47.19999999999977, 43.70000000000024, -30.399999999999757, -6.399999999999958, -229.10000000000016, -623.6, 22.700000000000053, -28.29999999999975, -197.70000000000027, 17.899999999999988, -5.499999999999957, -5.1999999999999265, -51.39999999999985, -89.20000000000084, 33.50000000000024, -36.699999999999754, -82.90000000000079, -80.7999999999999, -47.19999999999976, -40.899999999999785, 4.699999999999967, -31.299999999999777, -133.3000000000007, -31.299999999999763, 15.799999999999963, -57.70000000000034, -19.599999999999753, -13.599999999999783, -47.1999999999998, 30.8000000000002, -49.299999999999905, -21.999999999999744, -533.5, -15.699999999999747, -64.00000000000057, -7.299999999999891, -57.699999999999775, -200.50000000000028, 9.499999999999964, 23.30000000000006, -0.9999999999999846, 20.000000000000014, -15.100000000000017, -66.09999999999982, -26.199999999999747, 20.000000000000014, 4.6999999999999655, -9.399999999999855, -70.30000000000089, 52.700000000000216, -66.10000000000082, 38.900000000000254, -42.99999999999976, 20.000000000000014, -72.40000000000003, -143.8000000000001, 38.000000000000256, -32.49999999999975, -42.99999999999976, -42.99999999999976, -24.099999999999746, 13.699999999999964, 1.0999999999999865, 20.000000000000014, 5.299999999999972, -139.6000000000001, -78.10000000000056, -87.0999999999999, -55.600000000000335, -54.099999999999945, 20.000000000000014, -55.600000000000335, -21.99999999999975, -0.09999999999996162, -147.30000000000055, -97.60000000000082, -34.59999999999976, -34.59999999999976, -18.699999999999818, 20.000000000000014, -103.90000000000063, -19.89999999999987, -114.3999999999999, 33.50000000000019, -160.60000000000062, -21.999999999999744, 20.000000000000014, -29.49999999999975, -53.499999999999766, 7.9999999999999725, -217.30000000000044, -7.299999999999891, -13.60000000000003, -177.4000000000002, -66.1000000000009, -15.69999999999979, -130.80000000000007, -38.80000000000002, 9.499999999999964, -34.8999999999998, -38.79999999999983, -85.00000000000063, -45.39999999999978, 11.59999999999997, -70.60000000000086, -14.799999999999953, 20.000000000000014, -12.099999999999817, -143.8000000000007, 7.399999999999947, -63.70000000000085, 5.299999999999965, -26.199999999999747, -42.99999999999976, -15.699999999999754, -53.499999999999766, -93.39999999999984, 20.000000000000014, -66.10000000000086, -24.099999999999753, -60.1000000000006, -42.99999999999976, 5.299999999999965, -114.40000000000077, -57.700000000000465, -44.499999999999844, -9.399999999999855, -17.80000000000002, 14.299999999999967, 20.000000000000014, -137.50000000000045, 13.699999999999967, -49.299999999999905, -110.20000000000076, -0.9999999999999846, -0.9999999999999846, -64.00000000000091, 15.799999999999963, -19.899999999999988, 7.399999999999965, 5.299999999999965, -47.19999999999976, -5.1999999999999265, -5.1999999999999265, -55.600000000000264, -10.299999999999873, -0.10000000000001391, -118.60000000000025, -47.19999999999976, 40.700000000000244, -53.50000000000019, 20.000000000000014, -34.59999999999975, -91.30000000000084, -26.49999999999975, -15.999999999999774, -28.29999999999975, -17.799999999999784, 30.800000000000203, 10.399999999999968, -49.299999999999876, -15.699999999999747], "policy_predator_policy_reward": [197.0, 23.0, 28.0, 168.0, 10.0, 35.0, 61.0, 88.0, 41.0, 2.0, 30.0, 13.0, 23.0, 154.0, 204.0, 112.0, 11.0, 24.0, 57.0, 30.0, 38.0, 33.0, 11.0, 11.0, 77.0, 84.0, 62.0, 60.0, 21.0, 35.0, 256.0, 185.0, 11.0, 35.0, 21.0, 19.0, 120.0, 158.0, 13.0, 25.0, 29.0, 17.0, 366.0, 386.0, 13.0, 14.0, 65.0, 118.0, 25.0, 10.0, 36.0, 42.0, 26.0, 24.0, 30.0, 69.0, 35.0, 47.0, 37.0, 17.0, 50.0, 56.0, 37.0, 2.0, 4.0, 24.0, 18.0, 17.0, 22.0, 31.0, 286.0, 317.0, 19.0, 34.0, 19.0, 123.0, 4.0, 4.0, 10.0, 5.0, 26.0, 28.0, 21.0, 12.0, 9.0, 14.0, 26.0, 44.0, 31.0, 12.0, 13.0, 30.0, 6.0, 86.0, 21.0, 14.0, 19.0, 41.0, 17.0, 21.0, 9.0, 6.0, 11.0, 72.0, 18.0, 81.0, 21.0, 71.0, 25.0, 34.0, 16.0, 23.0, 56.0, 93.0, 14.0, 26.0, 17.0, 8.0, 37.0, 54.0, 63.0, 28.0, 61.0, 63.0, 11.0, 24.0, 19.0, 28.0, 38.0, 113.0, 94.0, 5.0, 39.0, 24.0, 12.0, 80.0, 40.0, 23.0, 31.0, 46.0, 14.0, 35.0, 61.0, 34.0, 8.0, 9.0, 78.0, 15.0, 7.0, 42.0, 30.0, 22.0, 20.0, 32.0, 32.0, 24.0, 41.0, 9.0, 39.0, 30.0, 61.0, 55.0, 13.0, 56.0, 14.0, 19.0, 13.0, 12.0, 74.0, 4.0, 62.0, 33.0, 11.0, 8.0, 40.0, 2.0, 6.0, 19.0, 22.0, 17.0, 12.0, 12.0, 37.0, 21.0, 72.0, 4.0, 32.0, 10.0, 5.0, 35.0, 53.0, 39.0, 36.0, 24.0, 26.0, 23.0, 6.0, 5.0, 16.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5614011626247599, "mean_inference_ms": 1.448130065393612, "mean_action_processing_ms": 0.24332601141132632, "mean_env_wait_ms": 0.18638845918279848, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004639029502868652, "StateBufferConnector_ms": 0.004197835922241211, "ViewRequirementAgentConnector_ms": 0.10756289958953857}, "num_episodes": 22, "episode_return_max": 124.39999999999978, "episode_return_min": -242.19999999999982, "episode_return_mean": -12.492999999999936, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.7102229356607, "num_env_steps_trained_throughput_per_sec": 388.7102229356607, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 10780.293, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10780.246, "sample_time_ms": 1310.189, "learn_time_ms": 9455.074, "learn_throughput": 423.053, "synch_weights_time_ms": 13.544}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-30-34", "timestamp": 1723645834, "time_this_iter_s": 10.293702125549316, "time_total_s": 354.3747892379761, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39adae9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 354.3747892379761, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 37.72, "ram_util_percent": 83.86666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5485694254043871, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.3192425711760447, "policy_loss": -0.01092812730684364, "vf_loss": 2.328348660279834, "vf_explained_var": -0.05269700604141074, "kl": 0.006073451593824706, "entropy": 1.431895471817602, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.943322960378001, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.291232275016724, "policy_loss": -0.003973150173468249, "vf_loss": 2.2941359137731885, "vf_explained_var": 0.03784643389560558, "kl": 0.005347545943972744, "entropy": 1.0232758601821919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 71.19999999999995, "episode_reward_min": -154.9000000000013, "episode_reward_mean": -7.49799999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -533.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.50000000000022, "predator_policy": 317.0}, "policy_reward_mean": {"prey_policy": -37.63900000000004, "predator_policy": 33.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.2000000000001068, 24.300000000000065, -62.600000000001344, 46.800000000000445, -64.69999999999959, -6.099999999999724, 27.400000000000116, -58.600000000000634, -2.8999999999998014, -5.199999999999685, 18.599999999999962, -18.29999999999967, 53.80000000000025, -18.299999999999507, -116.20000000000073, 40.80000000000031, 34.00000000000021, -27.199999999999903, 26.800000000000114, 18.299999999999994, 52.40000000000044, 15.799999999999923, 19.999999999999975, -124.20000000000007, 40.500000000000306, -25.999999999999517, 27.600000000000104, 36.10000000000024, -51.29999999999987, -66.19999999999996, -17.699999999999562, 23.40000000000004, 16.89999999999995, -95.90000000000137, -29.19999999999952, 26.30000000000013, -32.799999999999756, 10.100000000000241, -58.60000000000069, 25.50000000000007, 1.499999999999946, -73.60000000000116, -91.99999999999991, -18.799999999999564, -77.60000000000005, 37.60000000000035, -46.79999999999987, 15.199999999999916, 9.599999999999964, 24.90000000000006, -43.39999999999958, -9.399999999999634, -17.199999999999505, -17.199999999999513, -17.400000000000006, -40.20000000000003, -34.09999999999954, 6.899999999999979, -33.19999999999954, 5.799999999999951, 59.30000000000047, -45.7999999999997, -64.50000000000165, 17.000000000000004, -6.199999999999688, 12.499999999999957, -2.899999999999957, 13.60000000000004, -7.8999999999996895, -42.69999999999982, 35.500000000000234, 6.5000000000001155, -33.89999999999954, 17.49999999999994, 2.9000000000001163, 52.200000000000465, -16.999999999999503, 40.60000000000031, 34.00000000000031, -46.39999999999958, -30.399999999999615, 11.400000000000063, 14.699999999999987, -154.9000000000013, 37.40000000000026, 71.19999999999995, 52.20000000000051, -15.599999999999506, 8.100000000000039, -28.69999999999954, 20.299999999999994, 9.099999999999962, 23.300000000000036, 17.899999999999952, -60.20000000000134, 14.700000000000022, 13.400000000000013, -101.90000000000154, 11.000000000000004, 25.70000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-197.70000000000027, 17.899999999999988, -5.499999999999957, -5.1999999999999265, -51.39999999999985, -89.20000000000084, 33.50000000000024, -36.699999999999754, -82.90000000000079, -80.7999999999999, -47.19999999999976, -40.899999999999785, 4.699999999999967, -31.299999999999777, -133.3000000000007, -31.299999999999763, 15.799999999999963, -57.70000000000034, -19.599999999999753, -13.599999999999783, -47.1999999999998, 30.8000000000002, -49.299999999999905, -21.999999999999744, -533.5, -15.699999999999747, -64.00000000000057, -7.299999999999891, -57.699999999999775, -200.50000000000028, 9.499999999999964, 23.30000000000006, -0.9999999999999846, 20.000000000000014, -15.100000000000017, -66.09999999999982, -26.199999999999747, 20.000000000000014, 4.6999999999999655, -9.399999999999855, -70.30000000000089, 52.700000000000216, -66.10000000000082, 38.900000000000254, -42.99999999999976, 20.000000000000014, -72.40000000000003, -143.8000000000001, 38.000000000000256, -32.49999999999975, -42.99999999999976, -42.99999999999976, -24.099999999999746, 13.699999999999964, 1.0999999999999865, 20.000000000000014, 5.299999999999972, -139.6000000000001, -78.10000000000056, -87.0999999999999, -55.600000000000335, -54.099999999999945, 20.000000000000014, -55.600000000000335, -21.99999999999975, -0.09999999999996162, -147.30000000000055, -97.60000000000082, -34.59999999999976, -34.59999999999976, -18.699999999999818, 20.000000000000014, -103.90000000000063, -19.89999999999987, -114.3999999999999, 33.50000000000019, -160.60000000000062, -21.999999999999744, 20.000000000000014, -29.49999999999975, -53.499999999999766, 7.9999999999999725, -217.30000000000044, -7.299999999999891, -13.60000000000003, -177.4000000000002, -66.1000000000009, -15.69999999999979, -130.80000000000007, -38.80000000000002, 9.499999999999964, -34.8999999999998, -38.79999999999983, -85.00000000000063, -45.39999999999978, 11.59999999999997, -70.60000000000086, -14.799999999999953, 20.000000000000014, -12.099999999999817, -143.8000000000007, 7.399999999999947, -63.70000000000085, 5.299999999999965, -26.199999999999747, -42.99999999999976, -15.699999999999754, -53.499999999999766, -93.39999999999984, 20.000000000000014, -66.10000000000086, -24.099999999999753, -60.1000000000006, -42.99999999999976, 5.299999999999965, -114.40000000000077, -57.700000000000465, -44.499999999999844, -9.399999999999855, -17.80000000000002, 14.299999999999967, 20.000000000000014, -137.50000000000045, 13.699999999999967, -49.299999999999905, -110.20000000000076, -0.9999999999999846, -0.9999999999999846, -64.00000000000091, 15.799999999999963, -19.899999999999988, 7.399999999999965, 5.299999999999965, -47.19999999999976, -5.1999999999999265, -5.1999999999999265, -55.600000000000264, -10.299999999999873, -0.10000000000001391, -118.60000000000025, -47.19999999999976, 40.700000000000244, -53.50000000000019, 20.000000000000014, -34.59999999999975, -91.30000000000084, -26.49999999999975, -15.999999999999774, -28.29999999999975, -17.799999999999784, 30.800000000000203, 10.399999999999968, -49.299999999999876, -15.699999999999747, -28.29999999999975, 29.90000000000018, -259.29999999999853, 35.30000000000022, -108.40000000000077, -63.99999999999977, -42.99999999999976, -75.40000000000066, -5.799999999999924, -17.79999999999974, 13.699999999999964, -21.99999999999975, -196.30000000000055, -112.60000000000076, 20.000000000000014, -13.599999999999783, -7.299999999999891, 60.50000000000022, 4.999999999999966, 36.20000000000026, -34.59999999999975, -21.999999999999744, -36.699999999999754, 15.799999999999963, -66.1000000000009, -31.599999999999767, 26.300000000000114, -42.99999999999976, 17.899999999999988, -143.8000000000007, -34.59999999999976, 20.90000000000003, 9.499999999999973, -13.599999999999783, -85.00000000000085, -68.20000000000076, -11.499999999999819, 3.1999999999999615, -34.59999999999975, 20.000000000000014, -101.80000000000081, -129.10000000000073, -36.699999999999775, 19.70000000000001, 20.000000000000014, -7.299999999999891], "policy_predator_policy_reward": [65.0, 118.0, 25.0, 10.0, 36.0, 42.0, 26.0, 24.0, 30.0, 69.0, 35.0, 47.0, 37.0, 17.0, 50.0, 56.0, 37.0, 2.0, 4.0, 24.0, 18.0, 17.0, 22.0, 31.0, 286.0, 317.0, 19.0, 34.0, 19.0, 123.0, 4.0, 4.0, 10.0, 5.0, 26.0, 28.0, 21.0, 12.0, 9.0, 14.0, 26.0, 44.0, 31.0, 12.0, 13.0, 30.0, 6.0, 86.0, 21.0, 14.0, 19.0, 41.0, 17.0, 21.0, 9.0, 6.0, 11.0, 72.0, 18.0, 81.0, 21.0, 71.0, 25.0, 34.0, 16.0, 23.0, 56.0, 93.0, 14.0, 26.0, 17.0, 8.0, 37.0, 54.0, 63.0, 28.0, 61.0, 63.0, 11.0, 24.0, 19.0, 28.0, 38.0, 113.0, 94.0, 5.0, 39.0, 24.0, 12.0, 80.0, 40.0, 23.0, 31.0, 46.0, 14.0, 35.0, 61.0, 34.0, 8.0, 9.0, 78.0, 15.0, 7.0, 42.0, 30.0, 22.0, 20.0, 32.0, 32.0, 24.0, 41.0, 9.0, 39.0, 30.0, 61.0, 55.0, 13.0, 56.0, 14.0, 19.0, 13.0, 12.0, 74.0, 4.0, 62.0, 33.0, 11.0, 8.0, 40.0, 2.0, 6.0, 19.0, 22.0, 17.0, 12.0, 12.0, 37.0, 21.0, 72.0, 4.0, 32.0, 10.0, 5.0, 35.0, 53.0, 39.0, 36.0, 24.0, 26.0, 23.0, 6.0, 5.0, 16.0, 32.0, 23.0, 16.0, 133.0, 125.0, 82.0, 44.0, 58.0, 30.0, 18.0, 17.0, 20.0, 3.0, 103.0, 51.0, 15.0, 16.0, 5.0, 13.0, 8.0, 3.0, 13.0, 28.0, 16.0, 13.0, 28.0, 41.0, 27.0, 10.0, 73.0, 62.0, 26.0, 11.0, 18.0, 4.0, 39.0, 54.0, 15.0, 8.0, 26.0, 2.0, 71.0, 58.0, 26.0, 2.0, 13.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5652620215918287, "mean_inference_ms": 1.4575199341640797, "mean_action_processing_ms": 0.24490678749724729, "mean_env_wait_ms": 0.1880625650127141, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047980546951293945, "StateBufferConnector_ms": 0.0042459964752197266, "ViewRequirementAgentConnector_ms": 0.11720192432403564}, "num_episodes": 23, "episode_return_max": 71.19999999999995, "episode_return_min": -154.9000000000013, "episode_return_mean": -7.49799999999995, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.7188874779913, "num_env_steps_trained_throughput_per_sec": 368.7188874779913, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 10955.366, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10955.319, "sample_time_ms": 1355.54, "learn_time_ms": 9584.616, "learn_throughput": 417.335, "synch_weights_time_ms": 13.695}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-30-45", "timestamp": 1723645845, "time_this_iter_s": 10.857748985290527, "time_total_s": 365.2325382232666, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39aef98b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 365.2325382232666, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 41.913333333333334, "ram_util_percent": 83.42}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7095547684759058, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 1.7757259836587955, "policy_loss": -0.013090256433539763, "vf_loss": 1.7866723629848036, "vf_explained_var": 0.004746222464495866, "kl": 0.0071462361372134865, "entropy": 1.414803610844587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9656250102179391, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 1.4052536652517067, "policy_loss": -0.013424946800879543, "vf_loss": 1.417056613056748, "vf_explained_var": 0.01715331374022065, "kl": 0.00811000842204409, "entropy": 1.0764101205994843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 71.19999999999995, "episode_reward_min": -154.9000000000013, "episode_reward_mean": -4.749999999999922, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -259.29999999999853, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.50000000000022, "predator_policy": 133.0}, "policy_reward_mean": {"prey_policy": -31.35000000000004, "predator_policy": 28.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.800000000000114, 18.299999999999994, 52.40000000000044, 15.799999999999923, 19.999999999999975, -124.20000000000007, 40.500000000000306, -25.999999999999517, 27.600000000000104, 36.10000000000024, -51.29999999999987, -66.19999999999996, -17.699999999999562, 23.40000000000004, 16.89999999999995, -95.90000000000137, -29.19999999999952, 26.30000000000013, -32.799999999999756, 10.100000000000241, -58.60000000000069, 25.50000000000007, 1.499999999999946, -73.60000000000116, -91.99999999999991, -18.799999999999564, -77.60000000000005, 37.60000000000035, -46.79999999999987, 15.199999999999916, 9.599999999999964, 24.90000000000006, -43.39999999999958, -9.399999999999634, -17.199999999999505, -17.199999999999513, -17.400000000000006, -40.20000000000003, -34.09999999999954, 6.899999999999979, -33.19999999999954, 5.799999999999951, 59.30000000000047, -45.7999999999997, -64.50000000000165, 17.000000000000004, -6.199999999999688, 12.499999999999957, -2.899999999999957, 13.60000000000004, -7.8999999999996895, -42.69999999999982, 35.500000000000234, 6.5000000000001155, -33.89999999999954, 17.49999999999994, 2.9000000000001163, 52.200000000000465, -16.999999999999503, 40.60000000000031, 34.00000000000031, -46.39999999999958, -30.399999999999615, 11.400000000000063, 14.699999999999987, -154.9000000000013, 37.40000000000026, 71.19999999999995, 52.20000000000051, -15.599999999999506, 8.100000000000039, -28.69999999999954, 20.299999999999994, 9.099999999999962, 23.300000000000036, 17.899999999999952, -60.20000000000134, 14.700000000000022, 13.400000000000013, -101.90000000000154, 11.000000000000004, 25.70000000000007, -2.599999999999872, 40.3000000000003, -36.99999999999953, 37.50000000000026, 45.100000000000456, -10.599999999999609, -1.0999999999998709, 22.400000000000013, -24.899999999999515, -8.899999999999636, 15.599999999999977, 18.000000000000004, 32.80000000000018, 39.600000000000286, -60.00000000000061, -16.299999999999507, 43.40000000000035, 10.299999999999928], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.199999999999747, 20.000000000000014, 4.6999999999999655, -9.399999999999855, -70.30000000000089, 52.700000000000216, -66.10000000000082, 38.900000000000254, -42.99999999999976, 20.000000000000014, -72.40000000000003, -143.8000000000001, 38.000000000000256, -32.49999999999975, -42.99999999999976, -42.99999999999976, -24.099999999999746, 13.699999999999964, 1.0999999999999865, 20.000000000000014, 5.299999999999972, -139.6000000000001, -78.10000000000056, -87.0999999999999, -55.600000000000335, -54.099999999999945, 20.000000000000014, -55.600000000000335, -21.99999999999975, -0.09999999999996162, -147.30000000000055, -97.60000000000082, -34.59999999999976, -34.59999999999976, -18.699999999999818, 20.000000000000014, -103.90000000000063, -19.89999999999987, -114.3999999999999, 33.50000000000019, -160.60000000000062, -21.999999999999744, 20.000000000000014, -29.49999999999975, -53.499999999999766, 7.9999999999999725, -217.30000000000044, -7.299999999999891, -13.60000000000003, -177.4000000000002, -66.1000000000009, -15.69999999999979, -130.80000000000007, -38.80000000000002, 9.499999999999964, -34.8999999999998, -38.79999999999983, -85.00000000000063, -45.39999999999978, 11.59999999999997, -70.60000000000086, -14.799999999999953, 20.000000000000014, -12.099999999999817, -143.8000000000007, 7.399999999999947, -63.70000000000085, 5.299999999999965, -26.199999999999747, -42.99999999999976, -15.699999999999754, -53.499999999999766, -93.39999999999984, 20.000000000000014, -66.10000000000086, -24.099999999999753, -60.1000000000006, -42.99999999999976, 5.299999999999965, -114.40000000000077, -57.700000000000465, -44.499999999999844, -9.399999999999855, -17.80000000000002, 14.299999999999967, 20.000000000000014, -137.50000000000045, 13.699999999999967, -49.299999999999905, -110.20000000000076, -0.9999999999999846, -0.9999999999999846, -64.00000000000091, 15.799999999999963, -19.899999999999988, 7.399999999999965, 5.299999999999965, -47.19999999999976, -5.1999999999999265, -5.1999999999999265, -55.600000000000264, -10.299999999999873, -0.10000000000001391, -118.60000000000025, -47.19999999999976, 40.700000000000244, -53.50000000000019, 20.000000000000014, -34.59999999999975, -91.30000000000084, -26.49999999999975, -15.999999999999774, -28.29999999999975, -17.799999999999784, 30.800000000000203, 10.399999999999968, -49.299999999999876, -15.699999999999747, -28.29999999999975, 29.90000000000018, -259.29999999999853, 35.30000000000022, -108.40000000000077, -63.99999999999977, -42.99999999999976, -75.40000000000066, -5.799999999999924, -17.79999999999974, 13.699999999999964, -21.99999999999975, -196.30000000000055, -112.60000000000076, 20.000000000000014, -13.599999999999783, -7.299999999999891, 60.50000000000022, 4.999999999999966, 36.20000000000026, -34.59999999999975, -21.999999999999744, -36.699999999999754, 15.799999999999963, -66.1000000000009, -31.599999999999767, 26.300000000000114, -42.99999999999976, 17.899999999999988, -143.8000000000007, -34.59999999999976, 20.90000000000003, 9.499999999999973, -13.599999999999783, -85.00000000000085, -68.20000000000076, -11.499999999999819, 3.1999999999999615, -34.59999999999975, 20.000000000000014, -101.80000000000081, -129.10000000000073, -36.699999999999775, 19.70000000000001, 20.000000000000014, -7.299999999999891, 33.500000000000234, -87.10000000000068, -42.99999999999976, 26.300000000000114, -97.60000000000058, -9.399999999999855, 9.499999999999964, 20.000000000000014, 34.70000000000022, -34.59999999999975, -70.30000000000089, 13.699999999999966, 13.699999999999964, -62.800000000000665, 20.000000000000014, -13.599999999999783, -32.49999999999975, -51.399999999999764, -26.199999999999754, -36.699999999999754, -21.999999999999744, 5.599999999999971, -7.299999999999891, 5.299999999999965, 1.0999999999999581, 22.700000000000053, 5.600000000000014, 20.000000000000014, -81.4000000000004, -37.59999999999979, -40.89999999999976, -30.39999999999975, -29.19999999999979, 17.599999999999984, -37.29999999999978, 11.599999999999964], "policy_predator_policy_reward": [21.0, 12.0, 9.0, 14.0, 26.0, 44.0, 31.0, 12.0, 13.0, 30.0, 6.0, 86.0, 21.0, 14.0, 19.0, 41.0, 17.0, 21.0, 9.0, 6.0, 11.0, 72.0, 18.0, 81.0, 21.0, 71.0, 25.0, 34.0, 16.0, 23.0, 56.0, 93.0, 14.0, 26.0, 17.0, 8.0, 37.0, 54.0, 63.0, 28.0, 61.0, 63.0, 11.0, 24.0, 19.0, 28.0, 38.0, 113.0, 94.0, 5.0, 39.0, 24.0, 12.0, 80.0, 40.0, 23.0, 31.0, 46.0, 14.0, 35.0, 61.0, 34.0, 8.0, 9.0, 78.0, 15.0, 7.0, 42.0, 30.0, 22.0, 20.0, 32.0, 32.0, 24.0, 41.0, 9.0, 39.0, 30.0, 61.0, 55.0, 13.0, 56.0, 14.0, 19.0, 13.0, 12.0, 74.0, 4.0, 62.0, 33.0, 11.0, 8.0, 40.0, 2.0, 6.0, 19.0, 22.0, 17.0, 12.0, 12.0, 37.0, 21.0, 72.0, 4.0, 32.0, 10.0, 5.0, 35.0, 53.0, 39.0, 36.0, 24.0, 26.0, 23.0, 6.0, 5.0, 16.0, 32.0, 23.0, 16.0, 133.0, 125.0, 82.0, 44.0, 58.0, 30.0, 18.0, 17.0, 20.0, 3.0, 103.0, 51.0, 15.0, 16.0, 5.0, 13.0, 8.0, 3.0, 13.0, 28.0, 16.0, 13.0, 28.0, 41.0, 27.0, 10.0, 73.0, 62.0, 26.0, 11.0, 18.0, 4.0, 39.0, 54.0, 15.0, 8.0, 26.0, 2.0, 71.0, 58.0, 26.0, 2.0, 13.0, 0.0, 51.0, 0.0, 28.0, 29.0, 37.0, 33.0, 3.0, 5.0, 14.0, 31.0, 3.0, 43.0, 13.0, 35.0, 11.0, 5.0, 28.0, 31.0, 24.0, 30.0, 12.0, 20.0, 13.0, 7.0, 5.0, 4.0, 12.0, 2.0, 28.0, 31.0, 26.0, 29.0, 25.0, 30.0, 20.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5678010500215734, "mean_inference_ms": 1.4658060743940462, "mean_action_processing_ms": 0.24569673496402775, "mean_env_wait_ms": 0.18932886451316336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004730343818664551, "StateBufferConnector_ms": 0.004331111907958984, "ViewRequirementAgentConnector_ms": 0.12014198303222656}, "num_episodes": 18, "episode_return_max": 71.19999999999995, "episode_return_min": -154.9000000000013, "episode_return_mean": -4.749999999999922, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 383.865949156, "num_env_steps_trained_throughput_per_sec": 383.865949156, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 10988.133, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10988.088, "sample_time_ms": 1333.552, "learn_time_ms": 9639.798, "learn_throughput": 414.946, "synch_weights_time_ms": 13.354}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-30-55", "timestamp": 1723645855, "time_this_iter_s": 10.477005004882812, "time_total_s": 375.7095432281494, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0add30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 375.7095432281494, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 39.633333333333326, "ram_util_percent": 83.33999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5026758942339156, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 1.9263989341006709, "policy_loss": -0.010907661321168894, "vf_loss": 1.9352004880627627, "vf_explained_var": 0.018187744150716792, "kl": 0.007020350605021647, "entropy": 1.410796275088396, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6490698290565027, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 1.642988464662007, "policy_loss": -0.00958953795525881, "vf_loss": 1.651046949656552, "vf_explained_var": 0.04697275309966355, "kl": 0.007655261444545363, "entropy": 1.0960279954804315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 71.19999999999995, "episode_reward_min": -154.9000000000013, "episode_reward_mean": -1.989999999999896, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -259.29999999999853, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.50000000000022, "predator_policy": 133.0}, "policy_reward_mean": {"prey_policy": -28.355000000000047, "predator_policy": 27.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.799999999999756, 10.100000000000241, -58.60000000000069, 25.50000000000007, 1.499999999999946, -73.60000000000116, -91.99999999999991, -18.799999999999564, -77.60000000000005, 37.60000000000035, -46.79999999999987, 15.199999999999916, 9.599999999999964, 24.90000000000006, -43.39999999999958, -9.399999999999634, -17.199999999999505, -17.199999999999513, -17.400000000000006, -40.20000000000003, -34.09999999999954, 6.899999999999979, -33.19999999999954, 5.799999999999951, 59.30000000000047, -45.7999999999997, -64.50000000000165, 17.000000000000004, -6.199999999999688, 12.499999999999957, -2.899999999999957, 13.60000000000004, -7.8999999999996895, -42.69999999999982, 35.500000000000234, 6.5000000000001155, -33.89999999999954, 17.49999999999994, 2.9000000000001163, 52.200000000000465, -16.999999999999503, 40.60000000000031, 34.00000000000031, -46.39999999999958, -30.399999999999615, 11.400000000000063, 14.699999999999987, -154.9000000000013, 37.40000000000026, 71.19999999999995, 52.20000000000051, -15.599999999999506, 8.100000000000039, -28.69999999999954, 20.299999999999994, 9.099999999999962, 23.300000000000036, 17.899999999999952, -60.20000000000134, 14.700000000000022, 13.400000000000013, -101.90000000000154, 11.000000000000004, 25.70000000000007, -2.599999999999872, 40.3000000000003, -36.99999999999953, 37.50000000000026, 45.100000000000456, -10.599999999999609, -1.0999999999998709, 22.400000000000013, -24.899999999999515, -8.899999999999636, 15.599999999999977, 18.000000000000004, 32.80000000000018, 39.600000000000286, -60.00000000000061, -16.299999999999507, 43.40000000000035, 10.299999999999928, 28.200000000000458, 48.90000000000046, -6.9999999999997495, 32.70000000000019, -27.699999999999527, -20.09999999999989, 24.600000000000048, 12.200000000000172, -19.49999999999953, 37.90000000000041, 25.200000000000063, 27.900000000000112, -75.20000000000154, 47.50000000000043, 27.900000000000283, 51.200000000000486, -26.199999999999548, -18.899999999999515], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-103.90000000000063, -19.89999999999987, -114.3999999999999, 33.50000000000019, -160.60000000000062, -21.999999999999744, 20.000000000000014, -29.49999999999975, -53.499999999999766, 7.9999999999999725, -217.30000000000044, -7.299999999999891, -13.60000000000003, -177.4000000000002, -66.1000000000009, -15.69999999999979, -130.80000000000007, -38.80000000000002, 9.499999999999964, -34.8999999999998, -38.79999999999983, -85.00000000000063, -45.39999999999978, 11.59999999999997, -70.60000000000086, -14.799999999999953, 20.000000000000014, -12.099999999999817, -143.8000000000007, 7.399999999999947, -63.70000000000085, 5.299999999999965, -26.199999999999747, -42.99999999999976, -15.699999999999754, -53.499999999999766, -93.39999999999984, 20.000000000000014, -66.10000000000086, -24.099999999999753, -60.1000000000006, -42.99999999999976, 5.299999999999965, -114.40000000000077, -57.700000000000465, -44.499999999999844, -9.399999999999855, -17.80000000000002, 14.299999999999967, 20.000000000000014, -137.50000000000045, 13.699999999999967, -49.299999999999905, -110.20000000000076, -0.9999999999999846, -0.9999999999999846, -64.00000000000091, 15.799999999999963, -19.899999999999988, 7.399999999999965, 5.299999999999965, -47.19999999999976, -5.1999999999999265, -5.1999999999999265, -55.600000000000264, -10.299999999999873, -0.10000000000001391, -118.60000000000025, -47.19999999999976, 40.700000000000244, -53.50000000000019, 20.000000000000014, -34.59999999999975, -91.30000000000084, -26.49999999999975, -15.999999999999774, -28.29999999999975, -17.799999999999784, 30.800000000000203, 10.399999999999968, -49.299999999999876, -15.699999999999747, -28.29999999999975, 29.90000000000018, -259.29999999999853, 35.30000000000022, -108.40000000000077, -63.99999999999977, -42.99999999999976, -75.40000000000066, -5.799999999999924, -17.79999999999974, 13.699999999999964, -21.99999999999975, -196.30000000000055, -112.60000000000076, 20.000000000000014, -13.599999999999783, -7.299999999999891, 60.50000000000022, 4.999999999999966, 36.20000000000026, -34.59999999999975, -21.999999999999744, -36.699999999999754, 15.799999999999963, -66.1000000000009, -31.599999999999767, 26.300000000000114, -42.99999999999976, 17.899999999999988, -143.8000000000007, -34.59999999999976, 20.90000000000003, 9.499999999999973, -13.599999999999783, -85.00000000000085, -68.20000000000076, -11.499999999999819, 3.1999999999999615, -34.59999999999975, 20.000000000000014, -101.80000000000081, -129.10000000000073, -36.699999999999775, 19.70000000000001, 20.000000000000014, -7.299999999999891, 33.500000000000234, -87.10000000000068, -42.99999999999976, 26.300000000000114, -97.60000000000058, -9.399999999999855, 9.499999999999964, 20.000000000000014, 34.70000000000022, -34.59999999999975, -70.30000000000089, 13.699999999999966, 13.699999999999964, -62.800000000000665, 20.000000000000014, -13.599999999999783, -32.49999999999975, -51.399999999999764, -26.199999999999754, -36.699999999999754, -21.999999999999744, 5.599999999999971, -7.299999999999891, 5.299999999999965, 1.0999999999999581, 22.700000000000053, 5.600000000000014, 20.000000000000014, -81.4000000000004, -37.59999999999979, -40.89999999999976, -30.39999999999975, -29.19999999999979, 17.599999999999984, -37.29999999999978, 11.599999999999964, 41.300000000000246, -45.09999999999998, 13.699999999999964, 30.200000000000195, 40.40000000000018, -114.40000000000077, 2.299999999999968, 7.399999999999965, -61.900000000000766, -38.799999999999756, -76.60000000000026, -11.499999999999819, 5.299999999999965, 5.299999999999965, -22.00000000000003, 3.1999999999999615, 12.799999999999967, -91.30000000000078, 59.90000000000021, -64.00000000000037, -13.599999999999786, 21.80000000000004, 15.799999999999962, -7.8999999999998884, -74.5000000000005, -78.70000000000053, -9.399999999999855, 38.90000000000023, -30.399999999999842, 26.300000000000118, 9.499999999999964, 31.700000000000212, -87.10000000000085, -9.099999999999884, -8.799999999999871, -66.10000000000082], "policy_predator_policy_reward": [37.0, 54.0, 63.0, 28.0, 61.0, 63.0, 11.0, 24.0, 19.0, 28.0, 38.0, 113.0, 94.0, 5.0, 39.0, 24.0, 12.0, 80.0, 40.0, 23.0, 31.0, 46.0, 14.0, 35.0, 61.0, 34.0, 8.0, 9.0, 78.0, 15.0, 7.0, 42.0, 30.0, 22.0, 20.0, 32.0, 32.0, 24.0, 41.0, 9.0, 39.0, 30.0, 61.0, 55.0, 13.0, 56.0, 14.0, 19.0, 13.0, 12.0, 74.0, 4.0, 62.0, 33.0, 11.0, 8.0, 40.0, 2.0, 6.0, 19.0, 22.0, 17.0, 12.0, 12.0, 37.0, 21.0, 72.0, 4.0, 32.0, 10.0, 5.0, 35.0, 53.0, 39.0, 36.0, 24.0, 26.0, 23.0, 6.0, 5.0, 16.0, 32.0, 23.0, 16.0, 133.0, 125.0, 82.0, 44.0, 58.0, 30.0, 18.0, 17.0, 20.0, 3.0, 103.0, 51.0, 15.0, 16.0, 5.0, 13.0, 8.0, 3.0, 13.0, 28.0, 16.0, 13.0, 28.0, 41.0, 27.0, 10.0, 73.0, 62.0, 26.0, 11.0, 18.0, 4.0, 39.0, 54.0, 15.0, 8.0, 26.0, 2.0, 71.0, 58.0, 26.0, 2.0, 13.0, 0.0, 51.0, 0.0, 28.0, 29.0, 37.0, 33.0, 3.0, 5.0, 14.0, 31.0, 3.0, 43.0, 13.0, 35.0, 11.0, 5.0, 28.0, 31.0, 24.0, 30.0, 12.0, 20.0, 13.0, 7.0, 5.0, 4.0, 12.0, 2.0, 28.0, 31.0, 26.0, 29.0, 25.0, 30.0, 20.0, 16.0, 7.0, 25.0, 3.0, 2.0, 33.0, 34.0, 17.0, 6.0, 39.0, 34.0, 53.0, 15.0, 7.0, 7.0, 8.0, 23.0, 6.0, 53.0, 40.0, 2.0, 16.0, 1.0, 15.0, 5.0, 36.0, 42.0, 14.0, 4.0, 19.0, 13.0, 5.0, 5.0, 19.0, 51.0, 15.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5691678211856658, "mean_inference_ms": 1.4699802232073385, "mean_action_processing_ms": 0.24599813380382202, "mean_env_wait_ms": 0.19002853695918454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043315887451171875, "StateBufferConnector_ms": 0.0040760040283203125, "ViewRequirementAgentConnector_ms": 0.11440610885620117}, "num_episodes": 18, "episode_return_max": 71.19999999999995, "episode_return_min": -154.9000000000013, "episode_return_mean": -1.989999999999896, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 399.8959049346429, "num_env_steps_trained_throughput_per_sec": 399.8959049346429, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 10933.599, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10933.556, "sample_time_ms": 1295.557, "learn_time_ms": 9623.524, "learn_throughput": 415.648, "synch_weights_time_ms": 13.12}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-31-05", "timestamp": 1723645865, "time_this_iter_s": 10.007853031158447, "time_total_s": 385.71739625930786, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0fb820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 385.71739625930786, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 34.14666666666667, "ram_util_percent": 81.22000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5943652114224813, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.363650028415458, "policy_loss": -0.011556015554914083, "vf_loss": 2.372751815230758, "vf_explained_var": 0.01934084696744485, "kl": 0.008180778580338867, "entropy": 1.4314901830027342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5578683437178376, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.2871418365725766, "policy_loss": -0.012872505538835727, "vf_loss": 2.2976796870509153, "vf_explained_var": 0.025384085487436366, "kl": 0.011673262364579795, "entropy": 1.073336057341288, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 71.19999999999995, "episode_reward_min": -175.50000000000117, "episode_reward_mean": 1.7610000000000958, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -259.29999999999853, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.50000000000022, "predator_policy": 133.0}, "policy_reward_mean": {"prey_policy": -24.164500000000036, "predator_policy": 25.045}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-33.19999999999954, 5.799999999999951, 59.30000000000047, -45.7999999999997, -64.50000000000165, 17.000000000000004, -6.199999999999688, 12.499999999999957, -2.899999999999957, 13.60000000000004, -7.8999999999996895, -42.69999999999982, 35.500000000000234, 6.5000000000001155, -33.89999999999954, 17.49999999999994, 2.9000000000001163, 52.200000000000465, -16.999999999999503, 40.60000000000031, 34.00000000000031, -46.39999999999958, -30.399999999999615, 11.400000000000063, 14.699999999999987, -154.9000000000013, 37.40000000000026, 71.19999999999995, 52.20000000000051, -15.599999999999506, 8.100000000000039, -28.69999999999954, 20.299999999999994, 9.099999999999962, 23.300000000000036, 17.899999999999952, -60.20000000000134, 14.700000000000022, 13.400000000000013, -101.90000000000154, 11.000000000000004, 25.70000000000007, -2.599999999999872, 40.3000000000003, -36.99999999999953, 37.50000000000026, 45.100000000000456, -10.599999999999609, -1.0999999999998709, 22.400000000000013, -24.899999999999515, -8.899999999999636, 15.599999999999977, 18.000000000000004, 32.80000000000018, 39.600000000000286, -60.00000000000061, -16.299999999999507, 43.40000000000035, 10.299999999999928, 28.200000000000458, 48.90000000000046, -6.9999999999997495, 32.70000000000019, -27.699999999999527, -20.09999999999989, 24.600000000000048, 12.200000000000172, -19.49999999999953, 37.90000000000041, 25.200000000000063, 27.900000000000112, -75.20000000000154, 47.50000000000043, 27.900000000000283, 51.200000000000486, -26.199999999999548, -18.899999999999515, -125.1999999999998, 9.700000000000097, 19.600000000000005, -1.1999999999998496, 25.700000000000067, -175.50000000000117, 55.10000000000046, 35.600000000000236, -36.99999999999954, 38.60000000000028, 24.60000000000005, -28.399999999999665, 35.600000000000236, 47.20000000000037, 36.00000000000024, -79.50000000000145, 15.000000000000021, 27.4000000000001, 13.299999999999905, -55.499999999999936, 36.50000000000025, 9.700000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-57.700000000000465, -44.499999999999844, -9.399999999999855, -17.80000000000002, 14.299999999999967, 20.000000000000014, -137.50000000000045, 13.699999999999967, -49.299999999999905, -110.20000000000076, -0.9999999999999846, -0.9999999999999846, -64.00000000000091, 15.799999999999963, -19.899999999999988, 7.399999999999965, 5.299999999999965, -47.19999999999976, -5.1999999999999265, -5.1999999999999265, -55.600000000000264, -10.299999999999873, -0.10000000000001391, -118.60000000000025, -47.19999999999976, 40.700000000000244, -53.50000000000019, 20.000000000000014, -34.59999999999975, -91.30000000000084, -26.49999999999975, -15.999999999999774, -28.29999999999975, -17.799999999999784, 30.800000000000203, 10.399999999999968, -49.299999999999876, -15.699999999999747, -28.29999999999975, 29.90000000000018, -259.29999999999853, 35.30000000000022, -108.40000000000077, -63.99999999999977, -42.99999999999976, -75.40000000000066, -5.799999999999924, -17.79999999999974, 13.699999999999964, -21.99999999999975, -196.30000000000055, -112.60000000000076, 20.000000000000014, -13.599999999999783, -7.299999999999891, 60.50000000000022, 4.999999999999966, 36.20000000000026, -34.59999999999975, -21.999999999999744, -36.699999999999754, 15.799999999999963, -66.1000000000009, -31.599999999999767, 26.300000000000114, -42.99999999999976, 17.899999999999988, -143.8000000000007, -34.59999999999976, 20.90000000000003, 9.499999999999973, -13.599999999999783, -85.00000000000085, -68.20000000000076, -11.499999999999819, 3.1999999999999615, -34.59999999999975, 20.000000000000014, -101.80000000000081, -129.10000000000073, -36.699999999999775, 19.70000000000001, 20.000000000000014, -7.299999999999891, 33.500000000000234, -87.10000000000068, -42.99999999999976, 26.300000000000114, -97.60000000000058, -9.399999999999855, 9.499999999999964, 20.000000000000014, 34.70000000000022, -34.59999999999975, -70.30000000000089, 13.699999999999966, 13.699999999999964, -62.800000000000665, 20.000000000000014, -13.599999999999783, -32.49999999999975, -51.399999999999764, -26.199999999999754, -36.699999999999754, -21.999999999999744, 5.599999999999971, -7.299999999999891, 5.299999999999965, 1.0999999999999581, 22.700000000000053, 5.600000000000014, 20.000000000000014, -81.4000000000004, -37.59999999999979, -40.89999999999976, -30.39999999999975, -29.19999999999979, 17.599999999999984, -37.29999999999978, 11.599999999999964, 41.300000000000246, -45.09999999999998, 13.699999999999964, 30.200000000000195, 40.40000000000018, -114.40000000000077, 2.299999999999968, 7.399999999999965, -61.900000000000766, -38.799999999999756, -76.60000000000026, -11.499999999999819, 5.299999999999965, 5.299999999999965, -22.00000000000003, 3.1999999999999615, 12.799999999999967, -91.30000000000078, 59.90000000000021, -64.00000000000037, -13.599999999999786, 21.80000000000004, 15.799999999999962, -7.8999999999998884, -74.5000000000005, -78.70000000000053, -9.399999999999855, 38.90000000000023, -30.399999999999842, 26.300000000000118, 9.499999999999964, 31.700000000000212, -87.10000000000085, -9.099999999999884, -8.799999999999871, -66.10000000000082, -82.90000000000006, -133.3, 1.0999999999999723, -9.399999999999855, -55.30000000000022, 20.900000000000027, -57.70000000000028, 9.499999999999964, 5.299999999999965, 7.399999999999965, -103.90000000000049, -202.60000000000048, 50.60000000000023, -11.499999999999819, 13.699999999999964, 17.899999999999988, -114.40000000000055, 7.399999999999965, 23.600000000000065, -0.9999999999999846, -3.0999999999999615, 13.699999999999964, -240.40000000000043, 29.000000000000167, 13.699999999999964, 17.899999999999988, -53.50000000000008, 55.70000000000018, 20.000000000000014, -21.999999999999744, -152.20000000000067, -49.29999999999976, -0.9999999999999846, -0.9999999999999846, -55.60000000000012, 20.000000000000014, -20.499999999999886, 3.7999999999999656, 32.90000000000023, -219.40000000000032, 9.499999999999964, 20.000000000000014, -38.79999999999991, -5.49999999999994], "policy_predator_policy_reward": [13.0, 56.0, 14.0, 19.0, 13.0, 12.0, 74.0, 4.0, 62.0, 33.0, 11.0, 8.0, 40.0, 2.0, 6.0, 19.0, 22.0, 17.0, 12.0, 12.0, 37.0, 21.0, 72.0, 4.0, 32.0, 10.0, 5.0, 35.0, 53.0, 39.0, 36.0, 24.0, 26.0, 23.0, 6.0, 5.0, 16.0, 32.0, 23.0, 16.0, 133.0, 125.0, 82.0, 44.0, 58.0, 30.0, 18.0, 17.0, 20.0, 3.0, 103.0, 51.0, 15.0, 16.0, 5.0, 13.0, 8.0, 3.0, 13.0, 28.0, 16.0, 13.0, 28.0, 41.0, 27.0, 10.0, 73.0, 62.0, 26.0, 11.0, 18.0, 4.0, 39.0, 54.0, 15.0, 8.0, 26.0, 2.0, 71.0, 58.0, 26.0, 2.0, 13.0, 0.0, 51.0, 0.0, 28.0, 29.0, 37.0, 33.0, 3.0, 5.0, 14.0, 31.0, 3.0, 43.0, 13.0, 35.0, 11.0, 5.0, 28.0, 31.0, 24.0, 30.0, 12.0, 20.0, 13.0, 7.0, 5.0, 4.0, 12.0, 2.0, 28.0, 31.0, 26.0, 29.0, 25.0, 30.0, 20.0, 16.0, 7.0, 25.0, 3.0, 2.0, 33.0, 34.0, 17.0, 6.0, 39.0, 34.0, 53.0, 15.0, 7.0, 7.0, 8.0, 23.0, 6.0, 53.0, 40.0, 2.0, 16.0, 1.0, 15.0, 5.0, 36.0, 42.0, 14.0, 4.0, 19.0, 13.0, 5.0, 5.0, 19.0, 51.0, 15.0, 41.0, 11.0, 80.0, 5.0, 13.0, 28.0, 26.0, 23.0, 24.0, 7.0, 6.0, 69.0, 62.0, 15.0, 1.0, 1.0, 3.0, 64.0, 6.0, 6.0, 10.0, 11.0, 3.0, 112.0, 71.0, 3.0, 1.0, 6.0, 39.0, 18.0, 20.0, 83.0, 39.0, 7.0, 10.0, 33.0, 30.0, 17.0, 13.0, 39.0, 92.0, 3.0, 4.0, 42.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.57025553593767, "mean_inference_ms": 1.4758492886568184, "mean_action_processing_ms": 0.24576750354534732, "mean_env_wait_ms": 0.19055007407629979, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004170775413513184, "StateBufferConnector_ms": 0.003834962844848633, "ViewRequirementAgentConnector_ms": 0.10800397396087646}, "num_episodes": 22, "episode_return_max": 71.19999999999995, "episode_return_min": -175.50000000000117, "episode_return_mean": 1.7610000000000958, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 389.8417340082076, "num_env_steps_trained_throughput_per_sec": 389.8417340082076, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 10783.078, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10783.036, "sample_time_ms": 1305.247, "learn_time_ms": 9463.347, "learn_throughput": 422.683, "synch_weights_time_ms": 13.217}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-31-16", "timestamp": 1723645876, "time_this_iter_s": 10.309428930282593, "time_total_s": 396.02682518959045, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0adca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 396.02682518959045, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 37.07857142857143, "ram_util_percent": 81.02142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6654849572156472, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.6413574530964805, "policy_loss": -0.009306352267968197, "vf_loss": 2.648423806700126, "vf_explained_var": 0.012209390616290785, "kl": 0.007466639881378854, "entropy": 1.3607757892558183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.786153801692226, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.754473092694762, "policy_loss": -0.014644797457253965, "vf_loss": 2.7669376599725592, "vf_explained_var": 0.01576988283919279, "kl": 0.0109011391013025, "entropy": 1.1977883009683519, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 71.19999999999995, "episode_reward_min": -272.59999999999957, "episode_reward_mean": -1.5189999999999046, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -347.99999999999926, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.50000000000022, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": -25.95950000000003, "predator_policy": 25.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.400000000000063, 14.699999999999987, -154.9000000000013, 37.40000000000026, 71.19999999999995, 52.20000000000051, -15.599999999999506, 8.100000000000039, -28.69999999999954, 20.299999999999994, 9.099999999999962, 23.300000000000036, 17.899999999999952, -60.20000000000134, 14.700000000000022, 13.400000000000013, -101.90000000000154, 11.000000000000004, 25.70000000000007, -2.599999999999872, 40.3000000000003, -36.99999999999953, 37.50000000000026, 45.100000000000456, -10.599999999999609, -1.0999999999998709, 22.400000000000013, -24.899999999999515, -8.899999999999636, 15.599999999999977, 18.000000000000004, 32.80000000000018, 39.600000000000286, -60.00000000000061, -16.299999999999507, 43.40000000000035, 10.299999999999928, 28.200000000000458, 48.90000000000046, -6.9999999999997495, 32.70000000000019, -27.699999999999527, -20.09999999999989, 24.600000000000048, 12.200000000000172, -19.49999999999953, 37.90000000000041, 25.200000000000063, 27.900000000000112, -75.20000000000154, 47.50000000000043, 27.900000000000283, 51.200000000000486, -26.199999999999548, -18.899999999999515, -125.1999999999998, 9.700000000000097, 19.600000000000005, -1.1999999999998496, 25.700000000000067, -175.50000000000117, 55.10000000000046, 35.600000000000236, -36.99999999999954, 38.60000000000028, 24.60000000000005, -28.399999999999665, 35.600000000000236, 47.20000000000037, 36.00000000000024, -79.50000000000145, 15.000000000000021, 27.4000000000001, 13.299999999999905, -55.499999999999936, 36.50000000000025, 9.700000000000015, 38.90000000000028, 2.6000000000001657, -4.500000000000071, 2.00000000000008, -31.399999999999565, 28.50000000000013, 47.90000000000044, 26.900000000000087, -4.199999999999703, 20.19999999999998, -33.799999999999955, -18.399999999999494, -27.099999999999504, 57.600000000000485, 14.499999999999924, 18.199999999999974, 33.0000000000002, -6.300000000000063, -272.59999999999957, -39.299999999999706, 41.90000000000033, -14.799999999999978, -241.30000000000095], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.799999999999924, -17.79999999999974, 13.699999999999964, -21.99999999999975, -196.30000000000055, -112.60000000000076, 20.000000000000014, -13.599999999999783, -7.299999999999891, 60.50000000000022, 4.999999999999966, 36.20000000000026, -34.59999999999975, -21.999999999999744, -36.699999999999754, 15.799999999999963, -66.1000000000009, -31.599999999999767, 26.300000000000114, -42.99999999999976, 17.899999999999988, -143.8000000000007, -34.59999999999976, 20.90000000000003, 9.499999999999973, -13.599999999999783, -85.00000000000085, -68.20000000000076, -11.499999999999819, 3.1999999999999615, -34.59999999999975, 20.000000000000014, -101.80000000000081, -129.10000000000073, -36.699999999999775, 19.70000000000001, 20.000000000000014, -7.299999999999891, 33.500000000000234, -87.10000000000068, -42.99999999999976, 26.300000000000114, -97.60000000000058, -9.399999999999855, 9.499999999999964, 20.000000000000014, 34.70000000000022, -34.59999999999975, -70.30000000000089, 13.699999999999966, 13.699999999999964, -62.800000000000665, 20.000000000000014, -13.599999999999783, -32.49999999999975, -51.399999999999764, -26.199999999999754, -36.699999999999754, -21.999999999999744, 5.599999999999971, -7.299999999999891, 5.299999999999965, 1.0999999999999581, 22.700000000000053, 5.600000000000014, 20.000000000000014, -81.4000000000004, -37.59999999999979, -40.89999999999976, -30.39999999999975, -29.19999999999979, 17.599999999999984, -37.29999999999978, 11.599999999999964, 41.300000000000246, -45.09999999999998, 13.699999999999964, 30.200000000000195, 40.40000000000018, -114.40000000000077, 2.299999999999968, 7.399999999999965, -61.900000000000766, -38.799999999999756, -76.60000000000026, -11.499999999999819, 5.299999999999965, 5.299999999999965, -22.00000000000003, 3.1999999999999615, 12.799999999999967, -91.30000000000078, 59.90000000000021, -64.00000000000037, -13.599999999999786, 21.80000000000004, 15.799999999999962, -7.8999999999998884, -74.5000000000005, -78.70000000000053, -9.399999999999855, 38.90000000000023, -30.399999999999842, 26.300000000000118, 9.499999999999964, 31.700000000000212, -87.10000000000085, -9.099999999999884, -8.799999999999871, -66.10000000000082, -82.90000000000006, -133.3, 1.0999999999999723, -9.399999999999855, -55.30000000000022, 20.900000000000027, -57.70000000000028, 9.499999999999964, 5.299999999999965, 7.399999999999965, -103.90000000000049, -202.60000000000048, 50.60000000000023, -11.499999999999819, 13.699999999999964, 17.899999999999988, -114.40000000000055, 7.399999999999965, 23.600000000000065, -0.9999999999999846, -3.0999999999999615, 13.699999999999964, -240.40000000000043, 29.000000000000167, 13.699999999999964, 17.899999999999988, -53.50000000000008, 55.70000000000018, 20.000000000000014, -21.999999999999744, -152.20000000000067, -49.29999999999976, -0.9999999999999846, -0.9999999999999846, -55.60000000000012, 20.000000000000014, -20.499999999999886, 3.7999999999999656, 32.90000000000023, -219.40000000000032, 9.499999999999964, 20.000000000000014, -38.79999999999991, -5.49999999999994, 17.899999999999988, 20.000000000000014, -66.10000000000086, 25.700000000000117, -8.7999999999999, -120.70000000000027, 29.000000000000163, -127.00000000000074, -49.299999999999905, -42.09999999999976, -36.699999999999754, 27.20000000000013, 36.800000000000246, 1.0999999999999865, 9.499999999999964, 7.399999999999965, -53.500000000000135, 5.299999999999965, 27.20000000000013, -42.99999999999976, -190.00000000000023, 3.1999999999999615, -30.39999999999975, -21.999999999999744, -38.799999999999756, -28.29999999999975, 15.79999999999996, 30.800000000000196, 9.499999999999964, -27.999999999999794, -7.299999999999983, 9.499999999999988, -7.299999999999891, 8.299999999999969, -27.39999999999975, -52.89999999999989, -244.60000000000025, -347.99999999999926, -28.29999999999975, -85.00000000000077, -15.699999999999747, 35.600000000000236, -0.9999999999999917, -80.79999999999998, -206.8000000000004, -158.50000000000054], "policy_predator_policy_reward": [18.0, 17.0, 20.0, 3.0, 103.0, 51.0, 15.0, 16.0, 5.0, 13.0, 8.0, 3.0, 13.0, 28.0, 16.0, 13.0, 28.0, 41.0, 27.0, 10.0, 73.0, 62.0, 26.0, 11.0, 18.0, 4.0, 39.0, 54.0, 15.0, 8.0, 26.0, 2.0, 71.0, 58.0, 26.0, 2.0, 13.0, 0.0, 51.0, 0.0, 28.0, 29.0, 37.0, 33.0, 3.0, 5.0, 14.0, 31.0, 3.0, 43.0, 13.0, 35.0, 11.0, 5.0, 28.0, 31.0, 24.0, 30.0, 12.0, 20.0, 13.0, 7.0, 5.0, 4.0, 12.0, 2.0, 28.0, 31.0, 26.0, 29.0, 25.0, 30.0, 20.0, 16.0, 7.0, 25.0, 3.0, 2.0, 33.0, 34.0, 17.0, 6.0, 39.0, 34.0, 53.0, 15.0, 7.0, 7.0, 8.0, 23.0, 6.0, 53.0, 40.0, 2.0, 16.0, 1.0, 15.0, 5.0, 36.0, 42.0, 14.0, 4.0, 19.0, 13.0, 5.0, 5.0, 19.0, 51.0, 15.0, 41.0, 11.0, 80.0, 5.0, 13.0, 28.0, 26.0, 23.0, 24.0, 7.0, 6.0, 69.0, 62.0, 15.0, 1.0, 1.0, 3.0, 64.0, 6.0, 6.0, 10.0, 11.0, 3.0, 112.0, 71.0, 3.0, 1.0, 6.0, 39.0, 18.0, 20.0, 83.0, 39.0, 7.0, 10.0, 33.0, 30.0, 17.0, 13.0, 39.0, 92.0, 3.0, 4.0, 42.0, 12.0, 1.0, 0.0, 41.0, 2.0, 68.0, 57.0, 38.0, 62.0, 34.0, 26.0, 11.0, 27.0, 1.0, 9.0, 4.0, 6.0, 27.0, 17.0, 6.0, 30.0, 84.0, 69.0, 26.0, 8.0, 12.0, 28.0, 11.0, 0.0, 5.0, 28.0, 5.0, 11.0, 16.0, 16.0, 9.0, 65.0, 154.0, 166.0, 23.0, 51.0, 17.0, 5.0, 31.0, 36.0, 100.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5712091190633043, "mean_inference_ms": 1.4788649617440743, "mean_action_processing_ms": 0.24679201324701378, "mean_env_wait_ms": 0.19091094540915837, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041675567626953125, "StateBufferConnector_ms": 0.0035240650177001953, "ViewRequirementAgentConnector_ms": 0.10807430744171143}, "num_episodes": 23, "episode_return_max": 71.19999999999995, "episode_return_min": -272.59999999999957, "episode_return_mean": -1.5189999999999046, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 390.35757312444235, "num_env_steps_trained_throughput_per_sec": 390.35757312444235, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 10710.148, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10710.107, "sample_time_ms": 1305.375, "learn_time_ms": 9390.43, "learn_throughput": 425.966, "synch_weights_time_ms": 13.106}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-31-26", "timestamp": 1723645886, "time_this_iter_s": 10.250499963760376, "time_total_s": 406.27732515335083, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ade50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 406.27732515335083, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 35.66, "ram_util_percent": 81.04}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5715773650893459, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.9768673295066472, "policy_loss": -0.012201085586899094, "vf_loss": 2.986635583607608, "vf_explained_var": 0.033511674151849496, "kl": 0.008109433056466582, "entropy": 1.346334246100572, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8445164164538106, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.076804512013834, "policy_loss": -0.01318730436864176, "vf_loss": 3.0878454579878105, "vf_explained_var": 0.011203203440973999, "kl": 0.010731813950715253, "entropy": 1.169701397608197, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 77.49999999999952, "episode_reward_min": -272.59999999999957, "episode_reward_mean": -1.4279999999998512, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -347.99999999999926, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 59.90000000000021, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": -26.599000000000025, "predator_policy": 25.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.70000000000007, -2.599999999999872, 40.3000000000003, -36.99999999999953, 37.50000000000026, 45.100000000000456, -10.599999999999609, -1.0999999999998709, 22.400000000000013, -24.899999999999515, -8.899999999999636, 15.599999999999977, 18.000000000000004, 32.80000000000018, 39.600000000000286, -60.00000000000061, -16.299999999999507, 43.40000000000035, 10.299999999999928, 28.200000000000458, 48.90000000000046, -6.9999999999997495, 32.70000000000019, -27.699999999999527, -20.09999999999989, 24.600000000000048, 12.200000000000172, -19.49999999999953, 37.90000000000041, 25.200000000000063, 27.900000000000112, -75.20000000000154, 47.50000000000043, 27.900000000000283, 51.200000000000486, -26.199999999999548, -18.899999999999515, -125.1999999999998, 9.700000000000097, 19.600000000000005, -1.1999999999998496, 25.700000000000067, -175.50000000000117, 55.10000000000046, 35.600000000000236, -36.99999999999954, 38.60000000000028, 24.60000000000005, -28.399999999999665, 35.600000000000236, 47.20000000000037, 36.00000000000024, -79.50000000000145, 15.000000000000021, 27.4000000000001, 13.299999999999905, -55.499999999999936, 36.50000000000025, 9.700000000000015, 38.90000000000028, 2.6000000000001657, -4.500000000000071, 2.00000000000008, -31.399999999999565, 28.50000000000013, 47.90000000000044, 26.900000000000087, -4.199999999999703, 20.19999999999998, -33.799999999999955, -18.399999999999494, -27.099999999999504, 57.600000000000485, 14.499999999999924, 18.199999999999974, 33.0000000000002, -6.300000000000063, -272.59999999999957, -39.299999999999706, 41.90000000000033, -14.799999999999978, -241.30000000000095, -41.59999999999957, -12.199999999999582, 46.000000000000405, -79.29999999999968, 14.800000000000022, 5.8000000000001535, 63.8999999999997, 43.90000000000037, 77.49999999999952, 9.900000000000068, 31.90000000000017, -21.599999999999525, -30.599999999999575, 57.5000000000005, -171.3000000000006, -1.1999999999997502, -0.600000000000017, -40.299999999999656], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -7.299999999999891, 33.500000000000234, -87.10000000000068, -42.99999999999976, 26.300000000000114, -97.60000000000058, -9.399999999999855, 9.499999999999964, 20.000000000000014, 34.70000000000022, -34.59999999999975, -70.30000000000089, 13.699999999999966, 13.699999999999964, -62.800000000000665, 20.000000000000014, -13.599999999999783, -32.49999999999975, -51.399999999999764, -26.199999999999754, -36.699999999999754, -21.999999999999744, 5.599999999999971, -7.299999999999891, 5.299999999999965, 1.0999999999999581, 22.700000000000053, 5.600000000000014, 20.000000000000014, -81.4000000000004, -37.59999999999979, -40.89999999999976, -30.39999999999975, -29.19999999999979, 17.599999999999984, -37.29999999999978, 11.599999999999964, 41.300000000000246, -45.09999999999998, 13.699999999999964, 30.200000000000195, 40.40000000000018, -114.40000000000077, 2.299999999999968, 7.399999999999965, -61.900000000000766, -38.799999999999756, -76.60000000000026, -11.499999999999819, 5.299999999999965, 5.299999999999965, -22.00000000000003, 3.1999999999999615, 12.799999999999967, -91.30000000000078, 59.90000000000021, -64.00000000000037, -13.599999999999786, 21.80000000000004, 15.799999999999962, -7.8999999999998884, -74.5000000000005, -78.70000000000053, -9.399999999999855, 38.90000000000023, -30.399999999999842, 26.300000000000118, 9.499999999999964, 31.700000000000212, -87.10000000000085, -9.099999999999884, -8.799999999999871, -66.10000000000082, -82.90000000000006, -133.3, 1.0999999999999723, -9.399999999999855, -55.30000000000022, 20.900000000000027, -57.70000000000028, 9.499999999999964, 5.299999999999965, 7.399999999999965, -103.90000000000049, -202.60000000000048, 50.60000000000023, -11.499999999999819, 13.699999999999964, 17.899999999999988, -114.40000000000055, 7.399999999999965, 23.600000000000065, -0.9999999999999846, -3.0999999999999615, 13.699999999999964, -240.40000000000043, 29.000000000000167, 13.699999999999964, 17.899999999999988, -53.50000000000008, 55.70000000000018, 20.000000000000014, -21.999999999999744, -152.20000000000067, -49.29999999999976, -0.9999999999999846, -0.9999999999999846, -55.60000000000012, 20.000000000000014, -20.499999999999886, 3.7999999999999656, 32.90000000000023, -219.40000000000032, 9.499999999999964, 20.000000000000014, -38.79999999999991, -5.49999999999994, 17.899999999999988, 20.000000000000014, -66.10000000000086, 25.700000000000117, -8.7999999999999, -120.70000000000027, 29.000000000000163, -127.00000000000074, -49.299999999999905, -42.09999999999976, -36.699999999999754, 27.20000000000013, 36.800000000000246, 1.0999999999999865, 9.499999999999964, 7.399999999999965, -53.500000000000135, 5.299999999999965, 27.20000000000013, -42.99999999999976, -190.00000000000023, 3.1999999999999615, -30.39999999999975, -21.999999999999744, -38.799999999999756, -28.29999999999975, 15.79999999999996, 30.800000000000196, 9.499999999999964, -27.999999999999794, -7.299999999999983, 9.499999999999988, -7.299999999999891, 8.299999999999969, -27.39999999999975, -52.89999999999989, -244.60000000000025, -347.99999999999926, -28.29999999999975, -85.00000000000077, -15.699999999999747, 35.600000000000236, -0.9999999999999917, -80.79999999999998, -206.8000000000004, -158.50000000000054, -161.90000000000018, -15.699999999999747, -9.399999999999862, -38.79999999999977, -24.099999999999746, 43.100000000000236, -78.69999999999989, -118.60000000000073, -5.1999999999999265, -0.9999999999999846, -4.899999999999942, -19.29999999999975, 0.500000000000199, 10.399999999999972, 9.499999999999964, 22.400000000000052, 28.10000000000015, 46.40000000000022, 18.799999999999997, -37.89999999999976, 21.800000000000043, 1.0999999999999865, -66.1000000000009, -11.499999999999833, -95.50000000000037, -0.09999999999999937, 33.50000000000024, 16.999999999999964, -150.10000000000034, -152.2000000000003, -28.29999999999975, -13.899999999999785, -177.40000000000038, -14.199999999999795, -106.00000000000068, -49.29999999999983], "policy_predator_policy_reward": [13.0, 0.0, 51.0, 0.0, 28.0, 29.0, 37.0, 33.0, 3.0, 5.0, 14.0, 31.0, 3.0, 43.0, 13.0, 35.0, 11.0, 5.0, 28.0, 31.0, 24.0, 30.0, 12.0, 20.0, 13.0, 7.0, 5.0, 4.0, 12.0, 2.0, 28.0, 31.0, 26.0, 29.0, 25.0, 30.0, 20.0, 16.0, 7.0, 25.0, 3.0, 2.0, 33.0, 34.0, 17.0, 6.0, 39.0, 34.0, 53.0, 15.0, 7.0, 7.0, 8.0, 23.0, 6.0, 53.0, 40.0, 2.0, 16.0, 1.0, 15.0, 5.0, 36.0, 42.0, 14.0, 4.0, 19.0, 13.0, 5.0, 5.0, 19.0, 51.0, 15.0, 41.0, 11.0, 80.0, 5.0, 13.0, 28.0, 26.0, 23.0, 24.0, 7.0, 6.0, 69.0, 62.0, 15.0, 1.0, 1.0, 3.0, 64.0, 6.0, 6.0, 10.0, 11.0, 3.0, 112.0, 71.0, 3.0, 1.0, 6.0, 39.0, 18.0, 20.0, 83.0, 39.0, 7.0, 10.0, 33.0, 30.0, 17.0, 13.0, 39.0, 92.0, 3.0, 4.0, 42.0, 12.0, 1.0, 0.0, 41.0, 2.0, 68.0, 57.0, 38.0, 62.0, 34.0, 26.0, 11.0, 27.0, 1.0, 9.0, 4.0, 6.0, 27.0, 17.0, 6.0, 30.0, 84.0, 69.0, 26.0, 8.0, 12.0, 28.0, 11.0, 0.0, 5.0, 28.0, 5.0, 11.0, 16.0, 16.0, 9.0, 65.0, 154.0, 166.0, 23.0, 51.0, 17.0, 5.0, 31.0, 36.0, 100.0, 24.0, 74.0, 62.0, 10.0, 26.0, 21.0, 6.0, 69.0, 49.0, 12.0, 9.0, 21.0, 9.0, 22.0, 31.0, 7.0, 5.0, 0.0, 3.0, 1.0, 28.0, 9.0, 0.0, 15.0, 41.0, 18.0, 47.0, 4.0, 3.0, 82.0, 49.0, 23.0, 18.0, 85.0, 106.0, 63.0, 52.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.571179808653554, "mean_inference_ms": 1.4777456576323382, "mean_action_processing_ms": 0.24612680529921094, "mean_env_wait_ms": 0.19108285915099243, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004131674766540527, "StateBufferConnector_ms": 0.003095865249633789, "ViewRequirementAgentConnector_ms": 0.0938652753829956}, "num_episodes": 18, "episode_return_max": 77.49999999999952, "episode_return_min": -272.59999999999957, "episode_return_mean": -1.4279999999998512, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.1516213664971, "num_env_steps_trained_throughput_per_sec": 409.1516213664971, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 10699.397, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10699.357, "sample_time_ms": 1294.045, "learn_time_ms": 9390.94, "learn_throughput": 425.942, "synch_weights_time_ms": 13.113}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-31-36", "timestamp": 1723645896, "time_this_iter_s": 9.782301902770996, "time_total_s": 416.0596270561218, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 416.0596270561218, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 31.385714285714283, "ram_util_percent": 81.39285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6021798438180692, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.7958482577056483, "policy_loss": -0.009139435784644866, "vf_loss": 3.8029467869057227, "vf_explained_var": 0.050951037741211985, "kl": 0.006802996829779062, "entropy": 1.3387826879188498, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6654143472197194, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.3965765068770715, "policy_loss": -0.013450292844532264, "vf_loss": 4.407643993947872, "vf_explained_var": 0.03037539342093089, "kl": 0.011914064037876168, "entropy": 1.1605662386253397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 77.49999999999952, "episode_reward_min": -272.59999999999957, "episode_reward_mean": -9.292999999999873, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -347.99999999999926, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 59.90000000000021, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": -34.25650000000004, "predator_policy": 29.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.299999999999928, 28.200000000000458, 48.90000000000046, -6.9999999999997495, 32.70000000000019, -27.699999999999527, -20.09999999999989, 24.600000000000048, 12.200000000000172, -19.49999999999953, 37.90000000000041, 25.200000000000063, 27.900000000000112, -75.20000000000154, 47.50000000000043, 27.900000000000283, 51.200000000000486, -26.199999999999548, -18.899999999999515, -125.1999999999998, 9.700000000000097, 19.600000000000005, -1.1999999999998496, 25.700000000000067, -175.50000000000117, 55.10000000000046, 35.600000000000236, -36.99999999999954, 38.60000000000028, 24.60000000000005, -28.399999999999665, 35.600000000000236, 47.20000000000037, 36.00000000000024, -79.50000000000145, 15.000000000000021, 27.4000000000001, 13.299999999999905, -55.499999999999936, 36.50000000000025, 9.700000000000015, 38.90000000000028, 2.6000000000001657, -4.500000000000071, 2.00000000000008, -31.399999999999565, 28.50000000000013, 47.90000000000044, 26.900000000000087, -4.199999999999703, 20.19999999999998, -33.799999999999955, -18.399999999999494, -27.099999999999504, 57.600000000000485, 14.499999999999924, 18.199999999999974, 33.0000000000002, -6.300000000000063, -272.59999999999957, -39.299999999999706, 41.90000000000033, -14.799999999999978, -241.30000000000095, -41.59999999999957, -12.199999999999582, 46.000000000000405, -79.29999999999968, 14.800000000000022, 5.8000000000001535, 63.8999999999997, 43.90000000000037, 77.49999999999952, 9.900000000000068, 31.90000000000017, -21.599999999999525, -30.599999999999575, 57.5000000000005, -171.3000000000006, -1.1999999999997502, -0.600000000000017, -40.299999999999656, 36.70000000000025, -77.60000000000043, -48.099999999999724, -54.499999999999595, 36.200000000000244, 49.100000000000456, -150.10000000000008, 21.299999999999994, 19.099999999999973, -21.999999999999766, -28.099999999999802, -263.60000000000014, 25.30000000000006, -59.80000000000096, -50.49999999999961, -8.39999999999968, -18.29999999999955, -34.199999999999946], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-37.29999999999978, 11.599999999999964, 41.300000000000246, -45.09999999999998, 13.699999999999964, 30.200000000000195, 40.40000000000018, -114.40000000000077, 2.299999999999968, 7.399999999999965, -61.900000000000766, -38.799999999999756, -76.60000000000026, -11.499999999999819, 5.299999999999965, 5.299999999999965, -22.00000000000003, 3.1999999999999615, 12.799999999999967, -91.30000000000078, 59.90000000000021, -64.00000000000037, -13.599999999999786, 21.80000000000004, 15.799999999999962, -7.8999999999998884, -74.5000000000005, -78.70000000000053, -9.399999999999855, 38.90000000000023, -30.399999999999842, 26.300000000000118, 9.499999999999964, 31.700000000000212, -87.10000000000085, -9.099999999999884, -8.799999999999871, -66.10000000000082, -82.90000000000006, -133.3, 1.0999999999999723, -9.399999999999855, -55.30000000000022, 20.900000000000027, -57.70000000000028, 9.499999999999964, 5.299999999999965, 7.399999999999965, -103.90000000000049, -202.60000000000048, 50.60000000000023, -11.499999999999819, 13.699999999999964, 17.899999999999988, -114.40000000000055, 7.399999999999965, 23.600000000000065, -0.9999999999999846, -3.0999999999999615, 13.699999999999964, -240.40000000000043, 29.000000000000167, 13.699999999999964, 17.899999999999988, -53.50000000000008, 55.70000000000018, 20.000000000000014, -21.999999999999744, -152.20000000000067, -49.29999999999976, -0.9999999999999846, -0.9999999999999846, -55.60000000000012, 20.000000000000014, -20.499999999999886, 3.7999999999999656, 32.90000000000023, -219.40000000000032, 9.499999999999964, 20.000000000000014, -38.79999999999991, -5.49999999999994, 17.899999999999988, 20.000000000000014, -66.10000000000086, 25.700000000000117, -8.7999999999999, -120.70000000000027, 29.000000000000163, -127.00000000000074, -49.299999999999905, -42.09999999999976, -36.699999999999754, 27.20000000000013, 36.800000000000246, 1.0999999999999865, 9.499999999999964, 7.399999999999965, -53.500000000000135, 5.299999999999965, 27.20000000000013, -42.99999999999976, -190.00000000000023, 3.1999999999999615, -30.39999999999975, -21.999999999999744, -38.799999999999756, -28.29999999999975, 15.79999999999996, 30.800000000000196, 9.499999999999964, -27.999999999999794, -7.299999999999983, 9.499999999999988, -7.299999999999891, 8.299999999999969, -27.39999999999975, -52.89999999999989, -244.60000000000025, -347.99999999999926, -28.29999999999975, -85.00000000000077, -15.699999999999747, 35.600000000000236, -0.9999999999999917, -80.79999999999998, -206.8000000000004, -158.50000000000054, -161.90000000000018, -15.699999999999747, -9.399999999999862, -38.79999999999977, -24.099999999999746, 43.100000000000236, -78.69999999999989, -118.60000000000073, -5.1999999999999265, -0.9999999999999846, -4.899999999999942, -19.29999999999975, 0.500000000000199, 10.399999999999972, 9.499999999999964, 22.400000000000052, 28.10000000000015, 46.40000000000022, 18.799999999999997, -37.89999999999976, 21.800000000000043, 1.0999999999999865, -66.1000000000009, -11.499999999999833, -95.50000000000037, -0.09999999999999937, 33.50000000000024, 16.999999999999964, -150.10000000000034, -152.2000000000003, -28.29999999999975, -13.899999999999785, -177.40000000000038, -14.199999999999795, -106.00000000000068, -49.29999999999983, 20.000000000000014, 13.699999999999964, -225.7000000000003, 1.0999999999999865, 33.20000000000022, -175.30000000000044, -187.90000000000038, 7.399999999999968, 3.1999999999999615, 20.000000000000014, -1.2999999999999847, 34.400000000000254, -154.30000000000004, -101.80000000000003, -13.599999999999783, 17.899999999999988, -11.499999999999826, 11.599999999999964, -64.00000000000061, -22.000000000000007, -189.1000000000005, 20.000000000000014, -225.7000000000004, -250.90000000000038, 0.7999999999999865, 9.499999999999964, -26.199999999999747, -127.60000000000059, -219.40000000000032, -3.099999999999958, -19.899999999999785, -32.49999999999975, -13.599999999999783, -57.70000000000034, -122.80000000000011, -30.39999999999975], "policy_predator_policy_reward": [20.0, 16.0, 7.0, 25.0, 3.0, 2.0, 33.0, 34.0, 17.0, 6.0, 39.0, 34.0, 53.0, 15.0, 7.0, 7.0, 8.0, 23.0, 6.0, 53.0, 40.0, 2.0, 16.0, 1.0, 15.0, 5.0, 36.0, 42.0, 14.0, 4.0, 19.0, 13.0, 5.0, 5.0, 19.0, 51.0, 15.0, 41.0, 11.0, 80.0, 5.0, 13.0, 28.0, 26.0, 23.0, 24.0, 7.0, 6.0, 69.0, 62.0, 15.0, 1.0, 1.0, 3.0, 64.0, 6.0, 6.0, 10.0, 11.0, 3.0, 112.0, 71.0, 3.0, 1.0, 6.0, 39.0, 18.0, 20.0, 83.0, 39.0, 7.0, 10.0, 33.0, 30.0, 17.0, 13.0, 39.0, 92.0, 3.0, 4.0, 42.0, 12.0, 1.0, 0.0, 41.0, 2.0, 68.0, 57.0, 38.0, 62.0, 34.0, 26.0, 11.0, 27.0, 1.0, 9.0, 4.0, 6.0, 27.0, 17.0, 6.0, 30.0, 84.0, 69.0, 26.0, 8.0, 12.0, 28.0, 11.0, 0.0, 5.0, 28.0, 5.0, 11.0, 16.0, 16.0, 9.0, 65.0, 154.0, 166.0, 23.0, 51.0, 17.0, 5.0, 31.0, 36.0, 100.0, 24.0, 74.0, 62.0, 10.0, 26.0, 21.0, 6.0, 69.0, 49.0, 12.0, 9.0, 21.0, 9.0, 22.0, 31.0, 7.0, 5.0, 0.0, 3.0, 1.0, 28.0, 9.0, 0.0, 15.0, 41.0, 18.0, 47.0, 4.0, 3.0, 82.0, 49.0, 23.0, 18.0, 85.0, 106.0, 63.0, 52.0, 0.0, 3.0, 83.0, 64.0, 93.0, 1.0, 78.0, 48.0, 5.0, 8.0, 7.0, 9.0, 46.0, 60.0, 16.0, 1.0, 15.0, 4.0, 39.0, 25.0, 98.0, 43.0, 104.0, 109.0, 10.0, 5.0, 74.0, 20.0, 68.0, 104.0, 25.0, 19.0, 37.0, 16.0, 61.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5714218375073168, "mean_inference_ms": 1.4791676491896717, "mean_action_processing_ms": 0.24607036609189273, "mean_env_wait_ms": 0.19110516967881153, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004069089889526367, "StateBufferConnector_ms": 0.0029985904693603516, "ViewRequirementAgentConnector_ms": 0.09096693992614746}, "num_episodes": 18, "episode_return_max": 77.49999999999952, "episode_return_min": -272.59999999999957, "episode_return_mean": -9.292999999999873, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 401.6213929377737, "num_env_steps_trained_throughput_per_sec": 401.6213929377737, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 10342.429, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10342.386, "sample_time_ms": 1305.299, "learn_time_ms": 9023.057, "learn_throughput": 443.309, "synch_weights_time_ms": 12.86}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-31-46", "timestamp": 1723645906, "time_this_iter_s": 9.971189022064209, "time_total_s": 426.03081607818604, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b095550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 426.03081607818604, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 34.24285714285715, "ram_util_percent": 81.79285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.417264569562579, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 4.993625617910315, "policy_loss": -0.01190476417258165, "vf_loss": 5.003190137343432, "vf_explained_var": 0.0725542962551117, "kl": 0.00780084915469702, "entropy": 1.3282528273643008, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6312599277054822, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.461706454160983, "policy_loss": -0.01880919841788315, "vf_loss": 5.477557434102215, "vf_explained_var": 0.021721697232079885, "kl": 0.01479113499378108, "entropy": 1.1449655135472616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 77.49999999999952, "episode_reward_min": -457.0999999999992, "episode_reward_mean": -30.12699999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.89999999999975, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 55.70000000000018, "predator_policy": 172.0}, "policy_reward_mean": {"prey_policy": -51.73850000000003, "predator_policy": 36.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.899999999999515, -125.1999999999998, 9.700000000000097, 19.600000000000005, -1.1999999999998496, 25.700000000000067, -175.50000000000117, 55.10000000000046, 35.600000000000236, -36.99999999999954, 38.60000000000028, 24.60000000000005, -28.399999999999665, 35.600000000000236, 47.20000000000037, 36.00000000000024, -79.50000000000145, 15.000000000000021, 27.4000000000001, 13.299999999999905, -55.499999999999936, 36.50000000000025, 9.700000000000015, 38.90000000000028, 2.6000000000001657, -4.500000000000071, 2.00000000000008, -31.399999999999565, 28.50000000000013, 47.90000000000044, 26.900000000000087, -4.199999999999703, 20.19999999999998, -33.799999999999955, -18.399999999999494, -27.099999999999504, 57.600000000000485, 14.499999999999924, 18.199999999999974, 33.0000000000002, -6.300000000000063, -272.59999999999957, -39.299999999999706, 41.90000000000033, -14.799999999999978, -241.30000000000095, -41.59999999999957, -12.199999999999582, 46.000000000000405, -79.29999999999968, 14.800000000000022, 5.8000000000001535, 63.8999999999997, 43.90000000000037, 77.49999999999952, 9.900000000000068, 31.90000000000017, -21.599999999999525, -30.599999999999575, 57.5000000000005, -171.3000000000006, -1.1999999999997502, -0.600000000000017, -40.299999999999656, 36.70000000000025, -77.60000000000043, -48.099999999999724, -54.499999999999595, 36.200000000000244, 49.100000000000456, -150.10000000000008, 21.299999999999994, 19.099999999999973, -21.999999999999766, -28.099999999999802, -263.60000000000014, 25.30000000000006, -59.80000000000096, -50.49999999999961, -8.39999999999968, -18.29999999999955, -34.199999999999946, -17.799999999999514, -63.89999999999981, -74.39999999999998, -457.0999999999992, -113.3000000000002, -415.89999999999935, 24.60000000000006, -50.2000000000002, -18.29999999999987, -71.40000000000023, -41.99999999999984, 60.10000000000041, -297.50000000000006, 17.900000000000002, 58.400000000000475, -384.49999999999966, -57.2999999999998, 18.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.799999999999871, -66.10000000000082, -82.90000000000006, -133.3, 1.0999999999999723, -9.399999999999855, -55.30000000000022, 20.900000000000027, -57.70000000000028, 9.499999999999964, 5.299999999999965, 7.399999999999965, -103.90000000000049, -202.60000000000048, 50.60000000000023, -11.499999999999819, 13.699999999999964, 17.899999999999988, -114.40000000000055, 7.399999999999965, 23.600000000000065, -0.9999999999999846, -3.0999999999999615, 13.699999999999964, -240.40000000000043, 29.000000000000167, 13.699999999999964, 17.899999999999988, -53.50000000000008, 55.70000000000018, 20.000000000000014, -21.999999999999744, -152.20000000000067, -49.29999999999976, -0.9999999999999846, -0.9999999999999846, -55.60000000000012, 20.000000000000014, -20.499999999999886, 3.7999999999999656, 32.90000000000023, -219.40000000000032, 9.499999999999964, 20.000000000000014, -38.79999999999991, -5.49999999999994, 17.899999999999988, 20.000000000000014, -66.10000000000086, 25.700000000000117, -8.7999999999999, -120.70000000000027, 29.000000000000163, -127.00000000000074, -49.299999999999905, -42.09999999999976, -36.699999999999754, 27.20000000000013, 36.800000000000246, 1.0999999999999865, 9.499999999999964, 7.399999999999965, -53.500000000000135, 5.299999999999965, 27.20000000000013, -42.99999999999976, -190.00000000000023, 3.1999999999999615, -30.39999999999975, -21.999999999999744, -38.799999999999756, -28.29999999999975, 15.79999999999996, 30.800000000000196, 9.499999999999964, -27.999999999999794, -7.299999999999983, 9.499999999999988, -7.299999999999891, 8.299999999999969, -27.39999999999975, -52.89999999999989, -244.60000000000025, -347.99999999999926, -28.29999999999975, -85.00000000000077, -15.699999999999747, 35.600000000000236, -0.9999999999999917, -80.79999999999998, -206.8000000000004, -158.50000000000054, -161.90000000000018, -15.699999999999747, -9.399999999999862, -38.79999999999977, -24.099999999999746, 43.100000000000236, -78.69999999999989, -118.60000000000073, -5.1999999999999265, -0.9999999999999846, -4.899999999999942, -19.29999999999975, 0.500000000000199, 10.399999999999972, 9.499999999999964, 22.400000000000052, 28.10000000000015, 46.40000000000022, 18.799999999999997, -37.89999999999976, 21.800000000000043, 1.0999999999999865, -66.1000000000009, -11.499999999999833, -95.50000000000037, -0.09999999999999937, 33.50000000000024, 16.999999999999964, -150.10000000000034, -152.2000000000003, -28.29999999999975, -13.899999999999785, -177.40000000000038, -14.199999999999795, -106.00000000000068, -49.29999999999983, 20.000000000000014, 13.699999999999964, -225.7000000000003, 1.0999999999999865, 33.20000000000022, -175.30000000000044, -187.90000000000038, 7.399999999999968, 3.1999999999999615, 20.000000000000014, -1.2999999999999847, 34.400000000000254, -154.30000000000004, -101.80000000000003, -13.599999999999783, 17.899999999999988, -11.499999999999826, 11.599999999999964, -64.00000000000061, -22.000000000000007, -189.1000000000005, 20.000000000000014, -225.7000000000004, -250.90000000000038, 0.7999999999999865, 9.499999999999964, -26.199999999999747, -127.60000000000059, -219.40000000000032, -3.099999999999958, -19.899999999999785, -32.49999999999975, -13.599999999999783, -57.70000000000034, -122.80000000000011, -30.39999999999975, -12.9999999999998, -59.80000000000054, -261.4000000000001, 18.499999999999993, -160.60000000000014, -17.79999999999974, -316.00000000000006, -339.10000000000014, -118.60000000000059, -99.70000000000027, -336.9999999999999, -355.89999999999975, 7.399999999999974, -17.79999999999974, -80.80000000000072, -51.40000000000005, -5.1999999999999265, -66.0999999999998, -305.1, 13.699999999999964, -156.40000000000006, 7.399999999999965, 53.3000000000002, -5.1999999999999265, -265.60000000000036, -187.9, 3.1999999999999615, -7.299999999999891, 20.000000000000014, 16.399999999999963, -269.80000000000024, -330.6999999999998, -322.29999999999995, 20.000000000000014, 3.1999999999999615, -5.1999999999999265], "policy_predator_policy_reward": [15.0, 41.0, 11.0, 80.0, 5.0, 13.0, 28.0, 26.0, 23.0, 24.0, 7.0, 6.0, 69.0, 62.0, 15.0, 1.0, 1.0, 3.0, 64.0, 6.0, 6.0, 10.0, 11.0, 3.0, 112.0, 71.0, 3.0, 1.0, 6.0, 39.0, 18.0, 20.0, 83.0, 39.0, 7.0, 10.0, 33.0, 30.0, 17.0, 13.0, 39.0, 92.0, 3.0, 4.0, 42.0, 12.0, 1.0, 0.0, 41.0, 2.0, 68.0, 57.0, 38.0, 62.0, 34.0, 26.0, 11.0, 27.0, 1.0, 9.0, 4.0, 6.0, 27.0, 17.0, 6.0, 30.0, 84.0, 69.0, 26.0, 8.0, 12.0, 28.0, 11.0, 0.0, 5.0, 28.0, 5.0, 11.0, 16.0, 16.0, 9.0, 65.0, 154.0, 166.0, 23.0, 51.0, 17.0, 5.0, 31.0, 36.0, 100.0, 24.0, 74.0, 62.0, 10.0, 26.0, 21.0, 6.0, 69.0, 49.0, 12.0, 9.0, 21.0, 9.0, 22.0, 31.0, 7.0, 5.0, 0.0, 3.0, 1.0, 28.0, 9.0, 0.0, 15.0, 41.0, 18.0, 47.0, 4.0, 3.0, 82.0, 49.0, 23.0, 18.0, 85.0, 106.0, 63.0, 52.0, 0.0, 3.0, 83.0, 64.0, 93.0, 1.0, 78.0, 48.0, 5.0, 8.0, 7.0, 9.0, 46.0, 60.0, 16.0, 1.0, 15.0, 4.0, 39.0, 25.0, 98.0, 43.0, 104.0, 109.0, 10.0, 5.0, 74.0, 20.0, 68.0, 104.0, 25.0, 19.0, 37.0, 16.0, 61.0, 58.0, 16.0, 39.0, 106.0, 73.0, 7.0, 97.0, 172.0, 26.0, 69.0, 36.0, 158.0, 119.0, 23.0, 12.0, 34.0, 48.0, 18.0, 35.0, 125.0, 95.0, 63.0, 44.0, 0.0, 12.0, 112.0, 44.0, 9.0, 13.0, 10.0, 12.0, 54.0, 162.0, 140.0, 105.0, 8.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.571693410816867, "mean_inference_ms": 1.4805611618554093, "mean_action_processing_ms": 0.24603161858606648, "mean_env_wait_ms": 0.19111572814713618, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004083991050720215, "StateBufferConnector_ms": 0.002992868423461914, "ViewRequirementAgentConnector_ms": 0.09064459800720215}, "num_episodes": 18, "episode_return_max": 77.49999999999952, "episode_return_min": -457.0999999999992, "episode_return_mean": -30.12699999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 417.13542517454596, "num_env_steps_trained_throughput_per_sec": 417.13542517454596, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 10209.08, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10209.037, "sample_time_ms": 1249.504, "learn_time_ms": 8946.001, "learn_throughput": 447.127, "synch_weights_time_ms": 12.398}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-31-55", "timestamp": 1723645915, "time_this_iter_s": 9.592392206192017, "time_total_s": 435.62320828437805, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b09b160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 435.62320828437805, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 32.07857142857143, "ram_util_percent": 78.09285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8372593021266674, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 5.270388514907272, "policy_loss": -0.010578546976108872, "vf_loss": 5.278356059266146, "vf_explained_var": 0.07904781087365731, "kl": 0.008703335402590256, "entropy": 1.3100250137546074, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7315804074996364, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.619281948685015, "policy_loss": -0.01046657917242517, "vf_loss": 5.627957004970974, "vf_explained_var": 0.04453264519020363, "kl": 0.008957627363641646, "entropy": 1.156169022391082, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 77.49999999999952, "episode_reward_min": -457.0999999999992, "episode_reward_mean": -53.75599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.89999999999975, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 53.3000000000002, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -72.45300000000003, "predator_policy": 45.575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.700000000000015, 38.90000000000028, 2.6000000000001657, -4.500000000000071, 2.00000000000008, -31.399999999999565, 28.50000000000013, 47.90000000000044, 26.900000000000087, -4.199999999999703, 20.19999999999998, -33.799999999999955, -18.399999999999494, -27.099999999999504, 57.600000000000485, 14.499999999999924, 18.199999999999974, 33.0000000000002, -6.300000000000063, -272.59999999999957, -39.299999999999706, 41.90000000000033, -14.799999999999978, -241.30000000000095, -41.59999999999957, -12.199999999999582, 46.000000000000405, -79.29999999999968, 14.800000000000022, 5.8000000000001535, 63.8999999999997, 43.90000000000037, 77.49999999999952, 9.900000000000068, 31.90000000000017, -21.599999999999525, -30.599999999999575, 57.5000000000005, -171.3000000000006, -1.1999999999997502, -0.600000000000017, -40.299999999999656, 36.70000000000025, -77.60000000000043, -48.099999999999724, -54.499999999999595, 36.200000000000244, 49.100000000000456, -150.10000000000008, 21.299999999999994, 19.099999999999973, -21.999999999999766, -28.099999999999802, -263.60000000000014, 25.30000000000006, -59.80000000000096, -50.49999999999961, -8.39999999999968, -18.29999999999955, -34.199999999999946, -17.799999999999514, -63.89999999999981, -74.39999999999998, -457.0999999999992, -113.3000000000002, -415.89999999999935, 24.60000000000006, -50.2000000000002, -18.29999999999987, -71.40000000000023, -41.99999999999984, 60.10000000000041, -297.50000000000006, 17.900000000000002, 58.400000000000475, -384.49999999999966, -57.2999999999998, 18.0, -120.80000000000084, 12.999999999999964, -338.00000000000017, 21.200000000000035, 39.20000000000029, 9.700000000000076, -282.5000000000002, -42.29999999999989, 42.40000000000034, -76.60000000000004, -202.000000000001, -254.90000000000055, 46.400000000000404, -380.79999999999984, 37.00000000000027, -72.60000000000007, -64.79999999999976, -290.6999999999993, -67.79999999999984, 41.90000000000034, -135.1000000000002, -386.0999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-38.79999999999991, -5.49999999999994, 17.899999999999988, 20.000000000000014, -66.10000000000086, 25.700000000000117, -8.7999999999999, -120.70000000000027, 29.000000000000163, -127.00000000000074, -49.299999999999905, -42.09999999999976, -36.699999999999754, 27.20000000000013, 36.800000000000246, 1.0999999999999865, 9.499999999999964, 7.399999999999965, -53.500000000000135, 5.299999999999965, 27.20000000000013, -42.99999999999976, -190.00000000000023, 3.1999999999999615, -30.39999999999975, -21.999999999999744, -38.799999999999756, -28.29999999999975, 15.79999999999996, 30.800000000000196, 9.499999999999964, -27.999999999999794, -7.299999999999983, 9.499999999999988, -7.299999999999891, 8.299999999999969, -27.39999999999975, -52.89999999999989, -244.60000000000025, -347.99999999999926, -28.29999999999975, -85.00000000000077, -15.699999999999747, 35.600000000000236, -0.9999999999999917, -80.79999999999998, -206.8000000000004, -158.50000000000054, -161.90000000000018, -15.699999999999747, -9.399999999999862, -38.79999999999977, -24.099999999999746, 43.100000000000236, -78.69999999999989, -118.60000000000073, -5.1999999999999265, -0.9999999999999846, -4.899999999999942, -19.29999999999975, 0.500000000000199, 10.399999999999972, 9.499999999999964, 22.400000000000052, 28.10000000000015, 46.40000000000022, 18.799999999999997, -37.89999999999976, 21.800000000000043, 1.0999999999999865, -66.1000000000009, -11.499999999999833, -95.50000000000037, -0.09999999999999937, 33.50000000000024, 16.999999999999964, -150.10000000000034, -152.2000000000003, -28.29999999999975, -13.899999999999785, -177.40000000000038, -14.199999999999795, -106.00000000000068, -49.29999999999983, 20.000000000000014, 13.699999999999964, -225.7000000000003, 1.0999999999999865, 33.20000000000022, -175.30000000000044, -187.90000000000038, 7.399999999999968, 3.1999999999999615, 20.000000000000014, -1.2999999999999847, 34.400000000000254, -154.30000000000004, -101.80000000000003, -13.599999999999783, 17.899999999999988, -11.499999999999826, 11.599999999999964, -64.00000000000061, -22.000000000000007, -189.1000000000005, 20.000000000000014, -225.7000000000004, -250.90000000000038, 0.7999999999999865, 9.499999999999964, -26.199999999999747, -127.60000000000059, -219.40000000000032, -3.099999999999958, -19.899999999999785, -32.49999999999975, -13.599999999999783, -57.70000000000034, -122.80000000000011, -30.39999999999975, -12.9999999999998, -59.80000000000054, -261.4000000000001, 18.499999999999993, -160.60000000000014, -17.79999999999974, -316.00000000000006, -339.10000000000014, -118.60000000000059, -99.70000000000027, -336.9999999999999, -355.89999999999975, 7.399999999999974, -17.79999999999974, -80.80000000000072, -51.40000000000005, -5.1999999999999265, -66.0999999999998, -305.1, 13.699999999999964, -156.40000000000006, 7.399999999999965, 53.3000000000002, -5.1999999999999265, -265.60000000000036, -187.9, 3.1999999999999615, -7.299999999999891, 20.000000000000014, 16.399999999999963, -269.80000000000024, -330.6999999999998, -322.29999999999995, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, -311.80000000000007, 15.799999999999951, -29.799999999999756, -288.70000000000005, -301.30000000000007, 5.299999999999965, -6.099999999999923, 15.199999999999966, 20.000000000000014, -13.899999999999796, -9.399999999999855, -339.0999999999999, -219.4000000000001, 31.700000000000212, -294.99999999999983, 10.399999999999972, 20.000000000000014, -11.499999999999819, -255.10000000000028, -248.80000000000038, -173.2000000000006, -170.70000000000033, -305.1999999999998, 29.000000000000163, 7.399999999999965, -290.8, -274.0000000000002, 34.400000000000226, -93.40000000000083, -244.6000000000001, -0.9999999999999846, -237.7000000000003, 17.899999999999988, -246.70000000000033, -211.00000000000048, -91.3000000000001, -74.50000000000068, -9.699999999999854, 23.60000000000008, -116.5, -97.60000000000014, -353.79999999999984, -343.29999999999995], "policy_predator_policy_reward": [42.0, 12.0, 1.0, 0.0, 41.0, 2.0, 68.0, 57.0, 38.0, 62.0, 34.0, 26.0, 11.0, 27.0, 1.0, 9.0, 4.0, 6.0, 27.0, 17.0, 6.0, 30.0, 84.0, 69.0, 26.0, 8.0, 12.0, 28.0, 11.0, 0.0, 5.0, 28.0, 5.0, 11.0, 16.0, 16.0, 9.0, 65.0, 154.0, 166.0, 23.0, 51.0, 17.0, 5.0, 31.0, 36.0, 100.0, 24.0, 74.0, 62.0, 10.0, 26.0, 21.0, 6.0, 69.0, 49.0, 12.0, 9.0, 21.0, 9.0, 22.0, 31.0, 7.0, 5.0, 0.0, 3.0, 1.0, 28.0, 9.0, 0.0, 15.0, 41.0, 18.0, 47.0, 4.0, 3.0, 82.0, 49.0, 23.0, 18.0, 85.0, 106.0, 63.0, 52.0, 0.0, 3.0, 83.0, 64.0, 93.0, 1.0, 78.0, 48.0, 5.0, 8.0, 7.0, 9.0, 46.0, 60.0, 16.0, 1.0, 15.0, 4.0, 39.0, 25.0, 98.0, 43.0, 104.0, 109.0, 10.0, 5.0, 74.0, 20.0, 68.0, 104.0, 25.0, 19.0, 37.0, 16.0, 61.0, 58.0, 16.0, 39.0, 106.0, 73.0, 7.0, 97.0, 172.0, 26.0, 69.0, 36.0, 158.0, 119.0, 23.0, 12.0, 34.0, 48.0, 18.0, 35.0, 125.0, 95.0, 63.0, 44.0, 0.0, 12.0, 112.0, 44.0, 9.0, 13.0, 10.0, 12.0, 54.0, 162.0, 140.0, 105.0, 8.0, 12.0, 13.0, 158.0, 9.0, 18.0, 119.0, 133.0, 15.0, 7.0, 0.0, 4.0, 29.0, 4.0, 141.0, 135.0, 108.0, 113.0, 11.0, 1.0, 103.0, 87.0, 92.0, 128.0, 170.0, 51.0, 6.0, 4.0, 9.0, 175.0, 46.0, 50.0, 82.0, 91.0, 61.0, 94.0, 44.0, 123.0, 45.0, 53.0, 13.0, 15.0, 72.0, 7.0, 154.0, 157.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5714056918203688, "mean_inference_ms": 1.4800742273848846, "mean_action_processing_ms": 0.24585551995188248, "mean_env_wait_ms": 0.1909035214988532, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038907527923583984, "StateBufferConnector_ms": 0.002943873405456543, "ViewRequirementAgentConnector_ms": 0.0864870548248291}, "num_episodes": 22, "episode_return_max": 77.49999999999952, "episode_return_min": -457.0999999999992, "episode_return_mean": -53.75599999999989, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 440.83784967126246, "num_env_steps_trained_throughput_per_sec": 440.83784967126246, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 10046.819, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10046.775, "sample_time_ms": 1208.536, "learn_time_ms": 8825.159, "learn_throughput": 453.25, "synch_weights_time_ms": 11.945}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-32-04", "timestamp": 1723645924, "time_this_iter_s": 9.076645851135254, "time_total_s": 444.6998541355133, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aaee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 444.6998541355133, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 26.438461538461542, "ram_util_percent": 73.97692307692309}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.56447853253632, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 6.54953599909626, "policy_loss": -0.00858141081962025, "vf_loss": 6.555383067913156, "vf_explained_var": 0.17669089020244658, "kl": 0.009114412638805584, "entropy": 1.3196163960234828, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7489430964308441, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.410883610336869, "policy_loss": -0.012455969987309011, "vf_loss": 7.421168304120422, "vf_explained_var": 0.020392156908751794, "kl": 0.010856351997361496, "entropy": 1.1564347714974137, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 84.499999999999, "episode_reward_min": -457.0999999999992, "episode_reward_mean": -86.17999999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -376.89999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 54.500000000000206, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": -104.83500000000004, "predator_policy": 61.745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-241.30000000000095, -41.59999999999957, -12.199999999999582, 46.000000000000405, -79.29999999999968, 14.800000000000022, 5.8000000000001535, 63.8999999999997, 43.90000000000037, 77.49999999999952, 9.900000000000068, 31.90000000000017, -21.599999999999525, -30.599999999999575, 57.5000000000005, -171.3000000000006, -1.1999999999997502, -0.600000000000017, -40.299999999999656, 36.70000000000025, -77.60000000000043, -48.099999999999724, -54.499999999999595, 36.200000000000244, 49.100000000000456, -150.10000000000008, 21.299999999999994, 19.099999999999973, -21.999999999999766, -28.099999999999802, -263.60000000000014, 25.30000000000006, -59.80000000000096, -50.49999999999961, -8.39999999999968, -18.29999999999955, -34.199999999999946, -17.799999999999514, -63.89999999999981, -74.39999999999998, -457.0999999999992, -113.3000000000002, -415.89999999999935, 24.60000000000006, -50.2000000000002, -18.29999999999987, -71.40000000000023, -41.99999999999984, 60.10000000000041, -297.50000000000006, 17.900000000000002, 58.400000000000475, -384.49999999999966, -57.2999999999998, 18.0, -120.80000000000084, 12.999999999999964, -338.00000000000017, 21.200000000000035, 39.20000000000029, 9.700000000000076, -282.5000000000002, -42.29999999999989, 42.40000000000034, -76.60000000000004, -202.000000000001, -254.90000000000055, 46.400000000000404, -380.79999999999984, 37.00000000000027, -72.60000000000007, -64.79999999999976, -290.6999999999993, -67.79999999999984, 41.90000000000034, -135.1000000000002, -386.0999999999997, -19.700000000000003, -162.30000000000112, -85.20000000000012, -39.499999999999865, -53.59999999999983, 84.499999999999, -348.19999999999976, 31.200000000000163, -31.699999999999953, -81.60000000000032, -345.1999999999995, -3.2999999999997733, -361.89999999999986, -358.9000000000001, -140.10000000000105, -77.6999999999999, -358.19999999999993, 11.900000000000075, -381.2999999999998, 17.700000000000323, -242.80000000000058, -378.4999999999999, -28.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-206.8000000000004, -158.50000000000054, -161.90000000000018, -15.699999999999747, -9.399999999999862, -38.79999999999977, -24.099999999999746, 43.100000000000236, -78.69999999999989, -118.60000000000073, -5.1999999999999265, -0.9999999999999846, -4.899999999999942, -19.29999999999975, 0.500000000000199, 10.399999999999972, 9.499999999999964, 22.400000000000052, 28.10000000000015, 46.40000000000022, 18.799999999999997, -37.89999999999976, 21.800000000000043, 1.0999999999999865, -66.1000000000009, -11.499999999999833, -95.50000000000037, -0.09999999999999937, 33.50000000000024, 16.999999999999964, -150.10000000000034, -152.2000000000003, -28.29999999999975, -13.899999999999785, -177.40000000000038, -14.199999999999795, -106.00000000000068, -49.29999999999983, 20.000000000000014, 13.699999999999964, -225.7000000000003, 1.0999999999999865, 33.20000000000022, -175.30000000000044, -187.90000000000038, 7.399999999999968, 3.1999999999999615, 20.000000000000014, -1.2999999999999847, 34.400000000000254, -154.30000000000004, -101.80000000000003, -13.599999999999783, 17.899999999999988, -11.499999999999826, 11.599999999999964, -64.00000000000061, -22.000000000000007, -189.1000000000005, 20.000000000000014, -225.7000000000004, -250.90000000000038, 0.7999999999999865, 9.499999999999964, -26.199999999999747, -127.60000000000059, -219.40000000000032, -3.099999999999958, -19.899999999999785, -32.49999999999975, -13.599999999999783, -57.70000000000034, -122.80000000000011, -30.39999999999975, -12.9999999999998, -59.80000000000054, -261.4000000000001, 18.499999999999993, -160.60000000000014, -17.79999999999974, -316.00000000000006, -339.10000000000014, -118.60000000000059, -99.70000000000027, -336.9999999999999, -355.89999999999975, 7.399999999999974, -17.79999999999974, -80.80000000000072, -51.40000000000005, -5.1999999999999265, -66.0999999999998, -305.1, 13.699999999999964, -156.40000000000006, 7.399999999999965, 53.3000000000002, -5.1999999999999265, -265.60000000000036, -187.9, 3.1999999999999615, -7.299999999999891, 20.000000000000014, 16.399999999999963, -269.80000000000024, -330.6999999999998, -322.29999999999995, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, -311.80000000000007, 15.799999999999951, -29.799999999999756, -288.70000000000005, -301.30000000000007, 5.299999999999965, -6.099999999999923, 15.199999999999966, 20.000000000000014, -13.899999999999796, -9.399999999999855, -339.0999999999999, -219.4000000000001, 31.700000000000212, -294.99999999999983, 10.399999999999972, 20.000000000000014, -11.499999999999819, -255.10000000000028, -248.80000000000038, -173.2000000000006, -170.70000000000033, -305.1999999999998, 29.000000000000163, 7.399999999999965, -290.8, -274.0000000000002, 34.400000000000226, -93.40000000000083, -244.6000000000001, -0.9999999999999846, -237.7000000000003, 17.899999999999988, -246.70000000000033, -211.00000000000048, -91.3000000000001, -74.50000000000068, -9.699999999999854, 23.60000000000008, -116.5, -97.60000000000014, -353.79999999999984, -343.29999999999995, 28.10000000000015, -374.79999999999984, -85.00000000000051, -175.30000000000052, -257.20000000000033, -21.999999999999744, 20.000000000000014, -347.4999999999998, -349.59999999999985, 20.000000000000014, 54.500000000000206, 20.000000000000014, -295.0000000000001, -299.19999999999993, 11.599999999999964, 11.599999999999964, -227.80000000000015, 10.099999999999998, -345.39999999999986, 15.799999999999963, -368.4999999999998, -288.6999999999999, -38.799999999999756, -23.499999999999794, -355.89999999999986, -337.0, -322.3, -349.6, -239.20000000000044, -124.9000000000006, -150.10000000000025, -34.60000000000004, -263.50000000000034, -288.70000000000016, 3.1999999999999615, -7.299999999999891, -372.69999999999993, -370.59999999999985, -31.299999999999976, 20.000000000000014, -206.80000000000032, -303.0000000000001, -364.6, -376.89999999999986, -175.30000000000004, -26.199999999999747], "policy_predator_policy_reward": [100.0, 24.0, 74.0, 62.0, 10.0, 26.0, 21.0, 6.0, 69.0, 49.0, 12.0, 9.0, 21.0, 9.0, 22.0, 31.0, 7.0, 5.0, 0.0, 3.0, 1.0, 28.0, 9.0, 0.0, 15.0, 41.0, 18.0, 47.0, 4.0, 3.0, 82.0, 49.0, 23.0, 18.0, 85.0, 106.0, 63.0, 52.0, 0.0, 3.0, 83.0, 64.0, 93.0, 1.0, 78.0, 48.0, 5.0, 8.0, 7.0, 9.0, 46.0, 60.0, 16.0, 1.0, 15.0, 4.0, 39.0, 25.0, 98.0, 43.0, 104.0, 109.0, 10.0, 5.0, 74.0, 20.0, 68.0, 104.0, 25.0, 19.0, 37.0, 16.0, 61.0, 58.0, 16.0, 39.0, 106.0, 73.0, 7.0, 97.0, 172.0, 26.0, 69.0, 36.0, 158.0, 119.0, 23.0, 12.0, 34.0, 48.0, 18.0, 35.0, 125.0, 95.0, 63.0, 44.0, 0.0, 12.0, 112.0, 44.0, 9.0, 13.0, 10.0, 12.0, 54.0, 162.0, 140.0, 105.0, 8.0, 12.0, 13.0, 158.0, 9.0, 18.0, 119.0, 133.0, 15.0, 7.0, 0.0, 4.0, 29.0, 4.0, 141.0, 135.0, 108.0, 113.0, 11.0, 1.0, 103.0, 87.0, 92.0, 128.0, 170.0, 51.0, 6.0, 4.0, 9.0, 175.0, 46.0, 50.0, 82.0, 91.0, 61.0, 94.0, 44.0, 123.0, 45.0, 53.0, 13.0, 15.0, 72.0, 7.0, 154.0, 157.0, 164.0, 163.0, 96.0, 2.0, 82.0, 112.0, 131.0, 157.0, 129.0, 147.0, 5.0, 5.0, 154.0, 92.0, 4.0, 4.0, 93.0, 93.0, 107.0, 141.0, 149.0, 163.0, 31.0, 28.0, 167.0, 164.0, 157.0, 156.0, 102.0, 122.0, 81.0, 26.0, 161.0, 33.0, 3.0, 13.0, 183.0, 179.0, 27.0, 2.0, 159.0, 108.0, 181.0, 182.0, 94.0, 79.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5707095196620054, "mean_inference_ms": 1.478174293352016, "mean_action_processing_ms": 0.24541836155000551, "mean_env_wait_ms": 0.1904802122423372, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041686296463012695, "StateBufferConnector_ms": 0.0028913021087646484, "ViewRequirementAgentConnector_ms": 0.08276009559631348}, "num_episodes": 23, "episode_return_max": 84.499999999999, "episode_return_min": -457.0999999999992, "episode_return_mean": -86.17999999999995, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 430.9837711794122, "num_env_steps_trained_throughput_per_sec": 430.9837711794122, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 9945.884, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9945.841, "sample_time_ms": 1190.311, "learn_time_ms": 8742.49, "learn_throughput": 457.536, "synch_weights_time_ms": 11.904}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-32-14", "timestamp": 1723645934, "time_this_iter_s": 9.28396987915039, "time_total_s": 453.9838240146637, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aaf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 453.9838240146637, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 27.38461538461539, "ram_util_percent": 74.95384615384616}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9361599019595555, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 4.9573979062378095, "policy_loss": -0.00527883889646363, "vf_loss": 4.960703800090406, "vf_explained_var": 0.12019648350105083, "kl": 0.006576474288553428, "entropy": 1.3139857751982553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9883696898896859, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.818478894864441, "policy_loss": -0.012929888453738636, "vf_loss": 4.829269249098641, "vf_explained_var": 0.054584316160313034, "kl": 0.010697681036405813, "entropy": 1.1249447165342865, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 84.499999999999, "episode_reward_min": -457.0999999999992, "episode_reward_mean": -102.855, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -441.2999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 54.500000000000206, "predator_policy": 225.0}, "policy_reward_mean": {"prey_policy": -121.57250000000003, "predator_policy": 70.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.299999999999656, 36.70000000000025, -77.60000000000043, -48.099999999999724, -54.499999999999595, 36.200000000000244, 49.100000000000456, -150.10000000000008, 21.299999999999994, 19.099999999999973, -21.999999999999766, -28.099999999999802, -263.60000000000014, 25.30000000000006, -59.80000000000096, -50.49999999999961, -8.39999999999968, -18.29999999999955, -34.199999999999946, -17.799999999999514, -63.89999999999981, -74.39999999999998, -457.0999999999992, -113.3000000000002, -415.89999999999935, 24.60000000000006, -50.2000000000002, -18.29999999999987, -71.40000000000023, -41.99999999999984, 60.10000000000041, -297.50000000000006, 17.900000000000002, 58.400000000000475, -384.49999999999966, -57.2999999999998, 18.0, -120.80000000000084, 12.999999999999964, -338.00000000000017, 21.200000000000035, 39.20000000000029, 9.700000000000076, -282.5000000000002, -42.29999999999989, 42.40000000000034, -76.60000000000004, -202.000000000001, -254.90000000000055, 46.400000000000404, -380.79999999999984, 37.00000000000027, -72.60000000000007, -64.79999999999976, -290.6999999999993, -67.79999999999984, 41.90000000000034, -135.1000000000002, -386.0999999999997, -19.700000000000003, -162.30000000000112, -85.20000000000012, -39.499999999999865, -53.59999999999983, 84.499999999999, -348.19999999999976, 31.200000000000163, -31.699999999999953, -81.60000000000032, -345.1999999999995, -3.2999999999997733, -361.89999999999986, -358.9000000000001, -140.10000000000105, -77.6999999999999, -358.19999999999993, 11.900000000000075, -381.2999999999998, 17.700000000000323, -242.80000000000058, -378.4999999999999, -28.5, 37.00000000000025, 36.300000000000246, -50.29999999999969, -175.10000000000107, -39.49999999999982, 37.40000000000026, -287.1000000000001, -100.4000000000004, -156.9000000000009, -166.90000000000046, -380.20000000000005, 27.100000000000126, -118.80000000000072, 11.400000000000077, -176.500000000001, -17.900000000000006, -412.9999999999998, 17.399999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-106.00000000000068, -49.29999999999983, 20.000000000000014, 13.699999999999964, -225.7000000000003, 1.0999999999999865, 33.20000000000022, -175.30000000000044, -187.90000000000038, 7.399999999999968, 3.1999999999999615, 20.000000000000014, -1.2999999999999847, 34.400000000000254, -154.30000000000004, -101.80000000000003, -13.599999999999783, 17.899999999999988, -11.499999999999826, 11.599999999999964, -64.00000000000061, -22.000000000000007, -189.1000000000005, 20.000000000000014, -225.7000000000004, -250.90000000000038, 0.7999999999999865, 9.499999999999964, -26.199999999999747, -127.60000000000059, -219.40000000000032, -3.099999999999958, -19.899999999999785, -32.49999999999975, -13.599999999999783, -57.70000000000034, -122.80000000000011, -30.39999999999975, -12.9999999999998, -59.80000000000054, -261.4000000000001, 18.499999999999993, -160.60000000000014, -17.79999999999974, -316.00000000000006, -339.10000000000014, -118.60000000000059, -99.70000000000027, -336.9999999999999, -355.89999999999975, 7.399999999999974, -17.79999999999974, -80.80000000000072, -51.40000000000005, -5.1999999999999265, -66.0999999999998, -305.1, 13.699999999999964, -156.40000000000006, 7.399999999999965, 53.3000000000002, -5.1999999999999265, -265.60000000000036, -187.9, 3.1999999999999615, -7.299999999999891, 20.000000000000014, 16.399999999999963, -269.80000000000024, -330.6999999999998, -322.29999999999995, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, -311.80000000000007, 15.799999999999951, -29.799999999999756, -288.70000000000005, -301.30000000000007, 5.299999999999965, -6.099999999999923, 15.199999999999966, 20.000000000000014, -13.899999999999796, -9.399999999999855, -339.0999999999999, -219.4000000000001, 31.700000000000212, -294.99999999999983, 10.399999999999972, 20.000000000000014, -11.499999999999819, -255.10000000000028, -248.80000000000038, -173.2000000000006, -170.70000000000033, -305.1999999999998, 29.000000000000163, 7.399999999999965, -290.8, -274.0000000000002, 34.400000000000226, -93.40000000000083, -244.6000000000001, -0.9999999999999846, -237.7000000000003, 17.899999999999988, -246.70000000000033, -211.00000000000048, -91.3000000000001, -74.50000000000068, -9.699999999999854, 23.60000000000008, -116.5, -97.60000000000014, -353.79999999999984, -343.29999999999995, 28.10000000000015, -374.79999999999984, -85.00000000000051, -175.30000000000052, -257.20000000000033, -21.999999999999744, 20.000000000000014, -347.4999999999998, -349.59999999999985, 20.000000000000014, 54.500000000000206, 20.000000000000014, -295.0000000000001, -299.19999999999993, 11.599999999999964, 11.599999999999964, -227.80000000000015, 10.099999999999998, -345.39999999999986, 15.799999999999963, -368.4999999999998, -288.6999999999999, -38.799999999999756, -23.499999999999794, -355.89999999999986, -337.0, -322.3, -349.6, -239.20000000000044, -124.9000000000006, -150.10000000000025, -34.60000000000004, -263.50000000000034, -288.70000000000016, 3.1999999999999615, -7.299999999999891, -372.69999999999993, -370.59999999999985, -31.299999999999976, 20.000000000000014, -206.80000000000032, -303.0000000000001, -364.6, -376.89999999999986, -175.30000000000004, -26.199999999999747, -5.499999999999925, 27.500000000000146, 5.299999999999965, 20.000000000000014, -242.5000000000002, 9.199999999999982, -284.5000000000002, -88.60000000000076, -1.9000000000000514, -97.60000000000082, 34.40000000000024, -15.999999999999746, -355.89999999999986, -278.20000000000005, 7.399999999999965, -242.80000000000018, -74.50000000000045, -261.4000000000003, -130.00000000000014, -187.90000000000055, -372.70000000000005, -338.5, -30.39999999999978, 24.500000000000085, -311.7999999999995, 20.000000000000014, 3.1999999999999615, -17.79999999999974, -146.50000000000026, -193.0000000000005, -368.4999999999998, 32.60000000000023, -372.6999999999999, -441.2999999999999, -28.599999999999753, 20.000000000000014], "policy_predator_policy_reward": [63.0, 52.0, 0.0, 3.0, 83.0, 64.0, 93.0, 1.0, 78.0, 48.0, 5.0, 8.0, 7.0, 9.0, 46.0, 60.0, 16.0, 1.0, 15.0, 4.0, 39.0, 25.0, 98.0, 43.0, 104.0, 109.0, 10.0, 5.0, 74.0, 20.0, 68.0, 104.0, 25.0, 19.0, 37.0, 16.0, 61.0, 58.0, 16.0, 39.0, 106.0, 73.0, 7.0, 97.0, 172.0, 26.0, 69.0, 36.0, 158.0, 119.0, 23.0, 12.0, 34.0, 48.0, 18.0, 35.0, 125.0, 95.0, 63.0, 44.0, 0.0, 12.0, 112.0, 44.0, 9.0, 13.0, 10.0, 12.0, 54.0, 162.0, 140.0, 105.0, 8.0, 12.0, 13.0, 158.0, 9.0, 18.0, 119.0, 133.0, 15.0, 7.0, 0.0, 4.0, 29.0, 4.0, 141.0, 135.0, 108.0, 113.0, 11.0, 1.0, 103.0, 87.0, 92.0, 128.0, 170.0, 51.0, 6.0, 4.0, 9.0, 175.0, 46.0, 50.0, 82.0, 91.0, 61.0, 94.0, 44.0, 123.0, 45.0, 53.0, 13.0, 15.0, 72.0, 7.0, 154.0, 157.0, 164.0, 163.0, 96.0, 2.0, 82.0, 112.0, 131.0, 157.0, 129.0, 147.0, 5.0, 5.0, 154.0, 92.0, 4.0, 4.0, 93.0, 93.0, 107.0, 141.0, 149.0, 163.0, 31.0, 28.0, 167.0, 164.0, 157.0, 156.0, 102.0, 122.0, 81.0, 26.0, 161.0, 33.0, 3.0, 13.0, 183.0, 179.0, 27.0, 2.0, 159.0, 108.0, 181.0, 182.0, 94.0, 79.0, 13.0, 2.0, 4.0, 7.0, 116.0, 67.0, 53.0, 145.0, 2.0, 58.0, 16.0, 3.0, 157.0, 190.0, 6.0, 129.0, 45.0, 134.0, 0.0, 151.0, 174.0, 157.0, 15.0, 18.0, 158.0, 15.0, 8.0, 18.0, 69.0, 94.0, 176.0, 142.0, 225.0, 176.0, 19.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5701819188065836, "mean_inference_ms": 1.4766590428606603, "mean_action_processing_ms": 0.24511529180637737, "mean_env_wait_ms": 0.1901562390133818, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00405275821685791, "StateBufferConnector_ms": 0.0028791427612304688, "ViewRequirementAgentConnector_ms": 0.08303225040435791}, "num_episodes": 18, "episode_return_max": 84.499999999999, "episode_return_min": -457.0999999999992, "episode_return_mean": -102.855, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 439.838441872521, "num_env_steps_trained_throughput_per_sec": 439.838441872521, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 9770.472, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9770.428, "sample_time_ms": 1139.701, "learn_time_ms": 8617.949, "learn_throughput": 464.148, "synch_weights_time_ms": 11.631}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-32-23", "timestamp": 1723645943, "time_this_iter_s": 9.098013162612915, "time_total_s": 463.0818371772766, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39aef93a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 463.0818371772766, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 27.26923076923077, "ram_util_percent": 75.5923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.600851797269135, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 6.2909250862383965, "policy_loss": -0.006604616771077629, "vf_loss": 6.295748730059024, "vf_explained_var": 0.10963921578472884, "kl": 0.005936612728152386, "entropy": 1.3397738479432606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6277356005534924, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 5.952018922472757, "policy_loss": -0.009701866144314408, "vf_loss": 5.959720087303686, "vf_explained_var": 0.1081069949758116, "kl": 0.010003507047932195, "entropy": 1.118767650795992, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 84.499999999999, "episode_reward_min": -457.0999999999992, "episode_reward_mean": -118.86, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -441.2999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 54.500000000000206, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -136.71500000000003, "predator_policy": 77.285}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.199999999999946, -17.799999999999514, -63.89999999999981, -74.39999999999998, -457.0999999999992, -113.3000000000002, -415.89999999999935, 24.60000000000006, -50.2000000000002, -18.29999999999987, -71.40000000000023, -41.99999999999984, 60.10000000000041, -297.50000000000006, 17.900000000000002, 58.400000000000475, -384.49999999999966, -57.2999999999998, 18.0, -120.80000000000084, 12.999999999999964, -338.00000000000017, 21.200000000000035, 39.20000000000029, 9.700000000000076, -282.5000000000002, -42.29999999999989, 42.40000000000034, -76.60000000000004, -202.000000000001, -254.90000000000055, 46.400000000000404, -380.79999999999984, 37.00000000000027, -72.60000000000007, -64.79999999999976, -290.6999999999993, -67.79999999999984, 41.90000000000034, -135.1000000000002, -386.0999999999997, -19.700000000000003, -162.30000000000112, -85.20000000000012, -39.499999999999865, -53.59999999999983, 84.499999999999, -348.19999999999976, 31.200000000000163, -31.699999999999953, -81.60000000000032, -345.1999999999995, -3.2999999999997733, -361.89999999999986, -358.9000000000001, -140.10000000000105, -77.6999999999999, -358.19999999999993, 11.900000000000075, -381.2999999999998, 17.700000000000323, -242.80000000000058, -378.4999999999999, -28.5, 37.00000000000025, 36.300000000000246, -50.29999999999969, -175.10000000000107, -39.49999999999982, 37.40000000000026, -287.1000000000001, -100.4000000000004, -156.9000000000009, -166.90000000000046, -380.20000000000005, 27.100000000000126, -118.80000000000072, 11.400000000000077, -176.500000000001, -17.900000000000006, -412.9999999999998, 17.399999999999956, 34.50000000000022, -0.29999999999974314, -390.59999999999985, 30.000000000000146, -262.0000000000002, -58.89999999999968, 35.10000000000022, -280.70000000000016, 41.60000000000033, -17.200000000000028, -352.9999999999998, -241.80000000000038, -81.60000000000018, -287.5, -134.90000000000072, -370.4, 65.20000000000034, 38.400000000000276], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-122.80000000000011, -30.39999999999975, -12.9999999999998, -59.80000000000054, -261.4000000000001, 18.499999999999993, -160.60000000000014, -17.79999999999974, -316.00000000000006, -339.10000000000014, -118.60000000000059, -99.70000000000027, -336.9999999999999, -355.89999999999975, 7.399999999999974, -17.79999999999974, -80.80000000000072, -51.40000000000005, -5.1999999999999265, -66.0999999999998, -305.1, 13.699999999999964, -156.40000000000006, 7.399999999999965, 53.3000000000002, -5.1999999999999265, -265.60000000000036, -187.9, 3.1999999999999615, -7.299999999999891, 20.000000000000014, 16.399999999999963, -269.80000000000024, -330.6999999999998, -322.29999999999995, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 20.000000000000014, -311.80000000000007, 15.799999999999951, -29.799999999999756, -288.70000000000005, -301.30000000000007, 5.299999999999965, -6.099999999999923, 15.199999999999966, 20.000000000000014, -13.899999999999796, -9.399999999999855, -339.0999999999999, -219.4000000000001, 31.700000000000212, -294.99999999999983, 10.399999999999972, 20.000000000000014, -11.499999999999819, -255.10000000000028, -248.80000000000038, -173.2000000000006, -170.70000000000033, -305.1999999999998, 29.000000000000163, 7.399999999999965, -290.8, -274.0000000000002, 34.400000000000226, -93.40000000000083, -244.6000000000001, -0.9999999999999846, -237.7000000000003, 17.899999999999988, -246.70000000000033, -211.00000000000048, -91.3000000000001, -74.50000000000068, -9.699999999999854, 23.60000000000008, -116.5, -97.60000000000014, -353.79999999999984, -343.29999999999995, 28.10000000000015, -374.79999999999984, -85.00000000000051, -175.30000000000052, -257.20000000000033, -21.999999999999744, 20.000000000000014, -347.4999999999998, -349.59999999999985, 20.000000000000014, 54.500000000000206, 20.000000000000014, -295.0000000000001, -299.19999999999993, 11.599999999999964, 11.599999999999964, -227.80000000000015, 10.099999999999998, -345.39999999999986, 15.799999999999963, -368.4999999999998, -288.6999999999999, -38.799999999999756, -23.499999999999794, -355.89999999999986, -337.0, -322.3, -349.6, -239.20000000000044, -124.9000000000006, -150.10000000000025, -34.60000000000004, -263.50000000000034, -288.70000000000016, 3.1999999999999615, -7.299999999999891, -372.69999999999993, -370.59999999999985, -31.299999999999976, 20.000000000000014, -206.80000000000032, -303.0000000000001, -364.6, -376.89999999999986, -175.30000000000004, -26.199999999999747, -5.499999999999925, 27.500000000000146, 5.299999999999965, 20.000000000000014, -242.5000000000002, 9.199999999999982, -284.5000000000002, -88.60000000000076, -1.9000000000000514, -97.60000000000082, 34.40000000000024, -15.999999999999746, -355.89999999999986, -278.20000000000005, 7.399999999999965, -242.80000000000018, -74.50000000000045, -261.4000000000003, -130.00000000000014, -187.90000000000055, -372.70000000000005, -338.5, -30.39999999999978, 24.500000000000085, -311.7999999999995, 20.000000000000014, 3.1999999999999615, -17.79999999999974, -146.50000000000026, -193.0000000000005, -368.4999999999998, 32.60000000000023, -372.6999999999999, -441.2999999999999, -28.599999999999753, 20.000000000000014, 9.499999999999964, 20.000000000000014, -5.1999999999999265, -24.099999999999746, -358.0, -307.6000000000001, 5.899999999999967, 13.099999999999966, -259.3000000000002, -288.7, -309.3, -13.600000000000035, 26.600000000000126, -11.499999999999819, -244.6000000000002, -192.10000000000002, 25.1000000000001, -2.499999999999986, -417.70000000000005, 24.500000000000096, -242.09999999999994, -325.89999999999964, -169.00000000000023, -348.79999999999984, -225.7000000000001, 7.099999999999966, -296.69999999999993, -177.79999999999998, 3.1999999999999655, -297.1, -377.4, -411.0, 31.700000000000212, -2.500000000000029, 7.399999999999965, 20.000000000000014], "policy_predator_policy_reward": [61.0, 58.0, 16.0, 39.0, 106.0, 73.0, 7.0, 97.0, 172.0, 26.0, 69.0, 36.0, 158.0, 119.0, 23.0, 12.0, 34.0, 48.0, 18.0, 35.0, 125.0, 95.0, 63.0, 44.0, 0.0, 12.0, 112.0, 44.0, 9.0, 13.0, 10.0, 12.0, 54.0, 162.0, 140.0, 105.0, 8.0, 12.0, 13.0, 158.0, 9.0, 18.0, 119.0, 133.0, 15.0, 7.0, 0.0, 4.0, 29.0, 4.0, 141.0, 135.0, 108.0, 113.0, 11.0, 1.0, 103.0, 87.0, 92.0, 128.0, 170.0, 51.0, 6.0, 4.0, 9.0, 175.0, 46.0, 50.0, 82.0, 91.0, 61.0, 94.0, 44.0, 123.0, 45.0, 53.0, 13.0, 15.0, 72.0, 7.0, 154.0, 157.0, 164.0, 163.0, 96.0, 2.0, 82.0, 112.0, 131.0, 157.0, 129.0, 147.0, 5.0, 5.0, 154.0, 92.0, 4.0, 4.0, 93.0, 93.0, 107.0, 141.0, 149.0, 163.0, 31.0, 28.0, 167.0, 164.0, 157.0, 156.0, 102.0, 122.0, 81.0, 26.0, 161.0, 33.0, 3.0, 13.0, 183.0, 179.0, 27.0, 2.0, 159.0, 108.0, 181.0, 182.0, 94.0, 79.0, 13.0, 2.0, 4.0, 7.0, 116.0, 67.0, 53.0, 145.0, 2.0, 58.0, 16.0, 3.0, 157.0, 190.0, 6.0, 129.0, 45.0, 134.0, 0.0, 151.0, 174.0, 157.0, 15.0, 18.0, 158.0, 15.0, 8.0, 18.0, 69.0, 94.0, 176.0, 142.0, 225.0, 176.0, 19.0, 7.0, 5.0, 0.0, 8.0, 21.0, 146.0, 129.0, 3.0, 8.0, 151.0, 135.0, 126.0, 138.0, 15.0, 5.0, 148.0, 8.0, 4.0, 15.0, 170.0, 206.0, 204.0, 11.0, 90.0, 186.0, 121.0, 16.0, 187.0, 0.0, 154.0, 5.0, 190.0, 228.0, 12.0, 24.0, 5.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5688123171640057, "mean_inference_ms": 1.4723473054944065, "mean_action_processing_ms": 0.24442209036049284, "mean_env_wait_ms": 0.18952305459537055, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004316449165344238, "StateBufferConnector_ms": 0.002725958824157715, "ViewRequirementAgentConnector_ms": 0.07936036586761475}, "num_episodes": 18, "episode_return_max": 84.499999999999, "episode_return_min": -457.0999999999992, "episode_return_mean": -118.86, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 434.8409344245142, "num_env_steps_trained_throughput_per_sec": 434.8409344245142, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 9648.318, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9648.275, "sample_time_ms": 1108.97, "learn_time_ms": 8526.47, "learn_throughput": 469.127, "synch_weights_time_ms": 11.682}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-32-32", "timestamp": 1723645952, "time_this_iter_s": 9.20159387588501, "time_total_s": 472.2834310531616, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39aef9700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 472.2834310531616, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 25.984615384615385, "ram_util_percent": 75.71538461538464}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.514548875604357, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 6.719898305115876, "policy_loss": -0.011530243326964043, "vf_loss": 6.7292582458919945, "vf_explained_var": 0.15007673959252696, "kl": 0.007234323327094787, "entropy": 1.3022216621530118, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.043738657740689, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 7.580782537611704, "policy_loss": -0.012698490431325303, "vf_loss": 7.591042267582404, "vf_explained_var": 0.011675118611603186, "kl": 0.012193765449815604, "entropy": 1.095992957252674, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 84.499999999999, "episode_reward_min": -412.9999999999998, "episode_reward_mean": -126.57200000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -441.2999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 54.500000000000206, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -153.20600000000005, "predator_policy": 89.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.200000000000035, 39.20000000000029, 9.700000000000076, -282.5000000000002, -42.29999999999989, 42.40000000000034, -76.60000000000004, -202.000000000001, -254.90000000000055, 46.400000000000404, -380.79999999999984, 37.00000000000027, -72.60000000000007, -64.79999999999976, -290.6999999999993, -67.79999999999984, 41.90000000000034, -135.1000000000002, -386.0999999999997, -19.700000000000003, -162.30000000000112, -85.20000000000012, -39.499999999999865, -53.59999999999983, 84.499999999999, -348.19999999999976, 31.200000000000163, -31.699999999999953, -81.60000000000032, -345.1999999999995, -3.2999999999997733, -361.89999999999986, -358.9000000000001, -140.10000000000105, -77.6999999999999, -358.19999999999993, 11.900000000000075, -381.2999999999998, 17.700000000000323, -242.80000000000058, -378.4999999999999, -28.5, 37.00000000000025, 36.300000000000246, -50.29999999999969, -175.10000000000107, -39.49999999999982, 37.40000000000026, -287.1000000000001, -100.4000000000004, -156.9000000000009, -166.90000000000046, -380.20000000000005, 27.100000000000126, -118.80000000000072, 11.400000000000077, -176.500000000001, -17.900000000000006, -412.9999999999998, 17.399999999999956, 34.50000000000022, -0.29999999999974314, -390.59999999999985, 30.000000000000146, -262.0000000000002, -58.89999999999968, 35.10000000000022, -280.70000000000016, 41.60000000000033, -17.200000000000028, -352.9999999999998, -241.80000000000038, -81.60000000000018, -287.5, -134.90000000000072, -370.4, 65.20000000000034, 38.400000000000276, -115.20000000000083, -72.90000000000012, -141.30000000000013, -214.50000000000054, -46.69999999999974, -130.20000000000059, -132.60000000000002, -332.30000000000007, -187.70000000000098, -102.80000000000078, -241.00000000000009, -40.49999999999986, -115.09999999999997, -56.699999999999726, -359.5, -4.599999999999737, -366.0999999999998, -27.999999999999922, 44.00000000000037, -236.50000000000003, -36.49999999999973, -219.10000000000053], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, -6.099999999999923, 15.199999999999966, 20.000000000000014, -13.899999999999796, -9.399999999999855, -339.0999999999999, -219.4000000000001, 31.700000000000212, -294.99999999999983, 10.399999999999972, 20.000000000000014, -11.499999999999819, -255.10000000000028, -248.80000000000038, -173.2000000000006, -170.70000000000033, -305.1999999999998, 29.000000000000163, 7.399999999999965, -290.8, -274.0000000000002, 34.400000000000226, -93.40000000000083, -244.6000000000001, -0.9999999999999846, -237.7000000000003, 17.899999999999988, -246.70000000000033, -211.00000000000048, -91.3000000000001, -74.50000000000068, -9.699999999999854, 23.60000000000008, -116.5, -97.60000000000014, -353.79999999999984, -343.29999999999995, 28.10000000000015, -374.79999999999984, -85.00000000000051, -175.30000000000052, -257.20000000000033, -21.999999999999744, 20.000000000000014, -347.4999999999998, -349.59999999999985, 20.000000000000014, 54.500000000000206, 20.000000000000014, -295.0000000000001, -299.19999999999993, 11.599999999999964, 11.599999999999964, -227.80000000000015, 10.099999999999998, -345.39999999999986, 15.799999999999963, -368.4999999999998, -288.6999999999999, -38.799999999999756, -23.499999999999794, -355.89999999999986, -337.0, -322.3, -349.6, -239.20000000000044, -124.9000000000006, -150.10000000000025, -34.60000000000004, -263.50000000000034, -288.70000000000016, 3.1999999999999615, -7.299999999999891, -372.69999999999993, -370.59999999999985, -31.299999999999976, 20.000000000000014, -206.80000000000032, -303.0000000000001, -364.6, -376.89999999999986, -175.30000000000004, -26.199999999999747, -5.499999999999925, 27.500000000000146, 5.299999999999965, 20.000000000000014, -242.5000000000002, 9.199999999999982, -284.5000000000002, -88.60000000000076, -1.9000000000000514, -97.60000000000082, 34.40000000000024, -15.999999999999746, -355.89999999999986, -278.20000000000005, 7.399999999999965, -242.80000000000018, -74.50000000000045, -261.4000000000003, -130.00000000000014, -187.90000000000055, -372.70000000000005, -338.5, -30.39999999999978, 24.500000000000085, -311.7999999999995, 20.000000000000014, 3.1999999999999615, -17.79999999999974, -146.50000000000026, -193.0000000000005, -368.4999999999998, 32.60000000000023, -372.6999999999999, -441.2999999999999, -28.599999999999753, 20.000000000000014, 9.499999999999964, 20.000000000000014, -5.1999999999999265, -24.099999999999746, -358.0, -307.6000000000001, 5.899999999999967, 13.099999999999966, -259.3000000000002, -288.7, -309.3, -13.600000000000035, 26.600000000000126, -11.499999999999819, -244.6000000000002, -192.10000000000002, 25.1000000000001, -2.499999999999986, -417.70000000000005, 24.500000000000096, -242.09999999999994, -325.89999999999964, -169.00000000000023, -348.79999999999984, -225.7000000000001, 7.099999999999966, -296.69999999999993, -177.79999999999998, 3.1999999999999655, -297.1, -377.4, -411.0, 31.700000000000212, -2.500000000000029, 7.399999999999965, 20.000000000000014, -70.30000000000065, -271.9000000000002, 21.80000000000004, -372.6999999999998, -102.70000000000005, -139.60000000000014, -362.1999999999999, -217.3000000000005, 20.90000000000003, -370.6, 9.499999999999964, -330.70000000000005, -100.20000000000007, -168.40000000000012, -355.5, -364.79999999999995, -351.6999999999995, -42.99999999999976, -141.70000000000067, -117.1000000000003, -238.30000000000027, -141.7000000000001, -232.00000000000009, -26.499999999999794, -103.89999999999998, -378.19999999999993, -384.9000000000001, -17.79999999999974, -360.1, -324.4, -76.60000000000088, 20.000000000000014, -324.3999999999999, -330.6999999999998, -351.69999999999993, 31.700000000000216, 20.000000000000014, 16.99999999999997, -209.5, -358.00000000000006, -379.5, 20.000000000000014, -282.4, -99.6999999999999], "policy_predator_policy_reward": [15.0, 7.0, 0.0, 4.0, 29.0, 4.0, 141.0, 135.0, 108.0, 113.0, 11.0, 1.0, 103.0, 87.0, 92.0, 128.0, 170.0, 51.0, 6.0, 4.0, 9.0, 175.0, 46.0, 50.0, 82.0, 91.0, 61.0, 94.0, 44.0, 123.0, 45.0, 53.0, 13.0, 15.0, 72.0, 7.0, 154.0, 157.0, 164.0, 163.0, 96.0, 2.0, 82.0, 112.0, 131.0, 157.0, 129.0, 147.0, 5.0, 5.0, 154.0, 92.0, 4.0, 4.0, 93.0, 93.0, 107.0, 141.0, 149.0, 163.0, 31.0, 28.0, 167.0, 164.0, 157.0, 156.0, 102.0, 122.0, 81.0, 26.0, 161.0, 33.0, 3.0, 13.0, 183.0, 179.0, 27.0, 2.0, 159.0, 108.0, 181.0, 182.0, 94.0, 79.0, 13.0, 2.0, 4.0, 7.0, 116.0, 67.0, 53.0, 145.0, 2.0, 58.0, 16.0, 3.0, 157.0, 190.0, 6.0, 129.0, 45.0, 134.0, 0.0, 151.0, 174.0, 157.0, 15.0, 18.0, 158.0, 15.0, 8.0, 18.0, 69.0, 94.0, 176.0, 142.0, 225.0, 176.0, 19.0, 7.0, 5.0, 0.0, 8.0, 21.0, 146.0, 129.0, 3.0, 8.0, 151.0, 135.0, 126.0, 138.0, 15.0, 5.0, 148.0, 8.0, 4.0, 15.0, 170.0, 206.0, 204.0, 11.0, 90.0, 186.0, 121.0, 16.0, 187.0, 0.0, 154.0, 5.0, 190.0, 228.0, 12.0, 24.0, 5.0, 6.0, 106.0, 121.0, 160.0, 118.0, 86.0, 15.0, 183.0, 182.0, 137.0, 166.0, 155.0, 36.0, 14.0, 122.0, 194.0, 194.0, 30.0, 177.0, 123.0, 33.0, 138.0, 1.0, 142.0, 76.0, 178.0, 189.0, 167.0, 179.0, 152.0, 173.0, 46.0, 6.0, 124.0, 165.0, 152.0, 140.0, 3.0, 4.0, 168.0, 163.0, 172.0, 151.0, 16.0, 147.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.566986950457098, "mean_inference_ms": 1.4683644715438202, "mean_action_processing_ms": 0.2431219319727841, "mean_env_wait_ms": 0.18863668640433634, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004760146141052246, "StateBufferConnector_ms": 0.0026662349700927734, "ViewRequirementAgentConnector_ms": 0.0785670280456543}, "num_episodes": 22, "episode_return_max": 84.499999999999, "episode_return_min": -412.9999999999998, "episode_return_mean": -126.57200000000006, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 435.9308060411951, "num_env_steps_trained_throughput_per_sec": 435.9308060411951, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 9565.634, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9565.592, "sample_time_ms": 1101.277, "learn_time_ms": 8451.28, "learn_throughput": 473.301, "synch_weights_time_ms": 11.837}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-32-41", "timestamp": 1723645961, "time_this_iter_s": 9.178462028503418, "time_total_s": 481.46189308166504, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0fb550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 481.46189308166504, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 26.73846153846154, "ram_util_percent": 74.89999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4607971999695692, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 7.295607784311607, "policy_loss": -0.00854313241160184, "vf_loss": 7.301747736602864, "vf_explained_var": 0.11006167581472448, "kl": 0.008010536339076954, "entropy": 1.303641660377462, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1208936017026345, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.957512227820341, "policy_loss": -0.009796138103834536, "vf_loss": 6.96564685200888, "vf_explained_var": 0.19197775062429842, "kl": 0.008307612459788683, "entropy": 1.1363132285693336, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 84.499999999999, "episode_reward_min": -412.9999999999998, "episode_reward_mean": -136.67900000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -441.2999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 54.500000000000206, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -166.10450000000003, "predator_policy": 97.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-53.59999999999983, 84.499999999999, -348.19999999999976, 31.200000000000163, -31.699999999999953, -81.60000000000032, -345.1999999999995, -3.2999999999997733, -361.89999999999986, -358.9000000000001, -140.10000000000105, -77.6999999999999, -358.19999999999993, 11.900000000000075, -381.2999999999998, 17.700000000000323, -242.80000000000058, -378.4999999999999, -28.5, 37.00000000000025, 36.300000000000246, -50.29999999999969, -175.10000000000107, -39.49999999999982, 37.40000000000026, -287.1000000000001, -100.4000000000004, -156.9000000000009, -166.90000000000046, -380.20000000000005, 27.100000000000126, -118.80000000000072, 11.400000000000077, -176.500000000001, -17.900000000000006, -412.9999999999998, 17.399999999999956, 34.50000000000022, -0.29999999999974314, -390.59999999999985, 30.000000000000146, -262.0000000000002, -58.89999999999968, 35.10000000000022, -280.70000000000016, 41.60000000000033, -17.200000000000028, -352.9999999999998, -241.80000000000038, -81.60000000000018, -287.5, -134.90000000000072, -370.4, 65.20000000000034, 38.400000000000276, -115.20000000000083, -72.90000000000012, -141.30000000000013, -214.50000000000054, -46.69999999999974, -130.20000000000059, -132.60000000000002, -332.30000000000007, -187.70000000000098, -102.80000000000078, -241.00000000000009, -40.49999999999986, -115.09999999999997, -56.699999999999726, -359.5, -4.599999999999737, -366.0999999999998, -27.999999999999922, 44.00000000000037, -236.50000000000003, -36.49999999999973, -219.10000000000053, -343.4999999999996, 14.999999999999906, -52.69999999999968, -53.49999999999998, -144.5999999999998, -164.600000000001, -252.60000000000056, -342.99999999999994, -7.700000000000026, 29.000000000000124, -158.40000000000055, -257.0000000000006, -390.2999999999989, -44.199999999999676, 44.80000000000038, -261.40000000000043, -28.399999999999977, -130.7000000000001, -158.1000000000003, 11.400000000000063, -92.40000000000046, -272.80000000000007, -280.10000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-349.59999999999985, 20.000000000000014, 54.500000000000206, 20.000000000000014, -295.0000000000001, -299.19999999999993, 11.599999999999964, 11.599999999999964, -227.80000000000015, 10.099999999999998, -345.39999999999986, 15.799999999999963, -368.4999999999998, -288.6999999999999, -38.799999999999756, -23.499999999999794, -355.89999999999986, -337.0, -322.3, -349.6, -239.20000000000044, -124.9000000000006, -150.10000000000025, -34.60000000000004, -263.50000000000034, -288.70000000000016, 3.1999999999999615, -7.299999999999891, -372.69999999999993, -370.59999999999985, -31.299999999999976, 20.000000000000014, -206.80000000000032, -303.0000000000001, -364.6, -376.89999999999986, -175.30000000000004, -26.199999999999747, -5.499999999999925, 27.500000000000146, 5.299999999999965, 20.000000000000014, -242.5000000000002, 9.199999999999982, -284.5000000000002, -88.60000000000076, -1.9000000000000514, -97.60000000000082, 34.40000000000024, -15.999999999999746, -355.89999999999986, -278.20000000000005, 7.399999999999965, -242.80000000000018, -74.50000000000045, -261.4000000000003, -130.00000000000014, -187.90000000000055, -372.70000000000005, -338.5, -30.39999999999978, 24.500000000000085, -311.7999999999995, 20.000000000000014, 3.1999999999999615, -17.79999999999974, -146.50000000000026, -193.0000000000005, -368.4999999999998, 32.60000000000023, -372.6999999999999, -441.2999999999999, -28.599999999999753, 20.000000000000014, 9.499999999999964, 20.000000000000014, -5.1999999999999265, -24.099999999999746, -358.0, -307.6000000000001, 5.899999999999967, 13.099999999999966, -259.3000000000002, -288.7, -309.3, -13.600000000000035, 26.600000000000126, -11.499999999999819, -244.6000000000002, -192.10000000000002, 25.1000000000001, -2.499999999999986, -417.70000000000005, 24.500000000000096, -242.09999999999994, -325.89999999999964, -169.00000000000023, -348.79999999999984, -225.7000000000001, 7.099999999999966, -296.69999999999993, -177.79999999999998, 3.1999999999999655, -297.1, -377.4, -411.0, 31.700000000000212, -2.500000000000029, 7.399999999999965, 20.000000000000014, -70.30000000000065, -271.9000000000002, 21.80000000000004, -372.6999999999998, -102.70000000000005, -139.60000000000014, -362.1999999999999, -217.3000000000005, 20.90000000000003, -370.6, 9.499999999999964, -330.70000000000005, -100.20000000000007, -168.40000000000012, -355.5, -364.79999999999995, -351.6999999999995, -42.99999999999976, -141.70000000000067, -117.1000000000003, -238.30000000000027, -141.7000000000001, -232.00000000000009, -26.499999999999794, -103.89999999999998, -378.19999999999993, -384.9000000000001, -17.79999999999974, -360.1, -324.4, -76.60000000000088, 20.000000000000014, -324.3999999999999, -330.6999999999998, -351.69999999999993, 31.700000000000216, 20.000000000000014, 16.99999999999997, -209.5, -358.00000000000006, -379.5, 20.000000000000014, -282.4, -99.6999999999999, -322.29999999999984, -209.20000000000005, -13.599999999999833, -9.399999999999855, -330.69999999999993, -0.9999999999999846, -100.3000000000001, -302.20000000000033, -110.70000000000002, -292.9000000000002, -116.50000000000074, -234.09999999999994, -290.8000000000001, -227.80000000000047, -290.79999999999995, -378.19999999999993, -376.9, 30.200000000000173, 11.599999999999964, 7.399999999999965, -85.90000000000018, -242.50000000000028, -330.6999999999997, -196.3000000000005, -284.50000000000006, -269.8000000000003, -255.09999999999997, -24.09999999999981, 11.599999999999964, 27.200000000000134, -196.30000000000044, -339.0999999999997, 19.1, -305.5, -196.2, -158.50000000000006, -265.60000000000025, -69.50000000000004, 11.599999999999964, -26.199999999999747, 31.700000000000212, -339.1, -330.29999999999995, -368.5, -353.79999999999984, -217.30000000000044], "policy_predator_policy_reward": [129.0, 147.0, 5.0, 5.0, 154.0, 92.0, 4.0, 4.0, 93.0, 93.0, 107.0, 141.0, 149.0, 163.0, 31.0, 28.0, 167.0, 164.0, 157.0, 156.0, 102.0, 122.0, 81.0, 26.0, 161.0, 33.0, 3.0, 13.0, 183.0, 179.0, 27.0, 2.0, 159.0, 108.0, 181.0, 182.0, 94.0, 79.0, 13.0, 2.0, 4.0, 7.0, 116.0, 67.0, 53.0, 145.0, 2.0, 58.0, 16.0, 3.0, 157.0, 190.0, 6.0, 129.0, 45.0, 134.0, 0.0, 151.0, 174.0, 157.0, 15.0, 18.0, 158.0, 15.0, 8.0, 18.0, 69.0, 94.0, 176.0, 142.0, 225.0, 176.0, 19.0, 7.0, 5.0, 0.0, 8.0, 21.0, 146.0, 129.0, 3.0, 8.0, 151.0, 135.0, 126.0, 138.0, 15.0, 5.0, 148.0, 8.0, 4.0, 15.0, 170.0, 206.0, 204.0, 11.0, 90.0, 186.0, 121.0, 16.0, 187.0, 0.0, 154.0, 5.0, 190.0, 228.0, 12.0, 24.0, 5.0, 6.0, 106.0, 121.0, 160.0, 118.0, 86.0, 15.0, 183.0, 182.0, 137.0, 166.0, 155.0, 36.0, 14.0, 122.0, 194.0, 194.0, 30.0, 177.0, 123.0, 33.0, 138.0, 1.0, 142.0, 76.0, 178.0, 189.0, 167.0, 179.0, 152.0, 173.0, 46.0, 6.0, 124.0, 165.0, 152.0, 140.0, 3.0, 4.0, 168.0, 163.0, 172.0, 151.0, 16.0, 147.0, 16.0, 172.0, 24.0, 14.0, 148.0, 131.0, 145.0, 204.0, 136.0, 123.0, 65.0, 121.0, 148.0, 118.0, 180.0, 146.0, 167.0, 172.0, 6.0, 4.0, 162.0, 8.0, 167.0, 103.0, 160.0, 4.0, 118.0, 117.0, 4.0, 2.0, 103.0, 171.0, 126.0, 132.0, 119.0, 105.0, 8.0, 169.0, 4.0, 22.0, 55.0, 160.0, 223.0, 203.0, 178.0, 113.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5651614948599178, "mean_inference_ms": 1.4623544442716159, "mean_action_processing_ms": 0.24285411894625727, "mean_env_wait_ms": 0.18770338043953355, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004955172538757324, "StateBufferConnector_ms": 0.0027093887329101562, "ViewRequirementAgentConnector_ms": 0.0784984827041626}, "num_episodes": 23, "episode_return_max": 84.499999999999, "episode_return_min": -412.9999999999998, "episode_return_mean": -136.67900000000006, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 440.5857874637533, "num_env_steps_trained_throughput_per_sec": 440.5857874637533, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 9447.459, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9447.417, "sample_time_ms": 1072.886, "learn_time_ms": 8361.801, "learn_throughput": 478.366, "synch_weights_time_ms": 11.624}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-32-50", "timestamp": 1723645970, "time_this_iter_s": 9.081858158111572, "time_total_s": 490.5437512397766, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 490.5437512397766, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 27.176923076923075, "ram_util_percent": 74.9076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4927740329787844, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 6.127344176125905, "policy_loss": -0.01155006906594194, "vf_loss": 6.136250370520132, "vf_explained_var": 0.1708194410990155, "kl": 0.00881289608154639, "entropy": 1.3173541197701106, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1180547142154955, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.001177135094133, "policy_loss": -0.01538683295732847, "vf_loss": 6.013937134717508, "vf_explained_var": 0.2056266361443454, "kl": 0.013134092822407791, "entropy": 1.1198827916982943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 65.20000000000034, "episode_reward_min": -415.0999999999998, "episode_reward_mean": -134.08500000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -441.2999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 34.40000000000026, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -165.66750000000005, "predator_policy": 98.625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.5, 37.00000000000025, 36.300000000000246, -50.29999999999969, -175.10000000000107, -39.49999999999982, 37.40000000000026, -287.1000000000001, -100.4000000000004, -156.9000000000009, -166.90000000000046, -380.20000000000005, 27.100000000000126, -118.80000000000072, 11.400000000000077, -176.500000000001, -17.900000000000006, -412.9999999999998, 17.399999999999956, 34.50000000000022, -0.29999999999974314, -390.59999999999985, 30.000000000000146, -262.0000000000002, -58.89999999999968, 35.10000000000022, -280.70000000000016, 41.60000000000033, -17.200000000000028, -352.9999999999998, -241.80000000000038, -81.60000000000018, -287.5, -134.90000000000072, -370.4, 65.20000000000034, 38.400000000000276, -115.20000000000083, -72.90000000000012, -141.30000000000013, -214.50000000000054, -46.69999999999974, -130.20000000000059, -132.60000000000002, -332.30000000000007, -187.70000000000098, -102.80000000000078, -241.00000000000009, -40.49999999999986, -115.09999999999997, -56.699999999999726, -359.5, -4.599999999999737, -366.0999999999998, -27.999999999999922, 44.00000000000037, -236.50000000000003, -36.49999999999973, -219.10000000000053, -343.4999999999996, 14.999999999999906, -52.69999999999968, -53.49999999999998, -144.5999999999998, -164.600000000001, -252.60000000000056, -342.99999999999994, -7.700000000000026, 29.000000000000124, -158.40000000000055, -257.0000000000006, -390.2999999999989, -44.199999999999676, 44.80000000000038, -261.40000000000043, -28.399999999999977, -130.7000000000001, -158.1000000000003, 11.400000000000063, -92.40000000000046, -272.80000000000007, -280.10000000000014, -415.0999999999998, -271.29999999999995, -220.40000000000006, -269.6000000000005, -396.6, -311.20000000000005, -290.6000000000006, -247.40000000000018, -124.19999999999999, -96.40000000000015, 36.70000000000025, -11.20000000000006, -211.00000000000045, 15.800000000000004, 33.4000000000002, -13.400000000000059, 43.20000000000035, -9.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.30000000000004, -26.199999999999747, -5.499999999999925, 27.500000000000146, 5.299999999999965, 20.000000000000014, -242.5000000000002, 9.199999999999982, -284.5000000000002, -88.60000000000076, -1.9000000000000514, -97.60000000000082, 34.40000000000024, -15.999999999999746, -355.89999999999986, -278.20000000000005, 7.399999999999965, -242.80000000000018, -74.50000000000045, -261.4000000000003, -130.00000000000014, -187.90000000000055, -372.70000000000005, -338.5, -30.39999999999978, 24.500000000000085, -311.7999999999995, 20.000000000000014, 3.1999999999999615, -17.79999999999974, -146.50000000000026, -193.0000000000005, -368.4999999999998, 32.60000000000023, -372.6999999999999, -441.2999999999999, -28.599999999999753, 20.000000000000014, 9.499999999999964, 20.000000000000014, -5.1999999999999265, -24.099999999999746, -358.0, -307.6000000000001, 5.899999999999967, 13.099999999999966, -259.3000000000002, -288.7, -309.3, -13.600000000000035, 26.600000000000126, -11.499999999999819, -244.6000000000002, -192.10000000000002, 25.1000000000001, -2.499999999999986, -417.70000000000005, 24.500000000000096, -242.09999999999994, -325.89999999999964, -169.00000000000023, -348.79999999999984, -225.7000000000001, 7.099999999999966, -296.69999999999993, -177.79999999999998, 3.1999999999999655, -297.1, -377.4, -411.0, 31.700000000000212, -2.500000000000029, 7.399999999999965, 20.000000000000014, -70.30000000000065, -271.9000000000002, 21.80000000000004, -372.6999999999998, -102.70000000000005, -139.60000000000014, -362.1999999999999, -217.3000000000005, 20.90000000000003, -370.6, 9.499999999999964, -330.70000000000005, -100.20000000000007, -168.40000000000012, -355.5, -364.79999999999995, -351.6999999999995, -42.99999999999976, -141.70000000000067, -117.1000000000003, -238.30000000000027, -141.7000000000001, -232.00000000000009, -26.499999999999794, -103.89999999999998, -378.19999999999993, -384.9000000000001, -17.79999999999974, -360.1, -324.4, -76.60000000000088, 20.000000000000014, -324.3999999999999, -330.6999999999998, -351.69999999999993, 31.700000000000216, 20.000000000000014, 16.99999999999997, -209.5, -358.00000000000006, -379.5, 20.000000000000014, -282.4, -99.6999999999999, -322.29999999999984, -209.20000000000005, -13.599999999999833, -9.399999999999855, -330.69999999999993, -0.9999999999999846, -100.3000000000001, -302.20000000000033, -110.70000000000002, -292.9000000000002, -116.50000000000074, -234.09999999999994, -290.8000000000001, -227.80000000000047, -290.79999999999995, -378.19999999999993, -376.9, 30.200000000000173, 11.599999999999964, 7.399999999999965, -85.90000000000018, -242.50000000000028, -330.6999999999997, -196.3000000000005, -284.50000000000006, -269.8000000000003, -255.09999999999997, -24.09999999999981, 11.599999999999964, 27.200000000000134, -196.30000000000044, -339.0999999999997, 19.1, -305.5, -196.2, -158.50000000000006, -265.60000000000025, -69.50000000000004, 11.599999999999964, -26.199999999999747, 31.700000000000212, -339.1, -330.29999999999995, -368.5, -353.79999999999984, -217.30000000000044, -355.9, -383.19999999999993, -190.00000000000034, -238.30000000000013, -303.39999999999986, -157.00000000000014, -185.79999999999998, -248.80000000000027, -383.20000000000005, -387.4, -372.70000000000005, -300.5, -280.29999999999995, -280.3000000000003, -145.00000000000009, -240.4000000000002, -61.89999999999993, -343.3000000000001, -4.299999999999972, -255.10000000000005, 13.699999999999964, 20.000000000000014, 20.000000000000014, -399.20000000000005, -288.9999999999999, -93.00000000000009, -11.499999999999819, 5.299999999999965, 15.799999999999963, 11.599999999999964, 20.000000000000014, -306.40000000000003, 34.40000000000026, -26.199999999999747, 20.000000000000014, -400.0], "policy_predator_policy_reward": [94.0, 79.0, 13.0, 2.0, 4.0, 7.0, 116.0, 67.0, 53.0, 145.0, 2.0, 58.0, 16.0, 3.0, 157.0, 190.0, 6.0, 129.0, 45.0, 134.0, 0.0, 151.0, 174.0, 157.0, 15.0, 18.0, 158.0, 15.0, 8.0, 18.0, 69.0, 94.0, 176.0, 142.0, 225.0, 176.0, 19.0, 7.0, 5.0, 0.0, 8.0, 21.0, 146.0, 129.0, 3.0, 8.0, 151.0, 135.0, 126.0, 138.0, 15.0, 5.0, 148.0, 8.0, 4.0, 15.0, 170.0, 206.0, 204.0, 11.0, 90.0, 186.0, 121.0, 16.0, 187.0, 0.0, 154.0, 5.0, 190.0, 228.0, 12.0, 24.0, 5.0, 6.0, 106.0, 121.0, 160.0, 118.0, 86.0, 15.0, 183.0, 182.0, 137.0, 166.0, 155.0, 36.0, 14.0, 122.0, 194.0, 194.0, 30.0, 177.0, 123.0, 33.0, 138.0, 1.0, 142.0, 76.0, 178.0, 189.0, 167.0, 179.0, 152.0, 173.0, 46.0, 6.0, 124.0, 165.0, 152.0, 140.0, 3.0, 4.0, 168.0, 163.0, 172.0, 151.0, 16.0, 147.0, 16.0, 172.0, 24.0, 14.0, 148.0, 131.0, 145.0, 204.0, 136.0, 123.0, 65.0, 121.0, 148.0, 118.0, 180.0, 146.0, 167.0, 172.0, 6.0, 4.0, 162.0, 8.0, 167.0, 103.0, 160.0, 4.0, 118.0, 117.0, 4.0, 2.0, 103.0, 171.0, 126.0, 132.0, 119.0, 105.0, 8.0, 169.0, 4.0, 22.0, 55.0, 160.0, 223.0, 203.0, 178.0, 113.0, 148.0, 176.0, 17.0, 140.0, 89.0, 151.0, 2.0, 163.0, 187.0, 187.0, 173.0, 189.0, 126.0, 144.0, 135.0, 3.0, 162.0, 119.0, 15.0, 148.0, 3.0, 0.0, 185.0, 183.0, 160.0, 11.0, 7.0, 15.0, 4.0, 2.0, 120.0, 153.0, 16.0, 19.0, 187.0, 184.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5638128291364797, "mean_inference_ms": 1.457120267088129, "mean_action_processing_ms": 0.2419258771011333, "mean_env_wait_ms": 0.18731093242163122, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047016143798828125, "StateBufferConnector_ms": 0.0027065277099609375, "ViewRequirementAgentConnector_ms": 0.0787346363067627}, "num_episodes": 18, "episode_return_max": 65.20000000000034, "episode_return_min": -415.0999999999998, "episode_return_mean": -134.08500000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 432.50157059181856, "num_env_steps_trained_throughput_per_sec": 432.50157059181856, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 9347.61, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9347.567, "sample_time_ms": 1048.402, "learn_time_ms": 8286.452, "learn_throughput": 482.716, "synch_weights_time_ms": 11.617}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-33-00", "timestamp": 1723645980, "time_this_iter_s": 9.251528024673462, "time_total_s": 499.7952792644501, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 499.7952792644501, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 26.407692307692308, "ram_util_percent": 75.15384615384616}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5133474854249802, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 5.393608919905607, "policy_loss": -0.014322723457146259, "vf_loss": 5.40497470658923, "vf_explained_var": 0.2658889186760736, "kl": 0.009856452127685607, "entropy": 1.356895290796088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.307871770827228, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.7674495717205065, "policy_loss": -0.010810324980103701, "vf_loss": 6.776336185515873, "vf_explained_var": -0.020513351096047294, "kl": 0.009618546884822287, "entropy": 1.1414296159668573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 65.20000000000034, "episode_reward_min": -419.4999999999999, "episode_reward_mean": -132.64900000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -417.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 91.69999999999995, "predator_policy": 228.0}, "policy_reward_mean": {"prey_policy": -167.45450000000005, "predator_policy": 101.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.399999999999956, 34.50000000000022, -0.29999999999974314, -390.59999999999985, 30.000000000000146, -262.0000000000002, -58.89999999999968, 35.10000000000022, -280.70000000000016, 41.60000000000033, -17.200000000000028, -352.9999999999998, -241.80000000000038, -81.60000000000018, -287.5, -134.90000000000072, -370.4, 65.20000000000034, 38.400000000000276, -115.20000000000083, -72.90000000000012, -141.30000000000013, -214.50000000000054, -46.69999999999974, -130.20000000000059, -132.60000000000002, -332.30000000000007, -187.70000000000098, -102.80000000000078, -241.00000000000009, -40.49999999999986, -115.09999999999997, -56.699999999999726, -359.5, -4.599999999999737, -366.0999999999998, -27.999999999999922, 44.00000000000037, -236.50000000000003, -36.49999999999973, -219.10000000000053, -343.4999999999996, 14.999999999999906, -52.69999999999968, -53.49999999999998, -144.5999999999998, -164.600000000001, -252.60000000000056, -342.99999999999994, -7.700000000000026, 29.000000000000124, -158.40000000000055, -257.0000000000006, -390.2999999999989, -44.199999999999676, 44.80000000000038, -261.40000000000043, -28.399999999999977, -130.7000000000001, -158.1000000000003, 11.400000000000063, -92.40000000000046, -272.80000000000007, -280.10000000000014, -415.0999999999998, -271.29999999999995, -220.40000000000006, -269.6000000000005, -396.6, -311.20000000000005, -290.6000000000006, -247.40000000000018, -124.19999999999999, -96.40000000000015, 36.70000000000025, -11.20000000000006, -211.00000000000045, 15.800000000000004, 33.4000000000002, -13.400000000000059, 43.20000000000035, -9.0, -47.49999999999968, -403.19999999999993, 30.10000000000015, -44.699999999999875, -27.09999999999995, -262.70000000000005, 40.500000000000306, 49.50000000000046, -345.79999999999995, -419.4999999999999, -180.00000000000097, 39.40000000000029, -68.3000000000003, 25.70000000000007, -189.90000000000015, 43.800000000000026, -8.400000000000034, -50.19999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.599999999999753, 20.000000000000014, 9.499999999999964, 20.000000000000014, -5.1999999999999265, -24.099999999999746, -358.0, -307.6000000000001, 5.899999999999967, 13.099999999999966, -259.3000000000002, -288.7, -309.3, -13.600000000000035, 26.600000000000126, -11.499999999999819, -244.6000000000002, -192.10000000000002, 25.1000000000001, -2.499999999999986, -417.70000000000005, 24.500000000000096, -242.09999999999994, -325.89999999999964, -169.00000000000023, -348.79999999999984, -225.7000000000001, 7.099999999999966, -296.69999999999993, -177.79999999999998, 3.1999999999999655, -297.1, -377.4, -411.0, 31.700000000000212, -2.500000000000029, 7.399999999999965, 20.000000000000014, -70.30000000000065, -271.9000000000002, 21.80000000000004, -372.6999999999998, -102.70000000000005, -139.60000000000014, -362.1999999999999, -217.3000000000005, 20.90000000000003, -370.6, 9.499999999999964, -330.70000000000005, -100.20000000000007, -168.40000000000012, -355.5, -364.79999999999995, -351.6999999999995, -42.99999999999976, -141.70000000000067, -117.1000000000003, -238.30000000000027, -141.7000000000001, -232.00000000000009, -26.499999999999794, -103.89999999999998, -378.19999999999993, -384.9000000000001, -17.79999999999974, -360.1, -324.4, -76.60000000000088, 20.000000000000014, -324.3999999999999, -330.6999999999998, -351.69999999999993, 31.700000000000216, 20.000000000000014, 16.99999999999997, -209.5, -358.00000000000006, -379.5, 20.000000000000014, -282.4, -99.6999999999999, -322.29999999999984, -209.20000000000005, -13.599999999999833, -9.399999999999855, -330.69999999999993, -0.9999999999999846, -100.3000000000001, -302.20000000000033, -110.70000000000002, -292.9000000000002, -116.50000000000074, -234.09999999999994, -290.8000000000001, -227.80000000000047, -290.79999999999995, -378.19999999999993, -376.9, 30.200000000000173, 11.599999999999964, 7.399999999999965, -85.90000000000018, -242.50000000000028, -330.6999999999997, -196.3000000000005, -284.50000000000006, -269.8000000000003, -255.09999999999997, -24.09999999999981, 11.599999999999964, 27.200000000000134, -196.30000000000044, -339.0999999999997, 19.1, -305.5, -196.2, -158.50000000000006, -265.60000000000025, -69.50000000000004, 11.599999999999964, -26.199999999999747, 31.700000000000212, -339.1, -330.29999999999995, -368.5, -353.79999999999984, -217.30000000000044, -355.9, -383.19999999999993, -190.00000000000034, -238.30000000000013, -303.39999999999986, -157.00000000000014, -185.79999999999998, -248.80000000000027, -383.20000000000005, -387.4, -372.70000000000005, -300.5, -280.29999999999995, -280.3000000000003, -145.00000000000009, -240.4000000000002, -61.89999999999993, -343.3000000000001, -4.299999999999972, -255.10000000000005, 13.699999999999964, 20.000000000000014, 20.000000000000014, -399.20000000000005, -288.9999999999999, -93.00000000000009, -11.499999999999819, 5.299999999999965, 15.799999999999963, 11.599999999999964, 20.000000000000014, -306.40000000000003, 34.40000000000026, -26.199999999999747, 20.000000000000014, -400.0, -13.599999999999826, -270.9000000000002, -417.7, -389.5, 1.0999999999999794, 20.000000000000014, -124.89999999999986, 3.1999999999999615, -3.099999999999958, -94.00000000000011, -376.9, -306.8, 20.600000000000026, 17.899999999999988, 27.50000000000014, 20.000000000000014, -332.79999999999995, -400.0, -381.0999999999999, -387.3999999999999, -57.70000000000048, -322.29999999999984, 25.4000000000001, -21.999999999999744, 20.000000000000014, -322.30000000000007, -0.9999999999999992, 13.699999999999964, -208.9000000000004, -190.00000000000009, 91.69999999999995, -376.9, 25.100000000000094, -389.49999999999994, -135.4000000000001, 3.1999999999999615], "policy_predator_policy_reward": [19.0, 7.0, 5.0, 0.0, 8.0, 21.0, 146.0, 129.0, 3.0, 8.0, 151.0, 135.0, 126.0, 138.0, 15.0, 5.0, 148.0, 8.0, 4.0, 15.0, 170.0, 206.0, 204.0, 11.0, 90.0, 186.0, 121.0, 16.0, 187.0, 0.0, 154.0, 5.0, 190.0, 228.0, 12.0, 24.0, 5.0, 6.0, 106.0, 121.0, 160.0, 118.0, 86.0, 15.0, 183.0, 182.0, 137.0, 166.0, 155.0, 36.0, 14.0, 122.0, 194.0, 194.0, 30.0, 177.0, 123.0, 33.0, 138.0, 1.0, 142.0, 76.0, 178.0, 189.0, 167.0, 179.0, 152.0, 173.0, 46.0, 6.0, 124.0, 165.0, 152.0, 140.0, 3.0, 4.0, 168.0, 163.0, 172.0, 151.0, 16.0, 147.0, 16.0, 172.0, 24.0, 14.0, 148.0, 131.0, 145.0, 204.0, 136.0, 123.0, 65.0, 121.0, 148.0, 118.0, 180.0, 146.0, 167.0, 172.0, 6.0, 4.0, 162.0, 8.0, 167.0, 103.0, 160.0, 4.0, 118.0, 117.0, 4.0, 2.0, 103.0, 171.0, 126.0, 132.0, 119.0, 105.0, 8.0, 169.0, 4.0, 22.0, 55.0, 160.0, 223.0, 203.0, 178.0, 113.0, 148.0, 176.0, 17.0, 140.0, 89.0, 151.0, 2.0, 163.0, 187.0, 187.0, 173.0, 189.0, 126.0, 144.0, 135.0, 3.0, 162.0, 119.0, 15.0, 148.0, 3.0, 0.0, 185.0, 183.0, 160.0, 11.0, 7.0, 15.0, 4.0, 2.0, 120.0, 153.0, 16.0, 19.0, 187.0, 184.0, 112.0, 125.0, 207.0, 197.0, 0.0, 9.0, 16.0, 61.0, 61.0, 9.0, 214.0, 207.0, 1.0, 1.0, 0.0, 2.0, 191.0, 196.0, 181.0, 168.0, 37.0, 163.0, 16.0, 20.0, 80.0, 154.0, 0.0, 13.0, 109.0, 100.0, 169.0, 160.0, 179.0, 177.0, 0.0, 82.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5623831061054494, "mean_inference_ms": 1.4530935297257628, "mean_action_processing_ms": 0.24125328486761777, "mean_env_wait_ms": 0.18671103726459215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004368782043457031, "StateBufferConnector_ms": 0.003269195556640625, "ViewRequirementAgentConnector_ms": 0.08006167411804199}, "num_episodes": 18, "episode_return_max": 65.20000000000034, "episode_return_min": -419.4999999999999, "episode_return_mean": -132.64900000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 440.49550051598777, "num_env_steps_trained_throughput_per_sec": 440.49550051598777, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 9278.045, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9278.003, "sample_time_ms": 1042.63, "learn_time_ms": 8222.862, "learn_throughput": 486.449, "synch_weights_time_ms": 11.488}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-33-09", "timestamp": 1723645989, "time_this_iter_s": 9.084919929504395, "time_total_s": 508.88019919395447, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1561f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 508.88019919395447, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 26.692307692307693, "ram_util_percent": 75.61538461538463}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.373571418958997, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 4.869658121860847, "policy_loss": -0.012708870682707697, "vf_loss": 4.87957195932903, "vf_explained_var": 0.2977575003785431, "kl": 0.009316771311095583, "entropy": 1.35635654226182, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9089000117211117, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.511107487905593, "policy_loss": -0.011694745367107094, "vf_loss": 6.520193693877528, "vf_explained_var": 0.05009418208763082, "kl": 0.013042717521511081, "entropy": 1.10247776110967, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 92.59999999999913, "episode_reward_min": -419.4999999999999, "episode_reward_mean": -123.2250000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -417.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 91.69999999999995, "predator_policy": 223.0}, "policy_reward_mean": {"prey_policy": -163.07750000000004, "predator_policy": 101.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.400000000000276, -115.20000000000083, -72.90000000000012, -141.30000000000013, -214.50000000000054, -46.69999999999974, -130.20000000000059, -132.60000000000002, -332.30000000000007, -187.70000000000098, -102.80000000000078, -241.00000000000009, -40.49999999999986, -115.09999999999997, -56.699999999999726, -359.5, -4.599999999999737, -366.0999999999998, -27.999999999999922, 44.00000000000037, -236.50000000000003, -36.49999999999973, -219.10000000000053, -343.4999999999996, 14.999999999999906, -52.69999999999968, -53.49999999999998, -144.5999999999998, -164.600000000001, -252.60000000000056, -342.99999999999994, -7.700000000000026, 29.000000000000124, -158.40000000000055, -257.0000000000006, -390.2999999999989, -44.199999999999676, 44.80000000000038, -261.40000000000043, -28.399999999999977, -130.7000000000001, -158.1000000000003, 11.400000000000063, -92.40000000000046, -272.80000000000007, -280.10000000000014, -415.0999999999998, -271.29999999999995, -220.40000000000006, -269.6000000000005, -396.6, -311.20000000000005, -290.6000000000006, -247.40000000000018, -124.19999999999999, -96.40000000000015, 36.70000000000025, -11.20000000000006, -211.00000000000045, 15.800000000000004, 33.4000000000002, -13.400000000000059, 43.20000000000035, -9.0, -47.49999999999968, -403.19999999999993, 30.10000000000015, -44.699999999999875, -27.09999999999995, -262.70000000000005, 40.500000000000306, 49.50000000000046, -345.79999999999995, -419.4999999999999, -180.00000000000097, 39.40000000000029, -68.3000000000003, 25.70000000000007, -189.90000000000015, 43.800000000000026, -8.400000000000034, -50.19999999999996, -49.899999999999636, 22.40000000000005, -170.60000000000093, 13.500000000000124, -191.0000000000008, -174.0000000000008, -13.100000000000009, -20.89999999999997, -37.59999999999957, 92.59999999999913, -16.49999999999978, -192.10000000000085, -67.10000000000073, -112.90000000000003, 35.600000000000236, -166.80000000000078, 37.90000000000027, -302.20000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 20.000000000000014, -70.30000000000065, -271.9000000000002, 21.80000000000004, -372.6999999999998, -102.70000000000005, -139.60000000000014, -362.1999999999999, -217.3000000000005, 20.90000000000003, -370.6, 9.499999999999964, -330.70000000000005, -100.20000000000007, -168.40000000000012, -355.5, -364.79999999999995, -351.6999999999995, -42.99999999999976, -141.70000000000067, -117.1000000000003, -238.30000000000027, -141.7000000000001, -232.00000000000009, -26.499999999999794, -103.89999999999998, -378.19999999999993, -384.9000000000001, -17.79999999999974, -360.1, -324.4, -76.60000000000088, 20.000000000000014, -324.3999999999999, -330.6999999999998, -351.69999999999993, 31.700000000000216, 20.000000000000014, 16.99999999999997, -209.5, -358.00000000000006, -379.5, 20.000000000000014, -282.4, -99.6999999999999, -322.29999999999984, -209.20000000000005, -13.599999999999833, -9.399999999999855, -330.69999999999993, -0.9999999999999846, -100.3000000000001, -302.20000000000033, -110.70000000000002, -292.9000000000002, -116.50000000000074, -234.09999999999994, -290.8000000000001, -227.80000000000047, -290.79999999999995, -378.19999999999993, -376.9, 30.200000000000173, 11.599999999999964, 7.399999999999965, -85.90000000000018, -242.50000000000028, -330.6999999999997, -196.3000000000005, -284.50000000000006, -269.8000000000003, -255.09999999999997, -24.09999999999981, 11.599999999999964, 27.200000000000134, -196.30000000000044, -339.0999999999997, 19.1, -305.5, -196.2, -158.50000000000006, -265.60000000000025, -69.50000000000004, 11.599999999999964, -26.199999999999747, 31.700000000000212, -339.1, -330.29999999999995, -368.5, -353.79999999999984, -217.30000000000044, -355.9, -383.19999999999993, -190.00000000000034, -238.30000000000013, -303.39999999999986, -157.00000000000014, -185.79999999999998, -248.80000000000027, -383.20000000000005, -387.4, -372.70000000000005, -300.5, -280.29999999999995, -280.3000000000003, -145.00000000000009, -240.4000000000002, -61.89999999999993, -343.3000000000001, -4.299999999999972, -255.10000000000005, 13.699999999999964, 20.000000000000014, 20.000000000000014, -399.20000000000005, -288.9999999999999, -93.00000000000009, -11.499999999999819, 5.299999999999965, 15.799999999999963, 11.599999999999964, 20.000000000000014, -306.40000000000003, 34.40000000000026, -26.199999999999747, 20.000000000000014, -400.0, -13.599999999999826, -270.9000000000002, -417.7, -389.5, 1.0999999999999794, 20.000000000000014, -124.89999999999986, 3.1999999999999615, -3.099999999999958, -94.00000000000011, -376.9, -306.8, 20.600000000000026, 17.899999999999988, 27.50000000000014, 20.000000000000014, -332.79999999999995, -400.0, -381.0999999999999, -387.3999999999999, -57.70000000000048, -322.29999999999984, 25.4000000000001, -21.999999999999744, 20.000000000000014, -322.30000000000007, -0.9999999999999992, 13.699999999999964, -208.9000000000004, -190.00000000000009, 91.69999999999995, -376.9, 25.100000000000094, -389.49999999999994, -135.4000000000001, 3.1999999999999615, -148.00000000000034, 13.099999999999966, -7.299999999999951, 13.699999999999964, -89.20000000000078, -243.40000000000018, 22.40000000000005, -292.90000000000003, -28.29999999999975, -372.69999999999976, -362.1999999999998, -8.799999999999871, 30.8000000000002, -376.90000000000003, -397.9, 20.000000000000014, -162.70000000000064, 1.0999999999999865, 90.49999999999957, -40.89999999999976, 7.399999999999965, -166.90000000000046, -17.79999999999974, -385.30000000000007, -35.799999999999756, -112.30000000000032, -0.9999999999999952, -250.9000000000004, 15.799999999999963, 15.799999999999963, 1.0999999999999865, -355.8999999999999, 20.000000000000014, 8.899999999999967, -397.9, -280.3], "policy_predator_policy_reward": [5.0, 6.0, 106.0, 121.0, 160.0, 118.0, 86.0, 15.0, 183.0, 182.0, 137.0, 166.0, 155.0, 36.0, 14.0, 122.0, 194.0, 194.0, 30.0, 177.0, 123.0, 33.0, 138.0, 1.0, 142.0, 76.0, 178.0, 189.0, 167.0, 179.0, 152.0, 173.0, 46.0, 6.0, 124.0, 165.0, 152.0, 140.0, 3.0, 4.0, 168.0, 163.0, 172.0, 151.0, 16.0, 147.0, 16.0, 172.0, 24.0, 14.0, 148.0, 131.0, 145.0, 204.0, 136.0, 123.0, 65.0, 121.0, 148.0, 118.0, 180.0, 146.0, 167.0, 172.0, 6.0, 4.0, 162.0, 8.0, 167.0, 103.0, 160.0, 4.0, 118.0, 117.0, 4.0, 2.0, 103.0, 171.0, 126.0, 132.0, 119.0, 105.0, 8.0, 169.0, 4.0, 22.0, 55.0, 160.0, 223.0, 203.0, 178.0, 113.0, 148.0, 176.0, 17.0, 140.0, 89.0, 151.0, 2.0, 163.0, 187.0, 187.0, 173.0, 189.0, 126.0, 144.0, 135.0, 3.0, 162.0, 119.0, 15.0, 148.0, 3.0, 0.0, 185.0, 183.0, 160.0, 11.0, 7.0, 15.0, 4.0, 2.0, 120.0, 153.0, 16.0, 19.0, 187.0, 184.0, 112.0, 125.0, 207.0, 197.0, 0.0, 9.0, 16.0, 61.0, 61.0, 9.0, 214.0, 207.0, 1.0, 1.0, 0.0, 2.0, 191.0, 196.0, 181.0, 168.0, 37.0, 163.0, 16.0, 20.0, 80.0, 154.0, 0.0, 13.0, 109.0, 100.0, 169.0, 160.0, 179.0, 177.0, 0.0, 82.0, 80.0, 5.0, 1.0, 15.0, 5.0, 157.0, 142.0, 142.0, 23.0, 187.0, 182.0, 15.0, 154.0, 179.0, 183.0, 174.0, 44.0, 80.0, 8.0, 35.0, 62.0, 81.0, 193.0, 18.0, 78.0, 3.0, 129.0, 10.0, 2.0, 2.0, 9.0, 179.0, 7.0, 2.0, 189.0, 187.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5611347365846082, "mean_inference_ms": 1.4497846369737928, "mean_action_processing_ms": 0.24067069891356652, "mean_env_wait_ms": 0.18620161035019092, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003967761993408203, "StateBufferConnector_ms": 0.0032924413681030273, "ViewRequirementAgentConnector_ms": 0.08047866821289062}, "num_episodes": 18, "episode_return_max": 92.59999999999913, "episode_return_min": -419.4999999999999, "episode_return_mean": -123.2250000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 440.11126117075855, "num_env_steps_trained_throughput_per_sec": 440.11126117075855, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 9190.943, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9190.904, "sample_time_ms": 1004.473, "learn_time_ms": 8174.39, "learn_throughput": 489.333, "synch_weights_time_ms": 11.215}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-33-18", "timestamp": 1723645998, "time_this_iter_s": 9.091653108596802, "time_total_s": 517.9718523025513, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0adca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 517.9718523025513, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 27.60769230769231, "ram_util_percent": 75.89999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5551225036855727, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 4.591241902396792, "policy_loss": -0.01444663563201194, "vf_loss": 4.602073502919031, "vf_explained_var": 0.28096365222224484, "kl": 0.012050119563716793, "entropy": 1.3339934847973012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.065046294025643, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 6.055706329194326, "policy_loss": -0.01163898298095557, "vf_loss": 6.06470518187871, "vf_explained_var": 0.025432245851193785, "kl": 0.013200666457428678, "entropy": 1.125599660444512, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 157.9999999999995, "episode_reward_min": -419.4999999999999, "episode_reward_mean": -111.36800000000012, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -417.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.49999999999974, "predator_policy": 223.0}, "policy_reward_mean": {"prey_policy": -154.264, "predator_policy": 98.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-219.10000000000053, -343.4999999999996, 14.999999999999906, -52.69999999999968, -53.49999999999998, -144.5999999999998, -164.600000000001, -252.60000000000056, -342.99999999999994, -7.700000000000026, 29.000000000000124, -158.40000000000055, -257.0000000000006, -390.2999999999989, -44.199999999999676, 44.80000000000038, -261.40000000000043, -28.399999999999977, -130.7000000000001, -158.1000000000003, 11.400000000000063, -92.40000000000046, -272.80000000000007, -280.10000000000014, -415.0999999999998, -271.29999999999995, -220.40000000000006, -269.6000000000005, -396.6, -311.20000000000005, -290.6000000000006, -247.40000000000018, -124.19999999999999, -96.40000000000015, 36.70000000000025, -11.20000000000006, -211.00000000000045, 15.800000000000004, 33.4000000000002, -13.400000000000059, 43.20000000000035, -9.0, -47.49999999999968, -403.19999999999993, 30.10000000000015, -44.699999999999875, -27.09999999999995, -262.70000000000005, 40.500000000000306, 49.50000000000046, -345.79999999999995, -419.4999999999999, -180.00000000000097, 39.40000000000029, -68.3000000000003, 25.70000000000007, -189.90000000000015, 43.800000000000026, -8.400000000000034, -50.19999999999996, -49.899999999999636, 22.40000000000005, -170.60000000000093, 13.500000000000124, -191.0000000000008, -174.0000000000008, -13.100000000000009, -20.89999999999997, -37.59999999999957, 92.59999999999913, -16.49999999999978, -192.10000000000085, -67.10000000000073, -112.90000000000003, 35.600000000000236, -166.80000000000078, 37.90000000000027, -302.20000000000005, 102.99999999999997, -130.6000000000007, -11.500000000000076, -86.4000000000008, -136.20000000000044, -402.0, -386.39999999999975, -24.19999999999974, 157.9999999999995, -252.5, 27.4000000000001, -6.499999999999702, 2.1000000000000165, 120.99999999999973, -270.1, -92.60000000000072, 5.300000000000177, 35.600000000000236, 35.40000000000023, -154.6000000000006, 36.40000000000025, -263.1999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-282.4, -99.6999999999999, -322.29999999999984, -209.20000000000005, -13.599999999999833, -9.399999999999855, -330.69999999999993, -0.9999999999999846, -100.3000000000001, -302.20000000000033, -110.70000000000002, -292.9000000000002, -116.50000000000074, -234.09999999999994, -290.8000000000001, -227.80000000000047, -290.79999999999995, -378.19999999999993, -376.9, 30.200000000000173, 11.599999999999964, 7.399999999999965, -85.90000000000018, -242.50000000000028, -330.6999999999997, -196.3000000000005, -284.50000000000006, -269.8000000000003, -255.09999999999997, -24.09999999999981, 11.599999999999964, 27.200000000000134, -196.30000000000044, -339.0999999999997, 19.1, -305.5, -196.2, -158.50000000000006, -265.60000000000025, -69.50000000000004, 11.599999999999964, -26.199999999999747, 31.700000000000212, -339.1, -330.29999999999995, -368.5, -353.79999999999984, -217.30000000000044, -355.9, -383.19999999999993, -190.00000000000034, -238.30000000000013, -303.39999999999986, -157.00000000000014, -185.79999999999998, -248.80000000000027, -383.20000000000005, -387.4, -372.70000000000005, -300.5, -280.29999999999995, -280.3000000000003, -145.00000000000009, -240.4000000000002, -61.89999999999993, -343.3000000000001, -4.299999999999972, -255.10000000000005, 13.699999999999964, 20.000000000000014, 20.000000000000014, -399.20000000000005, -288.9999999999999, -93.00000000000009, -11.499999999999819, 5.299999999999965, 15.799999999999963, 11.599999999999964, 20.000000000000014, -306.40000000000003, 34.40000000000026, -26.199999999999747, 20.000000000000014, -400.0, -13.599999999999826, -270.9000000000002, -417.7, -389.5, 1.0999999999999794, 20.000000000000014, -124.89999999999986, 3.1999999999999615, -3.099999999999958, -94.00000000000011, -376.9, -306.8, 20.600000000000026, 17.899999999999988, 27.50000000000014, 20.000000000000014, -332.79999999999995, -400.0, -381.0999999999999, -387.3999999999999, -57.70000000000048, -322.29999999999984, 25.4000000000001, -21.999999999999744, 20.000000000000014, -322.30000000000007, -0.9999999999999992, 13.699999999999964, -208.9000000000004, -190.00000000000009, 91.69999999999995, -376.9, 25.100000000000094, -389.49999999999994, -135.4000000000001, 3.1999999999999615, -148.00000000000034, 13.099999999999966, -7.299999999999951, 13.699999999999964, -89.20000000000078, -243.40000000000018, 22.40000000000005, -292.90000000000003, -28.29999999999975, -372.69999999999976, -362.1999999999998, -8.799999999999871, 30.8000000000002, -376.90000000000003, -397.9, 20.000000000000014, -162.70000000000064, 1.0999999999999865, 90.49999999999957, -40.89999999999976, 7.399999999999965, -166.90000000000046, -17.79999999999974, -385.30000000000007, -35.799999999999756, -112.30000000000032, -0.9999999999999952, -250.9000000000004, 15.799999999999963, 15.799999999999963, 1.0999999999999865, -355.8999999999999, 20.000000000000014, 8.899999999999967, -397.9, -280.3, 108.79999999999993, -59.80000000000058, -393.70000000000005, 1.0999999999999865, 19.1, -265.6, -385.3, -12.099999999999817, -292.9, -7.299999999999891, -400.0, -400.0, -372.6999999999998, -393.69999999999993, 20.000000000000014, -299.2000000000003, 113.60000000000001, 13.399999999999965, -248.8, -393.69999999999993, -0.9999999999999846, 7.399999999999972, 5.299999999999972, -59.80000000000052, 34.70000000000025, -328.5999999999999, -389.49999999999994, 150.49999999999974, -355.9, -278.20000000000005, -376.9000000000001, -15.699999999999747, -0.9999999999999917, -15.699999999999747, 20.000000000000014, 11.599999999999964, 7.399999999999965, 20.000000000000014, 21.800000000000068, -366.3999999999999, 20.000000000000014, 7.399999999999965, -370.59999999999997, -265.5999999999999], "policy_predator_policy_reward": [16.0, 147.0, 16.0, 172.0, 24.0, 14.0, 148.0, 131.0, 145.0, 204.0, 136.0, 123.0, 65.0, 121.0, 148.0, 118.0, 180.0, 146.0, 167.0, 172.0, 6.0, 4.0, 162.0, 8.0, 167.0, 103.0, 160.0, 4.0, 118.0, 117.0, 4.0, 2.0, 103.0, 171.0, 126.0, 132.0, 119.0, 105.0, 8.0, 169.0, 4.0, 22.0, 55.0, 160.0, 223.0, 203.0, 178.0, 113.0, 148.0, 176.0, 17.0, 140.0, 89.0, 151.0, 2.0, 163.0, 187.0, 187.0, 173.0, 189.0, 126.0, 144.0, 135.0, 3.0, 162.0, 119.0, 15.0, 148.0, 3.0, 0.0, 185.0, 183.0, 160.0, 11.0, 7.0, 15.0, 4.0, 2.0, 120.0, 153.0, 16.0, 19.0, 187.0, 184.0, 112.0, 125.0, 207.0, 197.0, 0.0, 9.0, 16.0, 61.0, 61.0, 9.0, 214.0, 207.0, 1.0, 1.0, 0.0, 2.0, 191.0, 196.0, 181.0, 168.0, 37.0, 163.0, 16.0, 20.0, 80.0, 154.0, 0.0, 13.0, 109.0, 100.0, 169.0, 160.0, 179.0, 177.0, 0.0, 82.0, 80.0, 5.0, 1.0, 15.0, 5.0, 157.0, 142.0, 142.0, 23.0, 187.0, 182.0, 15.0, 154.0, 179.0, 183.0, 174.0, 44.0, 80.0, 8.0, 35.0, 62.0, 81.0, 193.0, 18.0, 78.0, 3.0, 129.0, 10.0, 2.0, 2.0, 9.0, 179.0, 7.0, 2.0, 189.0, 187.0, 11.0, 43.0, 69.0, 193.0, 106.0, 129.0, 187.0, 124.0, 12.0, 152.0, 198.0, 200.0, 184.0, 196.0, 126.0, 129.0, 23.0, 8.0, 195.0, 195.0, 6.0, 15.0, 37.0, 11.0, 154.0, 142.0, 171.0, 189.0, 179.0, 185.0, 119.0, 181.0, 5.0, 17.0, 0.0, 4.0, 2.0, 6.0, 184.0, 6.0, 6.0, 3.0, 187.0, 186.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5597459486081253, "mean_inference_ms": 1.4460701691301088, "mean_action_processing_ms": 0.24005055939255882, "mean_env_wait_ms": 0.18562572255132942, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003527998924255371, "StateBufferConnector_ms": 0.003318190574645996, "ViewRequirementAgentConnector_ms": 0.08291757106781006}, "num_episodes": 22, "episode_return_max": 157.9999999999995, "episode_return_min": -419.4999999999999, "episode_return_mean": -111.36800000000012, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 438.1216212782567, "num_env_steps_trained_throughput_per_sec": 438.1216212782567, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 9145.01, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9144.973, "sample_time_ms": 1002.485, "learn_time_ms": 8130.414, "learn_throughput": 491.98, "synch_weights_time_ms": 11.267}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-33-27", "timestamp": 1723646007, "time_this_iter_s": 9.13378095626831, "time_total_s": 527.1056332588196, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 527.1056332588196, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 26.253846153846155, "ram_util_percent": 76.16153846153847}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2295350478755105, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 4.810835749131662, "policy_loss": -0.012942125352602156, "vf_loss": 4.820971590375144, "vf_explained_var": 0.24443249920057872, "kl": 0.009354269201020077, "entropy": 1.2886693851657645, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.56191568242179, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.500551611658127, "policy_loss": -0.010136854578617705, "vf_loss": 4.5089338980023825, "vf_explained_var": 0.04940754175186157, "kl": 0.008772814511755024, "entropy": 1.1768193624637746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 206.99999999999932, "episode_reward_min": -419.4999999999999, "episode_reward_mean": -84.74100000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -417.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.0, "predator_policy": 214.0}, "policy_reward_mean": {"prey_policy": -132.29050000000004, "predator_policy": 89.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-280.10000000000014, -415.0999999999998, -271.29999999999995, -220.40000000000006, -269.6000000000005, -396.6, -311.20000000000005, -290.6000000000006, -247.40000000000018, -124.19999999999999, -96.40000000000015, 36.70000000000025, -11.20000000000006, -211.00000000000045, 15.800000000000004, 33.4000000000002, -13.400000000000059, 43.20000000000035, -9.0, -47.49999999999968, -403.19999999999993, 30.10000000000015, -44.699999999999875, -27.09999999999995, -262.70000000000005, 40.500000000000306, 49.50000000000046, -345.79999999999995, -419.4999999999999, -180.00000000000097, 39.40000000000029, -68.3000000000003, 25.70000000000007, -189.90000000000015, 43.800000000000026, -8.400000000000034, -50.19999999999996, -49.899999999999636, 22.40000000000005, -170.60000000000093, 13.500000000000124, -191.0000000000008, -174.0000000000008, -13.100000000000009, -20.89999999999997, -37.59999999999957, 92.59999999999913, -16.49999999999978, -192.10000000000085, -67.10000000000073, -112.90000000000003, 35.600000000000236, -166.80000000000078, 37.90000000000027, -302.20000000000005, 102.99999999999997, -130.6000000000007, -11.500000000000076, -86.4000000000008, -136.20000000000044, -402.0, -386.39999999999975, -24.19999999999974, 157.9999999999995, -252.5, 27.4000000000001, -6.499999999999702, 2.1000000000000165, 120.99999999999973, -270.1, -92.60000000000072, 5.300000000000177, 35.600000000000236, 35.40000000000023, -154.6000000000006, 36.40000000000025, -263.1999999999999, 31.20000000000017, 26.70000000000014, 33.1000000000002, 65.69999999999992, -191.00000000000108, 26.3000000000001, -20.59999999999983, -214.20000000000059, -88.6999999999999, 8.099999999999964, 167.59999999999923, 28.300000000000114, 22.700000000000028, -48.89999999999967, -188.80000000000072, 25.70000000000007, -177.80000000000072, 22.30000000000001, 27.800000000000136, -397.79999999999995, -12.09999999999981, 35.30000000000023, 206.99999999999932], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-353.79999999999984, -217.30000000000044, -355.9, -383.19999999999993, -190.00000000000034, -238.30000000000013, -303.39999999999986, -157.00000000000014, -185.79999999999998, -248.80000000000027, -383.20000000000005, -387.4, -372.70000000000005, -300.5, -280.29999999999995, -280.3000000000003, -145.00000000000009, -240.4000000000002, -61.89999999999993, -343.3000000000001, -4.299999999999972, -255.10000000000005, 13.699999999999964, 20.000000000000014, 20.000000000000014, -399.20000000000005, -288.9999999999999, -93.00000000000009, -11.499999999999819, 5.299999999999965, 15.799999999999963, 11.599999999999964, 20.000000000000014, -306.40000000000003, 34.40000000000026, -26.199999999999747, 20.000000000000014, -400.0, -13.599999999999826, -270.9000000000002, -417.7, -389.5, 1.0999999999999794, 20.000000000000014, -124.89999999999986, 3.1999999999999615, -3.099999999999958, -94.00000000000011, -376.9, -306.8, 20.600000000000026, 17.899999999999988, 27.50000000000014, 20.000000000000014, -332.79999999999995, -400.0, -381.0999999999999, -387.3999999999999, -57.70000000000048, -322.29999999999984, 25.4000000000001, -21.999999999999744, 20.000000000000014, -322.30000000000007, -0.9999999999999992, 13.699999999999964, -208.9000000000004, -190.00000000000009, 91.69999999999995, -376.9, 25.100000000000094, -389.49999999999994, -135.4000000000001, 3.1999999999999615, -148.00000000000034, 13.099999999999966, -7.299999999999951, 13.699999999999964, -89.20000000000078, -243.40000000000018, 22.40000000000005, -292.90000000000003, -28.29999999999975, -372.69999999999976, -362.1999999999998, -8.799999999999871, 30.8000000000002, -376.90000000000003, -397.9, 20.000000000000014, -162.70000000000064, 1.0999999999999865, 90.49999999999957, -40.89999999999976, 7.399999999999965, -166.90000000000046, -17.79999999999974, -385.30000000000007, -35.799999999999756, -112.30000000000032, -0.9999999999999952, -250.9000000000004, 15.799999999999963, 15.799999999999963, 1.0999999999999865, -355.8999999999999, 20.000000000000014, 8.899999999999967, -397.9, -280.3, 108.79999999999993, -59.80000000000058, -393.70000000000005, 1.0999999999999865, 19.1, -265.6, -385.3, -12.099999999999817, -292.9, -7.299999999999891, -400.0, -400.0, -372.6999999999998, -393.69999999999993, 20.000000000000014, -299.2000000000003, 113.60000000000001, 13.399999999999965, -248.8, -393.69999999999993, -0.9999999999999846, 7.399999999999972, 5.299999999999972, -59.80000000000052, 34.70000000000025, -328.5999999999999, -389.49999999999994, 150.49999999999974, -355.9, -278.20000000000005, -376.9000000000001, -15.699999999999747, -0.9999999999999917, -15.699999999999747, 20.000000000000014, 11.599999999999964, 7.399999999999965, 20.000000000000014, 21.800000000000068, -366.3999999999999, 20.000000000000014, 7.399999999999965, -370.59999999999997, -265.5999999999999, 20.000000000000014, 3.1999999999999615, 11.599999999999964, -124.90000000000003, -19.899999999999743, 20.000000000000014, 87.19999999999959, -389.5, -66.10000000000076, -334.90000000000003, 20.000000000000014, -57.70000000000045, 14.599999999999966, -142.20000000000005, -118.60000000000001, -286.6000000000002, -225.7000000000004, 20.000000000000014, 21.800000000000065, -330.70000000000005, 136.09999999999985, 12.499999999999968, 8.299999999999965, 4.999999999999966, -28.29999999999975, 20.000000000000014, -309.69999999999993, -5.1999999999999265, 3.1999999999999615, -400.0, 20.000000000000014, -7.299999999999891, -389.5, 13.699999999999964, 20.000000000000014, -15.699999999999747, -3.099999999999958, 5.899999999999974, -400.0, -395.79999999999995, 20.000000000000014, -381.1, 5.299999999999965, 20.000000000000014, 176.0, 20.000000000000014], "policy_predator_policy_reward": [178.0, 113.0, 148.0, 176.0, 17.0, 140.0, 89.0, 151.0, 2.0, 163.0, 187.0, 187.0, 173.0, 189.0, 126.0, 144.0, 135.0, 3.0, 162.0, 119.0, 15.0, 148.0, 3.0, 0.0, 185.0, 183.0, 160.0, 11.0, 7.0, 15.0, 4.0, 2.0, 120.0, 153.0, 16.0, 19.0, 187.0, 184.0, 112.0, 125.0, 207.0, 197.0, 0.0, 9.0, 16.0, 61.0, 61.0, 9.0, 214.0, 207.0, 1.0, 1.0, 0.0, 2.0, 191.0, 196.0, 181.0, 168.0, 37.0, 163.0, 16.0, 20.0, 80.0, 154.0, 0.0, 13.0, 109.0, 100.0, 169.0, 160.0, 179.0, 177.0, 0.0, 82.0, 80.0, 5.0, 1.0, 15.0, 5.0, 157.0, 142.0, 142.0, 23.0, 187.0, 182.0, 15.0, 154.0, 179.0, 183.0, 174.0, 44.0, 80.0, 8.0, 35.0, 62.0, 81.0, 193.0, 18.0, 78.0, 3.0, 129.0, 10.0, 2.0, 2.0, 9.0, 179.0, 7.0, 2.0, 189.0, 187.0, 11.0, 43.0, 69.0, 193.0, 106.0, 129.0, 187.0, 124.0, 12.0, 152.0, 198.0, 200.0, 184.0, 196.0, 126.0, 129.0, 23.0, 8.0, 195.0, 195.0, 6.0, 15.0, 37.0, 11.0, 154.0, 142.0, 171.0, 189.0, 179.0, 185.0, 119.0, 181.0, 5.0, 17.0, 0.0, 4.0, 2.0, 6.0, 184.0, 6.0, 6.0, 3.0, 187.0, 186.0, 0.0, 8.0, 67.0, 73.0, 14.0, 19.0, 183.0, 185.0, 169.0, 41.0, 34.0, 30.0, 9.0, 98.0, 27.0, 164.0, 112.0, 5.0, 185.0, 132.0, 15.0, 4.0, 7.0, 8.0, 21.0, 10.0, 119.0, 147.0, 8.0, 200.0, 0.0, 13.0, 3.0, 195.0, 1.0, 17.0, 11.0, 14.0, 199.0, 199.0, 167.0, 182.0, 7.0, 3.0, 3.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5584347943004748, "mean_inference_ms": 1.4426500605125656, "mean_action_processing_ms": 0.23941311957104847, "mean_env_wait_ms": 0.18509204471135032, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003275632858276367, "StateBufferConnector_ms": 0.0033168792724609375, "ViewRequirementAgentConnector_ms": 0.08549320697784424}, "num_episodes": 23, "episode_return_max": 206.99999999999932, "episode_return_min": -419.4999999999999, "episode_return_mean": -84.74100000000007, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 426.73757688719127, "num_env_steps_trained_throughput_per_sec": 426.73757688719127, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 9174.991, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9174.954, "sample_time_ms": 1006.688, "learn_time_ms": 8156.129, "learn_throughput": 490.429, "synch_weights_time_ms": 11.334}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-33-36", "timestamp": 1723646016, "time_this_iter_s": 9.37761402130127, "time_total_s": 536.4832472801208, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 536.4832472801208, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 28.36923076923077, "ram_util_percent": 76.78461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7458422289638924, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.1071146367718936, "policy_loss": -0.010217345504474545, "vf_loss": 3.1149444030706213, "vf_explained_var": 0.3202089442147149, "kl": 0.007958629738089374, "entropy": 1.3102843441660441, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6002173048793953, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.037209532689796, "policy_loss": -0.010655953026519565, "vf_loss": 3.046563038813374, "vf_explained_var": 0.11936454249437524, "kl": 0.00651229992112556, "entropy": 1.1976803375930383, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 206.99999999999932, "episode_reward_min": -419.4999999999999, "episode_reward_mean": -63.40300000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -417.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.0, "predator_policy": 214.0}, "policy_reward_mean": {"prey_policy": -113.36149999999999, "predator_policy": 81.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.0, -47.49999999999968, -403.19999999999993, 30.10000000000015, -44.699999999999875, -27.09999999999995, -262.70000000000005, 40.500000000000306, 49.50000000000046, -345.79999999999995, -419.4999999999999, -180.00000000000097, 39.40000000000029, -68.3000000000003, 25.70000000000007, -189.90000000000015, 43.800000000000026, -8.400000000000034, -50.19999999999996, -49.899999999999636, 22.40000000000005, -170.60000000000093, 13.500000000000124, -191.0000000000008, -174.0000000000008, -13.100000000000009, -20.89999999999997, -37.59999999999957, 92.59999999999913, -16.49999999999978, -192.10000000000085, -67.10000000000073, -112.90000000000003, 35.600000000000236, -166.80000000000078, 37.90000000000027, -302.20000000000005, 102.99999999999997, -130.6000000000007, -11.500000000000076, -86.4000000000008, -136.20000000000044, -402.0, -386.39999999999975, -24.19999999999974, 157.9999999999995, -252.5, 27.4000000000001, -6.499999999999702, 2.1000000000000165, 120.99999999999973, -270.1, -92.60000000000072, 5.300000000000177, 35.600000000000236, 35.40000000000023, -154.6000000000006, 36.40000000000025, -263.1999999999999, 31.20000000000017, 26.70000000000014, 33.1000000000002, 65.69999999999992, -191.00000000000108, 26.3000000000001, -20.59999999999983, -214.20000000000059, -88.6999999999999, 8.099999999999964, 167.59999999999923, 28.300000000000114, 22.700000000000028, -48.89999999999967, -188.80000000000072, 25.70000000000007, -177.80000000000072, 22.30000000000001, 27.800000000000136, -397.79999999999995, -12.09999999999981, 35.30000000000023, 206.99999999999932, 59.600000000000506, 52.000000000000504, 48.700000000000365, -12.999999999999558, -22.999999999999517, 7.300000000000148, -388.1, 9.600000000000112, 124.09999999999933, 43.00000000000034, 38.90000000000028, -402.6, -29.50000000000002, -332.3, -7.9999999999996465, -139.3000000000004, 21.09999999999999, 35.90000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -400.0, -13.599999999999826, -270.9000000000002, -417.7, -389.5, 1.0999999999999794, 20.000000000000014, -124.89999999999986, 3.1999999999999615, -3.099999999999958, -94.00000000000011, -376.9, -306.8, 20.600000000000026, 17.899999999999988, 27.50000000000014, 20.000000000000014, -332.79999999999995, -400.0, -381.0999999999999, -387.3999999999999, -57.70000000000048, -322.29999999999984, 25.4000000000001, -21.999999999999744, 20.000000000000014, -322.30000000000007, -0.9999999999999992, 13.699999999999964, -208.9000000000004, -190.00000000000009, 91.69999999999995, -376.9, 25.100000000000094, -389.49999999999994, -135.4000000000001, 3.1999999999999615, -148.00000000000034, 13.099999999999966, -7.299999999999951, 13.699999999999964, -89.20000000000078, -243.40000000000018, 22.40000000000005, -292.90000000000003, -28.29999999999975, -372.69999999999976, -362.1999999999998, -8.799999999999871, 30.8000000000002, -376.90000000000003, -397.9, 20.000000000000014, -162.70000000000064, 1.0999999999999865, 90.49999999999957, -40.89999999999976, 7.399999999999965, -166.90000000000046, -17.79999999999974, -385.30000000000007, -35.799999999999756, -112.30000000000032, -0.9999999999999952, -250.9000000000004, 15.799999999999963, 15.799999999999963, 1.0999999999999865, -355.8999999999999, 20.000000000000014, 8.899999999999967, -397.9, -280.3, 108.79999999999993, -59.80000000000058, -393.70000000000005, 1.0999999999999865, 19.1, -265.6, -385.3, -12.099999999999817, -292.9, -7.299999999999891, -400.0, -400.0, -372.6999999999998, -393.69999999999993, 20.000000000000014, -299.2000000000003, 113.60000000000001, 13.399999999999965, -248.8, -393.69999999999993, -0.9999999999999846, 7.399999999999972, 5.299999999999972, -59.80000000000052, 34.70000000000025, -328.5999999999999, -389.49999999999994, 150.49999999999974, -355.9, -278.20000000000005, -376.9000000000001, -15.699999999999747, -0.9999999999999917, -15.699999999999747, 20.000000000000014, 11.599999999999964, 7.399999999999965, 20.000000000000014, 21.800000000000068, -366.3999999999999, 20.000000000000014, 7.399999999999965, -370.59999999999997, -265.5999999999999, 20.000000000000014, 3.1999999999999615, 11.599999999999964, -124.90000000000003, -19.899999999999743, 20.000000000000014, 87.19999999999959, -389.5, -66.10000000000076, -334.90000000000003, 20.000000000000014, -57.70000000000045, 14.599999999999966, -142.20000000000005, -118.60000000000001, -286.6000000000002, -225.7000000000004, 20.000000000000014, 21.800000000000065, -330.70000000000005, 136.09999999999985, 12.499999999999968, 8.299999999999965, 4.999999999999966, -28.29999999999975, 20.000000000000014, -309.69999999999993, -5.1999999999999265, 3.1999999999999615, -400.0, 20.000000000000014, -7.299999999999891, -389.5, 13.699999999999964, 20.000000000000014, -15.699999999999747, -3.099999999999958, 5.899999999999974, -400.0, -395.79999999999995, 20.000000000000014, -381.1, 5.299999999999965, 20.000000000000014, 176.0, 20.000000000000014, 38.60000000000025, 20.000000000000014, 38.900000000000254, 1.0999999999999865, 5.299999999999965, 10.399999999999977, -28.29999999999975, -33.699999999999754, -59.80000000000028, -26.199999999999747, -15.699999999999747, -0.9999999999999846, -381.1, -400.0, -7.299999999999891, -3.099999999999958, 28.100000000000147, 41.00000000000006, 20.000000000000014, 13.999999999999966, 22.100000000000044, -2.1999999999999855, -397.9, -393.7, 7.399999999999965, -334.9, -335.8, -389.5, -34.59999999999977, -6.3999999999999115, 9.499999999999964, -311.79999999999995, 12.499999999999964, -9.399999999999855, -3.099999999999958, 20.000000000000014], "policy_predator_policy_reward": [187.0, 184.0, 112.0, 125.0, 207.0, 197.0, 0.0, 9.0, 16.0, 61.0, 61.0, 9.0, 214.0, 207.0, 1.0, 1.0, 0.0, 2.0, 191.0, 196.0, 181.0, 168.0, 37.0, 163.0, 16.0, 20.0, 80.0, 154.0, 0.0, 13.0, 109.0, 100.0, 169.0, 160.0, 179.0, 177.0, 0.0, 82.0, 80.0, 5.0, 1.0, 15.0, 5.0, 157.0, 142.0, 142.0, 23.0, 187.0, 182.0, 15.0, 154.0, 179.0, 183.0, 174.0, 44.0, 80.0, 8.0, 35.0, 62.0, 81.0, 193.0, 18.0, 78.0, 3.0, 129.0, 10.0, 2.0, 2.0, 9.0, 179.0, 7.0, 2.0, 189.0, 187.0, 11.0, 43.0, 69.0, 193.0, 106.0, 129.0, 187.0, 124.0, 12.0, 152.0, 198.0, 200.0, 184.0, 196.0, 126.0, 129.0, 23.0, 8.0, 195.0, 195.0, 6.0, 15.0, 37.0, 11.0, 154.0, 142.0, 171.0, 189.0, 179.0, 185.0, 119.0, 181.0, 5.0, 17.0, 0.0, 4.0, 2.0, 6.0, 184.0, 6.0, 6.0, 3.0, 187.0, 186.0, 0.0, 8.0, 67.0, 73.0, 14.0, 19.0, 183.0, 185.0, 169.0, 41.0, 34.0, 30.0, 9.0, 98.0, 27.0, 164.0, 112.0, 5.0, 185.0, 132.0, 15.0, 4.0, 7.0, 8.0, 21.0, 10.0, 119.0, 147.0, 8.0, 200.0, 0.0, 13.0, 3.0, 195.0, 1.0, 17.0, 11.0, 14.0, 199.0, 199.0, 167.0, 182.0, 7.0, 3.0, 3.0, 8.0, 1.0, 0.0, 9.0, 3.0, 27.0, 6.0, 13.0, 36.0, 38.0, 25.0, 17.0, 7.0, 199.0, 194.0, 9.0, 11.0, 37.0, 18.0, 4.0, 5.0, 14.0, 5.0, 196.0, 193.0, 146.0, 152.0, 197.0, 196.0, 30.0, 3.0, 158.0, 5.0, 4.0, 14.0, 8.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5574487545581922, "mean_inference_ms": 1.4398993959455493, "mean_action_processing_ms": 0.23892962638445653, "mean_env_wait_ms": 0.18465803266797323, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0032857656478881836, "StateBufferConnector_ms": 0.0033416748046875, "ViewRequirementAgentConnector_ms": 0.08591055870056152}, "num_episodes": 18, "episode_return_max": 206.99999999999932, "episode_return_min": -419.4999999999999, "episode_return_mean": -63.40300000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 433.7025086744555, "num_env_steps_trained_throughput_per_sec": 433.7025086744555, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 9169.173, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9169.137, "sample_time_ms": 1002.742, "learn_time_ms": 8154.326, "learn_throughput": 490.537, "synch_weights_time_ms": 11.281}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-33-46", "timestamp": 1723646026, "time_this_iter_s": 9.226511001586914, "time_total_s": 545.7097582817078, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b098c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 545.7097582817078, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 29.36923076923077, "ram_util_percent": 77.16923076923078}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8903680568965024, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.6223998351071875, "policy_loss": -0.013909588024148314, "vf_loss": 3.633554184499872, "vf_explained_var": 0.27173285594692936, "kl": 0.00918412795738796, "entropy": 1.2993927761991189, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2540438635008675, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.309242803709848, "policy_loss": -0.012183962444769878, "vf_loss": 3.319027950397875, "vf_explained_var": 0.1523484600284112, "kl": 0.01199406984174164, "entropy": 1.1740401742319582, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 206.99999999999932, "episode_reward_min": -402.6, "episode_reward_mean": -43.26400000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 176.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -93.33200000000001, "predator_policy": 71.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.19999999999996, -49.899999999999636, 22.40000000000005, -170.60000000000093, 13.500000000000124, -191.0000000000008, -174.0000000000008, -13.100000000000009, -20.89999999999997, -37.59999999999957, 92.59999999999913, -16.49999999999978, -192.10000000000085, -67.10000000000073, -112.90000000000003, 35.600000000000236, -166.80000000000078, 37.90000000000027, -302.20000000000005, 102.99999999999997, -130.6000000000007, -11.500000000000076, -86.4000000000008, -136.20000000000044, -402.0, -386.39999999999975, -24.19999999999974, 157.9999999999995, -252.5, 27.4000000000001, -6.499999999999702, 2.1000000000000165, 120.99999999999973, -270.1, -92.60000000000072, 5.300000000000177, 35.600000000000236, 35.40000000000023, -154.6000000000006, 36.40000000000025, -263.1999999999999, 31.20000000000017, 26.70000000000014, 33.1000000000002, 65.69999999999992, -191.00000000000108, 26.3000000000001, -20.59999999999983, -214.20000000000059, -88.6999999999999, 8.099999999999964, 167.59999999999923, 28.300000000000114, 22.700000000000028, -48.89999999999967, -188.80000000000072, 25.70000000000007, -177.80000000000072, 22.30000000000001, 27.800000000000136, -397.79999999999995, -12.09999999999981, 35.30000000000023, 206.99999999999932, 59.600000000000506, 52.000000000000504, 48.700000000000365, -12.999999999999558, -22.999999999999517, 7.300000000000148, -388.1, 9.600000000000112, 124.09999999999933, 43.00000000000034, 38.90000000000028, -402.6, -29.50000000000002, -332.3, -7.9999999999996465, -139.3000000000004, 21.09999999999999, 35.90000000000024, 37.40000000000026, 34.000000000000206, -39.19999999999956, 89.29999999999885, 174.99999999999946, 14.999999999999961, -11.999999999999938, 5.00000000000041, -54.79999999999981, -46.89999999999991, 131.99999999999898, -148.8000000000005, -0.9999999999998496, 8.40000000000008, 30.100000000000147, 2.6000000000000734, 31.80000000000018, -21.099999999999945], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-135.4000000000001, 3.1999999999999615, -148.00000000000034, 13.099999999999966, -7.299999999999951, 13.699999999999964, -89.20000000000078, -243.40000000000018, 22.40000000000005, -292.90000000000003, -28.29999999999975, -372.69999999999976, -362.1999999999998, -8.799999999999871, 30.8000000000002, -376.90000000000003, -397.9, 20.000000000000014, -162.70000000000064, 1.0999999999999865, 90.49999999999957, -40.89999999999976, 7.399999999999965, -166.90000000000046, -17.79999999999974, -385.30000000000007, -35.799999999999756, -112.30000000000032, -0.9999999999999952, -250.9000000000004, 15.799999999999963, 15.799999999999963, 1.0999999999999865, -355.8999999999999, 20.000000000000014, 8.899999999999967, -397.9, -280.3, 108.79999999999993, -59.80000000000058, -393.70000000000005, 1.0999999999999865, 19.1, -265.6, -385.3, -12.099999999999817, -292.9, -7.299999999999891, -400.0, -400.0, -372.6999999999998, -393.69999999999993, 20.000000000000014, -299.2000000000003, 113.60000000000001, 13.399999999999965, -248.8, -393.69999999999993, -0.9999999999999846, 7.399999999999972, 5.299999999999972, -59.80000000000052, 34.70000000000025, -328.5999999999999, -389.49999999999994, 150.49999999999974, -355.9, -278.20000000000005, -376.9000000000001, -15.699999999999747, -0.9999999999999917, -15.699999999999747, 20.000000000000014, 11.599999999999964, 7.399999999999965, 20.000000000000014, 21.800000000000068, -366.3999999999999, 20.000000000000014, 7.399999999999965, -370.59999999999997, -265.5999999999999, 20.000000000000014, 3.1999999999999615, 11.599999999999964, -124.90000000000003, -19.899999999999743, 20.000000000000014, 87.19999999999959, -389.5, -66.10000000000076, -334.90000000000003, 20.000000000000014, -57.70000000000045, 14.599999999999966, -142.20000000000005, -118.60000000000001, -286.6000000000002, -225.7000000000004, 20.000000000000014, 21.800000000000065, -330.70000000000005, 136.09999999999985, 12.499999999999968, 8.299999999999965, 4.999999999999966, -28.29999999999975, 20.000000000000014, -309.69999999999993, -5.1999999999999265, 3.1999999999999615, -400.0, 20.000000000000014, -7.299999999999891, -389.5, 13.699999999999964, 20.000000000000014, -15.699999999999747, -3.099999999999958, 5.899999999999974, -400.0, -395.79999999999995, 20.000000000000014, -381.1, 5.299999999999965, 20.000000000000014, 176.0, 20.000000000000014, 38.60000000000025, 20.000000000000014, 38.900000000000254, 1.0999999999999865, 5.299999999999965, 10.399999999999977, -28.29999999999975, -33.699999999999754, -59.80000000000028, -26.199999999999747, -15.699999999999747, -0.9999999999999846, -381.1, -400.0, -7.299999999999891, -3.099999999999958, 28.100000000000147, 41.00000000000006, 20.000000000000014, 13.999999999999966, 22.100000000000044, -2.1999999999999855, -397.9, -393.7, 7.399999999999965, -334.9, -335.8, -389.5, -34.59999999999977, -6.3999999999999115, 9.499999999999964, -311.79999999999995, 12.499999999999964, -9.399999999999855, -3.099999999999958, 20.000000000000014, 17.899999999999988, 9.499999999999964, -7.599999999999904, 23.600000000000076, -19.899999999999743, -91.30000000000052, 50.300000000000146, 20.000000000000014, 122.0, 20.000000000000014, -400.0, 20.000000000000014, 27.800000000000146, -395.8, -72.4, 13.399999999999972, 50.00000000000021, -227.80000000000038, 15.799999999999963, -141.70000000000002, 20.000000000000014, 85.9999999999996, -11.499999999999819, -322.29999999999995, -40.8999999999998, -3.099999999999958, -53.50000000000019, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -135.4000000000007, -5.1999999999999265, 20.000000000000014, 63.800000000000196, -187.90000000000055], "policy_predator_policy_reward": [0.0, 82.0, 80.0, 5.0, 1.0, 15.0, 5.0, 157.0, 142.0, 142.0, 23.0, 187.0, 182.0, 15.0, 154.0, 179.0, 183.0, 174.0, 44.0, 80.0, 8.0, 35.0, 62.0, 81.0, 193.0, 18.0, 78.0, 3.0, 129.0, 10.0, 2.0, 2.0, 9.0, 179.0, 7.0, 2.0, 189.0, 187.0, 11.0, 43.0, 69.0, 193.0, 106.0, 129.0, 187.0, 124.0, 12.0, 152.0, 198.0, 200.0, 184.0, 196.0, 126.0, 129.0, 23.0, 8.0, 195.0, 195.0, 6.0, 15.0, 37.0, 11.0, 154.0, 142.0, 171.0, 189.0, 179.0, 185.0, 119.0, 181.0, 5.0, 17.0, 0.0, 4.0, 2.0, 6.0, 184.0, 6.0, 6.0, 3.0, 187.0, 186.0, 0.0, 8.0, 67.0, 73.0, 14.0, 19.0, 183.0, 185.0, 169.0, 41.0, 34.0, 30.0, 9.0, 98.0, 27.0, 164.0, 112.0, 5.0, 185.0, 132.0, 15.0, 4.0, 7.0, 8.0, 21.0, 10.0, 119.0, 147.0, 8.0, 200.0, 0.0, 13.0, 3.0, 195.0, 1.0, 17.0, 11.0, 14.0, 199.0, 199.0, 167.0, 182.0, 7.0, 3.0, 3.0, 8.0, 1.0, 0.0, 9.0, 3.0, 27.0, 6.0, 13.0, 36.0, 38.0, 25.0, 17.0, 7.0, 199.0, 194.0, 9.0, 11.0, 37.0, 18.0, 4.0, 5.0, 14.0, 5.0, 196.0, 193.0, 146.0, 152.0, 197.0, 196.0, 30.0, 3.0, 158.0, 5.0, 4.0, 14.0, 8.0, 11.0, 5.0, 5.0, 17.0, 1.0, 17.0, 55.0, 19.0, 0.0, 26.0, 7.0, 197.0, 198.0, 169.0, 187.0, 51.0, 13.0, 5.0, 118.0, 77.0, 2.0, 17.0, 9.0, 170.0, 15.0, 7.0, 36.0, 33.0, 11.0, 9.0, 0.0, 68.0, 50.0, 5.0, 12.0, 4.0, 99.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5565267950615288, "mean_inference_ms": 1.437436248670413, "mean_action_processing_ms": 0.23849330906113103, "mean_env_wait_ms": 0.184244186655442, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0032624006271362305, "StateBufferConnector_ms": 0.002772212028503418, "ViewRequirementAgentConnector_ms": 0.08524513244628906}, "num_episodes": 18, "episode_return_max": 206.99999999999932, "episode_return_min": -402.6, "episode_return_mean": -43.26400000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 432.31595532492014, "num_env_steps_trained_throughput_per_sec": 432.31595532492014, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 9184.998, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9184.962, "sample_time_ms": 1005.17, "learn_time_ms": 8167.619, "learn_throughput": 489.739, "synch_weights_time_ms": 11.415}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-33-55", "timestamp": 1723646035, "time_this_iter_s": 9.25609278678894, "time_total_s": 554.9658510684967, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 554.9658510684967, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 30.500000000000007, "ram_util_percent": 77.28461538461538}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7728191593021312, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.5681090609737174, "policy_loss": -0.012506835797072324, "vf_loss": 3.577875239003903, "vf_explained_var": 0.263308575702092, "kl": 0.00913551861970737, "entropy": 1.2746840227217902, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9685061723151533, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 4.298596295477852, "policy_loss": -0.009868880270157384, "vf_loss": 4.306905346068125, "vf_explained_var": 0.09739155668430227, "kl": 0.007799120128726838, "entropy": 1.1308787149096293, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 259.49999999999955, "episode_reward_min": -402.6, "episode_reward_mean": -27.48700000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -81.91850000000001, "predator_policy": 68.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-86.4000000000008, -136.20000000000044, -402.0, -386.39999999999975, -24.19999999999974, 157.9999999999995, -252.5, 27.4000000000001, -6.499999999999702, 2.1000000000000165, 120.99999999999973, -270.1, -92.60000000000072, 5.300000000000177, 35.600000000000236, 35.40000000000023, -154.6000000000006, 36.40000000000025, -263.1999999999999, 31.20000000000017, 26.70000000000014, 33.1000000000002, 65.69999999999992, -191.00000000000108, 26.3000000000001, -20.59999999999983, -214.20000000000059, -88.6999999999999, 8.099999999999964, 167.59999999999923, 28.300000000000114, 22.700000000000028, -48.89999999999967, -188.80000000000072, 25.70000000000007, -177.80000000000072, 22.30000000000001, 27.800000000000136, -397.79999999999995, -12.09999999999981, 35.30000000000023, 206.99999999999932, 59.600000000000506, 52.000000000000504, 48.700000000000365, -12.999999999999558, -22.999999999999517, 7.300000000000148, -388.1, 9.600000000000112, 124.09999999999933, 43.00000000000034, 38.90000000000028, -402.6, -29.50000000000002, -332.3, -7.9999999999996465, -139.3000000000004, 21.09999999999999, 35.90000000000024, 37.40000000000026, 34.000000000000206, -39.19999999999956, 89.29999999999885, 174.99999999999946, 14.999999999999961, -11.999999999999938, 5.00000000000041, -54.79999999999981, -46.89999999999991, 131.99999999999898, -148.8000000000005, -0.9999999999998496, 8.40000000000008, 30.100000000000147, 2.6000000000000734, 31.80000000000018, -21.099999999999945, 93.89999999999895, 24.600000000000048, -63.100000000000364, -21.6999999999995, 14.399999999999945, 259.49999999999955, -166.8000000000006, 13.999999999999973, -7.899999999999999, -55.89999999999982, 8.100000000000081, -118.50000000000031, 209.2999999999993, 39.60000000000029, -159.40000000000072, 13.000000000000027, 30.000000000000146, 34.30000000000022, -181.6000000000011, 26.800000000000118, 167.89999999999966, 15.199999999999916], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-385.3, -12.099999999999817, -292.9, -7.299999999999891, -400.0, -400.0, -372.6999999999998, -393.69999999999993, 20.000000000000014, -299.2000000000003, 113.60000000000001, 13.399999999999965, -248.8, -393.69999999999993, -0.9999999999999846, 7.399999999999972, 5.299999999999972, -59.80000000000052, 34.70000000000025, -328.5999999999999, -389.49999999999994, 150.49999999999974, -355.9, -278.20000000000005, -376.9000000000001, -15.699999999999747, -0.9999999999999917, -15.699999999999747, 20.000000000000014, 11.599999999999964, 7.399999999999965, 20.000000000000014, 21.800000000000068, -366.3999999999999, 20.000000000000014, 7.399999999999965, -370.59999999999997, -265.5999999999999, 20.000000000000014, 3.1999999999999615, 11.599999999999964, -124.90000000000003, -19.899999999999743, 20.000000000000014, 87.19999999999959, -389.5, -66.10000000000076, -334.90000000000003, 20.000000000000014, -57.70000000000045, 14.599999999999966, -142.20000000000005, -118.60000000000001, -286.6000000000002, -225.7000000000004, 20.000000000000014, 21.800000000000065, -330.70000000000005, 136.09999999999985, 12.499999999999968, 8.299999999999965, 4.999999999999966, -28.29999999999975, 20.000000000000014, -309.69999999999993, -5.1999999999999265, 3.1999999999999615, -400.0, 20.000000000000014, -7.299999999999891, -389.5, 13.699999999999964, 20.000000000000014, -15.699999999999747, -3.099999999999958, 5.899999999999974, -400.0, -395.79999999999995, 20.000000000000014, -381.1, 5.299999999999965, 20.000000000000014, 176.0, 20.000000000000014, 38.60000000000025, 20.000000000000014, 38.900000000000254, 1.0999999999999865, 5.299999999999965, 10.399999999999977, -28.29999999999975, -33.699999999999754, -59.80000000000028, -26.199999999999747, -15.699999999999747, -0.9999999999999846, -381.1, -400.0, -7.299999999999891, -3.099999999999958, 28.100000000000147, 41.00000000000006, 20.000000000000014, 13.999999999999966, 22.100000000000044, -2.1999999999999855, -397.9, -393.7, 7.399999999999965, -334.9, -335.8, -389.5, -34.59999999999977, -6.3999999999999115, 9.499999999999964, -311.79999999999995, 12.499999999999964, -9.399999999999855, -3.099999999999958, 20.000000000000014, 17.899999999999988, 9.499999999999964, -7.599999999999904, 23.600000000000076, -19.899999999999743, -91.30000000000052, 50.300000000000146, 20.000000000000014, 122.0, 20.000000000000014, -400.0, 20.000000000000014, 27.800000000000146, -395.8, -72.4, 13.399999999999972, 50.00000000000021, -227.80000000000038, 15.799999999999963, -141.70000000000002, 20.000000000000014, 85.9999999999996, -11.499999999999819, -322.29999999999995, -40.8999999999998, -3.099999999999958, -53.50000000000019, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -135.4000000000007, -5.1999999999999265, 20.000000000000014, 63.800000000000196, -187.90000000000055, 34.10000000000013, 18.799999999999997, 3.1999999999999615, 7.399999999999965, -18.699999999999754, -366.4, -15.699999999999747, -42.99999999999976, -26.499999999999844, -3.099999999999958, 98.0, 105.49999999999947, -353.80000000000007, -1.0000000000000346, 20.000000000000014, -357.99999999999994, 20.000000000000014, -397.9, -376.9, 20.000000000000014, 3.1999999999999615, -24.099999999999746, -141.70000000000027, -143.80000000000007, 164.60000000000002, 31.700000000000216, 20.000000000000014, -3.399999999999958, -21.999999999999744, -348.4000000000001, 29.000000000000163, -400.0, 20.000000000000014, -0.9999999999999846, 7.399999999999965, 20.90000000000003, -57.70000000000048, -292.9, 7.099999999999975, -7.299999999999891, -112.29999999999983, 189.2, -19.899999999999785, 1.0999999999999794], "policy_predator_policy_reward": [187.0, 124.0, 12.0, 152.0, 198.0, 200.0, 184.0, 196.0, 126.0, 129.0, 23.0, 8.0, 195.0, 195.0, 6.0, 15.0, 37.0, 11.0, 154.0, 142.0, 171.0, 189.0, 179.0, 185.0, 119.0, 181.0, 5.0, 17.0, 0.0, 4.0, 2.0, 6.0, 184.0, 6.0, 6.0, 3.0, 187.0, 186.0, 0.0, 8.0, 67.0, 73.0, 14.0, 19.0, 183.0, 185.0, 169.0, 41.0, 34.0, 30.0, 9.0, 98.0, 27.0, 164.0, 112.0, 5.0, 185.0, 132.0, 15.0, 4.0, 7.0, 8.0, 21.0, 10.0, 119.0, 147.0, 8.0, 200.0, 0.0, 13.0, 3.0, 195.0, 1.0, 17.0, 11.0, 14.0, 199.0, 199.0, 167.0, 182.0, 7.0, 3.0, 3.0, 8.0, 1.0, 0.0, 9.0, 3.0, 27.0, 6.0, 13.0, 36.0, 38.0, 25.0, 17.0, 7.0, 199.0, 194.0, 9.0, 11.0, 37.0, 18.0, 4.0, 5.0, 14.0, 5.0, 196.0, 193.0, 146.0, 152.0, 197.0, 196.0, 30.0, 3.0, 158.0, 5.0, 4.0, 14.0, 8.0, 11.0, 5.0, 5.0, 17.0, 1.0, 17.0, 55.0, 19.0, 0.0, 26.0, 7.0, 197.0, 198.0, 169.0, 187.0, 51.0, 13.0, 5.0, 118.0, 77.0, 2.0, 17.0, 9.0, 170.0, 15.0, 7.0, 36.0, 33.0, 11.0, 9.0, 0.0, 68.0, 50.0, 5.0, 12.0, 4.0, 99.0, 27.0, 14.0, 6.0, 8.0, 161.0, 161.0, 33.0, 4.0, 19.0, 25.0, 32.0, 24.0, 178.0, 10.0, 174.0, 178.0, 179.0, 191.0, 158.0, 143.0, 9.0, 20.0, 91.0, 76.0, 4.0, 9.0, 11.0, 12.0, 20.0, 191.0, 190.0, 194.0, 10.0, 1.0, 0.0, 6.0, 4.0, 165.0, 20.0, 7.0, 59.0, 32.0, 26.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5553124249444651, "mean_inference_ms": 1.435460170315942, "mean_action_processing_ms": 0.23759521289646288, "mean_env_wait_ms": 0.18361617506257574, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0032764673233032227, "StateBufferConnector_ms": 0.0027382373809814453, "ViewRequirementAgentConnector_ms": 0.08440637588500977}, "num_episodes": 22, "episode_return_max": 259.49999999999955, "episode_return_min": -402.6, "episode_return_mean": -27.48700000000007, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 441.41579801460426, "num_env_steps_trained_throughput_per_sec": 441.41579801460426, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 9171.296, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9171.26, "sample_time_ms": 1004.851, "learn_time_ms": 8154.199, "learn_throughput": 490.545, "synch_weights_time_ms": 11.468}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-34-04", "timestamp": 1723646044, "time_this_iter_s": 9.065295934677124, "time_total_s": 564.0311470031738, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b098ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 564.0311470031738, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 25.830769230769235, "ram_util_percent": 77.24615384615385}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0439896841213185, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.6226459070488257, "policy_loss": -0.010282446759895831, "vf_loss": 2.631213670432883, "vf_explained_var": 0.25871177328326717, "kl": 0.005715620670420591, "entropy": 1.28686871383556, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5401352627882883, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.622049141750134, "policy_loss": -0.009979818103016999, "vf_loss": 2.63049857862412, "vf_explained_var": 0.05364167955186632, "kl": 0.007651941169919451, "entropy": 1.169989823853528, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 259.49999999999955, "episode_reward_min": -402.6, "episode_reward_mean": -10.331000000000047, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -65.64049999999999, "predator_policy": 60.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-263.1999999999999, 31.20000000000017, 26.70000000000014, 33.1000000000002, 65.69999999999992, -191.00000000000108, 26.3000000000001, -20.59999999999983, -214.20000000000059, -88.6999999999999, 8.099999999999964, 167.59999999999923, 28.300000000000114, 22.700000000000028, -48.89999999999967, -188.80000000000072, 25.70000000000007, -177.80000000000072, 22.30000000000001, 27.800000000000136, -397.79999999999995, -12.09999999999981, 35.30000000000023, 206.99999999999932, 59.600000000000506, 52.000000000000504, 48.700000000000365, -12.999999999999558, -22.999999999999517, 7.300000000000148, -388.1, 9.600000000000112, 124.09999999999933, 43.00000000000034, 38.90000000000028, -402.6, -29.50000000000002, -332.3, -7.9999999999996465, -139.3000000000004, 21.09999999999999, 35.90000000000024, 37.40000000000026, 34.000000000000206, -39.19999999999956, 89.29999999999885, 174.99999999999946, 14.999999999999961, -11.999999999999938, 5.00000000000041, -54.79999999999981, -46.89999999999991, 131.99999999999898, -148.8000000000005, -0.9999999999998496, 8.40000000000008, 30.100000000000147, 2.6000000000000734, 31.80000000000018, -21.099999999999945, 93.89999999999895, 24.600000000000048, -63.100000000000364, -21.6999999999995, 14.399999999999945, 259.49999999999955, -166.8000000000006, 13.999999999999973, -7.899999999999999, -55.89999999999982, 8.100000000000081, -118.50000000000031, 209.2999999999993, 39.60000000000029, -159.40000000000072, 13.000000000000027, 30.000000000000146, 34.30000000000022, -181.6000000000011, 26.800000000000118, 167.89999999999966, 15.199999999999916, -77.10000000000085, 30.80000000000016, 104.40000000000002, 27.700000000000106, 2.6000000000002155, 28.700000000000134, 35.600000000000236, -23.29999999999972, -58.89999999999973, 53.60000000000033, 25.400000000000073, -186.60000000000073, 188.89999999999938, 46.30000000000041, 63.40000000000042, 15.600000000000005, 24.100000000000108, 24.100000000000065], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-370.59999999999997, -265.5999999999999, 20.000000000000014, 3.1999999999999615, 11.599999999999964, -124.90000000000003, -19.899999999999743, 20.000000000000014, 87.19999999999959, -389.5, -66.10000000000076, -334.90000000000003, 20.000000000000014, -57.70000000000045, 14.599999999999966, -142.20000000000005, -118.60000000000001, -286.6000000000002, -225.7000000000004, 20.000000000000014, 21.800000000000065, -330.70000000000005, 136.09999999999985, 12.499999999999968, 8.299999999999965, 4.999999999999966, -28.29999999999975, 20.000000000000014, -309.69999999999993, -5.1999999999999265, 3.1999999999999615, -400.0, 20.000000000000014, -7.299999999999891, -389.5, 13.699999999999964, 20.000000000000014, -15.699999999999747, -3.099999999999958, 5.899999999999974, -400.0, -395.79999999999995, 20.000000000000014, -381.1, 5.299999999999965, 20.000000000000014, 176.0, 20.000000000000014, 38.60000000000025, 20.000000000000014, 38.900000000000254, 1.0999999999999865, 5.299999999999965, 10.399999999999977, -28.29999999999975, -33.699999999999754, -59.80000000000028, -26.199999999999747, -15.699999999999747, -0.9999999999999846, -381.1, -400.0, -7.299999999999891, -3.099999999999958, 28.100000000000147, 41.00000000000006, 20.000000000000014, 13.999999999999966, 22.100000000000044, -2.1999999999999855, -397.9, -393.7, 7.399999999999965, -334.9, -335.8, -389.5, -34.59999999999977, -6.3999999999999115, 9.499999999999964, -311.79999999999995, 12.499999999999964, -9.399999999999855, -3.099999999999958, 20.000000000000014, 17.899999999999988, 9.499999999999964, -7.599999999999904, 23.600000000000076, -19.899999999999743, -91.30000000000052, 50.300000000000146, 20.000000000000014, 122.0, 20.000000000000014, -400.0, 20.000000000000014, 27.800000000000146, -395.8, -72.4, 13.399999999999972, 50.00000000000021, -227.80000000000038, 15.799999999999963, -141.70000000000002, 20.000000000000014, 85.9999999999996, -11.499999999999819, -322.29999999999995, -40.8999999999998, -3.099999999999958, -53.50000000000019, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -135.4000000000007, -5.1999999999999265, 20.000000000000014, 63.800000000000196, -187.90000000000055, 34.10000000000013, 18.799999999999997, 3.1999999999999615, 7.399999999999965, -18.699999999999754, -366.4, -15.699999999999747, -42.99999999999976, -26.499999999999844, -3.099999999999958, 98.0, 105.49999999999947, -353.80000000000007, -1.0000000000000346, 20.000000000000014, -357.99999999999994, 20.000000000000014, -397.9, -376.9, 20.000000000000014, 3.1999999999999615, -24.099999999999746, -141.70000000000027, -143.80000000000007, 164.60000000000002, 31.700000000000216, 20.000000000000014, -3.399999999999958, -21.999999999999744, -348.4000000000001, 29.000000000000163, -400.0, 20.000000000000014, -0.9999999999999846, 7.399999999999965, 20.90000000000003, -57.70000000000048, -292.9, 7.099999999999975, -7.299999999999891, -112.29999999999983, 189.2, -19.899999999999785, 1.0999999999999794, -236.20000000000036, 37.10000000000026, 0.7999999999999865, 20.000000000000014, -389.5, 119.9, 20.000000000000014, -7.299999999999894, -15.699999999999747, -15.699999999999747, -47.19999999999978, 29.90000000000018, 20.000000000000014, -9.399999999999855, -4.299999999999958, -358.0000000000001, -355.90000000000003, 20.000000000000014, 88.99999999999937, -93.40000000000066, 29.90000000000018, -32.49999999999975, -5.1999999999999265, -387.4, 17.899999999999988, 155.0, 17.899999999999984, 19.40000000000001, 5.299999999999965, 40.1000000000002, 1.0999999999999865, -2.4999999999999716, -400.0, 28.100000000000147, 27.20000000000013, -24.09999999999979], "policy_predator_policy_reward": [187.0, 186.0, 0.0, 8.0, 67.0, 73.0, 14.0, 19.0, 183.0, 185.0, 169.0, 41.0, 34.0, 30.0, 9.0, 98.0, 27.0, 164.0, 112.0, 5.0, 185.0, 132.0, 15.0, 4.0, 7.0, 8.0, 21.0, 10.0, 119.0, 147.0, 8.0, 200.0, 0.0, 13.0, 3.0, 195.0, 1.0, 17.0, 11.0, 14.0, 199.0, 199.0, 167.0, 182.0, 7.0, 3.0, 3.0, 8.0, 1.0, 0.0, 9.0, 3.0, 27.0, 6.0, 13.0, 36.0, 38.0, 25.0, 17.0, 7.0, 199.0, 194.0, 9.0, 11.0, 37.0, 18.0, 4.0, 5.0, 14.0, 5.0, 196.0, 193.0, 146.0, 152.0, 197.0, 196.0, 30.0, 3.0, 158.0, 5.0, 4.0, 14.0, 8.0, 11.0, 5.0, 5.0, 17.0, 1.0, 17.0, 55.0, 19.0, 0.0, 26.0, 7.0, 197.0, 198.0, 169.0, 187.0, 51.0, 13.0, 5.0, 118.0, 77.0, 2.0, 17.0, 9.0, 170.0, 15.0, 7.0, 36.0, 33.0, 11.0, 9.0, 0.0, 68.0, 50.0, 5.0, 12.0, 4.0, 99.0, 27.0, 14.0, 6.0, 8.0, 161.0, 161.0, 33.0, 4.0, 19.0, 25.0, 32.0, 24.0, 178.0, 10.0, 174.0, 178.0, 179.0, 191.0, 158.0, 143.0, 9.0, 20.0, 91.0, 76.0, 4.0, 9.0, 11.0, 12.0, 20.0, 191.0, 190.0, 194.0, 10.0, 1.0, 0.0, 6.0, 4.0, 165.0, 20.0, 7.0, 59.0, 32.0, 26.0, 8.0, 16.0, 106.0, 10.0, 0.0, 193.0, 181.0, 2.0, 13.0, 17.0, 17.0, 31.0, 15.0, 12.0, 13.0, 162.0, 177.0, 134.0, 143.0, 4.0, 54.0, 25.0, 3.0, 12.0, 194.0, 1.0, 15.0, 2.0, 7.0, 7.0, 11.0, 5.0, 12.0, 196.0, 200.0, 1.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5543552676132779, "mean_inference_ms": 1.4311039556549041, "mean_action_processing_ms": 0.23744311077924946, "mean_env_wait_ms": 0.18323774217554656, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0032988786697387695, "StateBufferConnector_ms": 0.0027350187301635742, "ViewRequirementAgentConnector_ms": 0.08307194709777832}, "num_episodes": 18, "episode_return_max": 259.49999999999955, "episode_return_min": -402.6, "episode_return_mean": -10.331000000000047, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 433.7798706547494, "num_env_steps_trained_throughput_per_sec": 433.7798706547494, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 9175.846, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9175.81, "sample_time_ms": 1007.694, "learn_time_ms": 8155.973, "learn_throughput": 490.438, "synch_weights_time_ms": 11.436}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-34-13", "timestamp": 1723646053, "time_this_iter_s": 9.225704908370972, "time_total_s": 573.2568519115448, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b098550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 573.2568519115448, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 29.43076923076923, "ram_util_percent": 76.86923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.95297550177448, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.3086216780874462, "policy_loss": -0.016248220148146468, "vf_loss": 3.3223209294061813, "vf_explained_var": 0.32558472326823645, "kl": 0.00849655466494051, "entropy": 1.208091342512262, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.965735146261397, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.2893389011817002, "policy_loss": -0.012287395861906508, "vf_loss": 3.299765509398526, "vf_explained_var": 0.08835284996915746, "kl": 0.009303933626864854, "entropy": 1.1318942842660127, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 259.49999999999955, "episode_reward_min": -402.6, "episode_reward_mean": 6.7859999999999445, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -50.621999999999986, "predator_policy": 54.015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [206.99999999999932, 59.600000000000506, 52.000000000000504, 48.700000000000365, -12.999999999999558, -22.999999999999517, 7.300000000000148, -388.1, 9.600000000000112, 124.09999999999933, 43.00000000000034, 38.90000000000028, -402.6, -29.50000000000002, -332.3, -7.9999999999996465, -139.3000000000004, 21.09999999999999, 35.90000000000024, 37.40000000000026, 34.000000000000206, -39.19999999999956, 89.29999999999885, 174.99999999999946, 14.999999999999961, -11.999999999999938, 5.00000000000041, -54.79999999999981, -46.89999999999991, 131.99999999999898, -148.8000000000005, -0.9999999999998496, 8.40000000000008, 30.100000000000147, 2.6000000000000734, 31.80000000000018, -21.099999999999945, 93.89999999999895, 24.600000000000048, -63.100000000000364, -21.6999999999995, 14.399999999999945, 259.49999999999955, -166.8000000000006, 13.999999999999973, -7.899999999999999, -55.89999999999982, 8.100000000000081, -118.50000000000031, 209.2999999999993, 39.60000000000029, -159.40000000000072, 13.000000000000027, 30.000000000000146, 34.30000000000022, -181.6000000000011, 26.800000000000118, 167.89999999999966, 15.199999999999916, -77.10000000000085, 30.80000000000016, 104.40000000000002, 27.700000000000106, 2.6000000000002155, 28.700000000000134, 35.600000000000236, -23.29999999999972, -58.89999999999973, 53.60000000000033, 25.400000000000073, -186.60000000000073, 188.89999999999938, 46.30000000000041, 63.40000000000042, 15.600000000000005, 24.100000000000108, 24.100000000000065, 37.80000000000027, 43.50000000000023, -140.40000000000043, 1.400000000000001, -94.20000000000155, 24.70000000000005, 196.9999999999993, 213.69999999999928, 46.80000000000042, 202.39999999999935, 37.80000000000027, -191.00000000000077, 45.800000000000395, 2.4000000000002224, 46.400000000000404, -11.599999999999765, -11.899999999999576, 33.1000000000002, -83.00000000000048, 69.49999999999943, 17.899999999999974, 31.900000000000176, 109.39999999999951], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.0, 20.000000000000014, 38.60000000000025, 20.000000000000014, 38.900000000000254, 1.0999999999999865, 5.299999999999965, 10.399999999999977, -28.29999999999975, -33.699999999999754, -59.80000000000028, -26.199999999999747, -15.699999999999747, -0.9999999999999846, -381.1, -400.0, -7.299999999999891, -3.099999999999958, 28.100000000000147, 41.00000000000006, 20.000000000000014, 13.999999999999966, 22.100000000000044, -2.1999999999999855, -397.9, -393.7, 7.399999999999965, -334.9, -335.8, -389.5, -34.59999999999977, -6.3999999999999115, 9.499999999999964, -311.79999999999995, 12.499999999999964, -9.399999999999855, -3.099999999999958, 20.000000000000014, 17.899999999999988, 9.499999999999964, -7.599999999999904, 23.600000000000076, -19.899999999999743, -91.30000000000052, 50.300000000000146, 20.000000000000014, 122.0, 20.000000000000014, -400.0, 20.000000000000014, 27.800000000000146, -395.8, -72.4, 13.399999999999972, 50.00000000000021, -227.80000000000038, 15.799999999999963, -141.70000000000002, 20.000000000000014, 85.9999999999996, -11.499999999999819, -322.29999999999995, -40.8999999999998, -3.099999999999958, -53.50000000000019, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -135.4000000000007, -5.1999999999999265, 20.000000000000014, 63.800000000000196, -187.90000000000055, 34.10000000000013, 18.799999999999997, 3.1999999999999615, 7.399999999999965, -18.699999999999754, -366.4, -15.699999999999747, -42.99999999999976, -26.499999999999844, -3.099999999999958, 98.0, 105.49999999999947, -353.80000000000007, -1.0000000000000346, 20.000000000000014, -357.99999999999994, 20.000000000000014, -397.9, -376.9, 20.000000000000014, 3.1999999999999615, -24.099999999999746, -141.70000000000027, -143.80000000000007, 164.60000000000002, 31.700000000000216, 20.000000000000014, -3.399999999999958, -21.999999999999744, -348.4000000000001, 29.000000000000163, -400.0, 20.000000000000014, -0.9999999999999846, 7.399999999999965, 20.90000000000003, -57.70000000000048, -292.9, 7.099999999999975, -7.299999999999891, -112.29999999999983, 189.2, -19.899999999999785, 1.0999999999999794, -236.20000000000036, 37.10000000000026, 0.7999999999999865, 20.000000000000014, -389.5, 119.9, 20.000000000000014, -7.299999999999894, -15.699999999999747, -15.699999999999747, -47.19999999999978, 29.90000000000018, 20.000000000000014, -9.399999999999855, -4.299999999999958, -358.0000000000001, -355.90000000000003, 20.000000000000014, 88.99999999999937, -93.40000000000066, 29.90000000000018, -32.49999999999975, -5.1999999999999265, -387.4, 17.899999999999988, 155.0, 17.899999999999984, 19.40000000000001, 5.299999999999965, 40.1000000000002, 1.0999999999999865, -2.4999999999999716, -400.0, 28.100000000000147, 27.20000000000013, -24.09999999999979, 20.000000000000014, -5.1999999999999265, -400.0, 51.50000000000023, -286.6, -17.79999999999974, -29.19999999999984, -9.399999999999855, -148.00000000000068, -68.20000000000088, 3.1999999999999615, 9.499999999999964, -13.599999999999783, 185.59999999999997, 181.1, 32.60000000000023, 4.699999999999971, 28.100000000000154, 193.7, -7.299999999999891, -28.29999999999975, 28.100000000000147, -397.9, -3.0999999999999615, 17.899999999999988, 20.900000000000027, -13.599999999999783, -0.9999999999999881, 23.600000000000065, 18.799999999999997, -250.89999999999998, -15.699999999999747, -64.00000000000091, 4.099999999999966, 1.0999999999999865, 20.000000000000014, -357.2, 3.1999999999999615, 95.29999999999944, -395.8, 17.899999999999988, -21.999999999999744, 12.499999999999964, 10.399999999999965, -120.70000000000076, 115.09999999999982], "policy_predator_policy_reward": [3.0, 8.0, 1.0, 0.0, 9.0, 3.0, 27.0, 6.0, 13.0, 36.0, 38.0, 25.0, 17.0, 7.0, 199.0, 194.0, 9.0, 11.0, 37.0, 18.0, 4.0, 5.0, 14.0, 5.0, 196.0, 193.0, 146.0, 152.0, 197.0, 196.0, 30.0, 3.0, 158.0, 5.0, 4.0, 14.0, 8.0, 11.0, 5.0, 5.0, 17.0, 1.0, 17.0, 55.0, 19.0, 0.0, 26.0, 7.0, 197.0, 198.0, 169.0, 187.0, 51.0, 13.0, 5.0, 118.0, 77.0, 2.0, 17.0, 9.0, 170.0, 15.0, 7.0, 36.0, 33.0, 11.0, 9.0, 0.0, 68.0, 50.0, 5.0, 12.0, 4.0, 99.0, 27.0, 14.0, 6.0, 8.0, 161.0, 161.0, 33.0, 4.0, 19.0, 25.0, 32.0, 24.0, 178.0, 10.0, 174.0, 178.0, 179.0, 191.0, 158.0, 143.0, 9.0, 20.0, 91.0, 76.0, 4.0, 9.0, 11.0, 12.0, 20.0, 191.0, 190.0, 194.0, 10.0, 1.0, 0.0, 6.0, 4.0, 165.0, 20.0, 7.0, 59.0, 32.0, 26.0, 8.0, 16.0, 106.0, 10.0, 0.0, 193.0, 181.0, 2.0, 13.0, 17.0, 17.0, 31.0, 15.0, 12.0, 13.0, 162.0, 177.0, 134.0, 143.0, 4.0, 54.0, 25.0, 3.0, 12.0, 194.0, 1.0, 15.0, 2.0, 7.0, 7.0, 11.0, 5.0, 12.0, 196.0, 200.0, 1.0, 20.0, 12.0, 11.0, 197.0, 195.0, 18.0, 146.0, 1.0, 39.0, 80.0, 42.0, 4.0, 8.0, 9.0, 16.0, 0.0, 0.0, 12.0, 2.0, 3.0, 13.0, 15.0, 23.0, 11.0, 199.0, 6.0, 1.0, 0.0, 17.0, 4.0, 0.0, 128.0, 127.0, 13.0, 35.0, 3.0, 9.0, 90.0, 181.0, 175.0, 195.0, 20.0, 2.0, 4.0, 5.0, 52.0, 63.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5530828562656853, "mean_inference_ms": 1.427402056398843, "mean_action_processing_ms": 0.23678232822169143, "mean_env_wait_ms": 0.18264701343158415, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033060312271118164, "StateBufferConnector_ms": 0.0027370452880859375, "ViewRequirementAgentConnector_ms": 0.08216345310211182}, "num_episodes": 23, "episode_return_max": 259.49999999999955, "episode_return_min": -402.6, "episode_return_mean": 6.7859999999999445, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 437.00969397811417, "num_env_steps_trained_throughput_per_sec": 437.00969397811417, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 9183.275, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9183.24, "sample_time_ms": 1013.225, "learn_time_ms": 8157.755, "learn_throughput": 490.331, "synch_weights_time_ms": 11.543}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-34-22", "timestamp": 1723646062, "time_this_iter_s": 9.156116962432861, "time_total_s": 582.4129688739777, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0fbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 582.4129688739777, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 26.969230769230766, "ram_util_percent": 76.74615384615386}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8324248012096163, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.9724524620348816, "policy_loss": -0.015912785660475492, "vf_loss": 2.985433942552597, "vf_explained_var": 0.21504199113795366, "kl": 0.00977101824657637, "entropy": 1.2749645435620869, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.507068854570389, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 3.5370395709597875, "policy_loss": -0.009974781134185534, "vf_loss": 3.5454426414752134, "vf_explained_var": 0.10956030037037279, "kl": 0.007858547292364956, "entropy": 1.0795673195016446, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 259.49999999999955, "episode_reward_min": -192.10000000000076, "episode_reward_mean": 10.264999999999906, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -48.2875, "predator_policy": 53.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.90000000000024, 37.40000000000026, 34.000000000000206, -39.19999999999956, 89.29999999999885, 174.99999999999946, 14.999999999999961, -11.999999999999938, 5.00000000000041, -54.79999999999981, -46.89999999999991, 131.99999999999898, -148.8000000000005, -0.9999999999998496, 8.40000000000008, 30.100000000000147, 2.6000000000000734, 31.80000000000018, -21.099999999999945, 93.89999999999895, 24.600000000000048, -63.100000000000364, -21.6999999999995, 14.399999999999945, 259.49999999999955, -166.8000000000006, 13.999999999999973, -7.899999999999999, -55.89999999999982, 8.100000000000081, -118.50000000000031, 209.2999999999993, 39.60000000000029, -159.40000000000072, 13.000000000000027, 30.000000000000146, 34.30000000000022, -181.6000000000011, 26.800000000000118, 167.89999999999966, 15.199999999999916, -77.10000000000085, 30.80000000000016, 104.40000000000002, 27.700000000000106, 2.6000000000002155, 28.700000000000134, 35.600000000000236, -23.29999999999972, -58.89999999999973, 53.60000000000033, 25.400000000000073, -186.60000000000073, 188.89999999999938, 46.30000000000041, 63.40000000000042, 15.600000000000005, 24.100000000000108, 24.100000000000065, 37.80000000000027, 43.50000000000023, -140.40000000000043, 1.400000000000001, -94.20000000000155, 24.70000000000005, 196.9999999999993, 213.69999999999928, 46.80000000000042, 202.39999999999935, 37.80000000000027, -191.00000000000077, 45.800000000000395, 2.4000000000002224, 46.400000000000404, -11.599999999999765, -11.899999999999576, 33.1000000000002, -83.00000000000048, 69.49999999999943, 17.899999999999974, 31.900000000000176, 109.39999999999951, 15.200000000000006, -121.70000000000093, -10.599999999999602, -41.09999999999969, 204.59999999999934, -139.90000000000043, -148.20000000000044, 26.000000000000075, 18.899999999999984, 38.60000000000028, -192.10000000000076, 8.099999999999925, 37.700000000000266, 8.700000000000093, 27.600000000000104, -167.00000000000057, 17.999999999999996, 40.600000000000314], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.099999999999958, 20.000000000000014, 17.899999999999988, 9.499999999999964, -7.599999999999904, 23.600000000000076, -19.899999999999743, -91.30000000000052, 50.300000000000146, 20.000000000000014, 122.0, 20.000000000000014, -400.0, 20.000000000000014, 27.800000000000146, -395.8, -72.4, 13.399999999999972, 50.00000000000021, -227.80000000000038, 15.799999999999963, -141.70000000000002, 20.000000000000014, 85.9999999999996, -11.499999999999819, -322.29999999999995, -40.8999999999998, -3.099999999999958, -53.50000000000019, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 20.000000000000014, -135.4000000000007, -5.1999999999999265, 20.000000000000014, 63.800000000000196, -187.90000000000055, 34.10000000000013, 18.799999999999997, 3.1999999999999615, 7.399999999999965, -18.699999999999754, -366.4, -15.699999999999747, -42.99999999999976, -26.499999999999844, -3.099999999999958, 98.0, 105.49999999999947, -353.80000000000007, -1.0000000000000346, 20.000000000000014, -357.99999999999994, 20.000000000000014, -397.9, -376.9, 20.000000000000014, 3.1999999999999615, -24.099999999999746, -141.70000000000027, -143.80000000000007, 164.60000000000002, 31.700000000000216, 20.000000000000014, -3.399999999999958, -21.999999999999744, -348.4000000000001, 29.000000000000163, -400.0, 20.000000000000014, -0.9999999999999846, 7.399999999999965, 20.90000000000003, -57.70000000000048, -292.9, 7.099999999999975, -7.299999999999891, -112.29999999999983, 189.2, -19.899999999999785, 1.0999999999999794, -236.20000000000036, 37.10000000000026, 0.7999999999999865, 20.000000000000014, -389.5, 119.9, 20.000000000000014, -7.299999999999894, -15.699999999999747, -15.699999999999747, -47.19999999999978, 29.90000000000018, 20.000000000000014, -9.399999999999855, -4.299999999999958, -358.0000000000001, -355.90000000000003, 20.000000000000014, 88.99999999999937, -93.40000000000066, 29.90000000000018, -32.49999999999975, -5.1999999999999265, -387.4, 17.899999999999988, 155.0, 17.899999999999984, 19.40000000000001, 5.299999999999965, 40.1000000000002, 1.0999999999999865, -2.4999999999999716, -400.0, 28.100000000000147, 27.20000000000013, -24.09999999999979, 20.000000000000014, -5.1999999999999265, -400.0, 51.50000000000023, -286.6, -17.79999999999974, -29.19999999999984, -9.399999999999855, -148.00000000000068, -68.20000000000088, 3.1999999999999615, 9.499999999999964, -13.599999999999783, 185.59999999999997, 181.1, 32.60000000000023, 4.699999999999971, 28.100000000000154, 193.7, -7.299999999999891, -28.29999999999975, 28.100000000000147, -397.9, -3.0999999999999615, 17.899999999999988, 20.900000000000027, -13.599999999999783, -0.9999999999999881, 23.600000000000065, 18.799999999999997, -250.89999999999998, -15.699999999999747, -64.00000000000091, 4.099999999999966, 1.0999999999999865, 20.000000000000014, -357.2, 3.1999999999999615, 95.29999999999944, -395.8, 17.899999999999988, -21.999999999999744, 12.499999999999964, 10.399999999999965, -120.70000000000076, 115.09999999999982, 1.6999999999999729, -11.499999999999819, -294.9999999999995, 17.29999999999998, 7.399999999999965, -64.00000000000084, -311.79999999999995, -28.29999999999975, 25.4000000000001, 150.2, -336.6, 7.699999999999974, 17.899999999999988, -339.1, -13.599999999999783, 11.599999999999964, -376.29999999999995, 27.20000000000013, 11.599999999999964, 20.000000000000014, -400.0, -3.099999999999958, -5.1999999999999265, -15.69999999999996, 13.699999999999966, 20.000000000000014, -45.09999999999977, -5.1999999999999265, 15.799999999999962, -5.1999999999999265, -347.5, -8.499999999999872, -7.299999999999891, 5.299999999999965, 25.400000000000098, 0.19999999999997234], "policy_predator_policy_reward": [8.0, 11.0, 5.0, 5.0, 17.0, 1.0, 17.0, 55.0, 19.0, 0.0, 26.0, 7.0, 197.0, 198.0, 169.0, 187.0, 51.0, 13.0, 5.0, 118.0, 77.0, 2.0, 17.0, 9.0, 170.0, 15.0, 7.0, 36.0, 33.0, 11.0, 9.0, 0.0, 68.0, 50.0, 5.0, 12.0, 4.0, 99.0, 27.0, 14.0, 6.0, 8.0, 161.0, 161.0, 33.0, 4.0, 19.0, 25.0, 32.0, 24.0, 178.0, 10.0, 174.0, 178.0, 179.0, 191.0, 158.0, 143.0, 9.0, 20.0, 91.0, 76.0, 4.0, 9.0, 11.0, 12.0, 20.0, 191.0, 190.0, 194.0, 10.0, 1.0, 0.0, 6.0, 4.0, 165.0, 20.0, 7.0, 59.0, 32.0, 26.0, 8.0, 16.0, 106.0, 10.0, 0.0, 193.0, 181.0, 2.0, 13.0, 17.0, 17.0, 31.0, 15.0, 12.0, 13.0, 162.0, 177.0, 134.0, 143.0, 4.0, 54.0, 25.0, 3.0, 12.0, 194.0, 1.0, 15.0, 2.0, 7.0, 7.0, 11.0, 5.0, 12.0, 196.0, 200.0, 1.0, 20.0, 12.0, 11.0, 197.0, 195.0, 18.0, 146.0, 1.0, 39.0, 80.0, 42.0, 4.0, 8.0, 9.0, 16.0, 0.0, 0.0, 12.0, 2.0, 3.0, 13.0, 15.0, 23.0, 11.0, 199.0, 6.0, 1.0, 0.0, 17.0, 4.0, 0.0, 128.0, 127.0, 13.0, 35.0, 3.0, 9.0, 90.0, 181.0, 175.0, 195.0, 20.0, 2.0, 4.0, 5.0, 52.0, 63.0, 10.0, 15.0, 6.0, 150.0, 40.0, 6.0, 153.0, 146.0, 13.0, 16.0, 0.0, 189.0, 1.0, 172.0, 16.0, 12.0, 184.0, 184.0, 4.0, 3.0, 200.0, 11.0, 25.0, 4.0, 2.0, 2.0, 28.0, 31.0, 12.0, 5.0, 14.0, 175.0, 7.0, 13.0, 0.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5520808947034999, "mean_inference_ms": 1.4246252394380525, "mean_action_processing_ms": 0.23630717230457596, "mean_env_wait_ms": 0.18220998709716077, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033110380172729492, "StateBufferConnector_ms": 0.002730250358581543, "ViewRequirementAgentConnector_ms": 0.0822291374206543}, "num_episodes": 18, "episode_return_max": 259.49999999999955, "episode_return_min": -192.10000000000076, "episode_return_mean": 10.264999999999906, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 439.4706229707292, "num_env_steps_trained_throughput_per_sec": 439.4706229707292, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 9168.609, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9168.573, "sample_time_ms": 1015.187, "learn_time_ms": 8141.048, "learn_throughput": 491.337, "synch_weights_time_ms": 11.609}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-34-32", "timestamp": 1723646072, "time_this_iter_s": 9.105059146881104, "time_total_s": 591.5180280208588, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 591.5180280208588, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 26.415384615384614, "ram_util_percent": 76.77692307692308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6384496919692508, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.166988895526008, "policy_loss": -0.01951118768389933, "vf_loss": 3.183103225817756, "vf_explained_var": 0.3751702539189152, "kl": 0.011322854248689875, "entropy": 1.1982266642429211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9831055387933416, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.755242571376619, "policy_loss": -0.00915887063583507, "vf_loss": 2.762860025489141, "vf_explained_var": 0.11668308099741659, "kl": 0.007707081730926409, "entropy": 1.0832378123487745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 259.49999999999955, "episode_reward_min": -375.8, "episode_reward_mean": 9.835999999999904, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -411.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 218.0}, "policy_reward_mean": {"prey_policy": -50.37699999999999, "predator_policy": 55.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-21.099999999999945, 93.89999999999895, 24.600000000000048, -63.100000000000364, -21.6999999999995, 14.399999999999945, 259.49999999999955, -166.8000000000006, 13.999999999999973, -7.899999999999999, -55.89999999999982, 8.100000000000081, -118.50000000000031, 209.2999999999993, 39.60000000000029, -159.40000000000072, 13.000000000000027, 30.000000000000146, 34.30000000000022, -181.6000000000011, 26.800000000000118, 167.89999999999966, 15.199999999999916, -77.10000000000085, 30.80000000000016, 104.40000000000002, 27.700000000000106, 2.6000000000002155, 28.700000000000134, 35.600000000000236, -23.29999999999972, -58.89999999999973, 53.60000000000033, 25.400000000000073, -186.60000000000073, 188.89999999999938, 46.30000000000041, 63.40000000000042, 15.600000000000005, 24.100000000000108, 24.100000000000065, 37.80000000000027, 43.50000000000023, -140.40000000000043, 1.400000000000001, -94.20000000000155, 24.70000000000005, 196.9999999999993, 213.69999999999928, 46.80000000000042, 202.39999999999935, 37.80000000000027, -191.00000000000077, 45.800000000000395, 2.4000000000002224, 46.400000000000404, -11.599999999999765, -11.899999999999576, 33.1000000000002, -83.00000000000048, 69.49999999999943, 17.899999999999974, 31.900000000000176, 109.39999999999951, 15.200000000000006, -121.70000000000093, -10.599999999999602, -41.09999999999969, 204.59999999999934, -139.90000000000043, -148.20000000000044, 26.000000000000075, 18.899999999999984, 38.60000000000028, -192.10000000000076, 8.099999999999925, 37.700000000000266, 8.700000000000093, 27.600000000000104, -167.00000000000057, 17.999999999999996, 40.600000000000314, 30.20000000000016, 27.0000000000001, 53.80000000000048, 24.600000000000048, 31.80000000000018, 20.09999999999999, -8.399999999999872, -59.60000000000031, 26.800000000000086, 3.600000000000007, 122.89999999999984, -106.40000000000066, -375.8, 30.000000000000146, 46.000000000000206, 156.5999999999995, 17.79999999999997, 209.89999999999932], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [63.800000000000196, -187.90000000000055, 34.10000000000013, 18.799999999999997, 3.1999999999999615, 7.399999999999965, -18.699999999999754, -366.4, -15.699999999999747, -42.99999999999976, -26.499999999999844, -3.099999999999958, 98.0, 105.49999999999947, -353.80000000000007, -1.0000000000000346, 20.000000000000014, -357.99999999999994, 20.000000000000014, -397.9, -376.9, 20.000000000000014, 3.1999999999999615, -24.099999999999746, -141.70000000000027, -143.80000000000007, 164.60000000000002, 31.700000000000216, 20.000000000000014, -3.399999999999958, -21.999999999999744, -348.4000000000001, 29.000000000000163, -400.0, 20.000000000000014, -0.9999999999999846, 7.399999999999965, 20.90000000000003, -57.70000000000048, -292.9, 7.099999999999975, -7.299999999999891, -112.29999999999983, 189.2, -19.899999999999785, 1.0999999999999794, -236.20000000000036, 37.10000000000026, 0.7999999999999865, 20.000000000000014, -389.5, 119.9, 20.000000000000014, -7.299999999999894, -15.699999999999747, -15.699999999999747, -47.19999999999978, 29.90000000000018, 20.000000000000014, -9.399999999999855, -4.299999999999958, -358.0000000000001, -355.90000000000003, 20.000000000000014, 88.99999999999937, -93.40000000000066, 29.90000000000018, -32.49999999999975, -5.1999999999999265, -387.4, 17.899999999999988, 155.0, 17.899999999999984, 19.40000000000001, 5.299999999999965, 40.1000000000002, 1.0999999999999865, -2.4999999999999716, -400.0, 28.100000000000147, 27.20000000000013, -24.09999999999979, 20.000000000000014, -5.1999999999999265, -400.0, 51.50000000000023, -286.6, -17.79999999999974, -29.19999999999984, -9.399999999999855, -148.00000000000068, -68.20000000000088, 3.1999999999999615, 9.499999999999964, -13.599999999999783, 185.59999999999997, 181.1, 32.60000000000023, 4.699999999999971, 28.100000000000154, 193.7, -7.299999999999891, -28.29999999999975, 28.100000000000147, -397.9, -3.0999999999999615, 17.899999999999988, 20.900000000000027, -13.599999999999783, -0.9999999999999881, 23.600000000000065, 18.799999999999997, -250.89999999999998, -15.699999999999747, -64.00000000000091, 4.099999999999966, 1.0999999999999865, 20.000000000000014, -357.2, 3.1999999999999615, 95.29999999999944, -395.8, 17.899999999999988, -21.999999999999744, 12.499999999999964, 10.399999999999965, -120.70000000000076, 115.09999999999982, 1.6999999999999729, -11.499999999999819, -294.9999999999995, 17.29999999999998, 7.399999999999965, -64.00000000000084, -311.79999999999995, -28.29999999999975, 25.4000000000001, 150.2, -336.6, 7.699999999999974, 17.899999999999988, -339.1, -13.599999999999783, 11.599999999999964, -376.29999999999995, 27.20000000000013, 11.599999999999964, 20.000000000000014, -400.0, -3.099999999999958, -5.1999999999999265, -15.69999999999996, 13.699999999999966, 20.000000000000014, -45.09999999999977, -5.1999999999999265, 15.799999999999962, -5.1999999999999265, -347.5, -8.499999999999872, -7.299999999999891, 5.299999999999965, 25.400000000000098, 0.19999999999997234, -7.299999999999905, 9.499999999999964, 20.000000000000014, -21.999999999999744, 39.800000000000246, -21.999999999999787, 9.499999999999964, 1.0999999999999865, -5.1999999999999265, 20.000000000000014, 11.599999999999964, -11.499999999999819, -57.70000000000048, -330.7, -129.10000000000042, -53.50000000000019, 1.0999999999999865, 13.699999999999964, -173.20000000000002, -26.199999999999747, 7.99999999999997, 80.89999999999999, -99.69999999999987, -149.7000000000004, -411.8, -400.0, 20.000000000000014, -0.9999999999999846, -30.39999999999975, -124.60000000000002, 125.00000000000003, 11.599999999999964, -299.2, 20.000000000000014, 191.0, 17.899999999999988], "policy_predator_policy_reward": [4.0, 99.0, 27.0, 14.0, 6.0, 8.0, 161.0, 161.0, 33.0, 4.0, 19.0, 25.0, 32.0, 24.0, 178.0, 10.0, 174.0, 178.0, 179.0, 191.0, 158.0, 143.0, 9.0, 20.0, 91.0, 76.0, 4.0, 9.0, 11.0, 12.0, 20.0, 191.0, 190.0, 194.0, 10.0, 1.0, 0.0, 6.0, 4.0, 165.0, 20.0, 7.0, 59.0, 32.0, 26.0, 8.0, 16.0, 106.0, 10.0, 0.0, 193.0, 181.0, 2.0, 13.0, 17.0, 17.0, 31.0, 15.0, 12.0, 13.0, 162.0, 177.0, 134.0, 143.0, 4.0, 54.0, 25.0, 3.0, 12.0, 194.0, 1.0, 15.0, 2.0, 7.0, 7.0, 11.0, 5.0, 12.0, 196.0, 200.0, 1.0, 20.0, 12.0, 11.0, 197.0, 195.0, 18.0, 146.0, 1.0, 39.0, 80.0, 42.0, 4.0, 8.0, 9.0, 16.0, 0.0, 0.0, 12.0, 2.0, 3.0, 13.0, 15.0, 23.0, 11.0, 199.0, 6.0, 1.0, 0.0, 17.0, 4.0, 0.0, 128.0, 127.0, 13.0, 35.0, 3.0, 9.0, 90.0, 181.0, 175.0, 195.0, 20.0, 2.0, 4.0, 5.0, 52.0, 63.0, 10.0, 15.0, 6.0, 150.0, 40.0, 6.0, 153.0, 146.0, 13.0, 16.0, 0.0, 189.0, 1.0, 172.0, 16.0, 12.0, 184.0, 184.0, 4.0, 3.0, 200.0, 11.0, 25.0, 4.0, 2.0, 2.0, 28.0, 31.0, 12.0, 5.0, 14.0, 175.0, 7.0, 13.0, 0.0, 15.0, 13.0, 15.0, 18.0, 11.0, 18.0, 18.0, 5.0, 9.0, 12.0, 5.0, 15.0, 5.0, 192.0, 188.0, 70.0, 53.0, 9.0, 3.0, 113.0, 90.0, 27.0, 7.0, 25.0, 118.0, 218.0, 218.0, 10.0, 1.0, 101.0, 100.0, 4.0, 16.0, 149.0, 148.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5510814750176758, "mean_inference_ms": 1.4217849597470582, "mean_action_processing_ms": 0.23581108363742195, "mean_env_wait_ms": 0.1817747038497381, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003309965133666992, "StateBufferConnector_ms": 0.0027352571487426758, "ViewRequirementAgentConnector_ms": 0.08264851570129395}, "num_episodes": 18, "episode_return_max": 259.49999999999955, "episode_return_min": -375.8, "episode_return_mean": 9.835999999999904, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 448.6375573979667, "num_env_steps_trained_throughput_per_sec": 448.6375573979667, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 9152.129, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9152.093, "sample_time_ms": 1018.457, "learn_time_ms": 8121.253, "learn_throughput": 492.535, "synch_weights_time_ms": 11.635}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-34-40", "timestamp": 1723646080, "time_this_iter_s": 8.91917610168457, "time_total_s": 600.4372041225433, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b14a670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 600.4372041225433, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 25.76923076923077, "ram_util_percent": 76.57692307692308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.062584986730858, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.8068273581525007, "policy_loss": -0.016482640212283486, "vf_loss": 2.821311492137808, "vf_explained_var": 0.6585182042348953, "kl": 0.006661719007677943, "entropy": 1.1630207119164644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.599130075255399, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 1.2783827857681052, "policy_loss": -0.011319574193841723, "vf_loss": 1.2882002555188679, "vf_explained_var": 0.24437239466520844, "kl": 0.007510538252408267, "entropy": 1.1133243243214945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 213.69999999999928, "episode_reward_min": -375.8, "episode_reward_mean": 25.585999999999935, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -411.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 218.0}, "policy_reward_mean": {"prey_policy": -32.931999999999995, "predator_policy": 45.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.199999999999916, -77.10000000000085, 30.80000000000016, 104.40000000000002, 27.700000000000106, 2.6000000000002155, 28.700000000000134, 35.600000000000236, -23.29999999999972, -58.89999999999973, 53.60000000000033, 25.400000000000073, -186.60000000000073, 188.89999999999938, 46.30000000000041, 63.40000000000042, 15.600000000000005, 24.100000000000108, 24.100000000000065, 37.80000000000027, 43.50000000000023, -140.40000000000043, 1.400000000000001, -94.20000000000155, 24.70000000000005, 196.9999999999993, 213.69999999999928, 46.80000000000042, 202.39999999999935, 37.80000000000027, -191.00000000000077, 45.800000000000395, 2.4000000000002224, 46.400000000000404, -11.599999999999765, -11.899999999999576, 33.1000000000002, -83.00000000000048, 69.49999999999943, 17.899999999999974, 31.900000000000176, 109.39999999999951, 15.200000000000006, -121.70000000000093, -10.599999999999602, -41.09999999999969, 204.59999999999934, -139.90000000000043, -148.20000000000044, 26.000000000000075, 18.899999999999984, 38.60000000000028, -192.10000000000076, 8.099999999999925, 37.700000000000266, 8.700000000000093, 27.600000000000104, -167.00000000000057, 17.999999999999996, 40.600000000000314, 30.20000000000016, 27.0000000000001, 53.80000000000048, 24.600000000000048, 31.80000000000018, 20.09999999999999, -8.399999999999872, -59.60000000000031, 26.800000000000086, 3.600000000000007, 122.89999999999984, -106.40000000000066, -375.8, 30.000000000000146, 46.000000000000206, 156.5999999999995, 17.79999999999997, 209.89999999999932, 110.19999999999993, 187.5999999999994, 43.50000000000035, 41.40000000000032, 77.50000000000013, 33.70000000000021, 48.700000000000465, 188.69999999999942, 28.600000000000133, -52.199999999999754, 62.30000000000044, 19.899999999999977, 41.70000000000032, 133.49999999999952, 144.3, 33.3000000000002, 29.000000000000128, 129.09999999999872, 202.49999999999935, 147.8999999999991, 38.400000000000276, 24.80000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999785, 1.0999999999999794, -236.20000000000036, 37.10000000000026, 0.7999999999999865, 20.000000000000014, -389.5, 119.9, 20.000000000000014, -7.299999999999894, -15.699999999999747, -15.699999999999747, -47.19999999999978, 29.90000000000018, 20.000000000000014, -9.399999999999855, -4.299999999999958, -358.0000000000001, -355.90000000000003, 20.000000000000014, 88.99999999999937, -93.40000000000066, 29.90000000000018, -32.49999999999975, -5.1999999999999265, -387.4, 17.899999999999988, 155.0, 17.899999999999984, 19.40000000000001, 5.299999999999965, 40.1000000000002, 1.0999999999999865, -2.4999999999999716, -400.0, 28.100000000000147, 27.20000000000013, -24.09999999999979, 20.000000000000014, -5.1999999999999265, -400.0, 51.50000000000023, -286.6, -17.79999999999974, -29.19999999999984, -9.399999999999855, -148.00000000000068, -68.20000000000088, 3.1999999999999615, 9.499999999999964, -13.599999999999783, 185.59999999999997, 181.1, 32.60000000000023, 4.699999999999971, 28.100000000000154, 193.7, -7.299999999999891, -28.29999999999975, 28.100000000000147, -397.9, -3.0999999999999615, 17.899999999999988, 20.900000000000027, -13.599999999999783, -0.9999999999999881, 23.600000000000065, 18.799999999999997, -250.89999999999998, -15.699999999999747, -64.00000000000091, 4.099999999999966, 1.0999999999999865, 20.000000000000014, -357.2, 3.1999999999999615, 95.29999999999944, -395.8, 17.899999999999988, -21.999999999999744, 12.499999999999964, 10.399999999999965, -120.70000000000076, 115.09999999999982, 1.6999999999999729, -11.499999999999819, -294.9999999999995, 17.29999999999998, 7.399999999999965, -64.00000000000084, -311.79999999999995, -28.29999999999975, 25.4000000000001, 150.2, -336.6, 7.699999999999974, 17.899999999999988, -339.1, -13.599999999999783, 11.599999999999964, -376.29999999999995, 27.20000000000013, 11.599999999999964, 20.000000000000014, -400.0, -3.099999999999958, -5.1999999999999265, -15.69999999999996, 13.699999999999966, 20.000000000000014, -45.09999999999977, -5.1999999999999265, 15.799999999999962, -5.1999999999999265, -347.5, -8.499999999999872, -7.299999999999891, 5.299999999999965, 25.400000000000098, 0.19999999999997234, -7.299999999999905, 9.499999999999964, 20.000000000000014, -21.999999999999744, 39.800000000000246, -21.999999999999787, 9.499999999999964, 1.0999999999999865, -5.1999999999999265, 20.000000000000014, 11.599999999999964, -11.499999999999819, -57.70000000000048, -330.7, -129.10000000000042, -53.50000000000019, 1.0999999999999865, 13.699999999999964, -173.20000000000002, -26.199999999999747, 7.99999999999997, 80.89999999999999, -99.69999999999987, -149.7000000000004, -411.8, -400.0, 20.000000000000014, -0.9999999999999846, -30.39999999999975, -124.60000000000002, 125.00000000000003, 11.599999999999964, -299.2, 20.000000000000014, 191.0, 17.899999999999988, 20.000000000000014, 45.199999999999925, 20.000000000000014, 152.60000000000002, 26.900000000000126, 11.599999999999964, 5.299999999999965, 25.100000000000097, -25.0, 9.499999999999964, 17.299999999999976, 7.399999999999965, 22.100000000000044, 11.599999999999964, 127.70000000000002, 20.000000000000014, -0.9999999999999846, -9.39999999999988, 5.299999999999965, -263.49999999999886, 32.3000000000002, 20.000000000000014, -24.099999999999746, 20.000000000000014, 13.699999999999966, 23.000000000000057, -91.29999999999991, 165.7999999999999, -330.6999999999999, 161.0, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 114.19999999999948, -66.10000000000083, 20.000000000000014, 162.5, 9.499999999999964, 124.39999999999971, 20.000000000000014, 7.399999999999965, 5.299999999999965, 9.499999999999964], "policy_predator_policy_reward": [26.0, 8.0, 16.0, 106.0, 10.0, 0.0, 193.0, 181.0, 2.0, 13.0, 17.0, 17.0, 31.0, 15.0, 12.0, 13.0, 162.0, 177.0, 134.0, 143.0, 4.0, 54.0, 25.0, 3.0, 12.0, 194.0, 1.0, 15.0, 2.0, 7.0, 7.0, 11.0, 5.0, 12.0, 196.0, 200.0, 1.0, 20.0, 12.0, 11.0, 197.0, 195.0, 18.0, 146.0, 1.0, 39.0, 80.0, 42.0, 4.0, 8.0, 9.0, 16.0, 0.0, 0.0, 12.0, 2.0, 3.0, 13.0, 15.0, 23.0, 11.0, 199.0, 6.0, 1.0, 0.0, 17.0, 4.0, 0.0, 128.0, 127.0, 13.0, 35.0, 3.0, 9.0, 90.0, 181.0, 175.0, 195.0, 20.0, 2.0, 4.0, 5.0, 52.0, 63.0, 10.0, 15.0, 6.0, 150.0, 40.0, 6.0, 153.0, 146.0, 13.0, 16.0, 0.0, 189.0, 1.0, 172.0, 16.0, 12.0, 184.0, 184.0, 4.0, 3.0, 200.0, 11.0, 25.0, 4.0, 2.0, 2.0, 28.0, 31.0, 12.0, 5.0, 14.0, 175.0, 7.0, 13.0, 0.0, 15.0, 13.0, 15.0, 18.0, 11.0, 18.0, 18.0, 5.0, 9.0, 12.0, 5.0, 15.0, 5.0, 192.0, 188.0, 70.0, 53.0, 9.0, 3.0, 113.0, 90.0, 27.0, 7.0, 25.0, 118.0, 218.0, 218.0, 10.0, 1.0, 101.0, 100.0, 4.0, 16.0, 149.0, 148.0, 0.0, 1.0, 0.0, 45.0, 1.0, 14.0, 1.0, 4.0, 4.0, 7.0, 27.0, 66.0, 6.0, 3.0, 9.0, 6.0, 20.0, 21.0, 16.0, 23.0, 82.0, 124.0, 3.0, 7.0, 3.0, 21.0, 2.0, 3.0, 6.0, 53.0, 161.0, 153.0, 7.0, 1.0, 10.0, 0.0, 42.0, 39.0, 9.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5499095831078432, "mean_inference_ms": 1.4185384609039908, "mean_action_processing_ms": 0.23525112332063924, "mean_env_wait_ms": 0.1812746288540133, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00338590145111084, "StateBufferConnector_ms": 0.0027878284454345703, "ViewRequirementAgentConnector_ms": 0.08244049549102783}, "num_episodes": 22, "episode_return_max": 213.69999999999928, "episode_return_min": -375.8, "episode_return_mean": 25.585999999999935, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 444.6502272147455, "num_env_steps_trained_throughput_per_sec": 444.6502272147455, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 9142.852, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9142.815, "sample_time_ms": 1009.609, "learn_time_ms": 8120.788, "learn_throughput": 492.563, "synch_weights_time_ms": 11.683}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-34-49", "timestamp": 1723646089, "time_this_iter_s": 8.998865127563477, "time_total_s": 609.4360692501068, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b186e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 609.4360692501068, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 26.915384615384614, "ram_util_percent": 76.6923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1260161397949098, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 2.3671384452512023, "policy_loss": -0.01562461382019575, "vf_loss": 2.380968333867492, "vf_explained_var": 0.5038117876128545, "kl": 0.005982411371084646, "entropy": 1.2193308254398365, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2256756511314837, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 1.64894197318289, "policy_loss": -0.010202037679061056, "vf_loss": 1.6573040135007686, "vf_explained_var": 0.1239101770062926, "kl": 0.009199988428179352, "entropy": 1.10254092844075, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 213.69999999999928, "episode_reward_min": -375.8, "episode_reward_mean": 37.03399999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -411.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 218.0}, "policy_reward_mean": {"prey_policy": -18.80300000000001, "predator_policy": 37.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-94.20000000000155, 24.70000000000005, 196.9999999999993, 213.69999999999928, 46.80000000000042, 202.39999999999935, 37.80000000000027, -191.00000000000077, 45.800000000000395, 2.4000000000002224, 46.400000000000404, -11.599999999999765, -11.899999999999576, 33.1000000000002, -83.00000000000048, 69.49999999999943, 17.899999999999974, 31.900000000000176, 109.39999999999951, 15.200000000000006, -121.70000000000093, -10.599999999999602, -41.09999999999969, 204.59999999999934, -139.90000000000043, -148.20000000000044, 26.000000000000075, 18.899999999999984, 38.60000000000028, -192.10000000000076, 8.099999999999925, 37.700000000000266, 8.700000000000093, 27.600000000000104, -167.00000000000057, 17.999999999999996, 40.600000000000314, 30.20000000000016, 27.0000000000001, 53.80000000000048, 24.600000000000048, 31.80000000000018, 20.09999999999999, -8.399999999999872, -59.60000000000031, 26.800000000000086, 3.600000000000007, 122.89999999999984, -106.40000000000066, -375.8, 30.000000000000146, 46.000000000000206, 156.5999999999995, 17.79999999999997, 209.89999999999932, 110.19999999999993, 187.5999999999994, 43.50000000000035, 41.40000000000032, 77.50000000000013, 33.70000000000021, 48.700000000000465, 188.69999999999942, 28.600000000000133, -52.199999999999754, 62.30000000000044, 19.899999999999977, 41.70000000000032, 133.49999999999952, 144.3, 33.3000000000002, 29.000000000000128, 129.09999999999872, 202.49999999999935, 147.8999999999991, 38.400000000000276, 24.80000000000005, 192.99999999999937, 206.69999999999936, 190.0999999999993, 68.59999999999917, 28.700000000000138, 66.39999999999992, 3.7000000000002022, 46.0000000000004, 85.90000000000003, 35.600000000000236, -27.69999999999967, 26.80000000000009, 32.10000000000018, 21.299999999999994, 31.80000000000018, 36.200000000000244, 25.300000000000065, 71.29999999999988, 50.600000000000485, 43.80000000000036, 41.50000000000042, 9.400000000000112, 140.4999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-148.00000000000068, -68.20000000000088, 3.1999999999999615, 9.499999999999964, -13.599999999999783, 185.59999999999997, 181.1, 32.60000000000023, 4.699999999999971, 28.100000000000154, 193.7, -7.299999999999891, -28.29999999999975, 28.100000000000147, -397.9, -3.0999999999999615, 17.899999999999988, 20.900000000000027, -13.599999999999783, -0.9999999999999881, 23.600000000000065, 18.799999999999997, -250.89999999999998, -15.699999999999747, -64.00000000000091, 4.099999999999966, 1.0999999999999865, 20.000000000000014, -357.2, 3.1999999999999615, 95.29999999999944, -395.8, 17.899999999999988, -21.999999999999744, 12.499999999999964, 10.399999999999965, -120.70000000000076, 115.09999999999982, 1.6999999999999729, -11.499999999999819, -294.9999999999995, 17.29999999999998, 7.399999999999965, -64.00000000000084, -311.79999999999995, -28.29999999999975, 25.4000000000001, 150.2, -336.6, 7.699999999999974, 17.899999999999988, -339.1, -13.599999999999783, 11.599999999999964, -376.29999999999995, 27.20000000000013, 11.599999999999964, 20.000000000000014, -400.0, -3.099999999999958, -5.1999999999999265, -15.69999999999996, 13.699999999999966, 20.000000000000014, -45.09999999999977, -5.1999999999999265, 15.799999999999962, -5.1999999999999265, -347.5, -8.499999999999872, -7.299999999999891, 5.299999999999965, 25.400000000000098, 0.19999999999997234, -7.299999999999905, 9.499999999999964, 20.000000000000014, -21.999999999999744, 39.800000000000246, -21.999999999999787, 9.499999999999964, 1.0999999999999865, -5.1999999999999265, 20.000000000000014, 11.599999999999964, -11.499999999999819, -57.70000000000048, -330.7, -129.10000000000042, -53.50000000000019, 1.0999999999999865, 13.699999999999964, -173.20000000000002, -26.199999999999747, 7.99999999999997, 80.89999999999999, -99.69999999999987, -149.7000000000004, -411.8, -400.0, 20.000000000000014, -0.9999999999999846, -30.39999999999975, -124.60000000000002, 125.00000000000003, 11.599999999999964, -299.2, 20.000000000000014, 191.0, 17.899999999999988, 20.000000000000014, 45.199999999999925, 20.000000000000014, 152.60000000000002, 26.900000000000126, 11.599999999999964, 5.299999999999965, 25.100000000000097, -25.0, 9.499999999999964, 17.299999999999976, 7.399999999999965, 22.100000000000044, 11.599999999999964, 127.70000000000002, 20.000000000000014, -0.9999999999999846, -9.39999999999988, 5.299999999999965, -263.49999999999886, 32.3000000000002, 20.000000000000014, -24.099999999999746, 20.000000000000014, 13.699999999999966, 23.000000000000057, -91.29999999999991, 165.7999999999999, -330.6999999999999, 161.0, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 114.19999999999948, -66.10000000000083, 20.000000000000014, 162.5, 9.499999999999964, 124.39999999999971, 20.000000000000014, 7.399999999999965, 5.299999999999965, 9.499999999999964, 161.0, 13.999999999999966, 144.2, 33.50000000000024, 160.09999999999994, 20.000000000000014, -120.70000000000041, 116.29999999999953, 20.000000000000014, -175.3000000000006, 20.000000000000014, -121.60000000000042, 1.0999999999999865, -30.399999999999757, 18.8, 6.1999999999999655, 13.699999999999964, 9.199999999999932, 11.599999999999964, 20.000000000000014, -254.70000000000036, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 16.69999999999997, 7.399999999999965, 15.799999999999963, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -15.699999999999747, 1.0999999999999865, 51.20000000000019, 20.000000000000014, 23.600000000000072, 28.100000000000147, -7.299999999999891, 7.399999999999947, 28.100000000000147, -11.499999999999819, -3.099999999999958, 114.49999999999957, 20.000000000000014], "policy_predator_policy_reward": [80.0, 42.0, 4.0, 8.0, 9.0, 16.0, 0.0, 0.0, 12.0, 2.0, 3.0, 13.0, 15.0, 23.0, 11.0, 199.0, 6.0, 1.0, 0.0, 17.0, 4.0, 0.0, 128.0, 127.0, 13.0, 35.0, 3.0, 9.0, 90.0, 181.0, 175.0, 195.0, 20.0, 2.0, 4.0, 5.0, 52.0, 63.0, 10.0, 15.0, 6.0, 150.0, 40.0, 6.0, 153.0, 146.0, 13.0, 16.0, 0.0, 189.0, 1.0, 172.0, 16.0, 12.0, 184.0, 184.0, 4.0, 3.0, 200.0, 11.0, 25.0, 4.0, 2.0, 2.0, 28.0, 31.0, 12.0, 5.0, 14.0, 175.0, 7.0, 13.0, 0.0, 15.0, 13.0, 15.0, 18.0, 11.0, 18.0, 18.0, 5.0, 9.0, 12.0, 5.0, 15.0, 5.0, 192.0, 188.0, 70.0, 53.0, 9.0, 3.0, 113.0, 90.0, 27.0, 7.0, 25.0, 118.0, 218.0, 218.0, 10.0, 1.0, 101.0, 100.0, 4.0, 16.0, 149.0, 148.0, 0.0, 1.0, 0.0, 45.0, 1.0, 14.0, 1.0, 4.0, 4.0, 7.0, 27.0, 66.0, 6.0, 3.0, 9.0, 6.0, 20.0, 21.0, 16.0, 23.0, 82.0, 124.0, 3.0, 7.0, 3.0, 21.0, 2.0, 3.0, 6.0, 53.0, 161.0, 153.0, 7.0, 1.0, 10.0, 0.0, 42.0, 39.0, 9.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 3.0, 5.0, 13.0, 15.0, 14.0, 10.0, 0.0, 6.0, 67.0, 92.0, 92.0, 84.0, 84.0, 25.0, 8.0, 7.0, 14.0, 3.0, 60.0, 0.0, 4.0, 81.0, 126.0, 12.0, 0.0, 2.0, 6.0, 2.0, 15.0, 5.0, 12.0, 7.0, 6.0, 7.0, 14.0, 10.0, 9.0, 1.0, 6.0, 11.0, 12.0, 6.0, 0.0, 9.0, 15.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5486792660539069, "mean_inference_ms": 1.4165313653664855, "mean_action_processing_ms": 0.23490694100686085, "mean_env_wait_ms": 0.18060173867978035, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033686161041259766, "StateBufferConnector_ms": 0.00280916690826416, "ViewRequirementAgentConnector_ms": 0.08234310150146484}, "num_episodes": 23, "episode_return_max": 213.69999999999928, "episode_return_min": -375.8, "episode_return_mean": 37.03399999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 443.78947154578213, "num_env_steps_trained_throughput_per_sec": 443.78947154578213, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 9131.191, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9131.154, "sample_time_ms": 1009.755, "learn_time_ms": 8108.865, "learn_throughput": 493.287, "synch_weights_time_ms": 11.787}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-34-59", "timestamp": 1723646099, "time_this_iter_s": 9.016459941864014, "time_total_s": 618.4525291919708, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b186ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 618.4525291919708, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 26.076923076923077, "ram_util_percent": 76.82307692307691}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.270618434999355, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.513749171312524, "policy_loss": -0.0167033209573852, "vf_loss": 3.527895064581008, "vf_explained_var": 0.4457741126496956, "kl": 0.008524741961964392, "entropy": 1.1760585330150746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.240964398844532, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 2.1944918576371735, "policy_loss": -0.006854703564014503, "vf_loss": 2.200254910143595, "vf_explained_var": 0.17235626117892996, "kl": 0.005458241381739868, "entropy": 1.0982129075539806, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 209.89999999999932, "episode_reward_min": -375.8, "episode_reward_mean": 35.029999999999916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -411.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.8, "predator_policy": 218.0}, "policy_reward_mean": {"prey_policy": -18.42, "predator_policy": 35.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [109.39999999999951, 15.200000000000006, -121.70000000000093, -10.599999999999602, -41.09999999999969, 204.59999999999934, -139.90000000000043, -148.20000000000044, 26.000000000000075, 18.899999999999984, 38.60000000000028, -192.10000000000076, 8.099999999999925, 37.700000000000266, 8.700000000000093, 27.600000000000104, -167.00000000000057, 17.999999999999996, 40.600000000000314, 30.20000000000016, 27.0000000000001, 53.80000000000048, 24.600000000000048, 31.80000000000018, 20.09999999999999, -8.399999999999872, -59.60000000000031, 26.800000000000086, 3.600000000000007, 122.89999999999984, -106.40000000000066, -375.8, 30.000000000000146, 46.000000000000206, 156.5999999999995, 17.79999999999997, 209.89999999999932, 110.19999999999993, 187.5999999999994, 43.50000000000035, 41.40000000000032, 77.50000000000013, 33.70000000000021, 48.700000000000465, 188.69999999999942, 28.600000000000133, -52.199999999999754, 62.30000000000044, 19.899999999999977, 41.70000000000032, 133.49999999999952, 144.3, 33.3000000000002, 29.000000000000128, 129.09999999999872, 202.49999999999935, 147.8999999999991, 38.400000000000276, 24.80000000000005, 192.99999999999937, 206.69999999999936, 190.0999999999993, 68.59999999999917, 28.700000000000138, 66.39999999999992, 3.7000000000002022, 46.0000000000004, 85.90000000000003, 35.600000000000236, -27.69999999999967, 26.80000000000009, 32.10000000000018, 21.299999999999994, 31.80000000000018, 36.200000000000244, 25.300000000000065, 71.29999999999988, 50.600000000000485, 43.80000000000036, 41.50000000000042, 9.400000000000112, 140.4999999999989, 199.59999999999937, 11.400000000000063, -366.4000000000003, 41.60000000000033, 30.20000000000015, 101.09999999999997, 70.69999999999992, -28.29999999999967, 196.2999999999994, -150.5000000000007, 12.500000000000052, 30.100000000000147, 202.4999999999993, -227.80000000000075, 201.09999999999934, 13.60000000000004, 21.60000000000021, 17.99999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-120.70000000000076, 115.09999999999982, 1.6999999999999729, -11.499999999999819, -294.9999999999995, 17.29999999999998, 7.399999999999965, -64.00000000000084, -311.79999999999995, -28.29999999999975, 25.4000000000001, 150.2, -336.6, 7.699999999999974, 17.899999999999988, -339.1, -13.599999999999783, 11.599999999999964, -376.29999999999995, 27.20000000000013, 11.599999999999964, 20.000000000000014, -400.0, -3.099999999999958, -5.1999999999999265, -15.69999999999996, 13.699999999999966, 20.000000000000014, -45.09999999999977, -5.1999999999999265, 15.799999999999962, -5.1999999999999265, -347.5, -8.499999999999872, -7.299999999999891, 5.299999999999965, 25.400000000000098, 0.19999999999997234, -7.299999999999905, 9.499999999999964, 20.000000000000014, -21.999999999999744, 39.800000000000246, -21.999999999999787, 9.499999999999964, 1.0999999999999865, -5.1999999999999265, 20.000000000000014, 11.599999999999964, -11.499999999999819, -57.70000000000048, -330.7, -129.10000000000042, -53.50000000000019, 1.0999999999999865, 13.699999999999964, -173.20000000000002, -26.199999999999747, 7.99999999999997, 80.89999999999999, -99.69999999999987, -149.7000000000004, -411.8, -400.0, 20.000000000000014, -0.9999999999999846, -30.39999999999975, -124.60000000000002, 125.00000000000003, 11.599999999999964, -299.2, 20.000000000000014, 191.0, 17.899999999999988, 20.000000000000014, 45.199999999999925, 20.000000000000014, 152.60000000000002, 26.900000000000126, 11.599999999999964, 5.299999999999965, 25.100000000000097, -25.0, 9.499999999999964, 17.299999999999976, 7.399999999999965, 22.100000000000044, 11.599999999999964, 127.70000000000002, 20.000000000000014, -0.9999999999999846, -9.39999999999988, 5.299999999999965, -263.49999999999886, 32.3000000000002, 20.000000000000014, -24.099999999999746, 20.000000000000014, 13.699999999999966, 23.000000000000057, -91.29999999999991, 165.7999999999999, -330.6999999999999, 161.0, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 114.19999999999948, -66.10000000000083, 20.000000000000014, 162.5, 9.499999999999964, 124.39999999999971, 20.000000000000014, 7.399999999999965, 5.299999999999965, 9.499999999999964, 161.0, 13.999999999999966, 144.2, 33.50000000000024, 160.09999999999994, 20.000000000000014, -120.70000000000041, 116.29999999999953, 20.000000000000014, -175.3000000000006, 20.000000000000014, -121.60000000000042, 1.0999999999999865, -30.399999999999757, 18.8, 6.1999999999999655, 13.699999999999964, 9.199999999999932, 11.599999999999964, 20.000000000000014, -254.70000000000036, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 16.69999999999997, 7.399999999999965, 15.799999999999963, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -15.699999999999747, 1.0999999999999865, 51.20000000000019, 20.000000000000014, 23.600000000000072, 28.100000000000147, -7.299999999999891, 7.399999999999947, 28.100000000000147, -11.499999999999819, -3.099999999999958, 114.49999999999957, 20.000000000000014, -5.199999999999948, 192.8, -24.099999999999746, 9.499999999999964, -400.0, -177.39999999999992, 5.599999999999975, 20.000000000000014, 20.300000000000022, -3.099999999999958, 20.000000000000014, 19.099999999999994, 20.000000000000014, -4.299999999999942, 45.20000000000023, -179.50000000000057, 5.299999999999965, 176.0, 15.799999999999963, -376.29999999999984, 5.299999999999965, -17.79999999999974, 20.000000000000014, 1.0999999999999865, 158.89999999999998, 23.600000000000065, -83.80000000000013, -357.99999999999955, 185.6, 9.499999999999964, -13.599999999999783, 3.1999999999999615, -93.40000000000002, 20.000000000000014, -85.00000000000074, 47.000000000000234], "policy_predator_policy_reward": [52.0, 63.0, 10.0, 15.0, 6.0, 150.0, 40.0, 6.0, 153.0, 146.0, 13.0, 16.0, 0.0, 189.0, 1.0, 172.0, 16.0, 12.0, 184.0, 184.0, 4.0, 3.0, 200.0, 11.0, 25.0, 4.0, 2.0, 2.0, 28.0, 31.0, 12.0, 5.0, 14.0, 175.0, 7.0, 13.0, 0.0, 15.0, 13.0, 15.0, 18.0, 11.0, 18.0, 18.0, 5.0, 9.0, 12.0, 5.0, 15.0, 5.0, 192.0, 188.0, 70.0, 53.0, 9.0, 3.0, 113.0, 90.0, 27.0, 7.0, 25.0, 118.0, 218.0, 218.0, 10.0, 1.0, 101.0, 100.0, 4.0, 16.0, 149.0, 148.0, 0.0, 1.0, 0.0, 45.0, 1.0, 14.0, 1.0, 4.0, 4.0, 7.0, 27.0, 66.0, 6.0, 3.0, 9.0, 6.0, 20.0, 21.0, 16.0, 23.0, 82.0, 124.0, 3.0, 7.0, 3.0, 21.0, 2.0, 3.0, 6.0, 53.0, 161.0, 153.0, 7.0, 1.0, 10.0, 0.0, 42.0, 39.0, 9.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 3.0, 5.0, 13.0, 15.0, 14.0, 10.0, 0.0, 6.0, 67.0, 92.0, 92.0, 84.0, 84.0, 25.0, 8.0, 7.0, 14.0, 3.0, 60.0, 0.0, 4.0, 81.0, 126.0, 12.0, 0.0, 2.0, 6.0, 2.0, 15.0, 5.0, 12.0, 7.0, 6.0, 7.0, 14.0, 10.0, 9.0, 1.0, 6.0, 11.0, 12.0, 6.0, 0.0, 9.0, 15.0, 0.0, 6.0, 12.0, 0.0, 19.0, 7.0, 11.0, 200.0, 15.0, 1.0, 11.0, 2.0, 2.0, 60.0, 29.0, 26.0, 95.0, 11.0, 9.0, 6.0, 29.0, 181.0, 18.0, 7.0, 0.0, 9.0, 10.0, 10.0, 180.0, 34.0, 1.0, 5.0, 8.0, 16.0, 45.0, 50.0, 26.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5478194206504076, "mean_inference_ms": 1.413013852107524, "mean_action_processing_ms": 0.23430735853010545, "mean_env_wait_ms": 0.1804135581510047, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037844181060791016, "StateBufferConnector_ms": 0.002774834632873535, "ViewRequirementAgentConnector_ms": 0.08091104030609131}, "num_episodes": 18, "episode_return_max": 209.89999999999932, "episode_return_min": -375.8, "episode_return_mean": 35.029999999999916, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 442.90372146268436, "num_env_steps_trained_throughput_per_sec": 442.90372146268436, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 9096.978, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9096.941, "sample_time_ms": 1007.821, "learn_time_ms": 8076.626, "learn_throughput": 495.256, "synch_weights_time_ms": 11.735}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-35-08", "timestamp": 1723646108, "time_this_iter_s": 9.035242080688477, "time_total_s": 627.4877712726593, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1868b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 627.4877712726593, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 26.774999999999995, "ram_util_percent": 76.89166666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8720172249450886, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.00010000000000000003, "total_loss": 3.0038591564017, "policy_loss": -0.01154351043625779, "vf_loss": 3.014044857277441, "vf_explained_var": 0.47172897669373365, "kl": 0.004526040374565586, "entropy": 1.1240557542553655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.003239307580171, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 1.3005380945230918, "policy_loss": -0.0054941313870980465, "vf_loss": 1.3050140960979715, "vf_explained_var": 0.10446038529986428, "kl": 0.0050906442642380855, "entropy": 1.1011679609931966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 211.49999999999926, "episode_reward_min": -375.8, "episode_reward_mean": 52.57699999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -411.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.8, "predator_policy": 218.0}, "policy_reward_mean": {"prey_policy": -4.026500000000002, "predator_policy": 30.315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.600000000000314, 30.20000000000016, 27.0000000000001, 53.80000000000048, 24.600000000000048, 31.80000000000018, 20.09999999999999, -8.399999999999872, -59.60000000000031, 26.800000000000086, 3.600000000000007, 122.89999999999984, -106.40000000000066, -375.8, 30.000000000000146, 46.000000000000206, 156.5999999999995, 17.79999999999997, 209.89999999999932, 110.19999999999993, 187.5999999999994, 43.50000000000035, 41.40000000000032, 77.50000000000013, 33.70000000000021, 48.700000000000465, 188.69999999999942, 28.600000000000133, -52.199999999999754, 62.30000000000044, 19.899999999999977, 41.70000000000032, 133.49999999999952, 144.3, 33.3000000000002, 29.000000000000128, 129.09999999999872, 202.49999999999935, 147.8999999999991, 38.400000000000276, 24.80000000000005, 192.99999999999937, 206.69999999999936, 190.0999999999993, 68.59999999999917, 28.700000000000138, 66.39999999999992, 3.7000000000002022, 46.0000000000004, 85.90000000000003, 35.600000000000236, -27.69999999999967, 26.80000000000009, 32.10000000000018, 21.299999999999994, 31.80000000000018, 36.200000000000244, 25.300000000000065, 71.29999999999988, 50.600000000000485, 43.80000000000036, 41.50000000000042, 9.400000000000112, 140.4999999999989, 199.59999999999937, 11.400000000000063, -366.4000000000003, 41.60000000000033, 30.20000000000015, 101.09999999999997, 70.69999999999992, -28.29999999999967, 196.2999999999994, -150.5000000000007, 12.500000000000052, 30.100000000000147, 202.4999999999993, -227.80000000000075, 201.09999999999934, 13.60000000000004, 21.60000000000021, 17.99999999999996, 178.89999999999947, 103.3, 173.9999999999995, 194.4999999999994, 108.3999999999998, 110.99999999999977, 23.200000000000028, 177.69999999999948, 3.6000000000001062, 32.30000000000018, 211.49999999999926, -2.3999999999997157, 35.600000000000236, -40.199999999999925, 40.0000000000003, 21.099999999999987, 37.10000000000026, 37.30000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [25.400000000000098, 0.19999999999997234, -7.299999999999905, 9.499999999999964, 20.000000000000014, -21.999999999999744, 39.800000000000246, -21.999999999999787, 9.499999999999964, 1.0999999999999865, -5.1999999999999265, 20.000000000000014, 11.599999999999964, -11.499999999999819, -57.70000000000048, -330.7, -129.10000000000042, -53.50000000000019, 1.0999999999999865, 13.699999999999964, -173.20000000000002, -26.199999999999747, 7.99999999999997, 80.89999999999999, -99.69999999999987, -149.7000000000004, -411.8, -400.0, 20.000000000000014, -0.9999999999999846, -30.39999999999975, -124.60000000000002, 125.00000000000003, 11.599999999999964, -299.2, 20.000000000000014, 191.0, 17.899999999999988, 20.000000000000014, 45.199999999999925, 20.000000000000014, 152.60000000000002, 26.900000000000126, 11.599999999999964, 5.299999999999965, 25.100000000000097, -25.0, 9.499999999999964, 17.299999999999976, 7.399999999999965, 22.100000000000044, 11.599999999999964, 127.70000000000002, 20.000000000000014, -0.9999999999999846, -9.39999999999988, 5.299999999999965, -263.49999999999886, 32.3000000000002, 20.000000000000014, -24.099999999999746, 20.000000000000014, 13.699999999999966, 23.000000000000057, -91.29999999999991, 165.7999999999999, -330.6999999999999, 161.0, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 114.19999999999948, -66.10000000000083, 20.000000000000014, 162.5, 9.499999999999964, 124.39999999999971, 20.000000000000014, 7.399999999999965, 5.299999999999965, 9.499999999999964, 161.0, 13.999999999999966, 144.2, 33.50000000000024, 160.09999999999994, 20.000000000000014, -120.70000000000041, 116.29999999999953, 20.000000000000014, -175.3000000000006, 20.000000000000014, -121.60000000000042, 1.0999999999999865, -30.399999999999757, 18.8, 6.1999999999999655, 13.699999999999964, 9.199999999999932, 11.599999999999964, 20.000000000000014, -254.70000000000036, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 16.69999999999997, 7.399999999999965, 15.799999999999963, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -15.699999999999747, 1.0999999999999865, 51.20000000000019, 20.000000000000014, 23.600000000000072, 28.100000000000147, -7.299999999999891, 7.399999999999947, 28.100000000000147, -11.499999999999819, -3.099999999999958, 114.49999999999957, 20.000000000000014, -5.199999999999948, 192.8, -24.099999999999746, 9.499999999999964, -400.0, -177.39999999999992, 5.599999999999975, 20.000000000000014, 20.300000000000022, -3.099999999999958, 20.000000000000014, 19.099999999999994, 20.000000000000014, -4.299999999999942, 45.20000000000023, -179.50000000000057, 5.299999999999965, 176.0, 15.799999999999963, -376.29999999999984, 5.299999999999965, -17.79999999999974, 20.000000000000014, 1.0999999999999865, 158.89999999999998, 23.600000000000065, -83.80000000000013, -357.99999999999955, 185.6, 9.499999999999964, -13.599999999999783, 3.1999999999999615, -93.40000000000002, 20.000000000000014, -85.00000000000074, 47.000000000000234, 13.699999999999964, 162.2, -397.9, 123.2, -11.499999999999854, 168.5, 159.5, 20.000000000000014, 26.000000000000114, -31.60000000000005, 96.49999999999997, 9.499999999999964, 20.000000000000014, -17.79999999999974, 143.0, -1.2999999999999994, -80.80000000000081, 25.4000000000001, 20.000000000000014, 5.299999999999965, 191.89999999999998, 8.599999999999968, -5.1999999999999265, -26.199999999999747, 15.799999999999963, 15.799999999999963, -17.79999999999974, -120.40000000000009, 20.000000000000014, 20.000000000000014, 13.699999999999964, -10.599999999999836, 20.000000000000014, 1.0999999999999865, 13.699999999999966, 14.599999999999968], "policy_predator_policy_reward": [0.0, 15.0, 13.0, 15.0, 18.0, 11.0, 18.0, 18.0, 5.0, 9.0, 12.0, 5.0, 15.0, 5.0, 192.0, 188.0, 70.0, 53.0, 9.0, 3.0, 113.0, 90.0, 27.0, 7.0, 25.0, 118.0, 218.0, 218.0, 10.0, 1.0, 101.0, 100.0, 4.0, 16.0, 149.0, 148.0, 0.0, 1.0, 0.0, 45.0, 1.0, 14.0, 1.0, 4.0, 4.0, 7.0, 27.0, 66.0, 6.0, 3.0, 9.0, 6.0, 20.0, 21.0, 16.0, 23.0, 82.0, 124.0, 3.0, 7.0, 3.0, 21.0, 2.0, 3.0, 6.0, 53.0, 161.0, 153.0, 7.0, 1.0, 10.0, 0.0, 42.0, 39.0, 9.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 3.0, 5.0, 13.0, 15.0, 14.0, 10.0, 0.0, 6.0, 67.0, 92.0, 92.0, 84.0, 84.0, 25.0, 8.0, 7.0, 14.0, 3.0, 60.0, 0.0, 4.0, 81.0, 126.0, 12.0, 0.0, 2.0, 6.0, 2.0, 15.0, 5.0, 12.0, 7.0, 6.0, 7.0, 14.0, 10.0, 9.0, 1.0, 6.0, 11.0, 12.0, 6.0, 0.0, 9.0, 15.0, 0.0, 6.0, 12.0, 0.0, 19.0, 7.0, 11.0, 200.0, 15.0, 1.0, 11.0, 2.0, 2.0, 60.0, 29.0, 26.0, 95.0, 11.0, 9.0, 6.0, 29.0, 181.0, 18.0, 7.0, 0.0, 9.0, 10.0, 10.0, 180.0, 34.0, 1.0, 5.0, 8.0, 16.0, 45.0, 50.0, 26.0, 30.0, 3.0, 0.0, 185.0, 193.0, 2.0, 15.0, 3.0, 12.0, 55.0, 59.0, 0.0, 5.0, 3.0, 18.0, 14.0, 22.0, 45.0, 14.0, 7.0, 0.0, 3.0, 8.0, 22.0, 7.0, 2.0, 2.0, 18.0, 80.0, 0.0, 0.0, 16.0, 2.0, 9.0, 7.0, 6.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5469780360715388, "mean_inference_ms": 1.4107908734501415, "mean_action_processing_ms": 0.23392483134742711, "mean_env_wait_ms": 0.18005696642813881, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003805398941040039, "StateBufferConnector_ms": 0.0028134584426879883, "ViewRequirementAgentConnector_ms": 0.08329367637634277}, "num_episodes": 18, "episode_return_max": 211.49999999999926, "episode_return_min": -375.8, "episode_return_mean": 52.57699999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 444.4599039250971, "num_env_steps_trained_throughput_per_sec": 444.4599039250971, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 9074.656, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9074.618, "sample_time_ms": 1017.314, "learn_time_ms": 8044.758, "learn_throughput": 497.218, "synch_weights_time_ms": 11.769}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-35-17", "timestamp": 1723646117, "time_this_iter_s": 9.0034818649292, "time_total_s": 636.4912531375885, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b186c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 636.4912531375885, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 26.96153846153846, "ram_util_percent": 76.92307692307693}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.004450728874358, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 0.00010000000000000003, "total_loss": 3.613464578497347, "policy_loss": -0.019420039971979955, "vf_loss": 3.631057679211652, "vf_explained_var": 0.772059572689117, "kl": 0.01217959412145936, "entropy": 1.0151057417115206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.089917973961149, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 1.4200211050964537, "policy_loss": -0.007883361259859705, "vf_loss": 1.4264345659307702, "vf_explained_var": 0.02964876716729825, "kl": 0.007349512698587345, "entropy": 1.1076869104905103, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 347.2, "episode_reward_min": -366.4000000000003, "episode_reward_mean": 68.71499999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.8, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 10.352500000000004, "predator_policy": 24.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [41.40000000000032, 77.50000000000013, 33.70000000000021, 48.700000000000465, 188.69999999999942, 28.600000000000133, -52.199999999999754, 62.30000000000044, 19.899999999999977, 41.70000000000032, 133.49999999999952, 144.3, 33.3000000000002, 29.000000000000128, 129.09999999999872, 202.49999999999935, 147.8999999999991, 38.400000000000276, 24.80000000000005, 192.99999999999937, 206.69999999999936, 190.0999999999993, 68.59999999999917, 28.700000000000138, 66.39999999999992, 3.7000000000002022, 46.0000000000004, 85.90000000000003, 35.600000000000236, -27.69999999999967, 26.80000000000009, 32.10000000000018, 21.299999999999994, 31.80000000000018, 36.200000000000244, 25.300000000000065, 71.29999999999988, 50.600000000000485, 43.80000000000036, 41.50000000000042, 9.400000000000112, 140.4999999999989, 199.59999999999937, 11.400000000000063, -366.4000000000003, 41.60000000000033, 30.20000000000015, 101.09999999999997, 70.69999999999992, -28.29999999999967, 196.2999999999994, -150.5000000000007, 12.500000000000052, 30.100000000000147, 202.4999999999993, -227.80000000000075, 201.09999999999934, 13.60000000000004, 21.60000000000021, 17.99999999999996, 178.89999999999947, 103.3, 173.9999999999995, 194.4999999999994, 108.3999999999998, 110.99999999999977, 23.200000000000028, 177.69999999999948, 3.6000000000001062, 32.30000000000018, 211.49999999999926, -2.3999999999997157, 35.600000000000236, -40.199999999999925, 40.0000000000003, 21.099999999999987, 37.10000000000026, 37.30000000000026, 169.0999999999995, 25.700000000000067, 184.69999999999945, 35.500000000000234, 30.39999999999996, 347.2, -132.20000000000053, 147.90000000000003, 190.39999999999935, 52.200000000000465, 71.1, 33.2000000000002, 169.99999999999952, 346.0, 70.09999999999998, 21.099999999999994, 67.00000000000006, 52.5000000000005, 29.300000000000136, 194.09999999999937, 145.2999999999996, -3.999999999999703], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, 25.100000000000097, -25.0, 9.499999999999964, 17.299999999999976, 7.399999999999965, 22.100000000000044, 11.599999999999964, 127.70000000000002, 20.000000000000014, -0.9999999999999846, -9.39999999999988, 5.299999999999965, -263.49999999999886, 32.3000000000002, 20.000000000000014, -24.099999999999746, 20.000000000000014, 13.699999999999966, 23.000000000000057, -91.29999999999991, 165.7999999999999, -330.6999999999999, 161.0, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 114.19999999999948, -66.10000000000083, 20.000000000000014, 162.5, 9.499999999999964, 124.39999999999971, 20.000000000000014, 7.399999999999965, 5.299999999999965, 9.499999999999964, 161.0, 13.999999999999966, 144.2, 33.50000000000024, 160.09999999999994, 20.000000000000014, -120.70000000000041, 116.29999999999953, 20.000000000000014, -175.3000000000006, 20.000000000000014, -121.60000000000042, 1.0999999999999865, -30.399999999999757, 18.8, 6.1999999999999655, 13.699999999999964, 9.199999999999932, 11.599999999999964, 20.000000000000014, -254.70000000000036, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 16.69999999999997, 7.399999999999965, 15.799999999999963, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -15.699999999999747, 1.0999999999999865, 51.20000000000019, 20.000000000000014, 23.600000000000072, 28.100000000000147, -7.299999999999891, 7.399999999999947, 28.100000000000147, -11.499999999999819, -3.099999999999958, 114.49999999999957, 20.000000000000014, -5.199999999999948, 192.8, -24.099999999999746, 9.499999999999964, -400.0, -177.39999999999992, 5.599999999999975, 20.000000000000014, 20.300000000000022, -3.099999999999958, 20.000000000000014, 19.099999999999994, 20.000000000000014, -4.299999999999942, 45.20000000000023, -179.50000000000057, 5.299999999999965, 176.0, 15.799999999999963, -376.29999999999984, 5.299999999999965, -17.79999999999974, 20.000000000000014, 1.0999999999999865, 158.89999999999998, 23.600000000000065, -83.80000000000013, -357.99999999999955, 185.6, 9.499999999999964, -13.599999999999783, 3.1999999999999615, -93.40000000000002, 20.000000000000014, -85.00000000000074, 47.000000000000234, 13.699999999999964, 162.2, -397.9, 123.2, -11.499999999999854, 168.5, 159.5, 20.000000000000014, 26.000000000000114, -31.60000000000005, 96.49999999999997, 9.499999999999964, 20.000000000000014, -17.79999999999974, 143.0, -1.2999999999999994, -80.80000000000081, 25.4000000000001, 20.000000000000014, 5.299999999999965, 191.89999999999998, 8.599999999999968, -5.1999999999999265, -26.199999999999747, 15.799999999999963, 15.799999999999963, -17.79999999999974, -120.40000000000009, 20.000000000000014, 20.000000000000014, 13.699999999999964, -10.599999999999836, 20.000000000000014, 1.0999999999999865, 13.699999999999966, 14.599999999999968, 157.1, -21.999999999999744, 13.699999999999964, -0.9999999999999846, -28.29999999999975, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, -15.999999999999993, 146.0, 174.2, 31.10000000000021, -361.2999999999998, -101.2000000000005, 163.1, 157.39999999999998, 20.000000000000014, 20.000000000000014, 24.200000000000085, 178.7, -259.6, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 119.0, 155.0, 164.0, 9.499999999999964, 50.60000000000019, -11.499999999999819, 11.599999999999966, 48.80000000000012, 3.1999999999999615, 20.000000000000014, 27.500000000000142, 2.599999999999961, 13.699999999999964, 176.0, 1.0999999999999865, 125.3, 20.000000000000014, 1.0999999999999865, -45.09999999999976], "policy_predator_policy_reward": [4.0, 7.0, 27.0, 66.0, 6.0, 3.0, 9.0, 6.0, 20.0, 21.0, 16.0, 23.0, 82.0, 124.0, 3.0, 7.0, 3.0, 21.0, 2.0, 3.0, 6.0, 53.0, 161.0, 153.0, 7.0, 1.0, 10.0, 0.0, 42.0, 39.0, 9.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 3.0, 5.0, 13.0, 15.0, 14.0, 10.0, 0.0, 6.0, 67.0, 92.0, 92.0, 84.0, 84.0, 25.0, 8.0, 7.0, 14.0, 3.0, 60.0, 0.0, 4.0, 81.0, 126.0, 12.0, 0.0, 2.0, 6.0, 2.0, 15.0, 5.0, 12.0, 7.0, 6.0, 7.0, 14.0, 10.0, 9.0, 1.0, 6.0, 11.0, 12.0, 6.0, 0.0, 9.0, 15.0, 0.0, 6.0, 12.0, 0.0, 19.0, 7.0, 11.0, 200.0, 15.0, 1.0, 11.0, 2.0, 2.0, 60.0, 29.0, 26.0, 95.0, 11.0, 9.0, 6.0, 29.0, 181.0, 18.0, 7.0, 0.0, 9.0, 10.0, 10.0, 180.0, 34.0, 1.0, 5.0, 8.0, 16.0, 45.0, 50.0, 26.0, 30.0, 3.0, 0.0, 185.0, 193.0, 2.0, 15.0, 3.0, 12.0, 55.0, 59.0, 0.0, 5.0, 3.0, 18.0, 14.0, 22.0, 45.0, 14.0, 7.0, 0.0, 3.0, 8.0, 22.0, 7.0, 2.0, 2.0, 18.0, 80.0, 0.0, 0.0, 16.0, 2.0, 9.0, 7.0, 6.0, 3.0, 20.0, 14.0, 10.0, 3.0, 14.0, 23.0, 5.0, 1.0, 29.0, 31.0, 9.0, 18.0, 153.0, 45.0, 43.0, 43.0, 0.0, 13.0, 1.0, 7.0, 20.0, 132.0, 2.0, 8.0, 4.0, 27.0, 17.0, 10.0, 5.0, 5.0, 14.0, 7.0, 7.0, 8.0, 2.0, 3.0, 3.0, 10.0, 9.0, 8.0, 0.0, 0.0, 22.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.545929050744464, "mean_inference_ms": 1.409290972049805, "mean_action_processing_ms": 0.23318644443508788, "mean_env_wait_ms": 0.17953448097216282, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037839412689208984, "StateBufferConnector_ms": 0.0028142929077148438, "ViewRequirementAgentConnector_ms": 0.08286809921264648}, "num_episodes": 22, "episode_return_max": 347.2, "episode_return_min": -366.4000000000003, "episode_return_mean": 68.71499999999992, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 449.2716641446061, "num_env_steps_trained_throughput_per_sec": 449.2716641446061, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 9039.736, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9039.698, "sample_time_ms": 1015.396, "learn_time_ms": 8011.741, "learn_throughput": 499.267, "synch_weights_time_ms": 11.768}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-35-26", "timestamp": 1723646126, "time_this_iter_s": 8.906249046325684, "time_total_s": 645.3975021839142, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b14ae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 645.3975021839142, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 25.523076923076925, "ram_util_percent": 76.71538461538464}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8710448140820497, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 0.00010000000000000003, "total_loss": 4.938147182313223, "policy_loss": -0.008396916020114626, "vf_loss": 4.945518874365186, "vf_explained_var": 0.8148264489476643, "kl": 0.0068349241089516715, "entropy": 0.7820685501136477, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0231032204375694, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 0.7958882644851372, "policy_loss": -0.010913316633862753, "vf_loss": 0.8054562597836136, "vf_explained_var": 0.0451345095558772, "kl": 0.006726605418075099, "entropy": 1.0726504009236735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 373.0, "episode_reward_min": -366.4000000000003, "episode_reward_mean": 80.2879999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 18.379000000000005, "predator_policy": 21.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.80000000000005, 192.99999999999937, 206.69999999999936, 190.0999999999993, 68.59999999999917, 28.700000000000138, 66.39999999999992, 3.7000000000002022, 46.0000000000004, 85.90000000000003, 35.600000000000236, -27.69999999999967, 26.80000000000009, 32.10000000000018, 21.299999999999994, 31.80000000000018, 36.200000000000244, 25.300000000000065, 71.29999999999988, 50.600000000000485, 43.80000000000036, 41.50000000000042, 9.400000000000112, 140.4999999999989, 199.59999999999937, 11.400000000000063, -366.4000000000003, 41.60000000000033, 30.20000000000015, 101.09999999999997, 70.69999999999992, -28.29999999999967, 196.2999999999994, -150.5000000000007, 12.500000000000052, 30.100000000000147, 202.4999999999993, -227.80000000000075, 201.09999999999934, 13.60000000000004, 21.60000000000021, 17.99999999999996, 178.89999999999947, 103.3, 173.9999999999995, 194.4999999999994, 108.3999999999998, 110.99999999999977, 23.200000000000028, 177.69999999999948, 3.6000000000001062, 32.30000000000018, 211.49999999999926, -2.3999999999997157, 35.600000000000236, -40.199999999999925, 40.0000000000003, 21.099999999999987, 37.10000000000026, 37.30000000000026, 169.0999999999995, 25.700000000000067, 184.69999999999945, 35.500000000000234, 30.39999999999996, 347.2, -132.20000000000053, 147.90000000000003, 190.39999999999935, 52.200000000000465, 71.1, 33.2000000000002, 169.99999999999952, 346.0, 70.09999999999998, 21.099999999999994, 67.00000000000006, 52.5000000000005, 29.300000000000136, 194.09999999999937, 145.2999999999996, -3.999999999999703, 193.09999999999997, 216.19999999999928, 15.799999999999983, 209.99999999999932, 154.7999999999996, 29.000000000000124, 268.29999999999995, 256.00000000000006, 75.39999999999966, 101.7999999999987, 31.600000000000176, 240.5, 37.80000000000027, 16.900000000000002, 207.99999999999932, 40.0000000000003, 37.4000000000001, 373.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, 9.499999999999964, 161.0, 13.999999999999966, 144.2, 33.50000000000024, 160.09999999999994, 20.000000000000014, -120.70000000000041, 116.29999999999953, 20.000000000000014, -175.3000000000006, 20.000000000000014, -121.60000000000042, 1.0999999999999865, -30.399999999999757, 18.8, 6.1999999999999655, 13.699999999999964, 9.199999999999932, 11.599999999999964, 20.000000000000014, -254.70000000000036, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 16.69999999999997, 7.399999999999965, 15.799999999999963, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -15.699999999999747, 1.0999999999999865, 51.20000000000019, 20.000000000000014, 23.600000000000072, 28.100000000000147, -7.299999999999891, 7.399999999999947, 28.100000000000147, -11.499999999999819, -3.099999999999958, 114.49999999999957, 20.000000000000014, -5.199999999999948, 192.8, -24.099999999999746, 9.499999999999964, -400.0, -177.39999999999992, 5.599999999999975, 20.000000000000014, 20.300000000000022, -3.099999999999958, 20.000000000000014, 19.099999999999994, 20.000000000000014, -4.299999999999942, 45.20000000000023, -179.50000000000057, 5.299999999999965, 176.0, 15.799999999999963, -376.29999999999984, 5.299999999999965, -17.79999999999974, 20.000000000000014, 1.0999999999999865, 158.89999999999998, 23.600000000000065, -83.80000000000013, -357.99999999999955, 185.6, 9.499999999999964, -13.599999999999783, 3.1999999999999615, -93.40000000000002, 20.000000000000014, -85.00000000000074, 47.000000000000234, 13.699999999999964, 162.2, -397.9, 123.2, -11.499999999999854, 168.5, 159.5, 20.000000000000014, 26.000000000000114, -31.60000000000005, 96.49999999999997, 9.499999999999964, 20.000000000000014, -17.79999999999974, 143.0, -1.2999999999999994, -80.80000000000081, 25.4000000000001, 20.000000000000014, 5.299999999999965, 191.89999999999998, 8.599999999999968, -5.1999999999999265, -26.199999999999747, 15.799999999999963, 15.799999999999963, -17.79999999999974, -120.40000000000009, 20.000000000000014, 20.000000000000014, 13.699999999999964, -10.599999999999836, 20.000000000000014, 1.0999999999999865, 13.699999999999966, 14.599999999999968, 157.1, -21.999999999999744, 13.699999999999964, -0.9999999999999846, -28.29999999999975, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, -15.999999999999993, 146.0, 174.2, 31.10000000000021, -361.2999999999998, -101.2000000000005, 163.1, 157.39999999999998, 20.000000000000014, 20.000000000000014, 24.200000000000085, 178.7, -259.6, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 119.0, 155.0, 164.0, 9.499999999999964, 50.60000000000019, -11.499999999999819, 11.599999999999966, 48.80000000000012, 3.1999999999999615, 20.000000000000014, 27.500000000000142, 2.599999999999961, 13.699999999999964, 176.0, 1.0999999999999865, 125.3, 20.000000000000014, 1.0999999999999865, -45.09999999999976, 91.1, 7.999999999999886, -0.9999999999999846, 198.2, 7.399999999999965, -13.59999999999979, 4.399999999999977, 194.6, -9.399999999999855, 123.2, 3.1999999999999615, 15.799999999999963, 188.3, 56.0000000000001, 82.99999999999994, 125.00000000000001, 36.20000000000025, 24.200000000000088, -0.9999999999999846, 84.79999999999936, 15.499999999999961, 1.0999999999999865, 137.0, 18.5, 20.000000000000014, -5.1999999999999265, -3.099999999999958, -0.9999999999999846, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -22.599999999999767, 20.000000000000014, 161.0, 194.0], "policy_predator_policy_reward": [7.0, 3.0, 5.0, 13.0, 15.0, 14.0, 10.0, 0.0, 6.0, 67.0, 92.0, 92.0, 84.0, 84.0, 25.0, 8.0, 7.0, 14.0, 3.0, 60.0, 0.0, 4.0, 81.0, 126.0, 12.0, 0.0, 2.0, 6.0, 2.0, 15.0, 5.0, 12.0, 7.0, 6.0, 7.0, 14.0, 10.0, 9.0, 1.0, 6.0, 11.0, 12.0, 6.0, 0.0, 9.0, 15.0, 0.0, 6.0, 12.0, 0.0, 19.0, 7.0, 11.0, 200.0, 15.0, 1.0, 11.0, 2.0, 2.0, 60.0, 29.0, 26.0, 95.0, 11.0, 9.0, 6.0, 29.0, 181.0, 18.0, 7.0, 0.0, 9.0, 10.0, 10.0, 180.0, 34.0, 1.0, 5.0, 8.0, 16.0, 45.0, 50.0, 26.0, 30.0, 3.0, 0.0, 185.0, 193.0, 2.0, 15.0, 3.0, 12.0, 55.0, 59.0, 0.0, 5.0, 3.0, 18.0, 14.0, 22.0, 45.0, 14.0, 7.0, 0.0, 3.0, 8.0, 22.0, 7.0, 2.0, 2.0, 18.0, 80.0, 0.0, 0.0, 16.0, 2.0, 9.0, 7.0, 6.0, 3.0, 20.0, 14.0, 10.0, 3.0, 14.0, 23.0, 5.0, 1.0, 29.0, 31.0, 9.0, 18.0, 153.0, 45.0, 43.0, 43.0, 0.0, 13.0, 1.0, 7.0, 20.0, 132.0, 2.0, 8.0, 4.0, 27.0, 17.0, 10.0, 5.0, 5.0, 14.0, 7.0, 7.0, 8.0, 2.0, 3.0, 3.0, 10.0, 9.0, 8.0, 0.0, 0.0, 22.0, 18.0, 37.0, 57.0, 10.0, 9.0, 6.0, 16.0, 1.0, 10.0, 20.0, 21.0, 2.0, 8.0, 24.0, 0.0, 33.0, 15.0, 7.0, 8.0, 8.0, 10.0, 6.0, 9.0, 58.0, 27.0, 12.0, 11.0, 11.0, 10.0, 10.0, 8.0, 0.0, 0.0, 15.0, 25.0, 7.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5451569281422699, "mean_inference_ms": 1.4058580750988492, "mean_action_processing_ms": 0.23312916386904917, "mean_env_wait_ms": 0.17930262121707546, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038956403732299805, "StateBufferConnector_ms": 0.002809882164001465, "ViewRequirementAgentConnector_ms": 0.08322501182556152}, "num_episodes": 18, "episode_return_max": 373.0, "episode_return_min": -366.4000000000003, "episode_return_mean": 80.2879999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 448.640988555938, "num_env_steps_trained_throughput_per_sec": 448.640988555938, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 9025.143, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9025.104, "sample_time_ms": 1016.885, "learn_time_ms": 7995.789, "learn_throughput": 500.263, "synch_weights_time_ms": 11.604}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-35-34", "timestamp": 1723646134, "time_this_iter_s": 8.918979167938232, "time_total_s": 654.3164813518524, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 654.3164813518524, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 25.56153846153847, "ram_util_percent": 76.67692307692309}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9691583939330286, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 0.00010000000000000003, "total_loss": 4.969101291232639, "policy_loss": -0.008727681992708573, "vf_loss": 4.976334971347183, "vf_explained_var": 0.8394244577518847, "kl": 0.009959991850036586, "entropy": 0.7199915510321421, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8908142570149962, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 0.7978445541291009, "policy_loss": -0.00964667364651899, "vf_loss": 0.8063404520904577, "vf_explained_var": -0.3844118473075685, "kl": 0.005753864151720143, "entropy": 1.0371260272132026, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 378.2, "episode_reward_min": -366.4000000000003, "episode_reward_mean": 119.21299999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 40.266500000000015, "predator_policy": 19.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [140.4999999999989, 199.59999999999937, 11.400000000000063, -366.4000000000003, 41.60000000000033, 30.20000000000015, 101.09999999999997, 70.69999999999992, -28.29999999999967, 196.2999999999994, -150.5000000000007, 12.500000000000052, 30.100000000000147, 202.4999999999993, -227.80000000000075, 201.09999999999934, 13.60000000000004, 21.60000000000021, 17.99999999999996, 178.89999999999947, 103.3, 173.9999999999995, 194.4999999999994, 108.3999999999998, 110.99999999999977, 23.200000000000028, 177.69999999999948, 3.6000000000001062, 32.30000000000018, 211.49999999999926, -2.3999999999997157, 35.600000000000236, -40.199999999999925, 40.0000000000003, 21.099999999999987, 37.10000000000026, 37.30000000000026, 169.0999999999995, 25.700000000000067, 184.69999999999945, 35.500000000000234, 30.39999999999996, 347.2, -132.20000000000053, 147.90000000000003, 190.39999999999935, 52.200000000000465, 71.1, 33.2000000000002, 169.99999999999952, 346.0, 70.09999999999998, 21.099999999999994, 67.00000000000006, 52.5000000000005, 29.300000000000136, 194.09999999999937, 145.2999999999996, -3.999999999999703, 193.09999999999997, 216.19999999999928, 15.799999999999983, 209.99999999999932, 154.7999999999996, 29.000000000000124, 268.29999999999995, 256.00000000000006, 75.39999999999966, 101.7999999999987, 31.600000000000176, 240.5, 37.80000000000027, 16.900000000000002, 207.99999999999932, 40.0000000000003, 37.4000000000001, 373.0, 377.4, 192.99999999999937, 365.70000000000005, 202.1999999999993, 353.0, 224.39999999999924, 212.59999999999997, 332.3, 378.2, 342.6, 261.2999999999994, 170.4999999999995, 222.8999999999992, 92.89999999999914, 292.0, 4.500000000000151, 26.800000000000086, 209.5999999999993, 205.59999999999934, 48.100000000000435, 237.09999999999914, 236.99999999999912, 214.69999999999928], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [114.49999999999957, 20.000000000000014, -5.199999999999948, 192.8, -24.099999999999746, 9.499999999999964, -400.0, -177.39999999999992, 5.599999999999975, 20.000000000000014, 20.300000000000022, -3.099999999999958, 20.000000000000014, 19.099999999999994, 20.000000000000014, -4.299999999999942, 45.20000000000023, -179.50000000000057, 5.299999999999965, 176.0, 15.799999999999963, -376.29999999999984, 5.299999999999965, -17.79999999999974, 20.000000000000014, 1.0999999999999865, 158.89999999999998, 23.600000000000065, -83.80000000000013, -357.99999999999955, 185.6, 9.499999999999964, -13.599999999999783, 3.1999999999999615, -93.40000000000002, 20.000000000000014, -85.00000000000074, 47.000000000000234, 13.699999999999964, 162.2, -397.9, 123.2, -11.499999999999854, 168.5, 159.5, 20.000000000000014, 26.000000000000114, -31.60000000000005, 96.49999999999997, 9.499999999999964, 20.000000000000014, -17.79999999999974, 143.0, -1.2999999999999994, -80.80000000000081, 25.4000000000001, 20.000000000000014, 5.299999999999965, 191.89999999999998, 8.599999999999968, -5.1999999999999265, -26.199999999999747, 15.799999999999963, 15.799999999999963, -17.79999999999974, -120.40000000000009, 20.000000000000014, 20.000000000000014, 13.699999999999964, -10.599999999999836, 20.000000000000014, 1.0999999999999865, 13.699999999999966, 14.599999999999968, 157.1, -21.999999999999744, 13.699999999999964, -0.9999999999999846, -28.29999999999975, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, -15.999999999999993, 146.0, 174.2, 31.10000000000021, -361.2999999999998, -101.2000000000005, 163.1, 157.39999999999998, 20.000000000000014, 20.000000000000014, 24.200000000000085, 178.7, -259.6, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 119.0, 155.0, 164.0, 9.499999999999964, 50.60000000000019, -11.499999999999819, 11.599999999999966, 48.80000000000012, 3.1999999999999615, 20.000000000000014, 27.500000000000142, 2.599999999999961, 13.699999999999964, 176.0, 1.0999999999999865, 125.3, 20.000000000000014, 1.0999999999999865, -45.09999999999976, 91.1, 7.999999999999886, -0.9999999999999846, 198.2, 7.399999999999965, -13.59999999999979, 4.399999999999977, 194.6, -9.399999999999855, 123.2, 3.1999999999999615, 15.799999999999963, 188.3, 56.0000000000001, 82.99999999999994, 125.00000000000001, 36.20000000000025, 24.200000000000088, -0.9999999999999846, 84.79999999999936, 15.499999999999961, 1.0999999999999865, 137.0, 18.5, 20.000000000000014, -5.1999999999999265, -3.099999999999958, -0.9999999999999846, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -22.599999999999767, 20.000000000000014, 161.0, 194.0, 182.3, 190.1, 146.0, 20.000000000000014, 197.0, 163.7, 178.39999999999998, 15.799999999999963, 161.0, 167.0, 197.0, 25.400000000000098, 60.19999999999999, 49.39999999999997, 188.9, 112.40000000000002, 195.2, 152.0, 129.50000000000003, 181.1, 48.20000000000019, 199.1, 159.5, -0.9999999999999846, 29.600000000000183, 185.3, 11.599999999999964, 71.29999999999957, 74.0, 140.0, 11.599999999999977, -45.09999999999976, 13.699999999999964, 1.0999999999999794, 11.599999999999964, 191.0, 20.000000000000014, 170.6, 16.099999999999955, 20.000000000000014, 37.10000000000026, 200.0, 182.9, 49.10000000000023, 200.0, -7.299999999999891], "policy_predator_policy_reward": [0.0, 6.0, 12.0, 0.0, 19.0, 7.0, 11.0, 200.0, 15.0, 1.0, 11.0, 2.0, 2.0, 60.0, 29.0, 26.0, 95.0, 11.0, 9.0, 6.0, 29.0, 181.0, 18.0, 7.0, 0.0, 9.0, 10.0, 10.0, 180.0, 34.0, 1.0, 5.0, 8.0, 16.0, 45.0, 50.0, 26.0, 30.0, 3.0, 0.0, 185.0, 193.0, 2.0, 15.0, 3.0, 12.0, 55.0, 59.0, 0.0, 5.0, 3.0, 18.0, 14.0, 22.0, 45.0, 14.0, 7.0, 0.0, 3.0, 8.0, 22.0, 7.0, 2.0, 2.0, 18.0, 80.0, 0.0, 0.0, 16.0, 2.0, 9.0, 7.0, 6.0, 3.0, 20.0, 14.0, 10.0, 3.0, 14.0, 23.0, 5.0, 1.0, 29.0, 31.0, 9.0, 18.0, 153.0, 45.0, 43.0, 43.0, 0.0, 13.0, 1.0, 7.0, 20.0, 132.0, 2.0, 8.0, 4.0, 27.0, 17.0, 10.0, 5.0, 5.0, 14.0, 7.0, 7.0, 8.0, 2.0, 3.0, 3.0, 10.0, 9.0, 8.0, 0.0, 0.0, 22.0, 18.0, 37.0, 57.0, 10.0, 9.0, 6.0, 16.0, 1.0, 10.0, 20.0, 21.0, 2.0, 8.0, 24.0, 0.0, 33.0, 15.0, 7.0, 8.0, 8.0, 10.0, 6.0, 9.0, 58.0, 27.0, 12.0, 11.0, 11.0, 10.0, 10.0, 8.0, 0.0, 0.0, 15.0, 25.0, 7.0, 11.0, 2.0, 3.0, 18.0, 9.0, 4.0, 1.0, 2.0, 6.0, 13.0, 12.0, 1.0, 1.0, 56.0, 47.0, 6.0, 25.0, 16.0, 15.0, 16.0, 16.0, 3.0, 11.0, 3.0, 9.0, 7.0, 1.0, 4.0, 6.0, 36.0, 42.0, 34.0, 4.0, 3.0, 9.0, 6.0, 1.0, 7.0, 8.0, 7.0, 5.0, 0.0, 0.0, 2.0, 3.0, 9.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.544159749299819, "mean_inference_ms": 1.403086268277578, "mean_action_processing_ms": 0.23264879399457616, "mean_env_wait_ms": 0.1788853672025228, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0044209957122802734, "StateBufferConnector_ms": 0.00284576416015625, "ViewRequirementAgentConnector_ms": 0.08430397510528564}, "num_episodes": 23, "episode_return_max": 378.2, "episode_return_min": -366.4000000000003, "episode_return_mean": 119.21299999999981, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 442.9935830788294, "num_env_steps_trained_throughput_per_sec": 442.9935830788294, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 9005.964, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9005.925, "sample_time_ms": 1013.674, "learn_time_ms": 7979.985, "learn_throughput": 501.254, "synch_weights_time_ms": 11.459}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-35-44", "timestamp": 1723646144, "time_this_iter_s": 9.032379150390625, "time_total_s": 663.348860502243, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aad30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 663.348860502243, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 27.933333333333334, "ram_util_percent": 76.67500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.489536994790274, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 0.00010000000000000003, "total_loss": 4.273934980927321, "policy_loss": -0.007369440761591904, "vf_loss": 4.280014959214226, "vf_explained_var": 0.8868362305656312, "kl": 0.008596372018217625, "entropy": 0.6518102114793485, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.088565507420787, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 0.5620459394085975, "policy_loss": -0.013705105951090377, "vf_loss": 0.5740267992522272, "vf_explained_var": 0.10417267238652264, "kl": 0.00862123257707483, "entropy": 1.0119272749259989, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 378.2, "episode_reward_min": -132.20000000000053, "episode_reward_mean": 154.5919999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": 61.106000000000016, "predator_policy": 16.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.99999999999996, 178.89999999999947, 103.3, 173.9999999999995, 194.4999999999994, 108.3999999999998, 110.99999999999977, 23.200000000000028, 177.69999999999948, 3.6000000000001062, 32.30000000000018, 211.49999999999926, -2.3999999999997157, 35.600000000000236, -40.199999999999925, 40.0000000000003, 21.099999999999987, 37.10000000000026, 37.30000000000026, 169.0999999999995, 25.700000000000067, 184.69999999999945, 35.500000000000234, 30.39999999999996, 347.2, -132.20000000000053, 147.90000000000003, 190.39999999999935, 52.200000000000465, 71.1, 33.2000000000002, 169.99999999999952, 346.0, 70.09999999999998, 21.099999999999994, 67.00000000000006, 52.5000000000005, 29.300000000000136, 194.09999999999937, 145.2999999999996, -3.999999999999703, 193.09999999999997, 216.19999999999928, 15.799999999999983, 209.99999999999932, 154.7999999999996, 29.000000000000124, 268.29999999999995, 256.00000000000006, 75.39999999999966, 101.7999999999987, 31.600000000000176, 240.5, 37.80000000000027, 16.900000000000002, 207.99999999999932, 40.0000000000003, 37.4000000000001, 373.0, 377.4, 192.99999999999937, 365.70000000000005, 202.1999999999993, 353.0, 224.39999999999924, 212.59999999999997, 332.3, 378.2, 342.6, 261.2999999999994, 170.4999999999995, 222.8999999999992, 92.89999999999914, 292.0, 4.500000000000151, 26.800000000000086, 209.5999999999993, 205.59999999999934, 48.100000000000435, 237.09999999999914, 236.99999999999912, 214.69999999999928, 286.40000000000003, 136.5999999999997, 344.9, 178.59999999999914, 180.39999999999947, 192.89999999999938, 362.7, 265.89999999999986, 22.400000000000013, 356.0, 167.89999999999952, 319.5, 313.4, 342.8, 164.79999999999956, 199.99999999999935, -0.7999999999997288, 203.29999999999933], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-85.00000000000074, 47.000000000000234, 13.699999999999964, 162.2, -397.9, 123.2, -11.499999999999854, 168.5, 159.5, 20.000000000000014, 26.000000000000114, -31.60000000000005, 96.49999999999997, 9.499999999999964, 20.000000000000014, -17.79999999999974, 143.0, -1.2999999999999994, -80.80000000000081, 25.4000000000001, 20.000000000000014, 5.299999999999965, 191.89999999999998, 8.599999999999968, -5.1999999999999265, -26.199999999999747, 15.799999999999963, 15.799999999999963, -17.79999999999974, -120.40000000000009, 20.000000000000014, 20.000000000000014, 13.699999999999964, -10.599999999999836, 20.000000000000014, 1.0999999999999865, 13.699999999999966, 14.599999999999968, 157.1, -21.999999999999744, 13.699999999999964, -0.9999999999999846, -28.29999999999975, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, -15.999999999999993, 146.0, 174.2, 31.10000000000021, -361.2999999999998, -101.2000000000005, 163.1, 157.39999999999998, 20.000000000000014, 20.000000000000014, 24.200000000000085, 178.7, -259.6, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 119.0, 155.0, 164.0, 9.499999999999964, 50.60000000000019, -11.499999999999819, 11.599999999999966, 48.80000000000012, 3.1999999999999615, 20.000000000000014, 27.500000000000142, 2.599999999999961, 13.699999999999964, 176.0, 1.0999999999999865, 125.3, 20.000000000000014, 1.0999999999999865, -45.09999999999976, 91.1, 7.999999999999886, -0.9999999999999846, 198.2, 7.399999999999965, -13.59999999999979, 4.399999999999977, 194.6, -9.399999999999855, 123.2, 3.1999999999999615, 15.799999999999963, 188.3, 56.0000000000001, 82.99999999999994, 125.00000000000001, 36.20000000000025, 24.200000000000088, -0.9999999999999846, 84.79999999999936, 15.499999999999961, 1.0999999999999865, 137.0, 18.5, 20.000000000000014, -5.1999999999999265, -3.099999999999958, -0.9999999999999846, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -22.599999999999767, 20.000000000000014, 161.0, 194.0, 182.3, 190.1, 146.0, 20.000000000000014, 197.0, 163.7, 178.39999999999998, 15.799999999999963, 161.0, 167.0, 197.0, 25.400000000000098, 60.19999999999999, 49.39999999999997, 188.9, 112.40000000000002, 195.2, 152.0, 129.50000000000003, 181.1, 48.20000000000019, 199.1, 159.5, -0.9999999999999846, 29.600000000000183, 185.3, 11.599999999999964, 71.29999999999957, 74.0, 140.0, 11.599999999999977, -45.09999999999976, 13.699999999999964, 1.0999999999999794, 11.599999999999964, 191.0, 20.000000000000014, 170.6, 16.099999999999955, 20.000000000000014, 37.10000000000026, 200.0, 182.9, 49.10000000000023, 200.0, -7.299999999999891, 106.70000000000007, 154.70000000000002, 79.4, 3.1999999999999615, 173.0, 143.9, 151.69999999999982, 17.899999999999988, 128.0, 22.40000000000006, 119.0, 41.90000000000024, 127.70000000000002, 197.0, 149.60000000000002, 71.3, 17.899999999999988, -11.499999999999822, 171.8, 171.2, 128.3, -3.3999999999999866, 146.3, 135.2, 169.39999999999998, 107.0, 171.2, 167.6, 125.3, 9.499999999999964, 170.0, 20.000000000000014, -5.1999999999999265, -13.599999999999786, 185.6, -7.299999999999891], "policy_predator_policy_reward": [26.0, 30.0, 3.0, 0.0, 185.0, 193.0, 2.0, 15.0, 3.0, 12.0, 55.0, 59.0, 0.0, 5.0, 3.0, 18.0, 14.0, 22.0, 45.0, 14.0, 7.0, 0.0, 3.0, 8.0, 22.0, 7.0, 2.0, 2.0, 18.0, 80.0, 0.0, 0.0, 16.0, 2.0, 9.0, 7.0, 6.0, 3.0, 20.0, 14.0, 10.0, 3.0, 14.0, 23.0, 5.0, 1.0, 29.0, 31.0, 9.0, 18.0, 153.0, 45.0, 43.0, 43.0, 0.0, 13.0, 1.0, 7.0, 20.0, 132.0, 2.0, 8.0, 4.0, 27.0, 17.0, 10.0, 5.0, 5.0, 14.0, 7.0, 7.0, 8.0, 2.0, 3.0, 3.0, 10.0, 9.0, 8.0, 0.0, 0.0, 22.0, 18.0, 37.0, 57.0, 10.0, 9.0, 6.0, 16.0, 1.0, 10.0, 20.0, 21.0, 2.0, 8.0, 24.0, 0.0, 33.0, 15.0, 7.0, 8.0, 8.0, 10.0, 6.0, 9.0, 58.0, 27.0, 12.0, 11.0, 11.0, 10.0, 10.0, 8.0, 0.0, 0.0, 15.0, 25.0, 7.0, 11.0, 2.0, 3.0, 18.0, 9.0, 4.0, 1.0, 2.0, 6.0, 13.0, 12.0, 1.0, 1.0, 56.0, 47.0, 6.0, 25.0, 16.0, 15.0, 16.0, 16.0, 3.0, 11.0, 3.0, 9.0, 7.0, 1.0, 4.0, 6.0, 36.0, 42.0, 34.0, 4.0, 3.0, 9.0, 6.0, 1.0, 7.0, 8.0, 7.0, 5.0, 0.0, 0.0, 2.0, 3.0, 9.0, 13.0, 8.0, 17.0, 15.0, 39.0, 19.0, 9.0, 4.0, 5.0, 6.0, 24.0, 15.0, 17.0, 22.0, 16.0, 33.0, 12.0, 15.0, 1.0, 6.0, 7.0, 25.0, 18.0, 21.0, 17.0, 6.0, 31.0, 1.0, 3.0, 5.0, 25.0, 0.0, 10.0, 18.0, 0.0, 13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5433743627301859, "mean_inference_ms": 1.4008875470836337, "mean_action_processing_ms": 0.23227767513826214, "mean_env_wait_ms": 0.17856067520840035, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004419207572937012, "StateBufferConnector_ms": 0.002893209457397461, "ViewRequirementAgentConnector_ms": 0.08716928958892822}, "num_episodes": 18, "episode_return_max": 378.2, "episode_return_min": -132.20000000000053, "episode_return_mean": 154.5919999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 445.5613240859325, "num_env_steps_trained_throughput_per_sec": 445.5613240859325, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 8988.396, "restore_workers_time_ms": 0.014, "training_step_time_ms": 8988.358, "sample_time_ms": 1010.321, "learn_time_ms": 7965.89, "learn_throughput": 502.141, "synch_weights_time_ms": 11.371}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-35-53", "timestamp": 1723646153, "time_this_iter_s": 8.98016095161438, "time_total_s": 672.3290214538574, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0eb790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 672.3290214538574, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 26.307692307692307, "ram_util_percent": 76.63076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6024567741880973, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 0.00010000000000000003, "total_loss": 2.6539937907425815, "policy_loss": -0.006139467722889056, "vf_loss": 2.659405615531578, "vf_explained_var": 0.8989482005121847, "kl": 0.004850951467815883, "entropy": 0.8037192209372445, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3695311583539165, "cur_kl_coeff": 0.2, "cur_lr": 0.00010000000000000003, "total_loss": 0.5486418665322678, "policy_loss": -0.0034317538161914816, "vf_loss": 0.5514435176831232, "vf_explained_var": 0.04255010895628147, "kl": 0.003150511696971776, "entropy": 1.0366020747593472, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 379.1, "episode_reward_min": -132.20000000000053, "episode_reward_mean": 172.81299999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -361.2999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": 72.90650000000001, "predator_policy": 13.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.30000000000026, 169.0999999999995, 25.700000000000067, 184.69999999999945, 35.500000000000234, 30.39999999999996, 347.2, -132.20000000000053, 147.90000000000003, 190.39999999999935, 52.200000000000465, 71.1, 33.2000000000002, 169.99999999999952, 346.0, 70.09999999999998, 21.099999999999994, 67.00000000000006, 52.5000000000005, 29.300000000000136, 194.09999999999937, 145.2999999999996, -3.999999999999703, 193.09999999999997, 216.19999999999928, 15.799999999999983, 209.99999999999932, 154.7999999999996, 29.000000000000124, 268.29999999999995, 256.00000000000006, 75.39999999999966, 101.7999999999987, 31.600000000000176, 240.5, 37.80000000000027, 16.900000000000002, 207.99999999999932, 40.0000000000003, 37.4000000000001, 373.0, 377.4, 192.99999999999937, 365.70000000000005, 202.1999999999993, 353.0, 224.39999999999924, 212.59999999999997, 332.3, 378.2, 342.6, 261.2999999999994, 170.4999999999995, 222.8999999999992, 92.89999999999914, 292.0, 4.500000000000151, 26.800000000000086, 209.5999999999993, 205.59999999999934, 48.100000000000435, 237.09999999999914, 236.99999999999912, 214.69999999999928, 286.40000000000003, 136.5999999999997, 344.9, 178.59999999999914, 180.39999999999947, 192.89999999999938, 362.7, 265.89999999999986, 22.400000000000013, 356.0, 167.89999999999952, 319.5, 313.4, 342.8, 164.79999999999956, 199.99999999999935, -0.7999999999997288, 203.29999999999933, 39.800000000000296, 32.30000000000018, 193.7999999999994, 46.400000000000404, 24.60000000000005, 20.199999999999985, 153.39999999999958, 204.99999999999935, 379.1, 274.8, 188.8999999999994, 236.99999999999923, 337.0, 33.4000000000002, 244.8999999999992, 314.0, 154.69999999999962, 370.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999966, 14.599999999999968, 157.1, -21.999999999999744, 13.699999999999964, -0.9999999999999846, -28.29999999999975, 176.0, 9.499999999999964, 20.000000000000014, -13.599999999999783, -15.999999999999993, 146.0, 174.2, 31.10000000000021, -361.2999999999998, -101.2000000000005, 163.1, 157.39999999999998, 20.000000000000014, 20.000000000000014, 24.200000000000085, 178.7, -259.6, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 119.0, 155.0, 164.0, 9.499999999999964, 50.60000000000019, -11.499999999999819, 11.599999999999966, 48.80000000000012, 3.1999999999999615, 20.000000000000014, 27.500000000000142, 2.599999999999961, 13.699999999999964, 176.0, 1.0999999999999865, 125.3, 20.000000000000014, 1.0999999999999865, -45.09999999999976, 91.1, 7.999999999999886, -0.9999999999999846, 198.2, 7.399999999999965, -13.59999999999979, 4.399999999999977, 194.6, -9.399999999999855, 123.2, 3.1999999999999615, 15.799999999999963, 188.3, 56.0000000000001, 82.99999999999994, 125.00000000000001, 36.20000000000025, 24.200000000000088, -0.9999999999999846, 84.79999999999936, 15.499999999999961, 1.0999999999999865, 137.0, 18.5, 20.000000000000014, -5.1999999999999265, -3.099999999999958, -0.9999999999999846, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -22.599999999999767, 20.000000000000014, 161.0, 194.0, 182.3, 190.1, 146.0, 20.000000000000014, 197.0, 163.7, 178.39999999999998, 15.799999999999963, 161.0, 167.0, 197.0, 25.400000000000098, 60.19999999999999, 49.39999999999997, 188.9, 112.40000000000002, 195.2, 152.0, 129.50000000000003, 181.1, 48.20000000000019, 199.1, 159.5, -0.9999999999999846, 29.600000000000183, 185.3, 11.599999999999964, 71.29999999999957, 74.0, 140.0, 11.599999999999977, -45.09999999999976, 13.699999999999964, 1.0999999999999794, 11.599999999999964, 191.0, 20.000000000000014, 170.6, 16.099999999999955, 20.000000000000014, 37.10000000000026, 200.0, 182.9, 49.10000000000023, 200.0, -7.299999999999891, 106.70000000000007, 154.70000000000002, 79.4, 3.1999999999999615, 173.0, 143.9, 151.69999999999982, 17.899999999999988, 128.0, 22.40000000000006, 119.0, 41.90000000000024, 127.70000000000002, 197.0, 149.60000000000002, 71.3, 17.899999999999988, -11.499999999999822, 171.8, 171.2, 128.3, -3.3999999999999866, 146.3, 135.2, 169.39999999999998, 107.0, 171.2, 167.6, 125.3, 9.499999999999964, 170.0, 20.000000000000014, -5.1999999999999265, -13.599999999999786, 185.6, -7.299999999999891, 21.80000000000004, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 98.0, 57.800000000000225, 25.400000000000098, 16.999999999999975, 17.899999999999988, -7.299999999999891, 17.899999999999988, -15.699999999999768, 20.000000000000014, 121.39999999999998, 29.000000000000163, 164.0, 169.1, 200.0, 194.60000000000002, 21.200000000000003, 15.799999999999963, 157.1, 59.9000000000002, 172.1, 167.0, 149.0, 11.599999999999964, 15.799999999999963, 170.0, 56.9000000000002, 194.0, 77.0, 115.4, 5.299999999999965, 163.39999999999998, 194.0], "policy_predator_policy_reward": [6.0, 3.0, 20.0, 14.0, 10.0, 3.0, 14.0, 23.0, 5.0, 1.0, 29.0, 31.0, 9.0, 18.0, 153.0, 45.0, 43.0, 43.0, 0.0, 13.0, 1.0, 7.0, 20.0, 132.0, 2.0, 8.0, 4.0, 27.0, 17.0, 10.0, 5.0, 5.0, 14.0, 7.0, 7.0, 8.0, 2.0, 3.0, 3.0, 10.0, 9.0, 8.0, 0.0, 0.0, 22.0, 18.0, 37.0, 57.0, 10.0, 9.0, 6.0, 16.0, 1.0, 10.0, 20.0, 21.0, 2.0, 8.0, 24.0, 0.0, 33.0, 15.0, 7.0, 8.0, 8.0, 10.0, 6.0, 9.0, 58.0, 27.0, 12.0, 11.0, 11.0, 10.0, 10.0, 8.0, 0.0, 0.0, 15.0, 25.0, 7.0, 11.0, 2.0, 3.0, 18.0, 9.0, 4.0, 1.0, 2.0, 6.0, 13.0, 12.0, 1.0, 1.0, 56.0, 47.0, 6.0, 25.0, 16.0, 15.0, 16.0, 16.0, 3.0, 11.0, 3.0, 9.0, 7.0, 1.0, 4.0, 6.0, 36.0, 42.0, 34.0, 4.0, 3.0, 9.0, 6.0, 1.0, 7.0, 8.0, 7.0, 5.0, 0.0, 0.0, 2.0, 3.0, 9.0, 13.0, 8.0, 17.0, 15.0, 39.0, 19.0, 9.0, 4.0, 5.0, 6.0, 24.0, 15.0, 17.0, 22.0, 16.0, 33.0, 12.0, 15.0, 1.0, 6.0, 7.0, 25.0, 18.0, 21.0, 17.0, 6.0, 31.0, 1.0, 3.0, 5.0, 25.0, 0.0, 10.0, 18.0, 0.0, 13.0, 12.0, 9.0, 10.0, 7.0, 0.0, 5.0, 33.0, 4.0, 0.0, 1.0, 13.0, 1.0, 17.0, 5.0, 7.0, 12.0, 0.0, 0.0, 10.0, 43.0, 16.0, 14.0, 2.0, 0.0, 5.0, 4.0, 17.0, 2.0, 4.0, 10.0, 8.0, 40.0, 3.0, 7.0, 27.0, 5.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5426220213572657, "mean_inference_ms": 1.3988088873892404, "mean_action_processing_ms": 0.23192023472937456, "mean_env_wait_ms": 0.17824257487063547, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004861950874328613, "StateBufferConnector_ms": 0.002900242805480957, "ViewRequirementAgentConnector_ms": 0.08651411533355713}, "num_episodes": 18, "episode_return_max": 379.1, "episode_return_min": -132.20000000000053, "episode_return_mean": 172.81299999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 445.7667805969574, "num_env_steps_trained_throughput_per_sec": 445.7667805969574, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 8975.541, "restore_workers_time_ms": 0.014, "training_step_time_ms": 8975.502, "sample_time_ms": 1014.196, "learn_time_ms": 7949.214, "learn_throughput": 503.194, "synch_weights_time_ms": 11.31}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-36-02", "timestamp": 1723646162, "time_this_iter_s": 8.97804307937622, "time_total_s": 681.3070645332336, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aaee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 681.3070645332336, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 27.200000000000003, "ram_util_percent": 76.99230769230769}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5365880079685694, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 0.00010000000000000003, "total_loss": 3.2699493314223314, "policy_loss": -0.006815648159238869, "vf_loss": 3.276015186625183, "vf_explained_var": 0.8553129891869883, "kl": 0.009997365141615089, "entropy": 0.6745406720373366, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.60484918683925, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 0.837949582319411, "policy_loss": -0.008845383704457649, "vf_loss": 0.8460718060178416, "vf_explained_var": 0.09418752937720566, "kl": 0.007231584778836589, "entropy": 0.9691303489384828, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 392.8, "episode_reward_min": -3.999999999999703, "episode_reward_mean": 201.70199999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -45.09999999999976, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 58.0}, "policy_reward_mean": {"prey_policy": 89.38100000000003, "predator_policy": 11.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.999999999999703, 193.09999999999997, 216.19999999999928, 15.799999999999983, 209.99999999999932, 154.7999999999996, 29.000000000000124, 268.29999999999995, 256.00000000000006, 75.39999999999966, 101.7999999999987, 31.600000000000176, 240.5, 37.80000000000027, 16.900000000000002, 207.99999999999932, 40.0000000000003, 37.4000000000001, 373.0, 377.4, 192.99999999999937, 365.70000000000005, 202.1999999999993, 353.0, 224.39999999999924, 212.59999999999997, 332.3, 378.2, 342.6, 261.2999999999994, 170.4999999999995, 222.8999999999992, 92.89999999999914, 292.0, 4.500000000000151, 26.800000000000086, 209.5999999999993, 205.59999999999934, 48.100000000000435, 237.09999999999914, 236.99999999999912, 214.69999999999928, 286.40000000000003, 136.5999999999997, 344.9, 178.59999999999914, 180.39999999999947, 192.89999999999938, 362.7, 265.89999999999986, 22.400000000000013, 356.0, 167.89999999999952, 319.5, 313.4, 342.8, 164.79999999999956, 199.99999999999935, -0.7999999999997288, 203.29999999999933, 39.800000000000296, 32.30000000000018, 193.7999999999994, 46.400000000000404, 24.60000000000005, 20.199999999999985, 153.39999999999958, 204.99999999999935, 379.1, 274.8, 188.8999999999994, 236.99999999999923, 337.0, 33.4000000000002, 244.8999999999992, 314.0, 154.69999999999962, 370.4, 40.400000000000304, 216.39999999999927, 183.99999999999943, 177.7999999999995, 377.0, 183.99999999999943, 173.79999999999947, 388.0, 392.8, 372.4000000000001, 370.5, 209.8999999999993, 199.99999999999935, 303.9999999999999, 28.200000000000117, 269.2999999999996, 31.200000000000163, 330.9, 23.100000000000033, 304.0, 383.3, 215.79999999999927], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, -45.09999999999976, 91.1, 7.999999999999886, -0.9999999999999846, 198.2, 7.399999999999965, -13.59999999999979, 4.399999999999977, 194.6, -9.399999999999855, 123.2, 3.1999999999999615, 15.799999999999963, 188.3, 56.0000000000001, 82.99999999999994, 125.00000000000001, 36.20000000000025, 24.200000000000088, -0.9999999999999846, 84.79999999999936, 15.499999999999961, 1.0999999999999865, 137.0, 18.5, 20.000000000000014, -5.1999999999999265, -3.099999999999958, -0.9999999999999846, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -22.599999999999767, 20.000000000000014, 161.0, 194.0, 182.3, 190.1, 146.0, 20.000000000000014, 197.0, 163.7, 178.39999999999998, 15.799999999999963, 161.0, 167.0, 197.0, 25.400000000000098, 60.19999999999999, 49.39999999999997, 188.9, 112.40000000000002, 195.2, 152.0, 129.50000000000003, 181.1, 48.20000000000019, 199.1, 159.5, -0.9999999999999846, 29.600000000000183, 185.3, 11.599999999999964, 71.29999999999957, 74.0, 140.0, 11.599999999999977, -45.09999999999976, 13.699999999999964, 1.0999999999999794, 11.599999999999964, 191.0, 20.000000000000014, 170.6, 16.099999999999955, 20.000000000000014, 37.10000000000026, 200.0, 182.9, 49.10000000000023, 200.0, -7.299999999999891, 106.70000000000007, 154.70000000000002, 79.4, 3.1999999999999615, 173.0, 143.9, 151.69999999999982, 17.899999999999988, 128.0, 22.40000000000006, 119.0, 41.90000000000024, 127.70000000000002, 197.0, 149.60000000000002, 71.3, 17.899999999999988, -11.499999999999822, 171.8, 171.2, 128.3, -3.3999999999999866, 146.3, 135.2, 169.39999999999998, 107.0, 171.2, 167.6, 125.3, 9.499999999999964, 170.0, 20.000000000000014, -5.1999999999999265, -13.599999999999786, 185.6, -7.299999999999891, 21.80000000000004, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 98.0, 57.800000000000225, 25.400000000000098, 16.999999999999975, 17.899999999999988, -7.299999999999891, 17.899999999999988, -15.699999999999768, 20.000000000000014, 121.39999999999998, 29.000000000000163, 164.0, 169.1, 200.0, 194.60000000000002, 21.200000000000003, 15.799999999999963, 157.1, 59.9000000000002, 172.1, 167.0, 149.0, 11.599999999999964, 15.799999999999963, 170.0, 56.9000000000002, 194.0, 77.0, 115.4, 5.299999999999965, 163.39999999999998, 194.0, 29.60000000000018, -5.1999999999999265, 196.4, 20.000000000000014, 20.000000000000014, 107.0, 5.299999999999965, 150.5, 146.0, 200.0, 146.0, 20.000000000000014, 20.000000000000014, 138.8, 200.0, 176.0, 192.8, 200.0, 176.29999999999998, 193.1, 159.20000000000002, 197.3, 195.5, 7.399999999999965, 170.0, 20.000000000000014, 140.0, 128.00000000000003, -17.79999999999974, 20.000000000000014, 72.19999999999959, 187.1, 7.399999999999965, 15.799999999999963, 178.1, 132.80000000000004, 1.9999999999999607, 1.0999999999999865, 134.0, 119.0, 182.3, 194.0, 15.799999999999963, 197.0], "policy_predator_policy_reward": [22.0, 18.0, 37.0, 57.0, 10.0, 9.0, 6.0, 16.0, 1.0, 10.0, 20.0, 21.0, 2.0, 8.0, 24.0, 0.0, 33.0, 15.0, 7.0, 8.0, 8.0, 10.0, 6.0, 9.0, 58.0, 27.0, 12.0, 11.0, 11.0, 10.0, 10.0, 8.0, 0.0, 0.0, 15.0, 25.0, 7.0, 11.0, 2.0, 3.0, 18.0, 9.0, 4.0, 1.0, 2.0, 6.0, 13.0, 12.0, 1.0, 1.0, 56.0, 47.0, 6.0, 25.0, 16.0, 15.0, 16.0, 16.0, 3.0, 11.0, 3.0, 9.0, 7.0, 1.0, 4.0, 6.0, 36.0, 42.0, 34.0, 4.0, 3.0, 9.0, 6.0, 1.0, 7.0, 8.0, 7.0, 5.0, 0.0, 0.0, 2.0, 3.0, 9.0, 13.0, 8.0, 17.0, 15.0, 39.0, 19.0, 9.0, 4.0, 5.0, 6.0, 24.0, 15.0, 17.0, 22.0, 16.0, 33.0, 12.0, 15.0, 1.0, 6.0, 7.0, 25.0, 18.0, 21.0, 17.0, 6.0, 31.0, 1.0, 3.0, 5.0, 25.0, 0.0, 10.0, 18.0, 0.0, 13.0, 12.0, 9.0, 10.0, 7.0, 0.0, 5.0, 33.0, 4.0, 0.0, 1.0, 13.0, 1.0, 17.0, 5.0, 7.0, 12.0, 0.0, 0.0, 10.0, 43.0, 16.0, 14.0, 2.0, 0.0, 5.0, 4.0, 17.0, 2.0, 4.0, 10.0, 8.0, 40.0, 3.0, 7.0, 27.0, 5.0, 8.0, 12.0, 4.0, 0.0, 0.0, 26.0, 31.0, 7.0, 15.0, 13.0, 18.0, 18.0, 0.0, 0.0, 15.0, 8.0, 4.0, 0.0, 0.0, 2.0, 1.0, 5.0, 9.0, 6.0, 1.0, 10.0, 0.0, 22.0, 14.0, 11.0, 15.0, 4.0, 6.0, 4.0, 4.0, 9.0, 11.0, 15.0, 5.0, 30.0, 21.0, 5.0, 2.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5417625642042796, "mean_inference_ms": 1.3963655971487046, "mean_action_processing_ms": 0.23151732769443661, "mean_env_wait_ms": 0.17786487233420992, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00534510612487793, "StateBufferConnector_ms": 0.0029240846633911133, "ViewRequirementAgentConnector_ms": 0.08718526363372803}, "num_episodes": 22, "episode_return_max": 392.8, "episode_return_min": -3.999999999999703, "episode_return_mean": 201.70199999999974, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 448.6911182392985, "num_env_steps_trained_throughput_per_sec": 448.6911182392985, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 8975.434, "restore_workers_time_ms": 0.014, "training_step_time_ms": 8975.396, "sample_time_ms": 1009.304, "learn_time_ms": 7954.09, "learn_throughput": 502.886, "synch_weights_time_ms": 11.234}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-36-10", "timestamp": 1723646170, "time_this_iter_s": 8.91768193244934, "time_total_s": 690.224746465683, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aa670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 690.224746465683, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 26.184615384615377, "ram_util_percent": 77.12307692307694}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8039706071217854, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 0.00010000000000000003, "total_loss": 2.8996645083503116, "policy_loss": -0.012500883916530895, "vf_loss": 2.9095922593717223, "vf_explained_var": 0.7945147906346296, "kl": 0.03430848011363306, "entropy": 0.8349672136168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8861952727906919, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 0.9115260639203289, "policy_loss": -0.008299798440193098, "vf_loss": 0.9189546036262991, "vf_explained_var": 0.2318522140777931, "kl": 0.008712603590837644, "entropy": 0.8975783162646823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 392.8, "episode_reward_min": -0.7999999999997288, "episode_reward_mean": 217.2349999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -64.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 97.01750000000001, "predator_policy": 11.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.0, 224.39999999999924, 212.59999999999997, 332.3, 378.2, 342.6, 261.2999999999994, 170.4999999999995, 222.8999999999992, 92.89999999999914, 292.0, 4.500000000000151, 26.800000000000086, 209.5999999999993, 205.59999999999934, 48.100000000000435, 237.09999999999914, 236.99999999999912, 214.69999999999928, 286.40000000000003, 136.5999999999997, 344.9, 178.59999999999914, 180.39999999999947, 192.89999999999938, 362.7, 265.89999999999986, 22.400000000000013, 356.0, 167.89999999999952, 319.5, 313.4, 342.8, 164.79999999999956, 199.99999999999935, -0.7999999999997288, 203.29999999999933, 39.800000000000296, 32.30000000000018, 193.7999999999994, 46.400000000000404, 24.60000000000005, 20.199999999999985, 153.39999999999958, 204.99999999999935, 379.1, 274.8, 188.8999999999994, 236.99999999999923, 337.0, 33.4000000000002, 244.8999999999992, 314.0, 154.69999999999962, 370.4, 40.400000000000304, 216.39999999999927, 183.99999999999943, 177.7999999999995, 377.0, 183.99999999999943, 173.79999999999947, 388.0, 392.8, 372.4000000000001, 370.5, 209.8999999999993, 199.99999999999935, 303.9999999999999, 28.200000000000117, 269.2999999999996, 31.200000000000163, 330.9, 23.100000000000033, 304.0, 383.3, 215.79999999999927, 205.09999999999934, 207.7999999999993, 321.8, 349.0, 31.899999999999977, 198.59999999999937, 155.59999999999962, 206.5999999999993, 361.7, 308.7, 334.5, 52.9000000000004, 169.9999999999995, 382.4, 21.199999999999992, 332.20000000000005, 133.69999999999973, 211.9999999999993, 209.3999999999993, 326.20000000000005, 325.2, 182.19999999999945, 164.49999999999955], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [161.0, 167.0, 197.0, 25.400000000000098, 60.19999999999999, 49.39999999999997, 188.9, 112.40000000000002, 195.2, 152.0, 129.50000000000003, 181.1, 48.20000000000019, 199.1, 159.5, -0.9999999999999846, 29.600000000000183, 185.3, 11.599999999999964, 71.29999999999957, 74.0, 140.0, 11.599999999999977, -45.09999999999976, 13.699999999999964, 1.0999999999999794, 11.599999999999964, 191.0, 20.000000000000014, 170.6, 16.099999999999955, 20.000000000000014, 37.10000000000026, 200.0, 182.9, 49.10000000000023, 200.0, -7.299999999999891, 106.70000000000007, 154.70000000000002, 79.4, 3.1999999999999615, 173.0, 143.9, 151.69999999999982, 17.899999999999988, 128.0, 22.40000000000006, 119.0, 41.90000000000024, 127.70000000000002, 197.0, 149.60000000000002, 71.3, 17.899999999999988, -11.499999999999822, 171.8, 171.2, 128.3, -3.3999999999999866, 146.3, 135.2, 169.39999999999998, 107.0, 171.2, 167.6, 125.3, 9.499999999999964, 170.0, 20.000000000000014, -5.1999999999999265, -13.599999999999786, 185.6, -7.299999999999891, 21.80000000000004, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 98.0, 57.800000000000225, 25.400000000000098, 16.999999999999975, 17.899999999999988, -7.299999999999891, 17.899999999999988, -15.699999999999768, 20.000000000000014, 121.39999999999998, 29.000000000000163, 164.0, 169.1, 200.0, 194.60000000000002, 21.200000000000003, 15.799999999999963, 157.1, 59.9000000000002, 172.1, 167.0, 149.0, 11.599999999999964, 15.799999999999963, 170.0, 56.9000000000002, 194.0, 77.0, 115.4, 5.299999999999965, 163.39999999999998, 194.0, 29.60000000000018, -5.1999999999999265, 196.4, 20.000000000000014, 20.000000000000014, 107.0, 5.299999999999965, 150.5, 146.0, 200.0, 146.0, 20.000000000000014, 20.000000000000014, 138.8, 200.0, 176.0, 192.8, 200.0, 176.29999999999998, 193.1, 159.20000000000002, 197.3, 195.5, 7.399999999999965, 170.0, 20.000000000000014, 140.0, 128.00000000000003, -17.79999999999974, 20.000000000000014, 72.19999999999959, 187.1, 7.399999999999965, 15.799999999999963, 178.1, 132.80000000000004, 1.9999999999999607, 1.0999999999999865, 134.0, 119.0, 182.3, 194.0, 15.799999999999963, 197.0, -5.1999999999999265, 197.3, 13.699999999999964, 187.1, 131.0, 159.8, 128.3, 181.7, -3.099999999999965, -64.0, 29.000000000000167, 134.60000000000002, 110.0, 11.599999999999964, -9.399999999999855, 200.0, 190.1, 155.6, 130.7, 149.0, 143.0, 165.5, 18.200000000000017, 13.699999999999967, 152.89999999999998, 1.0999999999999865, 188.0, 187.39999999999995, 3.1999999999999615, -0.9999999999999846, 168.20000000000002, 134.0, 11.599999999999964, 61.099999999999994, 188.0, 20.000000000000014, 7.399999999999965, 188.0, 101.90000000000006, 197.3, 157.7, 135.5, 7.399999999999965, 156.8, 158.0, -32.49999999999975], "policy_predator_policy_reward": [13.0, 12.0, 1.0, 1.0, 56.0, 47.0, 6.0, 25.0, 16.0, 15.0, 16.0, 16.0, 3.0, 11.0, 3.0, 9.0, 7.0, 1.0, 4.0, 6.0, 36.0, 42.0, 34.0, 4.0, 3.0, 9.0, 6.0, 1.0, 7.0, 8.0, 7.0, 5.0, 0.0, 0.0, 2.0, 3.0, 9.0, 13.0, 8.0, 17.0, 15.0, 39.0, 19.0, 9.0, 4.0, 5.0, 6.0, 24.0, 15.0, 17.0, 22.0, 16.0, 33.0, 12.0, 15.0, 1.0, 6.0, 7.0, 25.0, 18.0, 21.0, 17.0, 6.0, 31.0, 1.0, 3.0, 5.0, 25.0, 0.0, 10.0, 18.0, 0.0, 13.0, 12.0, 9.0, 10.0, 7.0, 0.0, 5.0, 33.0, 4.0, 0.0, 1.0, 13.0, 1.0, 17.0, 5.0, 7.0, 12.0, 0.0, 0.0, 10.0, 43.0, 16.0, 14.0, 2.0, 0.0, 5.0, 4.0, 17.0, 2.0, 4.0, 10.0, 8.0, 40.0, 3.0, 7.0, 27.0, 5.0, 8.0, 12.0, 4.0, 0.0, 0.0, 26.0, 31.0, 7.0, 15.0, 13.0, 18.0, 18.0, 0.0, 0.0, 15.0, 8.0, 4.0, 0.0, 0.0, 2.0, 1.0, 5.0, 9.0, 6.0, 1.0, 10.0, 0.0, 22.0, 14.0, 11.0, 15.0, 4.0, 6.0, 4.0, 4.0, 9.0, 11.0, 15.0, 5.0, 30.0, 21.0, 5.0, 2.0, 2.0, 1.0, 12.0, 1.0, 3.0, 4.0, 8.0, 23.0, 21.0, 18.0, 19.0, 80.0, 18.0, 17.0, 30.0, 4.0, 14.0, 2.0, 1.0, 15.0, 28.0, 1.0, 19.0, 7.0, 10.0, 11.0, 9.0, 7.0, 3.0, 4.0, 8.0, 11.0, 14.0, 16.0, 44.0, 17.0, 0.0, 4.0, 10.0, 4.0, 6.0, 21.0, 20.0, 12.0, 12.0, 6.0, 14.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5408974590086558, "mean_inference_ms": 1.3951650026006697, "mean_action_processing_ms": 0.23129924320993422, "mean_env_wait_ms": 0.17732183244411354, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005264759063720703, "StateBufferConnector_ms": 0.003190755844116211, "ViewRequirementAgentConnector_ms": 0.08624088764190674}, "num_episodes": 23, "episode_return_max": 392.8, "episode_return_min": -0.7999999999997288, "episode_return_mean": 217.2349999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 439.8646187702029, "num_env_steps_trained_throughput_per_sec": 439.8646187702029, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 8985.221, "restore_workers_time_ms": 0.015, "training_step_time_ms": 8985.179, "sample_time_ms": 1009.048, "learn_time_ms": 7964.141, "learn_throughput": 502.251, "synch_weights_time_ms": 11.209}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-36-20", "timestamp": 1723646180, "time_this_iter_s": 9.09682321548462, "time_total_s": 699.3215696811676, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0fbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 699.3215696811676, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 28.353846153846153, "ram_util_percent": 77.10000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.165049444115351, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 5.6881403521885945, "policy_loss": -0.009363942118312317, "vf_loss": 5.696497238250005, "vf_explained_var": 0.22197840967506327, "kl": 0.00895159421307995, "entropy": 0.9359047950575592, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.59224595928949, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 2.631693349502705, "policy_loss": -0.00900801874071399, "vf_loss": 2.639390887659063, "vf_explained_var": 0.12008477913008796, "kl": 0.01310475982213738, "entropy": 1.0133501978147597, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 392.8, "episode_reward_min": -0.7999999999997288, "episode_reward_mean": 205.2889999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -316.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 171.0}, "policy_reward_mean": {"prey_policy": 88.64450000000001, "predator_policy": 14.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [214.69999999999928, 286.40000000000003, 136.5999999999997, 344.9, 178.59999999999914, 180.39999999999947, 192.89999999999938, 362.7, 265.89999999999986, 22.400000000000013, 356.0, 167.89999999999952, 319.5, 313.4, 342.8, 164.79999999999956, 199.99999999999935, -0.7999999999997288, 203.29999999999933, 39.800000000000296, 32.30000000000018, 193.7999999999994, 46.400000000000404, 24.60000000000005, 20.199999999999985, 153.39999999999958, 204.99999999999935, 379.1, 274.8, 188.8999999999994, 236.99999999999923, 337.0, 33.4000000000002, 244.8999999999992, 314.0, 154.69999999999962, 370.4, 40.400000000000304, 216.39999999999927, 183.99999999999943, 177.7999999999995, 377.0, 183.99999999999943, 173.79999999999947, 388.0, 392.8, 372.4000000000001, 370.5, 209.8999999999993, 199.99999999999935, 303.9999999999999, 28.200000000000117, 269.2999999999996, 31.200000000000163, 330.9, 23.100000000000033, 304.0, 383.3, 215.79999999999927, 205.09999999999934, 207.7999999999993, 321.8, 349.0, 31.899999999999977, 198.59999999999937, 155.59999999999962, 206.5999999999993, 361.7, 308.7, 334.5, 52.9000000000004, 169.9999999999995, 382.4, 21.199999999999992, 332.20000000000005, 133.69999999999973, 211.9999999999993, 209.3999999999993, 326.20000000000005, 325.2, 182.19999999999945, 164.49999999999955, 174.69999999999908, 27.400000000000105, 29.20000000000002, 239.99999999999915, 168.09999999999985, 153.1999999999998, 208.7999999999992, 57.000000000000206, 97.79999999999967, 329.90000000000055, 370.0000000000003, 167.29999999999947, 103.69999999999969, 34.100000000000215, 56.600000000000236, 130.99999999999955, 34.40000000000022, 273.60000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -7.299999999999891, 106.70000000000007, 154.70000000000002, 79.4, 3.1999999999999615, 173.0, 143.9, 151.69999999999982, 17.899999999999988, 128.0, 22.40000000000006, 119.0, 41.90000000000024, 127.70000000000002, 197.0, 149.60000000000002, 71.3, 17.899999999999988, -11.499999999999822, 171.8, 171.2, 128.3, -3.3999999999999866, 146.3, 135.2, 169.39999999999998, 107.0, 171.2, 167.6, 125.3, 9.499999999999964, 170.0, 20.000000000000014, -5.1999999999999265, -13.599999999999786, 185.6, -7.299999999999891, 21.80000000000004, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 98.0, 57.800000000000225, 25.400000000000098, 16.999999999999975, 17.899999999999988, -7.299999999999891, 17.899999999999988, -15.699999999999768, 20.000000000000014, 121.39999999999998, 29.000000000000163, 164.0, 169.1, 200.0, 194.60000000000002, 21.200000000000003, 15.799999999999963, 157.1, 59.9000000000002, 172.1, 167.0, 149.0, 11.599999999999964, 15.799999999999963, 170.0, 56.9000000000002, 194.0, 77.0, 115.4, 5.299999999999965, 163.39999999999998, 194.0, 29.60000000000018, -5.1999999999999265, 196.4, 20.000000000000014, 20.000000000000014, 107.0, 5.299999999999965, 150.5, 146.0, 200.0, 146.0, 20.000000000000014, 20.000000000000014, 138.8, 200.0, 176.0, 192.8, 200.0, 176.29999999999998, 193.1, 159.20000000000002, 197.3, 195.5, 7.399999999999965, 170.0, 20.000000000000014, 140.0, 128.00000000000003, -17.79999999999974, 20.000000000000014, 72.19999999999959, 187.1, 7.399999999999965, 15.799999999999963, 178.1, 132.80000000000004, 1.9999999999999607, 1.0999999999999865, 134.0, 119.0, 182.3, 194.0, 15.799999999999963, 197.0, -5.1999999999999265, 197.3, 13.699999999999964, 187.1, 131.0, 159.8, 128.3, 181.7, -3.099999999999965, -64.0, 29.000000000000167, 134.60000000000002, 110.0, 11.599999999999964, -9.399999999999855, 200.0, 190.1, 155.6, 130.7, 149.0, 143.0, 165.5, 18.200000000000017, 13.699999999999967, 152.89999999999998, 1.0999999999999865, 188.0, 187.39999999999995, 3.1999999999999615, -0.9999999999999846, 168.20000000000002, 134.0, 11.599999999999964, 61.099999999999994, 188.0, 20.000000000000014, 7.399999999999965, 188.0, 101.90000000000006, 197.3, 157.7, 135.5, 7.399999999999965, 156.8, 158.0, -32.49999999999975, 15.799999999999963, 152.89999999999978, -24.099999999999746, 9.499999999999964, 162.19999999999996, -316.0, 122.5999999999996, 109.39999999999972, 56.300000000000004, 63.80000000000001, -3.9999999999999574, 54.20000000000001, 190.09999999999994, 13.699999999999964, 20.000000000000014, -82.00000000000034, -36.699999999999754, 87.49999999999989, 168.19999999999993, 157.69999999999976, 200.0, 163.9999999999999, 140.29999999999995, 20.000000000000014, -172.89999999999998, 107.59999999999995, 20.000000000000014, -19.899999999999743, 36.80000000000006, -47.19999999999976, 20.000000000000014, 98.00000000000006, 7.399999999999965, 20.000000000000014, 170.29999999999987, 56.30000000000001], "policy_predator_policy_reward": [9.0, 13.0, 8.0, 17.0, 15.0, 39.0, 19.0, 9.0, 4.0, 5.0, 6.0, 24.0, 15.0, 17.0, 22.0, 16.0, 33.0, 12.0, 15.0, 1.0, 6.0, 7.0, 25.0, 18.0, 21.0, 17.0, 6.0, 31.0, 1.0, 3.0, 5.0, 25.0, 0.0, 10.0, 18.0, 0.0, 13.0, 12.0, 9.0, 10.0, 7.0, 0.0, 5.0, 33.0, 4.0, 0.0, 1.0, 13.0, 1.0, 17.0, 5.0, 7.0, 12.0, 0.0, 0.0, 10.0, 43.0, 16.0, 14.0, 2.0, 0.0, 5.0, 4.0, 17.0, 2.0, 4.0, 10.0, 8.0, 40.0, 3.0, 7.0, 27.0, 5.0, 8.0, 12.0, 4.0, 0.0, 0.0, 26.0, 31.0, 7.0, 15.0, 13.0, 18.0, 18.0, 0.0, 0.0, 15.0, 8.0, 4.0, 0.0, 0.0, 2.0, 1.0, 5.0, 9.0, 6.0, 1.0, 10.0, 0.0, 22.0, 14.0, 11.0, 15.0, 4.0, 6.0, 4.0, 4.0, 9.0, 11.0, 15.0, 5.0, 30.0, 21.0, 5.0, 2.0, 2.0, 1.0, 12.0, 1.0, 3.0, 4.0, 8.0, 23.0, 21.0, 18.0, 19.0, 80.0, 18.0, 17.0, 30.0, 4.0, 14.0, 2.0, 1.0, 15.0, 28.0, 1.0, 19.0, 7.0, 10.0, 11.0, 9.0, 7.0, 3.0, 4.0, 8.0, 11.0, 14.0, 16.0, 44.0, 17.0, 0.0, 4.0, 10.0, 4.0, 6.0, 21.0, 20.0, 12.0, 12.0, 6.0, 14.0, 25.0, 4.0, 2.0, 23.0, 19.0, 171.0, 12.0, 0.0, 8.0, 36.0, 12.0, 46.0, 57.0, 3.0, 2.0, 60.0, 59.0, 29.0, 18.0, 4.0, 0.0, 3.0, 3.0, 7.0, 0.0, 51.0, 118.0, 15.0, 19.0, 31.0, 36.0, 13.0, 0.0, 1.0, 6.0, 44.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.540323396977919, "mean_inference_ms": 1.3923522228447893, "mean_action_processing_ms": 0.2307864007631654, "mean_env_wait_ms": 0.17722190051585557, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004850268363952637, "StateBufferConnector_ms": 0.0031636953353881836, "ViewRequirementAgentConnector_ms": 0.08630084991455078}, "num_episodes": 18, "episode_return_max": 392.8, "episode_return_min": -0.7999999999997288, "episode_return_mean": 205.2889999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 439.74895656310247, "num_env_steps_trained_throughput_per_sec": 439.74895656310247, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 8993.503, "restore_workers_time_ms": 0.015, "training_step_time_ms": 8993.46, "sample_time_ms": 1011.838, "learn_time_ms": 7969.642, "learn_throughput": 501.905, "synch_weights_time_ms": 11.189}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-36-29", "timestamp": 1723646189, "time_this_iter_s": 9.099189043045044, "time_total_s": 708.4207587242126, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0eb790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 708.4207587242126, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 27.730769230769226, "ram_util_percent": 77.13076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.969052012729897, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 6.262848696380696, "policy_loss": -0.007795924002122351, "vf_loss": 6.268456610926876, "vf_explained_var": 0.4883284877217005, "kl": 0.01944896847288917, "entropy": 0.8565895309208562, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5416046297108688, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 2.151072467382623, "policy_loss": -0.006131923927373632, "vf_loss": 2.1560516052775913, "vf_explained_var": 0.11766529436464664, "kl": 0.011527835575548723, "entropy": 0.9212431160545854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 392.8, "episode_reward_min": -13.699999999999541, "episode_reward_mean": 200.32599999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -316.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 171.0}, "policy_reward_mean": {"prey_policy": 83.43799999999999, "predator_policy": 16.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [203.29999999999933, 39.800000000000296, 32.30000000000018, 193.7999999999994, 46.400000000000404, 24.60000000000005, 20.199999999999985, 153.39999999999958, 204.99999999999935, 379.1, 274.8, 188.8999999999994, 236.99999999999923, 337.0, 33.4000000000002, 244.8999999999992, 314.0, 154.69999999999962, 370.4, 40.400000000000304, 216.39999999999927, 183.99999999999943, 177.7999999999995, 377.0, 183.99999999999943, 173.79999999999947, 388.0, 392.8, 372.4000000000001, 370.5, 209.8999999999993, 199.99999999999935, 303.9999999999999, 28.200000000000117, 269.2999999999996, 31.200000000000163, 330.9, 23.100000000000033, 304.0, 383.3, 215.79999999999927, 205.09999999999934, 207.7999999999993, 321.8, 349.0, 31.899999999999977, 198.59999999999937, 155.59999999999962, 206.5999999999993, 361.7, 308.7, 334.5, 52.9000000000004, 169.9999999999995, 382.4, 21.199999999999992, 332.20000000000005, 133.69999999999973, 211.9999999999993, 209.3999999999993, 326.20000000000005, 325.2, 182.19999999999945, 164.49999999999955, 174.69999999999908, 27.400000000000105, 29.20000000000002, 239.99999999999915, 168.09999999999985, 153.1999999999998, 208.7999999999992, 57.000000000000206, 97.79999999999967, 329.90000000000055, 370.0000000000003, 167.29999999999947, 103.69999999999969, 34.100000000000215, 56.600000000000236, 130.99999999999955, 34.40000000000022, 273.60000000000014, 319.4, 222.39999999999986, 313.6999999999999, 162.79999999999993, 153.9999999999999, 338.20000000000005, 225.39999999999978, 148.5000000000001, 23.800000000000033, 148.39999999999955, 181.29999999999922, 309.70000000000056, 238.29999999999998, 346.8000000000003, 229.49999999999997, 110.29999999999912, 93.99999999999997, -13.699999999999541], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [185.6, -7.299999999999891, 21.80000000000004, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 98.0, 57.800000000000225, 25.400000000000098, 16.999999999999975, 17.899999999999988, -7.299999999999891, 17.899999999999988, -15.699999999999768, 20.000000000000014, 121.39999999999998, 29.000000000000163, 164.0, 169.1, 200.0, 194.60000000000002, 21.200000000000003, 15.799999999999963, 157.1, 59.9000000000002, 172.1, 167.0, 149.0, 11.599999999999964, 15.799999999999963, 170.0, 56.9000000000002, 194.0, 77.0, 115.4, 5.299999999999965, 163.39999999999998, 194.0, 29.60000000000018, -5.1999999999999265, 196.4, 20.000000000000014, 20.000000000000014, 107.0, 5.299999999999965, 150.5, 146.0, 200.0, 146.0, 20.000000000000014, 20.000000000000014, 138.8, 200.0, 176.0, 192.8, 200.0, 176.29999999999998, 193.1, 159.20000000000002, 197.3, 195.5, 7.399999999999965, 170.0, 20.000000000000014, 140.0, 128.00000000000003, -17.79999999999974, 20.000000000000014, 72.19999999999959, 187.1, 7.399999999999965, 15.799999999999963, 178.1, 132.80000000000004, 1.9999999999999607, 1.0999999999999865, 134.0, 119.0, 182.3, 194.0, 15.799999999999963, 197.0, -5.1999999999999265, 197.3, 13.699999999999964, 187.1, 131.0, 159.8, 128.3, 181.7, -3.099999999999965, -64.0, 29.000000000000167, 134.60000000000002, 110.0, 11.599999999999964, -9.399999999999855, 200.0, 190.1, 155.6, 130.7, 149.0, 143.0, 165.5, 18.200000000000017, 13.699999999999967, 152.89999999999998, 1.0999999999999865, 188.0, 187.39999999999995, 3.1999999999999615, -0.9999999999999846, 168.20000000000002, 134.0, 11.599999999999964, 61.099999999999994, 188.0, 20.000000000000014, 7.399999999999965, 188.0, 101.90000000000006, 197.3, 157.7, 135.5, 7.399999999999965, 156.8, 158.0, -32.49999999999975, 15.799999999999963, 152.89999999999978, -24.099999999999746, 9.499999999999964, 162.19999999999996, -316.0, 122.5999999999996, 109.39999999999972, 56.300000000000004, 63.80000000000001, -3.9999999999999574, 54.20000000000001, 190.09999999999994, 13.699999999999964, 20.000000000000014, -82.00000000000034, -36.699999999999754, 87.49999999999989, 168.19999999999993, 157.69999999999976, 200.0, 163.9999999999999, 140.29999999999995, 20.000000000000014, -172.89999999999998, 107.59999999999995, 20.000000000000014, -19.899999999999743, 36.80000000000006, -47.19999999999976, 20.000000000000014, 98.00000000000006, 7.399999999999965, 20.000000000000014, 170.29999999999987, 56.30000000000001, 173.0, 139.39999999999998, 132.49999999999994, 38.90000000000004, 160.9999999999999, 148.69999999999996, -171.70000000000002, 159.49999999999991, 170.29999999999995, -274.2999999999996, 192.79999999999995, 118.39999999999992, -38.500000000000014, 140.89999999999992, 66.50000000000004, 29.000000000000085, 9.499999999999964, 5.299999999999965, 111.79999999999997, 11.599999999999964, 20.000000000000014, 149.29999999999987, 160.99999999999986, 133.7, 113.30000000000003, 59.0, 187.09999999999994, 145.6999999999999, 127.10000000000002, 46.40000000000007, 118.09999999999957, -38.799999999999756, 30.80000000000004, -2.800000000000082, 1.0999999999999865, -59.80000000000062], "policy_predator_policy_reward": [13.0, 12.0, 9.0, 10.0, 7.0, 0.0, 5.0, 33.0, 4.0, 0.0, 1.0, 13.0, 1.0, 17.0, 5.0, 7.0, 12.0, 0.0, 0.0, 10.0, 43.0, 16.0, 14.0, 2.0, 0.0, 5.0, 4.0, 17.0, 2.0, 4.0, 10.0, 8.0, 40.0, 3.0, 7.0, 27.0, 5.0, 8.0, 12.0, 4.0, 0.0, 0.0, 26.0, 31.0, 7.0, 15.0, 13.0, 18.0, 18.0, 0.0, 0.0, 15.0, 8.0, 4.0, 0.0, 0.0, 2.0, 1.0, 5.0, 9.0, 6.0, 1.0, 10.0, 0.0, 22.0, 14.0, 11.0, 15.0, 4.0, 6.0, 4.0, 4.0, 9.0, 11.0, 15.0, 5.0, 30.0, 21.0, 5.0, 2.0, 2.0, 1.0, 12.0, 1.0, 3.0, 4.0, 8.0, 23.0, 21.0, 18.0, 19.0, 80.0, 18.0, 17.0, 30.0, 4.0, 14.0, 2.0, 1.0, 15.0, 28.0, 1.0, 19.0, 7.0, 10.0, 11.0, 9.0, 7.0, 3.0, 4.0, 8.0, 11.0, 14.0, 16.0, 44.0, 17.0, 0.0, 4.0, 10.0, 4.0, 6.0, 21.0, 20.0, 12.0, 12.0, 6.0, 14.0, 25.0, 4.0, 2.0, 23.0, 19.0, 171.0, 12.0, 0.0, 8.0, 36.0, 12.0, 46.0, 57.0, 3.0, 2.0, 60.0, 59.0, 29.0, 18.0, 4.0, 0.0, 3.0, 3.0, 7.0, 0.0, 51.0, 118.0, 15.0, 19.0, 31.0, 36.0, 13.0, 0.0, 1.0, 6.0, 44.0, 3.0, 7.0, 0.0, 6.0, 45.0, 4.0, 0.0, 52.0, 123.0, 147.0, 111.0, 23.0, 4.0, 63.0, 60.0, 26.0, 27.0, 0.0, 9.0, 17.0, 8.0, 5.0, 7.0, 14.0, 1.0, 17.0, 49.0, 14.0, 0.0, 26.0, 30.0, 28.0, 3.0, 24.0, 42.0, 7.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5397085072855026, "mean_inference_ms": 1.3907136678274492, "mean_action_processing_ms": 0.2304904366492589, "mean_env_wait_ms": 0.17695759327559138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004442453384399414, "StateBufferConnector_ms": 0.003154277801513672, "ViewRequirementAgentConnector_ms": 0.08812332153320312}, "num_episodes": 18, "episode_return_max": 392.8, "episode_return_min": -13.699999999999541, "episode_return_mean": 200.32599999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 446.5051079026368, "num_env_steps_trained_throughput_per_sec": 446.5051079026368, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 8986.219, "restore_workers_time_ms": 0.015, "training_step_time_ms": 8986.176, "sample_time_ms": 1016.005, "learn_time_ms": 7958.204, "learn_throughput": 502.626, "synch_weights_time_ms": 11.196}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-36-38", "timestamp": 1723646198, "time_this_iter_s": 8.961543798446655, "time_total_s": 717.3823025226593, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aaee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 717.3823025226593, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 27.14166666666667, "ram_util_percent": 76.98333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.246767082037749, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 6.364860417098595, "policy_loss": -0.002072352345505601, "vf_loss": 6.365554559293878, "vf_explained_var": 0.17916659239738705, "kl": 0.012250799451799885, "entropy": 0.8862936254531618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.265334109339134, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 2.3782628126876064, "policy_loss": -0.011712499598051032, "vf_loss": 2.3886107446655394, "vf_explained_var": 0.1812389594852609, "kl": 0.01364570538048779, "entropy": 0.7870224758430764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 392.8, "episode_reward_min": -444.4999999999997, "episode_reward_mean": 206.48699999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -350.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 83.35849999999999, "predator_policy": 19.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [177.7999999999995, 377.0, 183.99999999999943, 173.79999999999947, 388.0, 392.8, 372.4000000000001, 370.5, 209.8999999999993, 199.99999999999935, 303.9999999999999, 28.200000000000117, 269.2999999999996, 31.200000000000163, 330.9, 23.100000000000033, 304.0, 383.3, 215.79999999999927, 205.09999999999934, 207.7999999999993, 321.8, 349.0, 31.899999999999977, 198.59999999999937, 155.59999999999962, 206.5999999999993, 361.7, 308.7, 334.5, 52.9000000000004, 169.9999999999995, 382.4, 21.199999999999992, 332.20000000000005, 133.69999999999973, 211.9999999999993, 209.3999999999993, 326.20000000000005, 325.2, 182.19999999999945, 164.49999999999955, 174.69999999999908, 27.400000000000105, 29.20000000000002, 239.99999999999915, 168.09999999999985, 153.1999999999998, 208.7999999999992, 57.000000000000206, 97.79999999999967, 329.90000000000055, 370.0000000000003, 167.29999999999947, 103.69999999999969, 34.100000000000215, 56.600000000000236, 130.99999999999955, 34.40000000000022, 273.60000000000014, 319.4, 222.39999999999986, 313.6999999999999, 162.79999999999993, 153.9999999999999, 338.20000000000005, 225.39999999999978, 148.5000000000001, 23.800000000000033, 148.39999999999955, 181.29999999999922, 309.70000000000056, 238.29999999999998, 346.8000000000003, 229.49999999999997, 110.29999999999912, 93.99999999999997, -13.699999999999541, 294.1, 321.0000000000008, 54.899999999999835, 188.99999999999926, 133.39999999999964, 224.49999999999986, 243.59999999999974, 224.1999999999995, -444.4999999999997, 301.9999999999999, 302.5999999999996, 55.400000000000226, 297.1999999999999, 189.39999999999924, 274.1999999999996, 305.3, 330.4000000000005, 278.0999999999998, 174.60000000000002, 317.5, 110.49999999999974, 332.50000000000017], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, 150.5, 146.0, 200.0, 146.0, 20.000000000000014, 20.000000000000014, 138.8, 200.0, 176.0, 192.8, 200.0, 176.29999999999998, 193.1, 159.20000000000002, 197.3, 195.5, 7.399999999999965, 170.0, 20.000000000000014, 140.0, 128.00000000000003, -17.79999999999974, 20.000000000000014, 72.19999999999959, 187.1, 7.399999999999965, 15.799999999999963, 178.1, 132.80000000000004, 1.9999999999999607, 1.0999999999999865, 134.0, 119.0, 182.3, 194.0, 15.799999999999963, 197.0, -5.1999999999999265, 197.3, 13.699999999999964, 187.1, 131.0, 159.8, 128.3, 181.7, -3.099999999999965, -64.0, 29.000000000000167, 134.60000000000002, 110.0, 11.599999999999964, -9.399999999999855, 200.0, 190.1, 155.6, 130.7, 149.0, 143.0, 165.5, 18.200000000000017, 13.699999999999967, 152.89999999999998, 1.0999999999999865, 188.0, 187.39999999999995, 3.1999999999999615, -0.9999999999999846, 168.20000000000002, 134.0, 11.599999999999964, 61.099999999999994, 188.0, 20.000000000000014, 7.399999999999965, 188.0, 101.90000000000006, 197.3, 157.7, 135.5, 7.399999999999965, 156.8, 158.0, -32.49999999999975, 15.799999999999963, 152.89999999999978, -24.099999999999746, 9.499999999999964, 162.19999999999996, -316.0, 122.5999999999996, 109.39999999999972, 56.300000000000004, 63.80000000000001, -3.9999999999999574, 54.20000000000001, 190.09999999999994, 13.699999999999964, 20.000000000000014, -82.00000000000034, -36.699999999999754, 87.49999999999989, 168.19999999999993, 157.69999999999976, 200.0, 163.9999999999999, 140.29999999999995, 20.000000000000014, -172.89999999999998, 107.59999999999995, 20.000000000000014, -19.899999999999743, 36.80000000000006, -47.19999999999976, 20.000000000000014, 98.00000000000006, 7.399999999999965, 20.000000000000014, 170.29999999999987, 56.30000000000001, 173.0, 139.39999999999998, 132.49999999999994, 38.90000000000004, 160.9999999999999, 148.69999999999996, -171.70000000000002, 159.49999999999991, 170.29999999999995, -274.2999999999996, 192.79999999999995, 118.39999999999992, -38.500000000000014, 140.89999999999992, 66.50000000000004, 29.000000000000085, 9.499999999999964, 5.299999999999965, 111.79999999999997, 11.599999999999964, 20.000000000000014, 149.29999999999987, 160.99999999999986, 133.7, 113.30000000000003, 59.0, 187.09999999999994, 145.6999999999999, 127.10000000000002, 46.40000000000007, 118.09999999999957, -38.799999999999756, 30.80000000000004, -2.800000000000082, 1.0999999999999865, -59.80000000000062, 168.7999999999999, 92.29999999999995, 163.9999999999999, 112.99999999999989, -136.3000000000002, 42.199999999999974, 187.39999999999992, -30.39999999999975, 13.399999999999958, 58.999999999999936, 93.80000000000001, 97.70000000000007, 99.49999999999997, 109.10000000000002, 102.19999999999983, 98.00000000000003, -307.0, -350.4999999999998, 179.0, 83.0, 142.10000000000002, 141.49999999999991, -0.9999999999999846, 16.40000000000003, 62.00000000000004, 198.2, 23.600000000000072, 156.7999999999999, 139.99999999999997, 111.19999999999993, 131.89999999999998, 145.39999999999984, 117.49999999999987, 173.89999999999984, 61.100000000000016, 179.0, 70.4, 48.20000000000002, 178.40000000000003, 103.1, 19.399999999999785, 28.09999999999998, 161.0, 144.49999999999994], "policy_predator_policy_reward": [7.0, 15.0, 13.0, 18.0, 18.0, 0.0, 0.0, 15.0, 8.0, 4.0, 0.0, 0.0, 2.0, 1.0, 5.0, 9.0, 6.0, 1.0, 10.0, 0.0, 22.0, 14.0, 11.0, 15.0, 4.0, 6.0, 4.0, 4.0, 9.0, 11.0, 15.0, 5.0, 30.0, 21.0, 5.0, 2.0, 2.0, 1.0, 12.0, 1.0, 3.0, 4.0, 8.0, 23.0, 21.0, 18.0, 19.0, 80.0, 18.0, 17.0, 30.0, 4.0, 14.0, 2.0, 1.0, 15.0, 28.0, 1.0, 19.0, 7.0, 10.0, 11.0, 9.0, 7.0, 3.0, 4.0, 8.0, 11.0, 14.0, 16.0, 44.0, 17.0, 0.0, 4.0, 10.0, 4.0, 6.0, 21.0, 20.0, 12.0, 12.0, 6.0, 14.0, 25.0, 4.0, 2.0, 23.0, 19.0, 171.0, 12.0, 0.0, 8.0, 36.0, 12.0, 46.0, 57.0, 3.0, 2.0, 60.0, 59.0, 29.0, 18.0, 4.0, 0.0, 3.0, 3.0, 7.0, 0.0, 51.0, 118.0, 15.0, 19.0, 31.0, 36.0, 13.0, 0.0, 1.0, 6.0, 44.0, 3.0, 7.0, 0.0, 6.0, 45.0, 4.0, 0.0, 52.0, 123.0, 147.0, 111.0, 23.0, 4.0, 63.0, 60.0, 26.0, 27.0, 0.0, 9.0, 17.0, 8.0, 5.0, 7.0, 14.0, 1.0, 17.0, 49.0, 14.0, 0.0, 26.0, 30.0, 28.0, 3.0, 24.0, 42.0, 7.0, 38.0, 7.0, 26.0, 23.0, 21.0, 83.0, 66.0, 12.0, 20.0, 20.0, 41.0, 18.0, 15.0, 17.0, 18.0, 0.0, 24.0, 16.0, 197.0, 33.0, 7.0, 13.0, 6.0, 10.0, 30.0, 11.0, 26.0, 5.0, 4.0, 19.0, 4.0, 19.0, 9.0, 19.0, 20.0, 7.0, 31.0, 8.0, 48.0, 4.0, 32.0, 16.0, 47.0, 14.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5388925383353055, "mean_inference_ms": 1.3898061952722736, "mean_action_processing_ms": 0.2298947286282785, "mean_env_wait_ms": 0.17653808905966406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038732290267944336, "StateBufferConnector_ms": 0.0031048059463500977, "ViewRequirementAgentConnector_ms": 0.08571016788482666}, "num_episodes": 22, "episode_return_max": 392.8, "episode_return_min": -444.4999999999997, "episode_return_mean": 206.48699999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 432.0921251715392, "num_env_steps_trained_throughput_per_sec": 432.0921251715392, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 9011.979, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9011.935, "sample_time_ms": 1013.965, "learn_time_ms": 7986.049, "learn_throughput": 500.873, "synch_weights_time_ms": 11.157}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-36-47", "timestamp": 1723646207, "time_this_iter_s": 9.2608060836792, "time_total_s": 726.6431086063385, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b14a280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 726.6431086063385, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 28.48461538461538, "ram_util_percent": 77.06153846153848}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8265241008586983, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 4.99081131188327, "policy_loss": -0.005862522187332312, "vf_loss": 4.995609429021361, "vf_explained_var": 0.14087691322836296, "kl": 0.009461272039493283, "entropy": 0.9334817717945765, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3268521772805975, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 1.9711902055790815, "policy_loss": -0.006297741850798644, "vf_loss": 1.9765752413916209, "vf_explained_var": 0.15671662650411092, "kl": 0.00912707851925877, "entropy": 0.7653125059036981, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 382.4, "episode_reward_min": -444.4999999999997, "episode_reward_mean": 179.43299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -350.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 64.76149999999998, "predator_policy": 24.955}, "custom_metrics": {}, "hist_stats": {"episode_reward": [215.79999999999927, 205.09999999999934, 207.7999999999993, 321.8, 349.0, 31.899999999999977, 198.59999999999937, 155.59999999999962, 206.5999999999993, 361.7, 308.7, 334.5, 52.9000000000004, 169.9999999999995, 382.4, 21.199999999999992, 332.20000000000005, 133.69999999999973, 211.9999999999993, 209.3999999999993, 326.20000000000005, 325.2, 182.19999999999945, 164.49999999999955, 174.69999999999908, 27.400000000000105, 29.20000000000002, 239.99999999999915, 168.09999999999985, 153.1999999999998, 208.7999999999992, 57.000000000000206, 97.79999999999967, 329.90000000000055, 370.0000000000003, 167.29999999999947, 103.69999999999969, 34.100000000000215, 56.600000000000236, 130.99999999999955, 34.40000000000022, 273.60000000000014, 319.4, 222.39999999999986, 313.6999999999999, 162.79999999999993, 153.9999999999999, 338.20000000000005, 225.39999999999978, 148.5000000000001, 23.800000000000033, 148.39999999999955, 181.29999999999922, 309.70000000000056, 238.29999999999998, 346.8000000000003, 229.49999999999997, 110.29999999999912, 93.99999999999997, -13.699999999999541, 294.1, 321.0000000000008, 54.899999999999835, 188.99999999999926, 133.39999999999964, 224.49999999999986, 243.59999999999974, 224.1999999999995, -444.4999999999997, 301.9999999999999, 302.5999999999996, 55.400000000000226, 297.1999999999999, 189.39999999999924, 274.1999999999996, 305.3, 330.4000000000005, 278.0999999999998, 174.60000000000002, 317.5, 110.49999999999974, 332.50000000000017, 179.89999999999924, 177.29999999999953, 239.99999999999991, 177.2, 183.99999999999932, 170.2999999999994, -177.100000000001, 189.8999999999999, -58.60000000000052, 155.09999999999917, 188.10000000000002, -73.90000000000066, 148.49999999999966, 27.90000000000011, -50.600000000000364, 281.19999999999993, 291.5000000000002, -235.89999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, 197.0, -5.1999999999999265, 197.3, 13.699999999999964, 187.1, 131.0, 159.8, 128.3, 181.7, -3.099999999999965, -64.0, 29.000000000000167, 134.60000000000002, 110.0, 11.599999999999964, -9.399999999999855, 200.0, 190.1, 155.6, 130.7, 149.0, 143.0, 165.5, 18.200000000000017, 13.699999999999967, 152.89999999999998, 1.0999999999999865, 188.0, 187.39999999999995, 3.1999999999999615, -0.9999999999999846, 168.20000000000002, 134.0, 11.599999999999964, 61.099999999999994, 188.0, 20.000000000000014, 7.399999999999965, 188.0, 101.90000000000006, 197.3, 157.7, 135.5, 7.399999999999965, 156.8, 158.0, -32.49999999999975, 15.799999999999963, 152.89999999999978, -24.099999999999746, 9.499999999999964, 162.19999999999996, -316.0, 122.5999999999996, 109.39999999999972, 56.300000000000004, 63.80000000000001, -3.9999999999999574, 54.20000000000001, 190.09999999999994, 13.699999999999964, 20.000000000000014, -82.00000000000034, -36.699999999999754, 87.49999999999989, 168.19999999999993, 157.69999999999976, 200.0, 163.9999999999999, 140.29999999999995, 20.000000000000014, -172.89999999999998, 107.59999999999995, 20.000000000000014, -19.899999999999743, 36.80000000000006, -47.19999999999976, 20.000000000000014, 98.00000000000006, 7.399999999999965, 20.000000000000014, 170.29999999999987, 56.30000000000001, 173.0, 139.39999999999998, 132.49999999999994, 38.90000000000004, 160.9999999999999, 148.69999999999996, -171.70000000000002, 159.49999999999991, 170.29999999999995, -274.2999999999996, 192.79999999999995, 118.39999999999992, -38.500000000000014, 140.89999999999992, 66.50000000000004, 29.000000000000085, 9.499999999999964, 5.299999999999965, 111.79999999999997, 11.599999999999964, 20.000000000000014, 149.29999999999987, 160.99999999999986, 133.7, 113.30000000000003, 59.0, 187.09999999999994, 145.6999999999999, 127.10000000000002, 46.40000000000007, 118.09999999999957, -38.799999999999756, 30.80000000000004, -2.800000000000082, 1.0999999999999865, -59.80000000000062, 168.7999999999999, 92.29999999999995, 163.9999999999999, 112.99999999999989, -136.3000000000002, 42.199999999999974, 187.39999999999992, -30.39999999999975, 13.399999999999958, 58.999999999999936, 93.80000000000001, 97.70000000000007, 99.49999999999997, 109.10000000000002, 102.19999999999983, 98.00000000000003, -307.0, -350.4999999999998, 179.0, 83.0, 142.10000000000002, 141.49999999999991, -0.9999999999999846, 16.40000000000003, 62.00000000000004, 198.2, 23.600000000000072, 156.7999999999999, 139.99999999999997, 111.19999999999993, 131.89999999999998, 145.39999999999984, 117.49999999999987, 173.89999999999984, 61.100000000000016, 179.0, 70.4, 48.20000000000002, 178.40000000000003, 103.1, 19.399999999999785, 28.09999999999998, 161.0, 144.49999999999994, 25.4000000000001, 126.5, 20.000000000000014, 146.30000000000004, 188.3, -19.300000000000082, 167.29999999999998, -96.10000000000005, -13.599999999999783, 167.59999999999994, 134.30000000000004, 20.000000000000014, -45.099999999999774, -339.9999999999998, 69.49999999999999, 55.39999999999992, -181.00000000000028, 7.399999999999965, 109.09999999999982, 20.000000000000014, -6.100000000000051, 93.20000000000003, -237.69999999999993, 15.799999999999963, 164.90000000000003, -51.40000000000002, 20.000000000000014, -3.099999999999958, -124.00000000000017, -37.60000000000019, 118.4, 126.79999999999998, 98.89999999999995, 158.5999999999999, -190.30000000000004, -217.60000000000002], "policy_predator_policy_reward": [2.0, 1.0, 12.0, 1.0, 3.0, 4.0, 8.0, 23.0, 21.0, 18.0, 19.0, 80.0, 18.0, 17.0, 30.0, 4.0, 14.0, 2.0, 1.0, 15.0, 28.0, 1.0, 19.0, 7.0, 10.0, 11.0, 9.0, 7.0, 3.0, 4.0, 8.0, 11.0, 14.0, 16.0, 44.0, 17.0, 0.0, 4.0, 10.0, 4.0, 6.0, 21.0, 20.0, 12.0, 12.0, 6.0, 14.0, 25.0, 4.0, 2.0, 23.0, 19.0, 171.0, 12.0, 0.0, 8.0, 36.0, 12.0, 46.0, 57.0, 3.0, 2.0, 60.0, 59.0, 29.0, 18.0, 4.0, 0.0, 3.0, 3.0, 7.0, 0.0, 51.0, 118.0, 15.0, 19.0, 31.0, 36.0, 13.0, 0.0, 1.0, 6.0, 44.0, 3.0, 7.0, 0.0, 6.0, 45.0, 4.0, 0.0, 52.0, 123.0, 147.0, 111.0, 23.0, 4.0, 63.0, 60.0, 26.0, 27.0, 0.0, 9.0, 17.0, 8.0, 5.0, 7.0, 14.0, 1.0, 17.0, 49.0, 14.0, 0.0, 26.0, 30.0, 28.0, 3.0, 24.0, 42.0, 7.0, 38.0, 7.0, 26.0, 23.0, 21.0, 83.0, 66.0, 12.0, 20.0, 20.0, 41.0, 18.0, 15.0, 17.0, 18.0, 0.0, 24.0, 16.0, 197.0, 33.0, 7.0, 13.0, 6.0, 10.0, 30.0, 11.0, 26.0, 5.0, 4.0, 19.0, 4.0, 19.0, 9.0, 19.0, 20.0, 7.0, 31.0, 8.0, 48.0, 4.0, 32.0, 16.0, 47.0, 14.0, 13.0, 14.0, 14.0, 11.0, 0.0, 31.0, 40.0, 11.0, 95.0, 16.0, 14.0, 7.0, 9.0, 177.0, 31.0, 24.0, 41.0, 106.0, 9.0, 11.0, 15.0, 21.0, 80.0, 19.0, 129.0, 1.0, 34.0, 0.0, 11.0, 1.0, 110.0, 5.0, 31.0, 15.0, 19.0, 147.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5383290104457392, "mean_inference_ms": 1.3870830754453, "mean_action_processing_ms": 0.22988928816986615, "mean_env_wait_ms": 0.17643675268757067, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003441929817199707, "StateBufferConnector_ms": 0.0030608177185058594, "ViewRequirementAgentConnector_ms": 0.08519124984741211}, "num_episodes": 18, "episode_return_max": 382.4, "episode_return_min": -444.4999999999997, "episode_return_mean": 179.43299999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 442.42829857009446, "num_env_steps_trained_throughput_per_sec": 442.42829857009446, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 9025.75, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9025.707, "sample_time_ms": 1009.781, "learn_time_ms": 8004.021, "learn_throughput": 499.749, "synch_weights_time_ms": 11.164}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-36-56", "timestamp": 1723646216, "time_this_iter_s": 9.044280052185059, "time_total_s": 735.6873886585236, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ef160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 735.6873886585236, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 25.953846153846158, "ram_util_percent": 77.30769230769229}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.273671287077445, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 5.281712580105615, "policy_loss": -0.005982811714734429, "vf_loss": 5.286517707254521, "vf_explained_var": 0.20884301561527152, "kl": 0.010468329143422215, "entropy": 0.9211854509260289, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9232014858848834, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 2.318097903867247, "policy_loss": -0.005715362154311998, "vf_loss": 2.322931726962801, "vf_explained_var": 0.15660013026661343, "kl": 0.008815371306208982, "entropy": 0.6541758557476064, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 370.0000000000003, "episode_reward_min": -444.4999999999997, "episode_reward_mean": 166.49099999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -350.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 54.210499999999975, "predator_policy": 29.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [164.49999999999955, 174.69999999999908, 27.400000000000105, 29.20000000000002, 239.99999999999915, 168.09999999999985, 153.1999999999998, 208.7999999999992, 57.000000000000206, 97.79999999999967, 329.90000000000055, 370.0000000000003, 167.29999999999947, 103.69999999999969, 34.100000000000215, 56.600000000000236, 130.99999999999955, 34.40000000000022, 273.60000000000014, 319.4, 222.39999999999986, 313.6999999999999, 162.79999999999993, 153.9999999999999, 338.20000000000005, 225.39999999999978, 148.5000000000001, 23.800000000000033, 148.39999999999955, 181.29999999999922, 309.70000000000056, 238.29999999999998, 346.8000000000003, 229.49999999999997, 110.29999999999912, 93.99999999999997, -13.699999999999541, 294.1, 321.0000000000008, 54.899999999999835, 188.99999999999926, 133.39999999999964, 224.49999999999986, 243.59999999999974, 224.1999999999995, -444.4999999999997, 301.9999999999999, 302.5999999999996, 55.400000000000226, 297.1999999999999, 189.39999999999924, 274.1999999999996, 305.3, 330.4000000000005, 278.0999999999998, 174.60000000000002, 317.5, 110.49999999999974, 332.50000000000017, 179.89999999999924, 177.29999999999953, 239.99999999999991, 177.2, 183.99999999999932, 170.2999999999994, -177.100000000001, 189.8999999999999, -58.60000000000052, 155.09999999999917, 188.10000000000002, -73.90000000000066, 148.49999999999966, 27.90000000000011, -50.600000000000364, 281.19999999999993, 291.5000000000002, -235.89999999999972, 180.399999999999, 178.99999999999946, 252.8999999999999, 259.5999999999999, 298.7999999999996, 343.4000000000002, 201.69999999999928, 193.29999999999995, -61.600000000000215, 206.0999999999993, -66.00000000000006, 299.0999999999998, 147.4999999999996, 204.7999999999993, 30.599999999999604, 137.2, 239.29999999999998, 333.9000000000001, -245.39999999999998, 329.1999999999999, 215.59999999999982, 157.79999999999947, 113.09999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [158.0, -32.49999999999975, 15.799999999999963, 152.89999999999978, -24.099999999999746, 9.499999999999964, 162.19999999999996, -316.0, 122.5999999999996, 109.39999999999972, 56.300000000000004, 63.80000000000001, -3.9999999999999574, 54.20000000000001, 190.09999999999994, 13.699999999999964, 20.000000000000014, -82.00000000000034, -36.699999999999754, 87.49999999999989, 168.19999999999993, 157.69999999999976, 200.0, 163.9999999999999, 140.29999999999995, 20.000000000000014, -172.89999999999998, 107.59999999999995, 20.000000000000014, -19.899999999999743, 36.80000000000006, -47.19999999999976, 20.000000000000014, 98.00000000000006, 7.399999999999965, 20.000000000000014, 170.29999999999987, 56.30000000000001, 173.0, 139.39999999999998, 132.49999999999994, 38.90000000000004, 160.9999999999999, 148.69999999999996, -171.70000000000002, 159.49999999999991, 170.29999999999995, -274.2999999999996, 192.79999999999995, 118.39999999999992, -38.500000000000014, 140.89999999999992, 66.50000000000004, 29.000000000000085, 9.499999999999964, 5.299999999999965, 111.79999999999997, 11.599999999999964, 20.000000000000014, 149.29999999999987, 160.99999999999986, 133.7, 113.30000000000003, 59.0, 187.09999999999994, 145.6999999999999, 127.10000000000002, 46.40000000000007, 118.09999999999957, -38.799999999999756, 30.80000000000004, -2.800000000000082, 1.0999999999999865, -59.80000000000062, 168.7999999999999, 92.29999999999995, 163.9999999999999, 112.99999999999989, -136.3000000000002, 42.199999999999974, 187.39999999999992, -30.39999999999975, 13.399999999999958, 58.999999999999936, 93.80000000000001, 97.70000000000007, 99.49999999999997, 109.10000000000002, 102.19999999999983, 98.00000000000003, -307.0, -350.4999999999998, 179.0, 83.0, 142.10000000000002, 141.49999999999991, -0.9999999999999846, 16.40000000000003, 62.00000000000004, 198.2, 23.600000000000072, 156.7999999999999, 139.99999999999997, 111.19999999999993, 131.89999999999998, 145.39999999999984, 117.49999999999987, 173.89999999999984, 61.100000000000016, 179.0, 70.4, 48.20000000000002, 178.40000000000003, 103.1, 19.399999999999785, 28.09999999999998, 161.0, 144.49999999999994, 25.4000000000001, 126.5, 20.000000000000014, 146.30000000000004, 188.3, -19.300000000000082, 167.29999999999998, -96.10000000000005, -13.599999999999783, 167.59999999999994, 134.30000000000004, 20.000000000000014, -45.099999999999774, -339.9999999999998, 69.49999999999999, 55.39999999999992, -181.00000000000028, 7.399999999999965, 109.09999999999982, 20.000000000000014, -6.100000000000051, 93.20000000000003, -237.69999999999993, 15.799999999999963, 164.90000000000003, -51.40000000000002, 20.000000000000014, -3.099999999999958, -124.00000000000017, -37.60000000000019, 118.4, 126.79999999999998, 98.89999999999995, 158.5999999999999, -190.30000000000004, -217.60000000000002, 160.39999999999975, 20.000000000000014, 20.000000000000014, 137.00000000000003, 105.7999999999999, 100.09999999999997, 21.799999999999734, 153.79999999999998, 155.0, 123.79999999999981, 152.0, 178.39999999999992, 172.69999999999996, 20.000000000000014, 106.39999999999998, 26.899999999999835, 7.400000000000027, -211.0, 193.1, -21.999999999999744, 65.0, -331.0, 130.69999999999993, 163.40000000000003, 20.000000000000014, 93.49999999999997, 39.49999999999999, 134.2999999999999, -31.600000000000072, -38.799999999999756, -70.90000000000012, 85.10000000000004, 119.29999999999998, -4.0, 149.0, 164.8999999999999, -209.8, -211.6, 144.1999999999998, 158.0, 58.10000000000007, 105.49999999999991, 115.39999999999995, 7.399999999999965, -21.999999999999744, 82.10000000000002], "policy_predator_policy_reward": [14.0, 25.0, 4.0, 2.0, 23.0, 19.0, 171.0, 12.0, 0.0, 8.0, 36.0, 12.0, 46.0, 57.0, 3.0, 2.0, 60.0, 59.0, 29.0, 18.0, 4.0, 0.0, 3.0, 3.0, 7.0, 0.0, 51.0, 118.0, 15.0, 19.0, 31.0, 36.0, 13.0, 0.0, 1.0, 6.0, 44.0, 3.0, 7.0, 0.0, 6.0, 45.0, 4.0, 0.0, 52.0, 123.0, 147.0, 111.0, 23.0, 4.0, 63.0, 60.0, 26.0, 27.0, 0.0, 9.0, 17.0, 8.0, 5.0, 7.0, 14.0, 1.0, 17.0, 49.0, 14.0, 0.0, 26.0, 30.0, 28.0, 3.0, 24.0, 42.0, 7.0, 38.0, 7.0, 26.0, 23.0, 21.0, 83.0, 66.0, 12.0, 20.0, 20.0, 41.0, 18.0, 15.0, 17.0, 18.0, 0.0, 24.0, 16.0, 197.0, 33.0, 7.0, 13.0, 6.0, 10.0, 30.0, 11.0, 26.0, 5.0, 4.0, 19.0, 4.0, 19.0, 9.0, 19.0, 20.0, 7.0, 31.0, 8.0, 48.0, 4.0, 32.0, 16.0, 47.0, 14.0, 13.0, 14.0, 14.0, 11.0, 0.0, 31.0, 40.0, 11.0, 95.0, 16.0, 14.0, 7.0, 9.0, 177.0, 31.0, 24.0, 41.0, 106.0, 9.0, 11.0, 15.0, 21.0, 80.0, 19.0, 129.0, 1.0, 34.0, 0.0, 11.0, 1.0, 110.0, 5.0, 31.0, 15.0, 19.0, 147.0, 25.0, 0.0, 0.0, 7.0, 15.0, 28.0, 19.0, 31.0, 53.0, 6.0, 14.0, 0.0, 13.0, 7.0, 2.0, 12.0, 48.0, 14.0, 128.0, 20.0, 15.0, 176.0, 24.0, 2.0, 3.0, 34.0, 0.0, 0.0, 31.0, 53.0, 48.0, 78.0, 45.0, 56.0, 68.0, 6.0, 14.0, 153.0, 23.0, 14.0, 13.0, 26.0, 26.0, 11.0, 24.0, 9.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.537709328626439, "mean_inference_ms": 1.385724046242497, "mean_action_processing_ms": 0.22964423412284993, "mean_env_wait_ms": 0.17624363813676663, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003278493881225586, "StateBufferConnector_ms": 0.0027829408645629883, "ViewRequirementAgentConnector_ms": 0.09375441074371338}, "num_episodes": 23, "episode_return_max": 370.0000000000003, "episode_return_min": -444.4999999999997, "episode_return_mean": 166.49099999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 424.6308863119793, "num_env_steps_trained_throughput_per_sec": 424.6308863119793, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 9076.163, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9076.121, "sample_time_ms": 1023.599, "learn_time_ms": 8040.581, "learn_throughput": 497.477, "synch_weights_time_ms": 11.172}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-37-05", "timestamp": 1723646225, "time_this_iter_s": 9.423115015029907, "time_total_s": 745.1105036735535, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0efaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 745.1105036735535, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 30.200000000000006, "ram_util_percent": 77.67857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.479095256076288, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 6.4836024534134635, "policy_loss": -0.005499563327985545, "vf_loss": 6.488144474937802, "vf_explained_var": 0.04649345802251624, "kl": 0.008511379117113606, "entropy": 0.8646182834786713, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4660962921286385, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 2.886198755420705, "policy_loss": -0.006069100921648363, "vf_loss": 2.8914486906515857, "vf_explained_var": 0.14289236866607868, "kl": 0.008191659193661984, "entropy": 0.4800908772876023, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 346.8000000000003, "episode_reward_min": -474.1999999999989, "episode_reward_mean": 160.16299999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.6000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 46.94149999999998, "predator_policy": 33.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [273.60000000000014, 319.4, 222.39999999999986, 313.6999999999999, 162.79999999999993, 153.9999999999999, 338.20000000000005, 225.39999999999978, 148.5000000000001, 23.800000000000033, 148.39999999999955, 181.29999999999922, 309.70000000000056, 238.29999999999998, 346.8000000000003, 229.49999999999997, 110.29999999999912, 93.99999999999997, -13.699999999999541, 294.1, 321.0000000000008, 54.899999999999835, 188.99999999999926, 133.39999999999964, 224.49999999999986, 243.59999999999974, 224.1999999999995, -444.4999999999997, 301.9999999999999, 302.5999999999996, 55.400000000000226, 297.1999999999999, 189.39999999999924, 274.1999999999996, 305.3, 330.4000000000005, 278.0999999999998, 174.60000000000002, 317.5, 110.49999999999974, 332.50000000000017, 179.89999999999924, 177.29999999999953, 239.99999999999991, 177.2, 183.99999999999932, 170.2999999999994, -177.100000000001, 189.8999999999999, -58.60000000000052, 155.09999999999917, 188.10000000000002, -73.90000000000066, 148.49999999999966, 27.90000000000011, -50.600000000000364, 281.19999999999993, 291.5000000000002, -235.89999999999972, 180.399999999999, 178.99999999999946, 252.8999999999999, 259.5999999999999, 298.7999999999996, 343.4000000000002, 201.69999999999928, 193.29999999999995, -61.600000000000215, 206.0999999999993, -66.00000000000006, 299.0999999999998, 147.4999999999996, 204.7999999999993, 30.599999999999604, 137.2, 239.29999999999998, 333.9000000000001, -245.39999999999998, 329.1999999999999, 215.59999999999982, 157.79999999999947, 113.09999999999985, 195.70000000000005, 257.9999999999998, 285.29999999999984, 241.00000000000003, 129.39999999999995, -474.1999999999989, -238.10000000000034, 291.9000000000001, 83.8, 231.00000000000006, 9.3000000000001, 291.29999999999984, 75.30000000000001, 219.39999999999992, -173.40000000000066, -72.20000000000054, 339.40000000000003, 221.99999999999963], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.29999999999987, 56.30000000000001, 173.0, 139.39999999999998, 132.49999999999994, 38.90000000000004, 160.9999999999999, 148.69999999999996, -171.70000000000002, 159.49999999999991, 170.29999999999995, -274.2999999999996, 192.79999999999995, 118.39999999999992, -38.500000000000014, 140.89999999999992, 66.50000000000004, 29.000000000000085, 9.499999999999964, 5.299999999999965, 111.79999999999997, 11.599999999999964, 20.000000000000014, 149.29999999999987, 160.99999999999986, 133.7, 113.30000000000003, 59.0, 187.09999999999994, 145.6999999999999, 127.10000000000002, 46.40000000000007, 118.09999999999957, -38.799999999999756, 30.80000000000004, -2.800000000000082, 1.0999999999999865, -59.80000000000062, 168.7999999999999, 92.29999999999995, 163.9999999999999, 112.99999999999989, -136.3000000000002, 42.199999999999974, 187.39999999999992, -30.39999999999975, 13.399999999999958, 58.999999999999936, 93.80000000000001, 97.70000000000007, 99.49999999999997, 109.10000000000002, 102.19999999999983, 98.00000000000003, -307.0, -350.4999999999998, 179.0, 83.0, 142.10000000000002, 141.49999999999991, -0.9999999999999846, 16.40000000000003, 62.00000000000004, 198.2, 23.600000000000072, 156.7999999999999, 139.99999999999997, 111.19999999999993, 131.89999999999998, 145.39999999999984, 117.49999999999987, 173.89999999999984, 61.100000000000016, 179.0, 70.4, 48.20000000000002, 178.40000000000003, 103.1, 19.399999999999785, 28.09999999999998, 161.0, 144.49999999999994, 25.4000000000001, 126.5, 20.000000000000014, 146.30000000000004, 188.3, -19.300000000000082, 167.29999999999998, -96.10000000000005, -13.599999999999783, 167.59999999999994, 134.30000000000004, 20.000000000000014, -45.099999999999774, -339.9999999999998, 69.49999999999999, 55.39999999999992, -181.00000000000028, 7.399999999999965, 109.09999999999982, 20.000000000000014, -6.100000000000051, 93.20000000000003, -237.69999999999993, 15.799999999999963, 164.90000000000003, -51.40000000000002, 20.000000000000014, -3.099999999999958, -124.00000000000017, -37.60000000000019, 118.4, 126.79999999999998, 98.89999999999995, 158.5999999999999, -190.30000000000004, -217.60000000000002, 160.39999999999975, 20.000000000000014, 20.000000000000014, 137.00000000000003, 105.7999999999999, 100.09999999999997, 21.799999999999734, 153.79999999999998, 155.0, 123.79999999999981, 152.0, 178.39999999999992, 172.69999999999996, 20.000000000000014, 106.39999999999998, 26.899999999999835, 7.400000000000027, -211.0, 193.1, -21.999999999999744, 65.0, -331.0, 130.69999999999993, 163.40000000000003, 20.000000000000014, 93.49999999999997, 39.49999999999999, 134.2999999999999, -31.600000000000072, -38.799999999999756, -70.90000000000012, 85.10000000000004, 119.29999999999998, -4.0, 149.0, 164.8999999999999, -209.8, -211.6, 144.1999999999998, 158.0, 58.10000000000007, 105.49999999999991, 115.39999999999995, 7.399999999999965, -21.999999999999744, 82.10000000000002, 91.09999999999995, 53.599999999999966, 120.19999999999982, 69.8, 138.1999999999999, 127.0999999999999, 93.80000000000004, 93.19999999999999, 135.49999999999977, -108.10000000000011, -370.6000000000001, -328.5999999999992, -161.5000000000003, -346.6, 135.49999999999997, 118.39999999999992, 90.19999999999999, -51.40000000000005, 70.40000000000005, 119.60000000000002, -26.199999999999747, -92.5000000000002, 102.79999999999998, 168.5, 179.29999999999987, -276.9999999999999, 86.29999999999994, 94.1, -7.299999999999891, -360.09999999999985, -51.4000000000002, -191.80000000000015, 148.1, 161.29999999999978, 131.59999999999988, 31.40000000000009], "policy_predator_policy_reward": [44.0, 3.0, 7.0, 0.0, 6.0, 45.0, 4.0, 0.0, 52.0, 123.0, 147.0, 111.0, 23.0, 4.0, 63.0, 60.0, 26.0, 27.0, 0.0, 9.0, 17.0, 8.0, 5.0, 7.0, 14.0, 1.0, 17.0, 49.0, 14.0, 0.0, 26.0, 30.0, 28.0, 3.0, 24.0, 42.0, 7.0, 38.0, 7.0, 26.0, 23.0, 21.0, 83.0, 66.0, 12.0, 20.0, 20.0, 41.0, 18.0, 15.0, 17.0, 18.0, 0.0, 24.0, 16.0, 197.0, 33.0, 7.0, 13.0, 6.0, 10.0, 30.0, 11.0, 26.0, 5.0, 4.0, 19.0, 4.0, 19.0, 9.0, 19.0, 20.0, 7.0, 31.0, 8.0, 48.0, 4.0, 32.0, 16.0, 47.0, 14.0, 13.0, 14.0, 14.0, 11.0, 0.0, 31.0, 40.0, 11.0, 95.0, 16.0, 14.0, 7.0, 9.0, 177.0, 31.0, 24.0, 41.0, 106.0, 9.0, 11.0, 15.0, 21.0, 80.0, 19.0, 129.0, 1.0, 34.0, 0.0, 11.0, 1.0, 110.0, 5.0, 31.0, 15.0, 19.0, 147.0, 25.0, 0.0, 0.0, 7.0, 15.0, 28.0, 19.0, 31.0, 53.0, 6.0, 14.0, 0.0, 13.0, 7.0, 2.0, 12.0, 48.0, 14.0, 128.0, 20.0, 15.0, 176.0, 24.0, 2.0, 3.0, 34.0, 0.0, 0.0, 31.0, 53.0, 48.0, 78.0, 45.0, 56.0, 68.0, 6.0, 14.0, 153.0, 23.0, 14.0, 13.0, 26.0, 26.0, 11.0, 24.0, 9.0, 44.0, 23.0, 28.0, 40.0, 28.0, 9.0, 11.0, 27.0, 27.0, 88.0, 14.0, 25.0, 200.0, 85.0, 185.0, 15.0, 23.0, 34.0, 11.0, 25.0, 16.0, 80.0, 48.0, 4.0, 16.0, 143.0, 30.0, 12.0, 27.0, 185.0, 9.0, 30.0, 141.0, 13.0, 17.0, 22.0, 37.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5372165798650638, "mean_inference_ms": 1.384604766142731, "mean_action_processing_ms": 0.2294512406500341, "mean_env_wait_ms": 0.1760956143187449, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033532381057739258, "StateBufferConnector_ms": 0.002802729606628418, "ViewRequirementAgentConnector_ms": 0.09393572807312012}, "num_episodes": 18, "episode_return_max": 346.8000000000003, "episode_return_min": -474.1999999999989, "episode_return_mean": 160.16299999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 429.9042650863654, "num_env_steps_trained_throughput_per_sec": 429.9042650863654, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 9103.655, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9103.612, "sample_time_ms": 1025.301, "learn_time_ms": 8066.184, "learn_throughput": 495.897, "synch_weights_time_ms": 11.336}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-37-15", "timestamp": 1723646235, "time_this_iter_s": 9.309278011322021, "time_total_s": 754.4197816848755, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b186820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 754.4197816848755, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 29.738461538461536, "ram_util_percent": 77.47692307692309}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.442991638435888, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 6.427767994542601, "policy_loss": -0.0040723971795862315, "vf_loss": 6.430899345811713, "vf_explained_var": 0.16130842090283753, "kl": 0.008364801263002895, "entropy": 0.9094361503918965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2189620832286816, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 3.0329335602502976, "policy_loss": -0.0060847541797787895, "vf_loss": 3.0379701795401397, "vf_explained_var": 0.1516751933980871, "kl": 0.010481283468782172, "entropy": 0.45994874024517324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 368.1000000000006, "episode_reward_min": -474.1999999999989, "episode_reward_mean": 147.3639999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 38.43199999999998, "predator_policy": 35.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [188.99999999999926, 133.39999999999964, 224.49999999999986, 243.59999999999974, 224.1999999999995, -444.4999999999997, 301.9999999999999, 302.5999999999996, 55.400000000000226, 297.1999999999999, 189.39999999999924, 274.1999999999996, 305.3, 330.4000000000005, 278.0999999999998, 174.60000000000002, 317.5, 110.49999999999974, 332.50000000000017, 179.89999999999924, 177.29999999999953, 239.99999999999991, 177.2, 183.99999999999932, 170.2999999999994, -177.100000000001, 189.8999999999999, -58.60000000000052, 155.09999999999917, 188.10000000000002, -73.90000000000066, 148.49999999999966, 27.90000000000011, -50.600000000000364, 281.19999999999993, 291.5000000000002, -235.89999999999972, 180.399999999999, 178.99999999999946, 252.8999999999999, 259.5999999999999, 298.7999999999996, 343.4000000000002, 201.69999999999928, 193.29999999999995, -61.600000000000215, 206.0999999999993, -66.00000000000006, 299.0999999999998, 147.4999999999996, 204.7999999999993, 30.599999999999604, 137.2, 239.29999999999998, 333.9000000000001, -245.39999999999998, 329.1999999999999, 215.59999999999982, 157.79999999999947, 113.09999999999985, 195.70000000000005, 257.9999999999998, 285.29999999999984, 241.00000000000003, 129.39999999999995, -474.1999999999989, -238.10000000000034, 291.9000000000001, 83.8, 231.00000000000006, 9.3000000000001, 291.29999999999984, 75.30000000000001, 219.39999999999992, -173.40000000000066, -72.20000000000054, 339.40000000000003, 221.99999999999963, -183.8000000000009, 368.1000000000006, 343.59999999999997, 224.09999999999982, 129.69999999999985, 297.10000000000025, 263.89999999999986, 146.79999999999944, 235.49999999999972, 99.10000000000002, -5.999999999999833, 261.59999999999957, 296.5, 132.69999999999962, 210.69999999999965, 181.79999999999978, 3.3000000000000527, -152.7000000000007, 223.09999999999997, 72.09999999999977, 288.00000000000017, -218.70000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [187.39999999999992, -30.39999999999975, 13.399999999999958, 58.999999999999936, 93.80000000000001, 97.70000000000007, 99.49999999999997, 109.10000000000002, 102.19999999999983, 98.00000000000003, -307.0, -350.4999999999998, 179.0, 83.0, 142.10000000000002, 141.49999999999991, -0.9999999999999846, 16.40000000000003, 62.00000000000004, 198.2, 23.600000000000072, 156.7999999999999, 139.99999999999997, 111.19999999999993, 131.89999999999998, 145.39999999999984, 117.49999999999987, 173.89999999999984, 61.100000000000016, 179.0, 70.4, 48.20000000000002, 178.40000000000003, 103.1, 19.399999999999785, 28.09999999999998, 161.0, 144.49999999999994, 25.4000000000001, 126.5, 20.000000000000014, 146.30000000000004, 188.3, -19.300000000000082, 167.29999999999998, -96.10000000000005, -13.599999999999783, 167.59999999999994, 134.30000000000004, 20.000000000000014, -45.099999999999774, -339.9999999999998, 69.49999999999999, 55.39999999999992, -181.00000000000028, 7.399999999999965, 109.09999999999982, 20.000000000000014, -6.100000000000051, 93.20000000000003, -237.69999999999993, 15.799999999999963, 164.90000000000003, -51.40000000000002, 20.000000000000014, -3.099999999999958, -124.00000000000017, -37.60000000000019, 118.4, 126.79999999999998, 98.89999999999995, 158.5999999999999, -190.30000000000004, -217.60000000000002, 160.39999999999975, 20.000000000000014, 20.000000000000014, 137.00000000000003, 105.7999999999999, 100.09999999999997, 21.799999999999734, 153.79999999999998, 155.0, 123.79999999999981, 152.0, 178.39999999999992, 172.69999999999996, 20.000000000000014, 106.39999999999998, 26.899999999999835, 7.400000000000027, -211.0, 193.1, -21.999999999999744, 65.0, -331.0, 130.69999999999993, 163.40000000000003, 20.000000000000014, 93.49999999999997, 39.49999999999999, 134.2999999999999, -31.600000000000072, -38.799999999999756, -70.90000000000012, 85.10000000000004, 119.29999999999998, -4.0, 149.0, 164.8999999999999, -209.8, -211.6, 144.1999999999998, 158.0, 58.10000000000007, 105.49999999999991, 115.39999999999995, 7.399999999999965, -21.999999999999744, 82.10000000000002, 91.09999999999995, 53.599999999999966, 120.19999999999982, 69.8, 138.1999999999999, 127.0999999999999, 93.80000000000004, 93.19999999999999, 135.49999999999977, -108.10000000000011, -370.6000000000001, -328.5999999999992, -161.5000000000003, -346.6, 135.49999999999997, 118.39999999999992, 90.19999999999999, -51.40000000000005, 70.40000000000005, 119.60000000000002, -26.199999999999747, -92.5000000000002, 102.79999999999998, 168.5, 179.29999999999987, -276.9999999999999, 86.29999999999994, 94.1, -7.299999999999891, -360.09999999999985, -51.4000000000002, -191.80000000000015, 148.1, 161.29999999999978, 131.59999999999988, 31.40000000000009, -30.39999999999975, -387.4, 175.9999999999999, 190.09999999999994, 124.70000000000002, 170.89999999999995, 100.1, 64.99999999999997, -72.69999999999999, 40.39999999999992, 159.79999999999995, 89.29999999999993, 143.2999999999999, 89.60000000000004, 120.19999999999999, 11.599999999999964, 50.89999999999995, 131.5999999999997, 16.400000000000077, -73.30000000000001, -133.3, -33.699999999999754, 111.49999999999972, 139.09999999999988, 186.49999999999997, 109.99999999999982, 109.39999999999992, -15.699999999999747, 101.6, 61.10000000000006, 44.29999999999993, 81.49999999999986, -51.399999999999835, -7.299999999999891, -344.4999999999999, 15.799999999999955, 56.90000000000006, 120.19999999999993, -3.6999999999999957, 15.799999999999963, 106.10000000000001, 119.9, -358.9, -62.80000000000003], "policy_predator_policy_reward": [12.0, 20.0, 20.0, 41.0, 18.0, 15.0, 17.0, 18.0, 0.0, 24.0, 16.0, 197.0, 33.0, 7.0, 13.0, 6.0, 10.0, 30.0, 11.0, 26.0, 5.0, 4.0, 19.0, 4.0, 19.0, 9.0, 19.0, 20.0, 7.0, 31.0, 8.0, 48.0, 4.0, 32.0, 16.0, 47.0, 14.0, 13.0, 14.0, 14.0, 11.0, 0.0, 31.0, 40.0, 11.0, 95.0, 16.0, 14.0, 7.0, 9.0, 177.0, 31.0, 24.0, 41.0, 106.0, 9.0, 11.0, 15.0, 21.0, 80.0, 19.0, 129.0, 1.0, 34.0, 0.0, 11.0, 1.0, 110.0, 5.0, 31.0, 15.0, 19.0, 147.0, 25.0, 0.0, 0.0, 7.0, 15.0, 28.0, 19.0, 31.0, 53.0, 6.0, 14.0, 0.0, 13.0, 7.0, 2.0, 12.0, 48.0, 14.0, 128.0, 20.0, 15.0, 176.0, 24.0, 2.0, 3.0, 34.0, 0.0, 0.0, 31.0, 53.0, 48.0, 78.0, 45.0, 56.0, 68.0, 6.0, 14.0, 153.0, 23.0, 14.0, 13.0, 26.0, 26.0, 11.0, 24.0, 9.0, 44.0, 23.0, 28.0, 40.0, 28.0, 9.0, 11.0, 27.0, 27.0, 88.0, 14.0, 25.0, 200.0, 85.0, 185.0, 15.0, 23.0, 34.0, 11.0, 25.0, 16.0, 80.0, 48.0, 4.0, 16.0, 143.0, 30.0, 12.0, 27.0, 185.0, 9.0, 30.0, 141.0, 13.0, 17.0, 22.0, 37.0, 191.0, 43.0, 0.0, 2.0, 24.0, 24.0, 22.0, 37.0, 71.0, 91.0, 27.0, 21.0, 11.0, 20.0, 10.0, 5.0, 19.0, 34.0, 109.0, 47.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 30.0, 9.0, 43.0, 5.0, 14.0, 42.0, 23.0, 39.0, 2.0, 174.0, 34.0, 12.0, 12.0, 48.0, 26.0, 36.0, 178.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.536532612725391, "mean_inference_ms": 1.3844287082813553, "mean_action_processing_ms": 0.2289681046811158, "mean_env_wait_ms": 0.17579793857924458, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033750534057617188, "StateBufferConnector_ms": 0.0028204917907714844, "ViewRequirementAgentConnector_ms": 0.09057748317718506}, "num_episodes": 22, "episode_return_max": 368.1000000000006, "episode_return_min": -474.1999999999989, "episode_return_mean": 147.3639999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 443.90791525751683, "num_env_steps_trained_throughput_per_sec": 443.90791525751683, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 9106.999, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9106.956, "sample_time_ms": 1022.013, "learn_time_ms": 8072.858, "learn_throughput": 495.487, "synch_weights_time_ms": 11.295}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-37-24", "timestamp": 1723646244, "time_this_iter_s": 9.014663934707642, "time_total_s": 763.4344456195831, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 763.4344456195831, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 26.338461538461534, "ram_util_percent": 77.4076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7920720848772262, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 7.3600412310746615, "policy_loss": -0.006498567181240235, "vf_loss": 7.365378819823896, "vf_explained_var": -0.18216649984556532, "kl": 0.010319919782977803, "entropy": 0.9277681574935005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.294062560134464, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.014200004446444, "policy_loss": -0.008325424078093082, "vf_loss": 5.0213201449661655, "vf_explained_var": 0.11534054673538006, "kl": 0.012052890234329825, "entropy": 0.4471025871221351, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 368.1000000000006, "episode_reward_min": -544.5999999999999, "episode_reward_mean": 111.67899999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.1, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 12.65449999999998, "predator_policy": 43.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [332.50000000000017, 179.89999999999924, 177.29999999999953, 239.99999999999991, 177.2, 183.99999999999932, 170.2999999999994, -177.100000000001, 189.8999999999999, -58.60000000000052, 155.09999999999917, 188.10000000000002, -73.90000000000066, 148.49999999999966, 27.90000000000011, -50.600000000000364, 281.19999999999993, 291.5000000000002, -235.89999999999972, 180.399999999999, 178.99999999999946, 252.8999999999999, 259.5999999999999, 298.7999999999996, 343.4000000000002, 201.69999999999928, 193.29999999999995, -61.600000000000215, 206.0999999999993, -66.00000000000006, 299.0999999999998, 147.4999999999996, 204.7999999999993, 30.599999999999604, 137.2, 239.29999999999998, 333.9000000000001, -245.39999999999998, 329.1999999999999, 215.59999999999982, 157.79999999999947, 113.09999999999985, 195.70000000000005, 257.9999999999998, 285.29999999999984, 241.00000000000003, 129.39999999999995, -474.1999999999989, -238.10000000000034, 291.9000000000001, 83.8, 231.00000000000006, 9.3000000000001, 291.29999999999984, 75.30000000000001, 219.39999999999992, -173.40000000000066, -72.20000000000054, 339.40000000000003, 221.99999999999963, -183.8000000000009, 368.1000000000006, 343.59999999999997, 224.09999999999982, 129.69999999999985, 297.10000000000025, 263.89999999999986, 146.79999999999944, 235.49999999999972, 99.10000000000002, -5.999999999999833, 261.59999999999957, 296.5, 132.69999999999962, 210.69999999999965, 181.79999999999978, 3.3000000000000527, -152.7000000000007, 223.09999999999997, 72.09999999999977, 288.00000000000017, -218.70000000000005, -93.7000000000001, -81.10000000000055, 309.40000000000015, 40.90000000000005, 229.19999999999987, -86.20000000000027, -6.400000000000022, 13.100000000000037, 76.80000000000008, -228.60000000000014, -544.5999999999999, 148.69999999999962, 216.79999999999998, 272.89999999999986, 310.20000000000067, -347.9999999999999, -104.8000000000002, -185.70000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [161.0, 144.49999999999994, 25.4000000000001, 126.5, 20.000000000000014, 146.30000000000004, 188.3, -19.300000000000082, 167.29999999999998, -96.10000000000005, -13.599999999999783, 167.59999999999994, 134.30000000000004, 20.000000000000014, -45.099999999999774, -339.9999999999998, 69.49999999999999, 55.39999999999992, -181.00000000000028, 7.399999999999965, 109.09999999999982, 20.000000000000014, -6.100000000000051, 93.20000000000003, -237.69999999999993, 15.799999999999963, 164.90000000000003, -51.40000000000002, 20.000000000000014, -3.099999999999958, -124.00000000000017, -37.60000000000019, 118.4, 126.79999999999998, 98.89999999999995, 158.5999999999999, -190.30000000000004, -217.60000000000002, 160.39999999999975, 20.000000000000014, 20.000000000000014, 137.00000000000003, 105.7999999999999, 100.09999999999997, 21.799999999999734, 153.79999999999998, 155.0, 123.79999999999981, 152.0, 178.39999999999992, 172.69999999999996, 20.000000000000014, 106.39999999999998, 26.899999999999835, 7.400000000000027, -211.0, 193.1, -21.999999999999744, 65.0, -331.0, 130.69999999999993, 163.40000000000003, 20.000000000000014, 93.49999999999997, 39.49999999999999, 134.2999999999999, -31.600000000000072, -38.799999999999756, -70.90000000000012, 85.10000000000004, 119.29999999999998, -4.0, 149.0, 164.8999999999999, -209.8, -211.6, 144.1999999999998, 158.0, 58.10000000000007, 105.49999999999991, 115.39999999999995, 7.399999999999965, -21.999999999999744, 82.10000000000002, 91.09999999999995, 53.599999999999966, 120.19999999999982, 69.8, 138.1999999999999, 127.0999999999999, 93.80000000000004, 93.19999999999999, 135.49999999999977, -108.10000000000011, -370.6000000000001, -328.5999999999992, -161.5000000000003, -346.6, 135.49999999999997, 118.39999999999992, 90.19999999999999, -51.40000000000005, 70.40000000000005, 119.60000000000002, -26.199999999999747, -92.5000000000002, 102.79999999999998, 168.5, 179.29999999999987, -276.9999999999999, 86.29999999999994, 94.1, -7.299999999999891, -360.09999999999985, -51.4000000000002, -191.80000000000015, 148.1, 161.29999999999978, 131.59999999999988, 31.40000000000009, -30.39999999999975, -387.4, 175.9999999999999, 190.09999999999994, 124.70000000000002, 170.89999999999995, 100.1, 64.99999999999997, -72.69999999999999, 40.39999999999992, 159.79999999999995, 89.29999999999993, 143.2999999999999, 89.60000000000004, 120.19999999999999, 11.599999999999964, 50.89999999999995, 131.5999999999997, 16.400000000000077, -73.30000000000001, -133.3, -33.699999999999754, 111.49999999999972, 139.09999999999988, 186.49999999999997, 109.99999999999982, 109.39999999999992, -15.699999999999747, 101.6, 61.10000000000006, 44.29999999999993, 81.49999999999986, -51.399999999999835, -7.299999999999891, -344.4999999999999, 15.799999999999955, 56.90000000000006, 120.19999999999993, -3.6999999999999957, 15.799999999999963, 106.10000000000001, 119.9, -358.9, -62.80000000000003, -281.8, -19.899999999999743, -312.70000000000005, -30.39999999999975, 95.59999999999995, 192.79999999999998, -61.90000000000054, -5.199999999999967, 134.29999999999998, 59.8999999999999, -226.60000000000008, -28.600000000000044, -103.00000000000007, -33.39999999999999, -292.3, 121.39999999999999, -2.19999999999996, 20.000000000000014, -264.7000000000001, -145.9, -392.8, -371.8, -5.1999999999999265, 122.9, 18.5, 95.30000000000003, 147.79999999999984, 43.100000000000044, 167.2999999999998, 134.89999999999978, -318.4, -265.60000000000014, -236.2, -34.59999999999975, -311.4999999999999, -83.20000000000033], "policy_predator_policy_reward": [14.0, 13.0, 14.0, 14.0, 11.0, 0.0, 31.0, 40.0, 11.0, 95.0, 16.0, 14.0, 7.0, 9.0, 177.0, 31.0, 24.0, 41.0, 106.0, 9.0, 11.0, 15.0, 21.0, 80.0, 19.0, 129.0, 1.0, 34.0, 0.0, 11.0, 1.0, 110.0, 5.0, 31.0, 15.0, 19.0, 147.0, 25.0, 0.0, 0.0, 7.0, 15.0, 28.0, 19.0, 31.0, 53.0, 6.0, 14.0, 0.0, 13.0, 7.0, 2.0, 12.0, 48.0, 14.0, 128.0, 20.0, 15.0, 176.0, 24.0, 2.0, 3.0, 34.0, 0.0, 0.0, 31.0, 53.0, 48.0, 78.0, 45.0, 56.0, 68.0, 6.0, 14.0, 153.0, 23.0, 14.0, 13.0, 26.0, 26.0, 11.0, 24.0, 9.0, 44.0, 23.0, 28.0, 40.0, 28.0, 9.0, 11.0, 27.0, 27.0, 88.0, 14.0, 25.0, 200.0, 85.0, 185.0, 15.0, 23.0, 34.0, 11.0, 25.0, 16.0, 80.0, 48.0, 4.0, 16.0, 143.0, 30.0, 12.0, 27.0, 185.0, 9.0, 30.0, 141.0, 13.0, 17.0, 22.0, 37.0, 191.0, 43.0, 0.0, 2.0, 24.0, 24.0, 22.0, 37.0, 71.0, 91.0, 27.0, 21.0, 11.0, 20.0, 10.0, 5.0, 19.0, 34.0, 109.0, 47.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 30.0, 9.0, 43.0, 5.0, 14.0, 42.0, 23.0, 39.0, 2.0, 174.0, 34.0, 12.0, 12.0, 48.0, 26.0, 36.0, 178.0, 25.0, 34.0, 174.0, 115.0, 147.0, 18.0, 3.0, 60.0, 48.0, 35.0, 0.0, 32.0, 137.0, 99.0, 31.0, 22.0, 162.0, 0.0, 59.0, 24.0, 158.0, 199.0, 21.0, 5.0, 26.0, 59.0, 44.0, 42.0, 40.0, 7.0, 1.0, 53.0, 183.0, 166.0, 0.0, 40.0, 169.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5361659180044666, "mean_inference_ms": 1.3822044433885656, "mean_action_processing_ms": 0.22901640274315022, "mean_env_wait_ms": 0.17575920745776666, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033589601516723633, "StateBufferConnector_ms": 0.002812981605529785, "ViewRequirementAgentConnector_ms": 0.09170067310333252}, "num_episodes": 18, "episode_return_max": 368.1000000000006, "episode_return_min": -544.5999999999999, "episode_return_mean": 111.67899999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 441.35028245317835, "num_env_steps_trained_throughput_per_sec": 441.35028245317835, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 9115.979, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9115.935, "sample_time_ms": 1016.782, "learn_time_ms": 8086.962, "learn_throughput": 494.623, "synch_weights_time_ms": 11.411}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-37-33", "timestamp": 1723646253, "time_this_iter_s": 9.065949201583862, "time_total_s": 772.500394821167, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aaca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 772.500394821167, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 25.77692307692308, "ram_util_percent": 77.5769230769231}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4370571805686545, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 7.651884046433464, "policy_loss": -0.00328401831402468, "vf_loss": 7.654347738639387, "vf_explained_var": -0.12464039458168877, "kl": 0.0072919052523498585, "entropy": 0.9399962679103568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8273512885368692, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 4.738714094010611, "policy_loss": -0.0075920208210677464, "vf_loss": 4.745345647625191, "vf_explained_var": 0.1615602328979149, "kl": 0.009604675366936544, "entropy": 0.35529939786151604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 368.1000000000006, "episode_reward_min": -544.5999999999999, "episode_reward_mean": 74.39099999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.1, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -15.59950000000002, "predator_policy": 52.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [298.7999999999996, 343.4000000000002, 201.69999999999928, 193.29999999999995, -61.600000000000215, 206.0999999999993, -66.00000000000006, 299.0999999999998, 147.4999999999996, 204.7999999999993, 30.599999999999604, 137.2, 239.29999999999998, 333.9000000000001, -245.39999999999998, 329.1999999999999, 215.59999999999982, 157.79999999999947, 113.09999999999985, 195.70000000000005, 257.9999999999998, 285.29999999999984, 241.00000000000003, 129.39999999999995, -474.1999999999989, -238.10000000000034, 291.9000000000001, 83.8, 231.00000000000006, 9.3000000000001, 291.29999999999984, 75.30000000000001, 219.39999999999992, -173.40000000000066, -72.20000000000054, 339.40000000000003, 221.99999999999963, -183.8000000000009, 368.1000000000006, 343.59999999999997, 224.09999999999982, 129.69999999999985, 297.10000000000025, 263.89999999999986, 146.79999999999944, 235.49999999999972, 99.10000000000002, -5.999999999999833, 261.59999999999957, 296.5, 132.69999999999962, 210.69999999999965, 181.79999999999978, 3.3000000000000527, -152.7000000000007, 223.09999999999997, 72.09999999999977, 288.00000000000017, -218.70000000000005, -93.7000000000001, -81.10000000000055, 309.40000000000015, 40.90000000000005, 229.19999999999987, -86.20000000000027, -6.400000000000022, 13.100000000000037, 76.80000000000008, -228.60000000000014, -544.5999999999999, 148.69999999999962, 216.79999999999998, 272.89999999999986, 310.20000000000067, -347.9999999999999, -104.8000000000002, -185.70000000000036, -104.89999999999996, 68.20000000000019, -269.20000000000005, -320.6, 209.39999999999938, -384.30000000000007, 177.5999999999993, -299.8000000000002, -79.30000000000044, 216.99999999999966, -100.60000000000025, -142.60000000000036, -184.60000000000025, 4.300000000000031, -278.39999999999907, 55.79999999999989, -14.599999999999753, 93.29999999999993, 207.29999999999995, 311.8, 148.79999999999995, 214.5999999999994, -238.80000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [155.0, 123.79999999999981, 152.0, 178.39999999999992, 172.69999999999996, 20.000000000000014, 106.39999999999998, 26.899999999999835, 7.400000000000027, -211.0, 193.1, -21.999999999999744, 65.0, -331.0, 130.69999999999993, 163.40000000000003, 20.000000000000014, 93.49999999999997, 39.49999999999999, 134.2999999999999, -31.600000000000072, -38.799999999999756, -70.90000000000012, 85.10000000000004, 119.29999999999998, -4.0, 149.0, 164.8999999999999, -209.8, -211.6, 144.1999999999998, 158.0, 58.10000000000007, 105.49999999999991, 115.39999999999995, 7.399999999999965, -21.999999999999744, 82.10000000000002, 91.09999999999995, 53.599999999999966, 120.19999999999982, 69.8, 138.1999999999999, 127.0999999999999, 93.80000000000004, 93.19999999999999, 135.49999999999977, -108.10000000000011, -370.6000000000001, -328.5999999999992, -161.5000000000003, -346.6, 135.49999999999997, 118.39999999999992, 90.19999999999999, -51.40000000000005, 70.40000000000005, 119.60000000000002, -26.199999999999747, -92.5000000000002, 102.79999999999998, 168.5, 179.29999999999987, -276.9999999999999, 86.29999999999994, 94.1, -7.299999999999891, -360.09999999999985, -51.4000000000002, -191.80000000000015, 148.1, 161.29999999999978, 131.59999999999988, 31.40000000000009, -30.39999999999975, -387.4, 175.9999999999999, 190.09999999999994, 124.70000000000002, 170.89999999999995, 100.1, 64.99999999999997, -72.69999999999999, 40.39999999999992, 159.79999999999995, 89.29999999999993, 143.2999999999999, 89.60000000000004, 120.19999999999999, 11.599999999999964, 50.89999999999995, 131.5999999999997, 16.400000000000077, -73.30000000000001, -133.3, -33.699999999999754, 111.49999999999972, 139.09999999999988, 186.49999999999997, 109.99999999999982, 109.39999999999992, -15.699999999999747, 101.6, 61.10000000000006, 44.29999999999993, 81.49999999999986, -51.399999999999835, -7.299999999999891, -344.4999999999999, 15.799999999999955, 56.90000000000006, 120.19999999999993, -3.6999999999999957, 15.799999999999963, 106.10000000000001, 119.9, -358.9, -62.80000000000003, -281.8, -19.899999999999743, -312.70000000000005, -30.39999999999975, 95.59999999999995, 192.79999999999998, -61.90000000000054, -5.199999999999967, 134.29999999999998, 59.8999999999999, -226.60000000000008, -28.600000000000044, -103.00000000000007, -33.39999999999999, -292.3, 121.39999999999999, -2.19999999999996, 20.000000000000014, -264.7000000000001, -145.9, -392.8, -371.8, -5.1999999999999265, 122.9, 18.5, 95.30000000000003, 147.79999999999984, 43.100000000000044, 167.2999999999998, 134.89999999999978, -318.4, -265.60000000000014, -236.2, -34.59999999999975, -311.4999999999999, -83.20000000000033, -193.00000000000003, -235.9000000000001, 20.000000000000014, -41.800000000000054, -237.10000000000002, -345.1, -290.79999999999995, -224.8, 111.49999999999977, 53.90000000000005, -289.3, -349.0, 149.89999999999992, 13.699999999999964, -235.00000000000023, -245.8, -1.0000000000000133, -220.30000000000004, 134.60000000000002, 46.40000000000003, -259.30000000000007, 13.699999999999964, -305.49999999999994, -3.099999999999958, -180.10000000000014, -185.50000000000017, 9.499999999999964, -125.20000000000003, -137.20000000000013, -362.19999999999993, -135.4000000000001, 42.200000000000045, -391.6, 20.000000000000014, -37.59999999999999, 5.899999999999945, 73.4, 65.9, 94.09999999999988, 184.6999999999999, 70.39999999999999, -1.599999999999973, 96.80000000000004, 81.79999999999967, -201.40000000000003, -189.4], "policy_predator_policy_reward": [6.0, 14.0, 0.0, 13.0, 7.0, 2.0, 12.0, 48.0, 14.0, 128.0, 20.0, 15.0, 176.0, 24.0, 2.0, 3.0, 34.0, 0.0, 0.0, 31.0, 53.0, 48.0, 78.0, 45.0, 56.0, 68.0, 6.0, 14.0, 153.0, 23.0, 14.0, 13.0, 26.0, 26.0, 11.0, 24.0, 9.0, 44.0, 23.0, 28.0, 40.0, 28.0, 9.0, 11.0, 27.0, 27.0, 88.0, 14.0, 25.0, 200.0, 85.0, 185.0, 15.0, 23.0, 34.0, 11.0, 25.0, 16.0, 80.0, 48.0, 4.0, 16.0, 143.0, 30.0, 12.0, 27.0, 185.0, 9.0, 30.0, 141.0, 13.0, 17.0, 22.0, 37.0, 191.0, 43.0, 0.0, 2.0, 24.0, 24.0, 22.0, 37.0, 71.0, 91.0, 27.0, 21.0, 11.0, 20.0, 10.0, 5.0, 19.0, 34.0, 109.0, 47.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 30.0, 9.0, 43.0, 5.0, 14.0, 42.0, 23.0, 39.0, 2.0, 174.0, 34.0, 12.0, 12.0, 48.0, 26.0, 36.0, 178.0, 25.0, 34.0, 174.0, 115.0, 147.0, 18.0, 3.0, 60.0, 48.0, 35.0, 0.0, 32.0, 137.0, 99.0, 31.0, 22.0, 162.0, 0.0, 59.0, 24.0, 158.0, 199.0, 21.0, 5.0, 26.0, 59.0, 44.0, 42.0, 40.0, 7.0, 1.0, 53.0, 183.0, 166.0, 0.0, 40.0, 169.0, 158.0, 166.0, 61.0, 29.0, 184.0, 129.0, 36.0, 159.0, 40.0, 4.0, 167.0, 87.0, 3.0, 11.0, 10.0, 171.0, 19.0, 123.0, 11.0, 25.0, 3.0, 142.0, 12.0, 154.0, 15.0, 166.0, 18.0, 102.0, 182.0, 39.0, 55.0, 94.0, 161.0, 196.0, 86.0, 39.0, 4.0, 64.0, 28.0, 5.0, 67.0, 13.0, 24.0, 12.0, 13.0, 139.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5355472569745295, "mean_inference_ms": 1.382016229451405, "mean_action_processing_ms": 0.22895790826724824, "mean_env_wait_ms": 0.17538975736031526, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0034606456756591797, "StateBufferConnector_ms": 0.0028766393661499023, "ViewRequirementAgentConnector_ms": 0.09315288066864014}, "num_episodes": 23, "episode_return_max": 368.1000000000006, "episode_return_min": -544.5999999999999, "episode_return_mean": 74.39099999999988, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 443.27356417028153, "num_env_steps_trained_throughput_per_sec": 443.27356417028153, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 9126.874, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9126.83, "sample_time_ms": 1020.329, "learn_time_ms": 8094.193, "learn_throughput": 494.181, "synch_weights_time_ms": 11.515}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-37-42", "timestamp": 1723646262, "time_this_iter_s": 9.027072668075562, "time_total_s": 781.5274674892426, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ebf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 781.5274674892426, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 26.06923076923077, "ram_util_percent": 77.58461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4315647752827436, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 6.984042391953645, "policy_loss": -0.006308746188090592, "vf_loss": 6.98925658912255, "vf_explained_var": -0.19511362364683202, "kl": 0.009729225293667888, "entropy": 0.9925152300526856, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4716569066363037, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.649060062125877, "policy_loss": -0.010293270117066131, "vf_loss": 5.6583888101830055, "vf_explained_var": 0.1329867497007683, "kl": 0.009645121433447732, "entropy": 0.49950370723923676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 368.1000000000006, "episode_reward_min": -544.5999999999999, "episode_reward_mean": 41.58799999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -41.35600000000002, "predator_policy": 62.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [113.09999999999985, 195.70000000000005, 257.9999999999998, 285.29999999999984, 241.00000000000003, 129.39999999999995, -474.1999999999989, -238.10000000000034, 291.9000000000001, 83.8, 231.00000000000006, 9.3000000000001, 291.29999999999984, 75.30000000000001, 219.39999999999992, -173.40000000000066, -72.20000000000054, 339.40000000000003, 221.99999999999963, -183.8000000000009, 368.1000000000006, 343.59999999999997, 224.09999999999982, 129.69999999999985, 297.10000000000025, 263.89999999999986, 146.79999999999944, 235.49999999999972, 99.10000000000002, -5.999999999999833, 261.59999999999957, 296.5, 132.69999999999962, 210.69999999999965, 181.79999999999978, 3.3000000000000527, -152.7000000000007, 223.09999999999997, 72.09999999999977, 288.00000000000017, -218.70000000000005, -93.7000000000001, -81.10000000000055, 309.40000000000015, 40.90000000000005, 229.19999999999987, -86.20000000000027, -6.400000000000022, 13.100000000000037, 76.80000000000008, -228.60000000000014, -544.5999999999999, 148.69999999999962, 216.79999999999998, 272.89999999999986, 310.20000000000067, -347.9999999999999, -104.8000000000002, -185.70000000000036, -104.89999999999996, 68.20000000000019, -269.20000000000005, -320.6, 209.39999999999938, -384.30000000000007, 177.5999999999993, -299.8000000000002, -79.30000000000044, 216.99999999999966, -100.60000000000025, -142.60000000000036, -184.60000000000025, 4.300000000000031, -278.39999999999907, 55.79999999999989, -14.599999999999753, 93.29999999999993, 207.29999999999995, 311.8, 148.79999999999995, 214.5999999999994, -238.80000000000004, 267.1999999999996, -13.5999999999998, 222.89999999999986, 276.3000000000002, -246.70000000000002, 283.5999999999995, 187.59999999999934, -11.199999999999923, 249.0999999999995, -2.599999999999943, -84.3000000000005, -470.2, -160.80000000000075, -355.20000000000016, 74.80000000000017, -80.79999999999998, -134.50000000000037, -316.5999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-21.999999999999744, 82.10000000000002, 91.09999999999995, 53.599999999999966, 120.19999999999982, 69.8, 138.1999999999999, 127.0999999999999, 93.80000000000004, 93.19999999999999, 135.49999999999977, -108.10000000000011, -370.6000000000001, -328.5999999999992, -161.5000000000003, -346.6, 135.49999999999997, 118.39999999999992, 90.19999999999999, -51.40000000000005, 70.40000000000005, 119.60000000000002, -26.199999999999747, -92.5000000000002, 102.79999999999998, 168.5, 179.29999999999987, -276.9999999999999, 86.29999999999994, 94.1, -7.299999999999891, -360.09999999999985, -51.4000000000002, -191.80000000000015, 148.1, 161.29999999999978, 131.59999999999988, 31.40000000000009, -30.39999999999975, -387.4, 175.9999999999999, 190.09999999999994, 124.70000000000002, 170.89999999999995, 100.1, 64.99999999999997, -72.69999999999999, 40.39999999999992, 159.79999999999995, 89.29999999999993, 143.2999999999999, 89.60000000000004, 120.19999999999999, 11.599999999999964, 50.89999999999995, 131.5999999999997, 16.400000000000077, -73.30000000000001, -133.3, -33.699999999999754, 111.49999999999972, 139.09999999999988, 186.49999999999997, 109.99999999999982, 109.39999999999992, -15.699999999999747, 101.6, 61.10000000000006, 44.29999999999993, 81.49999999999986, -51.399999999999835, -7.299999999999891, -344.4999999999999, 15.799999999999955, 56.90000000000006, 120.19999999999993, -3.6999999999999957, 15.799999999999963, 106.10000000000001, 119.9, -358.9, -62.80000000000003, -281.8, -19.899999999999743, -312.70000000000005, -30.39999999999975, 95.59999999999995, 192.79999999999998, -61.90000000000054, -5.199999999999967, 134.29999999999998, 59.8999999999999, -226.60000000000008, -28.600000000000044, -103.00000000000007, -33.39999999999999, -292.3, 121.39999999999999, -2.19999999999996, 20.000000000000014, -264.7000000000001, -145.9, -392.8, -371.8, -5.1999999999999265, 122.9, 18.5, 95.30000000000003, 147.79999999999984, 43.100000000000044, 167.2999999999998, 134.89999999999978, -318.4, -265.60000000000014, -236.2, -34.59999999999975, -311.4999999999999, -83.20000000000033, -193.00000000000003, -235.9000000000001, 20.000000000000014, -41.800000000000054, -237.10000000000002, -345.1, -290.79999999999995, -224.8, 111.49999999999977, 53.90000000000005, -289.3, -349.0, 149.89999999999992, 13.699999999999964, -235.00000000000023, -245.8, -1.0000000000000133, -220.30000000000004, 134.60000000000002, 46.40000000000003, -259.30000000000007, 13.699999999999964, -305.49999999999994, -3.099999999999958, -180.10000000000014, -185.50000000000017, 9.499999999999964, -125.20000000000003, -137.20000000000013, -362.19999999999993, -135.4000000000001, 42.200000000000045, -391.6, 20.000000000000014, -37.59999999999999, 5.899999999999945, 73.4, 65.9, 94.09999999999988, 184.6999999999999, 70.39999999999999, -1.599999999999973, 96.80000000000004, 81.79999999999967, -201.40000000000003, -189.4, 101.59999999999994, 149.59999999999997, -391.5999999999999, 20.000000000000014, 102.49999999999996, 76.40000000000002, 115.69999999999989, 89.60000000000002, -241.9, -395.79999999999995, 147.79999999999967, 75.80000000000004, 87.1999999999997, 73.39999999999966, 20.000000000000014, -293.1999999999998, 139.69999999999968, 76.40000000000009, -199.0000000000001, 7.399999999999965, 13.699999999999964, -385.0, -355.90000000000003, -334.30000000000007, -3.099999999999958, -351.7000000000001, -320.80000000000007, -216.4000000000001, -23.799999999999983, 8.600000000000023, -237.70000000000002, -3.099999999999958, -329.5, 20.000000000000014, -292.5999999999999, -343.0], "policy_predator_policy_reward": [9.0, 44.0, 23.0, 28.0, 40.0, 28.0, 9.0, 11.0, 27.0, 27.0, 88.0, 14.0, 25.0, 200.0, 85.0, 185.0, 15.0, 23.0, 34.0, 11.0, 25.0, 16.0, 80.0, 48.0, 4.0, 16.0, 143.0, 30.0, 12.0, 27.0, 185.0, 9.0, 30.0, 141.0, 13.0, 17.0, 22.0, 37.0, 191.0, 43.0, 0.0, 2.0, 24.0, 24.0, 22.0, 37.0, 71.0, 91.0, 27.0, 21.0, 11.0, 20.0, 10.0, 5.0, 19.0, 34.0, 109.0, 47.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 30.0, 9.0, 43.0, 5.0, 14.0, 42.0, 23.0, 39.0, 2.0, 174.0, 34.0, 12.0, 12.0, 48.0, 26.0, 36.0, 178.0, 25.0, 34.0, 174.0, 115.0, 147.0, 18.0, 3.0, 60.0, 48.0, 35.0, 0.0, 32.0, 137.0, 99.0, 31.0, 22.0, 162.0, 0.0, 59.0, 24.0, 158.0, 199.0, 21.0, 5.0, 26.0, 59.0, 44.0, 42.0, 40.0, 7.0, 1.0, 53.0, 183.0, 166.0, 0.0, 40.0, 169.0, 158.0, 166.0, 61.0, 29.0, 184.0, 129.0, 36.0, 159.0, 40.0, 4.0, 167.0, 87.0, 3.0, 11.0, 10.0, 171.0, 19.0, 123.0, 11.0, 25.0, 3.0, 142.0, 12.0, 154.0, 15.0, 166.0, 18.0, 102.0, 182.0, 39.0, 55.0, 94.0, 161.0, 196.0, 86.0, 39.0, 4.0, 64.0, 28.0, 5.0, 67.0, 13.0, 24.0, 12.0, 13.0, 139.0, 16.0, 0.0, 162.0, 196.0, 27.0, 17.0, 33.0, 38.0, 192.0, 199.0, 32.0, 28.0, 26.0, 1.0, 111.0, 151.0, 18.0, 15.0, 128.0, 61.0, 195.0, 92.0, 44.0, 176.0, 53.0, 141.0, 8.0, 174.0, 53.0, 37.0, 9.0, 151.0, 175.0, 0.0, 165.0, 154.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5350529942050931, "mean_inference_ms": 1.3793892793551918, "mean_action_processing_ms": 0.22850995240010077, "mean_env_wait_ms": 0.17532518744842807, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003423452377319336, "StateBufferConnector_ms": 0.0028388500213623047, "ViewRequirementAgentConnector_ms": 0.08713531494140625}, "num_episodes": 18, "episode_return_max": 368.1000000000006, "episode_return_min": -544.5999999999999, "episode_return_mean": 41.58799999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 428.7837712709678, "num_env_steps_trained_throughput_per_sec": 428.7837712709678, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 9150.374, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9150.335, "sample_time_ms": 1019.198, "learn_time_ms": 8118.805, "learn_throughput": 492.683, "synch_weights_time_ms": 11.548}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-37-51", "timestamp": 1723646271, "time_this_iter_s": 9.331840991973877, "time_total_s": 790.8593084812164, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1beaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 790.8593084812164, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 29.207692307692305, "ram_util_percent": 77.75384615384615}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6689360053450972, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 6.2350922995774205, "policy_loss": -0.008208326784716476, "vf_loss": 6.24199129361955, "vf_explained_var": -0.5889693743337399, "kl": 0.011638429725380822, "entropy": 1.0710419557397328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9960417978662663, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.607386878684715, "policy_loss": -0.006640323572274711, "vf_loss": 5.6134849351549905, "vf_explained_var": 0.12782259476247917, "kl": 0.005422604429352754, "entropy": 0.3870934844332397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 368.1000000000006, "episode_reward_min": -544.5999999999999, "episode_reward_mean": 12.158999999999896, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -61.685500000000026, "predator_policy": 67.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [221.99999999999963, -183.8000000000009, 368.1000000000006, 343.59999999999997, 224.09999999999982, 129.69999999999985, 297.10000000000025, 263.89999999999986, 146.79999999999944, 235.49999999999972, 99.10000000000002, -5.999999999999833, 261.59999999999957, 296.5, 132.69999999999962, 210.69999999999965, 181.79999999999978, 3.3000000000000527, -152.7000000000007, 223.09999999999997, 72.09999999999977, 288.00000000000017, -218.70000000000005, -93.7000000000001, -81.10000000000055, 309.40000000000015, 40.90000000000005, 229.19999999999987, -86.20000000000027, -6.400000000000022, 13.100000000000037, 76.80000000000008, -228.60000000000014, -544.5999999999999, 148.69999999999962, 216.79999999999998, 272.89999999999986, 310.20000000000067, -347.9999999999999, -104.8000000000002, -185.70000000000036, -104.89999999999996, 68.20000000000019, -269.20000000000005, -320.6, 209.39999999999938, -384.30000000000007, 177.5999999999993, -299.8000000000002, -79.30000000000044, 216.99999999999966, -100.60000000000025, -142.60000000000036, -184.60000000000025, 4.300000000000031, -278.39999999999907, 55.79999999999989, -14.599999999999753, 93.29999999999993, 207.29999999999995, 311.8, 148.79999999999995, 214.5999999999994, -238.80000000000004, 267.1999999999996, -13.5999999999998, 222.89999999999986, 276.3000000000002, -246.70000000000002, 283.5999999999995, 187.59999999999934, -11.199999999999923, 249.0999999999995, -2.599999999999943, -84.3000000000005, -470.2, -160.80000000000075, -355.20000000000016, 74.80000000000017, -80.79999999999998, -134.50000000000037, -316.5999999999999, 39.500000000000036, -458.0999999999992, -31.90000000000002, -8.199999999999639, -55.300000000000104, -119.0000000000002, 200.1999999999999, 40.0000000000003, 2.1000000000001067, 295.1000000000008, 13.20000000000014, -301.1999999999999, -62.70000000000009, -65.09999999999988, 6.49999999999975, -186.80000000000044, -349.4000000000001, -95.80000000000058], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [131.59999999999988, 31.40000000000009, -30.39999999999975, -387.4, 175.9999999999999, 190.09999999999994, 124.70000000000002, 170.89999999999995, 100.1, 64.99999999999997, -72.69999999999999, 40.39999999999992, 159.79999999999995, 89.29999999999993, 143.2999999999999, 89.60000000000004, 120.19999999999999, 11.599999999999964, 50.89999999999995, 131.5999999999997, 16.400000000000077, -73.30000000000001, -133.3, -33.699999999999754, 111.49999999999972, 139.09999999999988, 186.49999999999997, 109.99999999999982, 109.39999999999992, -15.699999999999747, 101.6, 61.10000000000006, 44.29999999999993, 81.49999999999986, -51.399999999999835, -7.299999999999891, -344.4999999999999, 15.799999999999955, 56.90000000000006, 120.19999999999993, -3.6999999999999957, 15.799999999999963, 106.10000000000001, 119.9, -358.9, -62.80000000000003, -281.8, -19.899999999999743, -312.70000000000005, -30.39999999999975, 95.59999999999995, 192.79999999999998, -61.90000000000054, -5.199999999999967, 134.29999999999998, 59.8999999999999, -226.60000000000008, -28.600000000000044, -103.00000000000007, -33.39999999999999, -292.3, 121.39999999999999, -2.19999999999996, 20.000000000000014, -264.7000000000001, -145.9, -392.8, -371.8, -5.1999999999999265, 122.9, 18.5, 95.30000000000003, 147.79999999999984, 43.100000000000044, 167.2999999999998, 134.89999999999978, -318.4, -265.60000000000014, -236.2, -34.59999999999975, -311.4999999999999, -83.20000000000033, -193.00000000000003, -235.9000000000001, 20.000000000000014, -41.800000000000054, -237.10000000000002, -345.1, -290.79999999999995, -224.8, 111.49999999999977, 53.90000000000005, -289.3, -349.0, 149.89999999999992, 13.699999999999964, -235.00000000000023, -245.8, -1.0000000000000133, -220.30000000000004, 134.60000000000002, 46.40000000000003, -259.30000000000007, 13.699999999999964, -305.49999999999994, -3.099999999999958, -180.10000000000014, -185.50000000000017, 9.499999999999964, -125.20000000000003, -137.20000000000013, -362.19999999999993, -135.4000000000001, 42.200000000000045, -391.6, 20.000000000000014, -37.59999999999999, 5.899999999999945, 73.4, 65.9, 94.09999999999988, 184.6999999999999, 70.39999999999999, -1.599999999999973, 96.80000000000004, 81.79999999999967, -201.40000000000003, -189.4, 101.59999999999994, 149.59999999999997, -391.5999999999999, 20.000000000000014, 102.49999999999996, 76.40000000000002, 115.69999999999989, 89.60000000000002, -241.9, -395.79999999999995, 147.79999999999967, 75.80000000000004, 87.1999999999997, 73.39999999999966, 20.000000000000014, -293.1999999999998, 139.69999999999968, 76.40000000000009, -199.0000000000001, 7.399999999999965, 13.699999999999964, -385.0, -355.90000000000003, -334.30000000000007, -3.099999999999958, -351.7000000000001, -320.80000000000007, -216.4000000000001, -23.799999999999983, 8.600000000000023, -237.70000000000002, -3.099999999999958, -329.5, 20.000000000000014, -292.5999999999999, -343.0, -140.2, 13.699999999999964, -394.9, -299.19999999999936, -133.0, -43.89999999999998, -28.29999999999975, -19.89999999999975, 13.699999999999964, -400.0, 20.000000000000014, -394.0, 34.69999999999997, 102.50000000000003, 20.000000000000014, 20.000000000000014, -106.90000000000052, -21.999999999999922, 162.19999999999976, 98.90000000000006, -3.099999999999958, -114.7000000000002, -235.90000000000023, -229.30000000000007, 20.000000000000014, -234.70000000000036, -330.6999999999998, 11.599999999999964, -107.80000000000013, -48.69999999999985, -266.7999999999997, -127.00000000000023, -280.90000000000003, -254.50000000000003, -302.80000000000024, 20.000000000000014], "policy_predator_policy_reward": [22.0, 37.0, 191.0, 43.0, 0.0, 2.0, 24.0, 24.0, 22.0, 37.0, 71.0, 91.0, 27.0, 21.0, 11.0, 20.0, 10.0, 5.0, 19.0, 34.0, 109.0, 47.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 30.0, 9.0, 43.0, 5.0, 14.0, 42.0, 23.0, 39.0, 2.0, 174.0, 34.0, 12.0, 12.0, 48.0, 26.0, 36.0, 178.0, 25.0, 34.0, 174.0, 115.0, 147.0, 18.0, 3.0, 60.0, 48.0, 35.0, 0.0, 32.0, 137.0, 99.0, 31.0, 22.0, 162.0, 0.0, 59.0, 24.0, 158.0, 199.0, 21.0, 5.0, 26.0, 59.0, 44.0, 42.0, 40.0, 7.0, 1.0, 53.0, 183.0, 166.0, 0.0, 40.0, 169.0, 158.0, 166.0, 61.0, 29.0, 184.0, 129.0, 36.0, 159.0, 40.0, 4.0, 167.0, 87.0, 3.0, 11.0, 10.0, 171.0, 19.0, 123.0, 11.0, 25.0, 3.0, 142.0, 12.0, 154.0, 15.0, 166.0, 18.0, 102.0, 182.0, 39.0, 55.0, 94.0, 161.0, 196.0, 86.0, 39.0, 4.0, 64.0, 28.0, 5.0, 67.0, 13.0, 24.0, 12.0, 13.0, 139.0, 16.0, 0.0, 162.0, 196.0, 27.0, 17.0, 33.0, 38.0, 192.0, 199.0, 32.0, 28.0, 26.0, 1.0, 111.0, 151.0, 18.0, 15.0, 128.0, 61.0, 195.0, 92.0, 44.0, 176.0, 53.0, 141.0, 8.0, 174.0, 53.0, 37.0, 9.0, 151.0, 175.0, 0.0, 165.0, 154.0, 95.0, 71.0, 199.0, 37.0, 69.0, 76.0, 24.0, 16.0, 152.0, 179.0, 198.0, 57.0, 50.0, 13.0, 0.0, 0.0, 51.0, 80.0, 19.0, 15.0, 96.0, 35.0, 1.0, 163.0, 126.0, 26.0, 87.0, 167.0, 67.0, 96.0, 62.0, 145.0, 171.0, 15.0, 60.0, 127.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5345197428041341, "mean_inference_ms": 1.3779880189181255, "mean_action_processing_ms": 0.2282732102051116, "mean_env_wait_ms": 0.1751052533125062, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033913850784301758, "StateBufferConnector_ms": 0.0028421878814697266, "ViewRequirementAgentConnector_ms": 0.08642983436584473}, "num_episodes": 18, "episode_return_max": 368.1000000000006, "episode_return_min": -544.5999999999999, "episode_return_mean": 12.158999999999896, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 428.81798688483576, "num_env_steps_trained_throughput_per_sec": 428.81798688483576, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 9173.561, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9173.523, "sample_time_ms": 1015.754, "learn_time_ms": 8145.676, "learn_throughput": 491.058, "synch_weights_time_ms": 11.331}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-38-01", "timestamp": 1723646281, "time_this_iter_s": 9.331017017364502, "time_total_s": 800.1903254985809, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0eb940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 800.1903254985809, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 29.461538461538456, "ram_util_percent": 78.03076923076922}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9224143189412577, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 7.145414427853135, "policy_loss": -0.00794678089287743, "vf_loss": 7.152027580977748, "vf_explained_var": -0.4466213862101237, "kl": 0.011854516945269775, "entropy": 1.0246048478537766, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.1655184523453785, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 6.106712771471216, "policy_loss": -0.008615854989352916, "vf_loss": 6.114621392507401, "vf_explained_var": 0.12343140159334455, "kl": 0.0070723884029608285, "entropy": 0.36590608332365276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 311.8, "episode_reward_min": -544.5999999999999, "episode_reward_mean": -40.067000000000085, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -101.22850000000003, "predator_policy": 81.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-218.70000000000005, -93.7000000000001, -81.10000000000055, 309.40000000000015, 40.90000000000005, 229.19999999999987, -86.20000000000027, -6.400000000000022, 13.100000000000037, 76.80000000000008, -228.60000000000014, -544.5999999999999, 148.69999999999962, 216.79999999999998, 272.89999999999986, 310.20000000000067, -347.9999999999999, -104.8000000000002, -185.70000000000036, -104.89999999999996, 68.20000000000019, -269.20000000000005, -320.6, 209.39999999999938, -384.30000000000007, 177.5999999999993, -299.8000000000002, -79.30000000000044, 216.99999999999966, -100.60000000000025, -142.60000000000036, -184.60000000000025, 4.300000000000031, -278.39999999999907, 55.79999999999989, -14.599999999999753, 93.29999999999993, 207.29999999999995, 311.8, 148.79999999999995, 214.5999999999994, -238.80000000000004, 267.1999999999996, -13.5999999999998, 222.89999999999986, 276.3000000000002, -246.70000000000002, 283.5999999999995, 187.59999999999934, -11.199999999999923, 249.0999999999995, -2.599999999999943, -84.3000000000005, -470.2, -160.80000000000075, -355.20000000000016, 74.80000000000017, -80.79999999999998, -134.50000000000037, -316.5999999999999, 39.500000000000036, -458.0999999999992, -31.90000000000002, -8.199999999999639, -55.300000000000104, -119.0000000000002, 200.1999999999999, 40.0000000000003, 2.1000000000001067, 295.1000000000008, 13.20000000000014, -301.1999999999999, -62.70000000000009, -65.09999999999988, 6.49999999999975, -186.80000000000044, -349.4000000000001, -95.80000000000058, -1.7999999999997294, -397.1000000000001, -58.80000000000063, -364.3999999999999, 37.700000000000145, -148.0000000000003, 1.8999999999999482, 78.99999999999928, -106.20000000000078, 22.600000000000186, -259.90000000000055, 0.299999999999967, 81.09999999999992, 1.1000000000000805, 89.09999999999994, 109.29999999999998, -200.80000000000032, 76.29999999999964, -137.3000000000007, -22.899999999999817, -332.5999999999989, -33.99999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-358.9, -62.80000000000003, -281.8, -19.899999999999743, -312.70000000000005, -30.39999999999975, 95.59999999999995, 192.79999999999998, -61.90000000000054, -5.199999999999967, 134.29999999999998, 59.8999999999999, -226.60000000000008, -28.600000000000044, -103.00000000000007, -33.39999999999999, -292.3, 121.39999999999999, -2.19999999999996, 20.000000000000014, -264.7000000000001, -145.9, -392.8, -371.8, -5.1999999999999265, 122.9, 18.5, 95.30000000000003, 147.79999999999984, 43.100000000000044, 167.2999999999998, 134.89999999999978, -318.4, -265.60000000000014, -236.2, -34.59999999999975, -311.4999999999999, -83.20000000000033, -193.00000000000003, -235.9000000000001, 20.000000000000014, -41.800000000000054, -237.10000000000002, -345.1, -290.79999999999995, -224.8, 111.49999999999977, 53.90000000000005, -289.3, -349.0, 149.89999999999992, 13.699999999999964, -235.00000000000023, -245.8, -1.0000000000000133, -220.30000000000004, 134.60000000000002, 46.40000000000003, -259.30000000000007, 13.699999999999964, -305.49999999999994, -3.099999999999958, -180.10000000000014, -185.50000000000017, 9.499999999999964, -125.20000000000003, -137.20000000000013, -362.19999999999993, -135.4000000000001, 42.200000000000045, -391.6, 20.000000000000014, -37.59999999999999, 5.899999999999945, 73.4, 65.9, 94.09999999999988, 184.6999999999999, 70.39999999999999, -1.599999999999973, 96.80000000000004, 81.79999999999967, -201.40000000000003, -189.4, 101.59999999999994, 149.59999999999997, -391.5999999999999, 20.000000000000014, 102.49999999999996, 76.40000000000002, 115.69999999999989, 89.60000000000002, -241.9, -395.79999999999995, 147.79999999999967, 75.80000000000004, 87.1999999999997, 73.39999999999966, 20.000000000000014, -293.1999999999998, 139.69999999999968, 76.40000000000009, -199.0000000000001, 7.399999999999965, 13.699999999999964, -385.0, -355.90000000000003, -334.30000000000007, -3.099999999999958, -351.7000000000001, -320.80000000000007, -216.4000000000001, -23.799999999999983, 8.600000000000023, -237.70000000000002, -3.099999999999958, -329.5, 20.000000000000014, -292.5999999999999, -343.0, -140.2, 13.699999999999964, -394.9, -299.19999999999936, -133.0, -43.89999999999998, -28.29999999999975, -19.89999999999975, 13.699999999999964, -400.0, 20.000000000000014, -394.0, 34.69999999999997, 102.50000000000003, 20.000000000000014, 20.000000000000014, -106.90000000000052, -21.999999999999922, 162.19999999999976, 98.90000000000006, -3.099999999999958, -114.7000000000002, -235.90000000000023, -229.30000000000007, 20.000000000000014, -234.70000000000036, -330.6999999999998, 11.599999999999964, -107.80000000000013, -48.69999999999985, -266.7999999999997, -127.00000000000023, -280.90000000000003, -254.50000000000003, -302.80000000000024, 20.000000000000014, -0.9999999999999881, -38.799999999999756, -353.20000000000005, -280.90000000000003, -204.7000000000002, 11.899999999999983, -366.4, -327.9999999999999, 68.30000000000001, -151.6000000000003, -94.90000000000015, -228.10000000000016, -129.1000000000007, 20.000000000000014, 20.000000000000014, 41.00000000000016, -395.79999999999995, -9.399999999999855, -111.40000000000026, 20.000000000000014, -259.3000000000004, -328.6000000000001, -82.90000000000086, -242.80000000000018, -165.70000000000007, 36.800000000000004, -11.499999999999819, -57.40000000000006, -196.0, 49.100000000000186, 86.60000000000002, -124.30000000000027, -288.9999999999999, -248.80000000000007, -57.09999999999995, 49.3999999999998, -3.099999999999958, -341.19999999999936, -221.20000000000002, -15.699999999999747, -270.10000000000014, -326.4999999999993, -300.6999999999999, -7.299999999999891], "policy_predator_policy_reward": [178.0, 25.0, 34.0, 174.0, 115.0, 147.0, 18.0, 3.0, 60.0, 48.0, 35.0, 0.0, 32.0, 137.0, 99.0, 31.0, 22.0, 162.0, 0.0, 59.0, 24.0, 158.0, 199.0, 21.0, 5.0, 26.0, 59.0, 44.0, 42.0, 40.0, 7.0, 1.0, 53.0, 183.0, 166.0, 0.0, 40.0, 169.0, 158.0, 166.0, 61.0, 29.0, 184.0, 129.0, 36.0, 159.0, 40.0, 4.0, 167.0, 87.0, 3.0, 11.0, 10.0, 171.0, 19.0, 123.0, 11.0, 25.0, 3.0, 142.0, 12.0, 154.0, 15.0, 166.0, 18.0, 102.0, 182.0, 39.0, 55.0, 94.0, 161.0, 196.0, 86.0, 39.0, 4.0, 64.0, 28.0, 5.0, 67.0, 13.0, 24.0, 12.0, 13.0, 139.0, 16.0, 0.0, 162.0, 196.0, 27.0, 17.0, 33.0, 38.0, 192.0, 199.0, 32.0, 28.0, 26.0, 1.0, 111.0, 151.0, 18.0, 15.0, 128.0, 61.0, 195.0, 92.0, 44.0, 176.0, 53.0, 141.0, 8.0, 174.0, 53.0, 37.0, 9.0, 151.0, 175.0, 0.0, 165.0, 154.0, 95.0, 71.0, 199.0, 37.0, 69.0, 76.0, 24.0, 16.0, 152.0, 179.0, 198.0, 57.0, 50.0, 13.0, 0.0, 0.0, 51.0, 80.0, 19.0, 15.0, 96.0, 35.0, 1.0, 163.0, 126.0, 26.0, 87.0, 167.0, 67.0, 96.0, 62.0, 145.0, 171.0, 15.0, 60.0, 127.0, 9.0, 29.0, 42.0, 195.0, 15.0, 119.0, 187.0, 143.0, 71.0, 50.0, 132.0, 43.0, 71.0, 40.0, 5.0, 13.0, 165.0, 134.0, 37.0, 77.0, 187.0, 141.0, 158.0, 168.0, 84.0, 126.0, 63.0, 7.0, 108.0, 128.0, 71.0, 76.0, 159.0, 178.0, 38.0, 46.0, 78.0, 129.0, 145.0, 69.0, 197.0, 67.0, 175.0, 99.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5339162472755717, "mean_inference_ms": 1.376529672095179, "mean_action_processing_ms": 0.22802873486359324, "mean_env_wait_ms": 0.1748744970131989, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003351926803588867, "StateBufferConnector_ms": 0.002861618995666504, "ViewRequirementAgentConnector_ms": 0.08609127998352051}, "num_episodes": 22, "episode_return_max": 311.8, "episode_return_min": -544.5999999999999, "episode_return_mean": -40.067000000000085, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 432.8290004338038, "num_env_steps_trained_throughput_per_sec": 432.8290004338038, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 9201.867, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9201.829, "sample_time_ms": 1012.165, "learn_time_ms": 8177.574, "learn_throughput": 489.143, "synch_weights_time_ms": 11.317}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-38-10", "timestamp": 1723646290, "time_this_iter_s": 9.245245218276978, "time_total_s": 809.4355707168579, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0eb790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 809.4355707168579, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 28.15384615384615, "ram_util_percent": 78.0153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7456592128390356, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 5.911383952539434, "policy_loss": -0.01550682229125409, "vf_loss": 5.9250337752084885, "vf_explained_var": -0.6310244594932233, "kl": 0.016506474310510347, "entropy": 1.054486669939031, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.002422936063595, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 5.3754443872542605, "policy_loss": -0.008124183917974944, "vf_loss": 5.3829645431861675, "vf_explained_var": 0.07666759465737318, "kl": 0.0060403550740938975, "entropy": 0.27634402779201983, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 311.8, "episode_reward_min": -470.2, "episode_reward_mean": -41.486000000000104, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 184.6999999999999, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -103.49800000000003, "predator_policy": 82.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-185.70000000000036, -104.89999999999996, 68.20000000000019, -269.20000000000005, -320.6, 209.39999999999938, -384.30000000000007, 177.5999999999993, -299.8000000000002, -79.30000000000044, 216.99999999999966, -100.60000000000025, -142.60000000000036, -184.60000000000025, 4.300000000000031, -278.39999999999907, 55.79999999999989, -14.599999999999753, 93.29999999999993, 207.29999999999995, 311.8, 148.79999999999995, 214.5999999999994, -238.80000000000004, 267.1999999999996, -13.5999999999998, 222.89999999999986, 276.3000000000002, -246.70000000000002, 283.5999999999995, 187.59999999999934, -11.199999999999923, 249.0999999999995, -2.599999999999943, -84.3000000000005, -470.2, -160.80000000000075, -355.20000000000016, 74.80000000000017, -80.79999999999998, -134.50000000000037, -316.5999999999999, 39.500000000000036, -458.0999999999992, -31.90000000000002, -8.199999999999639, -55.300000000000104, -119.0000000000002, 200.1999999999999, 40.0000000000003, 2.1000000000001067, 295.1000000000008, 13.20000000000014, -301.1999999999999, -62.70000000000009, -65.09999999999988, 6.49999999999975, -186.80000000000044, -349.4000000000001, -95.80000000000058, -1.7999999999997294, -397.1000000000001, -58.80000000000063, -364.3999999999999, 37.700000000000145, -148.0000000000003, 1.8999999999999482, 78.99999999999928, -106.20000000000078, 22.600000000000186, -259.90000000000055, 0.299999999999967, 81.09999999999992, 1.1000000000000805, 89.09999999999994, 109.29999999999998, -200.80000000000032, 76.29999999999964, -137.3000000000007, -22.899999999999817, -332.5999999999989, -33.99999999999994, -185.50000000000082, -125.30000000000024, 18.799999999999994, 18.09999999999988, -57.20000000000009, -116.2000000000001, -26.999999999999762, 93.19999999999918, 187.89999999999972, -133.80000000000007, -13.700000000000607, 12.09999999999989, 72.50000000000006, 19.50000000000001, -183.00000000000017, 85.09999999999997, 91.09999999999994, 7.399999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-311.4999999999999, -83.20000000000033, -193.00000000000003, -235.9000000000001, 20.000000000000014, -41.800000000000054, -237.10000000000002, -345.1, -290.79999999999995, -224.8, 111.49999999999977, 53.90000000000005, -289.3, -349.0, 149.89999999999992, 13.699999999999964, -235.00000000000023, -245.8, -1.0000000000000133, -220.30000000000004, 134.60000000000002, 46.40000000000003, -259.30000000000007, 13.699999999999964, -305.49999999999994, -3.099999999999958, -180.10000000000014, -185.50000000000017, 9.499999999999964, -125.20000000000003, -137.20000000000013, -362.19999999999993, -135.4000000000001, 42.200000000000045, -391.6, 20.000000000000014, -37.59999999999999, 5.899999999999945, 73.4, 65.9, 94.09999999999988, 184.6999999999999, 70.39999999999999, -1.599999999999973, 96.80000000000004, 81.79999999999967, -201.40000000000003, -189.4, 101.59999999999994, 149.59999999999997, -391.5999999999999, 20.000000000000014, 102.49999999999996, 76.40000000000002, 115.69999999999989, 89.60000000000002, -241.9, -395.79999999999995, 147.79999999999967, 75.80000000000004, 87.1999999999997, 73.39999999999966, 20.000000000000014, -293.1999999999998, 139.69999999999968, 76.40000000000009, -199.0000000000001, 7.399999999999965, 13.699999999999964, -385.0, -355.90000000000003, -334.30000000000007, -3.099999999999958, -351.7000000000001, -320.80000000000007, -216.4000000000001, -23.799999999999983, 8.600000000000023, -237.70000000000002, -3.099999999999958, -329.5, 20.000000000000014, -292.5999999999999, -343.0, -140.2, 13.699999999999964, -394.9, -299.19999999999936, -133.0, -43.89999999999998, -28.29999999999975, -19.89999999999975, 13.699999999999964, -400.0, 20.000000000000014, -394.0, 34.69999999999997, 102.50000000000003, 20.000000000000014, 20.000000000000014, -106.90000000000052, -21.999999999999922, 162.19999999999976, 98.90000000000006, -3.099999999999958, -114.7000000000002, -235.90000000000023, -229.30000000000007, 20.000000000000014, -234.70000000000036, -330.6999999999998, 11.599999999999964, -107.80000000000013, -48.69999999999985, -266.7999999999997, -127.00000000000023, -280.90000000000003, -254.50000000000003, -302.80000000000024, 20.000000000000014, -0.9999999999999881, -38.799999999999756, -353.20000000000005, -280.90000000000003, -204.7000000000002, 11.899999999999983, -366.4, -327.9999999999999, 68.30000000000001, -151.6000000000003, -94.90000000000015, -228.10000000000016, -129.1000000000007, 20.000000000000014, 20.000000000000014, 41.00000000000016, -395.79999999999995, -9.399999999999855, -111.40000000000026, 20.000000000000014, -259.3000000000004, -328.6000000000001, -82.90000000000086, -242.80000000000018, -165.70000000000007, 36.800000000000004, -11.499999999999819, -57.40000000000006, -196.0, 49.100000000000186, 86.60000000000002, -124.30000000000027, -288.9999999999999, -248.80000000000007, -57.09999999999995, 49.3999999999998, -3.099999999999958, -341.19999999999936, -221.20000000000002, -15.699999999999747, -270.10000000000014, -326.4999999999993, -300.6999999999999, -7.299999999999891, -258.70000000000016, -80.80000000000062, 3.1999999999999633, -320.50000000000006, -17.79999999999974, 11.599999999999964, -16.300000000000097, -160.60000000000002, -7.299999999999891, -181.90000000000015, -138.70000000000002, -203.5000000000002, -250.90000000000023, -3.099999999999958, -67.60000000000005, -5.1999999999999265, 46.100000000000044, 87.79999999999993, -142.90000000000006, -232.9000000000001, -127.6000000000002, -12.099999999999838, -127.30000000000015, -46.600000000000016, -32.5000000000002, 20.000000000000043, 3.1999999999999615, 5.299999999999965, -271.6, -270.4, 10.09999999999985, 20.000000000000014, 3.1999999999997613, 17.899999999999988, -224.5000000000002, 17.899999999999988], "policy_predator_policy_reward": [40.0, 169.0, 158.0, 166.0, 61.0, 29.0, 184.0, 129.0, 36.0, 159.0, 40.0, 4.0, 167.0, 87.0, 3.0, 11.0, 10.0, 171.0, 19.0, 123.0, 11.0, 25.0, 3.0, 142.0, 12.0, 154.0, 15.0, 166.0, 18.0, 102.0, 182.0, 39.0, 55.0, 94.0, 161.0, 196.0, 86.0, 39.0, 4.0, 64.0, 28.0, 5.0, 67.0, 13.0, 24.0, 12.0, 13.0, 139.0, 16.0, 0.0, 162.0, 196.0, 27.0, 17.0, 33.0, 38.0, 192.0, 199.0, 32.0, 28.0, 26.0, 1.0, 111.0, 151.0, 18.0, 15.0, 128.0, 61.0, 195.0, 92.0, 44.0, 176.0, 53.0, 141.0, 8.0, 174.0, 53.0, 37.0, 9.0, 151.0, 175.0, 0.0, 165.0, 154.0, 95.0, 71.0, 199.0, 37.0, 69.0, 76.0, 24.0, 16.0, 152.0, 179.0, 198.0, 57.0, 50.0, 13.0, 0.0, 0.0, 51.0, 80.0, 19.0, 15.0, 96.0, 35.0, 1.0, 163.0, 126.0, 26.0, 87.0, 167.0, 67.0, 96.0, 62.0, 145.0, 171.0, 15.0, 60.0, 127.0, 9.0, 29.0, 42.0, 195.0, 15.0, 119.0, 187.0, 143.0, 71.0, 50.0, 132.0, 43.0, 71.0, 40.0, 5.0, 13.0, 165.0, 134.0, 37.0, 77.0, 187.0, 141.0, 158.0, 168.0, 84.0, 126.0, 63.0, 7.0, 108.0, 128.0, 71.0, 76.0, 159.0, 178.0, 38.0, 46.0, 78.0, 129.0, 145.0, 69.0, 197.0, 67.0, 175.0, 99.0, 143.0, 11.0, 144.0, 48.0, 15.0, 10.0, 119.0, 76.0, 116.0, 16.0, 157.0, 69.0, 138.0, 89.0, 81.0, 85.0, 46.0, 8.0, 134.0, 108.0, 91.0, 35.0, 101.0, 85.0, 39.0, 46.0, 3.0, 8.0, 198.0, 161.0, 41.0, 14.0, 17.0, 53.0, 118.0, 96.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5334755329681373, "mean_inference_ms": 1.3754290920429415, "mean_action_processing_ms": 0.22782932988504187, "mean_env_wait_ms": 0.17469644427204337, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0034276247024536133, "StateBufferConnector_ms": 0.002928495407104492, "ViewRequirementAgentConnector_ms": 0.08682513236999512}, "num_episodes": 18, "episode_return_max": 311.8, "episode_return_min": -470.2, "episode_return_mean": -41.486000000000104, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 431.0657371539015, "num_env_steps_trained_throughput_per_sec": 431.0657371539015, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 9204.071, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9204.033, "sample_time_ms": 1014.532, "learn_time_ms": 8177.356, "learn_throughput": 489.156, "synch_weights_time_ms": 11.383}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-38-19", "timestamp": 1723646299, "time_this_iter_s": 9.282038927078247, "time_total_s": 818.7176096439362, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1bec10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 818.7176096439362, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 28.0, "ram_util_percent": 78.14999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4668524275696466, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 5.195997143800927, "policy_loss": -0.013340433379117814, "vf_loss": 5.207661009591723, "vf_explained_var": -0.8610956280319779, "kl": 0.014902839556079395, "entropy": 1.0449957249025819, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9341394657180424, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 4.943190395138251, "policy_loss": -0.00797093726359505, "vf_loss": 4.95059219970905, "vf_explained_var": 0.11448289770928641, "kl": 0.005691241273901599, "entropy": 0.35418971214029527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 295.1000000000008, "episode_reward_min": -470.2, "episode_reward_mean": -48.638000000000076, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.19999999999976, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -107.97400000000002, "predator_policy": 83.655}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-238.80000000000004, 267.1999999999996, -13.5999999999998, 222.89999999999986, 276.3000000000002, -246.70000000000002, 283.5999999999995, 187.59999999999934, -11.199999999999923, 249.0999999999995, -2.599999999999943, -84.3000000000005, -470.2, -160.80000000000075, -355.20000000000016, 74.80000000000017, -80.79999999999998, -134.50000000000037, -316.5999999999999, 39.500000000000036, -458.0999999999992, -31.90000000000002, -8.199999999999639, -55.300000000000104, -119.0000000000002, 200.1999999999999, 40.0000000000003, 2.1000000000001067, 295.1000000000008, 13.20000000000014, -301.1999999999999, -62.70000000000009, -65.09999999999988, 6.49999999999975, -186.80000000000044, -349.4000000000001, -95.80000000000058, -1.7999999999997294, -397.1000000000001, -58.80000000000063, -364.3999999999999, 37.700000000000145, -148.0000000000003, 1.8999999999999482, 78.99999999999928, -106.20000000000078, 22.600000000000186, -259.90000000000055, 0.299999999999967, 81.09999999999992, 1.1000000000000805, 89.09999999999994, 109.29999999999998, -200.80000000000032, 76.29999999999964, -137.3000000000007, -22.899999999999817, -332.5999999999989, -33.99999999999994, -185.50000000000082, -125.30000000000024, 18.799999999999994, 18.09999999999988, -57.20000000000009, -116.2000000000001, -26.999999999999762, 93.19999999999918, 187.89999999999972, -133.80000000000007, -13.700000000000607, 12.09999999999989, 72.50000000000006, 19.50000000000001, -183.00000000000017, 85.09999999999997, 91.09999999999994, 7.399999999999995, -56.500000000000114, -442.4999999999992, -33.8000000000004, -45.49999999999981, 6.400000000000151, 25.70000000000007, -276.5999999999992, 24.40000000000005, 42.60000000000027, -92.20000000000005, 123.09999999999877, -97.40000000000026, -334.2999999999995, -47.09999999999976, 12.399999999999983, -1.3000000000000638, 33.99999999999974, -65.89999999999976, 20.0, 25.500000000000068, -19.800000000000615, -107.00000000000014, -65.8999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-201.40000000000003, -189.4, 101.59999999999994, 149.59999999999997, -391.5999999999999, 20.000000000000014, 102.49999999999996, 76.40000000000002, 115.69999999999989, 89.60000000000002, -241.9, -395.79999999999995, 147.79999999999967, 75.80000000000004, 87.1999999999997, 73.39999999999966, 20.000000000000014, -293.1999999999998, 139.69999999999968, 76.40000000000009, -199.0000000000001, 7.399999999999965, 13.699999999999964, -385.0, -355.90000000000003, -334.30000000000007, -3.099999999999958, -351.7000000000001, -320.80000000000007, -216.4000000000001, -23.799999999999983, 8.600000000000023, -237.70000000000002, -3.099999999999958, -329.5, 20.000000000000014, -292.5999999999999, -343.0, -140.2, 13.699999999999964, -394.9, -299.19999999999936, -133.0, -43.89999999999998, -28.29999999999975, -19.89999999999975, 13.699999999999964, -400.0, 20.000000000000014, -394.0, 34.69999999999997, 102.50000000000003, 20.000000000000014, 20.000000000000014, -106.90000000000052, -21.999999999999922, 162.19999999999976, 98.90000000000006, -3.099999999999958, -114.7000000000002, -235.90000000000023, -229.30000000000007, 20.000000000000014, -234.70000000000036, -330.6999999999998, 11.599999999999964, -107.80000000000013, -48.69999999999985, -266.7999999999997, -127.00000000000023, -280.90000000000003, -254.50000000000003, -302.80000000000024, 20.000000000000014, -0.9999999999999881, -38.799999999999756, -353.20000000000005, -280.90000000000003, -204.7000000000002, 11.899999999999983, -366.4, -327.9999999999999, 68.30000000000001, -151.6000000000003, -94.90000000000015, -228.10000000000016, -129.1000000000007, 20.000000000000014, 20.000000000000014, 41.00000000000016, -395.79999999999995, -9.399999999999855, -111.40000000000026, 20.000000000000014, -259.3000000000004, -328.6000000000001, -82.90000000000086, -242.80000000000018, -165.70000000000007, 36.800000000000004, -11.499999999999819, -57.40000000000006, -196.0, 49.100000000000186, 86.60000000000002, -124.30000000000027, -288.9999999999999, -248.80000000000007, -57.09999999999995, 49.3999999999998, -3.099999999999958, -341.19999999999936, -221.20000000000002, -15.699999999999747, -270.10000000000014, -326.4999999999993, -300.6999999999999, -7.299999999999891, -258.70000000000016, -80.80000000000062, 3.1999999999999633, -320.50000000000006, -17.79999999999974, 11.599999999999964, -16.300000000000097, -160.60000000000002, -7.299999999999891, -181.90000000000015, -138.70000000000002, -203.5000000000002, -250.90000000000023, -3.099999999999958, -67.60000000000005, -5.1999999999999265, 46.100000000000044, 87.79999999999993, -142.90000000000006, -232.9000000000001, -127.6000000000002, -12.099999999999838, -127.30000000000015, -46.600000000000016, -32.5000000000002, 20.000000000000043, 3.1999999999999615, 5.299999999999965, -271.6, -270.4, 10.09999999999985, 20.000000000000014, 3.1999999999997613, 17.899999999999988, -224.5000000000002, 17.899999999999988, -172.90000000000012, -58.599999999999994, -275.4999999999996, -357.9999999999997, -65.50000000000057, -169.30000000000015, -257.2000000000001, -139.30000000000067, -0.9999999999999846, -34.59999999999975, 17.899999999999988, -5.1999999999999265, -288.70000000000016, -208.90000000000052, 20.000000000000014, -13.599999999999783, -321.3999999999999, 20.000000000000014, -3.099999999999958, -312.1, 56.90000000000016, -11.799999999999981, -256.9000000000002, 21.500000000000036, -341.19999999999993, -342.09999999999957, -213.10000000000022, 20.000000000000014, -64.90000000000059, -0.7000000000000276, -249.40000000000018, 1.0999999999999865, -44.499999999999766, -32.500000000000085, -299.7999999999996, 17.899999999999988, 12.499999999999961, -11.499999999999819, -11.499999999999819, 20.000000000000014, -24.100000000000385, -51.69999999999998, -337.0000000000001, 20.000000000000014, -304.9, 20.000000000000014], "policy_predator_policy_reward": [13.0, 139.0, 16.0, 0.0, 162.0, 196.0, 27.0, 17.0, 33.0, 38.0, 192.0, 199.0, 32.0, 28.0, 26.0, 1.0, 111.0, 151.0, 18.0, 15.0, 128.0, 61.0, 195.0, 92.0, 44.0, 176.0, 53.0, 141.0, 8.0, 174.0, 53.0, 37.0, 9.0, 151.0, 175.0, 0.0, 165.0, 154.0, 95.0, 71.0, 199.0, 37.0, 69.0, 76.0, 24.0, 16.0, 152.0, 179.0, 198.0, 57.0, 50.0, 13.0, 0.0, 0.0, 51.0, 80.0, 19.0, 15.0, 96.0, 35.0, 1.0, 163.0, 126.0, 26.0, 87.0, 167.0, 67.0, 96.0, 62.0, 145.0, 171.0, 15.0, 60.0, 127.0, 9.0, 29.0, 42.0, 195.0, 15.0, 119.0, 187.0, 143.0, 71.0, 50.0, 132.0, 43.0, 71.0, 40.0, 5.0, 13.0, 165.0, 134.0, 37.0, 77.0, 187.0, 141.0, 158.0, 168.0, 84.0, 126.0, 63.0, 7.0, 108.0, 128.0, 71.0, 76.0, 159.0, 178.0, 38.0, 46.0, 78.0, 129.0, 145.0, 69.0, 197.0, 67.0, 175.0, 99.0, 143.0, 11.0, 144.0, 48.0, 15.0, 10.0, 119.0, 76.0, 116.0, 16.0, 157.0, 69.0, 138.0, 89.0, 81.0, 85.0, 46.0, 8.0, 134.0, 108.0, 91.0, 35.0, 101.0, 85.0, 39.0, 46.0, 3.0, 8.0, 198.0, 161.0, 41.0, 14.0, 17.0, 53.0, 118.0, 96.0, 71.0, 104.0, 188.0, 3.0, 99.0, 102.0, 173.0, 178.0, 27.0, 15.0, 12.0, 1.0, 168.0, 53.0, 5.0, 13.0, 172.0, 172.0, 158.0, 65.0, 38.0, 40.0, 27.0, 111.0, 199.0, 150.0, 126.0, 20.0, 20.0, 58.0, 105.0, 142.0, 80.0, 31.0, 75.0, 141.0, 4.0, 15.0, 15.0, 2.0, 53.0, 3.0, 151.0, 59.0, 125.0, 94.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5329521649520363, "mean_inference_ms": 1.3739805449437474, "mean_action_processing_ms": 0.22756968050836102, "mean_env_wait_ms": 0.17446419825163773, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003348231315612793, "StateBufferConnector_ms": 0.002866506576538086, "ViewRequirementAgentConnector_ms": 0.08532452583312988}, "num_episodes": 23, "episode_return_max": 295.1000000000008, "episode_return_min": -470.2, "episode_return_mean": -48.638000000000076, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 435.6160633257177, "num_env_steps_trained_throughput_per_sec": 435.6160633257177, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 9218.21, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9218.171, "sample_time_ms": 1020.678, "learn_time_ms": 8185.289, "learn_throughput": 488.682, "synch_weights_time_ms": 11.454}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-38-28", "timestamp": 1723646308, "time_this_iter_s": 9.185307741165161, "time_total_s": 827.9029173851013, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0aaca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 827.9029173851013, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 26.961538461538467, "ram_util_percent": 78.4153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.854513809731398, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 5.1255948522103525, "policy_loss": -0.00949706585693454, "vf_loss": 5.133229288348446, "vf_explained_var": -0.6802785315210857, "kl": 0.016556788001256623, "entropy": 1.0449871806871323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3460861321479554, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 4.825885160637911, "policy_loss": -0.00797833349018619, "vf_loss": 4.833144700716412, "vf_explained_var": 0.12056927898573497, "kl": 0.007187709829016546, "entropy": 0.28554701909974767, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 295.1000000000008, "episode_reward_min": -458.0999999999992, "episode_reward_mean": -48.11000000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.19999999999976, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -107.41000000000005, "predator_policy": 83.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-316.5999999999999, 39.500000000000036, -458.0999999999992, -31.90000000000002, -8.199999999999639, -55.300000000000104, -119.0000000000002, 200.1999999999999, 40.0000000000003, 2.1000000000001067, 295.1000000000008, 13.20000000000014, -301.1999999999999, -62.70000000000009, -65.09999999999988, 6.49999999999975, -186.80000000000044, -349.4000000000001, -95.80000000000058, -1.7999999999997294, -397.1000000000001, -58.80000000000063, -364.3999999999999, 37.700000000000145, -148.0000000000003, 1.8999999999999482, 78.99999999999928, -106.20000000000078, 22.600000000000186, -259.90000000000055, 0.299999999999967, 81.09999999999992, 1.1000000000000805, 89.09999999999994, 109.29999999999998, -200.80000000000032, 76.29999999999964, -137.3000000000007, -22.899999999999817, -332.5999999999989, -33.99999999999994, -185.50000000000082, -125.30000000000024, 18.799999999999994, 18.09999999999988, -57.20000000000009, -116.2000000000001, -26.999999999999762, 93.19999999999918, 187.89999999999972, -133.80000000000007, -13.700000000000607, 12.09999999999989, 72.50000000000006, 19.50000000000001, -183.00000000000017, 85.09999999999997, 91.09999999999994, 7.399999999999995, -56.500000000000114, -442.4999999999992, -33.8000000000004, -45.49999999999981, 6.400000000000151, 25.70000000000007, -276.5999999999992, 24.40000000000005, 42.60000000000027, -92.20000000000005, 123.09999999999877, -97.40000000000026, -334.2999999999995, -47.09999999999976, 12.399999999999983, -1.3000000000000638, 33.99999999999974, -65.89999999999976, 20.0, 25.500000000000068, -19.800000000000615, -107.00000000000014, -65.8999999999998, 15.200000000000271, -20.799999999999514, 66.3000000000001, -29.699999999999804, -166.00000000000063, -85.30000000000001, 107.19999999999953, -134.40000000000123, -120.4000000000002, 210.1999999999994, -161.50000000000117, 12.699999999999944, 121.799999999999, -2.2999999999999785, -26.699999999999598, -1.7999999999996636, -18.99999999999966, 50.10000000000035], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-292.5999999999999, -343.0, -140.2, 13.699999999999964, -394.9, -299.19999999999936, -133.0, -43.89999999999998, -28.29999999999975, -19.89999999999975, 13.699999999999964, -400.0, 20.000000000000014, -394.0, 34.69999999999997, 102.50000000000003, 20.000000000000014, 20.000000000000014, -106.90000000000052, -21.999999999999922, 162.19999999999976, 98.90000000000006, -3.099999999999958, -114.7000000000002, -235.90000000000023, -229.30000000000007, 20.000000000000014, -234.70000000000036, -330.6999999999998, 11.599999999999964, -107.80000000000013, -48.69999999999985, -266.7999999999997, -127.00000000000023, -280.90000000000003, -254.50000000000003, -302.80000000000024, 20.000000000000014, -0.9999999999999881, -38.799999999999756, -353.20000000000005, -280.90000000000003, -204.7000000000002, 11.899999999999983, -366.4, -327.9999999999999, 68.30000000000001, -151.6000000000003, -94.90000000000015, -228.10000000000016, -129.1000000000007, 20.000000000000014, 20.000000000000014, 41.00000000000016, -395.79999999999995, -9.399999999999855, -111.40000000000026, 20.000000000000014, -259.3000000000004, -328.6000000000001, -82.90000000000086, -242.80000000000018, -165.70000000000007, 36.800000000000004, -11.499999999999819, -57.40000000000006, -196.0, 49.100000000000186, 86.60000000000002, -124.30000000000027, -288.9999999999999, -248.80000000000007, -57.09999999999995, 49.3999999999998, -3.099999999999958, -341.19999999999936, -221.20000000000002, -15.699999999999747, -270.10000000000014, -326.4999999999993, -300.6999999999999, -7.299999999999891, -258.70000000000016, -80.80000000000062, 3.1999999999999633, -320.50000000000006, -17.79999999999974, 11.599999999999964, -16.300000000000097, -160.60000000000002, -7.299999999999891, -181.90000000000015, -138.70000000000002, -203.5000000000002, -250.90000000000023, -3.099999999999958, -67.60000000000005, -5.1999999999999265, 46.100000000000044, 87.79999999999993, -142.90000000000006, -232.9000000000001, -127.6000000000002, -12.099999999999838, -127.30000000000015, -46.600000000000016, -32.5000000000002, 20.000000000000043, 3.1999999999999615, 5.299999999999965, -271.6, -270.4, 10.09999999999985, 20.000000000000014, 3.1999999999997613, 17.899999999999988, -224.5000000000002, 17.899999999999988, -172.90000000000012, -58.599999999999994, -275.4999999999996, -357.9999999999997, -65.50000000000057, -169.30000000000015, -257.2000000000001, -139.30000000000067, -0.9999999999999846, -34.59999999999975, 17.899999999999988, -5.1999999999999265, -288.70000000000016, -208.90000000000052, 20.000000000000014, -13.599999999999783, -321.3999999999999, 20.000000000000014, -3.099999999999958, -312.1, 56.90000000000016, -11.799999999999981, -256.9000000000002, 21.500000000000036, -341.19999999999993, -342.09999999999957, -213.10000000000022, 20.000000000000014, -64.90000000000059, -0.7000000000000276, -249.40000000000018, 1.0999999999999865, -44.499999999999766, -32.500000000000085, -299.7999999999996, 17.899999999999988, 12.499999999999961, -11.499999999999819, -11.499999999999819, 20.000000000000014, -24.100000000000385, -51.69999999999998, -337.0000000000001, 20.000000000000014, -304.9, 20.000000000000014, -62.79999999999995, -0.9999999999999846, -76.6000000000008, -5.1999999999999265, 20.000000000000014, -108.70000000000019, 7.399999999999965, -138.09999999999994, -203.5000000000003, -284.49999999999926, 20.000000000000014, -364.29999999999995, 86.29999999999984, -162.10000000000028, -252.10000000000005, -70.30000000000089, -57.70000000000048, -234.70000000000013, -49.000000000000334, 153.1999999999998, -272.8000000000003, -78.70000000000087, 11.599999999999964, -262.89999999999986, 118.99999999999952, -194.2000000000005, -15.699999999999747, -31.59999999999986, -132.40000000000066, -49.299999999999905, -56.80000000000064, -61.00000000000058, 20.000000000000014, -148.00000000000045, -97.89999999999989, -0.9999999999999846], "policy_predator_policy_reward": [165.0, 154.0, 95.0, 71.0, 199.0, 37.0, 69.0, 76.0, 24.0, 16.0, 152.0, 179.0, 198.0, 57.0, 50.0, 13.0, 0.0, 0.0, 51.0, 80.0, 19.0, 15.0, 96.0, 35.0, 1.0, 163.0, 126.0, 26.0, 87.0, 167.0, 67.0, 96.0, 62.0, 145.0, 171.0, 15.0, 60.0, 127.0, 9.0, 29.0, 42.0, 195.0, 15.0, 119.0, 187.0, 143.0, 71.0, 50.0, 132.0, 43.0, 71.0, 40.0, 5.0, 13.0, 165.0, 134.0, 37.0, 77.0, 187.0, 141.0, 158.0, 168.0, 84.0, 126.0, 63.0, 7.0, 108.0, 128.0, 71.0, 76.0, 159.0, 178.0, 38.0, 46.0, 78.0, 129.0, 145.0, 69.0, 197.0, 67.0, 175.0, 99.0, 143.0, 11.0, 144.0, 48.0, 15.0, 10.0, 119.0, 76.0, 116.0, 16.0, 157.0, 69.0, 138.0, 89.0, 81.0, 85.0, 46.0, 8.0, 134.0, 108.0, 91.0, 35.0, 101.0, 85.0, 39.0, 46.0, 3.0, 8.0, 198.0, 161.0, 41.0, 14.0, 17.0, 53.0, 118.0, 96.0, 71.0, 104.0, 188.0, 3.0, 99.0, 102.0, 173.0, 178.0, 27.0, 15.0, 12.0, 1.0, 168.0, 53.0, 5.0, 13.0, 172.0, 172.0, 158.0, 65.0, 38.0, 40.0, 27.0, 111.0, 199.0, 150.0, 126.0, 20.0, 20.0, 58.0, 105.0, 142.0, 80.0, 31.0, 75.0, 141.0, 4.0, 15.0, 15.0, 2.0, 53.0, 3.0, 151.0, 59.0, 125.0, 94.0, 79.0, 0.0, 15.0, 46.0, 90.0, 65.0, 81.0, 20.0, 158.0, 164.0, 122.0, 137.0, 97.0, 86.0, 92.0, 96.0, 131.0, 41.0, 54.0, 52.0, 146.0, 44.0, 137.0, 127.0, 95.0, 102.0, 17.0, 28.0, 85.0, 70.0, 58.0, 58.0, 27.0, 82.0, 74.0, 75.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.532586452553576, "mean_inference_ms": 1.3729681768491548, "mean_action_processing_ms": 0.22739458461807044, "mean_env_wait_ms": 0.17430018060571015, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033823251724243164, "StateBufferConnector_ms": 0.002909541130065918, "ViewRequirementAgentConnector_ms": 0.08428394794464111}, "num_episodes": 18, "episode_return_max": 295.1000000000008, "episode_return_min": -458.0999999999992, "episode_return_mean": -48.11000000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 438.6395900428918, "num_env_steps_trained_throughput_per_sec": 438.6395900428918, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 9188.126, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9188.087, "sample_time_ms": 1009.223, "learn_time_ms": 8166.593, "learn_throughput": 489.8, "synch_weights_time_ms": 11.549}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-38-38", "timestamp": 1723646318, "time_this_iter_s": 9.122413158416748, "time_total_s": 837.0253305435181, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0fbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 837.0253305435181, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 26.853846153846156, "ram_util_percent": 78.53076923076922}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.059104961440677, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 3.987318276854419, "policy_loss": -0.014200644447374596, "vf_loss": 3.999956055419155, "vf_explained_var": -0.9689763175747382, "kl": 0.01389218008443285, "entropy": 1.0553778983297801, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.175996542923034, "cur_kl_coeff": 0.1, "cur_lr": 0.00010000000000000003, "total_loss": 3.5857578435272135, "policy_loss": -0.004926169958832876, "vf_loss": 3.5902294914558452, "vf_explained_var": 0.18820928022975014, "kl": 0.004545228616098511, "entropy": 0.2304040215199902, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 210.1999999999994, "episode_reward_min": -442.4999999999992, "episode_reward_mean": -34.723000000000084, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 153.1999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -95.81650000000005, "predator_policy": 78.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-364.3999999999999, 37.700000000000145, -148.0000000000003, 1.8999999999999482, 78.99999999999928, -106.20000000000078, 22.600000000000186, -259.90000000000055, 0.299999999999967, 81.09999999999992, 1.1000000000000805, 89.09999999999994, 109.29999999999998, -200.80000000000032, 76.29999999999964, -137.3000000000007, -22.899999999999817, -332.5999999999989, -33.99999999999994, -185.50000000000082, -125.30000000000024, 18.799999999999994, 18.09999999999988, -57.20000000000009, -116.2000000000001, -26.999999999999762, 93.19999999999918, 187.89999999999972, -133.80000000000007, -13.700000000000607, 12.09999999999989, 72.50000000000006, 19.50000000000001, -183.00000000000017, 85.09999999999997, 91.09999999999994, 7.399999999999995, -56.500000000000114, -442.4999999999992, -33.8000000000004, -45.49999999999981, 6.400000000000151, 25.70000000000007, -276.5999999999992, 24.40000000000005, 42.60000000000027, -92.20000000000005, 123.09999999999877, -97.40000000000026, -334.2999999999995, -47.09999999999976, 12.399999999999983, -1.3000000000000638, 33.99999999999974, -65.89999999999976, 20.0, 25.500000000000068, -19.800000000000615, -107.00000000000014, -65.8999999999998, 15.200000000000271, -20.799999999999514, 66.3000000000001, -29.699999999999804, -166.00000000000063, -85.30000000000001, 107.19999999999953, -134.40000000000123, -120.4000000000002, 210.1999999999994, -161.50000000000117, 12.699999999999944, 121.799999999999, -2.2999999999999785, -26.699999999999598, -1.7999999999996636, -18.99999999999966, 50.10000000000035, -45.80000000000037, 47.30000000000032, -148.30000000000098, 26.200000000000095, -77.99999999999994, 52.000000000000504, -347.599999999999, -5.599999999999861, -103.50000000000013, 27.900000000000105, 16.89999999999994, 142.5999999999993, 123.49999999999989, -85.10000000000079, 31.200000000000166, 59.50000000000048, -7.299999999999855, -158.0000000000005, -67.9, -37.300000000000004, -23.899999999999686, 8.700000000000086], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-366.4, -327.9999999999999, 68.30000000000001, -151.6000000000003, -94.90000000000015, -228.10000000000016, -129.1000000000007, 20.000000000000014, 20.000000000000014, 41.00000000000016, -395.79999999999995, -9.399999999999855, -111.40000000000026, 20.000000000000014, -259.3000000000004, -328.6000000000001, -82.90000000000086, -242.80000000000018, -165.70000000000007, 36.800000000000004, -11.499999999999819, -57.40000000000006, -196.0, 49.100000000000186, 86.60000000000002, -124.30000000000027, -288.9999999999999, -248.80000000000007, -57.09999999999995, 49.3999999999998, -3.099999999999958, -341.19999999999936, -221.20000000000002, -15.699999999999747, -270.10000000000014, -326.4999999999993, -300.6999999999999, -7.299999999999891, -258.70000000000016, -80.80000000000062, 3.1999999999999633, -320.50000000000006, -17.79999999999974, 11.599999999999964, -16.300000000000097, -160.60000000000002, -7.299999999999891, -181.90000000000015, -138.70000000000002, -203.5000000000002, -250.90000000000023, -3.099999999999958, -67.60000000000005, -5.1999999999999265, 46.100000000000044, 87.79999999999993, -142.90000000000006, -232.9000000000001, -127.6000000000002, -12.099999999999838, -127.30000000000015, -46.600000000000016, -32.5000000000002, 20.000000000000043, 3.1999999999999615, 5.299999999999965, -271.6, -270.4, 10.09999999999985, 20.000000000000014, 3.1999999999997613, 17.899999999999988, -224.5000000000002, 17.899999999999988, -172.90000000000012, -58.599999999999994, -275.4999999999996, -357.9999999999997, -65.50000000000057, -169.30000000000015, -257.2000000000001, -139.30000000000067, -0.9999999999999846, -34.59999999999975, 17.899999999999988, -5.1999999999999265, -288.70000000000016, -208.90000000000052, 20.000000000000014, -13.599999999999783, -321.3999999999999, 20.000000000000014, -3.099999999999958, -312.1, 56.90000000000016, -11.799999999999981, -256.9000000000002, 21.500000000000036, -341.19999999999993, -342.09999999999957, -213.10000000000022, 20.000000000000014, -64.90000000000059, -0.7000000000000276, -249.40000000000018, 1.0999999999999865, -44.499999999999766, -32.500000000000085, -299.7999999999996, 17.899999999999988, 12.499999999999961, -11.499999999999819, -11.499999999999819, 20.000000000000014, -24.100000000000385, -51.69999999999998, -337.0000000000001, 20.000000000000014, -304.9, 20.000000000000014, -62.79999999999995, -0.9999999999999846, -76.6000000000008, -5.1999999999999265, 20.000000000000014, -108.70000000000019, 7.399999999999965, -138.09999999999994, -203.5000000000003, -284.49999999999926, 20.000000000000014, -364.29999999999995, 86.29999999999984, -162.10000000000028, -252.10000000000005, -70.30000000000089, -57.70000000000048, -234.70000000000013, -49.000000000000334, 153.1999999999998, -272.8000000000003, -78.70000000000087, 11.599999999999964, -262.89999999999986, 118.99999999999952, -194.2000000000005, -15.699999999999747, -31.59999999999986, -132.40000000000066, -49.299999999999905, -56.80000000000064, -61.00000000000058, 20.000000000000014, -148.00000000000045, -97.89999999999989, -0.9999999999999846, -85.00000000000085, -38.79999999999977, -24.099999999999746, -187.59999999999994, -54.3999999999998, -235.90000000000035, 20.000000000000014, -59.80000000000062, -228.10000000000002, 1.0999999999999865, 11.599999999999964, 34.40000000000026, -255.09999999999985, -326.49999999999955, 20.000000000000014, -139.60000000000065, -274.0000000000002, 9.499999999999964, 3.1999999999999615, 13.699999999999964, -11.499999999999876, 7.399999999999965, -7.899999999999999, 72.50000000000006, 58.09999999999988, -88.6000000000003, -7.299999999999891, -212.80000000000035, 7.399999999999967, 15.799999999999963, 31.400000000000198, 13.099999999999966, 7.399999999999965, -270.70000000000005, -345.40000000000015, 7.399999999999965, -166.6, -67.3000000000003, -51.40000000000005, -40.89999999999976, -310.89999999999935, 20.000000000000014, -42.99999999999976, 13.699999999999964], "policy_predator_policy_reward": [187.0, 143.0, 71.0, 50.0, 132.0, 43.0, 71.0, 40.0, 5.0, 13.0, 165.0, 134.0, 37.0, 77.0, 187.0, 141.0, 158.0, 168.0, 84.0, 126.0, 63.0, 7.0, 108.0, 128.0, 71.0, 76.0, 159.0, 178.0, 38.0, 46.0, 78.0, 129.0, 145.0, 69.0, 197.0, 67.0, 175.0, 99.0, 143.0, 11.0, 144.0, 48.0, 15.0, 10.0, 119.0, 76.0, 116.0, 16.0, 157.0, 69.0, 138.0, 89.0, 81.0, 85.0, 46.0, 8.0, 134.0, 108.0, 91.0, 35.0, 101.0, 85.0, 39.0, 46.0, 3.0, 8.0, 198.0, 161.0, 41.0, 14.0, 17.0, 53.0, 118.0, 96.0, 71.0, 104.0, 188.0, 3.0, 99.0, 102.0, 173.0, 178.0, 27.0, 15.0, 12.0, 1.0, 168.0, 53.0, 5.0, 13.0, 172.0, 172.0, 158.0, 65.0, 38.0, 40.0, 27.0, 111.0, 199.0, 150.0, 126.0, 20.0, 20.0, 58.0, 105.0, 142.0, 80.0, 31.0, 75.0, 141.0, 4.0, 15.0, 15.0, 2.0, 53.0, 3.0, 151.0, 59.0, 125.0, 94.0, 79.0, 0.0, 15.0, 46.0, 90.0, 65.0, 81.0, 20.0, 158.0, 164.0, 122.0, 137.0, 97.0, 86.0, 92.0, 96.0, 131.0, 41.0, 54.0, 52.0, 146.0, 44.0, 137.0, 127.0, 95.0, 102.0, 17.0, 28.0, 85.0, 70.0, 58.0, 58.0, 27.0, 82.0, 74.0, 75.0, 30.0, 48.0, 131.0, 128.0, 3.0, 139.0, 31.0, 35.0, 140.0, 9.0, 4.0, 2.0, 70.0, 164.0, 48.0, 66.0, 123.0, 38.0, 8.0, 3.0, 0.0, 21.0, 39.0, 39.0, 81.0, 73.0, 94.0, 41.0, 2.0, 6.0, 5.0, 10.0, 119.0, 137.0, 35.0, 145.0, 35.0, 131.0, 34.0, 21.0, 109.0, 158.0, 25.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5319800901570684, "mean_inference_ms": 1.3728879279972148, "mean_action_processing_ms": 0.2269737904950475, "mean_env_wait_ms": 0.17399509444450026, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0033745765686035156, "StateBufferConnector_ms": 0.002851724624633789, "ViewRequirementAgentConnector_ms": 0.08469164371490479}, "num_episodes": 22, "episode_return_max": 210.1999999999994, "episode_return_min": -442.4999999999992, "episode_return_mean": -34.723000000000084, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 441.9158635374429, "num_env_steps_trained_throughput_per_sec": 441.9158635374429, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 9162.835, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9162.796, "sample_time_ms": 1006.922, "learn_time_ms": 8143.685, "learn_throughput": 491.178, "synch_weights_time_ms": 11.455}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-38-47", "timestamp": 1723646327, "time_this_iter_s": 9.055774927139282, "time_total_s": 846.0811054706573, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ef160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 846.0811054706573, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 28.641666666666666, "ram_util_percent": 78.64166666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5540853468198625, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 2.534345024035721, "policy_loss": -0.014567345562243154, "vf_loss": 2.5475936934430763, "vf_explained_var": -0.9990166682414907, "kl": 0.0117215885361453, "entropy": 1.1202317550699548, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5607399620391704, "cur_kl_coeff": 0.05, "cur_lr": 0.00010000000000000003, "total_loss": 2.591927104715317, "policy_loss": -0.004843388294318208, "vf_loss": 2.5966050009878856, "vf_explained_var": 0.11153715170880474, "kl": 0.003309832349081145, "entropy": 0.21216572534943384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 210.1999999999994, "episode_reward_min": -442.4999999999992, "episode_reward_mean": -23.542000000000044, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 153.1999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -79.05100000000007, "predator_policy": 67.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-33.99999999999994, -185.50000000000082, -125.30000000000024, 18.799999999999994, 18.09999999999988, -57.20000000000009, -116.2000000000001, -26.999999999999762, 93.19999999999918, 187.89999999999972, -133.80000000000007, -13.700000000000607, 12.09999999999989, 72.50000000000006, 19.50000000000001, -183.00000000000017, 85.09999999999997, 91.09999999999994, 7.399999999999995, -56.500000000000114, -442.4999999999992, -33.8000000000004, -45.49999999999981, 6.400000000000151, 25.70000000000007, -276.5999999999992, 24.40000000000005, 42.60000000000027, -92.20000000000005, 123.09999999999877, -97.40000000000026, -334.2999999999995, -47.09999999999976, 12.399999999999983, -1.3000000000000638, 33.99999999999974, -65.89999999999976, 20.0, 25.500000000000068, -19.800000000000615, -107.00000000000014, -65.8999999999998, 15.200000000000271, -20.799999999999514, 66.3000000000001, -29.699999999999804, -166.00000000000063, -85.30000000000001, 107.19999999999953, -134.40000000000123, -120.4000000000002, 210.1999999999994, -161.50000000000117, 12.699999999999944, 121.799999999999, -2.2999999999999785, -26.699999999999598, -1.7999999999996636, -18.99999999999966, 50.10000000000035, -45.80000000000037, 47.30000000000032, -148.30000000000098, 26.200000000000095, -77.99999999999994, 52.000000000000504, -347.599999999999, -5.599999999999861, -103.50000000000013, 27.900000000000105, 16.89999999999994, 142.5999999999993, 123.49999999999989, -85.10000000000079, 31.200000000000166, 59.50000000000048, -7.299999999999855, -158.0000000000005, -67.9, -37.300000000000004, -23.899999999999686, 8.700000000000086, -50.20000000000077, 55.60000000000035, -37.999999999999616, 32.20000000000022, -8.000000000000085, -9.199999999999699, -6.699999999999651, 17.39999999999997, 14.499999999999922, 39.000000000000284, 26.40000000000011, -59.90000000000099, 36.000000000000256, -19.39999999999951, -57.59999999999964, 11.19999999999995, 34.70000000000022, 26.4000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-300.6999999999999, -7.299999999999891, -258.70000000000016, -80.80000000000062, 3.1999999999999633, -320.50000000000006, -17.79999999999974, 11.599999999999964, -16.300000000000097, -160.60000000000002, -7.299999999999891, -181.90000000000015, -138.70000000000002, -203.5000000000002, -250.90000000000023, -3.099999999999958, -67.60000000000005, -5.1999999999999265, 46.100000000000044, 87.79999999999993, -142.90000000000006, -232.9000000000001, -127.6000000000002, -12.099999999999838, -127.30000000000015, -46.600000000000016, -32.5000000000002, 20.000000000000043, 3.1999999999999615, 5.299999999999965, -271.6, -270.4, 10.09999999999985, 20.000000000000014, 3.1999999999997613, 17.899999999999988, -224.5000000000002, 17.899999999999988, -172.90000000000012, -58.599999999999994, -275.4999999999996, -357.9999999999997, -65.50000000000057, -169.30000000000015, -257.2000000000001, -139.30000000000067, -0.9999999999999846, -34.59999999999975, 17.899999999999988, -5.1999999999999265, -288.70000000000016, -208.90000000000052, 20.000000000000014, -13.599999999999783, -321.3999999999999, 20.000000000000014, -3.099999999999958, -312.1, 56.90000000000016, -11.799999999999981, -256.9000000000002, 21.500000000000036, -341.19999999999993, -342.09999999999957, -213.10000000000022, 20.000000000000014, -64.90000000000059, -0.7000000000000276, -249.40000000000018, 1.0999999999999865, -44.499999999999766, -32.500000000000085, -299.7999999999996, 17.899999999999988, 12.499999999999961, -11.499999999999819, -11.499999999999819, 20.000000000000014, -24.100000000000385, -51.69999999999998, -337.0000000000001, 20.000000000000014, -304.9, 20.000000000000014, -62.79999999999995, -0.9999999999999846, -76.6000000000008, -5.1999999999999265, 20.000000000000014, -108.70000000000019, 7.399999999999965, -138.09999999999994, -203.5000000000003, -284.49999999999926, 20.000000000000014, -364.29999999999995, 86.29999999999984, -162.10000000000028, -252.10000000000005, -70.30000000000089, -57.70000000000048, -234.70000000000013, -49.000000000000334, 153.1999999999998, -272.8000000000003, -78.70000000000087, 11.599999999999964, -262.89999999999986, 118.99999999999952, -194.2000000000005, -15.699999999999747, -31.59999999999986, -132.40000000000066, -49.299999999999905, -56.80000000000064, -61.00000000000058, 20.000000000000014, -148.00000000000045, -97.89999999999989, -0.9999999999999846, -85.00000000000085, -38.79999999999977, -24.099999999999746, -187.59999999999994, -54.3999999999998, -235.90000000000035, 20.000000000000014, -59.80000000000062, -228.10000000000002, 1.0999999999999865, 11.599999999999964, 34.40000000000026, -255.09999999999985, -326.49999999999955, 20.000000000000014, -139.60000000000065, -274.0000000000002, 9.499999999999964, 3.1999999999999615, 13.699999999999964, -11.499999999999876, 7.399999999999965, -7.899999999999999, 72.50000000000006, 58.09999999999988, -88.6000000000003, -7.299999999999891, -212.80000000000035, 7.399999999999967, 15.799999999999963, 31.400000000000198, 13.099999999999966, 7.399999999999965, -270.70000000000005, -345.40000000000015, 7.399999999999965, -166.6, -67.3000000000003, -51.40000000000005, -40.89999999999976, -310.89999999999935, 20.000000000000014, -42.99999999999976, 13.699999999999964, -64.00000000000091, -68.20000000000084, 20.000000000000014, -39.399999999999835, -24.099999999999746, -208.90000000000052, -7.900000000000022, -37.89999999999976, -190.30000000000013, 5.299999999999965, -94.6000000000007, 7.399999999999965, -38.799999999999756, 1.0999999999999865, -25.599999999999753, 20.000000000000014, -74.50000000000088, 20.000000000000014, 20.000000000000014, 7.999999999999966, -55.60000000000028, 20.000000000000014, -10.899999999999835, -148.00000000000063, 35.30000000000026, -34.29999999999976, -68.2000000000009, -5.1999999999999265, -259.3000000000004, 13.699999999999964, 5.299999999999965, -24.099999999999795, -7.299999999999891, 20.000000000000014, 10.999999999999975, -31.599999999999753], "policy_predator_policy_reward": [175.0, 99.0, 143.0, 11.0, 144.0, 48.0, 15.0, 10.0, 119.0, 76.0, 116.0, 16.0, 157.0, 69.0, 138.0, 89.0, 81.0, 85.0, 46.0, 8.0, 134.0, 108.0, 91.0, 35.0, 101.0, 85.0, 39.0, 46.0, 3.0, 8.0, 198.0, 161.0, 41.0, 14.0, 17.0, 53.0, 118.0, 96.0, 71.0, 104.0, 188.0, 3.0, 99.0, 102.0, 173.0, 178.0, 27.0, 15.0, 12.0, 1.0, 168.0, 53.0, 5.0, 13.0, 172.0, 172.0, 158.0, 65.0, 38.0, 40.0, 27.0, 111.0, 199.0, 150.0, 126.0, 20.0, 20.0, 58.0, 105.0, 142.0, 80.0, 31.0, 75.0, 141.0, 4.0, 15.0, 15.0, 2.0, 53.0, 3.0, 151.0, 59.0, 125.0, 94.0, 79.0, 0.0, 15.0, 46.0, 90.0, 65.0, 81.0, 20.0, 158.0, 164.0, 122.0, 137.0, 97.0, 86.0, 92.0, 96.0, 131.0, 41.0, 54.0, 52.0, 146.0, 44.0, 137.0, 127.0, 95.0, 102.0, 17.0, 28.0, 85.0, 70.0, 58.0, 58.0, 27.0, 82.0, 74.0, 75.0, 30.0, 48.0, 131.0, 128.0, 3.0, 139.0, 31.0, 35.0, 140.0, 9.0, 4.0, 2.0, 70.0, 164.0, 48.0, 66.0, 123.0, 38.0, 8.0, 3.0, 0.0, 21.0, 39.0, 39.0, 81.0, 73.0, 94.0, 41.0, 2.0, 6.0, 5.0, 10.0, 119.0, 137.0, 35.0, 145.0, 35.0, 131.0, 34.0, 21.0, 109.0, 158.0, 25.0, 13.0, 32.0, 50.0, 45.0, 30.0, 101.0, 94.0, 23.0, 55.0, 111.0, 66.0, 61.0, 17.0, 1.0, 30.0, 23.0, 0.0, 24.0, 45.0, 7.0, 4.0, 32.0, 30.0, 16.0, 83.0, 7.0, 28.0, 42.0, 12.0, 72.0, 116.0, 6.0, 24.0, 11.0, 11.0, 11.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5317887057658031, "mean_inference_ms": 1.3705624673193093, "mean_action_processing_ms": 0.22700446084972037, "mean_env_wait_ms": 0.17392354353430253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003344416618347168, "StateBufferConnector_ms": 0.0028374195098876953, "ViewRequirementAgentConnector_ms": 0.08506298065185547}, "num_episodes": 18, "episode_return_max": 210.1999999999994, "episode_return_min": -442.4999999999992, "episode_return_mean": -23.542000000000044, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 436.18070975673794, "num_env_steps_trained_throughput_per_sec": 436.18070975673794, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 9178.799, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9178.76, "sample_time_ms": 1007.705, "learn_time_ms": 8158.838, "learn_throughput": 490.266, "synch_weights_time_ms": 11.483}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-38-56", "timestamp": 1723646336, "time_this_iter_s": 9.173292875289917, "time_total_s": 855.2543983459473, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1d4550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 855.2543983459473, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 27.285714285714285, "ram_util_percent": 78.45}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.001192118913408, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 2.33452085452105, "policy_loss": -0.021732100532587284, "vf_loss": 2.354533994323993, "vf_explained_var": -0.9940396513888445, "kl": 0.015279673129491933, "entropy": 1.144321896474828, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4639518960127753, "cur_kl_coeff": 0.025, "cur_lr": 0.00010000000000000003, "total_loss": 2.0746796510206957, "policy_loss": -0.005983449352865733, "vf_loss": 2.080573302665085, "vf_explained_var": 0.07816171154143318, "kl": 0.0035917757444487446, "entropy": 0.23999383127878582, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 210.1999999999994, "episode_reward_min": -347.599999999999, "episode_reward_mean": -15.659000000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 153.1999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -62.60950000000008, "predator_policy": 54.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.400000000000151, 25.70000000000007, -276.5999999999992, 24.40000000000005, 42.60000000000027, -92.20000000000005, 123.09999999999877, -97.40000000000026, -334.2999999999995, -47.09999999999976, 12.399999999999983, -1.3000000000000638, 33.99999999999974, -65.89999999999976, 20.0, 25.500000000000068, -19.800000000000615, -107.00000000000014, -65.8999999999998, 15.200000000000271, -20.799999999999514, 66.3000000000001, -29.699999999999804, -166.00000000000063, -85.30000000000001, 107.19999999999953, -134.40000000000123, -120.4000000000002, 210.1999999999994, -161.50000000000117, 12.699999999999944, 121.799999999999, -2.2999999999999785, -26.699999999999598, -1.7999999999996636, -18.99999999999966, 50.10000000000035, -45.80000000000037, 47.30000000000032, -148.30000000000098, 26.200000000000095, -77.99999999999994, 52.000000000000504, -347.599999999999, -5.599999999999861, -103.50000000000013, 27.900000000000105, 16.89999999999994, 142.5999999999993, 123.49999999999989, -85.10000000000079, 31.200000000000166, 59.50000000000048, -7.299999999999855, -158.0000000000005, -67.9, -37.300000000000004, -23.899999999999686, 8.700000000000086, -50.20000000000077, 55.60000000000035, -37.999999999999616, 32.20000000000022, -8.000000000000085, -9.199999999999699, -6.699999999999651, 17.39999999999997, 14.499999999999922, 39.000000000000284, 26.40000000000011, -59.90000000000099, 36.000000000000256, -19.39999999999951, -57.59999999999964, 11.19999999999995, 34.70000000000022, 26.4000000000001, -90.10000000000144, 35.70000000000024, 23.90000000000027, 12.700000000000058, -56.400000000001086, -0.999999999999814, 32.00000000000018, -30.999999999999567, 12.99999999999996, 29.90000000000016, -1.4999999999997575, -29.199999999999513, 34.70000000000022, 22.000000000000007, 39.30000000000029, -20.299999999999507, 33.200000000000195, 14.8, -83.20000000000067, -61.69999999999964, 1.7000000000001474, -13.699999999999655, 35.200000000000266], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.9999999999999846, -34.59999999999975, 17.899999999999988, -5.1999999999999265, -288.70000000000016, -208.90000000000052, 20.000000000000014, -13.599999999999783, -321.3999999999999, 20.000000000000014, -3.099999999999958, -312.1, 56.90000000000016, -11.799999999999981, -256.9000000000002, 21.500000000000036, -341.19999999999993, -342.09999999999957, -213.10000000000022, 20.000000000000014, -64.90000000000059, -0.7000000000000276, -249.40000000000018, 1.0999999999999865, -44.499999999999766, -32.500000000000085, -299.7999999999996, 17.899999999999988, 12.499999999999961, -11.499999999999819, -11.499999999999819, 20.000000000000014, -24.100000000000385, -51.69999999999998, -337.0000000000001, 20.000000000000014, -304.9, 20.000000000000014, -62.79999999999995, -0.9999999999999846, -76.6000000000008, -5.1999999999999265, 20.000000000000014, -108.70000000000019, 7.399999999999965, -138.09999999999994, -203.5000000000003, -284.49999999999926, 20.000000000000014, -364.29999999999995, 86.29999999999984, -162.10000000000028, -252.10000000000005, -70.30000000000089, -57.70000000000048, -234.70000000000013, -49.000000000000334, 153.1999999999998, -272.8000000000003, -78.70000000000087, 11.599999999999964, -262.89999999999986, 118.99999999999952, -194.2000000000005, -15.699999999999747, -31.59999999999986, -132.40000000000066, -49.299999999999905, -56.80000000000064, -61.00000000000058, 20.000000000000014, -148.00000000000045, -97.89999999999989, -0.9999999999999846, -85.00000000000085, -38.79999999999977, -24.099999999999746, -187.59999999999994, -54.3999999999998, -235.90000000000035, 20.000000000000014, -59.80000000000062, -228.10000000000002, 1.0999999999999865, 11.599999999999964, 34.40000000000026, -255.09999999999985, -326.49999999999955, 20.000000000000014, -139.60000000000065, -274.0000000000002, 9.499999999999964, 3.1999999999999615, 13.699999999999964, -11.499999999999876, 7.399999999999965, -7.899999999999999, 72.50000000000006, 58.09999999999988, -88.6000000000003, -7.299999999999891, -212.80000000000035, 7.399999999999967, 15.799999999999963, 31.400000000000198, 13.099999999999966, 7.399999999999965, -270.70000000000005, -345.40000000000015, 7.399999999999965, -166.6, -67.3000000000003, -51.40000000000005, -40.89999999999976, -310.89999999999935, 20.000000000000014, -42.99999999999976, 13.699999999999964, -64.00000000000091, -68.20000000000084, 20.000000000000014, -39.399999999999835, -24.099999999999746, -208.90000000000052, -7.900000000000022, -37.89999999999976, -190.30000000000013, 5.299999999999965, -94.6000000000007, 7.399999999999965, -38.799999999999756, 1.0999999999999865, -25.599999999999753, 20.000000000000014, -74.50000000000088, 20.000000000000014, 20.000000000000014, 7.999999999999966, -55.60000000000028, 20.000000000000014, -10.899999999999835, -148.00000000000063, 35.30000000000026, -34.29999999999976, -68.2000000000009, -5.1999999999999265, -259.3000000000004, 13.699999999999964, 5.299999999999965, -24.099999999999795, -7.299999999999891, 20.000000000000014, 10.999999999999975, -31.599999999999753, -135.40000000000063, -63.70000000000079, 15.799999999999963, 17.899999999999988, -138.10000000000036, -0.9999999999999846, -13.599999999999783, 5.299999999999965, -68.2000000000009, -95.20000000000073, 20.000000000000014, -106.0000000000008, -0.9999999999999846, 20.000000000000014, -77.20000000000068, -38.799999999999756, -45.09999999999976, -10.899999999999906, 3.1999999999999615, 13.69999999999997, -57.70000000000048, 15.199999999999966, -42.99999999999976, -26.199999999999747, 29.000000000000163, -28.29999999999975, -4.599999999999943, 11.599999999999964, 11.599999999999964, 19.700000000000014, -18.699999999999754, -34.59999999999975, 13.699999999999964, 12.499999999999964, -5.199999999999941, -0.9999999999999846, -13.599999999999783, -265.5999999999999, 32.60000000000015, -202.3000000000005, -109.30000000000078, 20.000000000000014, -35.799999999999834, -40.89999999999977, -64.30000000000084, 12.499999999999966], "policy_predator_policy_reward": [27.0, 15.0, 12.0, 1.0, 168.0, 53.0, 5.0, 13.0, 172.0, 172.0, 158.0, 65.0, 38.0, 40.0, 27.0, 111.0, 199.0, 150.0, 126.0, 20.0, 20.0, 58.0, 105.0, 142.0, 80.0, 31.0, 75.0, 141.0, 4.0, 15.0, 15.0, 2.0, 53.0, 3.0, 151.0, 59.0, 125.0, 94.0, 79.0, 0.0, 15.0, 46.0, 90.0, 65.0, 81.0, 20.0, 158.0, 164.0, 122.0, 137.0, 97.0, 86.0, 92.0, 96.0, 131.0, 41.0, 54.0, 52.0, 146.0, 44.0, 137.0, 127.0, 95.0, 102.0, 17.0, 28.0, 85.0, 70.0, 58.0, 58.0, 27.0, 82.0, 74.0, 75.0, 30.0, 48.0, 131.0, 128.0, 3.0, 139.0, 31.0, 35.0, 140.0, 9.0, 4.0, 2.0, 70.0, 164.0, 48.0, 66.0, 123.0, 38.0, 8.0, 3.0, 0.0, 21.0, 39.0, 39.0, 81.0, 73.0, 94.0, 41.0, 2.0, 6.0, 5.0, 10.0, 119.0, 137.0, 35.0, 145.0, 35.0, 131.0, 34.0, 21.0, 109.0, 158.0, 25.0, 13.0, 32.0, 50.0, 45.0, 30.0, 101.0, 94.0, 23.0, 55.0, 111.0, 66.0, 61.0, 17.0, 1.0, 30.0, 23.0, 0.0, 24.0, 45.0, 7.0, 4.0, 32.0, 30.0, 16.0, 83.0, 7.0, 28.0, 42.0, 12.0, 72.0, 116.0, 6.0, 24.0, 11.0, 11.0, 11.0, 36.0, 35.0, 74.0, 0.0, 2.0, 70.0, 93.0, 16.0, 5.0, 47.0, 60.0, 40.0, 45.0, 4.0, 9.0, 24.0, 61.0, 39.0, 30.0, 11.0, 2.0, 35.0, 6.0, 10.0, 30.0, 11.0, 23.0, 11.0, 4.0, 4.0, 4.0, 28.0, 5.0, 4.0, 3.0, 3.0, 18.0, 121.0, 75.0, 108.0, 0.0, 32.0, 59.0, 58.0, 5.0, 38.0, 49.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5312139307201527, "mean_inference_ms": 1.3701598705608837, "mean_action_processing_ms": 0.22693225988209786, "mean_env_wait_ms": 0.17350205558720463, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037146806716918945, "StateBufferConnector_ms": 0.0028655529022216797, "ViewRequirementAgentConnector_ms": 0.08462142944335938}, "num_episodes": 23, "episode_return_max": 210.1999999999994, "episode_return_min": -347.599999999999, "episode_return_mean": -15.659000000000002, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 447.94156719271956, "num_env_steps_trained_throughput_per_sec": 447.94156719271956, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 9165.463, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9165.424, "sample_time_ms": 1006.995, "learn_time_ms": 8146.357, "learn_throughput": 491.017, "synch_weights_time_ms": 11.308}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-39-05", "timestamp": 1723646345, "time_this_iter_s": 8.933082103729248, "time_total_s": 864.1874804496765, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ef8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 864.1874804496765, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 26.974999999999998, "ram_util_percent": 78.36666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6650133748533864, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 1.6675715046584922, "policy_loss": -0.031129302530643093, "vf_loss": 1.6968783798041167, "vf_explained_var": -0.9744947874987567, "kl": 0.01619931419660403, "entropy": 1.1318664186846012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1705672531216234, "cur_kl_coeff": 0.0125, "cur_lr": 0.00010000000000000003, "total_loss": 1.5882491902699547, "policy_loss": -0.008200683186530435, "vf_loss": 1.5963892326153144, "vf_explained_var": 0.1827943905951485, "kl": 0.004851631190465915, "entropy": 0.2670443560474764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 210.1999999999994, "episode_reward_min": -347.599999999999, "episode_reward_mean": -5.033999999999964, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 153.1999999999998, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -48.87700000000009, "predator_policy": 46.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-65.8999999999998, 15.200000000000271, -20.799999999999514, 66.3000000000001, -29.699999999999804, -166.00000000000063, -85.30000000000001, 107.19999999999953, -134.40000000000123, -120.4000000000002, 210.1999999999994, -161.50000000000117, 12.699999999999944, 121.799999999999, -2.2999999999999785, -26.699999999999598, -1.7999999999996636, -18.99999999999966, 50.10000000000035, -45.80000000000037, 47.30000000000032, -148.30000000000098, 26.200000000000095, -77.99999999999994, 52.000000000000504, -347.599999999999, -5.599999999999861, -103.50000000000013, 27.900000000000105, 16.89999999999994, 142.5999999999993, 123.49999999999989, -85.10000000000079, 31.200000000000166, 59.50000000000048, -7.299999999999855, -158.0000000000005, -67.9, -37.300000000000004, -23.899999999999686, 8.700000000000086, -50.20000000000077, 55.60000000000035, -37.999999999999616, 32.20000000000022, -8.000000000000085, -9.199999999999699, -6.699999999999651, 17.39999999999997, 14.499999999999922, 39.000000000000284, 26.40000000000011, -59.90000000000099, 36.000000000000256, -19.39999999999951, -57.59999999999964, 11.19999999999995, 34.70000000000022, 26.4000000000001, -90.10000000000144, 35.70000000000024, 23.90000000000027, 12.700000000000058, -56.400000000001086, -0.999999999999814, 32.00000000000018, -30.999999999999567, 12.99999999999996, 29.90000000000016, -1.4999999999997575, -29.199999999999513, 34.70000000000022, 22.000000000000007, 39.30000000000029, -20.299999999999507, 33.200000000000195, 14.8, -83.20000000000067, -61.69999999999964, 1.7000000000001474, -13.699999999999655, 35.200000000000266, -2.299999999999751, 15.200000000000005, -12.199999999999603, -23.699999999999527, 12.299999999999981, 9.400000000000126, 52.50000000000045, 36.80000000000025, 27.900000000000105, 27.90000000000011, 14.30000000000001, -11.79999999999959, 37.50000000000026, 24.600000000000055, 60.60000000000039, 25.800000000000082, 2.6000000000001906, 37.600000000000264], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-304.9, 20.000000000000014, -62.79999999999995, -0.9999999999999846, -76.6000000000008, -5.1999999999999265, 20.000000000000014, -108.70000000000019, 7.399999999999965, -138.09999999999994, -203.5000000000003, -284.49999999999926, 20.000000000000014, -364.29999999999995, 86.29999999999984, -162.10000000000028, -252.10000000000005, -70.30000000000089, -57.70000000000048, -234.70000000000013, -49.000000000000334, 153.1999999999998, -272.8000000000003, -78.70000000000087, 11.599999999999964, -262.89999999999986, 118.99999999999952, -194.2000000000005, -15.699999999999747, -31.59999999999986, -132.40000000000066, -49.299999999999905, -56.80000000000064, -61.00000000000058, 20.000000000000014, -148.00000000000045, -97.89999999999989, -0.9999999999999846, -85.00000000000085, -38.79999999999977, -24.099999999999746, -187.59999999999994, -54.3999999999998, -235.90000000000035, 20.000000000000014, -59.80000000000062, -228.10000000000002, 1.0999999999999865, 11.599999999999964, 34.40000000000026, -255.09999999999985, -326.49999999999955, 20.000000000000014, -139.60000000000065, -274.0000000000002, 9.499999999999964, 3.1999999999999615, 13.699999999999964, -11.499999999999876, 7.399999999999965, -7.899999999999999, 72.50000000000006, 58.09999999999988, -88.6000000000003, -7.299999999999891, -212.80000000000035, 7.399999999999967, 15.799999999999963, 31.400000000000198, 13.099999999999966, 7.399999999999965, -270.70000000000005, -345.40000000000015, 7.399999999999965, -166.6, -67.3000000000003, -51.40000000000005, -40.89999999999976, -310.89999999999935, 20.000000000000014, -42.99999999999976, 13.699999999999964, -64.00000000000091, -68.20000000000084, 20.000000000000014, -39.399999999999835, -24.099999999999746, -208.90000000000052, -7.900000000000022, -37.89999999999976, -190.30000000000013, 5.299999999999965, -94.6000000000007, 7.399999999999965, -38.799999999999756, 1.0999999999999865, -25.599999999999753, 20.000000000000014, -74.50000000000088, 20.000000000000014, 20.000000000000014, 7.999999999999966, -55.60000000000028, 20.000000000000014, -10.899999999999835, -148.00000000000063, 35.30000000000026, -34.29999999999976, -68.2000000000009, -5.1999999999999265, -259.3000000000004, 13.699999999999964, 5.299999999999965, -24.099999999999795, -7.299999999999891, 20.000000000000014, 10.999999999999975, -31.599999999999753, -135.40000000000063, -63.70000000000079, 15.799999999999963, 17.899999999999988, -138.10000000000036, -0.9999999999999846, -13.599999999999783, 5.299999999999965, -68.2000000000009, -95.20000000000073, 20.000000000000014, -106.0000000000008, -0.9999999999999846, 20.000000000000014, -77.20000000000068, -38.799999999999756, -45.09999999999976, -10.899999999999906, 3.1999999999999615, 13.69999999999997, -57.70000000000048, 15.199999999999966, -42.99999999999976, -26.199999999999747, 29.000000000000163, -28.29999999999975, -4.599999999999943, 11.599999999999964, 11.599999999999964, 19.700000000000014, -18.699999999999754, -34.59999999999975, 13.699999999999964, 12.499999999999964, -5.199999999999941, -0.9999999999999846, -13.599999999999783, -265.5999999999999, 32.60000000000015, -202.3000000000005, -109.30000000000078, 20.000000000000014, -35.799999999999834, -40.89999999999977, -64.30000000000084, 12.499999999999966, 13.699999999999964, -61.00000000000061, -47.19999999999976, 13.399999999999975, -48.099999999999774, -45.09999999999976, -61.900000000000766, -23.799999999999756, -67.30000000000054, 20.600000000000023, 9.499999999999964, -111.10000000000053, -38.799999999999756, 53.300000000000225, 17.899999999999988, 17.899999999999988, 11.599999999999964, 5.299999999999965, -3.099999999999958, 20.000000000000014, -24.99999999999976, 5.299999999999965, -13.599999999999783, -68.2000000000009, 9.499999999999964, 20.000000000000014, 7.399999999999965, -17.79999999999977, 16.699999999999967, 8.899999999999988, -60.70000000000062, 9.499999999999966, -49.299999999999876, 17.899999999999988, -50.799999999999926, 7.399999999999965], "policy_predator_policy_reward": [125.0, 94.0, 79.0, 0.0, 15.0, 46.0, 90.0, 65.0, 81.0, 20.0, 158.0, 164.0, 122.0, 137.0, 97.0, 86.0, 92.0, 96.0, 131.0, 41.0, 54.0, 52.0, 146.0, 44.0, 137.0, 127.0, 95.0, 102.0, 17.0, 28.0, 85.0, 70.0, 58.0, 58.0, 27.0, 82.0, 74.0, 75.0, 30.0, 48.0, 131.0, 128.0, 3.0, 139.0, 31.0, 35.0, 140.0, 9.0, 4.0, 2.0, 70.0, 164.0, 48.0, 66.0, 123.0, 38.0, 8.0, 3.0, 0.0, 21.0, 39.0, 39.0, 81.0, 73.0, 94.0, 41.0, 2.0, 6.0, 5.0, 10.0, 119.0, 137.0, 35.0, 145.0, 35.0, 131.0, 34.0, 21.0, 109.0, 158.0, 25.0, 13.0, 32.0, 50.0, 45.0, 30.0, 101.0, 94.0, 23.0, 55.0, 111.0, 66.0, 61.0, 17.0, 1.0, 30.0, 23.0, 0.0, 24.0, 45.0, 7.0, 4.0, 32.0, 30.0, 16.0, 83.0, 7.0, 28.0, 42.0, 12.0, 72.0, 116.0, 6.0, 24.0, 11.0, 11.0, 11.0, 36.0, 35.0, 74.0, 0.0, 2.0, 70.0, 93.0, 16.0, 5.0, 47.0, 60.0, 40.0, 45.0, 4.0, 9.0, 24.0, 61.0, 39.0, 30.0, 11.0, 2.0, 35.0, 6.0, 10.0, 30.0, 11.0, 23.0, 11.0, 4.0, 4.0, 4.0, 28.0, 5.0, 4.0, 3.0, 3.0, 18.0, 121.0, 75.0, 108.0, 0.0, 32.0, 59.0, 58.0, 5.0, 38.0, 49.0, 39.0, 6.0, 42.0, 7.0, 42.0, 39.0, 39.0, 23.0, 22.0, 37.0, 43.0, 68.0, 28.0, 10.0, 1.0, 0.0, 4.0, 7.0, 0.0, 11.0, 24.0, 10.0, 34.0, 36.0, 5.0, 3.0, 12.0, 23.0, 16.0, 19.0, 40.0, 37.0, 10.0, 24.0, 43.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5309182777610804, "mean_inference_ms": 1.3679492184863629, "mean_action_processing_ms": 0.22658234708779598, "mean_env_wait_ms": 0.17347279701649312, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004145503044128418, "StateBufferConnector_ms": 0.002873539924621582, "ViewRequirementAgentConnector_ms": 0.08476269245147705}, "num_episodes": 18, "episode_return_max": 210.1999999999994, "episode_return_min": -347.599999999999, "episode_return_mean": -5.033999999999964, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 439.7465821591051, "num_env_steps_trained_throughput_per_sec": 439.7465821591051, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 9172.7, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9172.662, "sample_time_ms": 1006.895, "learn_time_ms": 8153.805, "learn_throughput": 490.569, "synch_weights_time_ms": 11.215}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-39-14", "timestamp": 1723646354, "time_this_iter_s": 9.099270105361938, "time_total_s": 873.2867505550385, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0efc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 873.2867505550385, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 28.684615384615388, "ram_util_percent": 78.73076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5421805944707658, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 1.700481550561057, "policy_loss": -0.01940836092462103, "vf_loss": 1.7188447680738237, "vf_explained_var": -0.8465806490529781, "kl": 0.009290145932441216, "entropy": 1.1393493647297854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4132590331255444, "cur_kl_coeff": 0.00625, "cur_lr": 0.00010000000000000003, "total_loss": 1.7829736204374405, "policy_loss": -0.007661435254307454, "vf_loss": 1.7906064376629218, "vf_explained_var": 0.08800921919484618, "kl": 0.00457836040084031, "entropy": 0.2524822890285462, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 142.5999999999993, "episode_reward_min": -347.599999999999, "episode_reward_mean": -1.2639999999999214, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -345.40000000000015, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.50000000000006, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -36.23200000000006, "predator_policy": 35.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.10000000000035, -45.80000000000037, 47.30000000000032, -148.30000000000098, 26.200000000000095, -77.99999999999994, 52.000000000000504, -347.599999999999, -5.599999999999861, -103.50000000000013, 27.900000000000105, 16.89999999999994, 142.5999999999993, 123.49999999999989, -85.10000000000079, 31.200000000000166, 59.50000000000048, -7.299999999999855, -158.0000000000005, -67.9, -37.300000000000004, -23.899999999999686, 8.700000000000086, -50.20000000000077, 55.60000000000035, -37.999999999999616, 32.20000000000022, -8.000000000000085, -9.199999999999699, -6.699999999999651, 17.39999999999997, 14.499999999999922, 39.000000000000284, 26.40000000000011, -59.90000000000099, 36.000000000000256, -19.39999999999951, -57.59999999999964, 11.19999999999995, 34.70000000000022, 26.4000000000001, -90.10000000000144, 35.70000000000024, 23.90000000000027, 12.700000000000058, -56.400000000001086, -0.999999999999814, 32.00000000000018, -30.999999999999567, 12.99999999999996, 29.90000000000016, -1.4999999999997575, -29.199999999999513, 34.70000000000022, 22.000000000000007, 39.30000000000029, -20.299999999999507, 33.200000000000195, 14.8, -83.20000000000067, -61.69999999999964, 1.7000000000001474, -13.699999999999655, 35.200000000000266, -2.299999999999751, 15.200000000000005, -12.199999999999603, -23.699999999999527, 12.299999999999981, 9.400000000000126, 52.50000000000045, 36.80000000000025, 27.900000000000105, 27.90000000000011, 14.30000000000001, -11.79999999999959, 37.50000000000026, 24.600000000000055, 60.60000000000039, 25.800000000000082, 2.6000000000001906, 37.600000000000264, -62.700000000001374, 28.70000000000014, 22.40000000000001, 30.100000000000147, -33.39999999999955, -26.39999999999953, 13.40000000000003, 27.700000000000124, -44.90000000000058, 28.50000000000012, 10.300000000000066, 21.299999999999997, 11.699999999999969, 59.20000000000048, -22.399999999999594, -21.399999999999544, 31.200000000000173, 3.300000000000163], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-97.89999999999989, -0.9999999999999846, -85.00000000000085, -38.79999999999977, -24.099999999999746, -187.59999999999994, -54.3999999999998, -235.90000000000035, 20.000000000000014, -59.80000000000062, -228.10000000000002, 1.0999999999999865, 11.599999999999964, 34.40000000000026, -255.09999999999985, -326.49999999999955, 20.000000000000014, -139.60000000000065, -274.0000000000002, 9.499999999999964, 3.1999999999999615, 13.699999999999964, -11.499999999999876, 7.399999999999965, -7.899999999999999, 72.50000000000006, 58.09999999999988, -88.6000000000003, -7.299999999999891, -212.80000000000035, 7.399999999999967, 15.799999999999963, 31.400000000000198, 13.099999999999966, 7.399999999999965, -270.70000000000005, -345.40000000000015, 7.399999999999965, -166.6, -67.3000000000003, -51.40000000000005, -40.89999999999976, -310.89999999999935, 20.000000000000014, -42.99999999999976, 13.699999999999964, -64.00000000000091, -68.20000000000084, 20.000000000000014, -39.399999999999835, -24.099999999999746, -208.90000000000052, -7.900000000000022, -37.89999999999976, -190.30000000000013, 5.299999999999965, -94.6000000000007, 7.399999999999965, -38.799999999999756, 1.0999999999999865, -25.599999999999753, 20.000000000000014, -74.50000000000088, 20.000000000000014, 20.000000000000014, 7.999999999999966, -55.60000000000028, 20.000000000000014, -10.899999999999835, -148.00000000000063, 35.30000000000026, -34.29999999999976, -68.2000000000009, -5.1999999999999265, -259.3000000000004, 13.699999999999964, 5.299999999999965, -24.099999999999795, -7.299999999999891, 20.000000000000014, 10.999999999999975, -31.599999999999753, -135.40000000000063, -63.70000000000079, 15.799999999999963, 17.899999999999988, -138.10000000000036, -0.9999999999999846, -13.599999999999783, 5.299999999999965, -68.2000000000009, -95.20000000000073, 20.000000000000014, -106.0000000000008, -0.9999999999999846, 20.000000000000014, -77.20000000000068, -38.799999999999756, -45.09999999999976, -10.899999999999906, 3.1999999999999615, 13.69999999999997, -57.70000000000048, 15.199999999999966, -42.99999999999976, -26.199999999999747, 29.000000000000163, -28.29999999999975, -4.599999999999943, 11.599999999999964, 11.599999999999964, 19.700000000000014, -18.699999999999754, -34.59999999999975, 13.699999999999964, 12.499999999999964, -5.199999999999941, -0.9999999999999846, -13.599999999999783, -265.5999999999999, 32.60000000000015, -202.3000000000005, -109.30000000000078, 20.000000000000014, -35.799999999999834, -40.89999999999977, -64.30000000000084, 12.499999999999966, 13.699999999999964, -61.00000000000061, -47.19999999999976, 13.399999999999975, -48.099999999999774, -45.09999999999976, -61.900000000000766, -23.799999999999756, -67.30000000000054, 20.600000000000023, 9.499999999999964, -111.10000000000053, -38.799999999999756, 53.300000000000225, 17.899999999999988, 17.899999999999988, 11.599999999999964, 5.299999999999965, -3.099999999999958, 20.000000000000014, -24.99999999999976, 5.299999999999965, -13.599999999999783, -68.2000000000009, 9.499999999999964, 20.000000000000014, 7.399999999999965, -17.79999999999977, 16.699999999999967, 8.899999999999988, -60.70000000000062, 9.499999999999966, -49.299999999999876, 17.899999999999988, -50.799999999999926, 7.399999999999965, -49.59999999999977, -108.10000000000079, 20.000000000000014, -34.29999999999976, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, 3.1999999999999615, -85.00000000000085, -30.39999999999975, -79.0000000000008, -9.399999999999858, 17.899999999999988, -29.49999999999975, 5.299999999999965, 10.399999999999977, -38.799999999999756, -45.09999999999976, 9.499999999999964, 1.9999999999999607, -15.699999999999768, -0.9999999999999881, -9.399999999999855, 13.699999999999964, -21.999999999999744, -7.29999999999994, 42.500000000000234, -7.299999999999891, -78.70000000000087, -87.69999999999999, 9.49999999999998, -82.90000000000086, -17.79999999999974, 20.000000000000014, -53.50000000000016, 21.80000000000004], "policy_predator_policy_reward": [74.0, 75.0, 30.0, 48.0, 131.0, 128.0, 3.0, 139.0, 31.0, 35.0, 140.0, 9.0, 4.0, 2.0, 70.0, 164.0, 48.0, 66.0, 123.0, 38.0, 8.0, 3.0, 0.0, 21.0, 39.0, 39.0, 81.0, 73.0, 94.0, 41.0, 2.0, 6.0, 5.0, 10.0, 119.0, 137.0, 35.0, 145.0, 35.0, 131.0, 34.0, 21.0, 109.0, 158.0, 25.0, 13.0, 32.0, 50.0, 45.0, 30.0, 101.0, 94.0, 23.0, 55.0, 111.0, 66.0, 61.0, 17.0, 1.0, 30.0, 23.0, 0.0, 24.0, 45.0, 7.0, 4.0, 32.0, 30.0, 16.0, 83.0, 7.0, 28.0, 42.0, 12.0, 72.0, 116.0, 6.0, 24.0, 11.0, 11.0, 11.0, 36.0, 35.0, 74.0, 0.0, 2.0, 70.0, 93.0, 16.0, 5.0, 47.0, 60.0, 40.0, 45.0, 4.0, 9.0, 24.0, 61.0, 39.0, 30.0, 11.0, 2.0, 35.0, 6.0, 10.0, 30.0, 11.0, 23.0, 11.0, 4.0, 4.0, 4.0, 28.0, 5.0, 4.0, 3.0, 3.0, 18.0, 121.0, 75.0, 108.0, 0.0, 32.0, 59.0, 58.0, 5.0, 38.0, 49.0, 39.0, 6.0, 42.0, 7.0, 42.0, 39.0, 39.0, 23.0, 22.0, 37.0, 43.0, 68.0, 28.0, 10.0, 1.0, 0.0, 4.0, 7.0, 0.0, 11.0, 24.0, 10.0, 34.0, 36.0, 5.0, 3.0, 12.0, 23.0, 16.0, 19.0, 40.0, 37.0, 10.0, 24.0, 43.0, 38.0, 61.0, 34.0, 19.0, 24.0, 8.0, 8.0, 8.0, 1.0, 44.0, 38.0, 14.0, 48.0, 4.0, 21.0, 12.0, 0.0, 8.0, 31.0, 5.0, 12.0, 10.0, 17.0, 14.0, 3.0, 20.0, 21.0, 12.0, 12.0, 60.0, 84.0, 52.0, 0.0, 11.0, 18.0, 0.0, 35.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5304884224468411, "mean_inference_ms": 1.3667927366283201, "mean_action_processing_ms": 0.22638960419309712, "mean_env_wait_ms": 0.1732594550714867, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004474997520446777, "StateBufferConnector_ms": 0.0028547048568725586, "ViewRequirementAgentConnector_ms": 0.0835953950881958}, "num_episodes": 18, "episode_return_max": 142.5999999999993, "episode_return_min": -347.599999999999, "episode_return_mean": -1.2639999999999214, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 448.46015648403636, "num_env_steps_trained_throughput_per_sec": 448.46015648403636, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 9131.77, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9131.732, "sample_time_ms": 1006.89, "learn_time_ms": 8113.062, "learn_throughput": 493.032, "synch_weights_time_ms": 11.026}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-39-23", "timestamp": 1723646363, "time_this_iter_s": 8.922789096832275, "time_total_s": 882.2095396518707, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 882.2095396518707, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 27.353846153846153, "ram_util_percent": 79.17692307692307}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2540280250172136, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 1.0241621209732281, "policy_loss": -0.02469455747268897, "vf_loss": 1.0480957416472612, "vf_explained_var": -0.6899130384127299, "kl": 0.006763893644634608, "entropy": 1.0830138843526285, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7660447688329788, "cur_kl_coeff": 0.003125, "cur_lr": 0.00010000000000000003, "total_loss": 0.9335570943418634, "policy_loss": -0.010357022119831373, "vf_loss": 0.9438732887859698, "vf_explained_var": 0.29869256713402964, "kl": 0.013064426471995046, "entropy": 0.280572585572326, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 60.60000000000039, "episode_reward_min": -143.7000000000015, "episode_reward_mean": 6.243000000000098, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -265.5999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 53.300000000000225, "predator_policy": 121.0}, "policy_reward_mean": {"prey_policy": -23.018500000000063, "predator_policy": 26.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.700000000000086, -50.20000000000077, 55.60000000000035, -37.999999999999616, 32.20000000000022, -8.000000000000085, -9.199999999999699, -6.699999999999651, 17.39999999999997, 14.499999999999922, 39.000000000000284, 26.40000000000011, -59.90000000000099, 36.000000000000256, -19.39999999999951, -57.59999999999964, 11.19999999999995, 34.70000000000022, 26.4000000000001, -90.10000000000144, 35.70000000000024, 23.90000000000027, 12.700000000000058, -56.400000000001086, -0.999999999999814, 32.00000000000018, -30.999999999999567, 12.99999999999996, 29.90000000000016, -1.4999999999997575, -29.199999999999513, 34.70000000000022, 22.000000000000007, 39.30000000000029, -20.299999999999507, 33.200000000000195, 14.8, -83.20000000000067, -61.69999999999964, 1.7000000000001474, -13.699999999999655, 35.200000000000266, -2.299999999999751, 15.200000000000005, -12.199999999999603, -23.699999999999527, 12.299999999999981, 9.400000000000126, 52.50000000000045, 36.80000000000025, 27.900000000000105, 27.90000000000011, 14.30000000000001, -11.79999999999959, 37.50000000000026, 24.600000000000055, 60.60000000000039, 25.800000000000082, 2.6000000000001906, 37.600000000000264, -62.700000000001374, 28.70000000000014, 22.40000000000001, 30.100000000000147, -33.39999999999955, -26.39999999999953, 13.40000000000003, 27.700000000000124, -44.90000000000058, 28.50000000000012, 10.300000000000066, 21.299999999999997, 11.699999999999969, 59.20000000000048, -22.399999999999594, -21.399999999999544, 31.200000000000173, 3.300000000000163, -9.899999999999604, 10.800000000000079, 9.199999999999953, 17.499999999999936, 16.500000000000167, -32.79999999999953, -143.7000000000015, 14.699999999999994, 31.200000000000163, 35.40000000000023, 14.700000000000022, 36.70000000000025, 20.49999999999999, 50.50000000000048, -12.999999999999671, 34.800000000000225, 7.800000000000004, 27.5000000000001, 24.300000000000043, 8.100000000000131, 48.90000000000045, 9.90000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-42.99999999999976, 13.699999999999964, -64.00000000000091, -68.20000000000084, 20.000000000000014, -39.399999999999835, -24.099999999999746, -208.90000000000052, -7.900000000000022, -37.89999999999976, -190.30000000000013, 5.299999999999965, -94.6000000000007, 7.399999999999965, -38.799999999999756, 1.0999999999999865, -25.599999999999753, 20.000000000000014, -74.50000000000088, 20.000000000000014, 20.000000000000014, 7.999999999999966, -55.60000000000028, 20.000000000000014, -10.899999999999835, -148.00000000000063, 35.30000000000026, -34.29999999999976, -68.2000000000009, -5.1999999999999265, -259.3000000000004, 13.699999999999964, 5.299999999999965, -24.099999999999795, -7.299999999999891, 20.000000000000014, 10.999999999999975, -31.599999999999753, -135.40000000000063, -63.70000000000079, 15.799999999999963, 17.899999999999988, -138.10000000000036, -0.9999999999999846, -13.599999999999783, 5.299999999999965, -68.2000000000009, -95.20000000000073, 20.000000000000014, -106.0000000000008, -0.9999999999999846, 20.000000000000014, -77.20000000000068, -38.799999999999756, -45.09999999999976, -10.899999999999906, 3.1999999999999615, 13.69999999999997, -57.70000000000048, 15.199999999999966, -42.99999999999976, -26.199999999999747, 29.000000000000163, -28.29999999999975, -4.599999999999943, 11.599999999999964, 11.599999999999964, 19.700000000000014, -18.699999999999754, -34.59999999999975, 13.699999999999964, 12.499999999999964, -5.199999999999941, -0.9999999999999846, -13.599999999999783, -265.5999999999999, 32.60000000000015, -202.3000000000005, -109.30000000000078, 20.000000000000014, -35.799999999999834, -40.89999999999977, -64.30000000000084, 12.499999999999966, 13.699999999999964, -61.00000000000061, -47.19999999999976, 13.399999999999975, -48.099999999999774, -45.09999999999976, -61.900000000000766, -23.799999999999756, -67.30000000000054, 20.600000000000023, 9.499999999999964, -111.10000000000053, -38.799999999999756, 53.300000000000225, 17.899999999999988, 17.899999999999988, 11.599999999999964, 5.299999999999965, -3.099999999999958, 20.000000000000014, -24.99999999999976, 5.299999999999965, -13.599999999999783, -68.2000000000009, 9.499999999999964, 20.000000000000014, 7.399999999999965, -17.79999999999977, 16.699999999999967, 8.899999999999988, -60.70000000000062, 9.499999999999966, -49.299999999999876, 17.899999999999988, -50.799999999999926, 7.399999999999965, -49.59999999999977, -108.10000000000079, 20.000000000000014, -34.29999999999976, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, 3.1999999999999615, -85.00000000000085, -30.39999999999975, -79.0000000000008, -9.399999999999858, 17.899999999999988, -29.49999999999975, 5.299999999999965, 10.399999999999977, -38.799999999999756, -45.09999999999976, 9.499999999999964, 1.9999999999999607, -15.699999999999768, -0.9999999999999881, -9.399999999999855, 13.699999999999964, -21.999999999999744, -7.29999999999994, 42.500000000000234, -7.299999999999891, -78.70000000000087, -87.69999999999999, 9.49999999999998, -82.90000000000086, -17.79999999999974, 20.000000000000014, -53.50000000000016, 21.80000000000004, -40.89999999999976, -0.9999999999999917, -21.999999999999744, -5.1999999999999265, 3.1999999999999615, -21.99999999999983, 20.000000000000014, -32.49999999999977, -24.099999999999746, 8.600000000000065, -80.80000000000086, -21.999999999999744, -66.10000000000078, -181.60000000000053, -24.099999999999746, 15.799999999999963, 13.699999999999964, 9.499999999999964, 13.699999999999964, 16.69999999999997, -11.499999999999819, 3.1999999999999615, 20.000000000000014, 13.699999999999964, -36.699999999999775, 12.199999999999966, 7.399999999999965, 37.10000000000025, -184.00000000000057, 20.000000000000014, 23.600000000000065, 3.1999999999999615, -106.0000000000008, 15.799999999999963, 7.399999999999965, 7.099999999999966, 7.399999999999965, -3.099999999999958, -26.199999999999747, 5.299999999999965, 17.899999999999984, 20.000000000000014, -45.09999999999976, 20.000000000000014], "policy_predator_policy_reward": [25.0, 13.0, 32.0, 50.0, 45.0, 30.0, 101.0, 94.0, 23.0, 55.0, 111.0, 66.0, 61.0, 17.0, 1.0, 30.0, 23.0, 0.0, 24.0, 45.0, 7.0, 4.0, 32.0, 30.0, 16.0, 83.0, 7.0, 28.0, 42.0, 12.0, 72.0, 116.0, 6.0, 24.0, 11.0, 11.0, 11.0, 36.0, 35.0, 74.0, 0.0, 2.0, 70.0, 93.0, 16.0, 5.0, 47.0, 60.0, 40.0, 45.0, 4.0, 9.0, 24.0, 61.0, 39.0, 30.0, 11.0, 2.0, 35.0, 6.0, 10.0, 30.0, 11.0, 23.0, 11.0, 4.0, 4.0, 4.0, 28.0, 5.0, 4.0, 3.0, 3.0, 18.0, 121.0, 75.0, 108.0, 0.0, 32.0, 59.0, 58.0, 5.0, 38.0, 49.0, 39.0, 6.0, 42.0, 7.0, 42.0, 39.0, 39.0, 23.0, 22.0, 37.0, 43.0, 68.0, 28.0, 10.0, 1.0, 0.0, 4.0, 7.0, 0.0, 11.0, 24.0, 10.0, 34.0, 36.0, 5.0, 3.0, 12.0, 23.0, 16.0, 19.0, 40.0, 37.0, 10.0, 24.0, 43.0, 38.0, 61.0, 34.0, 19.0, 24.0, 8.0, 8.0, 8.0, 1.0, 44.0, 38.0, 14.0, 48.0, 4.0, 21.0, 12.0, 0.0, 8.0, 31.0, 5.0, 12.0, 10.0, 17.0, 14.0, 3.0, 20.0, 21.0, 12.0, 12.0, 60.0, 84.0, 52.0, 0.0, 11.0, 18.0, 0.0, 35.0, 30.0, 2.0, 18.0, 20.0, 10.0, 18.0, 5.0, 25.0, 21.0, 11.0, 48.0, 22.0, 54.0, 50.0, 10.0, 13.0, 2.0, 6.0, 3.0, 2.0, 8.0, 15.0, 0.0, 3.0, 27.0, 18.0, 6.0, 0.0, 97.0, 54.0, 6.0, 2.0, 38.0, 60.0, 6.0, 7.0, 11.0, 9.0, 22.0, 7.0, 4.0, 7.0, 31.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5299496443619562, "mean_inference_ms": 1.3653085857209064, "mean_action_processing_ms": 0.22615635914744658, "mean_env_wait_ms": 0.17299367910435115, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0048972368240356445, "StateBufferConnector_ms": 0.0027927160263061523, "ViewRequirementAgentConnector_ms": 0.08358943462371826}, "num_episodes": 22, "episode_return_max": 60.60000000000039, "episode_return_min": -143.7000000000015, "episode_return_mean": 6.243000000000098, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 447.4528745670015, "num_env_steps_trained_throughput_per_sec": 447.4528745670015, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 9092.922, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9092.884, "sample_time_ms": 1008.557, "learn_time_ms": 8072.344, "learn_throughput": 495.519, "synch_weights_time_ms": 11.206}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-39-32", "timestamp": 1723646372, "time_this_iter_s": 8.942888975143433, "time_total_s": 891.1524286270142, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0ebee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 891.1524286270142, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 26.007692307692306, "ram_util_percent": 79.38461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8501973335074369, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 1.0580044722371789, "policy_loss": -0.015906600981073642, "vf_loss": 1.0732155116146835, "vf_explained_var": -0.7366678804632217, "kl": 0.006182791419793227, "entropy": 1.120049192854967, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5373532112313326, "cur_kl_coeff": 0.003125, "cur_lr": 0.00010000000000000003, "total_loss": 1.0779851305737067, "policy_loss": -0.008053096044788915, "vf_loss": 1.0860220092787314, "vf_explained_var": 0.15338451903333108, "kl": 0.005190219835163928, "entropy": 0.25485506807527847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 86.9999999999988, "episode_reward_min": -143.7000000000015, "episode_reward_mean": 10.463000000000088, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -265.5999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999955, "predator_policy": 121.0}, "policy_reward_mean": {"prey_policy": -17.138500000000054, "predator_policy": 22.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.4000000000001, -90.10000000000144, 35.70000000000024, 23.90000000000027, 12.700000000000058, -56.400000000001086, -0.999999999999814, 32.00000000000018, -30.999999999999567, 12.99999999999996, 29.90000000000016, -1.4999999999997575, -29.199999999999513, 34.70000000000022, 22.000000000000007, 39.30000000000029, -20.299999999999507, 33.200000000000195, 14.8, -83.20000000000067, -61.69999999999964, 1.7000000000001474, -13.699999999999655, 35.200000000000266, -2.299999999999751, 15.200000000000005, -12.199999999999603, -23.699999999999527, 12.299999999999981, 9.400000000000126, 52.50000000000045, 36.80000000000025, 27.900000000000105, 27.90000000000011, 14.30000000000001, -11.79999999999959, 37.50000000000026, 24.600000000000055, 60.60000000000039, 25.800000000000082, 2.6000000000001906, 37.600000000000264, -62.700000000001374, 28.70000000000014, 22.40000000000001, 30.100000000000147, -33.39999999999955, -26.39999999999953, 13.40000000000003, 27.700000000000124, -44.90000000000058, 28.50000000000012, 10.300000000000066, 21.299999999999997, 11.699999999999969, 59.20000000000048, -22.399999999999594, -21.399999999999544, 31.200000000000173, 3.300000000000163, -9.899999999999604, 10.800000000000079, 9.199999999999953, 17.499999999999936, 16.500000000000167, -32.79999999999953, -143.7000000000015, 14.699999999999994, 31.200000000000163, 35.40000000000023, 14.700000000000022, 36.70000000000025, 20.49999999999999, 50.50000000000048, -12.999999999999671, 34.800000000000225, 7.800000000000004, 27.5000000000001, 24.300000000000043, 8.100000000000131, 48.90000000000045, 9.90000000000006, 12.399999999999917, 20.80000000000001, 22.40000000000001, 34.40000000000022, -6.199999999999681, 38.60000000000028, 16.599999999999923, 24.60000000000005, 25.900000000000098, 86.9999999999988, 33.400000000000205, 34.50000000000022, 9.799999999999947, 2.2000000000001796, 35.40000000000023, 33.4000000000002, 9.900000000000047, 13.599999999999977], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [10.999999999999975, -31.599999999999753, -135.40000000000063, -63.70000000000079, 15.799999999999963, 17.899999999999988, -138.10000000000036, -0.9999999999999846, -13.599999999999783, 5.299999999999965, -68.2000000000009, -95.20000000000073, 20.000000000000014, -106.0000000000008, -0.9999999999999846, 20.000000000000014, -77.20000000000068, -38.799999999999756, -45.09999999999976, -10.899999999999906, 3.1999999999999615, 13.69999999999997, -57.70000000000048, 15.199999999999966, -42.99999999999976, -26.199999999999747, 29.000000000000163, -28.29999999999975, -4.599999999999943, 11.599999999999964, 11.599999999999964, 19.700000000000014, -18.699999999999754, -34.59999999999975, 13.699999999999964, 12.499999999999964, -5.199999999999941, -0.9999999999999846, -13.599999999999783, -265.5999999999999, 32.60000000000015, -202.3000000000005, -109.30000000000078, 20.000000000000014, -35.799999999999834, -40.89999999999977, -64.30000000000084, 12.499999999999966, 13.699999999999964, -61.00000000000061, -47.19999999999976, 13.399999999999975, -48.099999999999774, -45.09999999999976, -61.900000000000766, -23.799999999999756, -67.30000000000054, 20.600000000000023, 9.499999999999964, -111.10000000000053, -38.799999999999756, 53.300000000000225, 17.899999999999988, 17.899999999999988, 11.599999999999964, 5.299999999999965, -3.099999999999958, 20.000000000000014, -24.99999999999976, 5.299999999999965, -13.599999999999783, -68.2000000000009, 9.499999999999964, 20.000000000000014, 7.399999999999965, -17.79999999999977, 16.699999999999967, 8.899999999999988, -60.70000000000062, 9.499999999999966, -49.299999999999876, 17.899999999999988, -50.799999999999926, 7.399999999999965, -49.59999999999977, -108.10000000000079, 20.000000000000014, -34.29999999999976, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, 3.1999999999999615, -85.00000000000085, -30.39999999999975, -79.0000000000008, -9.399999999999858, 17.899999999999988, -29.49999999999975, 5.299999999999965, 10.399999999999977, -38.799999999999756, -45.09999999999976, 9.499999999999964, 1.9999999999999607, -15.699999999999768, -0.9999999999999881, -9.399999999999855, 13.699999999999964, -21.999999999999744, -7.29999999999994, 42.500000000000234, -7.299999999999891, -78.70000000000087, -87.69999999999999, 9.49999999999998, -82.90000000000086, -17.79999999999974, 20.000000000000014, -53.50000000000016, 21.80000000000004, -40.89999999999976, -0.9999999999999917, -21.999999999999744, -5.1999999999999265, 3.1999999999999615, -21.99999999999983, 20.000000000000014, -32.49999999999977, -24.099999999999746, 8.600000000000065, -80.80000000000086, -21.999999999999744, -66.10000000000078, -181.60000000000053, -24.099999999999746, 15.799999999999963, 13.699999999999964, 9.499999999999964, 13.699999999999964, 16.69999999999997, -11.499999999999819, 3.1999999999999615, 20.000000000000014, 13.699999999999964, -36.699999999999775, 12.199999999999966, 7.399999999999965, 37.10000000000025, -184.00000000000057, 20.000000000000014, 23.600000000000065, 3.1999999999999615, -106.0000000000008, 15.799999999999963, 7.399999999999965, 7.099999999999966, 7.399999999999965, -3.099999999999958, -26.199999999999747, 5.299999999999965, 17.899999999999984, 20.000000000000014, -45.09999999999976, 20.000000000000014, -72.40000000000086, 21.800000000000047, -26.4999999999998, 5.299999999999965, 9.499999999999964, -3.099999999999958, -1.599999999999985, 20.000000000000014, 9.499999999999964, -57.700000000000365, -6.099999999999952, 13.699999999999967, -30.39999999999975, 20.000000000000014, 20.000000000000014, -9.399999999999855, -24.099999999999746, 20.000000000000014, -45.09999999999976, 73.09999999999955, 7.399999999999965, 20.000000000000014, 9.499999999999964, 20.000000000000014, -53.199999999999804, 20.000000000000014, -59.80000000000051, 20.000000000000014, 9.499999999999964, 17.899999999999984, 9.499999999999964, 17.899999999999988, -45.09999999999976, 20.000000000000014, -101.80000000000081, 7.399999999999965], "policy_predator_policy_reward": [11.0, 36.0, 35.0, 74.0, 0.0, 2.0, 70.0, 93.0, 16.0, 5.0, 47.0, 60.0, 40.0, 45.0, 4.0, 9.0, 24.0, 61.0, 39.0, 30.0, 11.0, 2.0, 35.0, 6.0, 10.0, 30.0, 11.0, 23.0, 11.0, 4.0, 4.0, 4.0, 28.0, 5.0, 4.0, 3.0, 3.0, 18.0, 121.0, 75.0, 108.0, 0.0, 32.0, 59.0, 58.0, 5.0, 38.0, 49.0, 39.0, 6.0, 42.0, 7.0, 42.0, 39.0, 39.0, 23.0, 22.0, 37.0, 43.0, 68.0, 28.0, 10.0, 1.0, 0.0, 4.0, 7.0, 0.0, 11.0, 24.0, 10.0, 34.0, 36.0, 5.0, 3.0, 12.0, 23.0, 16.0, 19.0, 40.0, 37.0, 10.0, 24.0, 43.0, 38.0, 61.0, 34.0, 19.0, 24.0, 8.0, 8.0, 8.0, 1.0, 44.0, 38.0, 14.0, 48.0, 4.0, 21.0, 12.0, 0.0, 8.0, 31.0, 5.0, 12.0, 10.0, 17.0, 14.0, 3.0, 20.0, 21.0, 12.0, 12.0, 60.0, 84.0, 52.0, 0.0, 11.0, 18.0, 0.0, 35.0, 30.0, 2.0, 18.0, 20.0, 10.0, 18.0, 5.0, 25.0, 21.0, 11.0, 48.0, 22.0, 54.0, 50.0, 10.0, 13.0, 2.0, 6.0, 3.0, 2.0, 8.0, 15.0, 0.0, 3.0, 27.0, 18.0, 6.0, 0.0, 97.0, 54.0, 6.0, 2.0, 38.0, 60.0, 6.0, 7.0, 11.0, 9.0, 22.0, 7.0, 4.0, 7.0, 31.0, 4.0, 38.0, 25.0, 17.0, 25.0, 5.0, 11.0, 8.0, 8.0, 37.0, 5.0, 13.0, 18.0, 24.0, 3.0, 14.0, 0.0, 18.0, 12.0, 28.0, 31.0, 6.0, 0.0, 5.0, 0.0, 17.0, 26.0, 4.0, 38.0, 6.0, 2.0, 5.0, 1.0, 20.0, 15.0, 54.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5294752671395588, "mean_inference_ms": 1.3640868872455736, "mean_action_processing_ms": 0.22596012698922174, "mean_env_wait_ms": 0.1727724569900778, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005196809768676758, "StateBufferConnector_ms": 0.0028017759323120117, "ViewRequirementAgentConnector_ms": 0.0835886001586914}, "num_episodes": 18, "episode_return_max": 86.9999999999988, "episode_return_min": -143.7000000000015, "episode_return_mean": 10.463000000000088, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 455.12486461315046, "num_env_steps_trained_throughput_per_sec": 455.12486461315046, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 9047.649, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9047.611, "sample_time_ms": 1007.399, "learn_time_ms": 8028.23, "learn_throughput": 498.242, "synch_weights_time_ms": 11.215}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-39-41", "timestamp": 1723646381, "time_this_iter_s": 8.7917799949646, "time_total_s": 899.9442086219788, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1f8670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 899.9442086219788, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 26.38333333333333, "ram_util_percent": 79.50833333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8373861659140813, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 1.092380465720854, "policy_loss": -0.013413132254832557, "vf_loss": 1.1051071397211185, "vf_explained_var": -0.8190084836470387, "kl": 0.006101828098411245, "entropy": 1.0807230631510416, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9595348630948042, "cur_kl_coeff": 0.003125, "cur_lr": 0.00010000000000000003, "total_loss": 1.2571090150762487, "policy_loss": -0.00470914888939766, "vf_loss": 1.261804847237925, "vf_explained_var": 0.04483527263636312, "kl": 0.004260239244513809, "entropy": 0.21255971731016876, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 145.19999999999922, "episode_reward_min": -143.7000000000015, "episode_reward_mean": 17.871000000000105, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -228.10000000000034, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999955, "predator_policy": 115.0}, "policy_reward_mean": {"prey_policy": -11.249500000000035, "predator_policy": 20.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.200000000000266, -2.299999999999751, 15.200000000000005, -12.199999999999603, -23.699999999999527, 12.299999999999981, 9.400000000000126, 52.50000000000045, 36.80000000000025, 27.900000000000105, 27.90000000000011, 14.30000000000001, -11.79999999999959, 37.50000000000026, 24.600000000000055, 60.60000000000039, 25.800000000000082, 2.6000000000001906, 37.600000000000264, -62.700000000001374, 28.70000000000014, 22.40000000000001, 30.100000000000147, -33.39999999999955, -26.39999999999953, 13.40000000000003, 27.700000000000124, -44.90000000000058, 28.50000000000012, 10.300000000000066, 21.299999999999997, 11.699999999999969, 59.20000000000048, -22.399999999999594, -21.399999999999544, 31.200000000000173, 3.300000000000163, -9.899999999999604, 10.800000000000079, 9.199999999999953, 17.499999999999936, 16.500000000000167, -32.79999999999953, -143.7000000000015, 14.699999999999994, 31.200000000000163, 35.40000000000023, 14.700000000000022, 36.70000000000025, 20.49999999999999, 50.50000000000048, -12.999999999999671, 34.800000000000225, 7.800000000000004, 27.5000000000001, 24.300000000000043, 8.100000000000131, 48.90000000000045, 9.90000000000006, 12.399999999999917, 20.80000000000001, 22.40000000000001, 34.40000000000022, -6.199999999999681, 38.60000000000028, 16.599999999999923, 24.60000000000005, 25.900000000000098, 86.9999999999988, 33.400000000000205, 34.50000000000022, 9.799999999999947, 2.2000000000001796, 35.40000000000023, 33.4000000000002, 9.900000000000047, 13.599999999999977, 6.999999999999979, 23.50000000000003, 12.500000000000055, 55.200000000000514, 24.50000000000005, -41.699999999999655, 145.19999999999922, 35.30000000000023, -52.600000000000804, 69.70000000000003, -1.1999999999997857, 34.100000000000215, 47.200000000000394, 27.90000000000011, 58.200000000000486, 37.30000000000026, 38.300000000000274, 11.400000000000077, 36.00000000000024, 10.400000000000073, 36.40000000000025, 14.700000000000015, 42.700000000000365], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-64.30000000000084, 12.499999999999966, 13.699999999999964, -61.00000000000061, -47.19999999999976, 13.399999999999975, -48.099999999999774, -45.09999999999976, -61.900000000000766, -23.799999999999756, -67.30000000000054, 20.600000000000023, 9.499999999999964, -111.10000000000053, -38.799999999999756, 53.300000000000225, 17.899999999999988, 17.899999999999988, 11.599999999999964, 5.299999999999965, -3.099999999999958, 20.000000000000014, -24.99999999999976, 5.299999999999965, -13.599999999999783, -68.2000000000009, 9.499999999999964, 20.000000000000014, 7.399999999999965, -17.79999999999977, 16.699999999999967, 8.899999999999988, -60.70000000000062, 9.499999999999966, -49.299999999999876, 17.899999999999988, -50.799999999999926, 7.399999999999965, -49.59999999999977, -108.10000000000079, 20.000000000000014, -34.29999999999976, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, 3.1999999999999615, -85.00000000000085, -30.39999999999975, -79.0000000000008, -9.399999999999858, 17.899999999999988, -29.49999999999975, 5.299999999999965, 10.399999999999977, -38.799999999999756, -45.09999999999976, 9.499999999999964, 1.9999999999999607, -15.699999999999768, -0.9999999999999881, -9.399999999999855, 13.699999999999964, -21.999999999999744, -7.29999999999994, 42.500000000000234, -7.299999999999891, -78.70000000000087, -87.69999999999999, 9.49999999999998, -82.90000000000086, -17.79999999999974, 20.000000000000014, -53.50000000000016, 21.80000000000004, -40.89999999999976, -0.9999999999999917, -21.999999999999744, -5.1999999999999265, 3.1999999999999615, -21.99999999999983, 20.000000000000014, -32.49999999999977, -24.099999999999746, 8.600000000000065, -80.80000000000086, -21.999999999999744, -66.10000000000078, -181.60000000000053, -24.099999999999746, 15.799999999999963, 13.699999999999964, 9.499999999999964, 13.699999999999964, 16.69999999999997, -11.499999999999819, 3.1999999999999615, 20.000000000000014, 13.699999999999964, -36.699999999999775, 12.199999999999966, 7.399999999999965, 37.10000000000025, -184.00000000000057, 20.000000000000014, 23.600000000000065, 3.1999999999999615, -106.0000000000008, 15.799999999999963, 7.399999999999965, 7.099999999999966, 7.399999999999965, -3.099999999999958, -26.199999999999747, 5.299999999999965, 17.899999999999984, 20.000000000000014, -45.09999999999976, 20.000000000000014, -72.40000000000086, 21.800000000000047, -26.4999999999998, 5.299999999999965, 9.499999999999964, -3.099999999999958, -1.599999999999985, 20.000000000000014, 9.499999999999964, -57.700000000000365, -6.099999999999952, 13.699999999999967, -30.39999999999975, 20.000000000000014, 20.000000000000014, -9.399999999999855, -24.099999999999746, 20.000000000000014, -45.09999999999976, 73.09999999999955, 7.399999999999965, 20.000000000000014, 9.499999999999964, 20.000000000000014, -53.199999999999804, 20.000000000000014, -59.80000000000051, 20.000000000000014, 9.499999999999964, 17.899999999999984, 9.499999999999964, 17.899999999999988, -45.09999999999976, 20.000000000000014, -101.80000000000081, 7.399999999999965, -151.00000000000057, 20.000000000000014, 9.499999999999964, -0.9999999999999846, -7.299999999999894, -5.1999999999999265, -19.899999999999743, 37.10000000000026, -11.499999999999819, 20.000000000000014, -228.10000000000034, 13.399999999999965, 20.000000000000014, 72.19999999999982, 20.000000000000014, 5.299999999999965, -71.20000000000084, -96.40000000000077, 42.80000000000021, 17.899999999999988, -19.899999999999743, -34.29999999999979, 20.000000000000014, 1.0999999999999865, -1.0000000000000222, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 39.80000000000025, -7.5999999999999215, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, -13.599999999999783, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -19.899999999999757, -0.6999999999999993, -34.59999999999975, 20.000000000000014, -17.79999999999974, 9.499999999999964, 17.899999999999977, 3.799999999999969], "policy_predator_policy_reward": [38.0, 49.0, 39.0, 6.0, 42.0, 7.0, 42.0, 39.0, 39.0, 23.0, 22.0, 37.0, 43.0, 68.0, 28.0, 10.0, 1.0, 0.0, 4.0, 7.0, 0.0, 11.0, 24.0, 10.0, 34.0, 36.0, 5.0, 3.0, 12.0, 23.0, 16.0, 19.0, 40.0, 37.0, 10.0, 24.0, 43.0, 38.0, 61.0, 34.0, 19.0, 24.0, 8.0, 8.0, 8.0, 1.0, 44.0, 38.0, 14.0, 48.0, 4.0, 21.0, 12.0, 0.0, 8.0, 31.0, 5.0, 12.0, 10.0, 17.0, 14.0, 3.0, 20.0, 21.0, 12.0, 12.0, 60.0, 84.0, 52.0, 0.0, 11.0, 18.0, 0.0, 35.0, 30.0, 2.0, 18.0, 20.0, 10.0, 18.0, 5.0, 25.0, 21.0, 11.0, 48.0, 22.0, 54.0, 50.0, 10.0, 13.0, 2.0, 6.0, 3.0, 2.0, 8.0, 15.0, 0.0, 3.0, 27.0, 18.0, 6.0, 0.0, 97.0, 54.0, 6.0, 2.0, 38.0, 60.0, 6.0, 7.0, 11.0, 9.0, 22.0, 7.0, 4.0, 7.0, 31.0, 4.0, 38.0, 25.0, 17.0, 25.0, 5.0, 11.0, 8.0, 8.0, 37.0, 5.0, 13.0, 18.0, 24.0, 3.0, 14.0, 0.0, 18.0, 12.0, 28.0, 31.0, 6.0, 0.0, 5.0, 0.0, 17.0, 26.0, 4.0, 38.0, 6.0, 2.0, 5.0, 1.0, 20.0, 15.0, 54.0, 54.0, 57.0, 81.0, 10.0, 5.0, 10.0, 15.0, 19.0, 19.0, 1.0, 15.0, 58.0, 115.0, 20.0, 33.0, 7.0, 3.0, 57.0, 58.0, 8.0, 1.0, 19.0, 34.0, 4.0, 9.0, 17.0, 28.0, 0.0, 11.0, 6.0, 20.0, 7.0, 5.0, 6.0, 7.0, 10.0, 16.0, 10.0, 7.0, 19.0, 12.0, 25.0, 26.0, 18.0, 5.0, 12.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5289181695796487, "mean_inference_ms": 1.3626677746384075, "mean_action_processing_ms": 0.22572701414552565, "mean_env_wait_ms": 0.17251554890767365, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047997236251831055, "StateBufferConnector_ms": 0.002730131149291992, "ViewRequirementAgentConnector_ms": 0.08236682415008545}, "num_episodes": 23, "episode_return_max": 145.19999999999922, "episode_return_min": -143.7000000000015, "episode_return_mean": 17.871000000000105, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 450.4984392123057, "num_env_steps_trained_throughput_per_sec": 450.4984392123057, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 9007.622, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9007.584, "sample_time_ms": 1003.085, "learn_time_ms": 7992.493, "learn_throughput": 500.47, "synch_weights_time_ms": 11.227}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-39-50", "timestamp": 1723646390, "time_this_iter_s": 8.881888628005981, "time_total_s": 908.8260972499847, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b0efc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 908.8260972499847, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 27.646153846153844, "ram_util_percent": 79.4923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0359739568971453, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 1.1547582741708509, "policy_loss": -0.019851892643297713, "vf_loss": 1.1735886348145348, "vf_explained_var": -0.5015549837281464, "kl": 0.009080244259396532, "entropy": 1.0697523818444954, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8816303508622305, "cur_kl_coeff": 0.0015625, "cur_lr": 0.00010000000000000003, "total_loss": 1.0986886455583824, "policy_loss": -0.007432636879039584, "vf_loss": 1.1061128670576388, "vf_explained_var": 0.2454891738437471, "kl": 0.00538489651497121, "entropy": 0.25246427831826385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 145.19999999999922, "episode_reward_min": -143.7000000000015, "episode_reward_mean": 19.537000000000102, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -228.10000000000034, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999955, "predator_policy": 115.0}, "policy_reward_mean": {"prey_policy": -8.486500000000008, "predator_policy": 18.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.600000000000264, -62.700000000001374, 28.70000000000014, 22.40000000000001, 30.100000000000147, -33.39999999999955, -26.39999999999953, 13.40000000000003, 27.700000000000124, -44.90000000000058, 28.50000000000012, 10.300000000000066, 21.299999999999997, 11.699999999999969, 59.20000000000048, -22.399999999999594, -21.399999999999544, 31.200000000000173, 3.300000000000163, -9.899999999999604, 10.800000000000079, 9.199999999999953, 17.499999999999936, 16.500000000000167, -32.79999999999953, -143.7000000000015, 14.699999999999994, 31.200000000000163, 35.40000000000023, 14.700000000000022, 36.70000000000025, 20.49999999999999, 50.50000000000048, -12.999999999999671, 34.800000000000225, 7.800000000000004, 27.5000000000001, 24.300000000000043, 8.100000000000131, 48.90000000000045, 9.90000000000006, 12.399999999999917, 20.80000000000001, 22.40000000000001, 34.40000000000022, -6.199999999999681, 38.60000000000028, 16.599999999999923, 24.60000000000005, 25.900000000000098, 86.9999999999988, 33.400000000000205, 34.50000000000022, 9.799999999999947, 2.2000000000001796, 35.40000000000023, 33.4000000000002, 9.900000000000047, 13.599999999999977, 6.999999999999979, 23.50000000000003, 12.500000000000055, 55.200000000000514, 24.50000000000005, -41.699999999999655, 145.19999999999922, 35.30000000000023, -52.600000000000804, 69.70000000000003, -1.1999999999997857, 34.100000000000215, 47.200000000000394, 27.90000000000011, 58.200000000000486, 37.30000000000026, 38.300000000000274, 11.400000000000077, 36.00000000000024, 10.400000000000073, 36.40000000000025, 14.700000000000015, 42.700000000000365, 6.100000000000152, 24.600000000000065, 2.3000000000002294, 36.70000000000025, 68.60000000000015, 34.800000000000225, 10.30000000000007, 29.000000000000124, 44.200000000000365, 37.200000000000266, 10.300000000000088, 4.900000000000171, 18.799999999999986, 25.100000000000062, 38.90000000000028, 34.800000000000225, 62.00000000000032, 10.60000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-50.799999999999926, 7.399999999999965, -49.59999999999977, -108.10000000000079, 20.000000000000014, -34.29999999999976, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, 3.1999999999999615, -85.00000000000085, -30.39999999999975, -79.0000000000008, -9.399999999999858, 17.899999999999988, -29.49999999999975, 5.299999999999965, 10.399999999999977, -38.799999999999756, -45.09999999999976, 9.499999999999964, 1.9999999999999607, -15.699999999999768, -0.9999999999999881, -9.399999999999855, 13.699999999999964, -21.999999999999744, -7.29999999999994, 42.500000000000234, -7.299999999999891, -78.70000000000087, -87.69999999999999, 9.49999999999998, -82.90000000000086, -17.79999999999974, 20.000000000000014, -53.50000000000016, 21.80000000000004, -40.89999999999976, -0.9999999999999917, -21.999999999999744, -5.1999999999999265, 3.1999999999999615, -21.99999999999983, 20.000000000000014, -32.49999999999977, -24.099999999999746, 8.600000000000065, -80.80000000000086, -21.999999999999744, -66.10000000000078, -181.60000000000053, -24.099999999999746, 15.799999999999963, 13.699999999999964, 9.499999999999964, 13.699999999999964, 16.69999999999997, -11.499999999999819, 3.1999999999999615, 20.000000000000014, 13.699999999999964, -36.699999999999775, 12.199999999999966, 7.399999999999965, 37.10000000000025, -184.00000000000057, 20.000000000000014, 23.600000000000065, 3.1999999999999615, -106.0000000000008, 15.799999999999963, 7.399999999999965, 7.099999999999966, 7.399999999999965, -3.099999999999958, -26.199999999999747, 5.299999999999965, 17.899999999999984, 20.000000000000014, -45.09999999999976, 20.000000000000014, -72.40000000000086, 21.800000000000047, -26.4999999999998, 5.299999999999965, 9.499999999999964, -3.099999999999958, -1.599999999999985, 20.000000000000014, 9.499999999999964, -57.700000000000365, -6.099999999999952, 13.699999999999967, -30.39999999999975, 20.000000000000014, 20.000000000000014, -9.399999999999855, -24.099999999999746, 20.000000000000014, -45.09999999999976, 73.09999999999955, 7.399999999999965, 20.000000000000014, 9.499999999999964, 20.000000000000014, -53.199999999999804, 20.000000000000014, -59.80000000000051, 20.000000000000014, 9.499999999999964, 17.899999999999984, 9.499999999999964, 17.899999999999988, -45.09999999999976, 20.000000000000014, -101.80000000000081, 7.399999999999965, -151.00000000000057, 20.000000000000014, 9.499999999999964, -0.9999999999999846, -7.299999999999894, -5.1999999999999265, -19.899999999999743, 37.10000000000026, -11.499999999999819, 20.000000000000014, -228.10000000000034, 13.399999999999965, 20.000000000000014, 72.19999999999982, 20.000000000000014, 5.299999999999965, -71.20000000000084, -96.40000000000077, 42.80000000000021, 17.899999999999988, -19.899999999999743, -34.29999999999979, 20.000000000000014, 1.0999999999999865, -1.0000000000000222, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 39.80000000000025, -7.5999999999999215, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, -13.599999999999783, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -19.899999999999757, -0.6999999999999993, -34.59999999999975, 20.000000000000014, -17.79999999999974, 9.499999999999964, 17.899999999999977, 3.799999999999969, -42.99999999999976, 1.0999999999999865, 9.499999999999977, 1.0999999999999865, -5.1999999999999265, -8.499999999999872, 13.699999999999964, 20.000000000000014, 47.900000000000226, 13.699999999999967, 31.700000000000212, -19.899999999999743, -34.59999999999975, 17.899999999999988, 5.299999999999965, 13.699999999999964, 19.1, 19.1, 13.699999999999964, 9.499999999999979, 5.299999999999965, -21.999999999999744, -30.09999999999976, -0.9999999999999846, -15.699999999999747, 9.499999999999964, 20.000000000000014, -40.89999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, -56.80000000000007, 21.80000000000004, -0.9999999999999846, -30.39999999999975], "policy_predator_policy_reward": [43.0, 38.0, 61.0, 34.0, 19.0, 24.0, 8.0, 8.0, 8.0, 1.0, 44.0, 38.0, 14.0, 48.0, 4.0, 21.0, 12.0, 0.0, 8.0, 31.0, 5.0, 12.0, 10.0, 17.0, 14.0, 3.0, 20.0, 21.0, 12.0, 12.0, 60.0, 84.0, 52.0, 0.0, 11.0, 18.0, 0.0, 35.0, 30.0, 2.0, 18.0, 20.0, 10.0, 18.0, 5.0, 25.0, 21.0, 11.0, 48.0, 22.0, 54.0, 50.0, 10.0, 13.0, 2.0, 6.0, 3.0, 2.0, 8.0, 15.0, 0.0, 3.0, 27.0, 18.0, 6.0, 0.0, 97.0, 54.0, 6.0, 2.0, 38.0, 60.0, 6.0, 7.0, 11.0, 9.0, 22.0, 7.0, 4.0, 7.0, 31.0, 4.0, 38.0, 25.0, 17.0, 25.0, 5.0, 11.0, 8.0, 8.0, 37.0, 5.0, 13.0, 18.0, 24.0, 3.0, 14.0, 0.0, 18.0, 12.0, 28.0, 31.0, 6.0, 0.0, 5.0, 0.0, 17.0, 26.0, 4.0, 38.0, 6.0, 2.0, 5.0, 1.0, 20.0, 15.0, 54.0, 54.0, 57.0, 81.0, 10.0, 5.0, 10.0, 15.0, 19.0, 19.0, 1.0, 15.0, 58.0, 115.0, 20.0, 33.0, 7.0, 3.0, 57.0, 58.0, 8.0, 1.0, 19.0, 34.0, 4.0, 9.0, 17.0, 28.0, 0.0, 11.0, 6.0, 20.0, 7.0, 5.0, 6.0, 7.0, 10.0, 16.0, 10.0, 7.0, 19.0, 12.0, 25.0, 26.0, 18.0, 5.0, 12.0, 9.0, 30.0, 18.0, 9.0, 5.0, 15.0, 1.0, 0.0, 3.0, 3.0, 4.0, 19.0, 4.0, 26.0, 1.0, 7.0, 3.0, 3.0, 3.0, 4.0, 10.0, 20.0, 7.0, 26.0, 10.0, 8.0, 17.0, 17.0, 29.0, 1.0, 0.0, 8.0, 12.0, 48.0, 49.0, 19.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5285147305124994, "mean_inference_ms": 1.36159015556808, "mean_action_processing_ms": 0.22554575106677055, "mean_env_wait_ms": 0.17231870041039898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004412531852722168, "StateBufferConnector_ms": 0.0027472972869873047, "ViewRequirementAgentConnector_ms": 0.08572900295257568}, "num_episodes": 18, "episode_return_max": 145.19999999999922, "episode_return_min": -143.7000000000015, "episode_return_mean": 19.537000000000102, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 451.65287425151956, "num_env_steps_trained_throughput_per_sec": 451.65287425151956, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 8975.018, "restore_workers_time_ms": 0.014, "training_step_time_ms": 8974.979, "sample_time_ms": 1001.62, "learn_time_ms": 7961.549, "learn_throughput": 502.415, "synch_weights_time_ms": 11.034}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-39-58", "timestamp": 1723646398, "time_this_iter_s": 8.859695196151733, "time_total_s": 917.6857924461365, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b156c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 917.6857924461365, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 27.25, "ram_util_percent": 79.50833333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0150337082052987, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 0.8518912917525364, "policy_loss": -0.008865667638373832, "vf_loss": 0.8599178841938733, "vf_explained_var": 0.020497544890358335, "kl": 0.007458443234948697, "entropy": 1.098605016173509, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8259796828504593, "cur_kl_coeff": 0.0015625, "cur_lr": 0.00010000000000000003, "total_loss": 0.8587354538932679, "policy_loss": -0.01995128669045193, "vf_loss": 0.8786456535102198, "vf_explained_var": 0.20089074004264104, "kl": 0.026297186800077997, "entropy": 0.35633761008422843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 145.19999999999922, "episode_reward_min": -143.7000000000015, "episode_reward_mean": 23.27500000000012, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -228.10000000000034, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999955, "predator_policy": 115.0}, "policy_reward_mean": {"prey_policy": -5.072500000000006, "predator_policy": 16.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.499999999999936, 16.500000000000167, -32.79999999999953, -143.7000000000015, 14.699999999999994, 31.200000000000163, 35.40000000000023, 14.700000000000022, 36.70000000000025, 20.49999999999999, 50.50000000000048, -12.999999999999671, 34.800000000000225, 7.800000000000004, 27.5000000000001, 24.300000000000043, 8.100000000000131, 48.90000000000045, 9.90000000000006, 12.399999999999917, 20.80000000000001, 22.40000000000001, 34.40000000000022, -6.199999999999681, 38.60000000000028, 16.599999999999923, 24.60000000000005, 25.900000000000098, 86.9999999999988, 33.400000000000205, 34.50000000000022, 9.799999999999947, 2.2000000000001796, 35.40000000000023, 33.4000000000002, 9.900000000000047, 13.599999999999977, 6.999999999999979, 23.50000000000003, 12.500000000000055, 55.200000000000514, 24.50000000000005, -41.699999999999655, 145.19999999999922, 35.30000000000023, -52.600000000000804, 69.70000000000003, -1.1999999999997857, 34.100000000000215, 47.200000000000394, 27.90000000000011, 58.200000000000486, 37.30000000000026, 38.300000000000274, 11.400000000000077, 36.00000000000024, 10.400000000000073, 36.40000000000025, 14.700000000000015, 42.700000000000365, 6.100000000000152, 24.600000000000065, 2.3000000000002294, 36.70000000000025, 68.60000000000015, 34.800000000000225, 10.30000000000007, 29.000000000000124, 44.200000000000365, 37.200000000000266, 10.300000000000088, 4.900000000000171, 18.799999999999986, 25.100000000000062, 38.90000000000028, 34.800000000000225, 62.00000000000032, 10.60000000000008, -19.59999999999951, 35.600000000000236, 52.200000000000365, 40.0000000000003, -25.999999999999538, 14.599999999999987, 30.300000000000164, 58.80000000000049, 37.000000000000256, -0.7000000000000773, -65.50000000000153, 33.1000000000002, -6.899999999999714, 27.900000000000105, 11.700000000000069, 31.20000000000017, 38.300000000000274, 35.90000000000024, 65.1000000000003, 29.100000000000147, 32.0000000000001, 44.00000000000038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -32.49999999999977, -24.099999999999746, 8.600000000000065, -80.80000000000086, -21.999999999999744, -66.10000000000078, -181.60000000000053, -24.099999999999746, 15.799999999999963, 13.699999999999964, 9.499999999999964, 13.699999999999964, 16.69999999999997, -11.499999999999819, 3.1999999999999615, 20.000000000000014, 13.699999999999964, -36.699999999999775, 12.199999999999966, 7.399999999999965, 37.10000000000025, -184.00000000000057, 20.000000000000014, 23.600000000000065, 3.1999999999999615, -106.0000000000008, 15.799999999999963, 7.399999999999965, 7.099999999999966, 7.399999999999965, -3.099999999999958, -26.199999999999747, 5.299999999999965, 17.899999999999984, 20.000000000000014, -45.09999999999976, 20.000000000000014, -72.40000000000086, 21.800000000000047, -26.4999999999998, 5.299999999999965, 9.499999999999964, -3.099999999999958, -1.599999999999985, 20.000000000000014, 9.499999999999964, -57.700000000000365, -6.099999999999952, 13.699999999999967, -30.39999999999975, 20.000000000000014, 20.000000000000014, -9.399999999999855, -24.099999999999746, 20.000000000000014, -45.09999999999976, 73.09999999999955, 7.399999999999965, 20.000000000000014, 9.499999999999964, 20.000000000000014, -53.199999999999804, 20.000000000000014, -59.80000000000051, 20.000000000000014, 9.499999999999964, 17.899999999999984, 9.499999999999964, 17.899999999999988, -45.09999999999976, 20.000000000000014, -101.80000000000081, 7.399999999999965, -151.00000000000057, 20.000000000000014, 9.499999999999964, -0.9999999999999846, -7.299999999999894, -5.1999999999999265, -19.899999999999743, 37.10000000000026, -11.499999999999819, 20.000000000000014, -228.10000000000034, 13.399999999999965, 20.000000000000014, 72.19999999999982, 20.000000000000014, 5.299999999999965, -71.20000000000084, -96.40000000000077, 42.80000000000021, 17.899999999999988, -19.899999999999743, -34.29999999999979, 20.000000000000014, 1.0999999999999865, -1.0000000000000222, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 39.80000000000025, -7.5999999999999215, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, -13.599999999999783, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -19.899999999999757, -0.6999999999999993, -34.59999999999975, 20.000000000000014, -17.79999999999974, 9.499999999999964, 17.899999999999977, 3.799999999999969, -42.99999999999976, 1.0999999999999865, 9.499999999999977, 1.0999999999999865, -5.1999999999999265, -8.499999999999872, 13.699999999999964, 20.000000000000014, 47.900000000000226, 13.699999999999967, 31.700000000000212, -19.899999999999743, -34.59999999999975, 17.899999999999988, 5.299999999999965, 13.699999999999964, 19.1, 19.1, 13.699999999999964, 9.499999999999979, 5.299999999999965, -21.999999999999744, -30.09999999999976, -0.9999999999999846, -15.699999999999747, 9.499999999999964, 20.000000000000014, -40.89999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, -56.80000000000007, 21.80000000000004, -0.9999999999999846, -30.39999999999975, -21.999999999999744, -52.60000000000012, 20.000000000000014, 11.599999999999964, 20.000000000000014, 9.200000000000042, 20.000000000000014, 20.000000000000014, 11.599999999999964, -97.60000000000076, -30.39999999999975, 20.000000000000014, -36.699999999999754, 20.000000000000014, 20.000000000000014, 33.80000000000023, -0.9999999999999846, 20.000000000000014, -55.59999999999977, 17.899999999999988, -110.20000000000076, -49.29999999999976, 24.50000000000008, -9.399999999999855, -82.90000000000082, 20.000000000000014, 13.699999999999964, 3.1999999999999615, 3.1999999999999615, -11.499999999999826, 15.799999999999963, 7.399999999999965, 20.000000000000014, 5.299999999999965, 20.000000000000014, 8.899999999999967, 17.899999999999988, 9.199999999999987, -19.299999999999763, 25.400000000000098, 1.9999999999999547, -42.9999999999998, 26.30000000000012, 13.699999999999964], "policy_predator_policy_reward": [5.0, 25.0, 21.0, 11.0, 48.0, 22.0, 54.0, 50.0, 10.0, 13.0, 2.0, 6.0, 3.0, 2.0, 8.0, 15.0, 0.0, 3.0, 27.0, 18.0, 6.0, 0.0, 97.0, 54.0, 6.0, 2.0, 38.0, 60.0, 6.0, 7.0, 11.0, 9.0, 22.0, 7.0, 4.0, 7.0, 31.0, 4.0, 38.0, 25.0, 17.0, 25.0, 5.0, 11.0, 8.0, 8.0, 37.0, 5.0, 13.0, 18.0, 24.0, 3.0, 14.0, 0.0, 18.0, 12.0, 28.0, 31.0, 6.0, 0.0, 5.0, 0.0, 17.0, 26.0, 4.0, 38.0, 6.0, 2.0, 5.0, 1.0, 20.0, 15.0, 54.0, 54.0, 57.0, 81.0, 10.0, 5.0, 10.0, 15.0, 19.0, 19.0, 1.0, 15.0, 58.0, 115.0, 20.0, 33.0, 7.0, 3.0, 57.0, 58.0, 8.0, 1.0, 19.0, 34.0, 4.0, 9.0, 17.0, 28.0, 0.0, 11.0, 6.0, 20.0, 7.0, 5.0, 6.0, 7.0, 10.0, 16.0, 10.0, 7.0, 19.0, 12.0, 25.0, 26.0, 18.0, 5.0, 12.0, 9.0, 30.0, 18.0, 9.0, 5.0, 15.0, 1.0, 0.0, 3.0, 3.0, 4.0, 19.0, 4.0, 26.0, 1.0, 7.0, 3.0, 3.0, 3.0, 4.0, 10.0, 20.0, 7.0, 26.0, 10.0, 8.0, 17.0, 17.0, 29.0, 1.0, 0.0, 8.0, 12.0, 48.0, 49.0, 19.0, 23.0, 35.0, 20.0, 4.0, 0.0, 8.0, 15.0, 0.0, 0.0, 56.0, 4.0, 18.0, 7.0, 27.0, 20.0, 3.0, 2.0, 8.0, 10.0, 36.0, 1.0, 30.0, 64.0, 14.0, 4.0, 30.0, 26.0, 3.0, 8.0, 1.0, 19.0, 5.0, 3.0, 6.0, 7.0, 0.0, 7.0, 15.0, 23.0, 23.0, 0.0, 30.0, 43.0, 1.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5279339998476711, "mean_inference_ms": 1.361626938912066, "mean_action_processing_ms": 0.2251589622996958, "mean_env_wait_ms": 0.17198810025127464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00394129753112793, "StateBufferConnector_ms": 0.0027294158935546875, "ViewRequirementAgentConnector_ms": 0.08409273624420166}, "num_episodes": 22, "episode_return_max": 145.19999999999922, "episode_return_min": -143.7000000000015, "episode_return_mean": 23.27500000000012, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 437.71262784021013, "num_env_steps_trained_throughput_per_sec": 437.71262784021013, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 8976.95, "restore_workers_time_ms": 0.014, "training_step_time_ms": 8976.911, "sample_time_ms": 1009.778, "learn_time_ms": 7955.308, "learn_throughput": 502.809, "synch_weights_time_ms": 11.082}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-40-08", "timestamp": 1723646408, "time_this_iter_s": 9.142131805419922, "time_total_s": 926.8279242515564, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1f8ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 926.8279242515564, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 26.315384615384616, "ram_util_percent": 79.46153846153847}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5576139117044117, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 2.2303850999269534, "policy_loss": -0.012405912006870108, "vf_loss": 2.2414395509888885, "vf_explained_var": -0.04621460071947209, "kl": 0.012012954648973275, "entropy": 1.031974315737921, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.235870399550786, "cur_kl_coeff": 0.0023437499999999995, "cur_lr": 0.00010000000000000003, "total_loss": 1.8388407910311664, "policy_loss": -0.01000177081706367, "vf_loss": 1.8488083659341095, "vf_explained_var": 0.196128331290351, "kl": 0.0145901626292834, "entropy": 0.3634220959017516, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 145.19999999999922, "episode_reward_min": -310.3999999999978, "episode_reward_mean": 22.070000000000128, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -305.499999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999955, "predator_policy": 171.0}, "policy_reward_mean": {"prey_policy": -6.114999999999984, "predator_policy": 17.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.90000000000006, 12.399999999999917, 20.80000000000001, 22.40000000000001, 34.40000000000022, -6.199999999999681, 38.60000000000028, 16.599999999999923, 24.60000000000005, 25.900000000000098, 86.9999999999988, 33.400000000000205, 34.50000000000022, 9.799999999999947, 2.2000000000001796, 35.40000000000023, 33.4000000000002, 9.900000000000047, 13.599999999999977, 6.999999999999979, 23.50000000000003, 12.500000000000055, 55.200000000000514, 24.50000000000005, -41.699999999999655, 145.19999999999922, 35.30000000000023, -52.600000000000804, 69.70000000000003, -1.1999999999997857, 34.100000000000215, 47.200000000000394, 27.90000000000011, 58.200000000000486, 37.30000000000026, 38.300000000000274, 11.400000000000077, 36.00000000000024, 10.400000000000073, 36.40000000000025, 14.700000000000015, 42.700000000000365, 6.100000000000152, 24.600000000000065, 2.3000000000002294, 36.70000000000025, 68.60000000000015, 34.800000000000225, 10.30000000000007, 29.000000000000124, 44.200000000000365, 37.200000000000266, 10.300000000000088, 4.900000000000171, 18.799999999999986, 25.100000000000062, 38.90000000000028, 34.800000000000225, 62.00000000000032, 10.60000000000008, -19.59999999999951, 35.600000000000236, 52.200000000000365, 40.0000000000003, -25.999999999999538, 14.599999999999987, 30.300000000000164, 58.80000000000049, 37.000000000000256, -0.7000000000000773, -65.50000000000153, 33.1000000000002, -6.899999999999714, 27.900000000000105, 11.700000000000069, 31.20000000000017, 38.300000000000274, 35.90000000000024, 65.1000000000003, 29.100000000000147, 32.0000000000001, 44.00000000000038, 34.00000000000021, 21.90000000000001, 38.60000000000028, -4.599999999999758, 43.10000000000036, 75.19999999999969, -2.399999999999943, -310.3999999999978, 15.599999999999977, 52.80000000000038, 23.400000000000027, 37.000000000000256, 63.1000000000005, 17.99999999999998, 9.90000000000006, -75.40000000000114, 14.700000000000015, 24.60000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-45.09999999999976, 20.000000000000014, -72.40000000000086, 21.800000000000047, -26.4999999999998, 5.299999999999965, 9.499999999999964, -3.099999999999958, -1.599999999999985, 20.000000000000014, 9.499999999999964, -57.700000000000365, -6.099999999999952, 13.699999999999967, -30.39999999999975, 20.000000000000014, 20.000000000000014, -9.399999999999855, -24.099999999999746, 20.000000000000014, -45.09999999999976, 73.09999999999955, 7.399999999999965, 20.000000000000014, 9.499999999999964, 20.000000000000014, -53.199999999999804, 20.000000000000014, -59.80000000000051, 20.000000000000014, 9.499999999999964, 17.899999999999984, 9.499999999999964, 17.899999999999988, -45.09999999999976, 20.000000000000014, -101.80000000000081, 7.399999999999965, -151.00000000000057, 20.000000000000014, 9.499999999999964, -0.9999999999999846, -7.299999999999894, -5.1999999999999265, -19.899999999999743, 37.10000000000026, -11.499999999999819, 20.000000000000014, -228.10000000000034, 13.399999999999965, 20.000000000000014, 72.19999999999982, 20.000000000000014, 5.299999999999965, -71.20000000000084, -96.40000000000077, 42.80000000000021, 17.899999999999988, -19.899999999999743, -34.29999999999979, 20.000000000000014, 1.0999999999999865, -1.0000000000000222, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 39.80000000000025, -7.5999999999999215, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, -13.599999999999783, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -19.899999999999757, -0.6999999999999993, -34.59999999999975, 20.000000000000014, -17.79999999999974, 9.499999999999964, 17.899999999999977, 3.799999999999969, -42.99999999999976, 1.0999999999999865, 9.499999999999977, 1.0999999999999865, -5.1999999999999265, -8.499999999999872, 13.699999999999964, 20.000000000000014, 47.900000000000226, 13.699999999999967, 31.700000000000212, -19.899999999999743, -34.59999999999975, 17.899999999999988, 5.299999999999965, 13.699999999999964, 19.1, 19.1, 13.699999999999964, 9.499999999999979, 5.299999999999965, -21.999999999999744, -30.09999999999976, -0.9999999999999846, -15.699999999999747, 9.499999999999964, 20.000000000000014, -40.89999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, -56.80000000000007, 21.80000000000004, -0.9999999999999846, -30.39999999999975, -21.999999999999744, -52.60000000000012, 20.000000000000014, 11.599999999999964, 20.000000000000014, 9.200000000000042, 20.000000000000014, 20.000000000000014, 11.599999999999964, -97.60000000000076, -30.39999999999975, 20.000000000000014, -36.699999999999754, 20.000000000000014, 20.000000000000014, 33.80000000000023, -0.9999999999999846, 20.000000000000014, -55.59999999999977, 17.899999999999988, -110.20000000000076, -49.29999999999976, 24.50000000000008, -9.399999999999855, -82.90000000000082, 20.000000000000014, 13.699999999999964, 3.1999999999999615, 3.1999999999999615, -11.499999999999826, 15.799999999999963, 7.399999999999965, 20.000000000000014, 5.299999999999965, 20.000000000000014, 8.899999999999967, 17.899999999999988, 9.199999999999987, -19.299999999999763, 25.400000000000098, 1.9999999999999547, -42.9999999999998, 26.30000000000012, 13.699999999999964, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, -7.299999999999905, 1.0999999999999865, 24.50000000000008, -26.799999999999798, -38.799999999999756, 4.09999999999998, -0.9999999999999846, 66.19999999999987, -21.999999999999794, -63.40000000000053, 20.000000000000014, -305.499999999999, -187.9000000000003, 18.799999999999997, -26.199999999999747, -34.59999999999975, 34.400000000000176, 5.299999999999965, 1.0999999999999865, -21.999999999999787, 7.999999999999966, 13.999999999999966, 43.10000000000024, 1.099999999999983, -45.09999999999976, -45.09999999999976, 20.000000000000014, -95.50000000000054, -52.89999999999982, -3.099999999999965, -5.1999999999999265, -9.399999999999855, 20.000000000000014], "policy_predator_policy_reward": [31.0, 4.0, 38.0, 25.0, 17.0, 25.0, 5.0, 11.0, 8.0, 8.0, 37.0, 5.0, 13.0, 18.0, 24.0, 3.0, 14.0, 0.0, 18.0, 12.0, 28.0, 31.0, 6.0, 0.0, 5.0, 0.0, 17.0, 26.0, 4.0, 38.0, 6.0, 2.0, 5.0, 1.0, 20.0, 15.0, 54.0, 54.0, 57.0, 81.0, 10.0, 5.0, 10.0, 15.0, 19.0, 19.0, 1.0, 15.0, 58.0, 115.0, 20.0, 33.0, 7.0, 3.0, 57.0, 58.0, 8.0, 1.0, 19.0, 34.0, 4.0, 9.0, 17.0, 28.0, 0.0, 11.0, 6.0, 20.0, 7.0, 5.0, 6.0, 7.0, 10.0, 16.0, 10.0, 7.0, 19.0, 12.0, 25.0, 26.0, 18.0, 5.0, 12.0, 9.0, 30.0, 18.0, 9.0, 5.0, 15.0, 1.0, 0.0, 3.0, 3.0, 4.0, 19.0, 4.0, 26.0, 1.0, 7.0, 3.0, 3.0, 3.0, 4.0, 10.0, 20.0, 7.0, 26.0, 10.0, 8.0, 17.0, 17.0, 29.0, 1.0, 0.0, 8.0, 12.0, 48.0, 49.0, 19.0, 23.0, 35.0, 20.0, 4.0, 0.0, 8.0, 15.0, 0.0, 0.0, 56.0, 4.0, 18.0, 7.0, 27.0, 20.0, 3.0, 2.0, 8.0, 10.0, 36.0, 1.0, 30.0, 64.0, 14.0, 4.0, 30.0, 26.0, 3.0, 8.0, 1.0, 19.0, 5.0, 3.0, 6.0, 7.0, 0.0, 7.0, 15.0, 23.0, 23.0, 0.0, 30.0, 43.0, 1.0, 3.0, 10.0, 5.0, 7.0, 19.0, 4.0, 9.0, 33.0, 28.0, 27.0, 13.0, 11.0, 20.0, 0.0, 41.0, 171.0, 12.0, 1.0, 22.0, 25.0, 28.0, 8.0, 9.0, 27.0, 24.0, 5.0, 1.0, 31.0, 31.0, 4.0, 31.0, 8.0, 65.0, 12.0, 11.0, 14.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5277207026229437, "mean_inference_ms": 1.359467433506813, "mean_action_processing_ms": 0.225176945274258, "mean_env_wait_ms": 0.1719088615640039, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035581588745117188, "StateBufferConnector_ms": 0.0028401613235473633, "ViewRequirementAgentConnector_ms": 0.08479654788970947}, "num_episodes": 18, "episode_return_max": 145.19999999999922, "episode_return_min": -310.3999999999978, "episode_return_mean": 22.070000000000128, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 429.42141526743046, "num_env_steps_trained_throughput_per_sec": 429.42141526743046, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 9003.286, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9003.247, "sample_time_ms": 1012.18, "learn_time_ms": 7979.056, "learn_throughput": 501.312, "synch_weights_time_ms": 11.271}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-40-17", "timestamp": 1723646417, "time_this_iter_s": 9.318780183792114, "time_total_s": 936.1467044353485, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1be670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 936.1467044353485, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 29.72142857142857, "ram_util_percent": 79.15}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6125133870455324, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 0.00010000000000000003, "total_loss": 3.0455369222731816, "policy_loss": -0.0057963003143273965, "vf_loss": 3.0503321845695455, "vf_explained_var": 0.011163088695082084, "kl": 0.008898086991240022, "entropy": 0.9990174177147093, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.682079591637566, "cur_kl_coeff": 0.0023437499999999995, "cur_lr": 0.00010000000000000003, "total_loss": 1.929964925467022, "policy_loss": -0.006369936453405196, "vf_loss": 1.9363043599343173, "vf_explained_var": 0.12588871175019198, "kl": 0.013013672054246314, "entropy": 0.40477870814699346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 145.19999999999922, "episode_reward_min": -424.3, "episode_reward_mean": 7.222000000000167, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -311.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.19999999999982, "predator_policy": 171.0}, "policy_reward_mean": {"prey_policy": -14.943999999999981, "predator_policy": 18.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.50000000000005, -41.699999999999655, 145.19999999999922, 35.30000000000023, -52.600000000000804, 69.70000000000003, -1.1999999999997857, 34.100000000000215, 47.200000000000394, 27.90000000000011, 58.200000000000486, 37.30000000000026, 38.300000000000274, 11.400000000000077, 36.00000000000024, 10.400000000000073, 36.40000000000025, 14.700000000000015, 42.700000000000365, 6.100000000000152, 24.600000000000065, 2.3000000000002294, 36.70000000000025, 68.60000000000015, 34.800000000000225, 10.30000000000007, 29.000000000000124, 44.200000000000365, 37.200000000000266, 10.300000000000088, 4.900000000000171, 18.799999999999986, 25.100000000000062, 38.90000000000028, 34.800000000000225, 62.00000000000032, 10.60000000000008, -19.59999999999951, 35.600000000000236, 52.200000000000365, 40.0000000000003, -25.999999999999538, 14.599999999999987, 30.300000000000164, 58.80000000000049, 37.000000000000256, -0.7000000000000773, -65.50000000000153, 33.1000000000002, -6.899999999999714, 27.900000000000105, 11.700000000000069, 31.20000000000017, 38.300000000000274, 35.90000000000024, 65.1000000000003, 29.100000000000147, 32.0000000000001, 44.00000000000038, 34.00000000000021, 21.90000000000001, 38.60000000000028, -4.599999999999758, 43.10000000000036, 75.19999999999969, -2.399999999999943, -310.3999999999978, 15.599999999999977, 52.80000000000038, 23.400000000000027, 37.000000000000256, 63.1000000000005, 17.99999999999998, 9.90000000000006, -75.40000000000114, 14.700000000000015, 24.60000000000005, 34.30000000000022, 53.200000000000514, 36.300000000000026, -30.39999999999951, 24.600000000000062, 28.00000000000011, -272.09999999999843, -51.60000000000085, -39.099999999999646, -158.39999999999998, 23.70000000000006, 39.50000000000029, 3.7000000000000512, -424.3, -13.599999999999527, 33.80000000000021, 30.100000000000158, 19.09999999999996, 24.400000000000055, -319.09999999999945, -17.399999999999523, 37.700000000000266, 9.600000000000131], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.499999999999819, 20.000000000000014, -228.10000000000034, 13.399999999999965, 20.000000000000014, 72.19999999999982, 20.000000000000014, 5.299999999999965, -71.20000000000084, -96.40000000000077, 42.80000000000021, 17.899999999999988, -19.899999999999743, -34.29999999999979, 20.000000000000014, 1.0999999999999865, -1.0000000000000222, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 39.80000000000025, -7.5999999999999215, 5.299999999999965, 20.000000000000014, 20.000000000000014, 5.299999999999965, -13.599999999999783, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -19.899999999999757, -0.6999999999999993, -34.59999999999975, 20.000000000000014, -17.79999999999974, 9.499999999999964, 17.899999999999977, 3.799999999999969, -42.99999999999976, 1.0999999999999865, 9.499999999999977, 1.0999999999999865, -5.1999999999999265, -8.499999999999872, 13.699999999999964, 20.000000000000014, 47.900000000000226, 13.699999999999967, 31.700000000000212, -19.899999999999743, -34.59999999999975, 17.899999999999988, 5.299999999999965, 13.699999999999964, 19.1, 19.1, 13.699999999999964, 9.499999999999979, 5.299999999999965, -21.999999999999744, -30.09999999999976, -0.9999999999999846, -15.699999999999747, 9.499999999999964, 20.000000000000014, -40.89999999999976, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, -56.80000000000007, 21.80000000000004, -0.9999999999999846, -30.39999999999975, -21.999999999999744, -52.60000000000012, 20.000000000000014, 11.599999999999964, 20.000000000000014, 9.200000000000042, 20.000000000000014, 20.000000000000014, 11.599999999999964, -97.60000000000076, -30.39999999999975, 20.000000000000014, -36.699999999999754, 20.000000000000014, 20.000000000000014, 33.80000000000023, -0.9999999999999846, 20.000000000000014, -55.59999999999977, 17.899999999999988, -110.20000000000076, -49.29999999999976, 24.50000000000008, -9.399999999999855, -82.90000000000082, 20.000000000000014, 13.699999999999964, 3.1999999999999615, 3.1999999999999615, -11.499999999999826, 15.799999999999963, 7.399999999999965, 20.000000000000014, 5.299999999999965, 20.000000000000014, 8.899999999999967, 17.899999999999988, 9.199999999999987, -19.299999999999763, 25.400000000000098, 1.9999999999999547, -42.9999999999998, 26.30000000000012, 13.699999999999964, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, -7.299999999999905, 1.0999999999999865, 24.50000000000008, -26.799999999999798, -38.799999999999756, 4.09999999999998, -0.9999999999999846, 66.19999999999987, -21.999999999999794, -63.40000000000053, 20.000000000000014, -305.499999999999, -187.9000000000003, 18.799999999999997, -26.199999999999747, -34.59999999999975, 34.400000000000176, 5.299999999999965, 1.0999999999999865, -21.999999999999787, 7.999999999999966, 13.999999999999966, 43.10000000000024, 1.099999999999983, -45.09999999999976, -45.09999999999976, 20.000000000000014, -95.50000000000054, -52.89999999999982, -3.099999999999965, -5.1999999999999265, -9.399999999999855, 20.000000000000014, 5.299999999999965, 20.000000000000014, 30.200000000000188, 20.000000000000014, 30.19999999999996, -19.89999999999975, -38.799999999999756, -34.59999999999975, 3.1999999999999615, 1.3999999999999726, 17.899999999999984, 1.099999999999983, -225.70000000000024, -219.4000000000005, -65.20000000000087, -30.399999999999785, -19.899999999999743, -89.20000000000041, -103.90000000000003, -200.5, 1.6999999999999729, 4.999999999999977, 9.499999999999964, 20.000000000000014, -19.899999999999803, -9.399999999999855, -311.8, -284.49999999999994, -11.499999999999819, -24.099999999999746, -19.899999999999743, 28.700000000000163, 20.000000000000014, 1.0999999999999563, 15.799999999999963, -15.699999999999761, 20.000000000000014, -13.599999999999797, -211.0, -234.09999999999997, 3.1999999999999615, -97.60000000000082, 17.899999999999988, 12.799999999999967, -68.20000000000076, 30.80000000000021], "policy_predator_policy_reward": [1.0, 15.0, 58.0, 115.0, 20.0, 33.0, 7.0, 3.0, 57.0, 58.0, 8.0, 1.0, 19.0, 34.0, 4.0, 9.0, 17.0, 28.0, 0.0, 11.0, 6.0, 20.0, 7.0, 5.0, 6.0, 7.0, 10.0, 16.0, 10.0, 7.0, 19.0, 12.0, 25.0, 26.0, 18.0, 5.0, 12.0, 9.0, 30.0, 18.0, 9.0, 5.0, 15.0, 1.0, 0.0, 3.0, 3.0, 4.0, 19.0, 4.0, 26.0, 1.0, 7.0, 3.0, 3.0, 3.0, 4.0, 10.0, 20.0, 7.0, 26.0, 10.0, 8.0, 17.0, 17.0, 29.0, 1.0, 0.0, 8.0, 12.0, 48.0, 49.0, 19.0, 23.0, 35.0, 20.0, 4.0, 0.0, 8.0, 15.0, 0.0, 0.0, 56.0, 4.0, 18.0, 7.0, 27.0, 20.0, 3.0, 2.0, 8.0, 10.0, 36.0, 1.0, 30.0, 64.0, 14.0, 4.0, 30.0, 26.0, 3.0, 8.0, 1.0, 19.0, 5.0, 3.0, 6.0, 7.0, 0.0, 7.0, 15.0, 23.0, 23.0, 0.0, 30.0, 43.0, 1.0, 3.0, 10.0, 5.0, 7.0, 19.0, 4.0, 9.0, 33.0, 28.0, 27.0, 13.0, 11.0, 20.0, 0.0, 41.0, 171.0, 12.0, 1.0, 22.0, 25.0, 28.0, 8.0, 9.0, 27.0, 24.0, 5.0, 1.0, 31.0, 31.0, 4.0, 31.0, 8.0, 65.0, 12.0, 11.0, 14.0, 0.0, 7.0, 2.0, 2.0, 1.0, 9.0, 17.0, 13.0, 30.0, 11.0, 9.0, 9.0, 0.0, 12.0, 161.0, 44.0, 0.0, 70.0, 0.0, 91.0, 55.0, 6.0, 11.0, 5.0, 5.0, 7.0, 26.0, 158.0, 14.0, 22.0, 0.0, 16.0, 9.0, 9.0, 0.0, 13.0, 6.0, 2.0, 16.0, 0.0, 126.0, 43.0, 34.0, 6.0, 1.0, 3.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5272334744276654, "mean_inference_ms": 1.3596571162440114, "mean_action_processing_ms": 0.22515293194298686, "mean_env_wait_ms": 0.17154915508046023, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003234386444091797, "StateBufferConnector_ms": 0.0028214454650878906, "ViewRequirementAgentConnector_ms": 0.0839540958404541}, "num_episodes": 23, "episode_return_max": 145.19999999999922, "episode_return_min": -424.3, "episode_return_mean": 7.222000000000167, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 441.7010323039184, "num_env_steps_trained_throughput_per_sec": 441.7010323039184, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 8991.825, "restore_workers_time_ms": 0.014, "training_step_time_ms": 8991.786, "sample_time_ms": 1021.692, "learn_time_ms": 7958.077, "learn_throughput": 502.634, "synch_weights_time_ms": 11.257}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "c7e6b_00002", "date": "2024-08-14_10-40-26", "timestamp": 1723646426, "time_this_iter_s": 9.059162139892578, "time_total_s": 945.2058665752411, "pid": 32854, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.0001, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39b1beaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 945.2058665752411, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 26.830769230769228, "ram_util_percent": 79.34615384615384}}
