{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9182431168026395, "cur_kl_coeff": 0.2, "cur_lr": 0.009999999999999998, "total_loss": 7.182746743651294, "policy_loss": 0.0453127565660647, "vf_loss": 7.117932161956868, "vf_explained_var": -0.0006565015782754888, "kl": 0.09750908162275895, "entropy": 1.5208678270773912, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6422232006277357, "cur_kl_coeff": 0.2, "cur_lr": 0.009999999999999998, "total_loss": 8.620313744065623, "policy_loss": 0.045257866448629155, "vf_loss": 8.554167120292703, "vf_explained_var": 0.0016945943945930117, "kl": 0.10444379433594332, "entropy": 1.519227692752919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 138.09999999999968, "episode_reward_min": -156.8000000000007, "episode_reward_mean": -50.40555555555574, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -378.9999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.19999999999987, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -107.5083333333334, "predator_policy": 82.30555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.30000000000009, -153.90000000000026, -77.40000000000055, -122.20000000000019, -30.50000000000032, -61.4999999999997, -37.89999999999979, -146.6000000000004, -66.69999999999993, -70.60000000000048, -156.8000000000007, -65.10000000000002, 110.89999999999986, 138.09999999999968, -94.90000000000013, -2.8999999999999257, -96.90000000000063, -11.699999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.19999999999987, -258.90000000000003, -290.1999999999996, -108.70000000000016, -223.60000000000048, -59.80000000000007, -378.9999999999999, 27.80000000000003, -72.10000000000073, -120.40000000000012, -135.40000000000072, -42.099999999999824, -166.90000000000043, 20.000000000000014, -328.59999999999945, -54.99999999999985, -79.29999999999995, -156.40000000000046, 20.000000000000014, -223.60000000000048, -311.4999999999995, -88.30000000000055, 20.000000000000014, -312.0999999999997, 66.80000000000001, -40.89999999999999, 99.2, -15.099999999999774, -231.20000000000016, -60.69999999999988, -38.20000000000002, -57.70000000000038, -213.70000000000002, -101.20000000000064, -55.89999999999999, -47.7999999999998], "policy_predator_policy_reward": [138.0, 10.0, 155.0, 90.0, 110.0, 96.0, 151.0, 78.0, 89.0, 73.0, 42.0, 74.0, 88.0, 21.0, 158.0, 79.0, 84.0, 85.0, 110.0, 23.0, 143.0, 100.0, 110.0, 117.0, 46.0, 39.0, 15.0, 39.0, 86.0, 111.0, 93.0, 0.0, 87.0, 131.0, 77.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6410948220035463, "mean_inference_ms": 2.0903101240925954, "mean_action_processing_ms": 0.2699331196318838, "mean_env_wait_ms": 0.2172073210322777, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010459952884250216, "StateBufferConnector_ms": 0.003293487760755751, "ViewRequirementAgentConnector_ms": 0.10390149222479926}, "num_episodes": 18, "episode_return_max": 138.09999999999968, "episode_return_min": -156.8000000000007, "episode_return_mean": -50.40555555555574, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.6031909910266, "num_env_steps_trained_throughput_per_sec": 351.6031909910266, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 11376.471, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11376.387, "sample_time_ms": 1552.067, "learn_time_ms": 9804.913, "learn_throughput": 407.959, "synch_weights_time_ms": 16.931}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-02-22", "timestamp": 1723644142, "time_this_iter_s": 11.403102159500122, "time_total_s": 11.403102159500122, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3186c0e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11.403102159500122, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 33.65882352941176, "ram_util_percent": 83.52941176470588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.042836830603383, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.009999999999999998, "total_loss": 1.8605483519967903, "policy_loss": 0.029462274651550664, "vf_loss": 1.8025750708643091, "vf_explained_var": 0.023645107109079917, "kl": 0.09503668794199684, "entropy": 1.4378414625843996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.789576681612661, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 0.009999999999999998, "total_loss": 5.511578642375886, "policy_loss": 0.02678696799225041, "vf_loss": 5.45468030076809, "vf_explained_var": -0.014282072158086868, "kl": 0.10037126599884352, "entropy": 1.469053396346077, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 138.09999999999968, "episode_reward_min": -156.8000000000007, "episode_reward_mean": -15.375000000000284, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -378.9999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.19999999999987, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -63.97916666666677, "predator_policy": 56.291666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.30000000000009, -153.90000000000026, -77.40000000000055, -122.20000000000019, -30.50000000000032, -61.4999999999997, -37.89999999999979, -146.6000000000004, -66.69999999999993, -70.60000000000048, -156.8000000000007, -65.10000000000002, 110.89999999999986, 138.09999999999968, -94.90000000000013, -2.8999999999999257, -96.90000000000063, -11.699999999999974, -69.90000000000157, 49.90000000000028, 112.89999999999885, 20.900000000000023, 94.5999999999988, 122.99999999999885, -11.799999999999619, 5.900000000000125, 74.59999999999967, -18.49999999999953, 47.00000000000033, 89.79999999999853, -38.800000000000246, 34.40000000000021, -106.00000000000063, 45.80000000000034, -38.199999999999676, -61.800000000001674], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.19999999999987, -258.90000000000003, -290.1999999999996, -108.70000000000016, -223.60000000000048, -59.80000000000007, -378.9999999999999, 27.80000000000003, -72.10000000000073, -120.40000000000012, -135.40000000000072, -42.099999999999824, -166.90000000000043, 20.000000000000014, -328.59999999999945, -54.99999999999985, -79.29999999999995, -156.40000000000046, 20.000000000000014, -223.60000000000048, -311.4999999999995, -88.30000000000055, 20.000000000000014, -312.0999999999997, 66.80000000000001, -40.89999999999999, 99.2, -15.099999999999774, -231.20000000000016, -60.69999999999988, -38.20000000000002, -57.70000000000038, -213.70000000000002, -101.20000000000064, -55.89999999999999, -47.7999999999998, -112.30000000000078, -61.600000000000676, -30.39999999999975, 47.300000000000146, 68.59999999999987, 44.300000000000125, -48.09999999999979, 20.000000000000014, 90.4999999999994, -19.899999999999743, 93.79999999999933, -11.800000000000043, -29.199999999999775, -43.59999999999977, 9.499999999999964, -55.60000000000022, -27.699999999999925, 14.29999999999997, -101.80000000000081, 5.299999999999965, 21.800000000000068, -14.799999999999864, 40.10000000000019, 37.7000000000002, -77.20000000000044, -76.60000000000088, -70.30000000000089, 31.70000000000022, -40.29999999999992, -204.70000000000033, -34.59999999999975, 34.40000000000017, -18.39999999999984, -101.80000000000064, -68.20000000000086, -46.59999999999977], "policy_predator_policy_reward": [138.0, 10.0, 155.0, 90.0, 110.0, 96.0, 151.0, 78.0, 89.0, 73.0, 42.0, 74.0, 88.0, 21.0, 158.0, 79.0, 84.0, 85.0, 110.0, 23.0, 143.0, 100.0, 110.0, 117.0, 46.0, 39.0, 15.0, 39.0, 86.0, 111.0, 93.0, 0.0, 87.0, 131.0, 77.0, 15.0, 40.0, 64.0, 9.0, 24.0, 0.0, 0.0, 19.0, 30.0, 19.0, 5.0, 40.0, 1.0, 29.0, 32.0, 28.0, 24.0, 7.0, 81.0, 58.0, 20.0, 38.0, 2.0, 2.0, 10.0, 46.0, 69.0, 43.0, 30.0, 29.0, 110.0, 2.0, 44.0, 39.0, 43.0, 9.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6389337206151219, "mean_inference_ms": 2.083342253583264, "mean_action_processing_ms": 0.26775719393627945, "mean_env_wait_ms": 0.2210532439763807, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009392036332024468, "StateBufferConnector_ms": 0.0033504433102077907, "ViewRequirementAgentConnector_ms": 0.1027875476413303}, "num_episodes": 18, "episode_return_max": 138.09999999999968, "episode_return_min": -156.8000000000007, "episode_return_mean": -15.375000000000284, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.23791383154287, "num_env_steps_trained_throughput_per_sec": 357.23791383154287, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 11286.753, "restore_workers_time_ms": 0.024, "training_step_time_ms": 11286.671, "sample_time_ms": 1525.434, "learn_time_ms": 9740.123, "learn_throughput": 410.672, "synch_weights_time_ms": 19.152}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-02-36", "timestamp": 1723644156, "time_this_iter_s": 11.230269193649292, "time_total_s": 22.633371353149414, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187379d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 22.633371353149414, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 40.43684210526315, "ram_util_percent": 83.71052631578948}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5358461306839395, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 0.009999999999999998, "total_loss": 1.0418184843959002, "policy_loss": 0.018881687480049633, "vf_loss": 0.9899090663150505, "vf_explained_var": 0.12555047166410577, "kl": 0.0733949598264767, "entropy": 1.462901127212262, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.485415575397077, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 0.009999999999999998, "total_loss": 3.3412081661678497, "policy_loss": 0.020168960930301596, "vf_loss": 3.2781245453647836, "vf_explained_var": 7.308100266431374e-05, "kl": 0.09536590363331447, "entropy": 1.3103267028533592, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 138.09999999999968, "episode_reward_min": -225.40000000000055, "episode_reward_mean": -4.111111111111248, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -378.9999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.19999999999987, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -45.54629629629636, "predator_policy": 43.49074074074074}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.30000000000009, -153.90000000000026, -77.40000000000055, -122.20000000000019, -30.50000000000032, -61.4999999999997, -37.89999999999979, -146.6000000000004, -66.69999999999993, -70.60000000000048, -156.8000000000007, -65.10000000000002, 110.89999999999986, 138.09999999999968, -94.90000000000013, -2.8999999999999257, -96.90000000000063, -11.699999999999974, -69.90000000000157, 49.90000000000028, 112.89999999999885, 20.900000000000023, 94.5999999999988, 122.99999999999885, -11.799999999999619, 5.900000000000125, 74.59999999999967, -18.49999999999953, 47.00000000000033, 89.79999999999853, -38.800000000000246, 34.40000000000021, -106.00000000000063, 45.80000000000034, -38.199999999999676, -61.800000000001674, 37.40000000000026, 56.400000000000425, 66.00000000000028, 30.000000000000146, 16.799999999999986, 53.70000000000042, -4.000000000000027, -6.199999999999667, -225.40000000000055, 17.199999999999964, 17.50000000000011, 40.70000000000031, -43.000000000000256, 45.800000000000395, 44.70000000000038, 55.20000000000046, 74.29999999999967, 54.400000000000446], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.19999999999987, -258.90000000000003, -290.1999999999996, -108.70000000000016, -223.60000000000048, -59.80000000000007, -378.9999999999999, 27.80000000000003, -72.10000000000073, -120.40000000000012, -135.40000000000072, -42.099999999999824, -166.90000000000043, 20.000000000000014, -328.59999999999945, -54.99999999999985, -79.29999999999995, -156.40000000000046, 20.000000000000014, -223.60000000000048, -311.4999999999995, -88.30000000000055, 20.000000000000014, -312.0999999999997, 66.80000000000001, -40.89999999999999, 99.2, -15.099999999999774, -231.20000000000016, -60.69999999999988, -38.20000000000002, -57.70000000000038, -213.70000000000002, -101.20000000000064, -55.89999999999999, -47.7999999999998, -112.30000000000078, -61.600000000000676, -30.39999999999975, 47.300000000000146, 68.59999999999987, 44.300000000000125, -48.09999999999979, 20.000000000000014, 90.4999999999994, -19.899999999999743, 93.79999999999933, -11.800000000000043, -29.199999999999775, -43.59999999999977, 9.499999999999964, -55.60000000000022, -27.699999999999925, 14.29999999999997, -101.80000000000081, 5.299999999999965, 21.800000000000068, -14.799999999999864, 40.10000000000019, 37.7000000000002, -77.20000000000044, -76.60000000000088, -70.30000000000089, 31.70000000000022, -40.29999999999992, -204.70000000000033, -34.59999999999975, 34.40000000000017, -18.39999999999984, -101.80000000000064, -68.20000000000086, -46.59999999999977, 21.80000000000004, 11.599999999999964, 13.399999999999979, 20.000000000000014, 2.599999999999975, 25.4000000000001, -0.9999999999999846, 20.000000000000014, -1.8999999999999853, -7.299999999999891, 30.8000000000002, 5.899999999999994, -64.00000000000001, 20.000000000000014, -28.29999999999975, -19.899999999999743, -245.10000000000042, -133.30000000000027, -4.299999999999962, -11.499999999999819, 3.1999999999999615, -63.70000000000065, 20.000000000000014, 13.699999999999967, -42.99999999999976, -64.00000000000088, 38.000000000000256, -5.1999999999999265, -6.999999999999956, 7.700000000000022, 15.499999999999961, 25.700000000000106, 60.20000000000018, 1.0999999999999617, -9.399999999999855, 39.80000000000022], "policy_predator_policy_reward": [138.0, 10.0, 155.0, 90.0, 110.0, 96.0, 151.0, 78.0, 89.0, 73.0, 42.0, 74.0, 88.0, 21.0, 158.0, 79.0, 84.0, 85.0, 110.0, 23.0, 143.0, 100.0, 110.0, 117.0, 46.0, 39.0, 15.0, 39.0, 86.0, 111.0, 93.0, 0.0, 87.0, 131.0, 77.0, 15.0, 40.0, 64.0, 9.0, 24.0, 0.0, 0.0, 19.0, 30.0, 19.0, 5.0, 40.0, 1.0, 29.0, 32.0, 28.0, 24.0, 7.0, 81.0, 58.0, 20.0, 38.0, 2.0, 2.0, 10.0, 46.0, 69.0, 43.0, 30.0, 29.0, 110.0, 2.0, 44.0, 39.0, 43.0, 9.0, 44.0, 4.0, 0.0, 16.0, 7.0, 24.0, 14.0, 1.0, 10.0, 13.0, 13.0, 14.0, 3.0, 0.0, 40.0, 26.0, 16.0, 0.0, 153.0, 8.0, 25.0, 44.0, 34.0, 6.0, 1.0, 31.0, 33.0, 12.0, 1.0, 24.0, 20.0, 8.0, 6.0, 9.0, 4.0, 10.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6376707385330129, "mean_inference_ms": 2.077138469839612, "mean_action_processing_ms": 0.26499665162909225, "mean_env_wait_ms": 0.22227856841118107, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00893010033501519, "StateBufferConnector_ms": 0.003367220913922345, "ViewRequirementAgentConnector_ms": 0.10150119110389992}, "num_episodes": 18, "episode_return_max": 138.09999999999968, "episode_return_min": -225.40000000000055, "episode_return_mean": -4.111111111111248, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.84690425504914, "num_env_steps_trained_throughput_per_sec": 364.84690425504914, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 11179.006, "restore_workers_time_ms": 0.021, "training_step_time_ms": 11178.929, "sample_time_ms": 1531.236, "learn_time_ms": 9629.113, "learn_throughput": 415.407, "synch_weights_time_ms": 16.415}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-02-47", "timestamp": 1723644167, "time_this_iter_s": 10.994359016418457, "time_total_s": 33.62773036956787, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318737c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 33.62773036956787, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 41.76875, "ram_util_percent": 82.75}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.302457634544877, "cur_kl_coeff": 0.675, "cur_lr": 0.009999999999999998, "total_loss": 2.3683462544093055, "policy_loss": 0.01584767321982081, "vf_loss": 2.31613617977768, "vf_explained_var": 0.08334512565501784, "kl": 0.053870221778659674, "entropy": 1.437378237297926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.490060629510375, "cur_kl_coeff": 0.675, "cur_lr": 0.009999999999999998, "total_loss": 4.154833010895542, "policy_loss": 0.02156589652446133, "vf_loss": 4.094184099681794, "vf_explained_var": 0.0017332180467232194, "kl": 0.05790074832811976, "entropy": 1.3472384536707842, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 138.09999999999968, "episode_reward_min": -359.199999999999, "episode_reward_mean": -11.488888888888956, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -400.1999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.19999999999987, "predator_policy": 291.0}, "policy_reward_mean": {"prey_policy": -47.765277777777825, "predator_policy": 42.020833333333336}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.30000000000009, -153.90000000000026, -77.40000000000055, -122.20000000000019, -30.50000000000032, -61.4999999999997, -37.89999999999979, -146.6000000000004, -66.69999999999993, -70.60000000000048, -156.8000000000007, -65.10000000000002, 110.89999999999986, 138.09999999999968, -94.90000000000013, -2.8999999999999257, -96.90000000000063, -11.699999999999974, -69.90000000000157, 49.90000000000028, 112.89999999999885, 20.900000000000023, 94.5999999999988, 122.99999999999885, -11.799999999999619, 5.900000000000125, 74.59999999999967, -18.49999999999953, 47.00000000000033, 89.79999999999853, -38.800000000000246, 34.40000000000021, -106.00000000000063, 45.80000000000034, -38.199999999999676, -61.800000000001674, 37.40000000000026, 56.400000000000425, 66.00000000000028, 30.000000000000146, 16.799999999999986, 53.70000000000042, -4.000000000000027, -6.199999999999667, -225.40000000000055, 17.199999999999964, 17.50000000000011, 40.70000000000031, -43.000000000000256, 45.800000000000395, 44.70000000000038, 55.20000000000046, 74.29999999999967, 54.400000000000446, 33.800000000000274, 9.400000000000112, 27.2000000000001, -60.400000000000105, -170.80000000000047, -29.999999999999524, 33.3000000000002, -181.20000000000005, -92.60000000000002, 51.9000000000005, 16.399999999999935, 52.50000000000043, 40.70000000000031, -43.09999999999987, -67.80000000000001, 80.09999999999933, 54.60000000000048, -359.199999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.19999999999987, -258.90000000000003, -290.1999999999996, -108.70000000000016, -223.60000000000048, -59.80000000000007, -378.9999999999999, 27.80000000000003, -72.10000000000073, -120.40000000000012, -135.40000000000072, -42.099999999999824, -166.90000000000043, 20.000000000000014, -328.59999999999945, -54.99999999999985, -79.29999999999995, -156.40000000000046, 20.000000000000014, -223.60000000000048, -311.4999999999995, -88.30000000000055, 20.000000000000014, -312.0999999999997, 66.80000000000001, -40.89999999999999, 99.2, -15.099999999999774, -231.20000000000016, -60.69999999999988, -38.20000000000002, -57.70000000000038, -213.70000000000002, -101.20000000000064, -55.89999999999999, -47.7999999999998, -112.30000000000078, -61.600000000000676, -30.39999999999975, 47.300000000000146, 68.59999999999987, 44.300000000000125, -48.09999999999979, 20.000000000000014, 90.4999999999994, -19.899999999999743, 93.79999999999933, -11.800000000000043, -29.199999999999775, -43.59999999999977, 9.499999999999964, -55.60000000000022, -27.699999999999925, 14.29999999999997, -101.80000000000081, 5.299999999999965, 21.800000000000068, -14.799999999999864, 40.10000000000019, 37.7000000000002, -77.20000000000044, -76.60000000000088, -70.30000000000089, 31.70000000000022, -40.29999999999992, -204.70000000000033, -34.59999999999975, 34.40000000000017, -18.39999999999984, -101.80000000000064, -68.20000000000086, -46.59999999999977, 21.80000000000004, 11.599999999999964, 13.399999999999979, 20.000000000000014, 2.599999999999975, 25.4000000000001, -0.9999999999999846, 20.000000000000014, -1.8999999999999853, -7.299999999999891, 30.8000000000002, 5.899999999999994, -64.00000000000001, 20.000000000000014, -28.29999999999975, -19.899999999999743, -245.10000000000042, -133.30000000000027, -4.299999999999962, -11.499999999999819, 3.1999999999999615, -63.70000000000065, 20.000000000000014, 13.699999999999967, -42.99999999999976, -64.00000000000088, 38.000000000000256, -5.1999999999999265, -6.999999999999956, 7.700000000000022, 15.499999999999961, 25.700000000000106, 60.20000000000018, 1.0999999999999617, -9.399999999999855, 39.80000000000022, 3.5000000000000084, -0.6999999999999993, -9.399999999999855, -5.1999999999999265, -17.79999999999974, 20.000000000000014, -108.10000000000035, -28.299999999999976, -99.6999999999999, -195.1000000000006, -34.59999999999975, -51.39999999999988, 30.800000000000196, -32.49999999999975, -295.30000000000064, -194.90000000000003, -85.29999999999993, -112.29999999999998, 28.100000000000147, 15.799999999999962, -56.80000000000038, 27.200000000000145, 39.50000000000021, -0.9999999999999846, -5.19999999999993, 29.90000000000018, -93.40000000000069, -57.70000000000048, 20.000000000000014, -185.79999999999998, 53.30000000000023, 15.79999999999996, 15.799999999999963, 30.800000000000203, -219.0000000000002, -400.1999999999996], "policy_predator_policy_reward": [138.0, 10.0, 155.0, 90.0, 110.0, 96.0, 151.0, 78.0, 89.0, 73.0, 42.0, 74.0, 88.0, 21.0, 158.0, 79.0, 84.0, 85.0, 110.0, 23.0, 143.0, 100.0, 110.0, 117.0, 46.0, 39.0, 15.0, 39.0, 86.0, 111.0, 93.0, 0.0, 87.0, 131.0, 77.0, 15.0, 40.0, 64.0, 9.0, 24.0, 0.0, 0.0, 19.0, 30.0, 19.0, 5.0, 40.0, 1.0, 29.0, 32.0, 28.0, 24.0, 7.0, 81.0, 58.0, 20.0, 38.0, 2.0, 2.0, 10.0, 46.0, 69.0, 43.0, 30.0, 29.0, 110.0, 2.0, 44.0, 39.0, 43.0, 9.0, 44.0, 4.0, 0.0, 16.0, 7.0, 24.0, 14.0, 1.0, 10.0, 13.0, 13.0, 14.0, 3.0, 0.0, 40.0, 26.0, 16.0, 0.0, 153.0, 8.0, 25.0, 44.0, 34.0, 6.0, 1.0, 31.0, 33.0, 12.0, 1.0, 24.0, 20.0, 8.0, 6.0, 9.0, 4.0, 10.0, 14.0, 19.0, 12.0, 10.0, 14.0, 17.0, 8.0, 8.0, 68.0, 113.0, 11.0, 19.0, 37.0, 25.0, 10.0, 18.0, 291.0, 9.0, 96.0, 8.0, 0.0, 37.0, 9.0, 10.0, 4.0, 4.0, 12.0, 53.0, 55.0, 0.0, 98.0, 11.0, 0.0, 6.0, 2.0, 8.0, 252.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6328589531188409, "mean_inference_ms": 2.0581357412002848, "mean_action_processing_ms": 0.26248357099325115, "mean_env_wait_ms": 0.22121144441712173, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008212195502387153, "StateBufferConnector_ms": 0.0032782554626464844, "ViewRequirementAgentConnector_ms": 0.09774350457721287}, "num_episodes": 18, "episode_return_max": 138.09999999999968, "episode_return_min": -359.199999999999, "episode_return_mean": -11.488888888888956, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.16098420230014, "num_env_steps_trained_throughput_per_sec": 363.16098420230014, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 11137.856, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11137.788, "sample_time_ms": 1478.701, "learn_time_ms": 9641.326, "learn_throughput": 414.881, "synch_weights_time_ms": 15.951}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-02-58", "timestamp": 1723644178, "time_this_iter_s": 11.021117925643921, "time_total_s": 44.64884829521179, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318737940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 44.64884829521179, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 38.36666666666667, "ram_util_percent": 82.27333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.307414782709546, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.009999999999999998, "total_loss": 1.770439518191827, "policy_loss": 0.001213278358299581, "vf_loss": 1.735943846160142, "vf_explained_var": 0.1696323545206161, "kl": 0.032871499414583956, "entropy": 1.3178439370538824, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.729473355081346, "cur_kl_coeff": 1.0124999999999997, "cur_lr": 0.009999999999999998, "total_loss": 2.530632407009286, "policy_loss": 0.010330706547635297, "vf_loss": 2.4757418218743865, "vf_explained_var": 0.00019884159956028852, "kl": 0.044009756638672806, "entropy": 1.3086829662322998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 138.09999999999968, "episode_reward_min": -371.80000000000007, "episode_reward_mean": -14.213131313131303, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -448.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 150.19999999999987, "predator_policy": 306.0}, "policy_reward_mean": {"prey_policy": -46.535858585858634, "predator_policy": 39.42929292929293}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.30000000000009, -153.90000000000026, -77.40000000000055, -122.20000000000019, -30.50000000000032, -61.4999999999997, -37.89999999999979, -146.6000000000004, -66.69999999999993, -70.60000000000048, -156.8000000000007, -65.10000000000002, 110.89999999999986, 138.09999999999968, -94.90000000000013, -2.8999999999999257, -96.90000000000063, -11.699999999999974, -69.90000000000157, 49.90000000000028, 112.89999999999885, 20.900000000000023, 94.5999999999988, 122.99999999999885, -11.799999999999619, 5.900000000000125, 74.59999999999967, -18.49999999999953, 47.00000000000033, 89.79999999999853, -38.800000000000246, 34.40000000000021, -106.00000000000063, 45.80000000000034, -38.199999999999676, -61.800000000001674, 37.40000000000026, 56.400000000000425, 66.00000000000028, 30.000000000000146, 16.799999999999986, 53.70000000000042, -4.000000000000027, -6.199999999999667, -225.40000000000055, 17.199999999999964, 17.50000000000011, 40.70000000000031, -43.000000000000256, 45.800000000000395, 44.70000000000038, 55.20000000000046, 74.29999999999967, 54.400000000000446, 33.800000000000274, 9.400000000000112, 27.2000000000001, -60.400000000000105, -170.80000000000047, -29.999999999999524, 33.3000000000002, -181.20000000000005, -92.60000000000002, 51.9000000000005, 16.399999999999935, 52.50000000000043, 40.70000000000031, -43.09999999999987, -67.80000000000001, 80.09999999999933, 54.60000000000048, -359.199999999999, -371.80000000000007, 34.200000000000216, 23.300000000000026, 53.60000000000037, 48.70000000000045, 67.80000000000015, -234.5999999999999, -257.99999999999886, 13.500000000000012, 74.69999999999969, 61.30000000000047, 54.800000000000445, -155.40000000000015, 41.70000000000037, 10.099999999999978, 11.800000000000047, 27.900000000000105, -366.5, 45.8000000000004, 77.59999999999953, 33.2000000000002, 54.80000000000045, 32.10000000000018, -28.399999999999558, 53.10000000000051, 42.60000000000034, -27.799999999999542], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.19999999999987, -258.90000000000003, -290.1999999999996, -108.70000000000016, -223.60000000000048, -59.80000000000007, -378.9999999999999, 27.80000000000003, -72.10000000000073, -120.40000000000012, -135.40000000000072, -42.099999999999824, -166.90000000000043, 20.000000000000014, -328.59999999999945, -54.99999999999985, -79.29999999999995, -156.40000000000046, 20.000000000000014, -223.60000000000048, -311.4999999999995, -88.30000000000055, 20.000000000000014, -312.0999999999997, 66.80000000000001, -40.89999999999999, 99.2, -15.099999999999774, -231.20000000000016, -60.69999999999988, -38.20000000000002, -57.70000000000038, -213.70000000000002, -101.20000000000064, -55.89999999999999, -47.7999999999998, -112.30000000000078, -61.600000000000676, -30.39999999999975, 47.300000000000146, 68.59999999999987, 44.300000000000125, -48.09999999999979, 20.000000000000014, 90.4999999999994, -19.899999999999743, 93.79999999999933, -11.800000000000043, -29.199999999999775, -43.59999999999977, 9.499999999999964, -55.60000000000022, -27.699999999999925, 14.29999999999997, -101.80000000000081, 5.299999999999965, 21.800000000000068, -14.799999999999864, 40.10000000000019, 37.7000000000002, -77.20000000000044, -76.60000000000088, -70.30000000000089, 31.70000000000022, -40.29999999999992, -204.70000000000033, -34.59999999999975, 34.40000000000017, -18.39999999999984, -101.80000000000064, -68.20000000000086, -46.59999999999977, 21.80000000000004, 11.599999999999964, 13.399999999999979, 20.000000000000014, 2.599999999999975, 25.4000000000001, -0.9999999999999846, 20.000000000000014, -1.8999999999999853, -7.299999999999891, 30.8000000000002, 5.899999999999994, -64.00000000000001, 20.000000000000014, -28.29999999999975, -19.899999999999743, -245.10000000000042, -133.30000000000027, -4.299999999999962, -11.499999999999819, 3.1999999999999615, -63.70000000000065, 20.000000000000014, 13.699999999999967, -42.99999999999976, -64.00000000000088, 38.000000000000256, -5.1999999999999265, -6.999999999999956, 7.700000000000022, 15.499999999999961, 25.700000000000106, 60.20000000000018, 1.0999999999999617, -9.399999999999855, 39.80000000000022, 3.5000000000000084, -0.6999999999999993, -9.399999999999855, -5.1999999999999265, -17.79999999999974, 20.000000000000014, -108.10000000000035, -28.299999999999976, -99.6999999999999, -195.1000000000006, -34.59999999999975, -51.39999999999988, 30.800000000000196, -32.49999999999975, -295.30000000000064, -194.90000000000003, -85.29999999999993, -112.29999999999998, 28.100000000000147, 15.799999999999962, -56.80000000000038, 27.200000000000145, 39.50000000000021, -0.9999999999999846, -5.19999999999993, 29.90000000000018, -93.40000000000069, -57.70000000000048, 20.000000000000014, -185.79999999999998, 53.30000000000023, 15.79999999999996, 15.799999999999963, 30.800000000000203, -219.0000000000002, -400.1999999999996, -366.1, -295.70000000000005, 20.000000000000014, 3.1999999999999615, -8.499999999999872, 15.799999999999963, 29.60000000000017, 20.000000000000014, 22.700000000000056, 20.000000000000014, 53.3000000000002, 9.49999999999997, -258.9999999999999, -197.60000000000002, -181.60000000000036, -219.40000000000038, -32.49999999999975, 20.000000000000014, -5.1999999999999265, 56.90000000000021, 20.000000000000014, 35.30000000000023, 3.1999999999999686, 35.60000000000022, -146.8, -139.60000000000068, 19.700000000000024, -0.9999999999999846, -31.59999999999983, -133.30000000000072, -7.5999999999998895, -1.6000000000000032, 11.599999999999964, 5.299999999999965, -448.9, -234.60000000000002, 5.299999999999965, 24.500000000000092, 32.60000000000023, 44.000000000000234, -17.79999999999974, 20.000000000000014, 20.000000000000014, 12.799999999999972, 4.099999999999966, 20.000000000000014, -17.79999999999974, -118.60000000000073, 25.100000000000097, 20.000000000000014, -7.299999999999891, 2.899999999999972, -83.2000000000007, -13.599999999999783], "policy_predator_policy_reward": [138.0, 10.0, 155.0, 90.0, 110.0, 96.0, 151.0, 78.0, 89.0, 73.0, 42.0, 74.0, 88.0, 21.0, 158.0, 79.0, 84.0, 85.0, 110.0, 23.0, 143.0, 100.0, 110.0, 117.0, 46.0, 39.0, 15.0, 39.0, 86.0, 111.0, 93.0, 0.0, 87.0, 131.0, 77.0, 15.0, 40.0, 64.0, 9.0, 24.0, 0.0, 0.0, 19.0, 30.0, 19.0, 5.0, 40.0, 1.0, 29.0, 32.0, 28.0, 24.0, 7.0, 81.0, 58.0, 20.0, 38.0, 2.0, 2.0, 10.0, 46.0, 69.0, 43.0, 30.0, 29.0, 110.0, 2.0, 44.0, 39.0, 43.0, 9.0, 44.0, 4.0, 0.0, 16.0, 7.0, 24.0, 14.0, 1.0, 10.0, 13.0, 13.0, 14.0, 3.0, 0.0, 40.0, 26.0, 16.0, 0.0, 153.0, 8.0, 25.0, 44.0, 34.0, 6.0, 1.0, 31.0, 33.0, 12.0, 1.0, 24.0, 20.0, 8.0, 6.0, 9.0, 4.0, 10.0, 14.0, 19.0, 12.0, 10.0, 14.0, 17.0, 8.0, 8.0, 68.0, 113.0, 11.0, 19.0, 37.0, 25.0, 10.0, 18.0, 291.0, 9.0, 96.0, 8.0, 0.0, 37.0, 9.0, 10.0, 4.0, 4.0, 12.0, 53.0, 55.0, 0.0, 98.0, 11.0, 0.0, 6.0, 2.0, 8.0, 252.0, 289.0, 1.0, 8.0, 3.0, 2.0, 14.0, 4.0, 0.0, 6.0, 0.0, 5.0, 0.0, 41.0, 181.0, 1.0, 142.0, 25.0, 1.0, 12.0, 11.0, 0.0, 6.0, 6.0, 10.0, 31.0, 100.0, 13.0, 10.0, 79.0, 96.0, 17.0, 4.0, 4.0, 7.0, 306.0, 11.0, 9.0, 7.0, 1.0, 0.0, 17.0, 14.0, 7.0, 15.0, 8.0, 0.0, 66.0, 42.0, 4.0, 4.0, 24.0, 23.0, 16.0, 53.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.627469255748907, "mean_inference_ms": 2.0345776986808604, "mean_action_processing_ms": 0.2600132655636264, "mean_env_wait_ms": 0.2192119934180364, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007993885965058298, "StateBufferConnector_ms": 0.00389693963407266, "ViewRequirementAgentConnector_ms": 0.09977468336471404}, "num_episodes": 27, "episode_return_max": 138.09999999999968, "episode_return_min": -371.80000000000007, "episode_return_mean": -14.213131313131303, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 394.78321534305906, "num_env_steps_trained_throughput_per_sec": 394.78321534305906, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 10936.715, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10936.653, "sample_time_ms": 1459.682, "learn_time_ms": 9459.599, "learn_throughput": 422.851, "synch_weights_time_ms": 15.609}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-03-08", "timestamp": 1723644188, "time_this_iter_s": 10.142572164535522, "time_total_s": 54.791420459747314, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3186c0e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 54.791420459747314, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 32.86, "ram_util_percent": 82.07999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2753496082686873, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.009999999999999998, "total_loss": 1.7734481688214359, "policy_loss": 0.0004773099869785328, "vf_loss": 1.7450218403780902, "vf_explained_var": 0.15794958488020316, "kl": 0.018402646993837812, "entropy": 1.27705945287432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.591618986735268, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.009999999999999998, "total_loss": 2.776761170291396, "policy_loss": 0.007800046872672817, "vf_loss": 2.7214778647220954, "vf_explained_var": 0.0028096437454223633, "kl": 0.031264705054127054, "entropy": 1.3289435966935739, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 122.99999999999885, "episode_reward_min": -587.2, "episode_reward_mean": -12.553999999999949, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -680.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 93.79999999999933, "predator_policy": 596.0}, "policy_reward_mean": {"prey_policy": -37.46200000000003, "predator_policy": 31.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.699999999999974, -69.90000000000157, 49.90000000000028, 112.89999999999885, 20.900000000000023, 94.5999999999988, 122.99999999999885, -11.799999999999619, 5.900000000000125, 74.59999999999967, -18.49999999999953, 47.00000000000033, 89.79999999999853, -38.800000000000246, 34.40000000000021, -106.00000000000063, 45.80000000000034, -38.199999999999676, -61.800000000001674, 37.40000000000026, 56.400000000000425, 66.00000000000028, 30.000000000000146, 16.799999999999986, 53.70000000000042, -4.000000000000027, -6.199999999999667, -225.40000000000055, 17.199999999999964, 17.50000000000011, 40.70000000000031, -43.000000000000256, 45.800000000000395, 44.70000000000038, 55.20000000000046, 74.29999999999967, 54.400000000000446, 33.800000000000274, 9.400000000000112, 27.2000000000001, -60.400000000000105, -170.80000000000047, -29.999999999999524, 33.3000000000002, -181.20000000000005, -92.60000000000002, 51.9000000000005, 16.399999999999935, 52.50000000000043, 40.70000000000031, -43.09999999999987, -67.80000000000001, 80.09999999999933, 54.60000000000048, -359.199999999999, -371.80000000000007, 34.200000000000216, 23.300000000000026, 53.60000000000037, 48.70000000000045, 67.80000000000015, -234.5999999999999, -257.99999999999886, 13.500000000000012, 74.69999999999969, 61.30000000000047, 54.800000000000445, -155.40000000000015, 41.70000000000037, 10.099999999999978, 11.800000000000047, 27.900000000000105, -366.5, 45.8000000000004, 77.59999999999953, 33.2000000000002, 54.80000000000045, 32.10000000000018, -28.399999999999558, 53.10000000000051, 42.60000000000034, -27.799999999999542, 72.79999999999977, 3.2000000000000526, 40.80000000000031, 41.400000000000325, 11.400000000000041, 15.699999999999934, -493.6, 69.70000000000007, 22.000000000000007, 29.000000000000124, -25.59999999999951, 11.100000000000014, -79.70000000000113, 36.40000000000025, -587.2, 33.2000000000002, 44.50000000000039, 11.000000000000078], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-55.89999999999999, -47.7999999999998, -112.30000000000078, -61.600000000000676, -30.39999999999975, 47.300000000000146, 68.59999999999987, 44.300000000000125, -48.09999999999979, 20.000000000000014, 90.4999999999994, -19.899999999999743, 93.79999999999933, -11.800000000000043, -29.199999999999775, -43.59999999999977, 9.499999999999964, -55.60000000000022, -27.699999999999925, 14.29999999999997, -101.80000000000081, 5.299999999999965, 21.800000000000068, -14.799999999999864, 40.10000000000019, 37.7000000000002, -77.20000000000044, -76.60000000000088, -70.30000000000089, 31.70000000000022, -40.29999999999992, -204.70000000000033, -34.59999999999975, 34.40000000000017, -18.39999999999984, -101.80000000000064, -68.20000000000086, -46.59999999999977, 21.80000000000004, 11.599999999999964, 13.399999999999979, 20.000000000000014, 2.599999999999975, 25.4000000000001, -0.9999999999999846, 20.000000000000014, -1.8999999999999853, -7.299999999999891, 30.8000000000002, 5.899999999999994, -64.00000000000001, 20.000000000000014, -28.29999999999975, -19.899999999999743, -245.10000000000042, -133.30000000000027, -4.299999999999962, -11.499999999999819, 3.1999999999999615, -63.70000000000065, 20.000000000000014, 13.699999999999967, -42.99999999999976, -64.00000000000088, 38.000000000000256, -5.1999999999999265, -6.999999999999956, 7.700000000000022, 15.499999999999961, 25.700000000000106, 60.20000000000018, 1.0999999999999617, -9.399999999999855, 39.80000000000022, 3.5000000000000084, -0.6999999999999993, -9.399999999999855, -5.1999999999999265, -17.79999999999974, 20.000000000000014, -108.10000000000035, -28.299999999999976, -99.6999999999999, -195.1000000000006, -34.59999999999975, -51.39999999999988, 30.800000000000196, -32.49999999999975, -295.30000000000064, -194.90000000000003, -85.29999999999993, -112.29999999999998, 28.100000000000147, 15.799999999999962, -56.80000000000038, 27.200000000000145, 39.50000000000021, -0.9999999999999846, -5.19999999999993, 29.90000000000018, -93.40000000000069, -57.70000000000048, 20.000000000000014, -185.79999999999998, 53.30000000000023, 15.79999999999996, 15.799999999999963, 30.800000000000203, -219.0000000000002, -400.1999999999996, -366.1, -295.70000000000005, 20.000000000000014, 3.1999999999999615, -8.499999999999872, 15.799999999999963, 29.60000000000017, 20.000000000000014, 22.700000000000056, 20.000000000000014, 53.3000000000002, 9.49999999999997, -258.9999999999999, -197.60000000000002, -181.60000000000036, -219.40000000000038, -32.49999999999975, 20.000000000000014, -5.1999999999999265, 56.90000000000021, 20.000000000000014, 35.30000000000023, 3.1999999999999686, 35.60000000000022, -146.8, -139.60000000000068, 19.700000000000024, -0.9999999999999846, -31.59999999999983, -133.30000000000072, -7.5999999999998895, -1.6000000000000032, 11.599999999999964, 5.299999999999965, -448.9, -234.60000000000002, 5.299999999999965, 24.500000000000092, 32.60000000000023, 44.000000000000234, -17.79999999999974, 20.000000000000014, 20.000000000000014, 12.799999999999972, 4.099999999999966, 20.000000000000014, -17.79999999999974, -118.60000000000073, 25.100000000000097, 20.000000000000014, -7.299999999999891, 2.899999999999972, -83.2000000000007, -13.599999999999783, 1.0999999999999865, 55.70000000000018, 20.000000000000014, -56.80000000000024, 2.900000000000002, 17.899999999999988, 13.399999999999965, 20.000000000000014, 20.000000000000014, -34.59999999999975, 28.400000000000162, -57.70000000000048, -313.2, -387.4, 42.50000000000023, 24.20000000000008, -21.999999999999744, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -30.39999999999975, -41.19999999999977, -72.40000000000089, 0.49999999999996525, -103.90000000000057, -59.80000000000025, 18.799999999999997, 2.599999999999961, -680.0, -531.2, 5.299999999999965, 17.899999999999988, -19.899999999999743, 37.40000000000022, 3.199999999999965, -5.1999999999999265], "policy_predator_policy_reward": [77.0, 15.0, 40.0, 64.0, 9.0, 24.0, 0.0, 0.0, 19.0, 30.0, 19.0, 5.0, 40.0, 1.0, 29.0, 32.0, 28.0, 24.0, 7.0, 81.0, 58.0, 20.0, 38.0, 2.0, 2.0, 10.0, 46.0, 69.0, 43.0, 30.0, 29.0, 110.0, 2.0, 44.0, 39.0, 43.0, 9.0, 44.0, 4.0, 0.0, 16.0, 7.0, 24.0, 14.0, 1.0, 10.0, 13.0, 13.0, 14.0, 3.0, 0.0, 40.0, 26.0, 16.0, 0.0, 153.0, 8.0, 25.0, 44.0, 34.0, 6.0, 1.0, 31.0, 33.0, 12.0, 1.0, 24.0, 20.0, 8.0, 6.0, 9.0, 4.0, 10.0, 14.0, 19.0, 12.0, 10.0, 14.0, 17.0, 8.0, 8.0, 68.0, 113.0, 11.0, 19.0, 37.0, 25.0, 10.0, 18.0, 291.0, 9.0, 96.0, 8.0, 0.0, 37.0, 9.0, 10.0, 4.0, 4.0, 12.0, 53.0, 55.0, 0.0, 98.0, 11.0, 0.0, 6.0, 2.0, 8.0, 252.0, 289.0, 1.0, 8.0, 3.0, 2.0, 14.0, 4.0, 0.0, 6.0, 0.0, 5.0, 0.0, 41.0, 181.0, 1.0, 142.0, 25.0, 1.0, 12.0, 11.0, 0.0, 6.0, 6.0, 10.0, 31.0, 100.0, 13.0, 10.0, 79.0, 96.0, 17.0, 4.0, 4.0, 7.0, 306.0, 11.0, 9.0, 7.0, 1.0, 0.0, 17.0, 14.0, 7.0, 15.0, 8.0, 0.0, 66.0, 42.0, 4.0, 4.0, 24.0, 23.0, 16.0, 53.0, 9.0, 7.0, 34.0, 6.0, 14.0, 6.0, 4.0, 4.0, 0.0, 26.0, 8.0, 37.0, 4.0, 203.0, 3.0, 0.0, 17.0, 7.0, 8.0, 2.0, 39.0, 7.0, 41.0, 42.0, 62.0, 22.0, 5.0, 10.0, 596.0, 28.0, 3.0, 7.0, 19.0, 8.0, 1.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.620230943274584, "mean_inference_ms": 2.004743721536164, "mean_action_processing_ms": 0.25602676190576323, "mean_env_wait_ms": 0.21728726096731163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006738781929016113, "StateBufferConnector_ms": 0.00383913516998291, "ViewRequirementAgentConnector_ms": 0.0966329574584961}, "num_episodes": 18, "episode_return_max": 122.99999999999885, "episode_return_min": -587.2, "episode_return_mean": -12.553999999999949, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 431.78252132781824, "num_env_steps_trained_throughput_per_sec": 431.78252132781824, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 10657.917, "restore_workers_time_ms": 0.017, "training_step_time_ms": 10657.86, "sample_time_ms": 1420.165, "learn_time_ms": 9220.596, "learn_throughput": 433.811, "synch_weights_time_ms": 15.5}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-03-17", "timestamp": 1723644197, "time_this_iter_s": 9.26794695854187, "time_total_s": 64.05936741828918, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31876cee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 64.05936741828918, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 29.476923076923075, "ram_util_percent": 81.64615384615385}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.352726235433861, "cur_kl_coeff": 1.5187500000000005, "cur_lr": 0.009999999999999998, "total_loss": 4.15048069928689, "policy_loss": 0.0063809831927298865, "vf_loss": 4.10293709840724, "vf_explained_var": 0.19002900028985645, "kl": 0.02710295438989147, "entropy": 1.164434315824004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.5850184040883235, "cur_kl_coeff": 2.278124999999999, "cur_lr": 0.009999999999999998, "total_loss": 6.097119275098125, "policy_loss": 0.006144535996108537, "vf_loss": 6.045252362760917, "vf_explained_var": 0.002927516187940325, "kl": 0.020070168453209577, "entropy": 1.3204373773443636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 80.09999999999933, "episode_reward_min": -587.2, "episode_reward_mean": -50.51599999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -680.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.20000000000018, "predator_policy": 596.0}, "policy_reward_mean": {"prey_policy": -70.14800000000002, "predator_policy": 44.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-61.800000000001674, 37.40000000000026, 56.400000000000425, 66.00000000000028, 30.000000000000146, 16.799999999999986, 53.70000000000042, -4.000000000000027, -6.199999999999667, -225.40000000000055, 17.199999999999964, 17.50000000000011, 40.70000000000031, -43.000000000000256, 45.800000000000395, 44.70000000000038, 55.20000000000046, 74.29999999999967, 54.400000000000446, 33.800000000000274, 9.400000000000112, 27.2000000000001, -60.400000000000105, -170.80000000000047, -29.999999999999524, 33.3000000000002, -181.20000000000005, -92.60000000000002, 51.9000000000005, 16.399999999999935, 52.50000000000043, 40.70000000000031, -43.09999999999987, -67.80000000000001, 80.09999999999933, 54.60000000000048, -359.199999999999, -371.80000000000007, 34.200000000000216, 23.300000000000026, 53.60000000000037, 48.70000000000045, 67.80000000000015, -234.5999999999999, -257.99999999999886, 13.500000000000012, 74.69999999999969, 61.30000000000047, 54.800000000000445, -155.40000000000015, 41.70000000000037, 10.099999999999978, 11.800000000000047, 27.900000000000105, -366.5, 45.8000000000004, 77.59999999999953, 33.2000000000002, 54.80000000000045, 32.10000000000018, -28.399999999999558, 53.10000000000051, 42.60000000000034, -27.799999999999542, 72.79999999999977, 3.2000000000000526, 40.80000000000031, 41.400000000000325, 11.400000000000041, 15.699999999999934, -493.6, 69.70000000000007, 22.000000000000007, 29.000000000000124, -25.59999999999951, 11.100000000000014, -79.70000000000113, 36.40000000000025, -587.2, 33.2000000000002, 44.50000000000039, 11.000000000000078, -277.6999999999999, 71.5999999999999, -504.0, -383.0, 16.299999999999933, -14.499999999999723, -342.8000000000003, -385.09999999999997, -448.4, -331.7, 63.00000000000046, 5.099999999999953, 64.10000000000043, -451.79999999999995, -465.99999999999994, 65.40000000000039, 37.30000000000026, -110.09999999999988], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-68.20000000000086, -46.59999999999977, 21.80000000000004, 11.599999999999964, 13.399999999999979, 20.000000000000014, 2.599999999999975, 25.4000000000001, -0.9999999999999846, 20.000000000000014, -1.8999999999999853, -7.299999999999891, 30.8000000000002, 5.899999999999994, -64.00000000000001, 20.000000000000014, -28.29999999999975, -19.899999999999743, -245.10000000000042, -133.30000000000027, -4.299999999999962, -11.499999999999819, 3.1999999999999615, -63.70000000000065, 20.000000000000014, 13.699999999999967, -42.99999999999976, -64.00000000000088, 38.000000000000256, -5.1999999999999265, -6.999999999999956, 7.700000000000022, 15.499999999999961, 25.700000000000106, 60.20000000000018, 1.0999999999999617, -9.399999999999855, 39.80000000000022, 3.5000000000000084, -0.6999999999999993, -9.399999999999855, -5.1999999999999265, -17.79999999999974, 20.000000000000014, -108.10000000000035, -28.299999999999976, -99.6999999999999, -195.1000000000006, -34.59999999999975, -51.39999999999988, 30.800000000000196, -32.49999999999975, -295.30000000000064, -194.90000000000003, -85.29999999999993, -112.29999999999998, 28.100000000000147, 15.799999999999962, -56.80000000000038, 27.200000000000145, 39.50000000000021, -0.9999999999999846, -5.19999999999993, 29.90000000000018, -93.40000000000069, -57.70000000000048, 20.000000000000014, -185.79999999999998, 53.30000000000023, 15.79999999999996, 15.799999999999963, 30.800000000000203, -219.0000000000002, -400.1999999999996, -366.1, -295.70000000000005, 20.000000000000014, 3.1999999999999615, -8.499999999999872, 15.799999999999963, 29.60000000000017, 20.000000000000014, 22.700000000000056, 20.000000000000014, 53.3000000000002, 9.49999999999997, -258.9999999999999, -197.60000000000002, -181.60000000000036, -219.40000000000038, -32.49999999999975, 20.000000000000014, -5.1999999999999265, 56.90000000000021, 20.000000000000014, 35.30000000000023, 3.1999999999999686, 35.60000000000022, -146.8, -139.60000000000068, 19.700000000000024, -0.9999999999999846, -31.59999999999983, -133.30000000000072, -7.5999999999998895, -1.6000000000000032, 11.599999999999964, 5.299999999999965, -448.9, -234.60000000000002, 5.299999999999965, 24.500000000000092, 32.60000000000023, 44.000000000000234, -17.79999999999974, 20.000000000000014, 20.000000000000014, 12.799999999999972, 4.099999999999966, 20.000000000000014, -17.79999999999974, -118.60000000000073, 25.100000000000097, 20.000000000000014, -7.299999999999891, 2.899999999999972, -83.2000000000007, -13.599999999999783, 1.0999999999999865, 55.70000000000018, 20.000000000000014, -56.80000000000024, 2.900000000000002, 17.899999999999988, 13.399999999999965, 20.000000000000014, 20.000000000000014, -34.59999999999975, 28.400000000000162, -57.70000000000048, -313.2, -387.4, 42.50000000000023, 24.20000000000008, -21.999999999999744, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -30.39999999999975, -41.19999999999977, -72.40000000000089, 0.49999999999996525, -103.90000000000057, -59.80000000000025, 18.799999999999997, 2.599999999999961, -680.0, -531.2, 5.299999999999965, 17.899999999999988, -19.899999999999743, 37.40000000000022, 3.199999999999965, -5.1999999999999265, -268.19999999999976, -274.4999999999999, 20.000000000000014, 38.6000000000002, -560.0, -468.0, -265.19999999999993, -427.8, -25.299999999999834, -9.399999999999869, -67.60000000000056, 1.0999999999999652, -244.60000000000022, -272.20000000000016, -210.09999999999997, -456.0, -359.3, -398.1, -360.0, -299.69999999999993, 24.200000000000085, 24.8000000000001, -67.90000000000055, 10.999999999999966, 19.700000000000024, 31.40000000000021, -539.4, -438.4, -401.9, -347.09999999999997, 23.600000000000072, 30.800000000000203, 20.000000000000014, 5.299999999999965, -389.9, -362.2000000000001], "policy_predator_policy_reward": [9.0, 44.0, 4.0, 0.0, 16.0, 7.0, 24.0, 14.0, 1.0, 10.0, 13.0, 13.0, 14.0, 3.0, 0.0, 40.0, 26.0, 16.0, 0.0, 153.0, 8.0, 25.0, 44.0, 34.0, 6.0, 1.0, 31.0, 33.0, 12.0, 1.0, 24.0, 20.0, 8.0, 6.0, 9.0, 4.0, 10.0, 14.0, 19.0, 12.0, 10.0, 14.0, 17.0, 8.0, 8.0, 68.0, 113.0, 11.0, 19.0, 37.0, 25.0, 10.0, 18.0, 291.0, 9.0, 96.0, 8.0, 0.0, 37.0, 9.0, 10.0, 4.0, 4.0, 12.0, 53.0, 55.0, 0.0, 98.0, 11.0, 0.0, 6.0, 2.0, 8.0, 252.0, 289.0, 1.0, 8.0, 3.0, 2.0, 14.0, 4.0, 0.0, 6.0, 0.0, 5.0, 0.0, 41.0, 181.0, 1.0, 142.0, 25.0, 1.0, 12.0, 11.0, 0.0, 6.0, 6.0, 10.0, 31.0, 100.0, 13.0, 10.0, 79.0, 96.0, 17.0, 4.0, 4.0, 7.0, 306.0, 11.0, 9.0, 7.0, 1.0, 0.0, 17.0, 14.0, 7.0, 15.0, 8.0, 0.0, 66.0, 42.0, 4.0, 4.0, 24.0, 23.0, 16.0, 53.0, 9.0, 7.0, 34.0, 6.0, 14.0, 6.0, 4.0, 4.0, 0.0, 26.0, 8.0, 37.0, 4.0, 203.0, 3.0, 0.0, 17.0, 7.0, 8.0, 2.0, 39.0, 7.0, 41.0, 42.0, 62.0, 22.0, 5.0, 10.0, 596.0, 28.0, 3.0, 7.0, 19.0, 8.0, 1.0, 12.0, 199.0, 66.0, 5.0, 8.0, 524.0, 0.0, 243.0, 67.0, 29.0, 22.0, 9.0, 43.0, 9.0, 165.0, 18.0, 263.0, 17.0, 292.0, 3.0, 325.0, 3.0, 11.0, 48.0, 14.0, 13.0, 0.0, 518.0, 8.0, 1.0, 282.0, 5.0, 6.0, 7.0, 5.0, 309.0, 333.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.611147359293345, "mean_inference_ms": 1.9660733412122706, "mean_action_processing_ms": 0.2519675737768657, "mean_env_wait_ms": 0.21286090451010242, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006006717681884766, "StateBufferConnector_ms": 0.0037529468536376953, "ViewRequirementAgentConnector_ms": 0.09482800960540771}, "num_episodes": 18, "episode_return_max": 80.09999999999933, "episode_return_min": -587.2, "episode_return_mean": -50.51599999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 396.9600308724313, "num_env_steps_trained_throughput_per_sec": 396.9600308724313, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 10574.87, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10574.814, "sample_time_ms": 1389.191, "learn_time_ms": 9168.431, "learn_throughput": 436.28, "synch_weights_time_ms": 15.21}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-03-28", "timestamp": 1723644208, "time_this_iter_s": 10.10417628288269, "time_total_s": 74.16354370117188, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31876c8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 74.16354370117188, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 32.15714285714286, "ram_util_percent": 81.75000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.594003175238453, "cur_kl_coeff": 2.278124999999999, "cur_lr": 0.009999999999999998, "total_loss": 4.740286365766374, "policy_loss": 0.0020893925046991733, "vf_loss": 4.69301194917588, "vf_explained_var": 0.12140266898447874, "kl": 0.019834297102529225, "entropy": 1.2751554250717163, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.360164493984646, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.980730606513049, "policy_loss": 0.0035065910308350805, "vf_loss": 5.925879792561607, "vf_explained_var": 0.0005221835519901659, "kl": 0.01502528115557972, "entropy": 1.3490688305683236, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 80.09999999999933, "episode_reward_min": -587.2, "episode_reward_mean": -73.70299999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -680.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 56.90000000000021, "predator_policy": 596.0}, "policy_reward_mean": {"prey_policy": -96.66650000000001, "predator_policy": 59.815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.400000000000446, 33.800000000000274, 9.400000000000112, 27.2000000000001, -60.400000000000105, -170.80000000000047, -29.999999999999524, 33.3000000000002, -181.20000000000005, -92.60000000000002, 51.9000000000005, 16.399999999999935, 52.50000000000043, 40.70000000000031, -43.09999999999987, -67.80000000000001, 80.09999999999933, 54.60000000000048, -359.199999999999, -371.80000000000007, 34.200000000000216, 23.300000000000026, 53.60000000000037, 48.70000000000045, 67.80000000000015, -234.5999999999999, -257.99999999999886, 13.500000000000012, 74.69999999999969, 61.30000000000047, 54.800000000000445, -155.40000000000015, 41.70000000000037, 10.099999999999978, 11.800000000000047, 27.900000000000105, -366.5, 45.8000000000004, 77.59999999999953, 33.2000000000002, 54.80000000000045, 32.10000000000018, -28.399999999999558, 53.10000000000051, 42.60000000000034, -27.799999999999542, 72.79999999999977, 3.2000000000000526, 40.80000000000031, 41.400000000000325, 11.400000000000041, 15.699999999999934, -493.6, 69.70000000000007, 22.000000000000007, 29.000000000000124, -25.59999999999951, 11.100000000000014, -79.70000000000113, 36.40000000000025, -587.2, 33.2000000000002, 44.50000000000039, 11.000000000000078, -277.6999999999999, 71.5999999999999, -504.0, -383.0, 16.299999999999933, -14.499999999999723, -342.8000000000003, -385.09999999999997, -448.4, -331.7, 63.00000000000046, 5.099999999999953, 64.10000000000043, -451.79999999999995, -465.99999999999994, 65.40000000000039, 37.30000000000026, -110.09999999999988, -82.60000000000039, 53.2000000000005, 48.80000000000046, -259.1000000000004, -469.4, -342.0, 30.000000000000192, -59.49999999999969, -366.69999999999993, 11.400000000000048, 52.100000000000406, -414.09999999999957, -245.39999999999998, 36.100000000000364, 58.20000000000047, 28.600000000000136, -170.00000000000094, -12.999999999999671], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.399999999999855, 39.80000000000022, 3.5000000000000084, -0.6999999999999993, -9.399999999999855, -5.1999999999999265, -17.79999999999974, 20.000000000000014, -108.10000000000035, -28.299999999999976, -99.6999999999999, -195.1000000000006, -34.59999999999975, -51.39999999999988, 30.800000000000196, -32.49999999999975, -295.30000000000064, -194.90000000000003, -85.29999999999993, -112.29999999999998, 28.100000000000147, 15.799999999999962, -56.80000000000038, 27.200000000000145, 39.50000000000021, -0.9999999999999846, -5.19999999999993, 29.90000000000018, -93.40000000000069, -57.70000000000048, 20.000000000000014, -185.79999999999998, 53.30000000000023, 15.79999999999996, 15.799999999999963, 30.800000000000203, -219.0000000000002, -400.1999999999996, -366.1, -295.70000000000005, 20.000000000000014, 3.1999999999999615, -8.499999999999872, 15.799999999999963, 29.60000000000017, 20.000000000000014, 22.700000000000056, 20.000000000000014, 53.3000000000002, 9.49999999999997, -258.9999999999999, -197.60000000000002, -181.60000000000036, -219.40000000000038, -32.49999999999975, 20.000000000000014, -5.1999999999999265, 56.90000000000021, 20.000000000000014, 35.30000000000023, 3.1999999999999686, 35.60000000000022, -146.8, -139.60000000000068, 19.700000000000024, -0.9999999999999846, -31.59999999999983, -133.30000000000072, -7.5999999999998895, -1.6000000000000032, 11.599999999999964, 5.299999999999965, -448.9, -234.60000000000002, 5.299999999999965, 24.500000000000092, 32.60000000000023, 44.000000000000234, -17.79999999999974, 20.000000000000014, 20.000000000000014, 12.799999999999972, 4.099999999999966, 20.000000000000014, -17.79999999999974, -118.60000000000073, 25.100000000000097, 20.000000000000014, -7.299999999999891, 2.899999999999972, -83.2000000000007, -13.599999999999783, 1.0999999999999865, 55.70000000000018, 20.000000000000014, -56.80000000000024, 2.900000000000002, 17.899999999999988, 13.399999999999965, 20.000000000000014, 20.000000000000014, -34.59999999999975, 28.400000000000162, -57.70000000000048, -313.2, -387.4, 42.50000000000023, 24.20000000000008, -21.999999999999744, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -30.39999999999975, -41.19999999999977, -72.40000000000089, 0.49999999999996525, -103.90000000000057, -59.80000000000025, 18.799999999999997, 2.599999999999961, -680.0, -531.2, 5.299999999999965, 17.899999999999988, -19.899999999999743, 37.40000000000022, 3.199999999999965, -5.1999999999999265, -268.19999999999976, -274.4999999999999, 20.000000000000014, 38.6000000000002, -560.0, -468.0, -265.19999999999993, -427.8, -25.299999999999834, -9.399999999999869, -67.60000000000056, 1.0999999999999652, -244.60000000000022, -272.20000000000016, -210.09999999999997, -456.0, -359.3, -398.1, -360.0, -299.69999999999993, 24.200000000000085, 24.8000000000001, -67.90000000000055, 10.999999999999966, 19.700000000000024, 31.40000000000021, -539.4, -438.4, -401.9, -347.09999999999997, 23.600000000000072, 30.800000000000203, 20.000000000000014, 5.299999999999965, -389.9, -362.2000000000001, -32.50000000000004, -171.10000000000042, 7.399999999999965, 39.80000000000025, 9.799999999999974, 20.000000000000014, -294.9000000000001, -236.20000000000036, -456.4, -528.0, -385.3, -380.7, 5.899999999999988, 1.0999999999999865, -127.00000000000074, -119.50000000000001, -483.20000000000005, -340.5, -34.59999999999975, 20.000000000000014, 24.50000000000009, 14.599999999999987, -337.3999999999995, -485.70000000000005, -531.0, -609.4, -19.899999999999743, 7.999999999999984, 23.000000000000064, 15.199999999999964, 41.60000000000025, -42.99999999999976, -200.50000000000054, -113.4999999999999, -61.00000000000041, -0.9999999999999846], "policy_predator_policy_reward": [10.0, 14.0, 19.0, 12.0, 10.0, 14.0, 17.0, 8.0, 8.0, 68.0, 113.0, 11.0, 19.0, 37.0, 25.0, 10.0, 18.0, 291.0, 9.0, 96.0, 8.0, 0.0, 37.0, 9.0, 10.0, 4.0, 4.0, 12.0, 53.0, 55.0, 0.0, 98.0, 11.0, 0.0, 6.0, 2.0, 8.0, 252.0, 289.0, 1.0, 8.0, 3.0, 2.0, 14.0, 4.0, 0.0, 6.0, 0.0, 5.0, 0.0, 41.0, 181.0, 1.0, 142.0, 25.0, 1.0, 12.0, 11.0, 0.0, 6.0, 6.0, 10.0, 31.0, 100.0, 13.0, 10.0, 79.0, 96.0, 17.0, 4.0, 4.0, 7.0, 306.0, 11.0, 9.0, 7.0, 1.0, 0.0, 17.0, 14.0, 7.0, 15.0, 8.0, 0.0, 66.0, 42.0, 4.0, 4.0, 24.0, 23.0, 16.0, 53.0, 9.0, 7.0, 34.0, 6.0, 14.0, 6.0, 4.0, 4.0, 0.0, 26.0, 8.0, 37.0, 4.0, 203.0, 3.0, 0.0, 17.0, 7.0, 8.0, 2.0, 39.0, 7.0, 41.0, 42.0, 62.0, 22.0, 5.0, 10.0, 596.0, 28.0, 3.0, 7.0, 19.0, 8.0, 1.0, 12.0, 199.0, 66.0, 5.0, 8.0, 524.0, 0.0, 243.0, 67.0, 29.0, 22.0, 9.0, 43.0, 9.0, 165.0, 18.0, 263.0, 17.0, 292.0, 3.0, 325.0, 3.0, 11.0, 48.0, 14.0, 13.0, 0.0, 518.0, 8.0, 1.0, 282.0, 5.0, 6.0, 7.0, 5.0, 309.0, 333.0, 22.0, 99.0, 0.0, 6.0, 6.0, 13.0, 161.0, 111.0, 0.0, 515.0, 217.0, 207.0, 14.0, 9.0, 117.0, 70.0, 449.0, 8.0, 26.0, 0.0, 9.0, 4.0, 398.0, 11.0, 490.0, 405.0, 11.0, 37.0, 7.0, 13.0, 26.0, 4.0, 139.0, 5.0, 10.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6035058554531547, "mean_inference_ms": 1.9325429484756667, "mean_action_processing_ms": 0.2492063628349451, "mean_env_wait_ms": 0.20874675912913118, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005221247673034668, "StateBufferConnector_ms": 0.003737330436706543, "ViewRequirementAgentConnector_ms": 0.09567141532897949}, "num_episodes": 18, "episode_return_max": 80.09999999999933, "episode_return_min": -587.2, "episode_return_mean": -73.70299999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.84836839430903, "num_env_steps_trained_throughput_per_sec": 398.84836839430903, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 10506.621, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10506.568, "sample_time_ms": 1401.316, "learn_time_ms": 9088.431, "learn_throughput": 440.12, "synch_weights_time_ms": 15.006}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-03-38", "timestamp": 1723644218, "time_this_iter_s": 10.033429861068726, "time_total_s": 84.1969735622406, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31877e700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 84.1969735622406, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 32.17333333333333, "ram_util_percent": 82.48666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7378796806726506, "cur_kl_coeff": 2.278124999999999, "cur_lr": 0.009999999999999998, "total_loss": 4.053072149160678, "policy_loss": 0.0015704749742148335, "vf_loss": 4.0160307042813175, "vf_explained_var": 0.25052749561885046, "kl": 0.015570241045529, "entropy": 1.2406601129385528, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.575034105746203, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.438201746360335, "policy_loss": 0.0021633946783988487, "vf_loss": 5.394939906761129, "vf_explained_var": -0.0001993932421245272, "kl": 0.012026975982242212, "entropy": 1.2521431699631707, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 77.59999999999953, "episode_reward_min": -587.2, "episode_reward_mean": -97.84699999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -764.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 56.90000000000021, "predator_policy": 689.0}, "policy_reward_mean": {"prey_policy": -127.95350000000002, "predator_policy": 79.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [53.60000000000037, 48.70000000000045, 67.80000000000015, -234.5999999999999, -257.99999999999886, 13.500000000000012, 74.69999999999969, 61.30000000000047, 54.800000000000445, -155.40000000000015, 41.70000000000037, 10.099999999999978, 11.800000000000047, 27.900000000000105, -366.5, 45.8000000000004, 77.59999999999953, 33.2000000000002, 54.80000000000045, 32.10000000000018, -28.399999999999558, 53.10000000000051, 42.60000000000034, -27.799999999999542, 72.79999999999977, 3.2000000000000526, 40.80000000000031, 41.400000000000325, 11.400000000000041, 15.699999999999934, -493.6, 69.70000000000007, 22.000000000000007, 29.000000000000124, -25.59999999999951, 11.100000000000014, -79.70000000000113, 36.40000000000025, -587.2, 33.2000000000002, 44.50000000000039, 11.000000000000078, -277.6999999999999, 71.5999999999999, -504.0, -383.0, 16.299999999999933, -14.499999999999723, -342.8000000000003, -385.09999999999997, -448.4, -331.7, 63.00000000000046, 5.099999999999953, 64.10000000000043, -451.79999999999995, -465.99999999999994, 65.40000000000039, 37.30000000000026, -110.09999999999988, -82.60000000000039, 53.2000000000005, 48.80000000000046, -259.1000000000004, -469.4, -342.0, 30.000000000000192, -59.49999999999969, -366.69999999999993, 11.400000000000048, 52.100000000000406, -414.09999999999957, -245.39999999999998, 36.100000000000364, 58.20000000000047, 28.600000000000136, -170.00000000000094, -12.999999999999671, -314.90000000000003, 28.800000000000132, -129.00000000000057, -479.5, -448.79999999999995, 69.50000000000009, 49.30000000000046, 32.60000000000019, -395.7999999999987, 38.8, -74.2999999999997, -51.3000000000005, -276.9, -130.30000000000086, 26.5000000000001, -21.59999999999951, -254.3, -239.2000000000004, -156.7999999999999, -533.9, 17.99999999999999, -36.39999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.60000000000017, 20.000000000000014, 22.700000000000056, 20.000000000000014, 53.3000000000002, 9.49999999999997, -258.9999999999999, -197.60000000000002, -181.60000000000036, -219.40000000000038, -32.49999999999975, 20.000000000000014, -5.1999999999999265, 56.90000000000021, 20.000000000000014, 35.30000000000023, 3.1999999999999686, 35.60000000000022, -146.8, -139.60000000000068, 19.700000000000024, -0.9999999999999846, -31.59999999999983, -133.30000000000072, -7.5999999999998895, -1.6000000000000032, 11.599999999999964, 5.299999999999965, -448.9, -234.60000000000002, 5.299999999999965, 24.500000000000092, 32.60000000000023, 44.000000000000234, -17.79999999999974, 20.000000000000014, 20.000000000000014, 12.799999999999972, 4.099999999999966, 20.000000000000014, -17.79999999999974, -118.60000000000073, 25.100000000000097, 20.000000000000014, -7.299999999999891, 2.899999999999972, -83.2000000000007, -13.599999999999783, 1.0999999999999865, 55.70000000000018, 20.000000000000014, -56.80000000000024, 2.900000000000002, 17.899999999999988, 13.399999999999965, 20.000000000000014, 20.000000000000014, -34.59999999999975, 28.400000000000162, -57.70000000000048, -313.2, -387.4, 42.50000000000023, 24.20000000000008, -21.999999999999744, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -30.39999999999975, -41.19999999999977, -72.40000000000089, 0.49999999999996525, -103.90000000000057, -59.80000000000025, 18.799999999999997, 2.599999999999961, -680.0, -531.2, 5.299999999999965, 17.899999999999988, -19.899999999999743, 37.40000000000022, 3.199999999999965, -5.1999999999999265, -268.19999999999976, -274.4999999999999, 20.000000000000014, 38.6000000000002, -560.0, -468.0, -265.19999999999993, -427.8, -25.299999999999834, -9.399999999999869, -67.60000000000056, 1.0999999999999652, -244.60000000000022, -272.20000000000016, -210.09999999999997, -456.0, -359.3, -398.1, -360.0, -299.69999999999993, 24.200000000000085, 24.8000000000001, -67.90000000000055, 10.999999999999966, 19.700000000000024, 31.40000000000021, -539.4, -438.4, -401.9, -347.09999999999997, 23.600000000000072, 30.800000000000203, 20.000000000000014, 5.299999999999965, -389.9, -362.2000000000001, -32.50000000000004, -171.10000000000042, 7.399999999999965, 39.80000000000025, 9.799999999999974, 20.000000000000014, -294.9000000000001, -236.20000000000036, -456.4, -528.0, -385.3, -380.7, 5.899999999999988, 1.0999999999999865, -127.00000000000074, -119.50000000000001, -483.20000000000005, -340.5, -34.59999999999975, 20.000000000000014, 24.50000000000009, 14.599999999999987, -337.3999999999995, -485.70000000000005, -531.0, -609.4, -19.899999999999743, 7.999999999999984, 23.000000000000064, 15.199999999999964, 41.60000000000025, -42.99999999999976, -200.50000000000054, -113.4999999999999, -61.00000000000041, -0.9999999999999846, -303.6999999999996, -203.20000000000027, 13.699999999999964, -4.899999999999956, -92.50000000000031, -200.50000000000045, -382.0, -413.5, -424.0, -547.8, 30.200000000000195, 26.300000000000114, 23.300000000000065, 20.000000000000014, 14.599999999999964, 1.9999999999999643, -315.99999999999966, -302.79999999999905, -332.8000000000002, -343.40000000000003, -194.20000000000056, 17.899999999999977, -141.7000000000007, 7.399999999999965, -102.09999999999988, -353.79999999999995, -284.5000000000003, -17.79999999999995, -49.299999999999905, 39.80000000000025, -3.099999999999958, -74.50000000000085, -274.6, -764.7, -223.60000000000008, -181.60000000000036, -714.7, -559.1, -400.0, -648.9, 3.1999999999999615, -5.199999999999934, -162.8, 7.399999999999965], "policy_predator_policy_reward": [4.0, 0.0, 6.0, 0.0, 5.0, 0.0, 41.0, 181.0, 1.0, 142.0, 25.0, 1.0, 12.0, 11.0, 0.0, 6.0, 6.0, 10.0, 31.0, 100.0, 13.0, 10.0, 79.0, 96.0, 17.0, 4.0, 4.0, 7.0, 306.0, 11.0, 9.0, 7.0, 1.0, 0.0, 17.0, 14.0, 7.0, 15.0, 8.0, 0.0, 66.0, 42.0, 4.0, 4.0, 24.0, 23.0, 16.0, 53.0, 9.0, 7.0, 34.0, 6.0, 14.0, 6.0, 4.0, 4.0, 0.0, 26.0, 8.0, 37.0, 4.0, 203.0, 3.0, 0.0, 17.0, 7.0, 8.0, 2.0, 39.0, 7.0, 41.0, 42.0, 62.0, 22.0, 5.0, 10.0, 596.0, 28.0, 3.0, 7.0, 19.0, 8.0, 1.0, 12.0, 199.0, 66.0, 5.0, 8.0, 524.0, 0.0, 243.0, 67.0, 29.0, 22.0, 9.0, 43.0, 9.0, 165.0, 18.0, 263.0, 17.0, 292.0, 3.0, 325.0, 3.0, 11.0, 48.0, 14.0, 13.0, 0.0, 518.0, 8.0, 1.0, 282.0, 5.0, 6.0, 7.0, 5.0, 309.0, 333.0, 22.0, 99.0, 0.0, 6.0, 6.0, 13.0, 161.0, 111.0, 0.0, 515.0, 217.0, 207.0, 14.0, 9.0, 117.0, 70.0, 449.0, 8.0, 26.0, 0.0, 9.0, 4.0, 398.0, 11.0, 490.0, 405.0, 11.0, 37.0, 7.0, 13.0, 26.0, 4.0, 139.0, 5.0, 10.0, 39.0, 16.0, 176.0, 9.0, 11.0, 66.0, 98.0, 13.0, 303.0, 251.0, 272.0, 5.0, 8.0, 4.0, 2.0, 1.0, 15.0, 177.0, 46.0, 341.0, 374.0, 102.0, 0.0, 77.0, 6.0, 178.0, 1.0, 103.0, 69.0, 33.0, 3.0, 11.0, 45.0, 166.0, 619.0, 11.0, 155.0, 428.0, 689.0, 9.0, 506.0, 12.0, 8.0, 21.0, 98.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5955602552827406, "mean_inference_ms": 1.9004763578075676, "mean_action_processing_ms": 0.24625435310325947, "mean_env_wait_ms": 0.20442228619074101, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046024322509765625, "StateBufferConnector_ms": 0.0036858320236206055, "ViewRequirementAgentConnector_ms": 0.09413540363311768}, "num_episodes": 22, "episode_return_max": 77.59999999999953, "episode_return_min": -587.2, "episode_return_mean": -97.84699999999988, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 434.5143370921262, "num_env_steps_trained_throughput_per_sec": 434.5143370921262, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 10362.073, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10362.02, "sample_time_ms": 1384.613, "learn_time_ms": 8960.587, "learn_throughput": 446.399, "synch_weights_time_ms": 15.099}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-03-47", "timestamp": 1723644227, "time_this_iter_s": 9.214343309402466, "time_total_s": 93.41131687164307, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31877e8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 93.41131687164307, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 30.615384615384617, "ram_util_percent": 82.41538461538461}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.2141917868896765, "cur_kl_coeff": 2.278124999999999, "cur_lr": 0.009999999999999998, "total_loss": 3.381601083467877, "policy_loss": 0.002253672440792557, "vf_loss": 3.3316018273590733, "vf_explained_var": 0.21453000209318898, "kl": 0.020958279437491702, "entropy": 1.3162729477756239, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.422649888986002, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.383499246299582, "policy_loss": 0.0036421028571942495, "vf_loss": 4.329180858501051, "vf_explained_var": 0.0011604897875003713, "kl": 0.014829824871447359, "entropy": 1.303091306219656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 74.99999999999964, "episode_reward_min": -587.2, "episode_reward_mean": -115.00799999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -764.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 55.70000000000018, "predator_policy": 689.0}, "policy_reward_mean": {"prey_policy": -143.96400000000003, "predator_policy": 86.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.799999999999542, 72.79999999999977, 3.2000000000000526, 40.80000000000031, 41.400000000000325, 11.400000000000041, 15.699999999999934, -493.6, 69.70000000000007, 22.000000000000007, 29.000000000000124, -25.59999999999951, 11.100000000000014, -79.70000000000113, 36.40000000000025, -587.2, 33.2000000000002, 44.50000000000039, 11.000000000000078, -277.6999999999999, 71.5999999999999, -504.0, -383.0, 16.299999999999933, -14.499999999999723, -342.8000000000003, -385.09999999999997, -448.4, -331.7, 63.00000000000046, 5.099999999999953, 64.10000000000043, -451.79999999999995, -465.99999999999994, 65.40000000000039, 37.30000000000026, -110.09999999999988, -82.60000000000039, 53.2000000000005, 48.80000000000046, -259.1000000000004, -469.4, -342.0, 30.000000000000192, -59.49999999999969, -366.69999999999993, 11.400000000000048, 52.100000000000406, -414.09999999999957, -245.39999999999998, 36.100000000000364, 58.20000000000047, 28.600000000000136, -170.00000000000094, -12.999999999999671, -314.90000000000003, 28.800000000000132, -129.00000000000057, -479.5, -448.79999999999995, 69.50000000000009, 49.30000000000046, 32.60000000000019, -395.7999999999987, 38.8, -74.2999999999997, -51.3000000000005, -276.9, -130.30000000000086, 26.5000000000001, -21.59999999999951, -254.3, -239.2000000000004, -156.7999999999999, -533.9, 17.99999999999999, -36.39999999999976, 63.200000000000486, 49.100000000000456, 27.100000000000087, -23.299999999999965, 44.800000000000395, 38.90000000000039, -20.79999999999979, -469.19999999999993, 35.20000000000023, -186.20000000000016, -65.30000000000035, -536.1, 74.99999999999964, 32.00000000000018, 59.2000000000005, -170.39999999999975, 29.200000000000138, -399.4, -185.70000000000084, 47.80000000000043, 47.700000000000436, 38.50000000000028, -485.20000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-83.2000000000007, -13.599999999999783, 1.0999999999999865, 55.70000000000018, 20.000000000000014, -56.80000000000024, 2.900000000000002, 17.899999999999988, 13.399999999999965, 20.000000000000014, 20.000000000000014, -34.59999999999975, 28.400000000000162, -57.70000000000048, -313.2, -387.4, 42.50000000000023, 24.20000000000008, -21.999999999999744, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -30.39999999999975, -41.19999999999977, -72.40000000000089, 0.49999999999996525, -103.90000000000057, -59.80000000000025, 18.799999999999997, 2.599999999999961, -680.0, -531.2, 5.299999999999965, 17.899999999999988, -19.899999999999743, 37.40000000000022, 3.199999999999965, -5.1999999999999265, -268.19999999999976, -274.4999999999999, 20.000000000000014, 38.6000000000002, -560.0, -468.0, -265.19999999999993, -427.8, -25.299999999999834, -9.399999999999869, -67.60000000000056, 1.0999999999999652, -244.60000000000022, -272.20000000000016, -210.09999999999997, -456.0, -359.3, -398.1, -360.0, -299.69999999999993, 24.200000000000085, 24.8000000000001, -67.90000000000055, 10.999999999999966, 19.700000000000024, 31.40000000000021, -539.4, -438.4, -401.9, -347.09999999999997, 23.600000000000072, 30.800000000000203, 20.000000000000014, 5.299999999999965, -389.9, -362.2000000000001, -32.50000000000004, -171.10000000000042, 7.399999999999965, 39.80000000000025, 9.799999999999974, 20.000000000000014, -294.9000000000001, -236.20000000000036, -456.4, -528.0, -385.3, -380.7, 5.899999999999988, 1.0999999999999865, -127.00000000000074, -119.50000000000001, -483.20000000000005, -340.5, -34.59999999999975, 20.000000000000014, 24.50000000000009, 14.599999999999987, -337.3999999999995, -485.70000000000005, -531.0, -609.4, -19.899999999999743, 7.999999999999984, 23.000000000000064, 15.199999999999964, 41.60000000000025, -42.99999999999976, -200.50000000000054, -113.4999999999999, -61.00000000000041, -0.9999999999999846, -303.6999999999996, -203.20000000000027, 13.699999999999964, -4.899999999999956, -92.50000000000031, -200.50000000000045, -382.0, -413.5, -424.0, -547.8, 30.200000000000195, 26.300000000000114, 23.300000000000065, 20.000000000000014, 14.599999999999964, 1.9999999999999643, -315.99999999999966, -302.79999999999905, -332.8000000000002, -343.40000000000003, -194.20000000000056, 17.899999999999977, -141.7000000000007, 7.399999999999965, -102.09999999999988, -353.79999999999995, -284.5000000000003, -17.79999999999995, -49.299999999999905, 39.80000000000025, -3.099999999999958, -74.50000000000085, -274.6, -764.7, -223.60000000000008, -181.60000000000036, -714.7, -559.1, -400.0, -648.9, 3.1999999999999615, -5.199999999999934, -162.8, 7.399999999999965, 23.600000000000065, 26.60000000000013, 5.299999999999965, 30.800000000000196, -1.6000000000000512, -7.299999999999891, -183.70000000000022, -13.599999999999783, 20.000000000000014, -8.199999999999902, -105.70000000000059, 20.600000000000026, -39.09999999999989, -36.699999999999754, -423.2, -499.0, 20.000000000000014, 3.1999999999999615, -64.90000000000003, -394.29999999999995, -136.00000000000009, -28.299999999999862, -424.0, -381.1, 20.000000000000014, 41.0000000000002, -0.9999999999999846, 20.000000000000014, 31.40000000000021, 21.80000000000004, -390.60000000000025, -125.80000000000004, 20.000000000000014, -17.79999999999974, -278.6, -421.8, -91.00000000000031, -249.70000000000036, 17.899999999999984, 20.900000000000027, 20.000000000000014, 4.699999999999976, 15.49999999999996, 20.000000000000014, -397.9, -492.29999999999995], "policy_predator_policy_reward": [16.0, 53.0, 9.0, 7.0, 34.0, 6.0, 14.0, 6.0, 4.0, 4.0, 0.0, 26.0, 8.0, 37.0, 4.0, 203.0, 3.0, 0.0, 17.0, 7.0, 8.0, 2.0, 39.0, 7.0, 41.0, 42.0, 62.0, 22.0, 5.0, 10.0, 596.0, 28.0, 3.0, 7.0, 19.0, 8.0, 1.0, 12.0, 199.0, 66.0, 5.0, 8.0, 524.0, 0.0, 243.0, 67.0, 29.0, 22.0, 9.0, 43.0, 9.0, 165.0, 18.0, 263.0, 17.0, 292.0, 3.0, 325.0, 3.0, 11.0, 48.0, 14.0, 13.0, 0.0, 518.0, 8.0, 1.0, 282.0, 5.0, 6.0, 7.0, 5.0, 309.0, 333.0, 22.0, 99.0, 0.0, 6.0, 6.0, 13.0, 161.0, 111.0, 0.0, 515.0, 217.0, 207.0, 14.0, 9.0, 117.0, 70.0, 449.0, 8.0, 26.0, 0.0, 9.0, 4.0, 398.0, 11.0, 490.0, 405.0, 11.0, 37.0, 7.0, 13.0, 26.0, 4.0, 139.0, 5.0, 10.0, 39.0, 16.0, 176.0, 9.0, 11.0, 66.0, 98.0, 13.0, 303.0, 251.0, 272.0, 5.0, 8.0, 4.0, 2.0, 1.0, 15.0, 177.0, 46.0, 341.0, 374.0, 102.0, 0.0, 77.0, 6.0, 178.0, 1.0, 103.0, 69.0, 33.0, 3.0, 11.0, 45.0, 166.0, 619.0, 11.0, 155.0, 428.0, 689.0, 9.0, 506.0, 12.0, 8.0, 21.0, 98.0, 8.0, 5.0, 7.0, 6.0, 28.0, 8.0, 76.0, 98.0, 14.0, 19.0, 66.0, 58.0, 35.0, 20.0, 373.0, 80.0, 4.0, 8.0, 271.0, 2.0, 2.0, 97.0, 227.0, 42.0, 11.0, 3.0, 10.0, 3.0, 2.0, 4.0, 272.0, 74.0, 18.0, 9.0, 295.0, 6.0, 152.0, 3.0, 7.0, 2.0, 8.0, 15.0, 0.0, 3.0, 39.0, 366.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5881153468711102, "mean_inference_ms": 1.8675526219740102, "mean_action_processing_ms": 0.24305657657518004, "mean_env_wait_ms": 0.200352316690873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036507844924926758, "StateBufferConnector_ms": 0.0031447410583496094, "ViewRequirementAgentConnector_ms": 0.0884392261505127}, "num_episodes": 23, "episode_return_max": 74.99999999999964, "episode_return_min": -587.2, "episode_return_mean": -115.00799999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 415.83007047952594, "num_env_steps_trained_throughput_per_sec": 415.83007047952594, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 10287.798, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10287.747, "sample_time_ms": 1368.783, "learn_time_ms": 8902.4, "learn_throughput": 449.317, "synch_weights_time_ms": 14.909}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-03-57", "timestamp": 1723644237, "time_this_iter_s": 9.625447034835815, "time_total_s": 103.03676390647888, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 103.03676390647888, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 29.707692307692312, "ram_util_percent": 82.22307692307693}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.088956988709313, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.063651451862678, "policy_loss": 0.00016892563536881455, "vf_loss": 4.020772916930063, "vf_explained_var": 0.22677587841553662, "kl": 0.01249846443481726, "entropy": 1.2047569120371784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.063555663161807, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.227606086756187, "policy_loss": 0.002822974508519841, "vf_loss": 5.175339872874911, "vf_explained_var": 0.0004481623097071572, "kl": 0.014468987486887233, "entropy": 1.374650495960599, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 74.99999999999964, "episode_reward_min": -536.1, "episode_reward_mean": -125.2779999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -764.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.60000000000025, "predator_policy": 689.0}, "policy_reward_mean": {"prey_policy": -163.794, "predator_policy": 101.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.000000000000078, -277.6999999999999, 71.5999999999999, -504.0, -383.0, 16.299999999999933, -14.499999999999723, -342.8000000000003, -385.09999999999997, -448.4, -331.7, 63.00000000000046, 5.099999999999953, 64.10000000000043, -451.79999999999995, -465.99999999999994, 65.40000000000039, 37.30000000000026, -110.09999999999988, -82.60000000000039, 53.2000000000005, 48.80000000000046, -259.1000000000004, -469.4, -342.0, 30.000000000000192, -59.49999999999969, -366.69999999999993, 11.400000000000048, 52.100000000000406, -414.09999999999957, -245.39999999999998, 36.100000000000364, 58.20000000000047, 28.600000000000136, -170.00000000000094, -12.999999999999671, -314.90000000000003, 28.800000000000132, -129.00000000000057, -479.5, -448.79999999999995, 69.50000000000009, 49.30000000000046, 32.60000000000019, -395.7999999999987, 38.8, -74.2999999999997, -51.3000000000005, -276.9, -130.30000000000086, 26.5000000000001, -21.59999999999951, -254.3, -239.2000000000004, -156.7999999999999, -533.9, 17.99999999999999, -36.39999999999976, 63.200000000000486, 49.100000000000456, 27.100000000000087, -23.299999999999965, 44.800000000000395, 38.90000000000039, -20.79999999999979, -469.19999999999993, 35.20000000000023, -186.20000000000016, -65.30000000000035, -536.1, 74.99999999999964, 32.00000000000018, 59.2000000000005, -170.39999999999975, 29.200000000000138, -399.4, -185.70000000000084, 47.80000000000043, 47.700000000000436, 38.50000000000028, -485.20000000000005, -327.00000000000045, -213.99999999999986, 38.80000000000028, 53.10000000000046, -89.00000000000081, -17.199999999999562, -25.09999999999973, -246.0, -27.399999999999586, 13.899999999999928, 54.00000000000048, 38.80000000000028, -170.80000000000095, -492.7999999999997, -260.8, -203.09999999999994, 19.099999999999984, 45.800000000000416], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.199999999999965, -5.1999999999999265, -268.19999999999976, -274.4999999999999, 20.000000000000014, 38.6000000000002, -560.0, -468.0, -265.19999999999993, -427.8, -25.299999999999834, -9.399999999999869, -67.60000000000056, 1.0999999999999652, -244.60000000000022, -272.20000000000016, -210.09999999999997, -456.0, -359.3, -398.1, -360.0, -299.69999999999993, 24.200000000000085, 24.8000000000001, -67.90000000000055, 10.999999999999966, 19.700000000000024, 31.40000000000021, -539.4, -438.4, -401.9, -347.09999999999997, 23.600000000000072, 30.800000000000203, 20.000000000000014, 5.299999999999965, -389.9, -362.2000000000001, -32.50000000000004, -171.10000000000042, 7.399999999999965, 39.80000000000025, 9.799999999999974, 20.000000000000014, -294.9000000000001, -236.20000000000036, -456.4, -528.0, -385.3, -380.7, 5.899999999999988, 1.0999999999999865, -127.00000000000074, -119.50000000000001, -483.20000000000005, -340.5, -34.59999999999975, 20.000000000000014, 24.50000000000009, 14.599999999999987, -337.3999999999995, -485.70000000000005, -531.0, -609.4, -19.899999999999743, 7.999999999999984, 23.000000000000064, 15.199999999999964, 41.60000000000025, -42.99999999999976, -200.50000000000054, -113.4999999999999, -61.00000000000041, -0.9999999999999846, -303.6999999999996, -203.20000000000027, 13.699999999999964, -4.899999999999956, -92.50000000000031, -200.50000000000045, -382.0, -413.5, -424.0, -547.8, 30.200000000000195, 26.300000000000114, 23.300000000000065, 20.000000000000014, 14.599999999999964, 1.9999999999999643, -315.99999999999966, -302.79999999999905, -332.8000000000002, -343.40000000000003, -194.20000000000056, 17.899999999999977, -141.7000000000007, 7.399999999999965, -102.09999999999988, -353.79999999999995, -284.5000000000003, -17.79999999999995, -49.299999999999905, 39.80000000000025, -3.099999999999958, -74.50000000000085, -274.6, -764.7, -223.60000000000008, -181.60000000000036, -714.7, -559.1, -400.0, -648.9, 3.1999999999999615, -5.199999999999934, -162.8, 7.399999999999965, 23.600000000000065, 26.60000000000013, 5.299999999999965, 30.800000000000196, -1.6000000000000512, -7.299999999999891, -183.70000000000022, -13.599999999999783, 20.000000000000014, -8.199999999999902, -105.70000000000059, 20.600000000000026, -39.09999999999989, -36.699999999999754, -423.2, -499.0, 20.000000000000014, 3.1999999999999615, -64.90000000000003, -394.29999999999995, -136.00000000000009, -28.299999999999862, -424.0, -381.1, 20.000000000000014, 41.0000000000002, -0.9999999999999846, 20.000000000000014, 31.40000000000021, 21.80000000000004, -390.60000000000025, -125.80000000000004, 20.000000000000014, -17.79999999999974, -278.6, -421.8, -91.00000000000031, -249.70000000000036, 17.899999999999984, 20.900000000000027, 20.000000000000014, 4.699999999999976, 15.49999999999996, 20.000000000000014, -397.9, -492.29999999999995, -352.0000000000002, -356.0000000000002, -213.3, -326.70000000000016, 3.79999999999998, 20.000000000000014, 13.699999999999964, 28.400000000000162, -28.899999999999892, -168.10000000000045, -36.699999999999754, -95.50000000000057, -87.40000000000049, -15.699999999999939, -696.0, -400.0, -103.10000000000062, -10.299999999999873, -47.19999999999978, 1.0999999999999865, 30.8000000000002, 0.19999999999998655, 20.000000000000014, 15.799999999999963, -248.8000000000004, -127.00000000000054, -697.8, -450.9999999999998, -568.5000000000001, -208.29999999999993, -473.30000000000007, -554.8, -15.699999999999747, 15.799999999999963, 9.199999999999966, 17.59999999999998], "policy_predator_policy_reward": [1.0, 12.0, 199.0, 66.0, 5.0, 8.0, 524.0, 0.0, 243.0, 67.0, 29.0, 22.0, 9.0, 43.0, 9.0, 165.0, 18.0, 263.0, 17.0, 292.0, 3.0, 325.0, 3.0, 11.0, 48.0, 14.0, 13.0, 0.0, 518.0, 8.0, 1.0, 282.0, 5.0, 6.0, 7.0, 5.0, 309.0, 333.0, 22.0, 99.0, 0.0, 6.0, 6.0, 13.0, 161.0, 111.0, 0.0, 515.0, 217.0, 207.0, 14.0, 9.0, 117.0, 70.0, 449.0, 8.0, 26.0, 0.0, 9.0, 4.0, 398.0, 11.0, 490.0, 405.0, 11.0, 37.0, 7.0, 13.0, 26.0, 4.0, 139.0, 5.0, 10.0, 39.0, 16.0, 176.0, 9.0, 11.0, 66.0, 98.0, 13.0, 303.0, 251.0, 272.0, 5.0, 8.0, 4.0, 2.0, 1.0, 15.0, 177.0, 46.0, 341.0, 374.0, 102.0, 0.0, 77.0, 6.0, 178.0, 1.0, 103.0, 69.0, 33.0, 3.0, 11.0, 45.0, 166.0, 619.0, 11.0, 155.0, 428.0, 689.0, 9.0, 506.0, 12.0, 8.0, 21.0, 98.0, 8.0, 5.0, 7.0, 6.0, 28.0, 8.0, 76.0, 98.0, 14.0, 19.0, 66.0, 58.0, 35.0, 20.0, 373.0, 80.0, 4.0, 8.0, 271.0, 2.0, 2.0, 97.0, 227.0, 42.0, 11.0, 3.0, 10.0, 3.0, 2.0, 4.0, 272.0, 74.0, 18.0, 9.0, 295.0, 6.0, 152.0, 3.0, 7.0, 2.0, 8.0, 15.0, 0.0, 3.0, 39.0, 366.0, 322.0, 59.0, 26.0, 300.0, 0.0, 15.0, 8.0, 3.0, 4.0, 104.0, 49.0, 66.0, 73.0, 5.0, 371.0, 479.0, 72.0, 14.0, 26.0, 34.0, 12.0, 11.0, 2.0, 1.0, 99.0, 106.0, 641.0, 15.0, 410.0, 106.0, 509.0, 316.0, 17.0, 2.0, 14.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5835344174192236, "mean_inference_ms": 1.8512173598551596, "mean_action_processing_ms": 0.24132441107138028, "mean_env_wait_ms": 0.19819813309716763, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036759376525878906, "StateBufferConnector_ms": 0.003193378448486328, "ViewRequirementAgentConnector_ms": 0.08833181858062744}, "num_episodes": 18, "episode_return_max": 74.99999999999964, "episode_return_min": -536.1, "episode_return_mean": -125.2779999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 401.29655124773467, "num_env_steps_trained_throughput_per_sec": 401.29655124773467, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 10146.92, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10146.874, "sample_time_ms": 1345.766, "learn_time_ms": 8784.88, "learn_throughput": 455.328, "synch_weights_time_ms": 14.713}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-04-07", "timestamp": 1723644247, "time_this_iter_s": 9.972611904144287, "time_total_s": 113.00937581062317, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 113.00937581062317, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 30.826666666666668, "ram_util_percent": 82.16666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6414352187403924, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.445056591588984, "policy_loss": 0.0011607392404041198, "vf_loss": 4.4049407559097125, "vf_explained_var": 0.3770962487768244, "kl": 0.011399754392203285, "entropy": 1.126491247440772, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.847434083841465, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 6.097571703996608, "policy_loss": 0.0019003858062975778, "vf_loss": 6.0478661529601565, "vf_explained_var": 0.0015359180944937247, "kl": 0.013989622726597302, "entropy": 1.4093017293031884, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 80.79999999999926, "episode_reward_min": -536.1, "episode_reward_mean": -123.61099999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.00000000000021, "predator_policy": 689.0}, "policy_reward_mean": {"prey_policy": -172.92050000000003, "predator_policy": 111.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-110.09999999999988, -82.60000000000039, 53.2000000000005, 48.80000000000046, -259.1000000000004, -469.4, -342.0, 30.000000000000192, -59.49999999999969, -366.69999999999993, 11.400000000000048, 52.100000000000406, -414.09999999999957, -245.39999999999998, 36.100000000000364, 58.20000000000047, 28.600000000000136, -170.00000000000094, -12.999999999999671, -314.90000000000003, 28.800000000000132, -129.00000000000057, -479.5, -448.79999999999995, 69.50000000000009, 49.30000000000046, 32.60000000000019, -395.7999999999987, 38.8, -74.2999999999997, -51.3000000000005, -276.9, -130.30000000000086, 26.5000000000001, -21.59999999999951, -254.3, -239.2000000000004, -156.7999999999999, -533.9, 17.99999999999999, -36.39999999999976, 63.200000000000486, 49.100000000000456, 27.100000000000087, -23.299999999999965, 44.800000000000395, 38.90000000000039, -20.79999999999979, -469.19999999999993, 35.20000000000023, -186.20000000000016, -65.30000000000035, -536.1, 74.99999999999964, 32.00000000000018, 59.2000000000005, -170.39999999999975, 29.200000000000138, -399.4, -185.70000000000084, 47.80000000000043, 47.700000000000436, 38.50000000000028, -485.20000000000005, -327.00000000000045, -213.99999999999986, 38.80000000000028, 53.10000000000046, -89.00000000000081, -17.199999999999562, -25.09999999999973, -246.0, -27.399999999999586, 13.899999999999928, 54.00000000000048, 38.80000000000028, -170.80000000000095, -492.7999999999997, -260.8, -203.09999999999994, 19.099999999999984, 45.800000000000416, -179.60000000000014, -382.79999999999995, 48.50000000000042, -20.09999999999968, 14.999999999999925, -111.80000000000025, 37.90000000000027, 14.399999999999995, -351.1, -343.6, -249.20000000000073, -456.7, -187.3000000000003, -288.0999999999997, -448.8, 80.79999999999926, -334.5999999999997, 52.60000000000044], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-389.9, -362.2000000000001, -32.50000000000004, -171.10000000000042, 7.399999999999965, 39.80000000000025, 9.799999999999974, 20.000000000000014, -294.9000000000001, -236.20000000000036, -456.4, -528.0, -385.3, -380.7, 5.899999999999988, 1.0999999999999865, -127.00000000000074, -119.50000000000001, -483.20000000000005, -340.5, -34.59999999999975, 20.000000000000014, 24.50000000000009, 14.599999999999987, -337.3999999999995, -485.70000000000005, -531.0, -609.4, -19.899999999999743, 7.999999999999984, 23.000000000000064, 15.199999999999964, 41.60000000000025, -42.99999999999976, -200.50000000000054, -113.4999999999999, -61.00000000000041, -0.9999999999999846, -303.6999999999996, -203.20000000000027, 13.699999999999964, -4.899999999999956, -92.50000000000031, -200.50000000000045, -382.0, -413.5, -424.0, -547.8, 30.200000000000195, 26.300000000000114, 23.300000000000065, 20.000000000000014, 14.599999999999964, 1.9999999999999643, -315.99999999999966, -302.79999999999905, -332.8000000000002, -343.40000000000003, -194.20000000000056, 17.899999999999977, -141.7000000000007, 7.399999999999965, -102.09999999999988, -353.79999999999995, -284.5000000000003, -17.79999999999995, -49.299999999999905, 39.80000000000025, -3.099999999999958, -74.50000000000085, -274.6, -764.7, -223.60000000000008, -181.60000000000036, -714.7, -559.1, -400.0, -648.9, 3.1999999999999615, -5.199999999999934, -162.8, 7.399999999999965, 23.600000000000065, 26.60000000000013, 5.299999999999965, 30.800000000000196, -1.6000000000000512, -7.299999999999891, -183.70000000000022, -13.599999999999783, 20.000000000000014, -8.199999999999902, -105.70000000000059, 20.600000000000026, -39.09999999999989, -36.699999999999754, -423.2, -499.0, 20.000000000000014, 3.1999999999999615, -64.90000000000003, -394.29999999999995, -136.00000000000009, -28.299999999999862, -424.0, -381.1, 20.000000000000014, 41.0000000000002, -0.9999999999999846, 20.000000000000014, 31.40000000000021, 21.80000000000004, -390.60000000000025, -125.80000000000004, 20.000000000000014, -17.79999999999974, -278.6, -421.8, -91.00000000000031, -249.70000000000036, 17.899999999999984, 20.900000000000027, 20.000000000000014, 4.699999999999976, 15.49999999999996, 20.000000000000014, -397.9, -492.29999999999995, -352.0000000000002, -356.0000000000002, -213.3, -326.70000000000016, 3.79999999999998, 20.000000000000014, 13.699999999999964, 28.400000000000162, -28.899999999999892, -168.10000000000045, -36.699999999999754, -95.50000000000057, -87.40000000000049, -15.699999999999939, -696.0, -400.0, -103.10000000000062, -10.299999999999873, -47.19999999999978, 1.0999999999999865, 30.8000000000002, 0.19999999999998655, 20.000000000000014, 15.799999999999963, -248.8000000000004, -127.00000000000054, -697.8, -450.9999999999998, -568.5000000000001, -208.29999999999993, -473.30000000000007, -554.8, -15.699999999999747, 15.799999999999963, 9.199999999999966, 17.59999999999998, -623.2999999999994, -291.29999999999995, -563.8, -400.0, 5.299999999999965, 18.200000000000045, 45.200000000000195, -154.30000000000067, -5.19999999999993, -14.799999999999828, -284.8000000000003, 20.000000000000014, 14.599999999999964, 20.300000000000022, -76.60000000000082, 35.000000000000206, -784.1, -728.0, -233.5, -343.1, -544.0, -89.19999999999979, -294.7, -544.0, -160.60000000000065, -192.70000000000002, -196.60000000000008, -287.5, -403.2, -408.6, 15.799999999999963, 62.00000000000021, -405.5999999999997, -552.0, 50.60000000000022, -42.99999999999976], "policy_predator_policy_reward": [309.0, 333.0, 22.0, 99.0, 0.0, 6.0, 6.0, 13.0, 161.0, 111.0, 0.0, 515.0, 217.0, 207.0, 14.0, 9.0, 117.0, 70.0, 449.0, 8.0, 26.0, 0.0, 9.0, 4.0, 398.0, 11.0, 490.0, 405.0, 11.0, 37.0, 7.0, 13.0, 26.0, 4.0, 139.0, 5.0, 10.0, 39.0, 16.0, 176.0, 9.0, 11.0, 66.0, 98.0, 13.0, 303.0, 251.0, 272.0, 5.0, 8.0, 4.0, 2.0, 1.0, 15.0, 177.0, 46.0, 341.0, 374.0, 102.0, 0.0, 77.0, 6.0, 178.0, 1.0, 103.0, 69.0, 33.0, 3.0, 11.0, 45.0, 166.0, 619.0, 11.0, 155.0, 428.0, 689.0, 9.0, 506.0, 12.0, 8.0, 21.0, 98.0, 8.0, 5.0, 7.0, 6.0, 28.0, 8.0, 76.0, 98.0, 14.0, 19.0, 66.0, 58.0, 35.0, 20.0, 373.0, 80.0, 4.0, 8.0, 271.0, 2.0, 2.0, 97.0, 227.0, 42.0, 11.0, 3.0, 10.0, 3.0, 2.0, 4.0, 272.0, 74.0, 18.0, 9.0, 295.0, 6.0, 152.0, 3.0, 7.0, 2.0, 8.0, 15.0, 0.0, 3.0, 39.0, 366.0, 322.0, 59.0, 26.0, 300.0, 0.0, 15.0, 8.0, 3.0, 4.0, 104.0, 49.0, 66.0, 73.0, 5.0, 371.0, 479.0, 72.0, 14.0, 26.0, 34.0, 12.0, 11.0, 2.0, 1.0, 99.0, 106.0, 641.0, 15.0, 410.0, 106.0, 509.0, 316.0, 17.0, 2.0, 14.0, 5.0, 400.0, 335.0, 344.0, 237.0, 7.0, 18.0, 6.0, 83.0, 33.0, 2.0, 7.0, 146.0, 3.0, 0.0, 10.0, 46.0, 668.0, 493.0, 1.0, 232.0, 22.0, 362.0, 20.0, 362.0, 159.0, 7.0, 15.0, 181.0, 0.0, 363.0, 1.0, 2.0, 334.0, 289.0, 19.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5804076851250569, "mean_inference_ms": 1.8420996232707734, "mean_action_processing_ms": 0.24001792153836157, "mean_env_wait_ms": 0.19690063574934297, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035587549209594727, "StateBufferConnector_ms": 0.0031741857528686523, "ViewRequirementAgentConnector_ms": 0.08667206764221191}, "num_episodes": 18, "episode_return_max": 80.79999999999926, "episode_return_min": -536.1, "episode_return_mean": -123.61099999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 418.6318388358287, "num_env_steps_trained_throughput_per_sec": 418.6318388358287, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 9982.711, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9982.669, "sample_time_ms": 1322.621, "learn_time_ms": 8644.584, "learn_throughput": 462.717, "synch_weights_time_ms": 14.022}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-04-16", "timestamp": 1723644256, "time_this_iter_s": 9.560781002044678, "time_total_s": 122.57015681266785, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8addc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 122.57015681266785, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 29.43846153846154, "ram_util_percent": 82.2846153846154}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.0945772001983, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.618520996305677, "policy_loss": 0.0018923554924272356, "vf_loss": 4.5704705187883325, "vf_explained_var": 0.300922643349915, "kl": 0.01350763488651715, "entropy": 1.1559811032638347, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.826612023354838, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 6.841320116557772, "policy_loss": 0.0020624755765927373, "vf_loss": 6.791804239484999, "vf_explained_var": 0.0013267715771993, "kl": 0.013886682497981582, "entropy": 1.4176256950570163, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 80.79999999999926, "episode_reward_min": -536.1, "episode_reward_mean": -137.1419999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.00000000000021, "predator_policy": 689.0}, "policy_reward_mean": {"prey_policy": -185.20100000000002, "predator_policy": 116.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.999999999999671, -314.90000000000003, 28.800000000000132, -129.00000000000057, -479.5, -448.79999999999995, 69.50000000000009, 49.30000000000046, 32.60000000000019, -395.7999999999987, 38.8, -74.2999999999997, -51.3000000000005, -276.9, -130.30000000000086, 26.5000000000001, -21.59999999999951, -254.3, -239.2000000000004, -156.7999999999999, -533.9, 17.99999999999999, -36.39999999999976, 63.200000000000486, 49.100000000000456, 27.100000000000087, -23.299999999999965, 44.800000000000395, 38.90000000000039, -20.79999999999979, -469.19999999999993, 35.20000000000023, -186.20000000000016, -65.30000000000035, -536.1, 74.99999999999964, 32.00000000000018, 59.2000000000005, -170.39999999999975, 29.200000000000138, -399.4, -185.70000000000084, 47.80000000000043, 47.700000000000436, 38.50000000000028, -485.20000000000005, -327.00000000000045, -213.99999999999986, 38.80000000000028, 53.10000000000046, -89.00000000000081, -17.199999999999562, -25.09999999999973, -246.0, -27.399999999999586, 13.899999999999928, 54.00000000000048, 38.80000000000028, -170.80000000000095, -492.7999999999997, -260.8, -203.09999999999994, 19.099999999999984, 45.800000000000416, -179.60000000000014, -382.79999999999995, 48.50000000000042, -20.09999999999968, 14.999999999999925, -111.80000000000025, 37.90000000000027, 14.399999999999995, -351.1, -343.6, -249.20000000000073, -456.7, -187.3000000000003, -288.0999999999997, -448.8, 80.79999999999926, -334.5999999999997, 52.60000000000044, 21.19999999999976, -343.1000000000006, -256.1, 64.20000000000037, 2.100000000000215, -302.2000000000003, -243.90000000000038, -415.3, 26.500000000000085, -283.0, -253.30000000000086, -189.40000000000012, 53.00000000000048, -496.7, 47.30000000000043, -301.4, -327.5999999999973, -355.9000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-61.00000000000041, -0.9999999999999846, -303.6999999999996, -203.20000000000027, 13.699999999999964, -4.899999999999956, -92.50000000000031, -200.50000000000045, -382.0, -413.5, -424.0, -547.8, 30.200000000000195, 26.300000000000114, 23.300000000000065, 20.000000000000014, 14.599999999999964, 1.9999999999999643, -315.99999999999966, -302.79999999999905, -332.8000000000002, -343.40000000000003, -194.20000000000056, 17.899999999999977, -141.7000000000007, 7.399999999999965, -102.09999999999988, -353.79999999999995, -284.5000000000003, -17.79999999999995, -49.299999999999905, 39.80000000000025, -3.099999999999958, -74.50000000000085, -274.6, -764.7, -223.60000000000008, -181.60000000000036, -714.7, -559.1, -400.0, -648.9, 3.1999999999999615, -5.199999999999934, -162.8, 7.399999999999965, 23.600000000000065, 26.60000000000013, 5.299999999999965, 30.800000000000196, -1.6000000000000512, -7.299999999999891, -183.70000000000022, -13.599999999999783, 20.000000000000014, -8.199999999999902, -105.70000000000059, 20.600000000000026, -39.09999999999989, -36.699999999999754, -423.2, -499.0, 20.000000000000014, 3.1999999999999615, -64.90000000000003, -394.29999999999995, -136.00000000000009, -28.299999999999862, -424.0, -381.1, 20.000000000000014, 41.0000000000002, -0.9999999999999846, 20.000000000000014, 31.40000000000021, 21.80000000000004, -390.60000000000025, -125.80000000000004, 20.000000000000014, -17.79999999999974, -278.6, -421.8, -91.00000000000031, -249.70000000000036, 17.899999999999984, 20.900000000000027, 20.000000000000014, 4.699999999999976, 15.49999999999996, 20.000000000000014, -397.9, -492.29999999999995, -352.0000000000002, -356.0000000000002, -213.3, -326.70000000000016, 3.79999999999998, 20.000000000000014, 13.699999999999964, 28.400000000000162, -28.899999999999892, -168.10000000000045, -36.699999999999754, -95.50000000000057, -87.40000000000049, -15.699999999999939, -696.0, -400.0, -103.10000000000062, -10.299999999999873, -47.19999999999978, 1.0999999999999865, 30.8000000000002, 0.19999999999998655, 20.000000000000014, 15.799999999999963, -248.8000000000004, -127.00000000000054, -697.8, -450.9999999999998, -568.5000000000001, -208.29999999999993, -473.30000000000007, -554.8, -15.699999999999747, 15.799999999999963, 9.199999999999966, 17.59999999999998, -623.2999999999994, -291.29999999999995, -563.8, -400.0, 5.299999999999965, 18.200000000000045, 45.200000000000195, -154.30000000000067, -5.19999999999993, -14.799999999999828, -284.8000000000003, 20.000000000000014, 14.599999999999964, 20.300000000000022, -76.60000000000082, 35.000000000000206, -784.1, -728.0, -233.5, -343.1, -544.0, -89.19999999999979, -294.7, -544.0, -160.60000000000065, -192.70000000000002, -196.60000000000008, -287.5, -403.2, -408.6, 15.799999999999963, 62.00000000000021, -405.5999999999997, -552.0, 50.60000000000022, -42.99999999999976, -600.5, -34.299999999999855, -385.30000000000007, -161.80000000000052, -215.20000000000002, -397.9, 5.899999999999967, 38.300000000000175, -15.699999999999747, -26.199999999999747, -408.0, -555.2000000000003, -232.00000000000043, -187.90000000000003, -353.8, -324.5, 13.699999999999967, -5.1999999999999265, -597.9, -478.1, -316.0000000000002, -112.29999999999986, -166.89999999999998, -237.50000000000048, -1.9, 29.90000000000018, -427.8, -347.9, 36.8000000000002, -11.499999999999819, -397.9, -640.5, -177.40000000000046, -320.1999999999993, -362.2000000000001, -532.7], "policy_predator_policy_reward": [10.0, 39.0, 16.0, 176.0, 9.0, 11.0, 66.0, 98.0, 13.0, 303.0, 251.0, 272.0, 5.0, 8.0, 4.0, 2.0, 1.0, 15.0, 177.0, 46.0, 341.0, 374.0, 102.0, 0.0, 77.0, 6.0, 178.0, 1.0, 103.0, 69.0, 33.0, 3.0, 11.0, 45.0, 166.0, 619.0, 11.0, 155.0, 428.0, 689.0, 9.0, 506.0, 12.0, 8.0, 21.0, 98.0, 8.0, 5.0, 7.0, 6.0, 28.0, 8.0, 76.0, 98.0, 14.0, 19.0, 66.0, 58.0, 35.0, 20.0, 373.0, 80.0, 4.0, 8.0, 271.0, 2.0, 2.0, 97.0, 227.0, 42.0, 11.0, 3.0, 10.0, 3.0, 2.0, 4.0, 272.0, 74.0, 18.0, 9.0, 295.0, 6.0, 152.0, 3.0, 7.0, 2.0, 8.0, 15.0, 0.0, 3.0, 39.0, 366.0, 322.0, 59.0, 26.0, 300.0, 0.0, 15.0, 8.0, 3.0, 4.0, 104.0, 49.0, 66.0, 73.0, 5.0, 371.0, 479.0, 72.0, 14.0, 26.0, 34.0, 12.0, 11.0, 2.0, 1.0, 99.0, 106.0, 641.0, 15.0, 410.0, 106.0, 509.0, 316.0, 17.0, 2.0, 14.0, 5.0, 400.0, 335.0, 344.0, 237.0, 7.0, 18.0, 6.0, 83.0, 33.0, 2.0, 7.0, 146.0, 3.0, 0.0, 10.0, 46.0, 668.0, 493.0, 1.0, 232.0, 22.0, 362.0, 20.0, 362.0, 159.0, 7.0, 15.0, 181.0, 0.0, 363.0, 1.0, 2.0, 334.0, 289.0, 19.0, 26.0, 390.0, 266.0, 200.0, 4.0, 160.0, 197.0, 17.0, 3.0, 22.0, 22.0, 282.0, 379.0, 176.0, 0.0, 258.0, 5.0, 12.0, 6.0, 271.0, 522.0, 54.0, 121.0, 204.0, 11.0, 9.0, 16.0, 0.0, 279.0, 15.0, 7.0, 325.0, 412.0, 8.0, 162.0, 204.0, 335.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5759407197772954, "mean_inference_ms": 1.8295277653334472, "mean_action_processing_ms": 0.23847401069158544, "mean_env_wait_ms": 0.19513044413874284, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003636598587036133, "StateBufferConnector_ms": 0.003130316734313965, "ViewRequirementAgentConnector_ms": 0.08445143699645996}, "num_episodes": 18, "episode_return_max": 80.79999999999926, "episode_return_min": -536.1, "episode_return_mean": -137.1419999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 401.2071883579528, "num_env_steps_trained_throughput_per_sec": 401.2071883579528, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 9883.351, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9883.314, "sample_time_ms": 1294.099, "learn_time_ms": 8573.714, "learn_throughput": 466.542, "synch_weights_time_ms": 14.171}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-04-26", "timestamp": 1723644266, "time_this_iter_s": 9.974087953567505, "time_total_s": 132.54424476623535, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31874c700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 132.54424476623535, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 29.357142857142854, "ram_util_percent": 82.35714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.3008207050896194, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.572868692811835, "policy_loss": 0.0026470577765610958, "vf_loss": 4.525027834675299, "vf_explained_var": 0.3872098044428245, "kl": 0.013225438057444217, "entropy": 1.1252958975771747, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.992397297106723, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.738296651461768, "policy_loss": 0.0021743285974793174, "vf_loss": 4.693414829269288, "vf_explained_var": 0.001155691865890745, "kl": 0.012497849897287475, "entropy": 1.261312934204384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 80.79999999999926, "episode_reward_min": -536.1, "episode_reward_mean": -131.30599999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.00000000000021, "predator_policy": 668.0}, "policy_reward_mean": {"prey_policy": -172.528, "predator_policy": 106.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.800000000000395, 38.90000000000039, -20.79999999999979, -469.19999999999993, 35.20000000000023, -186.20000000000016, -65.30000000000035, -536.1, 74.99999999999964, 32.00000000000018, 59.2000000000005, -170.39999999999975, 29.200000000000138, -399.4, -185.70000000000084, 47.80000000000043, 47.700000000000436, 38.50000000000028, -485.20000000000005, -327.00000000000045, -213.99999999999986, 38.80000000000028, 53.10000000000046, -89.00000000000081, -17.199999999999562, -25.09999999999973, -246.0, -27.399999999999586, 13.899999999999928, 54.00000000000048, 38.80000000000028, -170.80000000000095, -492.7999999999997, -260.8, -203.09999999999994, 19.099999999999984, 45.800000000000416, -179.60000000000014, -382.79999999999995, 48.50000000000042, -20.09999999999968, 14.999999999999925, -111.80000000000025, 37.90000000000027, 14.399999999999995, -351.1, -343.6, -249.20000000000073, -456.7, -187.3000000000003, -288.0999999999997, -448.8, 80.79999999999926, -334.5999999999997, 52.60000000000044, 21.19999999999976, -343.1000000000006, -256.1, 64.20000000000037, 2.100000000000215, -302.2000000000003, -243.90000000000038, -415.3, 26.500000000000085, -283.0, -253.30000000000086, -189.40000000000012, 53.00000000000048, -496.7, 47.30000000000043, -301.4, -327.5999999999973, -355.9000000000002, 60.000000000000476, -157.09999999999988, 70.30000000000001, -315.79999999999995, 6.4000000000000945, 25.80000000000009, -339.29999999999995, -131.30000000000064, -122.9000000000002, 53.700000000000486, 12.799999999999994, 39.100000000000286, 66.50000000000023, -109.20000000000081, 56.500000000000426, 52.60000000000048, -78.90000000000003, -312.0999999999999, -137.40000000000038, -178.9000000000008, -69.90000000000003, 40.2000000000003, -100.19999999999999, -255.10000000000082, -518.0, 34.50000000000022, -285.09999999999803], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -8.199999999999902, -105.70000000000059, 20.600000000000026, -39.09999999999989, -36.699999999999754, -423.2, -499.0, 20.000000000000014, 3.1999999999999615, -64.90000000000003, -394.29999999999995, -136.00000000000009, -28.299999999999862, -424.0, -381.1, 20.000000000000014, 41.0000000000002, -0.9999999999999846, 20.000000000000014, 31.40000000000021, 21.80000000000004, -390.60000000000025, -125.80000000000004, 20.000000000000014, -17.79999999999974, -278.6, -421.8, -91.00000000000031, -249.70000000000036, 17.899999999999984, 20.900000000000027, 20.000000000000014, 4.699999999999976, 15.49999999999996, 20.000000000000014, -397.9, -492.29999999999995, -352.0000000000002, -356.0000000000002, -213.3, -326.70000000000016, 3.79999999999998, 20.000000000000014, 13.699999999999964, 28.400000000000162, -28.899999999999892, -168.10000000000045, -36.699999999999754, -95.50000000000057, -87.40000000000049, -15.699999999999939, -696.0, -400.0, -103.10000000000062, -10.299999999999873, -47.19999999999978, 1.0999999999999865, 30.8000000000002, 0.19999999999998655, 20.000000000000014, 15.799999999999963, -248.8000000000004, -127.00000000000054, -697.8, -450.9999999999998, -568.5000000000001, -208.29999999999993, -473.30000000000007, -554.8, -15.699999999999747, 15.799999999999963, 9.199999999999966, 17.59999999999998, -623.2999999999994, -291.29999999999995, -563.8, -400.0, 5.299999999999965, 18.200000000000045, 45.200000000000195, -154.30000000000067, -5.19999999999993, -14.799999999999828, -284.8000000000003, 20.000000000000014, 14.599999999999964, 20.300000000000022, -76.60000000000082, 35.000000000000206, -784.1, -728.0, -233.5, -343.1, -544.0, -89.19999999999979, -294.7, -544.0, -160.60000000000065, -192.70000000000002, -196.60000000000008, -287.5, -403.2, -408.6, 15.799999999999963, 62.00000000000021, -405.5999999999997, -552.0, 50.60000000000022, -42.99999999999976, -600.5, -34.299999999999855, -385.30000000000007, -161.80000000000052, -215.20000000000002, -397.9, 5.899999999999967, 38.300000000000175, -15.699999999999747, -26.199999999999747, -408.0, -555.2000000000003, -232.00000000000043, -187.90000000000003, -353.8, -324.5, 13.699999999999967, -5.1999999999999265, -597.9, -478.1, -316.0000000000002, -112.29999999999986, -166.89999999999998, -237.50000000000048, -1.9, 29.90000000000018, -427.8, -347.9, 36.8000000000002, -11.499999999999819, -397.9, -640.5, -177.40000000000046, -320.1999999999993, -362.2000000000001, -532.7, 23.600000000000072, 22.400000000000055, -217.50000000000003, -367.6, 31.40000000000022, 20.90000000000003, -233.8, -231.99999999999994, 4.699999999999978, -49.299999999999805, 3.199999999999965, -0.40000000000002056, -295.0, -253.29999999999998, 21.500000000000036, -311.79999999999967, -114.40000000000077, -182.49999999999994, -28.29999999999975, 44.00000000000024, -24.699999999999754, 9.499999999999966, 1.0999999999999865, 20.000000000000014, 19.400000000000013, 16.099999999999962, -330.69999999999936, 9.499999999999968, 1.0999999999999865, 34.40000000000021, 11.599999999999964, 32.00000000000022, -26.499999999999847, -132.39999999999984, -330.7, -547.3999999999999, 21.500000000000036, -334.9000000000002, -3.099999999999958, -374.7999999999997, 3.199999999999965, -186.1000000000003, -13.899999999999782, 37.10000000000026, 6.199999999999999, -240.3999999999999, -397.9, -65.20000000000078, -547.0, -512.0, 9.499999999999964, 20.000000000000014, -290.7999999999988, -244.3000000000002], "policy_predator_policy_reward": [14.0, 19.0, 66.0, 58.0, 35.0, 20.0, 373.0, 80.0, 4.0, 8.0, 271.0, 2.0, 2.0, 97.0, 227.0, 42.0, 11.0, 3.0, 10.0, 3.0, 2.0, 4.0, 272.0, 74.0, 18.0, 9.0, 295.0, 6.0, 152.0, 3.0, 7.0, 2.0, 8.0, 15.0, 0.0, 3.0, 39.0, 366.0, 322.0, 59.0, 26.0, 300.0, 0.0, 15.0, 8.0, 3.0, 4.0, 104.0, 49.0, 66.0, 73.0, 5.0, 371.0, 479.0, 72.0, 14.0, 26.0, 34.0, 12.0, 11.0, 2.0, 1.0, 99.0, 106.0, 641.0, 15.0, 410.0, 106.0, 509.0, 316.0, 17.0, 2.0, 14.0, 5.0, 400.0, 335.0, 344.0, 237.0, 7.0, 18.0, 6.0, 83.0, 33.0, 2.0, 7.0, 146.0, 3.0, 0.0, 10.0, 46.0, 668.0, 493.0, 1.0, 232.0, 22.0, 362.0, 20.0, 362.0, 159.0, 7.0, 15.0, 181.0, 0.0, 363.0, 1.0, 2.0, 334.0, 289.0, 19.0, 26.0, 390.0, 266.0, 200.0, 4.0, 160.0, 197.0, 17.0, 3.0, 22.0, 22.0, 282.0, 379.0, 176.0, 0.0, 258.0, 5.0, 12.0, 6.0, 271.0, 522.0, 54.0, 121.0, 204.0, 11.0, 9.0, 16.0, 0.0, 279.0, 15.0, 7.0, 325.0, 412.0, 8.0, 162.0, 204.0, 335.0, 6.0, 8.0, 168.0, 260.0, 8.0, 10.0, 16.0, 134.0, 33.0, 18.0, 19.0, 4.0, 177.0, 32.0, 1.0, 158.0, 172.0, 2.0, 21.0, 17.0, 12.0, 16.0, 9.0, 9.0, 11.0, 20.0, 73.0, 139.0, 14.0, 7.0, 4.0, 5.0, 75.0, 5.0, 323.0, 243.0, 169.0, 7.0, 11.0, 188.0, 111.0, 2.0, 0.0, 17.0, 124.0, 10.0, 9.0, 199.0, 452.0, 89.0, 0.0, 5.0, 149.0, 101.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.570440264597095, "mean_inference_ms": 1.8207423482439316, "mean_action_processing_ms": 0.23690978387519665, "mean_env_wait_ms": 0.19301885810836644, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003870725631713867, "StateBufferConnector_ms": 0.0034859180450439453, "ViewRequirementAgentConnector_ms": 0.0883406400680542}, "num_episodes": 27, "episode_return_max": 80.79999999999926, "episode_return_min": -536.1, "episode_return_mean": -131.30599999999995, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 426.19238976564117, "num_env_steps_trained_throughput_per_sec": 426.19238976564117, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 9720.455, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9720.417, "sample_time_ms": 1284.692, "learn_time_ms": 8420.519, "learn_throughput": 475.03, "synch_weights_time_ms": 13.856}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-04-36", "timestamp": 1723644276, "time_this_iter_s": 9.390624046325684, "time_total_s": 141.93486881256104, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31874ca60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 141.93486881256104, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 31.064285714285717, "ram_util_percent": 82.33571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7584278630831887, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.739397170682433, "policy_loss": 0.0013200130558784597, "vf_loss": 4.705192512431473, "vf_explained_var": 0.4229463258117595, "kl": 0.009623307956436521, "entropy": 1.0274121784343921, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.069920343192166, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.981601292494113, "policy_loss": 0.0025901674400157634, "vf_loss": 3.933833872325837, "vf_explained_var": 0.001851682877414441, "kl": 0.01322059244560833, "entropy": 1.2381480942958247, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 80.79999999999926, "episode_reward_min": -518.0, "episode_reward_mean": -121.83899999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.00000000000021, "predator_policy": 668.0}, "policy_reward_mean": {"prey_policy": -169.04449999999997, "predator_policy": 108.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-485.20000000000005, -327.00000000000045, -213.99999999999986, 38.80000000000028, 53.10000000000046, -89.00000000000081, -17.199999999999562, -25.09999999999973, -246.0, -27.399999999999586, 13.899999999999928, 54.00000000000048, 38.80000000000028, -170.80000000000095, -492.7999999999997, -260.8, -203.09999999999994, 19.099999999999984, 45.800000000000416, -179.60000000000014, -382.79999999999995, 48.50000000000042, -20.09999999999968, 14.999999999999925, -111.80000000000025, 37.90000000000027, 14.399999999999995, -351.1, -343.6, -249.20000000000073, -456.7, -187.3000000000003, -288.0999999999997, -448.8, 80.79999999999926, -334.5999999999997, 52.60000000000044, 21.19999999999976, -343.1000000000006, -256.1, 64.20000000000037, 2.100000000000215, -302.2000000000003, -243.90000000000038, -415.3, 26.500000000000085, -283.0, -253.30000000000086, -189.40000000000012, 53.00000000000048, -496.7, 47.30000000000043, -301.4, -327.5999999999973, -355.9000000000002, 60.000000000000476, -157.09999999999988, 70.30000000000001, -315.79999999999995, 6.4000000000000945, 25.80000000000009, -339.29999999999995, -131.30000000000064, -122.9000000000002, 53.700000000000486, 12.799999999999994, 39.100000000000286, 66.50000000000023, -109.20000000000081, 56.500000000000426, 52.60000000000048, -78.90000000000003, -312.0999999999999, -137.40000000000038, -178.9000000000008, -69.90000000000003, 40.2000000000003, -100.19999999999999, -255.10000000000082, -518.0, 34.50000000000022, -285.09999999999803, -38.39999999999959, -41.399999999999906, 61.40000000000048, -226.2000000000009, 44.900000000000375, -155.8000000000004, -66.30000000000106, -112.50000000000009, -53.999999999999844, 20.50000000000022, -57.80000000000091, 32.9000000000002, 21.599999999999994, 29.200000000000166, 74.29999999999974, 30.40000000000016, 4.200000000000195, -205.10000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-397.9, -492.29999999999995, -352.0000000000002, -356.0000000000002, -213.3, -326.70000000000016, 3.79999999999998, 20.000000000000014, 13.699999999999964, 28.400000000000162, -28.899999999999892, -168.10000000000045, -36.699999999999754, -95.50000000000057, -87.40000000000049, -15.699999999999939, -696.0, -400.0, -103.10000000000062, -10.299999999999873, -47.19999999999978, 1.0999999999999865, 30.8000000000002, 0.19999999999998655, 20.000000000000014, 15.799999999999963, -248.8000000000004, -127.00000000000054, -697.8, -450.9999999999998, -568.5000000000001, -208.29999999999993, -473.30000000000007, -554.8, -15.699999999999747, 15.799999999999963, 9.199999999999966, 17.59999999999998, -623.2999999999994, -291.29999999999995, -563.8, -400.0, 5.299999999999965, 18.200000000000045, 45.200000000000195, -154.30000000000067, -5.19999999999993, -14.799999999999828, -284.8000000000003, 20.000000000000014, 14.599999999999964, 20.300000000000022, -76.60000000000082, 35.000000000000206, -784.1, -728.0, -233.5, -343.1, -544.0, -89.19999999999979, -294.7, -544.0, -160.60000000000065, -192.70000000000002, -196.60000000000008, -287.5, -403.2, -408.6, 15.799999999999963, 62.00000000000021, -405.5999999999997, -552.0, 50.60000000000022, -42.99999999999976, -600.5, -34.299999999999855, -385.30000000000007, -161.80000000000052, -215.20000000000002, -397.9, 5.899999999999967, 38.300000000000175, -15.699999999999747, -26.199999999999747, -408.0, -555.2000000000003, -232.00000000000043, -187.90000000000003, -353.8, -324.5, 13.699999999999967, -5.1999999999999265, -597.9, -478.1, -316.0000000000002, -112.29999999999986, -166.89999999999998, -237.50000000000048, -1.9, 29.90000000000018, -427.8, -347.9, 36.8000000000002, -11.499999999999819, -397.9, -640.5, -177.40000000000046, -320.1999999999993, -362.2000000000001, -532.7, 23.600000000000072, 22.400000000000055, -217.50000000000003, -367.6, 31.40000000000022, 20.90000000000003, -233.8, -231.99999999999994, 4.699999999999978, -49.299999999999805, 3.199999999999965, -0.40000000000002056, -295.0, -253.29999999999998, 21.500000000000036, -311.79999999999967, -114.40000000000077, -182.49999999999994, -28.29999999999975, 44.00000000000024, -24.699999999999754, 9.499999999999966, 1.0999999999999865, 20.000000000000014, 19.400000000000013, 16.099999999999962, -330.69999999999936, 9.499999999999968, 1.0999999999999865, 34.40000000000021, 11.599999999999964, 32.00000000000022, -26.499999999999847, -132.39999999999984, -330.7, -547.3999999999999, 21.500000000000036, -334.9000000000002, -3.099999999999958, -374.7999999999997, 3.199999999999965, -186.1000000000003, -13.899999999999782, 37.10000000000026, 6.199999999999999, -240.3999999999999, -397.9, -65.20000000000078, -547.0, -512.0, 9.499999999999964, 20.000000000000014, -290.7999999999988, -244.3000000000002, -141.7000000000007, 26.300000000000114, -116.50000000000077, 1.0999999999999865, 44.30000000000023, 10.099999999999966, -276.10000000000036, -192.10000000000056, 20.000000000000014, 17.899999999999984, -196.6000000000003, -233.2, 6.799999999999964, -309.099999999998, -103.89999999999998, -160.60000000000065, -28.000000000000036, -400.0, -462.99999999999886, 33.50000000000024, -162.70000000000064, -45.09999999999976, -15.699999999999747, 23.600000000000065, 20.000000000000014, -30.399999999999885, -5.1999999999999265, 7.399999999999977, 52.40000000000022, 17.899999999999988, 28.100000000000147, -15.699999999999747, -13.599999999999794, -5.1999999999999265, -142.90000000000066, -355.1999999999993], "policy_predator_policy_reward": [39.0, 366.0, 322.0, 59.0, 26.0, 300.0, 0.0, 15.0, 8.0, 3.0, 4.0, 104.0, 49.0, 66.0, 73.0, 5.0, 371.0, 479.0, 72.0, 14.0, 26.0, 34.0, 12.0, 11.0, 2.0, 1.0, 99.0, 106.0, 641.0, 15.0, 410.0, 106.0, 509.0, 316.0, 17.0, 2.0, 14.0, 5.0, 400.0, 335.0, 344.0, 237.0, 7.0, 18.0, 6.0, 83.0, 33.0, 2.0, 7.0, 146.0, 3.0, 0.0, 10.0, 46.0, 668.0, 493.0, 1.0, 232.0, 22.0, 362.0, 20.0, 362.0, 159.0, 7.0, 15.0, 181.0, 0.0, 363.0, 1.0, 2.0, 334.0, 289.0, 19.0, 26.0, 390.0, 266.0, 200.0, 4.0, 160.0, 197.0, 17.0, 3.0, 22.0, 22.0, 282.0, 379.0, 176.0, 0.0, 258.0, 5.0, 12.0, 6.0, 271.0, 522.0, 54.0, 121.0, 204.0, 11.0, 9.0, 16.0, 0.0, 279.0, 15.0, 7.0, 325.0, 412.0, 8.0, 162.0, 204.0, 335.0, 6.0, 8.0, 168.0, 260.0, 8.0, 10.0, 16.0, 134.0, 33.0, 18.0, 19.0, 4.0, 177.0, 32.0, 1.0, 158.0, 172.0, 2.0, 21.0, 17.0, 12.0, 16.0, 9.0, 9.0, 11.0, 20.0, 73.0, 139.0, 14.0, 7.0, 4.0, 5.0, 75.0, 5.0, 323.0, 243.0, 169.0, 7.0, 11.0, 188.0, 111.0, 2.0, 0.0, 17.0, 124.0, 10.0, 9.0, 199.0, 452.0, 89.0, 0.0, 5.0, 149.0, 101.0, 0.0, 77.0, 65.0, 9.0, 3.0, 4.0, 141.0, 101.0, 4.0, 3.0, 166.0, 108.0, 13.0, 223.0, 4.0, 148.0, 188.0, 186.0, 312.0, 138.0, 63.0, 87.0, 17.0, 8.0, 16.0, 16.0, 12.0, 15.0, 3.0, 1.0, 1.0, 17.0, 0.0, 23.0, 168.0, 125.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.567932615266239, "mean_inference_ms": 1.808612694401661, "mean_action_processing_ms": 0.23621758546290222, "mean_env_wait_ms": 0.19228968300477794, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003859400749206543, "StateBufferConnector_ms": 0.0033529996871948242, "ViewRequirementAgentConnector_ms": 0.08872699737548828}, "num_episodes": 18, "episode_return_max": 80.79999999999926, "episode_return_min": -518.0, "episode_return_mean": -121.83899999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 411.2607665613733, "num_env_steps_trained_throughput_per_sec": 411.2607665613733, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 9679.859, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9679.822, "sample_time_ms": 1280.013, "learn_time_ms": 8385.021, "learn_throughput": 477.041, "synch_weights_time_ms": 13.522}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-04-45", "timestamp": 1723644285, "time_this_iter_s": 9.73168396949768, "time_total_s": 151.66655278205872, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31874c9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 151.66655278205872, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 32.39230769230769, "ram_util_percent": 82.20769230769231}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9459107546263903, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.9144812964888476, "policy_loss": 0.004472737230247172, "vf_loss": 3.870233382497515, "vf_explained_var": 0.25186841907324614, "kl": 0.011639743457861096, "entropy": 1.0566267135282041, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.868827455132096, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.021270978387702, "policy_loss": 0.0016608233277799276, "vf_loss": 3.9748677260030516, "vf_explained_var": 0.0002626003096343348, "kl": 0.013093350216072707, "entropy": 1.2604884005097485, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 80.79999999999926, "episode_reward_min": -518.0, "episode_reward_mean": -105.60999999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -784.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.00000000000021, "predator_policy": 668.0}, "policy_reward_mean": {"prey_policy": -150.495, "predator_policy": 97.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.800000000000416, -179.60000000000014, -382.79999999999995, 48.50000000000042, -20.09999999999968, 14.999999999999925, -111.80000000000025, 37.90000000000027, 14.399999999999995, -351.1, -343.6, -249.20000000000073, -456.7, -187.3000000000003, -288.0999999999997, -448.8, 80.79999999999926, -334.5999999999997, 52.60000000000044, 21.19999999999976, -343.1000000000006, -256.1, 64.20000000000037, 2.100000000000215, -302.2000000000003, -243.90000000000038, -415.3, 26.500000000000085, -283.0, -253.30000000000086, -189.40000000000012, 53.00000000000048, -496.7, 47.30000000000043, -301.4, -327.5999999999973, -355.9000000000002, 60.000000000000476, -157.09999999999988, 70.30000000000001, -315.79999999999995, 6.4000000000000945, 25.80000000000009, -339.29999999999995, -131.30000000000064, -122.9000000000002, 53.700000000000486, 12.799999999999994, 39.100000000000286, 66.50000000000023, -109.20000000000081, 56.500000000000426, 52.60000000000048, -78.90000000000003, -312.0999999999999, -137.40000000000038, -178.9000000000008, -69.90000000000003, 40.2000000000003, -100.19999999999999, -255.10000000000082, -518.0, 34.50000000000022, -285.09999999999803, -38.39999999999959, -41.399999999999906, 61.40000000000048, -226.2000000000009, 44.900000000000375, -155.8000000000004, -66.30000000000106, -112.50000000000009, -53.999999999999844, 20.50000000000022, -57.80000000000091, 32.9000000000002, 21.599999999999994, 29.200000000000166, 74.29999999999974, 30.40000000000016, 4.200000000000195, -205.10000000000082, -383.5999999999999, 37.50000000000026, 47.0000000000004, 61.40000000000045, -240.3000000000003, 47.50000000000043, 44.70000000000039, 46.50000000000042, 25.900000000000162, -116.40000000000038, 46.00000000000041, -17.399999999999842, 60.10000000000044, -247.00000000000023, 35.00000000000023, -120.000000000001, 1.0000000000002427, -45.69999999999962], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.199999999999966, 17.59999999999998, -623.2999999999994, -291.29999999999995, -563.8, -400.0, 5.299999999999965, 18.200000000000045, 45.200000000000195, -154.30000000000067, -5.19999999999993, -14.799999999999828, -284.8000000000003, 20.000000000000014, 14.599999999999964, 20.300000000000022, -76.60000000000082, 35.000000000000206, -784.1, -728.0, -233.5, -343.1, -544.0, -89.19999999999979, -294.7, -544.0, -160.60000000000065, -192.70000000000002, -196.60000000000008, -287.5, -403.2, -408.6, 15.799999999999963, 62.00000000000021, -405.5999999999997, -552.0, 50.60000000000022, -42.99999999999976, -600.5, -34.299999999999855, -385.30000000000007, -161.80000000000052, -215.20000000000002, -397.9, 5.899999999999967, 38.300000000000175, -15.699999999999747, -26.199999999999747, -408.0, -555.2000000000003, -232.00000000000043, -187.90000000000003, -353.8, -324.5, 13.699999999999967, -5.1999999999999265, -597.9, -478.1, -316.0000000000002, -112.29999999999986, -166.89999999999998, -237.50000000000048, -1.9, 29.90000000000018, -427.8, -347.9, 36.8000000000002, -11.499999999999819, -397.9, -640.5, -177.40000000000046, -320.1999999999993, -362.2000000000001, -532.7, 23.600000000000072, 22.400000000000055, -217.50000000000003, -367.6, 31.40000000000022, 20.90000000000003, -233.8, -231.99999999999994, 4.699999999999978, -49.299999999999805, 3.199999999999965, -0.40000000000002056, -295.0, -253.29999999999998, 21.500000000000036, -311.79999999999967, -114.40000000000077, -182.49999999999994, -28.29999999999975, 44.00000000000024, -24.699999999999754, 9.499999999999966, 1.0999999999999865, 20.000000000000014, 19.400000000000013, 16.099999999999962, -330.69999999999936, 9.499999999999968, 1.0999999999999865, 34.40000000000021, 11.599999999999964, 32.00000000000022, -26.499999999999847, -132.39999999999984, -330.7, -547.3999999999999, 21.500000000000036, -334.9000000000002, -3.099999999999958, -374.7999999999997, 3.199999999999965, -186.1000000000003, -13.899999999999782, 37.10000000000026, 6.199999999999999, -240.3999999999999, -397.9, -65.20000000000078, -547.0, -512.0, 9.499999999999964, 20.000000000000014, -290.7999999999988, -244.3000000000002, -141.7000000000007, 26.300000000000114, -116.50000000000077, 1.0999999999999865, 44.30000000000023, 10.099999999999966, -276.10000000000036, -192.10000000000056, 20.000000000000014, 17.899999999999984, -196.6000000000003, -233.2, 6.799999999999964, -309.099999999998, -103.89999999999998, -160.60000000000065, -28.000000000000036, -400.0, -462.99999999999886, 33.50000000000024, -162.70000000000064, -45.09999999999976, -15.699999999999747, 23.600000000000065, 20.000000000000014, -30.399999999999885, -5.1999999999999265, 7.399999999999977, 52.40000000000022, 17.899999999999988, 28.100000000000147, -15.699999999999747, -13.599999999999794, -5.1999999999999265, -142.90000000000066, -355.1999999999993, -323.4999999999999, -360.1, 17.29999999999998, 3.1999999999999615, -16.29999999999979, 23.30000000000007, 47.00000000000022, 7.399999999999965, -351.6999999999996, -286.60000000000014, -0.10000000000001347, 26.60000000000013, 5.299999999999965, 22.400000000000055, 3.5000000000000173, 20.000000000000014, 39.800000000000246, -103.90000000000053, -248.8, -34.59999999999975, 5.299999999999965, 31.70000000000022, 20.000000000000014, -387.4, 16.09999999999996, 13.999999999999973, -664.0, -253.00000000000023, 20.000000000000014, -0.9999999999999846, -238.30000000000044, -120.70000000000056, -21.999999999999744, -0.9999999999999846, -238.50000000000065, 15.799999999999963], "policy_predator_policy_reward": [14.0, 5.0, 400.0, 335.0, 344.0, 237.0, 7.0, 18.0, 6.0, 83.0, 33.0, 2.0, 7.0, 146.0, 3.0, 0.0, 10.0, 46.0, 668.0, 493.0, 1.0, 232.0, 22.0, 362.0, 20.0, 362.0, 159.0, 7.0, 15.0, 181.0, 0.0, 363.0, 1.0, 2.0, 334.0, 289.0, 19.0, 26.0, 390.0, 266.0, 200.0, 4.0, 160.0, 197.0, 17.0, 3.0, 22.0, 22.0, 282.0, 379.0, 176.0, 0.0, 258.0, 5.0, 12.0, 6.0, 271.0, 522.0, 54.0, 121.0, 204.0, 11.0, 9.0, 16.0, 0.0, 279.0, 15.0, 7.0, 325.0, 412.0, 8.0, 162.0, 204.0, 335.0, 6.0, 8.0, 168.0, 260.0, 8.0, 10.0, 16.0, 134.0, 33.0, 18.0, 19.0, 4.0, 177.0, 32.0, 1.0, 158.0, 172.0, 2.0, 21.0, 17.0, 12.0, 16.0, 9.0, 9.0, 11.0, 20.0, 73.0, 139.0, 14.0, 7.0, 4.0, 5.0, 75.0, 5.0, 323.0, 243.0, 169.0, 7.0, 11.0, 188.0, 111.0, 2.0, 0.0, 17.0, 124.0, 10.0, 9.0, 199.0, 452.0, 89.0, 0.0, 5.0, 149.0, 101.0, 0.0, 77.0, 65.0, 9.0, 3.0, 4.0, 141.0, 101.0, 4.0, 3.0, 166.0, 108.0, 13.0, 223.0, 4.0, 148.0, 188.0, 186.0, 312.0, 138.0, 63.0, 87.0, 17.0, 8.0, 16.0, 16.0, 12.0, 15.0, 3.0, 1.0, 1.0, 17.0, 0.0, 23.0, 168.0, 125.0, 185.0, 115.0, 8.0, 9.0, 25.0, 15.0, 1.0, 6.0, 200.0, 198.0, 8.0, 13.0, 7.0, 10.0, 13.0, 10.0, 35.0, 55.0, 4.0, 163.0, 5.0, 4.0, 178.0, 172.0, 20.0, 10.0, 309.0, 361.0, 6.0, 10.0, 123.0, 116.0, 21.0, 3.0, 175.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5655473591531988, "mean_inference_ms": 1.8021084598210353, "mean_action_processing_ms": 0.2358216586669284, "mean_env_wait_ms": 0.19150131078192595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004003286361694336, "StateBufferConnector_ms": 0.0033757686614990234, "ViewRequirementAgentConnector_ms": 0.09070491790771484}, "num_episodes": 18, "episode_return_max": 80.79999999999926, "episode_return_min": -518.0, "episode_return_mean": -105.60999999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 406.1934786218769, "num_env_steps_trained_throughput_per_sec": 406.1934786218769, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 9738.22, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9738.182, "sample_time_ms": 1285.703, "learn_time_ms": 8437.55, "learn_throughput": 474.071, "synch_weights_time_ms": 13.619}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-04-55", "timestamp": 1723644295, "time_this_iter_s": 9.852515935897827, "time_total_s": 161.51906871795654, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8addc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 161.51906871795654, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 28.58, "ram_util_percent": 82.18666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.25466146481731, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.6032776111017455, "policy_loss": 0.002053942329560717, "vf_loss": 4.560691383276036, "vf_explained_var": 0.3958450850355562, "kl": 0.011861294381588389, "entropy": 0.957320822483648, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.139980956170925, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.877109631154903, "policy_loss": 0.0028566738898575146, "vf_loss": 3.8290625008325727, "vf_explained_var": -0.0027324021808684817, "kl": 0.013224457010136626, "entropy": 1.2355598998763573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 111.29999999999923, "episode_reward_min": -518.0, "episode_reward_mean": -84.60699999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -664.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 52.40000000000022, "predator_policy": 522.0}, "policy_reward_mean": {"prey_policy": -127.24349999999998, "predator_policy": 84.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [52.60000000000044, 21.19999999999976, -343.1000000000006, -256.1, 64.20000000000037, 2.100000000000215, -302.2000000000003, -243.90000000000038, -415.3, 26.500000000000085, -283.0, -253.30000000000086, -189.40000000000012, 53.00000000000048, -496.7, 47.30000000000043, -301.4, -327.5999999999973, -355.9000000000002, 60.000000000000476, -157.09999999999988, 70.30000000000001, -315.79999999999995, 6.4000000000000945, 25.80000000000009, -339.29999999999995, -131.30000000000064, -122.9000000000002, 53.700000000000486, 12.799999999999994, 39.100000000000286, 66.50000000000023, -109.20000000000081, 56.500000000000426, 52.60000000000048, -78.90000000000003, -312.0999999999999, -137.40000000000038, -178.9000000000008, -69.90000000000003, 40.2000000000003, -100.19999999999999, -255.10000000000082, -518.0, 34.50000000000022, -285.09999999999803, -38.39999999999959, -41.399999999999906, 61.40000000000048, -226.2000000000009, 44.900000000000375, -155.8000000000004, -66.30000000000106, -112.50000000000009, -53.999999999999844, 20.50000000000022, -57.80000000000091, 32.9000000000002, 21.599999999999994, 29.200000000000166, 74.29999999999974, 30.40000000000016, 4.200000000000195, -205.10000000000082, -383.5999999999999, 37.50000000000026, 47.0000000000004, 61.40000000000045, -240.3000000000003, 47.50000000000043, 44.70000000000039, 46.50000000000042, 25.900000000000162, -116.40000000000038, 46.00000000000041, -17.399999999999842, 60.10000000000044, -247.00000000000023, 35.00000000000023, -120.000000000001, 1.0000000000002427, -45.69999999999962, 36.70000000000025, 41.900000000000325, -379.5000000000002, -42.29999999999969, -288.19999999999845, -128.40000000000035, -130.0000000000007, -41.99999999999965, -150.000000000001, 46.70000000000043, 41.900000000000325, -35.89999999999956, -166.6000000000006, 1.1000000000002002, 41.60000000000035, -27.699999999999804, 111.29999999999923, 58.40000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [50.60000000000022, -42.99999999999976, -600.5, -34.299999999999855, -385.30000000000007, -161.80000000000052, -215.20000000000002, -397.9, 5.899999999999967, 38.300000000000175, -15.699999999999747, -26.199999999999747, -408.0, -555.2000000000003, -232.00000000000043, -187.90000000000003, -353.8, -324.5, 13.699999999999967, -5.1999999999999265, -597.9, -478.1, -316.0000000000002, -112.29999999999986, -166.89999999999998, -237.50000000000048, -1.9, 29.90000000000018, -427.8, -347.9, 36.8000000000002, -11.499999999999819, -397.9, -640.5, -177.40000000000046, -320.1999999999993, -362.2000000000001, -532.7, 23.600000000000072, 22.400000000000055, -217.50000000000003, -367.6, 31.40000000000022, 20.90000000000003, -233.8, -231.99999999999994, 4.699999999999978, -49.299999999999805, 3.199999999999965, -0.40000000000002056, -295.0, -253.29999999999998, 21.500000000000036, -311.79999999999967, -114.40000000000077, -182.49999999999994, -28.29999999999975, 44.00000000000024, -24.699999999999754, 9.499999999999966, 1.0999999999999865, 20.000000000000014, 19.400000000000013, 16.099999999999962, -330.69999999999936, 9.499999999999968, 1.0999999999999865, 34.40000000000021, 11.599999999999964, 32.00000000000022, -26.499999999999847, -132.39999999999984, -330.7, -547.3999999999999, 21.500000000000036, -334.9000000000002, -3.099999999999958, -374.7999999999997, 3.199999999999965, -186.1000000000003, -13.899999999999782, 37.10000000000026, 6.199999999999999, -240.3999999999999, -397.9, -65.20000000000078, -547.0, -512.0, 9.499999999999964, 20.000000000000014, -290.7999999999988, -244.3000000000002, -141.7000000000007, 26.300000000000114, -116.50000000000077, 1.0999999999999865, 44.30000000000023, 10.099999999999966, -276.10000000000036, -192.10000000000056, 20.000000000000014, 17.899999999999984, -196.6000000000003, -233.2, 6.799999999999964, -309.099999999998, -103.89999999999998, -160.60000000000065, -28.000000000000036, -400.0, -462.99999999999886, 33.50000000000024, -162.70000000000064, -45.09999999999976, -15.699999999999747, 23.600000000000065, 20.000000000000014, -30.399999999999885, -5.1999999999999265, 7.399999999999977, 52.40000000000022, 17.899999999999988, 28.100000000000147, -15.699999999999747, -13.599999999999794, -5.1999999999999265, -142.90000000000066, -355.1999999999993, -323.4999999999999, -360.1, 17.29999999999998, 3.1999999999999615, -16.29999999999979, 23.30000000000007, 47.00000000000022, 7.399999999999965, -351.6999999999996, -286.60000000000014, -0.10000000000001347, 26.60000000000013, 5.299999999999965, 22.400000000000055, 3.5000000000000173, 20.000000000000014, 39.800000000000246, -103.90000000000053, -248.8, -34.59999999999975, 5.299999999999965, 31.70000000000022, 20.000000000000014, -387.4, 16.09999999999996, 13.999999999999973, -664.0, -253.00000000000023, 20.000000000000014, -0.9999999999999846, -238.30000000000044, -120.70000000000056, -21.999999999999744, -0.9999999999999846, -238.50000000000065, 15.799999999999963, 8.89999999999997, -8.19999999999993, 11.89999999999997, 20.000000000000014, -296.9, -307.60000000000025, -297.0999999999989, -47.19999999999976, -627.0999999999993, -159.10000000000036, -292.9, 9.499999999999964, 25.100000000000108, -339.09999999999934, -82.90000000000086, -120.10000000000008, -95.50000000000077, -209.49999999999991, -12.699999999999815, 25.400000000000112, 14.899999999999967, 20.000000000000014, 9.499999999999964, -114.40000000000074, -400.0, 28.40000000000016, 10.700000000000017, -55.600000000000335, 15.199999999999974, 7.399999999999965, -9.999999999999895, -99.70000000000026, 38.900000000000254, -371.599999999999, 38.60000000000022, -5.1999999999999265], "policy_predator_policy_reward": [19.0, 26.0, 390.0, 266.0, 200.0, 4.0, 160.0, 197.0, 17.0, 3.0, 22.0, 22.0, 282.0, 379.0, 176.0, 0.0, 258.0, 5.0, 12.0, 6.0, 271.0, 522.0, 54.0, 121.0, 204.0, 11.0, 9.0, 16.0, 0.0, 279.0, 15.0, 7.0, 325.0, 412.0, 8.0, 162.0, 204.0, 335.0, 6.0, 8.0, 168.0, 260.0, 8.0, 10.0, 16.0, 134.0, 33.0, 18.0, 19.0, 4.0, 177.0, 32.0, 1.0, 158.0, 172.0, 2.0, 21.0, 17.0, 12.0, 16.0, 9.0, 9.0, 11.0, 20.0, 73.0, 139.0, 14.0, 7.0, 4.0, 5.0, 75.0, 5.0, 323.0, 243.0, 169.0, 7.0, 11.0, 188.0, 111.0, 2.0, 0.0, 17.0, 124.0, 10.0, 9.0, 199.0, 452.0, 89.0, 0.0, 5.0, 149.0, 101.0, 0.0, 77.0, 65.0, 9.0, 3.0, 4.0, 141.0, 101.0, 4.0, 3.0, 166.0, 108.0, 13.0, 223.0, 4.0, 148.0, 188.0, 186.0, 312.0, 138.0, 63.0, 87.0, 17.0, 8.0, 16.0, 16.0, 12.0, 15.0, 3.0, 1.0, 1.0, 17.0, 0.0, 23.0, 168.0, 125.0, 185.0, 115.0, 8.0, 9.0, 25.0, 15.0, 1.0, 6.0, 200.0, 198.0, 8.0, 13.0, 7.0, 10.0, 13.0, 10.0, 35.0, 55.0, 4.0, 163.0, 5.0, 4.0, 178.0, 172.0, 20.0, 10.0, 309.0, 361.0, 6.0, 10.0, 123.0, 116.0, 21.0, 3.0, 175.0, 2.0, 10.0, 26.0, 1.0, 9.0, 7.0, 218.0, 151.0, 151.0, 3.0, 495.0, 2.0, 153.0, 13.0, 171.0, 83.0, 78.0, 1.0, 154.0, 18.0, 16.0, 3.0, 4.0, 5.0, 64.0, 200.0, 5.0, 10.0, 36.0, 13.0, 6.0, 79.0, 3.0, 228.0, 216.0, 13.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5634238888195265, "mean_inference_ms": 1.7952408556908923, "mean_action_processing_ms": 0.23549816010440844, "mean_env_wait_ms": 0.19068148702689514, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004088401794433594, "StateBufferConnector_ms": 0.0033909082412719727, "ViewRequirementAgentConnector_ms": 0.09135925769805908}, "num_episodes": 18, "episode_return_max": 111.29999999999923, "episode_return_min": -518.0, "episode_return_mean": -84.60699999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 415.0089260277696, "num_env_steps_trained_throughput_per_sec": 415.0089260277696, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 9694.396, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9694.36, "sample_time_ms": 1286.348, "learn_time_ms": 8393.376, "learn_throughput": 476.566, "synch_weights_time_ms": 13.694}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-05-05", "timestamp": 1723644305, "time_this_iter_s": 9.64427375793457, "time_total_s": 171.1633424758911, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 171.1633424758911, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 29.88461538461538, "ram_util_percent": 82.33846153846153}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.172264118232424, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.365430970166726, "policy_loss": 0.002185563524820344, "vf_loss": 4.312083015744649, "vf_explained_var": 0.2947310951336351, "kl": 0.014972075174221201, "entropy": 0.9816849849526844, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.974378780113957, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 2.940573662109476, "policy_loss": 0.0010891534186032398, "vf_loss": 2.8963141518925863, "vf_explained_var": -0.0012895946464841327, "kl": 0.012633300772242284, "entropy": 1.2102701421452577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 111.29999999999923, "episode_reward_min": -518.0, "episode_reward_mean": -60.51500000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -664.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 52.40000000000022, "predator_policy": 495.0}, "policy_reward_mean": {"prey_policy": -98.9375, "predator_policy": 68.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-315.79999999999995, 6.4000000000000945, 25.80000000000009, -339.29999999999995, -131.30000000000064, -122.9000000000002, 53.700000000000486, 12.799999999999994, 39.100000000000286, 66.50000000000023, -109.20000000000081, 56.500000000000426, 52.60000000000048, -78.90000000000003, -312.0999999999999, -137.40000000000038, -178.9000000000008, -69.90000000000003, 40.2000000000003, -100.19999999999999, -255.10000000000082, -518.0, 34.50000000000022, -285.09999999999803, -38.39999999999959, -41.399999999999906, 61.40000000000048, -226.2000000000009, 44.900000000000375, -155.8000000000004, -66.30000000000106, -112.50000000000009, -53.999999999999844, 20.50000000000022, -57.80000000000091, 32.9000000000002, 21.599999999999994, 29.200000000000166, 74.29999999999974, 30.40000000000016, 4.200000000000195, -205.10000000000082, -383.5999999999999, 37.50000000000026, 47.0000000000004, 61.40000000000045, -240.3000000000003, 47.50000000000043, 44.70000000000039, 46.50000000000042, 25.900000000000162, -116.40000000000038, 46.00000000000041, -17.399999999999842, 60.10000000000044, -247.00000000000023, 35.00000000000023, -120.000000000001, 1.0000000000002427, -45.69999999999962, 36.70000000000025, 41.900000000000325, -379.5000000000002, -42.29999999999969, -288.19999999999845, -128.40000000000035, -130.0000000000007, -41.99999999999965, -150.000000000001, 46.70000000000043, 41.900000000000325, -35.89999999999956, -166.6000000000006, 1.1000000000002002, 41.60000000000035, -27.699999999999804, 111.29999999999923, 58.40000000000045, -3.99999999999971, 23.800000000000068, 7.200000000000074, 62.50000000000048, -229.50000000000097, -166.20000000000064, 28.00000000000031, -149.5000000000004, 27.800000000000107, -123.30000000000095, -21.699999999999584, 6.300000000000077, -102.70000000000104, 31.700000000000184, -198.0000000000012, 53.40000000000048, 27.200000000000102, -93.50000000000092, -69.60000000000119, 16.499999999999996, -155.60000000000076, -89.40000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-233.8, -231.99999999999994, 4.699999999999978, -49.299999999999805, 3.199999999999965, -0.40000000000002056, -295.0, -253.29999999999998, 21.500000000000036, -311.79999999999967, -114.40000000000077, -182.49999999999994, -28.29999999999975, 44.00000000000024, -24.699999999999754, 9.499999999999966, 1.0999999999999865, 20.000000000000014, 19.400000000000013, 16.099999999999962, -330.69999999999936, 9.499999999999968, 1.0999999999999865, 34.40000000000021, 11.599999999999964, 32.00000000000022, -26.499999999999847, -132.39999999999984, -330.7, -547.3999999999999, 21.500000000000036, -334.9000000000002, -3.099999999999958, -374.7999999999997, 3.199999999999965, -186.1000000000003, -13.899999999999782, 37.10000000000026, 6.199999999999999, -240.3999999999999, -397.9, -65.20000000000078, -547.0, -512.0, 9.499999999999964, 20.000000000000014, -290.7999999999988, -244.3000000000002, -141.7000000000007, 26.300000000000114, -116.50000000000077, 1.0999999999999865, 44.30000000000023, 10.099999999999966, -276.10000000000036, -192.10000000000056, 20.000000000000014, 17.899999999999984, -196.6000000000003, -233.2, 6.799999999999964, -309.099999999998, -103.89999999999998, -160.60000000000065, -28.000000000000036, -400.0, -462.99999999999886, 33.50000000000024, -162.70000000000064, -45.09999999999976, -15.699999999999747, 23.600000000000065, 20.000000000000014, -30.399999999999885, -5.1999999999999265, 7.399999999999977, 52.40000000000022, 17.899999999999988, 28.100000000000147, -15.699999999999747, -13.599999999999794, -5.1999999999999265, -142.90000000000066, -355.1999999999993, -323.4999999999999, -360.1, 17.29999999999998, 3.1999999999999615, -16.29999999999979, 23.30000000000007, 47.00000000000022, 7.399999999999965, -351.6999999999996, -286.60000000000014, -0.10000000000001347, 26.60000000000013, 5.299999999999965, 22.400000000000055, 3.5000000000000173, 20.000000000000014, 39.800000000000246, -103.90000000000053, -248.8, -34.59999999999975, 5.299999999999965, 31.70000000000022, 20.000000000000014, -387.4, 16.09999999999996, 13.999999999999973, -664.0, -253.00000000000023, 20.000000000000014, -0.9999999999999846, -238.30000000000044, -120.70000000000056, -21.999999999999744, -0.9999999999999846, -238.50000000000065, 15.799999999999963, 8.89999999999997, -8.19999999999993, 11.89999999999997, 20.000000000000014, -296.9, -307.60000000000025, -297.0999999999989, -47.19999999999976, -627.0999999999993, -159.10000000000036, -292.9, 9.499999999999964, 25.100000000000108, -339.09999999999934, -82.90000000000086, -120.10000000000008, -95.50000000000077, -209.49999999999991, -12.699999999999815, 25.400000000000112, 14.899999999999967, 20.000000000000014, 9.499999999999964, -114.40000000000074, -400.0, 28.40000000000016, 10.700000000000017, -55.600000000000335, 15.199999999999974, 7.399999999999965, -9.999999999999895, -99.70000000000026, 38.900000000000254, -371.599999999999, 38.60000000000022, -5.1999999999999265, -51.400000000000006, 7.399999999999965, -85.00000000000085, 21.80000000000004, -47.199999999999775, 16.399999999999967, 17.599999999999984, 29.90000000000018, -190.90000000000038, -181.6000000000006, -182.20000000000013, -145.00000000000048, 47.90000000000024, -103.90000000000052, -57.69999999999998, -248.8000000000004, -5.1999999999999265, 20.000000000000014, -0.10000000000001347, -278.1999999999988, 5.299999999999965, -148.00000000000065, 18.800000000000008, -68.50000000000087, -106.0000000000008, -291.699999999999, -0.9999999999999846, 13.69999999999997, -190.00000000000057, -169.00000000000063, 12.499999999999972, 20.900000000000027, 26.00000000000011, -17.79999999999975, -40.89999999999981, -360.5999999999992, -278.2, -51.40000000000002, -7.299999999999891, 9.799999999999967, -296.1999999999998, -156.40000000000066, -71.60000000000011, -161.80000000000035], "policy_predator_policy_reward": [16.0, 134.0, 33.0, 18.0, 19.0, 4.0, 177.0, 32.0, 1.0, 158.0, 172.0, 2.0, 21.0, 17.0, 12.0, 16.0, 9.0, 9.0, 11.0, 20.0, 73.0, 139.0, 14.0, 7.0, 4.0, 5.0, 75.0, 5.0, 323.0, 243.0, 169.0, 7.0, 11.0, 188.0, 111.0, 2.0, 0.0, 17.0, 124.0, 10.0, 9.0, 199.0, 452.0, 89.0, 0.0, 5.0, 149.0, 101.0, 0.0, 77.0, 65.0, 9.0, 3.0, 4.0, 141.0, 101.0, 4.0, 3.0, 166.0, 108.0, 13.0, 223.0, 4.0, 148.0, 188.0, 186.0, 312.0, 138.0, 63.0, 87.0, 17.0, 8.0, 16.0, 16.0, 12.0, 15.0, 3.0, 1.0, 1.0, 17.0, 0.0, 23.0, 168.0, 125.0, 185.0, 115.0, 8.0, 9.0, 25.0, 15.0, 1.0, 6.0, 200.0, 198.0, 8.0, 13.0, 7.0, 10.0, 13.0, 10.0, 35.0, 55.0, 4.0, 163.0, 5.0, 4.0, 178.0, 172.0, 20.0, 10.0, 309.0, 361.0, 6.0, 10.0, 123.0, 116.0, 21.0, 3.0, 175.0, 2.0, 10.0, 26.0, 1.0, 9.0, 7.0, 218.0, 151.0, 151.0, 3.0, 495.0, 2.0, 153.0, 13.0, 171.0, 83.0, 78.0, 1.0, 154.0, 18.0, 16.0, 3.0, 4.0, 5.0, 64.0, 200.0, 5.0, 10.0, 36.0, 13.0, 6.0, 79.0, 3.0, 228.0, 216.0, 13.0, 12.0, 34.0, 6.0, 50.0, 37.0, 32.0, 6.0, 4.0, 11.0, 140.0, 3.0, 151.0, 10.0, 32.0, 52.0, 51.0, 106.0, 12.0, 1.0, 13.0, 142.0, 53.0, 68.0, 43.0, 13.0, 139.0, 156.0, 9.0, 10.0, 100.0, 61.0, 11.0, 9.0, 7.0, 12.0, 116.0, 192.0, 122.0, 138.0, 2.0, 12.0, 134.0, 163.0, 141.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5610524131630038, "mean_inference_ms": 1.7882197217014897, "mean_action_processing_ms": 0.23499175480083537, "mean_env_wait_ms": 0.18983626972678141, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005672574043273926, "StateBufferConnector_ms": 0.0032732486724853516, "ViewRequirementAgentConnector_ms": 0.09223687648773193}, "num_episodes": 22, "episode_return_max": 111.29999999999923, "episode_return_min": -518.0, "episode_return_mean": -60.51500000000003, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.50531189431274, "num_env_steps_trained_throughput_per_sec": 409.50531189431274, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 9668.297, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9668.26, "sample_time_ms": 1260.878, "learn_time_ms": 8392.556, "learn_throughput": 476.613, "synch_weights_time_ms": 13.879}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-05-15", "timestamp": 1723644315, "time_this_iter_s": 9.774207830429077, "time_total_s": 180.9375503063202, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31876c790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 180.9375503063202, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 29.892857142857142, "ram_util_percent": 82.67142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.264560335874558, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.77224548039613, "policy_loss": 0.00420977512901777, "vf_loss": 4.7153977920138646, "vf_explained_var": 0.10521341373050024, "kl": 0.015403870066578415, "entropy": 0.9805697088203733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.259794213879045, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.834576724193714, "policy_loss": 0.004523736490528026, "vf_loss": 3.7840963503671072, "vf_explained_var": 0.0017003705261876344, "kl": 0.013448672360495573, "entropy": 1.2178045648431022, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 111.29999999999923, "episode_reward_min": -383.5999999999999, "episode_reward_mean": -44.51499999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -664.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 52.40000000000022, "predator_policy": 495.0}, "policy_reward_mean": {"prey_policy": -86.35750000000002, "predator_policy": 64.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-285.09999999999803, -38.39999999999959, -41.399999999999906, 61.40000000000048, -226.2000000000009, 44.900000000000375, -155.8000000000004, -66.30000000000106, -112.50000000000009, -53.999999999999844, 20.50000000000022, -57.80000000000091, 32.9000000000002, 21.599999999999994, 29.200000000000166, 74.29999999999974, 30.40000000000016, 4.200000000000195, -205.10000000000082, -383.5999999999999, 37.50000000000026, 47.0000000000004, 61.40000000000045, -240.3000000000003, 47.50000000000043, 44.70000000000039, 46.50000000000042, 25.900000000000162, -116.40000000000038, 46.00000000000041, -17.399999999999842, 60.10000000000044, -247.00000000000023, 35.00000000000023, -120.000000000001, 1.0000000000002427, -45.69999999999962, 36.70000000000025, 41.900000000000325, -379.5000000000002, -42.29999999999969, -288.19999999999845, -128.40000000000035, -130.0000000000007, -41.99999999999965, -150.000000000001, 46.70000000000043, 41.900000000000325, -35.89999999999956, -166.6000000000006, 1.1000000000002002, 41.60000000000035, -27.699999999999804, 111.29999999999923, 58.40000000000045, -3.99999999999971, 23.800000000000068, 7.200000000000074, 62.50000000000048, -229.50000000000097, -166.20000000000064, 28.00000000000031, -149.5000000000004, 27.800000000000107, -123.30000000000095, -21.699999999999584, 6.300000000000077, -102.70000000000104, 31.700000000000184, -198.0000000000012, 53.40000000000048, 27.200000000000102, -93.50000000000092, -69.60000000000119, 16.499999999999996, -155.60000000000076, -89.40000000000026, 55.400000000000496, 72.59999999999975, -145.00000000000142, 39.000000000000284, -108.20000000000023, -314.2999999999976, -53.700000000001005, 50.600000000000485, 18.299999999999997, -49.09999999999976, -382.19999999999976, 61.300000000000466, 40.000000000000334, 4.600000000000172, -11.699999999999605, -256.60000000000093, 47.10000000000027, -3.99999999999971, 19.399999999999995, 60.40000000000042, 41.200000000000315, 71.19999999999996, 62.80000000000039], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-290.7999999999988, -244.3000000000002, -141.7000000000007, 26.300000000000114, -116.50000000000077, 1.0999999999999865, 44.30000000000023, 10.099999999999966, -276.10000000000036, -192.10000000000056, 20.000000000000014, 17.899999999999984, -196.6000000000003, -233.2, 6.799999999999964, -309.099999999998, -103.89999999999998, -160.60000000000065, -28.000000000000036, -400.0, -462.99999999999886, 33.50000000000024, -162.70000000000064, -45.09999999999976, -15.699999999999747, 23.600000000000065, 20.000000000000014, -30.399999999999885, -5.1999999999999265, 7.399999999999977, 52.40000000000022, 17.899999999999988, 28.100000000000147, -15.699999999999747, -13.599999999999794, -5.1999999999999265, -142.90000000000066, -355.1999999999993, -323.4999999999999, -360.1, 17.29999999999998, 3.1999999999999615, -16.29999999999979, 23.30000000000007, 47.00000000000022, 7.399999999999965, -351.6999999999996, -286.60000000000014, -0.10000000000001347, 26.60000000000013, 5.299999999999965, 22.400000000000055, 3.5000000000000173, 20.000000000000014, 39.800000000000246, -103.90000000000053, -248.8, -34.59999999999975, 5.299999999999965, 31.70000000000022, 20.000000000000014, -387.4, 16.09999999999996, 13.999999999999973, -664.0, -253.00000000000023, 20.000000000000014, -0.9999999999999846, -238.30000000000044, -120.70000000000056, -21.999999999999744, -0.9999999999999846, -238.50000000000065, 15.799999999999963, 8.89999999999997, -8.19999999999993, 11.89999999999997, 20.000000000000014, -296.9, -307.60000000000025, -297.0999999999989, -47.19999999999976, -627.0999999999993, -159.10000000000036, -292.9, 9.499999999999964, 25.100000000000108, -339.09999999999934, -82.90000000000086, -120.10000000000008, -95.50000000000077, -209.49999999999991, -12.699999999999815, 25.400000000000112, 14.899999999999967, 20.000000000000014, 9.499999999999964, -114.40000000000074, -400.0, 28.40000000000016, 10.700000000000017, -55.600000000000335, 15.199999999999974, 7.399999999999965, -9.999999999999895, -99.70000000000026, 38.900000000000254, -371.599999999999, 38.60000000000022, -5.1999999999999265, -51.400000000000006, 7.399999999999965, -85.00000000000085, 21.80000000000004, -47.199999999999775, 16.399999999999967, 17.599999999999984, 29.90000000000018, -190.90000000000038, -181.6000000000006, -182.20000000000013, -145.00000000000048, 47.90000000000024, -103.90000000000052, -57.69999999999998, -248.8000000000004, -5.1999999999999265, 20.000000000000014, -0.10000000000001347, -278.1999999999988, 5.299999999999965, -148.00000000000065, 18.800000000000008, -68.50000000000087, -106.0000000000008, -291.699999999999, -0.9999999999999846, 13.69999999999997, -190.00000000000057, -169.00000000000063, 12.499999999999972, 20.900000000000027, 26.00000000000011, -17.79999999999975, -40.89999999999981, -360.5999999999992, -278.2, -51.40000000000002, -7.299999999999891, 9.799999999999967, -296.1999999999998, -156.40000000000066, -71.60000000000011, -161.80000000000035, 20.000000000000014, 22.400000000000052, 22.700000000000053, 32.90000000000018, -78.70000000000087, -196.30000000000055, 20.000000000000014, -0.9999999999999846, -249.10000000000002, -24.099999999999746, -248.8000000000004, -326.4999999999992, -72.40000000000086, -28.299999999999777, 20.000000000000014, 14.599999999999966, -160.60000000000053, 20.90000000000003, -3.099999999999958, -127.00000000000037, -379.1999999999998, -499.9999999999991, 20.000000000000014, 29.30000000000018, 21.200000000000045, -8.199999999999912, -11.799999999999818, -1.5999999999999996, -72.40000000000087, 13.699999999999964, -213.1, -221.50000000000048, 16.09999999999996, -256.0, 7.399999999999965, -51.40000000000005, -97.6000000000008, 20.000000000000014, 49.70000000000024, -94.3000000000007, 1.0999999999999794, 28.100000000000147, 48.20000000000023, 20.000000000000014, 26.60000000000013, 21.20000000000004], "policy_predator_policy_reward": [149.0, 101.0, 0.0, 77.0, 65.0, 9.0, 3.0, 4.0, 141.0, 101.0, 4.0, 3.0, 166.0, 108.0, 13.0, 223.0, 4.0, 148.0, 188.0, 186.0, 312.0, 138.0, 63.0, 87.0, 17.0, 8.0, 16.0, 16.0, 12.0, 15.0, 3.0, 1.0, 1.0, 17.0, 0.0, 23.0, 168.0, 125.0, 185.0, 115.0, 8.0, 9.0, 25.0, 15.0, 1.0, 6.0, 200.0, 198.0, 8.0, 13.0, 7.0, 10.0, 13.0, 10.0, 35.0, 55.0, 4.0, 163.0, 5.0, 4.0, 178.0, 172.0, 20.0, 10.0, 309.0, 361.0, 6.0, 10.0, 123.0, 116.0, 21.0, 3.0, 175.0, 2.0, 10.0, 26.0, 1.0, 9.0, 7.0, 218.0, 151.0, 151.0, 3.0, 495.0, 2.0, 153.0, 13.0, 171.0, 83.0, 78.0, 1.0, 154.0, 18.0, 16.0, 3.0, 4.0, 5.0, 64.0, 200.0, 5.0, 10.0, 36.0, 13.0, 6.0, 79.0, 3.0, 228.0, 216.0, 13.0, 12.0, 34.0, 6.0, 50.0, 37.0, 32.0, 6.0, 4.0, 11.0, 140.0, 3.0, 151.0, 10.0, 32.0, 52.0, 51.0, 106.0, 12.0, 1.0, 13.0, 142.0, 53.0, 68.0, 43.0, 13.0, 139.0, 156.0, 9.0, 10.0, 100.0, 61.0, 11.0, 9.0, 7.0, 12.0, 116.0, 192.0, 122.0, 138.0, 2.0, 12.0, 134.0, 163.0, 141.0, 3.0, 6.0, 7.0, 0.0, 17.0, 27.0, 103.0, 10.0, 10.0, 8.0, 157.0, 166.0, 95.0, 2.0, 45.0, 7.0, 9.0, 85.0, 73.0, 81.0, 0.0, 12.0, 485.0, 4.0, 8.0, 23.0, 4.0, 2.0, 16.0, 44.0, 3.0, 131.0, 47.0, 144.0, 143.0, 34.0, 6.0, 42.0, 55.0, 57.0, 48.0, 9.0, 3.0, 2.0, 1.0, 14.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5591027474640358, "mean_inference_ms": 1.7795948148209222, "mean_action_processing_ms": 0.2347432227362262, "mean_env_wait_ms": 0.1888623401522625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0054836273193359375, "StateBufferConnector_ms": 0.0031239986419677734, "ViewRequirementAgentConnector_ms": 0.08908748626708984}, "num_episodes": 23, "episode_return_max": 111.29999999999923, "episode_return_min": -383.5999999999999, "episode_return_mean": -44.51499999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 413.01846388109317, "num_env_steps_trained_throughput_per_sec": 413.01846388109317, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 9716.209, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9716.174, "sample_time_ms": 1262.173, "learn_time_ms": 8439.743, "learn_throughput": 473.948, "synch_weights_time_ms": 13.33}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-05-24", "timestamp": 1723644324, "time_this_iter_s": 9.689898014068604, "time_total_s": 190.6274483203888, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187484c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 190.6274483203888, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 27.9, "ram_util_percent": 82.70714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.341251207186431, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.169972397852196, "policy_loss": -0.0002323446996145384, "vf_loss": 3.152799334034087, "vf_explained_var": 0.05425068587853164, "kl": 0.00509348870702709, "entropy": 0.9979301158397916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.779936773089505, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 2.6129604645507047, "policy_loss": 0.0015555862630544988, "vf_loss": 2.570874127761397, "vf_explained_var": -0.0008413908342835765, "kl": 0.01186085062877176, "entropy": 1.104102169363587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 111.29999999999923, "episode_reward_min": -383.5999999999999, "episode_reward_mean": -38.65500000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -664.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 57.20000000000021, "predator_policy": 495.0}, "policy_reward_mean": {"prey_policy": -80.13750000000005, "predator_policy": 60.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-205.10000000000082, -383.5999999999999, 37.50000000000026, 47.0000000000004, 61.40000000000045, -240.3000000000003, 47.50000000000043, 44.70000000000039, 46.50000000000042, 25.900000000000162, -116.40000000000038, 46.00000000000041, -17.399999999999842, 60.10000000000044, -247.00000000000023, 35.00000000000023, -120.000000000001, 1.0000000000002427, -45.69999999999962, 36.70000000000025, 41.900000000000325, -379.5000000000002, -42.29999999999969, -288.19999999999845, -128.40000000000035, -130.0000000000007, -41.99999999999965, -150.000000000001, 46.70000000000043, 41.900000000000325, -35.89999999999956, -166.6000000000006, 1.1000000000002002, 41.60000000000035, -27.699999999999804, 111.29999999999923, 58.40000000000045, -3.99999999999971, 23.800000000000068, 7.200000000000074, 62.50000000000048, -229.50000000000097, -166.20000000000064, 28.00000000000031, -149.5000000000004, 27.800000000000107, -123.30000000000095, -21.699999999999584, 6.300000000000077, -102.70000000000104, 31.700000000000184, -198.0000000000012, 53.40000000000048, 27.200000000000102, -93.50000000000092, -69.60000000000119, 16.499999999999996, -155.60000000000076, -89.40000000000026, 55.400000000000496, 72.59999999999975, -145.00000000000142, 39.000000000000284, -108.20000000000023, -314.2999999999976, -53.700000000001005, 50.600000000000485, 18.299999999999997, -49.09999999999976, -382.19999999999976, 61.300000000000466, 40.000000000000334, 4.600000000000172, -11.699999999999605, -256.60000000000093, 47.10000000000027, -3.99999999999971, 19.399999999999995, 60.40000000000042, 41.200000000000315, 71.19999999999996, 62.80000000000039, 21.40000000000008, -21.59999999999966, 2.300000000000066, -48.30000000000066, -37.89999999999995, -133.30000000000052, 38.70000000000027, 35.500000000000234, 39.40000000000028, -50.89999999999981, -98.10000000000127, 55.80000000000051, 5.100000000000046, -68.60000000000167, 5.999999999999956, 72.49999999999986, 76.99999999999953, -27.099999999999525], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-142.90000000000066, -355.1999999999993, -323.4999999999999, -360.1, 17.29999999999998, 3.1999999999999615, -16.29999999999979, 23.30000000000007, 47.00000000000022, 7.399999999999965, -351.6999999999996, -286.60000000000014, -0.10000000000001347, 26.60000000000013, 5.299999999999965, 22.400000000000055, 3.5000000000000173, 20.000000000000014, 39.800000000000246, -103.90000000000053, -248.8, -34.59999999999975, 5.299999999999965, 31.70000000000022, 20.000000000000014, -387.4, 16.09999999999996, 13.999999999999973, -664.0, -253.00000000000023, 20.000000000000014, -0.9999999999999846, -238.30000000000044, -120.70000000000056, -21.999999999999744, -0.9999999999999846, -238.50000000000065, 15.799999999999963, 8.89999999999997, -8.19999999999993, 11.89999999999997, 20.000000000000014, -296.9, -307.60000000000025, -297.0999999999989, -47.19999999999976, -627.0999999999993, -159.10000000000036, -292.9, 9.499999999999964, 25.100000000000108, -339.09999999999934, -82.90000000000086, -120.10000000000008, -95.50000000000077, -209.49999999999991, -12.699999999999815, 25.400000000000112, 14.899999999999967, 20.000000000000014, 9.499999999999964, -114.40000000000074, -400.0, 28.40000000000016, 10.700000000000017, -55.600000000000335, 15.199999999999974, 7.399999999999965, -9.999999999999895, -99.70000000000026, 38.900000000000254, -371.599999999999, 38.60000000000022, -5.1999999999999265, -51.400000000000006, 7.399999999999965, -85.00000000000085, 21.80000000000004, -47.199999999999775, 16.399999999999967, 17.599999999999984, 29.90000000000018, -190.90000000000038, -181.6000000000006, -182.20000000000013, -145.00000000000048, 47.90000000000024, -103.90000000000052, -57.69999999999998, -248.8000000000004, -5.1999999999999265, 20.000000000000014, -0.10000000000001347, -278.1999999999988, 5.299999999999965, -148.00000000000065, 18.800000000000008, -68.50000000000087, -106.0000000000008, -291.699999999999, -0.9999999999999846, 13.69999999999997, -190.00000000000057, -169.00000000000063, 12.499999999999972, 20.900000000000027, 26.00000000000011, -17.79999999999975, -40.89999999999981, -360.5999999999992, -278.2, -51.40000000000002, -7.299999999999891, 9.799999999999967, -296.1999999999998, -156.40000000000066, -71.60000000000011, -161.80000000000035, 20.000000000000014, 22.400000000000052, 22.700000000000053, 32.90000000000018, -78.70000000000087, -196.30000000000055, 20.000000000000014, -0.9999999999999846, -249.10000000000002, -24.099999999999746, -248.8000000000004, -326.4999999999992, -72.40000000000086, -28.299999999999777, 20.000000000000014, 14.599999999999966, -160.60000000000053, 20.90000000000003, -3.099999999999958, -127.00000000000037, -379.1999999999998, -499.9999999999991, 20.000000000000014, 29.30000000000018, 21.200000000000045, -8.199999999999912, -11.799999999999818, -1.5999999999999996, -72.40000000000087, 13.699999999999964, -213.1, -221.50000000000048, 16.09999999999996, -256.0, 7.399999999999965, -51.40000000000005, -97.6000000000008, 20.000000000000014, 49.70000000000024, -94.3000000000007, 1.0999999999999794, 28.100000000000147, 48.20000000000023, 20.000000000000014, 26.60000000000013, 21.20000000000004, 7.1000000000000085, -15.699999999999754, -97.60000000000062, 20.000000000000014, 47.00000000000021, -192.70000000000073, -64.00000000000088, -70.30000000000089, -68.79999999999987, -66.10000000000075, -615.6, 29.300000000000175, 25.400000000000098, -36.699999999999754, 20.000000000000014, 9.499999999999964, 15.799999999999962, 11.599999999999964, -78.70000000000084, -131.2, -217.3000000000005, -17.799999999999798, 22.700000000000053, 31.100000000000204, -310.7999999999984, 8.899999999999977, -122.80000000000075, -59.80000000000062, -26.799999999999855, -5.199999999999969, 20.000000000000014, 48.50000000000022, 15.799999999999963, 57.20000000000021, 7.399999999999965, -95.50000000000081], "policy_predator_policy_reward": [168.0, 125.0, 185.0, 115.0, 8.0, 9.0, 25.0, 15.0, 1.0, 6.0, 200.0, 198.0, 8.0, 13.0, 7.0, 10.0, 13.0, 10.0, 35.0, 55.0, 4.0, 163.0, 5.0, 4.0, 178.0, 172.0, 20.0, 10.0, 309.0, 361.0, 6.0, 10.0, 123.0, 116.0, 21.0, 3.0, 175.0, 2.0, 10.0, 26.0, 1.0, 9.0, 7.0, 218.0, 151.0, 151.0, 3.0, 495.0, 2.0, 153.0, 13.0, 171.0, 83.0, 78.0, 1.0, 154.0, 18.0, 16.0, 3.0, 4.0, 5.0, 64.0, 200.0, 5.0, 10.0, 36.0, 13.0, 6.0, 79.0, 3.0, 228.0, 216.0, 13.0, 12.0, 34.0, 6.0, 50.0, 37.0, 32.0, 6.0, 4.0, 11.0, 140.0, 3.0, 151.0, 10.0, 32.0, 52.0, 51.0, 106.0, 12.0, 1.0, 13.0, 142.0, 53.0, 68.0, 43.0, 13.0, 139.0, 156.0, 9.0, 10.0, 100.0, 61.0, 11.0, 9.0, 7.0, 12.0, 116.0, 192.0, 122.0, 138.0, 2.0, 12.0, 134.0, 163.0, 141.0, 3.0, 6.0, 7.0, 0.0, 17.0, 27.0, 103.0, 10.0, 10.0, 8.0, 157.0, 166.0, 95.0, 2.0, 45.0, 7.0, 9.0, 85.0, 73.0, 81.0, 0.0, 12.0, 485.0, 4.0, 8.0, 23.0, 4.0, 2.0, 16.0, 44.0, 3.0, 131.0, 47.0, 144.0, 143.0, 34.0, 6.0, 42.0, 55.0, 57.0, 48.0, 9.0, 3.0, 2.0, 1.0, 14.0, 1.0, 17.0, 13.0, 56.0, 0.0, 148.0, 0.0, 45.0, 41.0, 3.0, 94.0, 448.0, 5.0, 25.0, 25.0, 1.0, 5.0, 4.0, 8.0, 98.0, 61.0, 31.0, 106.0, 2.0, 0.0, 107.0, 200.0, 46.0, 68.0, 36.0, 2.0, 4.0, 0.0, 2.0, 2.0, 55.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.557265368091733, "mean_inference_ms": 1.7729773031944627, "mean_action_processing_ms": 0.2340487315876593, "mean_env_wait_ms": 0.18796688750459287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005451202392578125, "StateBufferConnector_ms": 0.003086686134338379, "ViewRequirementAgentConnector_ms": 0.08838200569152832}, "num_episodes": 18, "episode_return_max": 111.29999999999923, "episode_return_min": -383.5999999999999, "episode_return_mean": -38.65500000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 422.50658595099196, "num_env_steps_trained_throughput_per_sec": 422.50658595099196, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 9701.008, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9700.973, "sample_time_ms": 1258.599, "learn_time_ms": 8428.137, "learn_throughput": 474.601, "synch_weights_time_ms": 13.321}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-05-34", "timestamp": 1723644334, "time_this_iter_s": 9.503480911254883, "time_total_s": 200.13092923164368, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318748dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 200.13092923164368, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 29.971428571428568, "ram_util_percent": 82.75714285714288}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5675880592966838, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.672362981397639, "policy_loss": -0.00039636104456370784, "vf_loss": 3.639859761132134, "vf_explained_var": 0.04633417848556761, "kl": 0.009627676179103935, "entropy": 1.0442550766720342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.48283499157618, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.563201591388258, "policy_loss": 0.0022798491655430073, "vf_loss": 3.5264393959095868, "vf_explained_var": -0.0013673935617719377, "kl": 0.010090857223781915, "entropy": 0.9269842021364384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 111.29999999999923, "episode_reward_min": -382.19999999999976, "episode_reward_mean": -37.15900000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -627.0999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 57.20000000000021, "predator_policy": 495.0}, "policy_reward_mean": {"prey_policy": -75.61950000000006, "predator_policy": 57.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-45.69999999999962, 36.70000000000025, 41.900000000000325, -379.5000000000002, -42.29999999999969, -288.19999999999845, -128.40000000000035, -130.0000000000007, -41.99999999999965, -150.000000000001, 46.70000000000043, 41.900000000000325, -35.89999999999956, -166.6000000000006, 1.1000000000002002, 41.60000000000035, -27.699999999999804, 111.29999999999923, 58.40000000000045, -3.99999999999971, 23.800000000000068, 7.200000000000074, 62.50000000000048, -229.50000000000097, -166.20000000000064, 28.00000000000031, -149.5000000000004, 27.800000000000107, -123.30000000000095, -21.699999999999584, 6.300000000000077, -102.70000000000104, 31.700000000000184, -198.0000000000012, 53.40000000000048, 27.200000000000102, -93.50000000000092, -69.60000000000119, 16.499999999999996, -155.60000000000076, -89.40000000000026, 55.400000000000496, 72.59999999999975, -145.00000000000142, 39.000000000000284, -108.20000000000023, -314.2999999999976, -53.700000000001005, 50.600000000000485, 18.299999999999997, -49.09999999999976, -382.19999999999976, 61.300000000000466, 40.000000000000334, 4.600000000000172, -11.699999999999605, -256.60000000000093, 47.10000000000027, -3.99999999999971, 19.399999999999995, 60.40000000000042, 41.200000000000315, 71.19999999999996, 62.80000000000039, 21.40000000000008, -21.59999999999966, 2.300000000000066, -48.30000000000066, -37.89999999999995, -133.30000000000052, 38.70000000000027, 35.500000000000234, 39.40000000000028, -50.89999999999981, -98.10000000000127, 55.80000000000051, 5.100000000000046, -68.60000000000167, 5.999999999999956, 72.49999999999986, 76.99999999999953, -27.099999999999525, -72.60000000000156, -8.999999999999678, 24.50000000000005, -353.69999999999993, 91.69999999999848, -73.39999999999995, 35.90000000000024, -92.50000000000131, 20.499999999999996, -75.10000000000085, 38.00000000000029, 12.499999999999995, -55.69999999999966, 45.6000000000004, 18.899999999999988, -86.30000000000024, -22.59999999999986, -174.3000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-238.50000000000065, 15.799999999999963, 8.89999999999997, -8.19999999999993, 11.89999999999997, 20.000000000000014, -296.9, -307.60000000000025, -297.0999999999989, -47.19999999999976, -627.0999999999993, -159.10000000000036, -292.9, 9.499999999999964, 25.100000000000108, -339.09999999999934, -82.90000000000086, -120.10000000000008, -95.50000000000077, -209.49999999999991, -12.699999999999815, 25.400000000000112, 14.899999999999967, 20.000000000000014, 9.499999999999964, -114.40000000000074, -400.0, 28.40000000000016, 10.700000000000017, -55.600000000000335, 15.199999999999974, 7.399999999999965, -9.999999999999895, -99.70000000000026, 38.900000000000254, -371.599999999999, 38.60000000000022, -5.1999999999999265, -51.400000000000006, 7.399999999999965, -85.00000000000085, 21.80000000000004, -47.199999999999775, 16.399999999999967, 17.599999999999984, 29.90000000000018, -190.90000000000038, -181.6000000000006, -182.20000000000013, -145.00000000000048, 47.90000000000024, -103.90000000000052, -57.69999999999998, -248.8000000000004, -5.1999999999999265, 20.000000000000014, -0.10000000000001347, -278.1999999999988, 5.299999999999965, -148.00000000000065, 18.800000000000008, -68.50000000000087, -106.0000000000008, -291.699999999999, -0.9999999999999846, 13.69999999999997, -190.00000000000057, -169.00000000000063, 12.499999999999972, 20.900000000000027, 26.00000000000011, -17.79999999999975, -40.89999999999981, -360.5999999999992, -278.2, -51.40000000000002, -7.299999999999891, 9.799999999999967, -296.1999999999998, -156.40000000000066, -71.60000000000011, -161.80000000000035, 20.000000000000014, 22.400000000000052, 22.700000000000053, 32.90000000000018, -78.70000000000087, -196.30000000000055, 20.000000000000014, -0.9999999999999846, -249.10000000000002, -24.099999999999746, -248.8000000000004, -326.4999999999992, -72.40000000000086, -28.299999999999777, 20.000000000000014, 14.599999999999966, -160.60000000000053, 20.90000000000003, -3.099999999999958, -127.00000000000037, -379.1999999999998, -499.9999999999991, 20.000000000000014, 29.30000000000018, 21.200000000000045, -8.199999999999912, -11.799999999999818, -1.5999999999999996, -72.40000000000087, 13.699999999999964, -213.1, -221.50000000000048, 16.09999999999996, -256.0, 7.399999999999965, -51.40000000000005, -97.6000000000008, 20.000000000000014, 49.70000000000024, -94.3000000000007, 1.0999999999999794, 28.100000000000147, 48.20000000000023, 20.000000000000014, 26.60000000000013, 21.20000000000004, 7.1000000000000085, -15.699999999999754, -97.60000000000062, 20.000000000000014, 47.00000000000021, -192.70000000000073, -64.00000000000088, -70.30000000000089, -68.79999999999987, -66.10000000000075, -615.6, 29.300000000000175, 25.400000000000098, -36.699999999999754, 20.000000000000014, 9.499999999999964, 15.799999999999962, 11.599999999999964, -78.70000000000084, -131.2, -217.3000000000005, -17.799999999999798, 22.700000000000053, 31.100000000000204, -310.7999999999984, 8.899999999999977, -122.80000000000075, -59.80000000000062, -26.799999999999855, -5.199999999999969, 20.000000000000014, 48.50000000000022, 15.799999999999963, 57.20000000000021, 7.399999999999965, -95.50000000000081, -114.40000000000077, -53.20000000000002, -63.400000000000716, 7.399999999999965, -11.499999999999819, 20.000000000000014, -513.8, -397.9, 42.20000000000021, 42.50000000000025, -32.49999999999975, -145.90000000000003, 20.000000000000014, 8.899999999999967, -120.70000000000056, -53.8, -0.9999999999999846, 0.49999999999998657, -196.30000000000055, 3.2000000000001654, -0.9999999999999846, 10.999999999999982, 5.299999999999965, -17.79999999999977, 20.000000000000014, -162.70000000000053, 17.59999999999998, 20.000000000000014, -7.299999999999901, 9.199999999999969, 26.300000000000114, -509.6, -202.60000000000028, 20.000000000000014, -293.49999999999955, -59.80000000000034], "policy_predator_policy_reward": [175.0, 2.0, 10.0, 26.0, 1.0, 9.0, 7.0, 218.0, 151.0, 151.0, 3.0, 495.0, 2.0, 153.0, 13.0, 171.0, 83.0, 78.0, 1.0, 154.0, 18.0, 16.0, 3.0, 4.0, 5.0, 64.0, 200.0, 5.0, 10.0, 36.0, 13.0, 6.0, 79.0, 3.0, 228.0, 216.0, 13.0, 12.0, 34.0, 6.0, 50.0, 37.0, 32.0, 6.0, 4.0, 11.0, 140.0, 3.0, 151.0, 10.0, 32.0, 52.0, 51.0, 106.0, 12.0, 1.0, 13.0, 142.0, 53.0, 68.0, 43.0, 13.0, 139.0, 156.0, 9.0, 10.0, 100.0, 61.0, 11.0, 9.0, 7.0, 12.0, 116.0, 192.0, 122.0, 138.0, 2.0, 12.0, 134.0, 163.0, 141.0, 3.0, 6.0, 7.0, 0.0, 17.0, 27.0, 103.0, 10.0, 10.0, 8.0, 157.0, 166.0, 95.0, 2.0, 45.0, 7.0, 9.0, 85.0, 73.0, 81.0, 0.0, 12.0, 485.0, 4.0, 8.0, 23.0, 4.0, 2.0, 16.0, 44.0, 3.0, 131.0, 47.0, 144.0, 143.0, 34.0, 6.0, 42.0, 55.0, 57.0, 48.0, 9.0, 3.0, 2.0, 1.0, 14.0, 1.0, 17.0, 13.0, 56.0, 0.0, 148.0, 0.0, 45.0, 41.0, 3.0, 94.0, 448.0, 5.0, 25.0, 25.0, 1.0, 5.0, 4.0, 8.0, 98.0, 61.0, 31.0, 106.0, 2.0, 0.0, 107.0, 200.0, 46.0, 68.0, 36.0, 2.0, 4.0, 0.0, 2.0, 2.0, 55.0, 6.0, 71.0, 24.0, 41.0, 6.0, 15.0, 1.0, 332.0, 226.0, 0.0, 7.0, 1.0, 104.0, 7.0, 0.0, 6.0, 76.0, 11.0, 10.0, 118.0, 0.0, 10.0, 18.0, 20.0, 5.0, 0.0, 87.0, 0.0, 8.0, 3.0, 14.0, 41.0, 356.0, 97.0, 63.0, 173.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5569877325135069, "mean_inference_ms": 1.770400057371936, "mean_action_processing_ms": 0.23381178347316772, "mean_env_wait_ms": 0.1876269798643127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005480289459228516, "StateBufferConnector_ms": 0.003169536590576172, "ViewRequirementAgentConnector_ms": 0.09424102306365967}, "num_episodes": 18, "episode_return_max": 111.29999999999923, "episode_return_min": -382.19999999999976, "episode_return_mean": -37.15900000000008, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 385.5119236932895, "num_env_steps_trained_throughput_per_sec": 385.5119236932895, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 9741.821, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9741.785, "sample_time_ms": 1284.54, "learn_time_ms": 8443.197, "learn_throughput": 473.754, "synch_weights_time_ms": 13.146}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-05-44", "timestamp": 1723644344, "time_this_iter_s": 10.391554117202759, "time_total_s": 210.52248334884644, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187f3700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 210.52248334884644, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 34.96428571428571, "ram_util_percent": 83.07142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.996338642463482, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.805242984383194, "policy_loss": 0.0027170001371472916, "vf_loss": 4.761959655196579, "vf_explained_var": 0.04973667658195294, "kl": 0.011871262722225915, "entropy": 0.9594982684604705, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8320382256671865, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.655381968160155, "policy_loss": 0.003184279846273875, "vf_loss": 4.6158821224535584, "vf_explained_var": -0.0014469920642792232, "kl": 0.010627329243260134, "entropy": 0.9451943695860565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 91.69999999999848, "episode_reward_min": -382.19999999999976, "episode_reward_mean": -38.29600000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -615.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 57.20000000000021, "predator_policy": 485.0}, "policy_reward_mean": {"prey_policy": -75.72300000000007, "predator_policy": 56.575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.40000000000045, -3.99999999999971, 23.800000000000068, 7.200000000000074, 62.50000000000048, -229.50000000000097, -166.20000000000064, 28.00000000000031, -149.5000000000004, 27.800000000000107, -123.30000000000095, -21.699999999999584, 6.300000000000077, -102.70000000000104, 31.700000000000184, -198.0000000000012, 53.40000000000048, 27.200000000000102, -93.50000000000092, -69.60000000000119, 16.499999999999996, -155.60000000000076, -89.40000000000026, 55.400000000000496, 72.59999999999975, -145.00000000000142, 39.000000000000284, -108.20000000000023, -314.2999999999976, -53.700000000001005, 50.600000000000485, 18.299999999999997, -49.09999999999976, -382.19999999999976, 61.300000000000466, 40.000000000000334, 4.600000000000172, -11.699999999999605, -256.60000000000093, 47.10000000000027, -3.99999999999971, 19.399999999999995, 60.40000000000042, 41.200000000000315, 71.19999999999996, 62.80000000000039, 21.40000000000008, -21.59999999999966, 2.300000000000066, -48.30000000000066, -37.89999999999995, -133.30000000000052, 38.70000000000027, 35.500000000000234, 39.40000000000028, -50.89999999999981, -98.10000000000127, 55.80000000000051, 5.100000000000046, -68.60000000000167, 5.999999999999956, 72.49999999999986, 76.99999999999953, -27.099999999999525, -72.60000000000156, -8.999999999999678, 24.50000000000005, -353.69999999999993, 91.69999999999848, -73.39999999999995, 35.90000000000024, -92.50000000000131, 20.499999999999996, -75.10000000000085, 38.00000000000029, 12.499999999999995, -55.69999999999966, 45.6000000000004, 18.899999999999988, -86.30000000000024, -22.59999999999986, -174.3000000000009, -91.20000000000002, -342.5, 35.10000000000023, -132.00000000000068, -139.60000000000042, -263.1999999999989, 25.30000000000006, -154.10000000000136, 45.20000000000038, -206.00000000000088, -125.20000000000053, 41.00000000000031, -70.30000000000084, 28.900000000000134, 39.60000000000029, 48.00000000000043, 2.600000000000194, 29.60000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [38.60000000000022, -5.1999999999999265, -51.400000000000006, 7.399999999999965, -85.00000000000085, 21.80000000000004, -47.199999999999775, 16.399999999999967, 17.599999999999984, 29.90000000000018, -190.90000000000038, -181.6000000000006, -182.20000000000013, -145.00000000000048, 47.90000000000024, -103.90000000000052, -57.69999999999998, -248.8000000000004, -5.1999999999999265, 20.000000000000014, -0.10000000000001347, -278.1999999999988, 5.299999999999965, -148.00000000000065, 18.800000000000008, -68.50000000000087, -106.0000000000008, -291.699999999999, -0.9999999999999846, 13.69999999999997, -190.00000000000057, -169.00000000000063, 12.499999999999972, 20.900000000000027, 26.00000000000011, -17.79999999999975, -40.89999999999981, -360.5999999999992, -278.2, -51.40000000000002, -7.299999999999891, 9.799999999999967, -296.1999999999998, -156.40000000000066, -71.60000000000011, -161.80000000000035, 20.000000000000014, 22.400000000000052, 22.700000000000053, 32.90000000000018, -78.70000000000087, -196.30000000000055, 20.000000000000014, -0.9999999999999846, -249.10000000000002, -24.099999999999746, -248.8000000000004, -326.4999999999992, -72.40000000000086, -28.299999999999777, 20.000000000000014, 14.599999999999966, -160.60000000000053, 20.90000000000003, -3.099999999999958, -127.00000000000037, -379.1999999999998, -499.9999999999991, 20.000000000000014, 29.30000000000018, 21.200000000000045, -8.199999999999912, -11.799999999999818, -1.5999999999999996, -72.40000000000087, 13.699999999999964, -213.1, -221.50000000000048, 16.09999999999996, -256.0, 7.399999999999965, -51.40000000000005, -97.6000000000008, 20.000000000000014, 49.70000000000024, -94.3000000000007, 1.0999999999999794, 28.100000000000147, 48.20000000000023, 20.000000000000014, 26.60000000000013, 21.20000000000004, 7.1000000000000085, -15.699999999999754, -97.60000000000062, 20.000000000000014, 47.00000000000021, -192.70000000000073, -64.00000000000088, -70.30000000000089, -68.79999999999987, -66.10000000000075, -615.6, 29.300000000000175, 25.400000000000098, -36.699999999999754, 20.000000000000014, 9.499999999999964, 15.799999999999962, 11.599999999999964, -78.70000000000084, -131.2, -217.3000000000005, -17.799999999999798, 22.700000000000053, 31.100000000000204, -310.7999999999984, 8.899999999999977, -122.80000000000075, -59.80000000000062, -26.799999999999855, -5.199999999999969, 20.000000000000014, 48.50000000000022, 15.799999999999963, 57.20000000000021, 7.399999999999965, -95.50000000000081, -114.40000000000077, -53.20000000000002, -63.400000000000716, 7.399999999999965, -11.499999999999819, 20.000000000000014, -513.8, -397.9, 42.20000000000021, 42.50000000000025, -32.49999999999975, -145.90000000000003, 20.000000000000014, 8.899999999999967, -120.70000000000056, -53.8, -0.9999999999999846, 0.49999999999998657, -196.30000000000055, 3.2000000000001654, -0.9999999999999846, 10.999999999999982, 5.299999999999965, -17.79999999999977, 20.000000000000014, -162.70000000000053, 17.59999999999998, 20.000000000000014, -7.299999999999901, 9.199999999999969, 26.300000000000114, -509.6, -202.60000000000028, 20.000000000000014, -293.49999999999955, -59.80000000000034, -67.89999999999998, -343.2999999999994, -338.2, -367.30000000000007, 6.199999999999973, 8.899999999999974, -148.00000000000068, -440.0, 38.900000000000254, -365.5, -303.0999999999994, -129.10000000000068, 4.999999999999966, 5.299999999999965, -154.30000000000067, -143.8000000000007, 30.800000000000196, 7.399999999999965, -271.899999999999, -75.10000000000055, -400.0, -125.20000000000053, 20.000000000000014, 10.99999999999997, -400.0, -70.30000000000084, -15.699999999999747, 23.600000000000065, 20.000000000000014, 11.599999999999968, 33.50000000000024, 9.499999999999964, 15.799999999999963, -47.19999999999976, 14.599999999999964, -0.9999999999999917], "policy_predator_policy_reward": [13.0, 12.0, 34.0, 6.0, 50.0, 37.0, 32.0, 6.0, 4.0, 11.0, 140.0, 3.0, 151.0, 10.0, 32.0, 52.0, 51.0, 106.0, 12.0, 1.0, 13.0, 142.0, 53.0, 68.0, 43.0, 13.0, 139.0, 156.0, 9.0, 10.0, 100.0, 61.0, 11.0, 9.0, 7.0, 12.0, 116.0, 192.0, 122.0, 138.0, 2.0, 12.0, 134.0, 163.0, 141.0, 3.0, 6.0, 7.0, 0.0, 17.0, 27.0, 103.0, 10.0, 10.0, 8.0, 157.0, 166.0, 95.0, 2.0, 45.0, 7.0, 9.0, 85.0, 73.0, 81.0, 0.0, 12.0, 485.0, 4.0, 8.0, 23.0, 4.0, 2.0, 16.0, 44.0, 3.0, 131.0, 47.0, 144.0, 143.0, 34.0, 6.0, 42.0, 55.0, 57.0, 48.0, 9.0, 3.0, 2.0, 1.0, 14.0, 1.0, 17.0, 13.0, 56.0, 0.0, 148.0, 0.0, 45.0, 41.0, 3.0, 94.0, 448.0, 5.0, 25.0, 25.0, 1.0, 5.0, 4.0, 8.0, 98.0, 61.0, 31.0, 106.0, 2.0, 0.0, 107.0, 200.0, 46.0, 68.0, 36.0, 2.0, 4.0, 0.0, 2.0, 2.0, 55.0, 6.0, 71.0, 24.0, 41.0, 6.0, 15.0, 1.0, 332.0, 226.0, 0.0, 7.0, 1.0, 104.0, 7.0, 0.0, 6.0, 76.0, 11.0, 10.0, 118.0, 0.0, 10.0, 18.0, 20.0, 5.0, 0.0, 87.0, 0.0, 8.0, 3.0, 14.0, 41.0, 356.0, 97.0, 63.0, 173.0, 6.0, 137.0, 183.0, 171.0, 192.0, 13.0, 7.0, 245.0, 211.0, 171.0, 16.0, 4.0, 165.0, 7.0, 8.0, 109.0, 35.0, 3.0, 4.0, 141.0, 0.0, 200.0, 200.0, 1.0, 9.0, 200.0, 200.0, 17.0, 4.0, 1.0, 7.0, 0.0, 5.0, 32.0, 2.0, 6.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5573997618954447, "mean_inference_ms": 1.771141569761447, "mean_action_processing_ms": 0.23397361495068902, "mean_env_wait_ms": 0.18778236822178115, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005548000335693359, "StateBufferConnector_ms": 0.00322568416595459, "ViewRequirementAgentConnector_ms": 0.09854066371917725}, "num_episodes": 18, "episode_return_max": 91.69999999999848, "episode_return_min": -382.19999999999976, "episode_return_mean": -38.29600000000009, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 337.2926765890996, "num_env_steps_trained_throughput_per_sec": 337.2926765890996, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 9972.241, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9972.203, "sample_time_ms": 1299.506, "learn_time_ms": 8655.754, "learn_throughput": 462.12, "synch_weights_time_ms": 15.94}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-05-56", "timestamp": 1723644356, "time_this_iter_s": 11.930870056152344, "time_total_s": 222.45335340499878, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31876c5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 222.45335340499878, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 43.22941176470588, "ram_util_percent": 83.65882352941176}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9043035574691007, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.543414736298657, "policy_loss": 0.00243068492537729, "vf_loss": 5.499694278505113, "vf_explained_var": 0.06003368055378949, "kl": 0.012082970812162908, "entropy": 0.8944919756795994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.048417412667048, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.761236465166485, "policy_loss": 0.0026938581686447222, "vf_loss": 4.724855560726589, "vf_explained_var": 0.00017775987821912008, "kl": 0.009858121729654017, "entropy": 0.8575089925180668, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 91.69999999999848, "episode_reward_min": -416.8999999999998, "episode_reward_mean": -50.8410000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -615.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 57.20000000000021, "predator_policy": 485.0}, "policy_reward_mean": {"prey_policy": -94.10550000000006, "predator_policy": 68.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-108.20000000000023, -314.2999999999976, -53.700000000001005, 50.600000000000485, 18.299999999999997, -49.09999999999976, -382.19999999999976, 61.300000000000466, 40.000000000000334, 4.600000000000172, -11.699999999999605, -256.60000000000093, 47.10000000000027, -3.99999999999971, 19.399999999999995, 60.40000000000042, 41.200000000000315, 71.19999999999996, 62.80000000000039, 21.40000000000008, -21.59999999999966, 2.300000000000066, -48.30000000000066, -37.89999999999995, -133.30000000000052, 38.70000000000027, 35.500000000000234, 39.40000000000028, -50.89999999999981, -98.10000000000127, 55.80000000000051, 5.100000000000046, -68.60000000000167, 5.999999999999956, 72.49999999999986, 76.99999999999953, -27.099999999999525, -72.60000000000156, -8.999999999999678, 24.50000000000005, -353.69999999999993, 91.69999999999848, -73.39999999999995, 35.90000000000024, -92.50000000000131, 20.499999999999996, -75.10000000000085, 38.00000000000029, 12.499999999999995, -55.69999999999966, 45.6000000000004, 18.899999999999988, -86.30000000000024, -22.59999999999986, -174.3000000000009, -91.20000000000002, -342.5, 35.10000000000023, -132.00000000000068, -139.60000000000042, -263.1999999999989, 25.30000000000006, -154.10000000000136, 45.20000000000038, -206.00000000000088, -125.20000000000053, 41.00000000000031, -70.30000000000084, 28.900000000000134, 39.60000000000029, 48.00000000000043, 2.600000000000194, 29.60000000000014, -263.1000000000006, -105.20000000000093, 14.59999999999996, -110.00000000000092, 12.999999999999957, -8.499999999999986, -118.50000000000125, -154.10000000000045, -174.90000000000106, -240.40000000000006, -175.3000000000006, -273.3000000000003, -19.299999999999848, -33.79999999999967, 24.40000000000019, 45.700000000000394, 8.999999999999948, 35.20000000000023, -46.99999999999983, 26.400000000000105, -103.90000000000157, -60.69999999999988, -416.8999999999998, 45.20000000000039, -143.10000000000045, -112.00000000000122, 53.80000000000052], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-249.10000000000002, -24.099999999999746, -248.8000000000004, -326.4999999999992, -72.40000000000086, -28.299999999999777, 20.000000000000014, 14.599999999999966, -160.60000000000053, 20.90000000000003, -3.099999999999958, -127.00000000000037, -379.1999999999998, -499.9999999999991, 20.000000000000014, 29.30000000000018, 21.200000000000045, -8.199999999999912, -11.799999999999818, -1.5999999999999996, -72.40000000000087, 13.699999999999964, -213.1, -221.50000000000048, 16.09999999999996, -256.0, 7.399999999999965, -51.40000000000005, -97.6000000000008, 20.000000000000014, 49.70000000000024, -94.3000000000007, 1.0999999999999794, 28.100000000000147, 48.20000000000023, 20.000000000000014, 26.60000000000013, 21.20000000000004, 7.1000000000000085, -15.699999999999754, -97.60000000000062, 20.000000000000014, 47.00000000000021, -192.70000000000073, -64.00000000000088, -70.30000000000089, -68.79999999999987, -66.10000000000075, -615.6, 29.300000000000175, 25.400000000000098, -36.699999999999754, 20.000000000000014, 9.499999999999964, 15.799999999999962, 11.599999999999964, -78.70000000000084, -131.2, -217.3000000000005, -17.799999999999798, 22.700000000000053, 31.100000000000204, -310.7999999999984, 8.899999999999977, -122.80000000000075, -59.80000000000062, -26.799999999999855, -5.199999999999969, 20.000000000000014, 48.50000000000022, 15.799999999999963, 57.20000000000021, 7.399999999999965, -95.50000000000081, -114.40000000000077, -53.20000000000002, -63.400000000000716, 7.399999999999965, -11.499999999999819, 20.000000000000014, -513.8, -397.9, 42.20000000000021, 42.50000000000025, -32.49999999999975, -145.90000000000003, 20.000000000000014, 8.899999999999967, -120.70000000000056, -53.8, -0.9999999999999846, 0.49999999999998657, -196.30000000000055, 3.2000000000001654, -0.9999999999999846, 10.999999999999982, 5.299999999999965, -17.79999999999977, 20.000000000000014, -162.70000000000053, 17.59999999999998, 20.000000000000014, -7.299999999999901, 9.199999999999969, 26.300000000000114, -509.6, -202.60000000000028, 20.000000000000014, -293.49999999999955, -59.80000000000034, -67.89999999999998, -343.2999999999994, -338.2, -367.30000000000007, 6.199999999999973, 8.899999999999974, -148.00000000000068, -440.0, 38.900000000000254, -365.5, -303.0999999999994, -129.10000000000068, 4.999999999999966, 5.299999999999965, -154.30000000000067, -143.8000000000007, 30.800000000000196, 7.399999999999965, -271.899999999999, -75.10000000000055, -400.0, -125.20000000000053, 20.000000000000014, 10.99999999999997, -400.0, -70.30000000000084, -15.699999999999747, 23.600000000000065, 20.000000000000014, 11.599999999999968, 33.50000000000024, 9.499999999999964, 15.799999999999963, -47.19999999999976, 14.599999999999964, -0.9999999999999917, -72.70000000000046, -387.39999999999986, 17.899999999999988, -255.0999999999999, -387.4, 20.000000000000014, -313.8999999999997, -51.099999999999824, -400.0, 20.000000000000014, -211.60000000000002, -19.899999999999743, -112.60000000000068, -187.90000000000057, 9.799999999999976, -355.9000000000001, -185.80000000000058, -192.10000000000048, -259.3, -381.0999999999998, -400.0, -172.3000000000006, -276.1, -194.20000000000056, -85.00000000000081, -7.300000000000004, -64.00000000000088, -206.7999999999999, 5.299999999999965, -4.900000000000002, 15.79999999999996, 17.899999999999988, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -448.0, -48.999999999999815, 4.399999999999972, -0.9999999999999846, -94.00000000000072, -82.90000000000086, 15.799999999999963, -170.50000000000003, -376.8999999999998, -400.0, 35.30000000000025, -0.09999999999999937, -330.7, 5.5999999999999766, -143.8000000000007, -104.20000000000053, 17.899999999999984, 29.90000000000018], "policy_predator_policy_reward": [8.0, 157.0, 166.0, 95.0, 2.0, 45.0, 7.0, 9.0, 85.0, 73.0, 81.0, 0.0, 12.0, 485.0, 4.0, 8.0, 23.0, 4.0, 2.0, 16.0, 44.0, 3.0, 131.0, 47.0, 144.0, 143.0, 34.0, 6.0, 42.0, 55.0, 57.0, 48.0, 9.0, 3.0, 2.0, 1.0, 14.0, 1.0, 17.0, 13.0, 56.0, 0.0, 148.0, 0.0, 45.0, 41.0, 3.0, 94.0, 448.0, 5.0, 25.0, 25.0, 1.0, 5.0, 4.0, 8.0, 98.0, 61.0, 31.0, 106.0, 2.0, 0.0, 107.0, 200.0, 46.0, 68.0, 36.0, 2.0, 4.0, 0.0, 2.0, 2.0, 55.0, 6.0, 71.0, 24.0, 41.0, 6.0, 15.0, 1.0, 332.0, 226.0, 0.0, 7.0, 1.0, 104.0, 7.0, 0.0, 6.0, 76.0, 11.0, 10.0, 118.0, 0.0, 10.0, 18.0, 20.0, 5.0, 0.0, 87.0, 0.0, 8.0, 3.0, 14.0, 41.0, 356.0, 97.0, 63.0, 173.0, 6.0, 137.0, 183.0, 171.0, 192.0, 13.0, 7.0, 245.0, 211.0, 171.0, 16.0, 4.0, 165.0, 7.0, 8.0, 109.0, 35.0, 3.0, 4.0, 141.0, 0.0, 200.0, 200.0, 1.0, 9.0, 200.0, 200.0, 17.0, 4.0, 1.0, 7.0, 0.0, 5.0, 32.0, 2.0, 6.0, 10.0, 194.0, 3.0, 1.0, 131.0, 194.0, 188.0, 125.0, 130.0, 199.0, 194.0, 76.0, 147.0, 91.0, 91.0, 13.0, 179.0, 100.0, 103.0, 200.0, 200.0, 197.0, 200.0, 13.0, 184.0, 10.0, 63.0, 110.0, 127.0, 17.0, 7.0, 11.0, 1.0, 200.0, 189.0, 4.0, 8.0, 238.0, 212.0, 10.0, 13.0, 72.0, 1.0, 92.0, 2.0, 200.0, 160.0, 0.0, 10.0, 15.0, 167.0, 34.0, 102.0, 4.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5603655018252772, "mean_inference_ms": 1.7869985880460597, "mean_action_processing_ms": 0.23532076568669902, "mean_env_wait_ms": 0.18919905838176718, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004747629165649414, "StateBufferConnector_ms": 0.0034879446029663086, "ViewRequirementAgentConnector_ms": 0.12263655662536621}, "num_episodes": 27, "episode_return_max": 91.69999999999848, "episode_return_min": -416.8999999999998, "episode_return_mean": -50.8410000000001, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 11.152893627963183, "num_env_steps_trained_throughput_per_sec": 11.152893627963183, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 44840.382, "restore_workers_time_ms": 0.013, "training_step_time_ms": 44840.343, "sample_time_ms": 1350.115, "learn_time_ms": 43471.926, "learn_throughput": 92.013, "synch_weights_time_ms": 17.093}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-11-55", "timestamp": 1723644715, "time_this_iter_s": 358.7934329509735, "time_total_s": 581.2467863559723, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31877e5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 581.2467863559723, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 69.22380952380954, "ram_util_percent": 82.37142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.863302114211693, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.670645575296311, "policy_loss": 0.0008498447690967214, "vf_loss": 4.633602913977608, "vf_explained_var": 0.041789138537866095, "kl": 0.010591405614373306, "entropy": 0.9658033761397872, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.606042487706457, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.0122459072284595, "policy_loss": 0.0026115959532381525, "vf_loss": 3.985869130381831, "vf_explained_var": -0.0005633626034650853, "kl": 0.006954601538560562, "entropy": 0.6679977414942292, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 91.69999999999848, "episode_reward_min": -416.8999999999998, "episode_reward_mean": -55.512000000000164, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -615.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 57.20000000000021, "predator_policy": 448.0}, "policy_reward_mean": {"prey_policy": -100.42600000000007, "predator_policy": 72.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [62.80000000000039, 21.40000000000008, -21.59999999999966, 2.300000000000066, -48.30000000000066, -37.89999999999995, -133.30000000000052, 38.70000000000027, 35.500000000000234, 39.40000000000028, -50.89999999999981, -98.10000000000127, 55.80000000000051, 5.100000000000046, -68.60000000000167, 5.999999999999956, 72.49999999999986, 76.99999999999953, -27.099999999999525, -72.60000000000156, -8.999999999999678, 24.50000000000005, -353.69999999999993, 91.69999999999848, -73.39999999999995, 35.90000000000024, -92.50000000000131, 20.499999999999996, -75.10000000000085, 38.00000000000029, 12.499999999999995, -55.69999999999966, 45.6000000000004, 18.899999999999988, -86.30000000000024, -22.59999999999986, -174.3000000000009, -91.20000000000002, -342.5, 35.10000000000023, -132.00000000000068, -139.60000000000042, -263.1999999999989, 25.30000000000006, -154.10000000000136, 45.20000000000038, -206.00000000000088, -125.20000000000053, 41.00000000000031, -70.30000000000084, 28.900000000000134, 39.60000000000029, 48.00000000000043, 2.600000000000194, 29.60000000000014, -263.1000000000006, -105.20000000000093, 14.59999999999996, -110.00000000000092, 12.999999999999957, -8.499999999999986, -118.50000000000125, -154.10000000000045, -174.90000000000106, -240.40000000000006, -175.3000000000006, -273.3000000000003, -19.299999999999848, -33.79999999999967, 24.40000000000019, 45.700000000000394, 8.999999999999948, 35.20000000000023, -46.99999999999983, 26.400000000000105, -103.90000000000157, -60.69999999999988, -416.8999999999998, 45.20000000000039, -143.10000000000045, -112.00000000000122, 53.80000000000052, 39.800000000000296, -89.4000000000011, 52.70000000000049, -393.0999999999996, 4.900000000000006, 7.999999999999959, -242.50000000000034, 20.199999999999974, -107.70000000000064, 32.9000000000002, -5.099999999999685, -177.50000000000065, 44.10000000000037, -188.10000000000016, -69.19999999999993, -18.899999999999523, -145.80000000000075, 1.900000000000073], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.60000000000013, 21.20000000000004, 7.1000000000000085, -15.699999999999754, -97.60000000000062, 20.000000000000014, 47.00000000000021, -192.70000000000073, -64.00000000000088, -70.30000000000089, -68.79999999999987, -66.10000000000075, -615.6, 29.300000000000175, 25.400000000000098, -36.699999999999754, 20.000000000000014, 9.499999999999964, 15.799999999999962, 11.599999999999964, -78.70000000000084, -131.2, -217.3000000000005, -17.799999999999798, 22.700000000000053, 31.100000000000204, -310.7999999999984, 8.899999999999977, -122.80000000000075, -59.80000000000062, -26.799999999999855, -5.199999999999969, 20.000000000000014, 48.50000000000022, 15.799999999999963, 57.20000000000021, 7.399999999999965, -95.50000000000081, -114.40000000000077, -53.20000000000002, -63.400000000000716, 7.399999999999965, -11.499999999999819, 20.000000000000014, -513.8, -397.9, 42.20000000000021, 42.50000000000025, -32.49999999999975, -145.90000000000003, 20.000000000000014, 8.899999999999967, -120.70000000000056, -53.8, -0.9999999999999846, 0.49999999999998657, -196.30000000000055, 3.2000000000001654, -0.9999999999999846, 10.999999999999982, 5.299999999999965, -17.79999999999977, 20.000000000000014, -162.70000000000053, 17.59999999999998, 20.000000000000014, -7.299999999999901, 9.199999999999969, 26.300000000000114, -509.6, -202.60000000000028, 20.000000000000014, -293.49999999999955, -59.80000000000034, -67.89999999999998, -343.2999999999994, -338.2, -367.30000000000007, 6.199999999999973, 8.899999999999974, -148.00000000000068, -440.0, 38.900000000000254, -365.5, -303.0999999999994, -129.10000000000068, 4.999999999999966, 5.299999999999965, -154.30000000000067, -143.8000000000007, 30.800000000000196, 7.399999999999965, -271.899999999999, -75.10000000000055, -400.0, -125.20000000000053, 20.000000000000014, 10.99999999999997, -400.0, -70.30000000000084, -15.699999999999747, 23.600000000000065, 20.000000000000014, 11.599999999999968, 33.50000000000024, 9.499999999999964, 15.799999999999963, -47.19999999999976, 14.599999999999964, -0.9999999999999917, -72.70000000000046, -387.39999999999986, 17.899999999999988, -255.0999999999999, -387.4, 20.000000000000014, -313.8999999999997, -51.099999999999824, -400.0, 20.000000000000014, -211.60000000000002, -19.899999999999743, -112.60000000000068, -187.90000000000057, 9.799999999999976, -355.9000000000001, -185.80000000000058, -192.10000000000048, -259.3, -381.0999999999998, -400.0, -172.3000000000006, -276.1, -194.20000000000056, -85.00000000000081, -7.300000000000004, -64.00000000000088, -206.7999999999999, 5.299999999999965, -4.900000000000002, 15.79999999999996, 17.899999999999988, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -448.0, -48.999999999999815, 4.399999999999972, -0.9999999999999846, -94.00000000000072, -82.90000000000086, 15.799999999999963, -170.50000000000003, -376.8999999999998, -400.0, 35.30000000000025, -0.09999999999999937, -330.7, 5.5999999999999766, -143.8000000000007, -104.20000000000053, 17.899999999999984, 29.90000000000018, -0.09999999999999937, 29.90000000000018, -76.60000000000056, -155.80000000000055, 24.20000000000008, 12.499999999999972, -292.9000000000001, -278.1999999999996, -32.49999999999975, -13.600000000000023, -480.0, 20.000000000000014, -207.10000000000034, -387.4, -7.299999999999905, 9.499999999999964, -330.69999999999925, 20.000000000000014, 20.000000000000014, 2.8999999999999613, 3.1999999999999615, -49.299999999999756, -400.0, 12.499999999999973, 17.299999999999976, 15.799999999999963, -232.0, -255.09999999999928, 18.49999999999998, -393.70000000000005, -24.099999999999767, -38.799999999999756, -400.0, -122.80000000000075, 20.000000000000014, -129.10000000000073], "policy_predator_policy_reward": [14.0, 1.0, 17.0, 13.0, 56.0, 0.0, 148.0, 0.0, 45.0, 41.0, 3.0, 94.0, 448.0, 5.0, 25.0, 25.0, 1.0, 5.0, 4.0, 8.0, 98.0, 61.0, 31.0, 106.0, 2.0, 0.0, 107.0, 200.0, 46.0, 68.0, 36.0, 2.0, 4.0, 0.0, 2.0, 2.0, 55.0, 6.0, 71.0, 24.0, 41.0, 6.0, 15.0, 1.0, 332.0, 226.0, 0.0, 7.0, 1.0, 104.0, 7.0, 0.0, 6.0, 76.0, 11.0, 10.0, 118.0, 0.0, 10.0, 18.0, 20.0, 5.0, 0.0, 87.0, 0.0, 8.0, 3.0, 14.0, 41.0, 356.0, 97.0, 63.0, 173.0, 6.0, 137.0, 183.0, 171.0, 192.0, 13.0, 7.0, 245.0, 211.0, 171.0, 16.0, 4.0, 165.0, 7.0, 8.0, 109.0, 35.0, 3.0, 4.0, 141.0, 0.0, 200.0, 200.0, 1.0, 9.0, 200.0, 200.0, 17.0, 4.0, 1.0, 7.0, 0.0, 5.0, 32.0, 2.0, 6.0, 10.0, 194.0, 3.0, 1.0, 131.0, 194.0, 188.0, 125.0, 130.0, 199.0, 194.0, 76.0, 147.0, 91.0, 91.0, 13.0, 179.0, 100.0, 103.0, 200.0, 200.0, 197.0, 200.0, 13.0, 184.0, 10.0, 63.0, 110.0, 127.0, 17.0, 7.0, 11.0, 1.0, 200.0, 189.0, 4.0, 8.0, 238.0, 212.0, 10.0, 13.0, 72.0, 1.0, 92.0, 2.0, 200.0, 160.0, 0.0, 10.0, 15.0, 167.0, 34.0, 102.0, 4.0, 2.0, 0.0, 10.0, 84.0, 59.0, 6.0, 10.0, 6.0, 172.0, 19.0, 32.0, 186.0, 282.0, 159.0, 193.0, 2.0, 16.0, 167.0, 36.0, 9.0, 1.0, 33.0, 8.0, 200.0, 10.0, 9.0, 2.0, 117.0, 182.0, 114.0, 192.0, 25.0, 19.0, 200.0, 177.0, 67.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5690139116738628, "mean_inference_ms": 1.8067846219530603, "mean_action_processing_ms": 0.23809965552440981, "mean_env_wait_ms": 0.192416983508795, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005457758903503418, "StateBufferConnector_ms": 0.01182711124420166, "ViewRequirementAgentConnector_ms": 0.12891030311584473}, "num_episodes": 18, "episode_return_max": 91.69999999999848, "episode_return_min": -416.8999999999998, "episode_return_mean": -55.512000000000164, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.2955233363215, "num_env_steps_trained_throughput_per_sec": 316.2955233363215, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 45166.479, "restore_workers_time_ms": 0.013, "training_step_time_ms": 45166.439, "sample_time_ms": 1525.498, "learn_time_ms": 43621.497, "learn_throughput": 91.698, "synch_weights_time_ms": 17.655}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-12-08", "timestamp": 1723644728, "time_this_iter_s": 12.69823932647705, "time_total_s": 593.9450256824493, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187f3700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 593.9450256824493, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 66.52777777777777, "ram_util_percent": 82.2611111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7449716172521077, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.2808090232036733, "policy_loss": -2.6696053624310824e-07, "vf_loss": 3.247100128320159, "vf_explained_var": 0.04145635555660914, "kl": 0.00986459271332806, "entropy": 1.0493180284424433, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9326061023606194, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 2.9380979857747516, "policy_loss": 0.0029616202203133117, "vf_loss": 2.9010694229413594, "vf_explained_var": 0.0007858115844625645, "kl": 0.009969291796968944, "entropy": 0.7060286573947422, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 91.69999999999848, "episode_reward_min": -456.0999999999989, "episode_reward_mean": -60.01600000000013, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -513.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 42.50000000000025, "predator_policy": 356.0}, "policy_reward_mean": {"prey_policy": -104.91800000000006, "predator_policy": 74.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.099999999999525, -72.60000000000156, -8.999999999999678, 24.50000000000005, -353.69999999999993, 91.69999999999848, -73.39999999999995, 35.90000000000024, -92.50000000000131, 20.499999999999996, -75.10000000000085, 38.00000000000029, 12.499999999999995, -55.69999999999966, 45.6000000000004, 18.899999999999988, -86.30000000000024, -22.59999999999986, -174.3000000000009, -91.20000000000002, -342.5, 35.10000000000023, -132.00000000000068, -139.60000000000042, -263.1999999999989, 25.30000000000006, -154.10000000000136, 45.20000000000038, -206.00000000000088, -125.20000000000053, 41.00000000000031, -70.30000000000084, 28.900000000000134, 39.60000000000029, 48.00000000000043, 2.600000000000194, 29.60000000000014, -263.1000000000006, -105.20000000000093, 14.59999999999996, -110.00000000000092, 12.999999999999957, -8.499999999999986, -118.50000000000125, -154.10000000000045, -174.90000000000106, -240.40000000000006, -175.3000000000006, -273.3000000000003, -19.299999999999848, -33.79999999999967, 24.40000000000019, 45.700000000000394, 8.999999999999948, 35.20000000000023, -46.99999999999983, 26.400000000000105, -103.90000000000157, -60.69999999999988, -416.8999999999998, 45.20000000000039, -143.10000000000045, -112.00000000000122, 53.80000000000052, 39.800000000000296, -89.4000000000011, 52.70000000000049, -393.0999999999996, 4.900000000000006, 7.999999999999959, -242.50000000000034, 20.199999999999974, -107.70000000000064, 32.9000000000002, -5.099999999999685, -177.50000000000065, 44.10000000000037, -188.10000000000016, -69.19999999999993, -18.899999999999523, -145.80000000000075, 1.900000000000073, 38.70000000000028, -456.0999999999989, 28.900000000000187, -79.60000000000117, 34.900000000000226, 40.90000000000031, -94.4000000000015, 58.20000000000049, 28.80000000000012, -87.60000000000113, 0.3999999999999826, -152.0000000000005, 50.500000000000476, 61.00000000000049, -16.999999999999744, 35.90000000000024, -28.099999999999845, 44.00000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, -95.50000000000081, -114.40000000000077, -53.20000000000002, -63.400000000000716, 7.399999999999965, -11.499999999999819, 20.000000000000014, -513.8, -397.9, 42.20000000000021, 42.50000000000025, -32.49999999999975, -145.90000000000003, 20.000000000000014, 8.899999999999967, -120.70000000000056, -53.8, -0.9999999999999846, 0.49999999999998657, -196.30000000000055, 3.2000000000001654, -0.9999999999999846, 10.999999999999982, 5.299999999999965, -17.79999999999977, 20.000000000000014, -162.70000000000053, 17.59999999999998, 20.000000000000014, -7.299999999999901, 9.199999999999969, 26.300000000000114, -509.6, -202.60000000000028, 20.000000000000014, -293.49999999999955, -59.80000000000034, -67.89999999999998, -343.2999999999994, -338.2, -367.30000000000007, 6.199999999999973, 8.899999999999974, -148.00000000000068, -440.0, 38.900000000000254, -365.5, -303.0999999999994, -129.10000000000068, 4.999999999999966, 5.299999999999965, -154.30000000000067, -143.8000000000007, 30.800000000000196, 7.399999999999965, -271.899999999999, -75.10000000000055, -400.0, -125.20000000000053, 20.000000000000014, 10.99999999999997, -400.0, -70.30000000000084, -15.699999999999747, 23.600000000000065, 20.000000000000014, 11.599999999999968, 33.50000000000024, 9.499999999999964, 15.799999999999963, -47.19999999999976, 14.599999999999964, -0.9999999999999917, -72.70000000000046, -387.39999999999986, 17.899999999999988, -255.0999999999999, -387.4, 20.000000000000014, -313.8999999999997, -51.099999999999824, -400.0, 20.000000000000014, -211.60000000000002, -19.899999999999743, -112.60000000000068, -187.90000000000057, 9.799999999999976, -355.9000000000001, -185.80000000000058, -192.10000000000048, -259.3, -381.0999999999998, -400.0, -172.3000000000006, -276.1, -194.20000000000056, -85.00000000000081, -7.300000000000004, -64.00000000000088, -206.7999999999999, 5.299999999999965, -4.900000000000002, 15.79999999999996, 17.899999999999988, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -448.0, -48.999999999999815, 4.399999999999972, -0.9999999999999846, -94.00000000000072, -82.90000000000086, 15.799999999999963, -170.50000000000003, -376.8999999999998, -400.0, 35.30000000000025, -0.09999999999999937, -330.7, 5.5999999999999766, -143.8000000000007, -104.20000000000053, 17.899999999999984, 29.90000000000018, -0.09999999999999937, 29.90000000000018, -76.60000000000056, -155.80000000000055, 24.20000000000008, 12.499999999999972, -292.9000000000001, -278.1999999999996, -32.49999999999975, -13.600000000000023, -480.0, 20.000000000000014, -207.10000000000034, -387.4, -7.299999999999905, 9.499999999999964, -330.69999999999925, 20.000000000000014, 20.000000000000014, 2.8999999999999613, 3.1999999999999615, -49.299999999999756, -400.0, 12.499999999999973, 17.299999999999976, 15.799999999999963, -232.0, -255.09999999999928, 18.49999999999998, -393.70000000000005, -24.099999999999767, -38.799999999999756, -400.0, -122.80000000000075, 20.000000000000014, -129.10000000000073, 20.000000000000014, 13.699999999999964, -283.5999999999999, -368.5, -318.10000000000025, 29.000000000000163, -59.80000000000035, -206.80000000000052, 20.000000000000014, -3.099999999999958, 24.50000000000008, 7.399999999999965, -137.5000000000007, -61.900000000000595, 20.000000000000014, 27.200000000000138, 12.499999999999964, 5.299999999999965, -215.20000000000047, 11.599999999999964, 20.000000000000014, -391.6, -351.7, 22.700000000000053, 7.399999999999965, 37.10000000000026, 32.00000000000022, 20.000000000000014, 20.000000000000014, -400.0, 9.499999999999964, 16.399999999999967, 23.000000000000064, -297.0999999999989, 16.09999999999996, 20.900000000000027], "policy_predator_policy_reward": [55.0, 6.0, 71.0, 24.0, 41.0, 6.0, 15.0, 1.0, 332.0, 226.0, 0.0, 7.0, 1.0, 104.0, 7.0, 0.0, 6.0, 76.0, 11.0, 10.0, 118.0, 0.0, 10.0, 18.0, 20.0, 5.0, 0.0, 87.0, 0.0, 8.0, 3.0, 14.0, 41.0, 356.0, 97.0, 63.0, 173.0, 6.0, 137.0, 183.0, 171.0, 192.0, 13.0, 7.0, 245.0, 211.0, 171.0, 16.0, 4.0, 165.0, 7.0, 8.0, 109.0, 35.0, 3.0, 4.0, 141.0, 0.0, 200.0, 200.0, 1.0, 9.0, 200.0, 200.0, 17.0, 4.0, 1.0, 7.0, 0.0, 5.0, 32.0, 2.0, 6.0, 10.0, 194.0, 3.0, 1.0, 131.0, 194.0, 188.0, 125.0, 130.0, 199.0, 194.0, 76.0, 147.0, 91.0, 91.0, 13.0, 179.0, 100.0, 103.0, 200.0, 200.0, 197.0, 200.0, 13.0, 184.0, 10.0, 63.0, 110.0, 127.0, 17.0, 7.0, 11.0, 1.0, 200.0, 189.0, 4.0, 8.0, 238.0, 212.0, 10.0, 13.0, 72.0, 1.0, 92.0, 2.0, 200.0, 160.0, 0.0, 10.0, 15.0, 167.0, 34.0, 102.0, 4.0, 2.0, 0.0, 10.0, 84.0, 59.0, 6.0, 10.0, 6.0, 172.0, 19.0, 32.0, 186.0, 282.0, 159.0, 193.0, 2.0, 16.0, 167.0, 36.0, 9.0, 1.0, 33.0, 8.0, 200.0, 10.0, 9.0, 2.0, 117.0, 182.0, 114.0, 192.0, 25.0, 19.0, 200.0, 177.0, 67.0, 44.0, 3.0, 2.0, 2.0, 194.0, 157.0, 161.0, 91.0, 96.0, 11.0, 7.0, 3.0, 6.0, 30.0, 75.0, 6.0, 5.0, 7.0, 4.0, 112.0, 4.0, 176.0, 196.0, 177.0, 0.0, 0.0, 6.0, 5.0, 4.0, 200.0, 163.0, 1.0, 9.0, 95.0, 151.0, 3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5807213421181489, "mean_inference_ms": 1.8388044829304937, "mean_action_processing_ms": 0.24210529031563763, "mean_env_wait_ms": 0.1967425722402043, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008688807487487793, "StateBufferConnector_ms": 0.01221919059753418, "ViewRequirementAgentConnector_ms": 0.14393818378448486}, "num_episodes": 18, "episode_return_max": 91.69999999999848, "episode_return_min": -456.0999999999989, "episode_return_mean": -60.01600000000013, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.3214838049492, "num_env_steps_trained_throughput_per_sec": 364.3214838049492, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 45291.791, "restore_workers_time_ms": 0.014, "training_step_time_ms": 45291.75, "sample_time_ms": 1602.317, "learn_time_ms": 43669.653, "learn_throughput": 91.597, "synch_weights_time_ms": 17.899}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-12-19", "timestamp": 1723644739, "time_this_iter_s": 11.011380910873413, "time_total_s": 604.9564065933228, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 604.9564065933228, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 40.075, "ram_util_percent": 83.83125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.749103273065002, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.2453202340968703, "policy_loss": 6.195852587186785e-05, "vf_loss": 3.2176812443152936, "vf_explained_var": 0.043985359914719115, "kl": 0.008070096649898847, "entropy": 0.9420912215003261, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.996522288647278, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.3188795232898975, "policy_loss": 0.00412762718763025, "vf_loss": 3.269925756429238, "vf_explained_var": 0.0009762867417915788, "kl": 0.013117847035105889, "entropy": 0.9078855398155394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 61.00000000000049, "episode_reward_min": -456.0999999999989, "episode_reward_mean": -57.80700000000011, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -480.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.500000000000234, "predator_policy": 282.0}, "policy_reward_mean": {"prey_policy": -102.26350000000006, "predator_policy": 73.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-174.3000000000009, -91.20000000000002, -342.5, 35.10000000000023, -132.00000000000068, -139.60000000000042, -263.1999999999989, 25.30000000000006, -154.10000000000136, 45.20000000000038, -206.00000000000088, -125.20000000000053, 41.00000000000031, -70.30000000000084, 28.900000000000134, 39.60000000000029, 48.00000000000043, 2.600000000000194, 29.60000000000014, -263.1000000000006, -105.20000000000093, 14.59999999999996, -110.00000000000092, 12.999999999999957, -8.499999999999986, -118.50000000000125, -154.10000000000045, -174.90000000000106, -240.40000000000006, -175.3000000000006, -273.3000000000003, -19.299999999999848, -33.79999999999967, 24.40000000000019, 45.700000000000394, 8.999999999999948, 35.20000000000023, -46.99999999999983, 26.400000000000105, -103.90000000000157, -60.69999999999988, -416.8999999999998, 45.20000000000039, -143.10000000000045, -112.00000000000122, 53.80000000000052, 39.800000000000296, -89.4000000000011, 52.70000000000049, -393.0999999999996, 4.900000000000006, 7.999999999999959, -242.50000000000034, 20.199999999999974, -107.70000000000064, 32.9000000000002, -5.099999999999685, -177.50000000000065, 44.10000000000037, -188.10000000000016, -69.19999999999993, -18.899999999999523, -145.80000000000075, 1.900000000000073, 38.70000000000028, -456.0999999999989, 28.900000000000187, -79.60000000000117, 34.900000000000226, 40.90000000000031, -94.4000000000015, 58.20000000000049, 28.80000000000012, -87.60000000000113, 0.3999999999999826, -152.0000000000005, 50.500000000000476, 61.00000000000049, -16.999999999999744, 35.90000000000024, -28.099999999999845, 44.00000000000036, -165.20000000000127, 52.400000000000496, -83.90000000000055, -132.2000000000012, 5.100000000000184, -0.499999999999871, 13.199999999999944, 41.20000000000032, -147.00000000000037, -164.80000000000075, 60.4000000000005, 55.80000000000047, 43.80000000000037, 36.10000000000024, -72.20000000000162, 19.09999999999996, 47.30000000000042, 31.900000000000176], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-293.49999999999955, -59.80000000000034, -67.89999999999998, -343.2999999999994, -338.2, -367.30000000000007, 6.199999999999973, 8.899999999999974, -148.00000000000068, -440.0, 38.900000000000254, -365.5, -303.0999999999994, -129.10000000000068, 4.999999999999966, 5.299999999999965, -154.30000000000067, -143.8000000000007, 30.800000000000196, 7.399999999999965, -271.899999999999, -75.10000000000055, -400.0, -125.20000000000053, 20.000000000000014, 10.99999999999997, -400.0, -70.30000000000084, -15.699999999999747, 23.600000000000065, 20.000000000000014, 11.599999999999968, 33.50000000000024, 9.499999999999964, 15.799999999999963, -47.19999999999976, 14.599999999999964, -0.9999999999999917, -72.70000000000046, -387.39999999999986, 17.899999999999988, -255.0999999999999, -387.4, 20.000000000000014, -313.8999999999997, -51.099999999999824, -400.0, 20.000000000000014, -211.60000000000002, -19.899999999999743, -112.60000000000068, -187.90000000000057, 9.799999999999976, -355.9000000000001, -185.80000000000058, -192.10000000000048, -259.3, -381.0999999999998, -400.0, -172.3000000000006, -276.1, -194.20000000000056, -85.00000000000081, -7.300000000000004, -64.00000000000088, -206.7999999999999, 5.299999999999965, -4.900000000000002, 15.79999999999996, 17.899999999999988, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -448.0, -48.999999999999815, 4.399999999999972, -0.9999999999999846, -94.00000000000072, -82.90000000000086, 15.799999999999963, -170.50000000000003, -376.8999999999998, -400.0, 35.30000000000025, -0.09999999999999937, -330.7, 5.5999999999999766, -143.8000000000007, -104.20000000000053, 17.899999999999984, 29.90000000000018, -0.09999999999999937, 29.90000000000018, -76.60000000000056, -155.80000000000055, 24.20000000000008, 12.499999999999972, -292.9000000000001, -278.1999999999996, -32.49999999999975, -13.600000000000023, -480.0, 20.000000000000014, -207.10000000000034, -387.4, -7.299999999999905, 9.499999999999964, -330.69999999999925, 20.000000000000014, 20.000000000000014, 2.8999999999999613, 3.1999999999999615, -49.299999999999756, -400.0, 12.499999999999973, 17.299999999999976, 15.799999999999963, -232.0, -255.09999999999928, 18.49999999999998, -393.70000000000005, -24.099999999999767, -38.799999999999756, -400.0, -122.80000000000075, 20.000000000000014, -129.10000000000073, 20.000000000000014, 13.699999999999964, -283.5999999999999, -368.5, -318.10000000000025, 29.000000000000163, -59.80000000000035, -206.80000000000052, 20.000000000000014, -3.099999999999958, 24.50000000000008, 7.399999999999965, -137.5000000000007, -61.900000000000595, 20.000000000000014, 27.200000000000138, 12.499999999999964, 5.299999999999965, -215.20000000000047, 11.599999999999964, 20.000000000000014, -391.6, -351.7, 22.700000000000053, 7.399999999999965, 37.10000000000026, 32.00000000000022, 20.000000000000014, 20.000000000000014, -400.0, 9.499999999999964, 16.399999999999967, 23.000000000000064, -297.0999999999989, 16.09999999999996, 20.900000000000027, -141.7000000000007, -179.5000000000006, 20.000000000000014, 19.400000000000006, 20.000000000000014, -313.89999999999935, -152.20000000000067, -166.00000000000054, -13.599999999999783, -7.299999999999891, 20.000000000000014, -116.50000000000077, -301.29999999999905, 24.50000000000008, 1.9999999999999625, 27.20000000000013, -326.49999999999994, 9.499999999999964, 12.499999999999964, -364.2999999999996, 20.000000000000014, 37.40000000000025, 5.299999999999965, 39.500000000000234, 20.000000000000014, 6.7999999999999705, 1.0999999999999865, 20.000000000000014, -128.20000000000073, -36.99999999999978, 20.000000000000014, -19.899999999999935, 29.600000000000176, 13.699999999999964, 5.5999999999999925, 5.299999999999965], "policy_predator_policy_reward": [173.0, 6.0, 137.0, 183.0, 171.0, 192.0, 13.0, 7.0, 245.0, 211.0, 171.0, 16.0, 4.0, 165.0, 7.0, 8.0, 109.0, 35.0, 3.0, 4.0, 141.0, 0.0, 200.0, 200.0, 1.0, 9.0, 200.0, 200.0, 17.0, 4.0, 1.0, 7.0, 0.0, 5.0, 32.0, 2.0, 6.0, 10.0, 194.0, 3.0, 1.0, 131.0, 194.0, 188.0, 125.0, 130.0, 199.0, 194.0, 76.0, 147.0, 91.0, 91.0, 13.0, 179.0, 100.0, 103.0, 200.0, 200.0, 197.0, 200.0, 13.0, 184.0, 10.0, 63.0, 110.0, 127.0, 17.0, 7.0, 11.0, 1.0, 200.0, 189.0, 4.0, 8.0, 238.0, 212.0, 10.0, 13.0, 72.0, 1.0, 92.0, 2.0, 200.0, 160.0, 0.0, 10.0, 15.0, 167.0, 34.0, 102.0, 4.0, 2.0, 0.0, 10.0, 84.0, 59.0, 6.0, 10.0, 6.0, 172.0, 19.0, 32.0, 186.0, 282.0, 159.0, 193.0, 2.0, 16.0, 167.0, 36.0, 9.0, 1.0, 33.0, 8.0, 200.0, 10.0, 9.0, 2.0, 117.0, 182.0, 114.0, 192.0, 25.0, 19.0, 200.0, 177.0, 67.0, 44.0, 3.0, 2.0, 2.0, 194.0, 157.0, 161.0, 91.0, 96.0, 11.0, 7.0, 3.0, 6.0, 30.0, 75.0, 6.0, 5.0, 7.0, 4.0, 112.0, 4.0, 176.0, 196.0, 177.0, 0.0, 0.0, 6.0, 5.0, 4.0, 200.0, 163.0, 1.0, 9.0, 95.0, 151.0, 3.0, 4.0, 59.0, 97.0, 6.0, 7.0, 49.0, 161.0, 88.0, 98.0, 10.0, 16.0, 61.0, 35.0, 137.0, 153.0, 4.0, 8.0, 165.0, 5.0, 183.0, 4.0, 1.0, 2.0, 4.0, 7.0, 8.0, 9.0, 9.0, 6.0, 58.0, 35.0, 19.0, 0.0, 1.0, 3.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5911248170682019, "mean_inference_ms": 1.8667771054084787, "mean_action_processing_ms": 0.24564031564745606, "mean_env_wait_ms": 0.20065288863559444, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009127497673034668, "StateBufferConnector_ms": 0.012208819389343262, "ViewRequirementAgentConnector_ms": 0.14201593399047852}, "num_episodes": 18, "episode_return_max": 61.00000000000049, "episode_return_min": -456.0999999999989, "episode_return_mean": -57.80700000000011, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 403.88583387171644, "num_env_steps_trained_throughput_per_sec": 403.88583387171644, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 45297.418, "restore_workers_time_ms": 0.015, "training_step_time_ms": 45297.366, "sample_time_ms": 1606.829, "learn_time_ms": 43670.996, "learn_throughput": 91.594, "synch_weights_time_ms": 17.716}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-12-29", "timestamp": 1723644749, "time_this_iter_s": 9.909703254699707, "time_total_s": 614.8661098480225, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318743940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 614.8661098480225, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 31.05, "ram_util_percent": 83.2}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2187347608583945, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.1880746968839535, "policy_loss": -0.0002367912852032869, "vf_loss": 3.16888021867742, "vf_explained_var": 0.011157187141438641, "kl": 0.005686335194366766, "entropy": 0.9218682124816552, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.171623034515078, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.0735019582289236, "policy_loss": 0.0014846630823162814, "vf_loss": 3.0385735162351497, "vf_explained_var": 0.000500688287946913, "kl": 0.009786931120108526, "entropy": 0.8646550813364604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 61.00000000000049, "episode_reward_min": -456.0999999999989, "episode_reward_mean": -49.843000000000096, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -910.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000024, "predator_policy": 767.0}, "policy_reward_mean": {"prey_policy": -102.48650000000005, "predator_policy": 77.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-110.00000000000092, 12.999999999999957, -8.499999999999986, -118.50000000000125, -154.10000000000045, -174.90000000000106, -240.40000000000006, -175.3000000000006, -273.3000000000003, -19.299999999999848, -33.79999999999967, 24.40000000000019, 45.700000000000394, 8.999999999999948, 35.20000000000023, -46.99999999999983, 26.400000000000105, -103.90000000000157, -60.69999999999988, -416.8999999999998, 45.20000000000039, -143.10000000000045, -112.00000000000122, 53.80000000000052, 39.800000000000296, -89.4000000000011, 52.70000000000049, -393.0999999999996, 4.900000000000006, 7.999999999999959, -242.50000000000034, 20.199999999999974, -107.70000000000064, 32.9000000000002, -5.099999999999685, -177.50000000000065, 44.10000000000037, -188.10000000000016, -69.19999999999993, -18.899999999999523, -145.80000000000075, 1.900000000000073, 38.70000000000028, -456.0999999999989, 28.900000000000187, -79.60000000000117, 34.900000000000226, 40.90000000000031, -94.4000000000015, 58.20000000000049, 28.80000000000012, -87.60000000000113, 0.3999999999999826, -152.0000000000005, 50.500000000000476, 61.00000000000049, -16.999999999999744, 35.90000000000024, -28.099999999999845, 44.00000000000036, -165.20000000000127, 52.400000000000496, -83.90000000000055, -132.2000000000012, 5.100000000000184, -0.499999999999871, 13.199999999999944, 41.20000000000032, -147.00000000000037, -164.80000000000075, 60.4000000000005, 55.80000000000047, 43.80000000000037, 36.10000000000024, -72.20000000000162, 19.09999999999996, 47.30000000000042, 31.900000000000176, 53.50000000000028, 60.0000000000002, 51.50000000000049, -140.00000000000045, 32.60000000000019, -7.299999999999855, -59.800000000001305, 57.40000000000048, -26.199999999999555, -330.09999999999883, 54.7000000000005, 42.40000000000033, -116.90000000000012, 50.60000000000045, 3.300000000000131, 36.000000000000234, -169.10000000000116, -177.90000000000106, -107.20000000000087, 57.80000000000047, -170.29999999999995, -155.4000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-313.8999999999997, -51.099999999999824, -400.0, 20.000000000000014, -211.60000000000002, -19.899999999999743, -112.60000000000068, -187.90000000000057, 9.799999999999976, -355.9000000000001, -185.80000000000058, -192.10000000000048, -259.3, -381.0999999999998, -400.0, -172.3000000000006, -276.1, -194.20000000000056, -85.00000000000081, -7.300000000000004, -64.00000000000088, -206.7999999999999, 5.299999999999965, -4.900000000000002, 15.79999999999996, 17.899999999999988, -400.0, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -448.0, -48.999999999999815, 4.399999999999972, -0.9999999999999846, -94.00000000000072, -82.90000000000086, 15.799999999999963, -170.50000000000003, -376.8999999999998, -400.0, 35.30000000000025, -0.09999999999999937, -330.7, 5.5999999999999766, -143.8000000000007, -104.20000000000053, 17.899999999999984, 29.90000000000018, -0.09999999999999937, 29.90000000000018, -76.60000000000056, -155.80000000000055, 24.20000000000008, 12.499999999999972, -292.9000000000001, -278.1999999999996, -32.49999999999975, -13.600000000000023, -480.0, 20.000000000000014, -207.10000000000034, -387.4, -7.299999999999905, 9.499999999999964, -330.69999999999925, 20.000000000000014, 20.000000000000014, 2.8999999999999613, 3.1999999999999615, -49.299999999999756, -400.0, 12.499999999999973, 17.299999999999976, 15.799999999999963, -232.0, -255.09999999999928, 18.49999999999998, -393.70000000000005, -24.099999999999767, -38.799999999999756, -400.0, -122.80000000000075, 20.000000000000014, -129.10000000000073, 20.000000000000014, 13.699999999999964, -283.5999999999999, -368.5, -318.10000000000025, 29.000000000000163, -59.80000000000035, -206.80000000000052, 20.000000000000014, -3.099999999999958, 24.50000000000008, 7.399999999999965, -137.5000000000007, -61.900000000000595, 20.000000000000014, 27.200000000000138, 12.499999999999964, 5.299999999999965, -215.20000000000047, 11.599999999999964, 20.000000000000014, -391.6, -351.7, 22.700000000000053, 7.399999999999965, 37.10000000000026, 32.00000000000022, 20.000000000000014, 20.000000000000014, -400.0, 9.499999999999964, 16.399999999999967, 23.000000000000064, -297.0999999999989, 16.09999999999996, 20.900000000000027, -141.7000000000007, -179.5000000000006, 20.000000000000014, 19.400000000000006, 20.000000000000014, -313.89999999999935, -152.20000000000067, -166.00000000000054, -13.599999999999783, -7.299999999999891, 20.000000000000014, -116.50000000000077, -301.29999999999905, 24.50000000000008, 1.9999999999999625, 27.20000000000013, -326.49999999999994, 9.499999999999964, 12.499999999999964, -364.2999999999996, 20.000000000000014, 37.40000000000025, 5.299999999999965, 39.500000000000234, 20.000000000000014, 6.7999999999999705, 1.0999999999999865, 20.000000000000014, -128.20000000000073, -36.99999999999978, 20.000000000000014, -19.899999999999935, 29.600000000000176, 13.699999999999964, 5.5999999999999925, 5.299999999999965, -399.8, 35.300000000000246, 20.000000000000014, -776.0, 27.50000000000014, 20.000000000000014, 20.000000000000014, -502.0, 23.600000000000065, -0.9999999999999846, -103.8999999999998, -910.4, -38.799999999999756, -127.00000000000074, 40.70000000000024, 13.699999999999964, 20.000000000000014, -110.20000000000078, -198.40000000000018, -288.69999999999936, 20.000000000000014, 31.700000000000216, 20.600000000000023, 15.799999999999963, -292.90000000000026, 26.00000000000011, 20.000000000000014, 14.599999999999964, 20.000000000000014, -57.70000000000041, 7.999999999999966, 20.000000000000014, -202.60000000000053, -77.50000000000065, -134.50000000000048, -156.40000000000057, -568.0, -26.199999999999747, 40.70000000000023, 1.0999999999999865, -359.5, -185.80000000000058, -385.30000000000007, 35.900000000000254], "policy_predator_policy_reward": [125.0, 130.0, 199.0, 194.0, 76.0, 147.0, 91.0, 91.0, 13.0, 179.0, 100.0, 103.0, 200.0, 200.0, 197.0, 200.0, 13.0, 184.0, 10.0, 63.0, 110.0, 127.0, 17.0, 7.0, 11.0, 1.0, 200.0, 189.0, 4.0, 8.0, 238.0, 212.0, 10.0, 13.0, 72.0, 1.0, 92.0, 2.0, 200.0, 160.0, 0.0, 10.0, 15.0, 167.0, 34.0, 102.0, 4.0, 2.0, 0.0, 10.0, 84.0, 59.0, 6.0, 10.0, 6.0, 172.0, 19.0, 32.0, 186.0, 282.0, 159.0, 193.0, 2.0, 16.0, 167.0, 36.0, 9.0, 1.0, 33.0, 8.0, 200.0, 10.0, 9.0, 2.0, 117.0, 182.0, 114.0, 192.0, 25.0, 19.0, 200.0, 177.0, 67.0, 44.0, 3.0, 2.0, 2.0, 194.0, 157.0, 161.0, 91.0, 96.0, 11.0, 7.0, 3.0, 6.0, 30.0, 75.0, 6.0, 5.0, 7.0, 4.0, 112.0, 4.0, 176.0, 196.0, 177.0, 0.0, 0.0, 6.0, 5.0, 4.0, 200.0, 163.0, 1.0, 9.0, 95.0, 151.0, 3.0, 4.0, 59.0, 97.0, 6.0, 7.0, 49.0, 161.0, 88.0, 98.0, 10.0, 16.0, 61.0, 35.0, 137.0, 153.0, 4.0, 8.0, 165.0, 5.0, 183.0, 4.0, 1.0, 2.0, 4.0, 7.0, 8.0, 9.0, 9.0, 6.0, 58.0, 35.0, 19.0, 0.0, 1.0, 3.0, 11.0, 10.0, 161.0, 257.0, 274.0, 542.0, 2.0, 2.0, 342.0, 0.0, 0.0, 10.0, 240.0, 767.0, 70.0, 36.0, 3.0, 0.0, 14.0, 50.0, 3.0, 154.0, 0.0, 3.0, 4.0, 2.0, 1.0, 149.0, 12.0, 4.0, 40.0, 1.0, 7.0, 1.0, 5.0, 106.0, 83.0, 30.0, 389.0, 98.0, 7.0, 9.0, 277.0, 98.0, 193.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6022948127646205, "mean_inference_ms": 1.8982778212745581, "mean_action_processing_ms": 0.2494743101372531, "mean_env_wait_ms": 0.20459310634772535, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009119987487792969, "StateBufferConnector_ms": 0.012154459953308105, "ViewRequirementAgentConnector_ms": 0.13637292385101318}, "num_episodes": 22, "episode_return_max": 61.00000000000049, "episode_return_min": -456.0999999999989, "episode_return_mean": -49.843000000000096, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 421.4683787352459, "num_env_steps_trained_throughput_per_sec": 421.4683787352459, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 45282.646, "restore_workers_time_ms": 0.015, "training_step_time_ms": 45282.594, "sample_time_ms": 1611.355, "learn_time_ms": 43651.689, "learn_throughput": 91.634, "synch_weights_time_ms": 17.701}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-12-38", "timestamp": 1723644758, "time_this_iter_s": 9.49451994895935, "time_total_s": 624.3606297969818, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187439d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 624.3606297969818, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 27.435714285714283, "ram_util_percent": 83.29285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.2812143312560185, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 2.290248228696288, "policy_loss": 0.0020174842850162237, "vf_loss": 2.244257940943279, "vf_explained_var": 0.06816716985727744, "kl": 0.012868127909841485, "entropy": 1.0049383162506043, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9979467815192287, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 2.6495233374297933, "policy_loss": 0.003023506026769244, "vf_loss": 2.614083666965444, "vf_explained_var": 0.00030444582934102053, "kl": 0.009486211819042188, "entropy": 0.7932377397856384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 75.1999999999997, "episode_reward_min": -456.0999999999989, "episode_reward_mean": -32.78900000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -910.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000025, "predator_policy": 767.0}, "policy_reward_mean": {"prey_policy": -80.99450000000007, "predator_policy": 64.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [53.80000000000052, 39.800000000000296, -89.4000000000011, 52.70000000000049, -393.0999999999996, 4.900000000000006, 7.999999999999959, -242.50000000000034, 20.199999999999974, -107.70000000000064, 32.9000000000002, -5.099999999999685, -177.50000000000065, 44.10000000000037, -188.10000000000016, -69.19999999999993, -18.899999999999523, -145.80000000000075, 1.900000000000073, 38.70000000000028, -456.0999999999989, 28.900000000000187, -79.60000000000117, 34.900000000000226, 40.90000000000031, -94.4000000000015, 58.20000000000049, 28.80000000000012, -87.60000000000113, 0.3999999999999826, -152.0000000000005, 50.500000000000476, 61.00000000000049, -16.999999999999744, 35.90000000000024, -28.099999999999845, 44.00000000000036, -165.20000000000127, 52.400000000000496, -83.90000000000055, -132.2000000000012, 5.100000000000184, -0.499999999999871, 13.199999999999944, 41.20000000000032, -147.00000000000037, -164.80000000000075, 60.4000000000005, 55.80000000000047, 43.80000000000037, 36.10000000000024, -72.20000000000162, 19.09999999999996, 47.30000000000042, 31.900000000000176, 53.50000000000028, 60.0000000000002, 51.50000000000049, -140.00000000000045, 32.60000000000019, -7.299999999999855, -59.800000000001305, 57.40000000000048, -26.199999999999555, -330.09999999999883, 54.7000000000005, 42.40000000000033, -116.90000000000012, 50.60000000000045, 3.300000000000131, 36.000000000000234, -169.10000000000116, -177.90000000000106, -107.20000000000087, 57.80000000000047, -170.29999999999995, -155.4000000000006, 21.300000000000015, 55.30000000000048, -1.199999999999814, -116.00000000000134, -14.499999999999645, -18.299999999999528, 75.1999999999997, 46.30000000000043, -38.69999999999968, 24.600000000000048, -51.10000000000007, -44.29999999999986, -100.70000000000161, 35.40000000000023, -165.4000000000007, 41.10000000000032, 29.000000000000146, 54.8000000000005, -78.10000000000127, -33.99999999999957, 39.100000000000286, -93.1000000000007, 45.900000000000404], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999984, 29.90000000000018, -0.09999999999999937, 29.90000000000018, -76.60000000000056, -155.80000000000055, 24.20000000000008, 12.499999999999972, -292.9000000000001, -278.1999999999996, -32.49999999999975, -13.600000000000023, -480.0, 20.000000000000014, -207.10000000000034, -387.4, -7.299999999999905, 9.499999999999964, -330.69999999999925, 20.000000000000014, 20.000000000000014, 2.8999999999999613, 3.1999999999999615, -49.299999999999756, -400.0, 12.499999999999973, 17.299999999999976, 15.799999999999963, -232.0, -255.09999999999928, 18.49999999999998, -393.70000000000005, -24.099999999999767, -38.799999999999756, -400.0, -122.80000000000075, 20.000000000000014, -129.10000000000073, 20.000000000000014, 13.699999999999964, -283.5999999999999, -368.5, -318.10000000000025, 29.000000000000163, -59.80000000000035, -206.80000000000052, 20.000000000000014, -3.099999999999958, 24.50000000000008, 7.399999999999965, -137.5000000000007, -61.900000000000595, 20.000000000000014, 27.200000000000138, 12.499999999999964, 5.299999999999965, -215.20000000000047, 11.599999999999964, 20.000000000000014, -391.6, -351.7, 22.700000000000053, 7.399999999999965, 37.10000000000026, 32.00000000000022, 20.000000000000014, 20.000000000000014, -400.0, 9.499999999999964, 16.399999999999967, 23.000000000000064, -297.0999999999989, 16.09999999999996, 20.900000000000027, -141.7000000000007, -179.5000000000006, 20.000000000000014, 19.400000000000006, 20.000000000000014, -313.89999999999935, -152.20000000000067, -166.00000000000054, -13.599999999999783, -7.299999999999891, 20.000000000000014, -116.50000000000077, -301.29999999999905, 24.50000000000008, 1.9999999999999625, 27.20000000000013, -326.49999999999994, 9.499999999999964, 12.499999999999964, -364.2999999999996, 20.000000000000014, 37.40000000000025, 5.299999999999965, 39.500000000000234, 20.000000000000014, 6.7999999999999705, 1.0999999999999865, 20.000000000000014, -128.20000000000073, -36.99999999999978, 20.000000000000014, -19.899999999999935, 29.600000000000176, 13.699999999999964, 5.5999999999999925, 5.299999999999965, -399.8, 35.300000000000246, 20.000000000000014, -776.0, 27.50000000000014, 20.000000000000014, 20.000000000000014, -502.0, 23.600000000000065, -0.9999999999999846, -103.8999999999998, -910.4, -38.799999999999756, -127.00000000000074, 40.70000000000024, 13.699999999999964, 20.000000000000014, -110.20000000000078, -198.40000000000018, -288.69999999999936, 20.000000000000014, 31.700000000000216, 20.600000000000023, 15.799999999999963, -292.90000000000026, 26.00000000000011, 20.000000000000014, 14.599999999999964, 20.000000000000014, -57.70000000000041, 7.999999999999966, 20.000000000000014, -202.60000000000053, -77.50000000000065, -134.50000000000048, -156.40000000000057, -568.0, -26.199999999999747, 40.70000000000023, 1.0999999999999865, -359.5, -185.80000000000058, -385.30000000000007, 35.900000000000254, 3.1999999999999633, -16.899999999999796, 29.300000000000175, 20.000000000000014, 15.499999999999964, -60.70000000000061, -152.20000000000067, -101.80000000000067, 20.000000000000014, -158.50000000000065, -72.40000000000089, 4.099999999999971, 21.80000000000004, 43.40000000000025, -150.10000000000068, 34.40000000000026, -122.80000000000075, -19.89999999999977, 11.599999999999964, -0.9999999999999917, -4.899999999999984, -152.20000000000067, -25.299999999999862, -400.0, -103.9000000000008, -65.80000000000081, 11.599999999999964, 15.799999999999963, -309.6999999999993, -120.70000000000053, -7.299999999999891, 31.40000000000021, 6.799999999999974, 3.1999999999999615, 28.100000000000147, 19.70000000000001, -70.30000000000089, -128.80000000000055, -113.50000000000077, -11.499999999999833, 1.0999999999999865, 20.000000000000014, -78.70000000000087, -135.40000000000032, 20.000000000000014, 11.899999999999974], "policy_predator_policy_reward": [4.0, 2.0, 0.0, 10.0, 84.0, 59.0, 6.0, 10.0, 6.0, 172.0, 19.0, 32.0, 186.0, 282.0, 159.0, 193.0, 2.0, 16.0, 167.0, 36.0, 9.0, 1.0, 33.0, 8.0, 200.0, 10.0, 9.0, 2.0, 117.0, 182.0, 114.0, 192.0, 25.0, 19.0, 200.0, 177.0, 67.0, 44.0, 3.0, 2.0, 2.0, 194.0, 157.0, 161.0, 91.0, 96.0, 11.0, 7.0, 3.0, 6.0, 30.0, 75.0, 6.0, 5.0, 7.0, 4.0, 112.0, 4.0, 176.0, 196.0, 177.0, 0.0, 0.0, 6.0, 5.0, 4.0, 200.0, 163.0, 1.0, 9.0, 95.0, 151.0, 3.0, 4.0, 59.0, 97.0, 6.0, 7.0, 49.0, 161.0, 88.0, 98.0, 10.0, 16.0, 61.0, 35.0, 137.0, 153.0, 4.0, 8.0, 165.0, 5.0, 183.0, 4.0, 1.0, 2.0, 4.0, 7.0, 8.0, 9.0, 9.0, 6.0, 58.0, 35.0, 19.0, 0.0, 1.0, 3.0, 11.0, 10.0, 161.0, 257.0, 274.0, 542.0, 2.0, 2.0, 342.0, 0.0, 0.0, 10.0, 240.0, 767.0, 70.0, 36.0, 3.0, 0.0, 14.0, 50.0, 3.0, 154.0, 0.0, 3.0, 4.0, 2.0, 1.0, 149.0, 12.0, 4.0, 40.0, 1.0, 7.0, 1.0, 5.0, 106.0, 83.0, 30.0, 389.0, 98.0, 7.0, 9.0, 277.0, 98.0, 193.0, 1.0, 31.0, 4.0, 5.0, 1.0, 12.0, 32.0, 55.0, 83.0, 85.0, 39.0, 6.0, 44.0, 6.0, 4.0, 81.0, 81.0, 47.0, 57.0, 1.0, 13.0, 24.0, 82.0, 196.0, 185.0, 9.0, 60.0, 4.0, 4.0, 157.0, 108.0, 13.0, 4.0, 8.0, 11.0, 0.0, 7.0, 18.0, 103.0, 54.0, 37.0, 9.0, 9.0, 4.0, 117.0, 12.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.612929790609293, "mean_inference_ms": 1.9226405213532032, "mean_action_processing_ms": 0.25813342441929776, "mean_env_wait_ms": 0.20793908707958442, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008787035942077637, "StateBufferConnector_ms": 0.0118560791015625, "ViewRequirementAgentConnector_ms": 0.11188840866088867}, "num_episodes": 23, "episode_return_max": 75.1999999999997, "episode_return_min": -456.0999999999989, "episode_return_mean": -32.78900000000004, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 384.1474550381308, "num_env_steps_trained_throughput_per_sec": 384.1474550381308, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 45347.125, "restore_workers_time_ms": 0.015, "training_step_time_ms": 45347.07, "sample_time_ms": 1660.942, "learn_time_ms": 43665.917, "learn_throughput": 91.605, "synch_weights_time_ms": 18.23}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-12-49", "timestamp": 1723644769, "time_this_iter_s": 10.429529190063477, "time_total_s": 634.7901589870453, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31874c040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 634.7901589870453, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 33.07333333333334, "ram_util_percent": 83.70666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.11848727994495, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.9310012175292566, "policy_loss": 0.0010609524420625161, "vf_loss": 3.903611788169417, "vf_explained_var": 0.020736260609652, "kl": 0.007704721292099644, "entropy": 0.8453710039772054, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5063213324420666, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.588895280146725, "policy_loss": 0.0028220616199726625, "vf_loss": 3.5588130595822816, "vf_explained_var": 0.0017838488810907596, "kl": 0.00797736898579166, "entropy": 0.6729557495741617, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 75.1999999999997, "episode_reward_min": -456.0999999999989, "episode_reward_mean": -34.45900000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -910.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000025, "predator_policy": 767.0}, "policy_reward_mean": {"prey_policy": -81.48950000000009, "predator_policy": 64.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.900000000000073, 38.70000000000028, -456.0999999999989, 28.900000000000187, -79.60000000000117, 34.900000000000226, 40.90000000000031, -94.4000000000015, 58.20000000000049, 28.80000000000012, -87.60000000000113, 0.3999999999999826, -152.0000000000005, 50.500000000000476, 61.00000000000049, -16.999999999999744, 35.90000000000024, -28.099999999999845, 44.00000000000036, -165.20000000000127, 52.400000000000496, -83.90000000000055, -132.2000000000012, 5.100000000000184, -0.499999999999871, 13.199999999999944, 41.20000000000032, -147.00000000000037, -164.80000000000075, 60.4000000000005, 55.80000000000047, 43.80000000000037, 36.10000000000024, -72.20000000000162, 19.09999999999996, 47.30000000000042, 31.900000000000176, 53.50000000000028, 60.0000000000002, 51.50000000000049, -140.00000000000045, 32.60000000000019, -7.299999999999855, -59.800000000001305, 57.40000000000048, -26.199999999999555, -330.09999999999883, 54.7000000000005, 42.40000000000033, -116.90000000000012, 50.60000000000045, 3.300000000000131, 36.000000000000234, -169.10000000000116, -177.90000000000106, -107.20000000000087, 57.80000000000047, -170.29999999999995, -155.4000000000006, 21.300000000000015, 55.30000000000048, -1.199999999999814, -116.00000000000134, -14.499999999999645, -18.299999999999528, 75.1999999999997, 46.30000000000043, -38.69999999999968, 24.600000000000048, -51.10000000000007, -44.29999999999986, -100.70000000000161, 35.40000000000023, -165.4000000000007, 41.10000000000032, 29.000000000000146, 54.8000000000005, -78.10000000000127, -33.99999999999957, 39.100000000000286, -93.1000000000007, 45.900000000000404, -164.0000000000012, -13.099999999999572, -123.80000000000138, -25.59999999999954, -113.80000000000157, -160.80000000000058, -145.2000000000006, -78.89999999999995, -195.10000000000062, -37.699999999999584, 73.8999999999998, 30.60000000000016, -202.5000000000004, -143.00000000000045, 47.500000000000426, 27.60000000000011, 6.499999999999953, -130.50000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -129.10000000000073, 20.000000000000014, 13.699999999999964, -283.5999999999999, -368.5, -318.10000000000025, 29.000000000000163, -59.80000000000035, -206.80000000000052, 20.000000000000014, -3.099999999999958, 24.50000000000008, 7.399999999999965, -137.5000000000007, -61.900000000000595, 20.000000000000014, 27.200000000000138, 12.499999999999964, 5.299999999999965, -215.20000000000047, 11.599999999999964, 20.000000000000014, -391.6, -351.7, 22.700000000000053, 7.399999999999965, 37.10000000000026, 32.00000000000022, 20.000000000000014, 20.000000000000014, -400.0, 9.499999999999964, 16.399999999999967, 23.000000000000064, -297.0999999999989, 16.09999999999996, 20.900000000000027, -141.7000000000007, -179.5000000000006, 20.000000000000014, 19.400000000000006, 20.000000000000014, -313.89999999999935, -152.20000000000067, -166.00000000000054, -13.599999999999783, -7.299999999999891, 20.000000000000014, -116.50000000000077, -301.29999999999905, 24.50000000000008, 1.9999999999999625, 27.20000000000013, -326.49999999999994, 9.499999999999964, 12.499999999999964, -364.2999999999996, 20.000000000000014, 37.40000000000025, 5.299999999999965, 39.500000000000234, 20.000000000000014, 6.7999999999999705, 1.0999999999999865, 20.000000000000014, -128.20000000000073, -36.99999999999978, 20.000000000000014, -19.899999999999935, 29.600000000000176, 13.699999999999964, 5.5999999999999925, 5.299999999999965, -399.8, 35.300000000000246, 20.000000000000014, -776.0, 27.50000000000014, 20.000000000000014, 20.000000000000014, -502.0, 23.600000000000065, -0.9999999999999846, -103.8999999999998, -910.4, -38.799999999999756, -127.00000000000074, 40.70000000000024, 13.699999999999964, 20.000000000000014, -110.20000000000078, -198.40000000000018, -288.69999999999936, 20.000000000000014, 31.700000000000216, 20.600000000000023, 15.799999999999963, -292.90000000000026, 26.00000000000011, 20.000000000000014, 14.599999999999964, 20.000000000000014, -57.70000000000041, 7.999999999999966, 20.000000000000014, -202.60000000000053, -77.50000000000065, -134.50000000000048, -156.40000000000057, -568.0, -26.199999999999747, 40.70000000000023, 1.0999999999999865, -359.5, -185.80000000000058, -385.30000000000007, 35.900000000000254, 3.1999999999999633, -16.899999999999796, 29.300000000000175, 20.000000000000014, 15.499999999999964, -60.70000000000061, -152.20000000000067, -101.80000000000067, 20.000000000000014, -158.50000000000065, -72.40000000000089, 4.099999999999971, 21.80000000000004, 43.40000000000025, -150.10000000000068, 34.40000000000026, -122.80000000000075, -19.89999999999977, 11.599999999999964, -0.9999999999999917, -4.899999999999984, -152.20000000000067, -25.299999999999862, -400.0, -103.9000000000008, -65.80000000000081, 11.599999999999964, 15.799999999999963, -309.6999999999993, -120.70000000000053, -7.299999999999891, 31.40000000000021, 6.799999999999974, 3.1999999999999615, 28.100000000000147, 19.70000000000001, -70.30000000000089, -128.80000000000055, -113.50000000000077, -11.499999999999833, 1.0999999999999865, 20.000000000000014, -78.70000000000087, -135.40000000000032, 20.000000000000014, 11.899999999999974, -152.20000000000067, -206.80000000000052, 0.7999999999999758, -61.900000000000766, -114.40000000000077, -177.4000000000006, -15.699999999999775, -40.89999999999977, -63.10000000000077, -120.70000000000076, -464.0, 24.200000000000085, -388.6999999999997, 36.50000000000025, -400.0, 37.10000000000025, -160.60000000000065, -368.5, -148.00000000000065, 5.299999999999965, 32.60000000000023, 38.300000000000246, 20.000000000000014, -9.399999999999855, -250.89999999999986, -349.6, -362.2, 33.200000000000244, 15.799999999999963, 28.70000000000016, -0.700000000000024, 5.299999999999965, -135.4000000000004, -24.099999999999746, -51.399999999999764, -234.10000000000002], "policy_predator_policy_reward": [67.0, 44.0, 3.0, 2.0, 2.0, 194.0, 157.0, 161.0, 91.0, 96.0, 11.0, 7.0, 3.0, 6.0, 30.0, 75.0, 6.0, 5.0, 7.0, 4.0, 112.0, 4.0, 176.0, 196.0, 177.0, 0.0, 0.0, 6.0, 5.0, 4.0, 200.0, 163.0, 1.0, 9.0, 95.0, 151.0, 3.0, 4.0, 59.0, 97.0, 6.0, 7.0, 49.0, 161.0, 88.0, 98.0, 10.0, 16.0, 61.0, 35.0, 137.0, 153.0, 4.0, 8.0, 165.0, 5.0, 183.0, 4.0, 1.0, 2.0, 4.0, 7.0, 8.0, 9.0, 9.0, 6.0, 58.0, 35.0, 19.0, 0.0, 1.0, 3.0, 11.0, 10.0, 161.0, 257.0, 274.0, 542.0, 2.0, 2.0, 342.0, 0.0, 0.0, 10.0, 240.0, 767.0, 70.0, 36.0, 3.0, 0.0, 14.0, 50.0, 3.0, 154.0, 0.0, 3.0, 4.0, 2.0, 1.0, 149.0, 12.0, 4.0, 40.0, 1.0, 7.0, 1.0, 5.0, 106.0, 83.0, 30.0, 389.0, 98.0, 7.0, 9.0, 277.0, 98.0, 193.0, 1.0, 31.0, 4.0, 5.0, 1.0, 12.0, 32.0, 55.0, 83.0, 85.0, 39.0, 6.0, 44.0, 6.0, 4.0, 81.0, 81.0, 47.0, 57.0, 1.0, 13.0, 24.0, 82.0, 196.0, 185.0, 9.0, 60.0, 4.0, 4.0, 157.0, 108.0, 13.0, 4.0, 8.0, 11.0, 0.0, 7.0, 18.0, 103.0, 54.0, 37.0, 9.0, 9.0, 4.0, 117.0, 12.0, 2.0, 87.0, 108.0, 9.0, 39.0, 74.0, 94.0, 7.0, 24.0, 3.0, 67.0, 7.0, 272.0, 2.0, 205.0, 88.0, 196.0, 149.0, 185.0, 71.0, 34.0, 2.0, 1.0, 6.0, 14.0, 198.0, 200.0, 182.0, 4.0, 2.0, 1.0, 1.0, 22.0, 80.0, 86.0, 8.0, 147.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6148053991899994, "mean_inference_ms": 1.9261701398502589, "mean_action_processing_ms": 0.26218402781013017, "mean_env_wait_ms": 0.20844201586242364, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00811922550201416, "StateBufferConnector_ms": 0.011681675910949707, "ViewRequirementAgentConnector_ms": 0.10773038864135742}, "num_episodes": 18, "episode_return_max": 75.1999999999997, "episode_return_min": -456.0999999999989, "episode_return_mean": -34.45900000000009, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.46137398412674, "num_env_steps_trained_throughput_per_sec": 416.46137398412674, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 45339.119, "restore_workers_time_ms": 0.016, "training_step_time_ms": 45339.062, "sample_time_ms": 1664.826, "learn_time_ms": 43653.791, "learn_throughput": 91.63, "synch_weights_time_ms": 18.458}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-12-58", "timestamp": 1723644778, "time_this_iter_s": 9.634653806686401, "time_total_s": 644.4248127937317, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3186d80d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 644.4248127937317, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 29.46153846153846, "ram_util_percent": 83.72307692307693}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.66238701277309, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 3.475061365536281, "policy_loss": 0.000362765469351813, "vf_loss": 3.4522316978091285, "vf_explained_var": 0.00881047185766634, "kl": 0.00657467690471864, "entropy": 0.8566726109338185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.595321494624728, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 2.9400163374249897, "policy_loss": 0.0023299019791126726, "vf_loss": 2.9045014584506, "vf_explained_var": 0.00032665798903773073, "kl": 0.009711199208352391, "entropy": 0.6414265956512835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 75.1999999999997, "episode_reward_min": -330.09999999999883, "episode_reward_mean": -32.4170000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -910.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000025, "predator_policy": 767.0}, "policy_reward_mean": {"prey_policy": -82.54850000000009, "predator_policy": 66.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.00000000000036, -165.20000000000127, 52.400000000000496, -83.90000000000055, -132.2000000000012, 5.100000000000184, -0.499999999999871, 13.199999999999944, 41.20000000000032, -147.00000000000037, -164.80000000000075, 60.4000000000005, 55.80000000000047, 43.80000000000037, 36.10000000000024, -72.20000000000162, 19.09999999999996, 47.30000000000042, 31.900000000000176, 53.50000000000028, 60.0000000000002, 51.50000000000049, -140.00000000000045, 32.60000000000019, -7.299999999999855, -59.800000000001305, 57.40000000000048, -26.199999999999555, -330.09999999999883, 54.7000000000005, 42.40000000000033, -116.90000000000012, 50.60000000000045, 3.300000000000131, 36.000000000000234, -169.10000000000116, -177.90000000000106, -107.20000000000087, 57.80000000000047, -170.29999999999995, -155.4000000000006, 21.300000000000015, 55.30000000000048, -1.199999999999814, -116.00000000000134, -14.499999999999645, -18.299999999999528, 75.1999999999997, 46.30000000000043, -38.69999999999968, 24.600000000000048, -51.10000000000007, -44.29999999999986, -100.70000000000161, 35.40000000000023, -165.4000000000007, 41.10000000000032, 29.000000000000146, 54.8000000000005, -78.10000000000127, -33.99999999999957, 39.100000000000286, -93.1000000000007, 45.900000000000404, -164.0000000000012, -13.099999999999572, -123.80000000000138, -25.59999999999954, -113.80000000000157, -160.80000000000058, -145.2000000000006, -78.89999999999995, -195.10000000000062, -37.699999999999584, 73.8999999999998, 30.60000000000016, -202.5000000000004, -143.00000000000045, 47.500000000000426, 27.60000000000011, 6.499999999999953, -130.50000000000028, -144.5000000000007, 19.39999999999997, -50.10000000000087, -37.699999999999626, 36.50000000000025, -122.70000000000155, -23.499999999999666, 17.900000000000002, -26.399999999999558, -10.99999999999965, -44.70000000000035, 49.800000000000466, 54.000000000000135, -22.299999999999635, 24.200000000000042, -137.2000000000006, 52.7000000000005, 35.10000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [16.09999999999996, 20.900000000000027, -141.7000000000007, -179.5000000000006, 20.000000000000014, 19.400000000000006, 20.000000000000014, -313.89999999999935, -152.20000000000067, -166.00000000000054, -13.599999999999783, -7.299999999999891, 20.000000000000014, -116.50000000000077, -301.29999999999905, 24.50000000000008, 1.9999999999999625, 27.20000000000013, -326.49999999999994, 9.499999999999964, 12.499999999999964, -364.2999999999996, 20.000000000000014, 37.40000000000025, 5.299999999999965, 39.500000000000234, 20.000000000000014, 6.7999999999999705, 1.0999999999999865, 20.000000000000014, -128.20000000000073, -36.99999999999978, 20.000000000000014, -19.899999999999935, 29.600000000000176, 13.699999999999964, 5.5999999999999925, 5.299999999999965, -399.8, 35.300000000000246, 20.000000000000014, -776.0, 27.50000000000014, 20.000000000000014, 20.000000000000014, -502.0, 23.600000000000065, -0.9999999999999846, -103.8999999999998, -910.4, -38.799999999999756, -127.00000000000074, 40.70000000000024, 13.699999999999964, 20.000000000000014, -110.20000000000078, -198.40000000000018, -288.69999999999936, 20.000000000000014, 31.700000000000216, 20.600000000000023, 15.799999999999963, -292.90000000000026, 26.00000000000011, 20.000000000000014, 14.599999999999964, 20.000000000000014, -57.70000000000041, 7.999999999999966, 20.000000000000014, -202.60000000000053, -77.50000000000065, -134.50000000000048, -156.40000000000057, -568.0, -26.199999999999747, 40.70000000000023, 1.0999999999999865, -359.5, -185.80000000000058, -385.30000000000007, 35.900000000000254, 3.1999999999999633, -16.899999999999796, 29.300000000000175, 20.000000000000014, 15.499999999999964, -60.70000000000061, -152.20000000000067, -101.80000000000067, 20.000000000000014, -158.50000000000065, -72.40000000000089, 4.099999999999971, 21.80000000000004, 43.40000000000025, -150.10000000000068, 34.40000000000026, -122.80000000000075, -19.89999999999977, 11.599999999999964, -0.9999999999999917, -4.899999999999984, -152.20000000000067, -25.299999999999862, -400.0, -103.9000000000008, -65.80000000000081, 11.599999999999964, 15.799999999999963, -309.6999999999993, -120.70000000000053, -7.299999999999891, 31.40000000000021, 6.799999999999974, 3.1999999999999615, 28.100000000000147, 19.70000000000001, -70.30000000000089, -128.80000000000055, -113.50000000000077, -11.499999999999833, 1.0999999999999865, 20.000000000000014, -78.70000000000087, -135.40000000000032, 20.000000000000014, 11.899999999999974, -152.20000000000067, -206.80000000000052, 0.7999999999999758, -61.900000000000766, -114.40000000000077, -177.4000000000006, -15.699999999999775, -40.89999999999977, -63.10000000000077, -120.70000000000076, -464.0, 24.200000000000085, -388.6999999999997, 36.50000000000025, -400.0, 37.10000000000025, -160.60000000000065, -368.5, -148.00000000000065, 5.299999999999965, 32.60000000000023, 38.300000000000246, 20.000000000000014, -9.399999999999855, -250.89999999999986, -349.6, -362.2, 33.200000000000244, 15.799999999999963, 28.70000000000016, -0.700000000000024, 5.299999999999965, -135.4000000000004, -24.099999999999746, -51.399999999999764, -234.10000000000002, -392.8, -141.7000000000007, 5.299999999999965, 1.0999999999999874, -41.79999999999977, -49.299999999999905, -184.29999999999998, -51.40000000000005, 20.000000000000014, 9.499999999999964, -108.10000000000079, -118.60000000000076, -19.899999999999743, -148.60000000000053, -7.299999999999891, 3.1999999999999615, 20.000000000000014, -114.40000000000077, 31.700000000000212, -99.70000000000081, -26.199999999999747, -74.50000000000088, 12.79999999999997, 20.000000000000014, 20.000000000000014, -904.0, -246.70000000000041, -13.599999999999786, 11.599999999999964, -3.399999999999958, -162.70000000000064, -326.5, 20.000000000000014, 22.700000000000056, 1.0999999999999865, 20.000000000000014], "policy_predator_policy_reward": [3.0, 4.0, 59.0, 97.0, 6.0, 7.0, 49.0, 161.0, 88.0, 98.0, 10.0, 16.0, 61.0, 35.0, 137.0, 153.0, 4.0, 8.0, 165.0, 5.0, 183.0, 4.0, 1.0, 2.0, 4.0, 7.0, 8.0, 9.0, 9.0, 6.0, 58.0, 35.0, 19.0, 0.0, 1.0, 3.0, 11.0, 10.0, 161.0, 257.0, 274.0, 542.0, 2.0, 2.0, 342.0, 0.0, 0.0, 10.0, 240.0, 767.0, 70.0, 36.0, 3.0, 0.0, 14.0, 50.0, 3.0, 154.0, 0.0, 3.0, 4.0, 2.0, 1.0, 149.0, 12.0, 4.0, 40.0, 1.0, 7.0, 1.0, 5.0, 106.0, 83.0, 30.0, 389.0, 98.0, 7.0, 9.0, 277.0, 98.0, 193.0, 1.0, 31.0, 4.0, 5.0, 1.0, 12.0, 32.0, 55.0, 83.0, 85.0, 39.0, 6.0, 44.0, 6.0, 4.0, 81.0, 81.0, 47.0, 57.0, 1.0, 13.0, 24.0, 82.0, 196.0, 185.0, 9.0, 60.0, 4.0, 4.0, 157.0, 108.0, 13.0, 4.0, 8.0, 11.0, 0.0, 7.0, 18.0, 103.0, 54.0, 37.0, 9.0, 9.0, 4.0, 117.0, 12.0, 2.0, 87.0, 108.0, 9.0, 39.0, 74.0, 94.0, 7.0, 24.0, 3.0, 67.0, 7.0, 272.0, 2.0, 205.0, 88.0, 196.0, 149.0, 185.0, 71.0, 34.0, 2.0, 1.0, 6.0, 14.0, 198.0, 200.0, 182.0, 4.0, 2.0, 1.0, 1.0, 22.0, 80.0, 86.0, 8.0, 147.0, 190.0, 200.0, 0.0, 13.0, 1.0, 40.0, 100.0, 98.0, 2.0, 5.0, 36.0, 68.0, 80.0, 65.0, 9.0, 13.0, 4.0, 64.0, 57.0, 0.0, 11.0, 45.0, 9.0, 8.0, 532.0, 406.0, 127.0, 111.0, 12.0, 4.0, 152.0, 200.0, 4.0, 6.0, 9.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.613152490066634, "mean_inference_ms": 1.9215921410688241, "mean_action_processing_ms": 0.2650385279035664, "mean_env_wait_ms": 0.20771322642633372, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004935503005981445, "StateBufferConnector_ms": 0.003303050994873047, "ViewRequirementAgentConnector_ms": 0.09336972236633301}, "num_episodes": 18, "episode_return_max": 75.1999999999997, "episode_return_min": -330.09999999999883, "episode_return_mean": -32.4170000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 423.6986555159364, "num_env_steps_trained_throughput_per_sec": 423.6986555159364, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 45336.456, "restore_workers_time_ms": 0.016, "training_step_time_ms": 45336.399, "sample_time_ms": 1671.233, "learn_time_ms": 43644.681, "learn_throughput": 91.649, "synch_weights_time_ms": 18.526}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-13-08", "timestamp": 1723644788, "time_this_iter_s": 9.445112705230713, "time_total_s": 653.8699254989624, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3186c0e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 653.8699254989624, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 28.035714285714278, "ram_util_percent": 83.68571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6718361986061883, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 2.1734337408075888, "policy_loss": 0.0006916662902329807, "vf_loss": 2.138696198362522, "vf_explained_var": 0.011712663545810357, "kl": 0.009963130785694042, "entropy": 1.0529283865103647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.991192090211722, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 2.2981312773530447, "policy_loss": 0.0021986575821838364, "vf_loss": 2.2664441896178733, "vf_explained_var": 0.00012552845414984164, "kl": 0.008629443140152456, "entropy": 0.7027234858779049, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 75.1999999999997, "episode_reward_min": -330.09999999999883, "episode_reward_mean": -38.5710000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -910.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000025, "predator_policy": 767.0}, "policy_reward_mean": {"prey_policy": -87.3905000000001, "predator_policy": 68.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.900000000000176, 53.50000000000028, 60.0000000000002, 51.50000000000049, -140.00000000000045, 32.60000000000019, -7.299999999999855, -59.800000000001305, 57.40000000000048, -26.199999999999555, -330.09999999999883, 54.7000000000005, 42.40000000000033, -116.90000000000012, 50.60000000000045, 3.300000000000131, 36.000000000000234, -169.10000000000116, -177.90000000000106, -107.20000000000087, 57.80000000000047, -170.29999999999995, -155.4000000000006, 21.300000000000015, 55.30000000000048, -1.199999999999814, -116.00000000000134, -14.499999999999645, -18.299999999999528, 75.1999999999997, 46.30000000000043, -38.69999999999968, 24.600000000000048, -51.10000000000007, -44.29999999999986, -100.70000000000161, 35.40000000000023, -165.4000000000007, 41.10000000000032, 29.000000000000146, 54.8000000000005, -78.10000000000127, -33.99999999999957, 39.100000000000286, -93.1000000000007, 45.900000000000404, -164.0000000000012, -13.099999999999572, -123.80000000000138, -25.59999999999954, -113.80000000000157, -160.80000000000058, -145.2000000000006, -78.89999999999995, -195.10000000000062, -37.699999999999584, 73.8999999999998, 30.60000000000016, -202.5000000000004, -143.00000000000045, 47.500000000000426, 27.60000000000011, 6.499999999999953, -130.50000000000028, -144.5000000000007, 19.39999999999997, -50.10000000000087, -37.699999999999626, 36.50000000000025, -122.70000000000155, -23.499999999999666, 17.900000000000002, -26.399999999999558, -10.99999999999965, -44.70000000000035, 49.800000000000466, 54.000000000000135, -22.299999999999635, 24.200000000000042, -137.2000000000006, 52.7000000000005, 35.10000000000023, -226.80000000000078, 33.4000000000002, -95.70000000000138, -136.10000000000096, 57.80000000000048, -232.30000000000075, 39.50000000000029, 44.20000000000036, -183.9000000000007, -138.20000000000078, -32.59999999999954, -1.899999999999765, 53.40000000000051, -167.90000000000074, -6.699999999999765, 28.900000000000134, -45.59999999999985, 47.70000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.5999999999999925, 5.299999999999965, -399.8, 35.300000000000246, 20.000000000000014, -776.0, 27.50000000000014, 20.000000000000014, 20.000000000000014, -502.0, 23.600000000000065, -0.9999999999999846, -103.8999999999998, -910.4, -38.799999999999756, -127.00000000000074, 40.70000000000024, 13.699999999999964, 20.000000000000014, -110.20000000000078, -198.40000000000018, -288.69999999999936, 20.000000000000014, 31.700000000000216, 20.600000000000023, 15.799999999999963, -292.90000000000026, 26.00000000000011, 20.000000000000014, 14.599999999999964, 20.000000000000014, -57.70000000000041, 7.999999999999966, 20.000000000000014, -202.60000000000053, -77.50000000000065, -134.50000000000048, -156.40000000000057, -568.0, -26.199999999999747, 40.70000000000023, 1.0999999999999865, -359.5, -185.80000000000058, -385.30000000000007, 35.900000000000254, 3.1999999999999633, -16.899999999999796, 29.300000000000175, 20.000000000000014, 15.499999999999964, -60.70000000000061, -152.20000000000067, -101.80000000000067, 20.000000000000014, -158.50000000000065, -72.40000000000089, 4.099999999999971, 21.80000000000004, 43.40000000000025, -150.10000000000068, 34.40000000000026, -122.80000000000075, -19.89999999999977, 11.599999999999964, -0.9999999999999917, -4.899999999999984, -152.20000000000067, -25.299999999999862, -400.0, -103.9000000000008, -65.80000000000081, 11.599999999999964, 15.799999999999963, -309.6999999999993, -120.70000000000053, -7.299999999999891, 31.40000000000021, 6.799999999999974, 3.1999999999999615, 28.100000000000147, 19.70000000000001, -70.30000000000089, -128.80000000000055, -113.50000000000077, -11.499999999999833, 1.0999999999999865, 20.000000000000014, -78.70000000000087, -135.40000000000032, 20.000000000000014, 11.899999999999974, -152.20000000000067, -206.80000000000052, 0.7999999999999758, -61.900000000000766, -114.40000000000077, -177.4000000000006, -15.699999999999775, -40.89999999999977, -63.10000000000077, -120.70000000000076, -464.0, 24.200000000000085, -388.6999999999997, 36.50000000000025, -400.0, 37.10000000000025, -160.60000000000065, -368.5, -148.00000000000065, 5.299999999999965, 32.60000000000023, 38.300000000000246, 20.000000000000014, -9.399999999999855, -250.89999999999986, -349.6, -362.2, 33.200000000000244, 15.799999999999963, 28.70000000000016, -0.700000000000024, 5.299999999999965, -135.4000000000004, -24.099999999999746, -51.399999999999764, -234.10000000000002, -392.8, -141.7000000000007, 5.299999999999965, 1.0999999999999874, -41.79999999999977, -49.299999999999905, -184.29999999999998, -51.40000000000005, 20.000000000000014, 9.499999999999964, -108.10000000000079, -118.60000000000076, -19.899999999999743, -148.60000000000053, -7.299999999999891, 3.1999999999999615, 20.000000000000014, -114.40000000000077, 31.700000000000212, -99.70000000000081, -26.199999999999747, -74.50000000000088, 12.79999999999997, 20.000000000000014, 20.000000000000014, -904.0, -246.70000000000041, -13.599999999999786, 11.599999999999964, -3.399999999999958, -162.70000000000064, -326.5, 20.000000000000014, 22.700000000000056, 1.0999999999999865, 20.000000000000014, -303.4000000000001, -105.40000000000067, -4.299999999999958, 22.700000000000053, -55.600000000000335, -234.10000000000045, -400.0, -45.09999999999976, 1.0999999999999865, 40.70000000000024, -320.1999999999998, -81.10000000000073, 7.699999999999974, 15.799999999999963, 24.50000000000008, 13.699999999999964, -413.20000000000005, -57.70000000000005, -276.0999999999994, -24.099999999999746, -34.59999999999976, -39.99999999999978, -53.80000000000018, 8.899999999999967, 19.40000000000001, 29.000000000000167, 9.499999999999964, -366.3999999999997, -45.69999999999981, -21.999999999999744, -15.699999999999747, 20.600000000000023, -136.30000000000052, -49.299999999999905, 19.70000000000001, 20.000000000000014], "policy_predator_policy_reward": [11.0, 10.0, 161.0, 257.0, 274.0, 542.0, 2.0, 2.0, 342.0, 0.0, 0.0, 10.0, 240.0, 767.0, 70.0, 36.0, 3.0, 0.0, 14.0, 50.0, 3.0, 154.0, 0.0, 3.0, 4.0, 2.0, 1.0, 149.0, 12.0, 4.0, 40.0, 1.0, 7.0, 1.0, 5.0, 106.0, 83.0, 30.0, 389.0, 98.0, 7.0, 9.0, 277.0, 98.0, 193.0, 1.0, 31.0, 4.0, 5.0, 1.0, 12.0, 32.0, 55.0, 83.0, 85.0, 39.0, 6.0, 44.0, 6.0, 4.0, 81.0, 81.0, 47.0, 57.0, 1.0, 13.0, 24.0, 82.0, 196.0, 185.0, 9.0, 60.0, 4.0, 4.0, 157.0, 108.0, 13.0, 4.0, 8.0, 11.0, 0.0, 7.0, 18.0, 103.0, 54.0, 37.0, 9.0, 9.0, 4.0, 117.0, 12.0, 2.0, 87.0, 108.0, 9.0, 39.0, 74.0, 94.0, 7.0, 24.0, 3.0, 67.0, 7.0, 272.0, 2.0, 205.0, 88.0, 196.0, 149.0, 185.0, 71.0, 34.0, 2.0, 1.0, 6.0, 14.0, 198.0, 200.0, 182.0, 4.0, 2.0, 1.0, 1.0, 22.0, 80.0, 86.0, 8.0, 147.0, 190.0, 200.0, 0.0, 13.0, 1.0, 40.0, 100.0, 98.0, 2.0, 5.0, 36.0, 68.0, 80.0, 65.0, 9.0, 13.0, 4.0, 64.0, 57.0, 0.0, 11.0, 45.0, 9.0, 8.0, 532.0, 406.0, 127.0, 111.0, 12.0, 4.0, 152.0, 200.0, 4.0, 6.0, 9.0, 5.0, 169.0, 13.0, 15.0, 0.0, 73.0, 121.0, 166.0, 143.0, 9.0, 7.0, 2.0, 167.0, 14.0, 2.0, 3.0, 3.0, 7.0, 280.0, 162.0, 0.0, 0.0, 42.0, 36.0, 7.0, 5.0, 0.0, 5.0, 184.0, 59.0, 2.0, 7.0, 17.0, 30.0, 110.0, 1.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6113142948379499, "mean_inference_ms": 1.916735619598101, "mean_action_processing_ms": 0.2676859277292778, "mean_env_wait_ms": 0.2068271033782614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0043451786041259766, "StateBufferConnector_ms": 0.0032377243041992188, "ViewRequirementAgentConnector_ms": 0.0915675163269043}, "num_episodes": 18, "episode_return_max": 75.1999999999997, "episode_return_min": -330.09999999999883, "episode_return_mean": -38.5710000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 420.6379252921361, "num_env_steps_trained_throughput_per_sec": 420.6379252921361, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 45249.811, "restore_workers_time_ms": 0.016, "training_step_time_ms": 45249.753, "sample_time_ms": 1649.862, "learn_time_ms": 43579.135, "learn_throughput": 91.787, "synch_weights_time_ms": 18.776}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-13-17", "timestamp": 1723644797, "time_this_iter_s": 9.533905267715454, "time_total_s": 663.4038307666779, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318748040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 663.4038307666779, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 29.307692307692307, "ram_util_percent": 83.66153846153847}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3199665306421813, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.1713972483993205, "policy_loss": 0.0003096035705071199, "vf_loss": 5.144388538062888, "vf_explained_var": 0.012466390076137724, "kl": 0.007813180832327196, "entropy": 0.7974704268432798, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.498084044582629, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.884474789150177, "policy_loss": 0.004041613587646415, "vf_loss": 4.845483646569429, "vf_explained_var": 0.0005277153676149076, "kl": 0.010227572854329485, "entropy": 0.6668701922767377, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 75.1999999999997, "episode_reward_min": -404.6999999999998, "episode_reward_mean": -50.14900000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -904.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000025, "predator_policy": 677.0}, "policy_reward_mean": {"prey_policy": -94.6095000000001, "predator_policy": 69.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-14.499999999999645, -18.299999999999528, 75.1999999999997, 46.30000000000043, -38.69999999999968, 24.600000000000048, -51.10000000000007, -44.29999999999986, -100.70000000000161, 35.40000000000023, -165.4000000000007, 41.10000000000032, 29.000000000000146, 54.8000000000005, -78.10000000000127, -33.99999999999957, 39.100000000000286, -93.1000000000007, 45.900000000000404, -164.0000000000012, -13.099999999999572, -123.80000000000138, -25.59999999999954, -113.80000000000157, -160.80000000000058, -145.2000000000006, -78.89999999999995, -195.10000000000062, -37.699999999999584, 73.8999999999998, 30.60000000000016, -202.5000000000004, -143.00000000000045, 47.500000000000426, 27.60000000000011, 6.499999999999953, -130.50000000000028, -144.5000000000007, 19.39999999999997, -50.10000000000087, -37.699999999999626, 36.50000000000025, -122.70000000000155, -23.499999999999666, 17.900000000000002, -26.399999999999558, -10.99999999999965, -44.70000000000035, 49.800000000000466, 54.000000000000135, -22.299999999999635, 24.200000000000042, -137.2000000000006, 52.7000000000005, 35.10000000000023, -226.80000000000078, 33.4000000000002, -95.70000000000138, -136.10000000000096, 57.80000000000048, -232.30000000000075, 39.50000000000029, 44.20000000000036, -183.9000000000007, -138.20000000000078, -32.59999999999954, -1.899999999999765, 53.40000000000051, -167.90000000000074, -6.699999999999765, 28.900000000000134, -45.59999999999985, 47.70000000000043, 38.60000000000028, 41.70000000000032, 61.90000000000025, 65.10000000000043, -404.6999999999998, 55.00000000000048, 34.40000000000022, -231.0000000000008, -291.0999999999994, 51.300000000000495, -164.10000000000056, -124.60000000000076, -27.499999999999524, 20.00000000000001, 46.100000000000406, 58.10000000000052, -50.500000000000576, -360.40000000000003, -130.5000000000014, -266.10000000000014, -11.09999999999975, 48.70000000000045, 55.100000000000506, -229.30000000000047, -98.80000000000149, -134.20000000000022, -179.00000000000065], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -158.50000000000065, -72.40000000000089, 4.099999999999971, 21.80000000000004, 43.40000000000025, -150.10000000000068, 34.40000000000026, -122.80000000000075, -19.89999999999977, 11.599999999999964, -0.9999999999999917, -4.899999999999984, -152.20000000000067, -25.299999999999862, -400.0, -103.9000000000008, -65.80000000000081, 11.599999999999964, 15.799999999999963, -309.6999999999993, -120.70000000000053, -7.299999999999891, 31.40000000000021, 6.799999999999974, 3.1999999999999615, 28.100000000000147, 19.70000000000001, -70.30000000000089, -128.80000000000055, -113.50000000000077, -11.499999999999833, 1.0999999999999865, 20.000000000000014, -78.70000000000087, -135.40000000000032, 20.000000000000014, 11.899999999999974, -152.20000000000067, -206.80000000000052, 0.7999999999999758, -61.900000000000766, -114.40000000000077, -177.4000000000006, -15.699999999999775, -40.89999999999977, -63.10000000000077, -120.70000000000076, -464.0, 24.200000000000085, -388.6999999999997, 36.50000000000025, -400.0, 37.10000000000025, -160.60000000000065, -368.5, -148.00000000000065, 5.299999999999965, 32.60000000000023, 38.300000000000246, 20.000000000000014, -9.399999999999855, -250.89999999999986, -349.6, -362.2, 33.200000000000244, 15.799999999999963, 28.70000000000016, -0.700000000000024, 5.299999999999965, -135.4000000000004, -24.099999999999746, -51.399999999999764, -234.10000000000002, -392.8, -141.7000000000007, 5.299999999999965, 1.0999999999999874, -41.79999999999977, -49.299999999999905, -184.29999999999998, -51.40000000000005, 20.000000000000014, 9.499999999999964, -108.10000000000079, -118.60000000000076, -19.899999999999743, -148.60000000000053, -7.299999999999891, 3.1999999999999615, 20.000000000000014, -114.40000000000077, 31.700000000000212, -99.70000000000081, -26.199999999999747, -74.50000000000088, 12.79999999999997, 20.000000000000014, 20.000000000000014, -904.0, -246.70000000000041, -13.599999999999786, 11.599999999999964, -3.399999999999958, -162.70000000000064, -326.5, 20.000000000000014, 22.700000000000056, 1.0999999999999865, 20.000000000000014, -303.4000000000001, -105.40000000000067, -4.299999999999958, 22.700000000000053, -55.600000000000335, -234.10000000000045, -400.0, -45.09999999999976, 1.0999999999999865, 40.70000000000024, -320.1999999999998, -81.10000000000073, 7.699999999999974, 15.799999999999963, 24.50000000000008, 13.699999999999964, -413.20000000000005, -57.70000000000005, -276.0999999999994, -24.099999999999746, -34.59999999999976, -39.99999999999978, -53.80000000000018, 8.899999999999967, 19.40000000000001, 29.000000000000167, 9.499999999999964, -366.3999999999997, -45.69999999999981, -21.999999999999744, -15.699999999999747, 20.600000000000023, -136.30000000000052, -49.299999999999905, 19.70000000000001, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 7.699999999999967, -584.0, 38.90000000000024, 34.40000000000026, 22.700000000000056, -352.89999999999986, -362.8, 20.000000000000014, 20.000000000000014, 16.999999999999975, 7.399999999999965, -387.4, -97.6000000000008, -400.0, -192.10000000000056, 20.000000000000014, 26.300000000000118, -400.0, 20.90000000000003, -328.5999999999992, 38.000000000000256, -26.199999999999747, -49.29999999999985, -21.999999999999794, 20.000000000000014, 26.30000000000012, 0.7999999999999723, 23.00000000000006, 28.100000000000147, -4.300000000000008, -110.20000000000078, -552.9, -389.5, -78.70000000000087, -206.80000000000052, -807.2, -334.9000000000002, -192.10000000000056, 20.000000000000014, 35.30000000000025, 7.399999999999965, -3.099999999999958, 36.20000000000025, -400.0, -175.3000000000005, -101.80000000000081, -148.00000000000068, -499.4, -17.79999999999999, -400.0, 20.000000000000014], "policy_predator_policy_reward": [85.0, 39.0, 6.0, 44.0, 6.0, 4.0, 81.0, 81.0, 47.0, 57.0, 1.0, 13.0, 24.0, 82.0, 196.0, 185.0, 9.0, 60.0, 4.0, 4.0, 157.0, 108.0, 13.0, 4.0, 8.0, 11.0, 0.0, 7.0, 18.0, 103.0, 54.0, 37.0, 9.0, 9.0, 4.0, 117.0, 12.0, 2.0, 87.0, 108.0, 9.0, 39.0, 74.0, 94.0, 7.0, 24.0, 3.0, 67.0, 7.0, 272.0, 2.0, 205.0, 88.0, 196.0, 149.0, 185.0, 71.0, 34.0, 2.0, 1.0, 6.0, 14.0, 198.0, 200.0, 182.0, 4.0, 2.0, 1.0, 1.0, 22.0, 80.0, 86.0, 8.0, 147.0, 190.0, 200.0, 0.0, 13.0, 1.0, 40.0, 100.0, 98.0, 2.0, 5.0, 36.0, 68.0, 80.0, 65.0, 9.0, 13.0, 4.0, 64.0, 57.0, 0.0, 11.0, 45.0, 9.0, 8.0, 532.0, 406.0, 127.0, 111.0, 12.0, 4.0, 152.0, 200.0, 4.0, 6.0, 9.0, 5.0, 169.0, 13.0, 15.0, 0.0, 73.0, 121.0, 166.0, 143.0, 9.0, 7.0, 2.0, 167.0, 14.0, 2.0, 3.0, 3.0, 7.0, 280.0, 162.0, 0.0, 0.0, 42.0, 36.0, 7.0, 5.0, 0.0, 5.0, 184.0, 59.0, 2.0, 7.0, 17.0, 30.0, 110.0, 1.0, 7.0, 14.0, 14.0, 8.0, 6.0, 407.0, 200.0, 6.0, 2.0, 185.0, 126.0, 9.0, 6.0, 4.0, 6.0, 54.0, 200.0, 200.0, 101.0, 2.0, 3.0, 15.0, 200.0, 166.0, 0.0, 43.0, 5.0, 19.0, 3.0, 13.0, 6.0, 2.0, 5.0, 2.0, 62.0, 387.0, 195.0, 49.0, 106.0, 199.0, 677.0, 60.0, 101.0, 0.0, 6.0, 11.0, 11.0, 178.0, 168.0, 71.0, 80.0, 72.0, 311.0, 1.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6089486596966944, "mean_inference_ms": 1.9148500255188707, "mean_action_processing_ms": 0.27111091611647814, "mean_env_wait_ms": 0.20552413737062472, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004062533378601074, "StateBufferConnector_ms": 0.0032984018325805664, "ViewRequirementAgentConnector_ms": 0.09342968463897705}, "num_episodes": 27, "episode_return_max": 75.1999999999997, "episode_return_min": -404.6999999999998, "episode_return_mean": -50.14900000000009, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.18502085531424, "num_env_steps_trained_throughput_per_sec": 409.18502085531424, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 45041.45, "restore_workers_time_ms": 0.016, "training_step_time_ms": 45041.394, "sample_time_ms": 1638.344, "learn_time_ms": 43385.018, "learn_throughput": 92.198, "synch_weights_time_ms": 16.107}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-13-27", "timestamp": 1723644807, "time_this_iter_s": 9.782075881958008, "time_total_s": 673.1859066486359, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187f3940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 673.1859066486359, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 30.414285714285718, "ram_util_percent": 83.72857142857144}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1109649464724556, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.940526963541747, "policy_loss": 0.0006858530385350739, "vf_loss": 5.910025748500118, "vf_explained_var": 0.05409160578061664, "kl": 0.008725118822305625, "entropy": 0.814393536565165, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.140463194850261, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.9120992037354325, "policy_loss": 0.0034160119151233365, "vf_loss": 5.880764726103929, "vf_explained_var": 0.001474739981706811, "kl": 0.008170014224688877, "entropy": 0.5903134125250357, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 73.8999999999998, "episode_reward_min": -539.5999999999999, "episode_reward_mean": -79.40700000000011, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -904.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000024, "predator_policy": 677.0}, "policy_reward_mean": {"prey_policy": -124.32850000000006, "predator_policy": 84.625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.900000000000404, -164.0000000000012, -13.099999999999572, -123.80000000000138, -25.59999999999954, -113.80000000000157, -160.80000000000058, -145.2000000000006, -78.89999999999995, -195.10000000000062, -37.699999999999584, 73.8999999999998, 30.60000000000016, -202.5000000000004, -143.00000000000045, 47.500000000000426, 27.60000000000011, 6.499999999999953, -130.50000000000028, -144.5000000000007, 19.39999999999997, -50.10000000000087, -37.699999999999626, 36.50000000000025, -122.70000000000155, -23.499999999999666, 17.900000000000002, -26.399999999999558, -10.99999999999965, -44.70000000000035, 49.800000000000466, 54.000000000000135, -22.299999999999635, 24.200000000000042, -137.2000000000006, 52.7000000000005, 35.10000000000023, -226.80000000000078, 33.4000000000002, -95.70000000000138, -136.10000000000096, 57.80000000000048, -232.30000000000075, 39.50000000000029, 44.20000000000036, -183.9000000000007, -138.20000000000078, -32.59999999999954, -1.899999999999765, 53.40000000000051, -167.90000000000074, -6.699999999999765, 28.900000000000134, -45.59999999999985, 47.70000000000043, 38.60000000000028, 41.70000000000032, 61.90000000000025, 65.10000000000043, -404.6999999999998, 55.00000000000048, 34.40000000000022, -231.0000000000008, -291.0999999999994, 51.300000000000495, -164.10000000000056, -124.60000000000076, -27.499999999999524, 20.00000000000001, 46.100000000000406, 58.10000000000052, -50.500000000000576, -360.40000000000003, -130.5000000000014, -266.10000000000014, -11.09999999999975, 48.70000000000045, 55.100000000000506, -229.30000000000047, -98.80000000000149, -134.20000000000022, -179.00000000000065, -80.30000000000089, 14.000000000000092, -6.999999999999927, -56.9999999999999, -56.09999999999991, -350.59999999999997, -216.90000000000057, -22.300000000000004, -539.5999999999999, 50.400000000000475, -484.7, -181.10000000000068, -413.2, -408.0, 52.5000000000005, -214.800000000001, -144.50000000000043, -159.30000000000052], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 11.899999999999974, -152.20000000000067, -206.80000000000052, 0.7999999999999758, -61.900000000000766, -114.40000000000077, -177.4000000000006, -15.699999999999775, -40.89999999999977, -63.10000000000077, -120.70000000000076, -464.0, 24.200000000000085, -388.6999999999997, 36.50000000000025, -400.0, 37.10000000000025, -160.60000000000065, -368.5, -148.00000000000065, 5.299999999999965, 32.60000000000023, 38.300000000000246, 20.000000000000014, -9.399999999999855, -250.89999999999986, -349.6, -362.2, 33.200000000000244, 15.799999999999963, 28.70000000000016, -0.700000000000024, 5.299999999999965, -135.4000000000004, -24.099999999999746, -51.399999999999764, -234.10000000000002, -392.8, -141.7000000000007, 5.299999999999965, 1.0999999999999874, -41.79999999999977, -49.299999999999905, -184.29999999999998, -51.40000000000005, 20.000000000000014, 9.499999999999964, -108.10000000000079, -118.60000000000076, -19.899999999999743, -148.60000000000053, -7.299999999999891, 3.1999999999999615, 20.000000000000014, -114.40000000000077, 31.700000000000212, -99.70000000000081, -26.199999999999747, -74.50000000000088, 12.79999999999997, 20.000000000000014, 20.000000000000014, -904.0, -246.70000000000041, -13.599999999999786, 11.599999999999964, -3.399999999999958, -162.70000000000064, -326.5, 20.000000000000014, 22.700000000000056, 1.0999999999999865, 20.000000000000014, -303.4000000000001, -105.40000000000067, -4.299999999999958, 22.700000000000053, -55.600000000000335, -234.10000000000045, -400.0, -45.09999999999976, 1.0999999999999865, 40.70000000000024, -320.1999999999998, -81.10000000000073, 7.699999999999974, 15.799999999999963, 24.50000000000008, 13.699999999999964, -413.20000000000005, -57.70000000000005, -276.0999999999994, -24.099999999999746, -34.59999999999976, -39.99999999999978, -53.80000000000018, 8.899999999999967, 19.40000000000001, 29.000000000000167, 9.499999999999964, -366.3999999999997, -45.69999999999981, -21.999999999999744, -15.699999999999747, 20.600000000000023, -136.30000000000052, -49.299999999999905, 19.70000000000001, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 7.699999999999967, -584.0, 38.90000000000024, 34.40000000000026, 22.700000000000056, -352.89999999999986, -362.8, 20.000000000000014, 20.000000000000014, 16.999999999999975, 7.399999999999965, -387.4, -97.6000000000008, -400.0, -192.10000000000056, 20.000000000000014, 26.300000000000118, -400.0, 20.90000000000003, -328.5999999999992, 38.000000000000256, -26.199999999999747, -49.29999999999985, -21.999999999999794, 20.000000000000014, 26.30000000000012, 0.7999999999999723, 23.00000000000006, 28.100000000000147, -4.300000000000008, -110.20000000000078, -552.9, -389.5, -78.70000000000087, -206.80000000000052, -807.2, -334.9000000000002, -192.10000000000056, 20.000000000000014, 35.30000000000025, 7.399999999999965, -3.099999999999958, 36.20000000000025, -400.0, -175.3000000000005, -101.80000000000081, -148.00000000000068, -499.4, -17.79999999999999, -400.0, 20.000000000000014, -259.30000000000035, 20.000000000000014, -364.2999999999996, 35.30000000000026, 17.899999999999988, -334.9, -400.0, 20.000000000000014, 15.799999999999963, -525.9000000000001, -400.0, -328.6, -148.0, -271.8999999999986, 22.700000000000053, -379.0, -448.09999999999997, -592.5, 21.80000000000004, 26.600000000000122, -327.1, -349.59999999999997, 15.799999999999963, -397.9, -383.2, -400.0, -400.0, -400.0, 24.50000000000009, 20.000000000000014, -141.7000000000007, -237.10000000000028, -358.00000000000006, 33.50000000000024, 26.600000000000122, -376.9], "policy_predator_policy_reward": [12.0, 2.0, 87.0, 108.0, 9.0, 39.0, 74.0, 94.0, 7.0, 24.0, 3.0, 67.0, 7.0, 272.0, 2.0, 205.0, 88.0, 196.0, 149.0, 185.0, 71.0, 34.0, 2.0, 1.0, 6.0, 14.0, 198.0, 200.0, 182.0, 4.0, 2.0, 1.0, 1.0, 22.0, 80.0, 86.0, 8.0, 147.0, 190.0, 200.0, 0.0, 13.0, 1.0, 40.0, 100.0, 98.0, 2.0, 5.0, 36.0, 68.0, 80.0, 65.0, 9.0, 13.0, 4.0, 64.0, 57.0, 0.0, 11.0, 45.0, 9.0, 8.0, 532.0, 406.0, 127.0, 111.0, 12.0, 4.0, 152.0, 200.0, 4.0, 6.0, 9.0, 5.0, 169.0, 13.0, 15.0, 0.0, 73.0, 121.0, 166.0, 143.0, 9.0, 7.0, 2.0, 167.0, 14.0, 2.0, 3.0, 3.0, 7.0, 280.0, 162.0, 0.0, 0.0, 42.0, 36.0, 7.0, 5.0, 0.0, 5.0, 184.0, 59.0, 2.0, 7.0, 17.0, 30.0, 110.0, 1.0, 7.0, 14.0, 14.0, 8.0, 6.0, 407.0, 200.0, 6.0, 2.0, 185.0, 126.0, 9.0, 6.0, 4.0, 6.0, 54.0, 200.0, 200.0, 101.0, 2.0, 3.0, 15.0, 200.0, 166.0, 0.0, 43.0, 5.0, 19.0, 3.0, 13.0, 6.0, 2.0, 5.0, 2.0, 62.0, 387.0, 195.0, 49.0, 106.0, 199.0, 677.0, 60.0, 101.0, 0.0, 6.0, 11.0, 11.0, 178.0, 168.0, 71.0, 80.0, 72.0, 311.0, 1.0, 200.0, 133.0, 26.0, 173.0, 170.0, 168.0, 142.0, 177.0, 146.0, 452.0, 2.0, 178.0, 200.0, 3.0, 200.0, 162.0, 172.0, 10.0, 491.0, 0.0, 2.0, 2.0, 190.0, 2.0, 199.0, 170.0, 200.0, 192.0, 200.0, 2.0, 6.0, 143.0, 21.0, 0.0, 180.0, 189.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6073878308283487, "mean_inference_ms": 1.9050142795875604, "mean_action_processing_ms": 0.26905756903514194, "mean_env_wait_ms": 0.20500374505465482, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038982629776000977, "StateBufferConnector_ms": 0.003302454948425293, "ViewRequirementAgentConnector_ms": 0.09394049644470215}, "num_episodes": 18, "episode_return_max": 73.8999999999998, "episode_return_min": -539.5999999999999, "episode_return_mean": -79.40700000000011, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 412.68324559325424, "num_env_steps_trained_throughput_per_sec": 412.68324559325424, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 10145.585, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10145.53, "sample_time_ms": 1597.511, "learn_time_ms": 8531.09, "learn_throughput": 468.873, "synch_weights_time_ms": 15.289}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-13-37", "timestamp": 1723644817, "time_this_iter_s": 9.697464227676392, "time_total_s": 682.8833708763123, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d3ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 682.8833708763123, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 30.178571428571434, "ram_util_percent": 83.65}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.785770496678731, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.94082248841644, "policy_loss": 0.0012234540138807563, "vf_loss": 4.903259075507916, "vf_explained_var": 0.1778279741605123, "kl": 0.01063446269954078, "entropy": 0.9342825441764145, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.292385872552004, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 4.650659831995687, "policy_loss": 0.003781309273468439, "vf_loss": 4.61995129686184, "vf_explained_var": -0.00023917927943840228, "kl": 0.007879941295671478, "entropy": 0.526885757607127, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 65.10000000000043, "episode_reward_min": -563.0, "episode_reward_mean": -86.50500000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -904.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000024, "predator_policy": 677.0}, "policy_reward_mean": {"prey_policy": -130.22250000000003, "predator_policy": 86.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-130.50000000000028, -144.5000000000007, 19.39999999999997, -50.10000000000087, -37.699999999999626, 36.50000000000025, -122.70000000000155, -23.499999999999666, 17.900000000000002, -26.399999999999558, -10.99999999999965, -44.70000000000035, 49.800000000000466, 54.000000000000135, -22.299999999999635, 24.200000000000042, -137.2000000000006, 52.7000000000005, 35.10000000000023, -226.80000000000078, 33.4000000000002, -95.70000000000138, -136.10000000000096, 57.80000000000048, -232.30000000000075, 39.50000000000029, 44.20000000000036, -183.9000000000007, -138.20000000000078, -32.59999999999954, -1.899999999999765, 53.40000000000051, -167.90000000000074, -6.699999999999765, 28.900000000000134, -45.59999999999985, 47.70000000000043, 38.60000000000028, 41.70000000000032, 61.90000000000025, 65.10000000000043, -404.6999999999998, 55.00000000000048, 34.40000000000022, -231.0000000000008, -291.0999999999994, 51.300000000000495, -164.10000000000056, -124.60000000000076, -27.499999999999524, 20.00000000000001, 46.100000000000406, 58.10000000000052, -50.500000000000576, -360.40000000000003, -130.5000000000014, -266.10000000000014, -11.09999999999975, 48.70000000000045, 55.100000000000506, -229.30000000000047, -98.80000000000149, -134.20000000000022, -179.00000000000065, -80.30000000000089, 14.000000000000092, -6.999999999999927, -56.9999999999999, -56.09999999999991, -350.59999999999997, -216.90000000000057, -22.300000000000004, -539.5999999999999, 50.400000000000475, -484.7, -181.10000000000068, -413.2, -408.0, 52.5000000000005, -214.800000000001, -144.50000000000043, -159.30000000000052, -120.60000000000085, -388.20000000000005, 46.40000000000041, 48.50000000000045, 53.500000000000526, -319.40000000000043, -377.49999999999994, -254.90000000000052, 47.70000000000043, -563.0, 39.90000000000029, 42.500000000000334, 30.800000000000196, -109.00000000000017, 57.900000000000524, 1.5999999999999872, -165.10000000000056, 47.60000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-51.399999999999764, -234.10000000000002, -392.8, -141.7000000000007, 5.299999999999965, 1.0999999999999874, -41.79999999999977, -49.299999999999905, -184.29999999999998, -51.40000000000005, 20.000000000000014, 9.499999999999964, -108.10000000000079, -118.60000000000076, -19.899999999999743, -148.60000000000053, -7.299999999999891, 3.1999999999999615, 20.000000000000014, -114.40000000000077, 31.700000000000212, -99.70000000000081, -26.199999999999747, -74.50000000000088, 12.79999999999997, 20.000000000000014, 20.000000000000014, -904.0, -246.70000000000041, -13.599999999999786, 11.599999999999964, -3.399999999999958, -162.70000000000064, -326.5, 20.000000000000014, 22.700000000000056, 1.0999999999999865, 20.000000000000014, -303.4000000000001, -105.40000000000067, -4.299999999999958, 22.700000000000053, -55.600000000000335, -234.10000000000045, -400.0, -45.09999999999976, 1.0999999999999865, 40.70000000000024, -320.1999999999998, -81.10000000000073, 7.699999999999974, 15.799999999999963, 24.50000000000008, 13.699999999999964, -413.20000000000005, -57.70000000000005, -276.0999999999994, -24.099999999999746, -34.59999999999976, -39.99999999999978, -53.80000000000018, 8.899999999999967, 19.40000000000001, 29.000000000000167, 9.499999999999964, -366.3999999999997, -45.69999999999981, -21.999999999999744, -15.699999999999747, 20.600000000000023, -136.30000000000052, -49.299999999999905, 19.70000000000001, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 7.699999999999967, -584.0, 38.90000000000024, 34.40000000000026, 22.700000000000056, -352.89999999999986, -362.8, 20.000000000000014, 20.000000000000014, 16.999999999999975, 7.399999999999965, -387.4, -97.6000000000008, -400.0, -192.10000000000056, 20.000000000000014, 26.300000000000118, -400.0, 20.90000000000003, -328.5999999999992, 38.000000000000256, -26.199999999999747, -49.29999999999985, -21.999999999999794, 20.000000000000014, 26.30000000000012, 0.7999999999999723, 23.00000000000006, 28.100000000000147, -4.300000000000008, -110.20000000000078, -552.9, -389.5, -78.70000000000087, -206.80000000000052, -807.2, -334.9000000000002, -192.10000000000056, 20.000000000000014, 35.30000000000025, 7.399999999999965, -3.099999999999958, 36.20000000000025, -400.0, -175.3000000000005, -101.80000000000081, -148.00000000000068, -499.4, -17.79999999999999, -400.0, 20.000000000000014, -259.30000000000035, 20.000000000000014, -364.2999999999996, 35.30000000000026, 17.899999999999988, -334.9, -400.0, 20.000000000000014, 15.799999999999963, -525.9000000000001, -400.0, -328.6, -148.0, -271.8999999999986, 22.700000000000053, -379.0, -448.09999999999997, -592.5, 21.80000000000004, 26.600000000000122, -327.1, -349.59999999999997, 15.799999999999963, -397.9, -383.2, -400.0, -400.0, -400.0, 24.50000000000009, 20.000000000000014, -141.7000000000007, -237.10000000000028, -358.00000000000006, 33.50000000000024, 26.600000000000122, -376.9, 17.899999999999988, -284.5000000000002, -400.0, -383.20000000000005, 16.399999999999963, 20.000000000000014, 13.699999999999964, 27.800000000000146, 33.50000000000024, 20.000000000000014, -240.40000000000043, -400.0, -377.49999999999994, -400.0, -231.40000000000035, -221.50000000000028, 25.700000000000106, 20.000000000000014, -400.0, -400.0, 8.89999999999997, 20.000000000000014, 1.0999999999999865, 25.400000000000098, -400.0, 30.800000000000196, -400.0, 20.000000000000014, 31.700000000000212, 18.19999999999999, -400.0, 23.600000000000065, -385.3, 27.20000000000013, 17.59999999999998, 20.000000000000014], "policy_predator_policy_reward": [8.0, 147.0, 190.0, 200.0, 0.0, 13.0, 1.0, 40.0, 100.0, 98.0, 2.0, 5.0, 36.0, 68.0, 80.0, 65.0, 9.0, 13.0, 4.0, 64.0, 57.0, 0.0, 11.0, 45.0, 9.0, 8.0, 532.0, 406.0, 127.0, 111.0, 12.0, 4.0, 152.0, 200.0, 4.0, 6.0, 9.0, 5.0, 169.0, 13.0, 15.0, 0.0, 73.0, 121.0, 166.0, 143.0, 9.0, 7.0, 2.0, 167.0, 14.0, 2.0, 3.0, 3.0, 7.0, 280.0, 162.0, 0.0, 0.0, 42.0, 36.0, 7.0, 5.0, 0.0, 5.0, 184.0, 59.0, 2.0, 7.0, 17.0, 30.0, 110.0, 1.0, 7.0, 14.0, 14.0, 8.0, 6.0, 407.0, 200.0, 6.0, 2.0, 185.0, 126.0, 9.0, 6.0, 4.0, 6.0, 54.0, 200.0, 200.0, 101.0, 2.0, 3.0, 15.0, 200.0, 166.0, 0.0, 43.0, 5.0, 19.0, 3.0, 13.0, 6.0, 2.0, 5.0, 2.0, 62.0, 387.0, 195.0, 49.0, 106.0, 199.0, 677.0, 60.0, 101.0, 0.0, 6.0, 11.0, 11.0, 178.0, 168.0, 71.0, 80.0, 72.0, 311.0, 1.0, 200.0, 133.0, 26.0, 173.0, 170.0, 168.0, 142.0, 177.0, 146.0, 452.0, 2.0, 178.0, 200.0, 3.0, 200.0, 162.0, 172.0, 10.0, 491.0, 0.0, 2.0, 2.0, 190.0, 2.0, 199.0, 170.0, 200.0, 192.0, 200.0, 2.0, 6.0, 143.0, 21.0, 0.0, 180.0, 189.0, 2.0, 145.0, 1.0, 195.0, 200.0, 6.0, 4.0, 3.0, 4.0, 0.0, 0.0, 200.0, 121.0, 200.0, 200.0, 37.0, 161.0, 2.0, 0.0, 200.0, 37.0, 1.0, 10.0, 7.0, 9.0, 200.0, 200.0, 71.0, 200.0, 2.0, 6.0, 178.0, 200.0, 0.0, 193.0, 5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6057647351047879, "mean_inference_ms": 1.8998020467328742, "mean_action_processing_ms": 0.2678564316961992, "mean_env_wait_ms": 0.2043169869538097, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038619041442871094, "StateBufferConnector_ms": 0.003260016441345215, "ViewRequirementAgentConnector_ms": 0.09387779235839844}, "num_episodes": 18, "episode_return_max": 65.10000000000043, "episode_return_min": -563.0, "episode_return_mean": -86.50500000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.51613289002455, "num_env_steps_trained_throughput_per_sec": 404.51613289002455, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 9869.78, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9869.726, "sample_time_ms": 1430.528, "learn_time_ms": 8423.08, "learn_throughput": 474.886, "synch_weights_time_ms": 15.08}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-13-47", "timestamp": 1723644827, "time_this_iter_s": 9.894138097763062, "time_total_s": 692.7775089740753, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187f3e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 692.7775089740753, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 28.107142857142858, "ram_util_percent": 83.61428571428573}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9464475080449746, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.598220528748931, "policy_loss": 0.0019098162153371112, "vf_loss": 5.55846474889725, "vf_explained_var": 0.14103488155773708, "kl": 0.011075174319033154, "entropy": 0.8395210720559276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7565135913078116, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 5.651646591242028, "policy_loss": 0.0030899302945250557, "vf_loss": 5.625946741255503, "vf_explained_var": 0.001470118382620433, "kl": 0.00661652678695094, "entropy": 0.4869339069440251, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 65.10000000000043, "episode_reward_min": -563.0, "episode_reward_mean": -103.58600000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -807.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000024, "predator_policy": 677.0}, "policy_reward_mean": {"prey_policy": -140.94299999999998, "predator_policy": 89.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.10000000000023, -226.80000000000078, 33.4000000000002, -95.70000000000138, -136.10000000000096, 57.80000000000048, -232.30000000000075, 39.50000000000029, 44.20000000000036, -183.9000000000007, -138.20000000000078, -32.59999999999954, -1.899999999999765, 53.40000000000051, -167.90000000000074, -6.699999999999765, 28.900000000000134, -45.59999999999985, 47.70000000000043, 38.60000000000028, 41.70000000000032, 61.90000000000025, 65.10000000000043, -404.6999999999998, 55.00000000000048, 34.40000000000022, -231.0000000000008, -291.0999999999994, 51.300000000000495, -164.10000000000056, -124.60000000000076, -27.499999999999524, 20.00000000000001, 46.100000000000406, 58.10000000000052, -50.500000000000576, -360.40000000000003, -130.5000000000014, -266.10000000000014, -11.09999999999975, 48.70000000000045, 55.100000000000506, -229.30000000000047, -98.80000000000149, -134.20000000000022, -179.00000000000065, -80.30000000000089, 14.000000000000092, -6.999999999999927, -56.9999999999999, -56.09999999999991, -350.59999999999997, -216.90000000000057, -22.300000000000004, -539.5999999999999, 50.400000000000475, -484.7, -181.10000000000068, -413.2, -408.0, 52.5000000000005, -214.800000000001, -144.50000000000043, -159.30000000000052, -120.60000000000085, -388.20000000000005, 46.40000000000041, 48.50000000000045, 53.500000000000526, -319.40000000000043, -377.49999999999994, -254.90000000000052, 47.70000000000043, -563.0, 39.90000000000029, 42.500000000000334, 30.800000000000196, -109.00000000000017, 57.900000000000524, 1.5999999999999872, -165.10000000000056, 47.60000000000043, -194.30000000000078, 50.10000000000048, 47.10000000000042, -243.30000000000007, 25.800000000000068, 55.20000000000051, -397.3, 50.10000000000047, -400.0, 21.80000000000004, 40.3000000000003, -354.80000000000007, -358.20000000000016, -49.39999999999985, -221.70000000000073, -188.10000000000073, 39.30000000000029, -126.80000000000057], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, 20.000000000000014, -303.4000000000001, -105.40000000000067, -4.299999999999958, 22.700000000000053, -55.600000000000335, -234.10000000000045, -400.0, -45.09999999999976, 1.0999999999999865, 40.70000000000024, -320.1999999999998, -81.10000000000073, 7.699999999999974, 15.799999999999963, 24.50000000000008, 13.699999999999964, -413.20000000000005, -57.70000000000005, -276.0999999999994, -24.099999999999746, -34.59999999999976, -39.99999999999978, -53.80000000000018, 8.899999999999967, 19.40000000000001, 29.000000000000167, 9.499999999999964, -366.3999999999997, -45.69999999999981, -21.999999999999744, -15.699999999999747, 20.600000000000023, -136.30000000000052, -49.299999999999905, 19.70000000000001, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, 7.699999999999967, -584.0, 38.90000000000024, 34.40000000000026, 22.700000000000056, -352.89999999999986, -362.8, 20.000000000000014, 20.000000000000014, 16.999999999999975, 7.399999999999965, -387.4, -97.6000000000008, -400.0, -192.10000000000056, 20.000000000000014, 26.300000000000118, -400.0, 20.90000000000003, -328.5999999999992, 38.000000000000256, -26.199999999999747, -49.29999999999985, -21.999999999999794, 20.000000000000014, 26.30000000000012, 0.7999999999999723, 23.00000000000006, 28.100000000000147, -4.300000000000008, -110.20000000000078, -552.9, -389.5, -78.70000000000087, -206.80000000000052, -807.2, -334.9000000000002, -192.10000000000056, 20.000000000000014, 35.30000000000025, 7.399999999999965, -3.099999999999958, 36.20000000000025, -400.0, -175.3000000000005, -101.80000000000081, -148.00000000000068, -499.4, -17.79999999999999, -400.0, 20.000000000000014, -259.30000000000035, 20.000000000000014, -364.2999999999996, 35.30000000000026, 17.899999999999988, -334.9, -400.0, 20.000000000000014, 15.799999999999963, -525.9000000000001, -400.0, -328.6, -148.0, -271.8999999999986, 22.700000000000053, -379.0, -448.09999999999997, -592.5, 21.80000000000004, 26.600000000000122, -327.1, -349.59999999999997, 15.799999999999963, -397.9, -383.2, -400.0, -400.0, -400.0, 24.50000000000009, 20.000000000000014, -141.7000000000007, -237.10000000000028, -358.00000000000006, 33.50000000000024, 26.600000000000122, -376.9, 17.899999999999988, -284.5000000000002, -400.0, -383.20000000000005, 16.399999999999963, 20.000000000000014, 13.699999999999964, 27.800000000000146, 33.50000000000024, 20.000000000000014, -240.40000000000043, -400.0, -377.49999999999994, -400.0, -231.40000000000035, -221.50000000000028, 25.700000000000106, 20.000000000000014, -400.0, -400.0, 8.89999999999997, 20.000000000000014, 1.0999999999999865, 25.400000000000098, -400.0, 30.800000000000196, -400.0, 20.000000000000014, 31.700000000000212, 18.19999999999999, -400.0, 23.600000000000065, -385.3, 27.20000000000013, 17.59999999999998, 20.000000000000014, -395.8, -11.499999999999819, 7.399999999999965, 34.70000000000025, 13.699999999999964, 28.400000000000155, -137.49999999999997, -278.79999999999995, 9.499999999999964, 5.299999999999965, 19.1, 28.100000000000147, -328.3, -400.0, 7.399999999999965, 31.700000000000212, -400.0, -400.0, 21.80000000000004, -400.0, 20.000000000000014, 8.299999999999972, -353.80000000000007, -400.0, -387.4, -332.8000000000002, 20.000000000000014, -387.39999999999986, -36.699999999999754, -400.0, -0.10000000000003478, -400.0, 21.20000000000003, 1.0999999999999865, -332.80000000000007, 38.000000000000256], "policy_predator_policy_reward": [9.0, 5.0, 169.0, 13.0, 15.0, 0.0, 73.0, 121.0, 166.0, 143.0, 9.0, 7.0, 2.0, 167.0, 14.0, 2.0, 3.0, 3.0, 7.0, 280.0, 162.0, 0.0, 0.0, 42.0, 36.0, 7.0, 5.0, 0.0, 5.0, 184.0, 59.0, 2.0, 7.0, 17.0, 30.0, 110.0, 1.0, 7.0, 14.0, 14.0, 8.0, 6.0, 407.0, 200.0, 6.0, 2.0, 185.0, 126.0, 9.0, 6.0, 4.0, 6.0, 54.0, 200.0, 200.0, 101.0, 2.0, 3.0, 15.0, 200.0, 166.0, 0.0, 43.0, 5.0, 19.0, 3.0, 13.0, 6.0, 2.0, 5.0, 2.0, 62.0, 387.0, 195.0, 49.0, 106.0, 199.0, 677.0, 60.0, 101.0, 0.0, 6.0, 11.0, 11.0, 178.0, 168.0, 71.0, 80.0, 72.0, 311.0, 1.0, 200.0, 133.0, 26.0, 173.0, 170.0, 168.0, 142.0, 177.0, 146.0, 452.0, 2.0, 178.0, 200.0, 3.0, 200.0, 162.0, 172.0, 10.0, 491.0, 0.0, 2.0, 2.0, 190.0, 2.0, 199.0, 170.0, 200.0, 192.0, 200.0, 2.0, 6.0, 143.0, 21.0, 0.0, 180.0, 189.0, 2.0, 145.0, 1.0, 195.0, 200.0, 6.0, 4.0, 3.0, 4.0, 0.0, 0.0, 200.0, 121.0, 200.0, 200.0, 37.0, 161.0, 2.0, 0.0, 200.0, 37.0, 1.0, 10.0, 7.0, 9.0, 200.0, 200.0, 71.0, 200.0, 2.0, 6.0, 178.0, 200.0, 0.0, 193.0, 5.0, 5.0, 198.0, 15.0, 2.0, 6.0, 2.0, 3.0, 3.0, 170.0, 4.0, 7.0, 2.0, 6.0, 200.0, 131.0, 6.0, 5.0, 200.0, 200.0, 200.0, 200.0, 0.0, 12.0, 200.0, 199.0, 194.0, 168.0, 124.0, 194.0, 200.0, 15.0, 12.0, 200.0, 8.0, 9.0, 166.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6042206153100939, "mean_inference_ms": 1.8948566777690907, "mean_action_processing_ms": 0.2667094651792788, "mean_env_wait_ms": 0.20365940213404835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003829479217529297, "StateBufferConnector_ms": 0.003113269805908203, "ViewRequirementAgentConnector_ms": 0.09456908702850342}, "num_episodes": 18, "episode_return_max": 65.10000000000043, "episode_return_min": -563.0, "episode_return_mean": -103.58600000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.5342505558678, "num_env_steps_trained_throughput_per_sec": 409.5342505558678, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 9748.568, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9748.514, "sample_time_ms": 1344.334, "learn_time_ms": 8387.792, "learn_throughput": 476.884, "synch_weights_time_ms": 15.089}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-13-57", "timestamp": 1723644837, "time_this_iter_s": 9.777093887329102, "time_total_s": 702.5546028614044, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318748790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 702.5546028614044, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 29.27142857142857, "ram_util_percent": 83.58571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.354671648885838, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 6.161858982762332, "policy_loss": 0.0014596326722610723, "vf_loss": 6.128096826492794, "vf_explained_var": 0.14618514482937162, "kl": 0.009452951934671378, "entropy": 0.7181053095709079, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.492554372178499, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 6.657274984178089, "policy_loss": 0.0016505706062412294, "vf_loss": 6.639866188594273, "vf_explained_var": 0.0010181599193149144, "kl": 0.004611461210245494, "entropy": 0.34943721157217783, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 65.10000000000043, "episode_reward_min": -563.0, "episode_reward_mean": -150.04000000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -807.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 677.0}, "policy_reward_mean": {"prey_policy": -176.785, "predator_policy": 101.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [65.10000000000043, -404.6999999999998, 55.00000000000048, 34.40000000000022, -231.0000000000008, -291.0999999999994, 51.300000000000495, -164.10000000000056, -124.60000000000076, -27.499999999999524, 20.00000000000001, 46.100000000000406, 58.10000000000052, -50.500000000000576, -360.40000000000003, -130.5000000000014, -266.10000000000014, -11.09999999999975, 48.70000000000045, 55.100000000000506, -229.30000000000047, -98.80000000000149, -134.20000000000022, -179.00000000000065, -80.30000000000089, 14.000000000000092, -6.999999999999927, -56.9999999999999, -56.09999999999991, -350.59999999999997, -216.90000000000057, -22.300000000000004, -539.5999999999999, 50.400000000000475, -484.7, -181.10000000000068, -413.2, -408.0, 52.5000000000005, -214.800000000001, -144.50000000000043, -159.30000000000052, -120.60000000000085, -388.20000000000005, 46.40000000000041, 48.50000000000045, 53.500000000000526, -319.40000000000043, -377.49999999999994, -254.90000000000052, 47.70000000000043, -563.0, 39.90000000000029, 42.500000000000334, 30.800000000000196, -109.00000000000017, 57.900000000000524, 1.5999999999999872, -165.10000000000056, 47.60000000000043, -194.30000000000078, 50.10000000000048, 47.10000000000042, -243.30000000000007, 25.800000000000068, 55.20000000000051, -397.3, 50.10000000000047, -400.0, 21.80000000000004, 40.3000000000003, -354.80000000000007, -358.20000000000016, -49.39999999999985, -221.70000000000073, -188.10000000000073, 39.30000000000029, -126.80000000000057, -549.3, -400.0, -186.6000000000007, 31.900000000000183, -165.20000000000059, -11.799999999999775, -304.7999999999991, 58.10000000000052, -474.0, -64.90000000000063, -169.20000000000059, -155.80000000000052, -400.0, -273.4999999999999, 11.200000000000049, -184.4000000000007, -454.80000000000007, -376.89999999999975, -400.7, -489.0, -389.6000000000005, -81.60000000000056], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [34.40000000000026, 22.700000000000056, -352.89999999999986, -362.8, 20.000000000000014, 20.000000000000014, 16.999999999999975, 7.399999999999965, -387.4, -97.6000000000008, -400.0, -192.10000000000056, 20.000000000000014, 26.300000000000118, -400.0, 20.90000000000003, -328.5999999999992, 38.000000000000256, -26.199999999999747, -49.29999999999985, -21.999999999999794, 20.000000000000014, 26.30000000000012, 0.7999999999999723, 23.00000000000006, 28.100000000000147, -4.300000000000008, -110.20000000000078, -552.9, -389.5, -78.70000000000087, -206.80000000000052, -807.2, -334.9000000000002, -192.10000000000056, 20.000000000000014, 35.30000000000025, 7.399999999999965, -3.099999999999958, 36.20000000000025, -400.0, -175.3000000000005, -101.80000000000081, -148.00000000000068, -499.4, -17.79999999999999, -400.0, 20.000000000000014, -259.30000000000035, 20.000000000000014, -364.2999999999996, 35.30000000000026, 17.899999999999988, -334.9, -400.0, 20.000000000000014, 15.799999999999963, -525.9000000000001, -400.0, -328.6, -148.0, -271.8999999999986, 22.700000000000053, -379.0, -448.09999999999997, -592.5, 21.80000000000004, 26.600000000000122, -327.1, -349.59999999999997, 15.799999999999963, -397.9, -383.2, -400.0, -400.0, -400.0, 24.50000000000009, 20.000000000000014, -141.7000000000007, -237.10000000000028, -358.00000000000006, 33.50000000000024, 26.600000000000122, -376.9, 17.899999999999988, -284.5000000000002, -400.0, -383.20000000000005, 16.399999999999963, 20.000000000000014, 13.699999999999964, 27.800000000000146, 33.50000000000024, 20.000000000000014, -240.40000000000043, -400.0, -377.49999999999994, -400.0, -231.40000000000035, -221.50000000000028, 25.700000000000106, 20.000000000000014, -400.0, -400.0, 8.89999999999997, 20.000000000000014, 1.0999999999999865, 25.400000000000098, -400.0, 30.800000000000196, -400.0, 20.000000000000014, 31.700000000000212, 18.19999999999999, -400.0, 23.600000000000065, -385.3, 27.20000000000013, 17.59999999999998, 20.000000000000014, -395.8, -11.499999999999819, 7.399999999999965, 34.70000000000025, 13.699999999999964, 28.400000000000155, -137.49999999999997, -278.79999999999995, 9.499999999999964, 5.299999999999965, 19.1, 28.100000000000147, -328.3, -400.0, 7.399999999999965, 31.700000000000212, -400.0, -400.0, 21.80000000000004, -400.0, 20.000000000000014, 8.299999999999972, -353.80000000000007, -400.0, -387.4, -332.8000000000002, 20.000000000000014, -387.39999999999986, -36.699999999999754, -400.0, -0.10000000000003478, -400.0, 21.20000000000003, 1.0999999999999865, -332.80000000000007, 38.000000000000256, -381.1, -362.2, -400.0, -400.0, -400.0, 7.399999999999965, -3.099999999999958, 20.000000000000014, -391.6, 28.400000000000155, -5.199999999999934, -55.599999999999866, -290.7999999999991, -400.0, 16.099999999999962, 29.000000000000163, -400.0, -400.0, -386.8, -3.099999999999979, 15.799999999999963, -376.0, 20.000000000000014, -353.8, -400.0, -400.0, -400.0, -158.50000000000009, 20.000000000000014, -38.799999999999756, 11.599999999999964, -400.0, -400.0, -332.80000000000007, -376.89999999999975, -400.0, -400.0, -384.7, -400.0, -400.0, -253.90000000000015, -303.7000000000002, 7.399999999999965, -202.0000000000005], "policy_predator_policy_reward": [6.0, 2.0, 185.0, 126.0, 9.0, 6.0, 4.0, 6.0, 54.0, 200.0, 200.0, 101.0, 2.0, 3.0, 15.0, 200.0, 166.0, 0.0, 43.0, 5.0, 19.0, 3.0, 13.0, 6.0, 2.0, 5.0, 2.0, 62.0, 387.0, 195.0, 49.0, 106.0, 199.0, 677.0, 60.0, 101.0, 0.0, 6.0, 11.0, 11.0, 178.0, 168.0, 71.0, 80.0, 72.0, 311.0, 1.0, 200.0, 133.0, 26.0, 173.0, 170.0, 168.0, 142.0, 177.0, 146.0, 452.0, 2.0, 178.0, 200.0, 3.0, 200.0, 162.0, 172.0, 10.0, 491.0, 0.0, 2.0, 2.0, 190.0, 2.0, 199.0, 170.0, 200.0, 192.0, 200.0, 2.0, 6.0, 143.0, 21.0, 0.0, 180.0, 189.0, 2.0, 145.0, 1.0, 195.0, 200.0, 6.0, 4.0, 3.0, 4.0, 0.0, 0.0, 200.0, 121.0, 200.0, 200.0, 37.0, 161.0, 2.0, 0.0, 200.0, 37.0, 1.0, 10.0, 7.0, 9.0, 200.0, 200.0, 71.0, 200.0, 2.0, 6.0, 178.0, 200.0, 0.0, 193.0, 5.0, 5.0, 198.0, 15.0, 2.0, 6.0, 2.0, 3.0, 3.0, 170.0, 4.0, 7.0, 2.0, 6.0, 200.0, 131.0, 6.0, 5.0, 200.0, 200.0, 200.0, 200.0, 0.0, 12.0, 200.0, 199.0, 194.0, 168.0, 124.0, 194.0, 200.0, 15.0, 12.0, 200.0, 8.0, 9.0, 166.0, 2.0, 3.0, 191.0, 200.0, 200.0, 200.0, 6.0, 4.0, 11.0, 196.0, 2.0, 47.0, 2.0, 186.0, 200.0, 7.0, 6.0, 200.0, 126.0, 130.0, 195.0, 189.0, 2.0, 6.0, 172.0, 200.0, 200.0, 200.0, 85.0, 2.0, 28.0, 200.0, 4.0, 78.0, 200.0, 200.0, 200.0, 184.0, 200.0, 111.0, 200.0, 4.0, 164.0, 6.0, 107.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.602312776418623, "mean_inference_ms": 1.8915665394424541, "mean_action_processing_ms": 0.26480225584371503, "mean_env_wait_ms": 0.20298743653431273, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038176774978637695, "StateBufferConnector_ms": 0.003206610679626465, "ViewRequirementAgentConnector_ms": 0.0930938720703125}, "num_episodes": 22, "episode_return_max": 65.10000000000043, "episode_return_min": -563.0, "episode_return_mean": -150.04000000000008, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 412.8342275991224, "num_env_steps_trained_throughput_per_sec": 412.8342275991224, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 9727.1, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9727.058, "sample_time_ms": 1341.236, "learn_time_ms": 8369.424, "learn_throughput": 477.93, "synch_weights_time_ms": 15.03}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-14-06", "timestamp": 1723644846, "time_this_iter_s": 9.694612979888916, "time_total_s": 712.2492158412933, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 712.2492158412933, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 28.107142857142858, "ram_util_percent": 83.67857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.403568313361476, "cur_kl_coeff": 3.417187499999999, "cur_lr": 0.009999999999999998, "total_loss": 7.513228670756022, "policy_loss": 0.00034088545464097507, "vf_loss": 7.496531289216702, "vf_explained_var": 0.08321814959642118, "kl": 0.00478653807178258, "entropy": 0.5792487612792424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.460821518191585, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.009999999999999998, "total_loss": 7.696721392838413, "policy_loss": 0.008960378032039713, "vf_loss": 7.65177486989864, "vf_explained_var": 0.004022218121422662, "kl": 0.02106185390071992, "entropy": 0.41014611787266203, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 94.09999999999991, "episode_reward_min": -564.3, "episode_reward_mean": -177.73900000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1024.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 890.0}, "policy_reward_mean": {"prey_policy": -201.20449999999997, "predator_policy": 112.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-179.00000000000065, -80.30000000000089, 14.000000000000092, -6.999999999999927, -56.9999999999999, -56.09999999999991, -350.59999999999997, -216.90000000000057, -22.300000000000004, -539.5999999999999, 50.400000000000475, -484.7, -181.10000000000068, -413.2, -408.0, 52.5000000000005, -214.800000000001, -144.50000000000043, -159.30000000000052, -120.60000000000085, -388.20000000000005, 46.40000000000041, 48.50000000000045, 53.500000000000526, -319.40000000000043, -377.49999999999994, -254.90000000000052, 47.70000000000043, -563.0, 39.90000000000029, 42.500000000000334, 30.800000000000196, -109.00000000000017, 57.900000000000524, 1.5999999999999872, -165.10000000000056, 47.60000000000043, -194.30000000000078, 50.10000000000048, 47.10000000000042, -243.30000000000007, 25.800000000000068, 55.20000000000051, -397.3, 50.10000000000047, -400.0, 21.80000000000004, 40.3000000000003, -354.80000000000007, -358.20000000000016, -49.39999999999985, -221.70000000000073, -188.10000000000073, 39.30000000000029, -126.80000000000057, -549.3, -400.0, -186.6000000000007, 31.900000000000183, -165.20000000000059, -11.799999999999775, -304.7999999999991, 58.10000000000052, -474.0, -64.90000000000063, -169.20000000000059, -155.80000000000052, -400.0, -273.4999999999999, 11.200000000000049, -184.4000000000007, -454.80000000000007, -376.89999999999975, -400.7, -489.0, -389.6000000000005, -81.60000000000056, -225.5000000000005, 94.09999999999991, -308.4, -461.59999999999997, -160.89999999999998, -184.60000000000102, 52.000000000000504, -334.4999999999999, -154.70000000000093, -92.70000000000073, -136.90000000000015, -557.8, 55.400000000000496, -44.99999999999965, -410.9, -186.6000000000007, -564.3, -48.69999999999975, -22.599999999999767, -263.50000000000017, -183.3000000000007, -325.5999999999999, -393.40000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 20.000000000000014, -259.30000000000035, 20.000000000000014, -364.2999999999996, 35.30000000000026, 17.899999999999988, -334.9, -400.0, 20.000000000000014, 15.799999999999963, -525.9000000000001, -400.0, -328.6, -148.0, -271.8999999999986, 22.700000000000053, -379.0, -448.09999999999997, -592.5, 21.80000000000004, 26.600000000000122, -327.1, -349.59999999999997, 15.799999999999963, -397.9, -383.2, -400.0, -400.0, -400.0, 24.50000000000009, 20.000000000000014, -141.7000000000007, -237.10000000000028, -358.00000000000006, 33.50000000000024, 26.600000000000122, -376.9, 17.899999999999988, -284.5000000000002, -400.0, -383.20000000000005, 16.399999999999963, 20.000000000000014, 13.699999999999964, 27.800000000000146, 33.50000000000024, 20.000000000000014, -240.40000000000043, -400.0, -377.49999999999994, -400.0, -231.40000000000035, -221.50000000000028, 25.700000000000106, 20.000000000000014, -400.0, -400.0, 8.89999999999997, 20.000000000000014, 1.0999999999999865, 25.400000000000098, -400.0, 30.800000000000196, -400.0, 20.000000000000014, 31.700000000000212, 18.19999999999999, -400.0, 23.600000000000065, -385.3, 27.20000000000013, 17.59999999999998, 20.000000000000014, -395.8, -11.499999999999819, 7.399999999999965, 34.70000000000025, 13.699999999999964, 28.400000000000155, -137.49999999999997, -278.79999999999995, 9.499999999999964, 5.299999999999965, 19.1, 28.100000000000147, -328.3, -400.0, 7.399999999999965, 31.700000000000212, -400.0, -400.0, 21.80000000000004, -400.0, 20.000000000000014, 8.299999999999972, -353.80000000000007, -400.0, -387.4, -332.8000000000002, 20.000000000000014, -387.39999999999986, -36.699999999999754, -400.0, -0.10000000000003478, -400.0, 21.20000000000003, 1.0999999999999865, -332.80000000000007, 38.000000000000256, -381.1, -362.2, -400.0, -400.0, -400.0, 7.399999999999965, -3.099999999999958, 20.000000000000014, -391.6, 28.400000000000155, -5.199999999999934, -55.599999999999866, -290.7999999999991, -400.0, 16.099999999999962, 29.000000000000163, -400.0, -400.0, -386.8, -3.099999999999979, 15.799999999999963, -376.0, 20.000000000000014, -353.8, -400.0, -400.0, -400.0, -158.50000000000009, 20.000000000000014, -38.799999999999756, 11.599999999999964, -400.0, -400.0, -332.80000000000007, -376.89999999999975, -400.0, -400.0, -384.7, -400.0, -400.0, -253.90000000000015, -303.7000000000002, 7.399999999999965, -202.0000000000005, -204.70000000000016, -371.8, 28.100000000000147, -1024.0, -277.6, -359.8, -304.6, -400.0, -96.09999999999984, -326.7999999999996, -257.1999999999988, -132.40000000000072, 23.00000000000006, 20.000000000000014, -325.89999999999986, -181.60000000000002, -0.9999999999999846, -330.70000000000016, -371.8, -82.90000000000072, -156.39999999999992, -74.50000000000013, -359.8, -400.0, 20.000000000000014, 28.40000000000016, -253.0, 20.000000000000014, -391.6, -364.3, 1.0999999999999865, -393.7, -400.0, -364.3, 32.60000000000023, -301.3000000000003, -376.9, 14.299999999999965, -158.5, -385.0, -400.0, 13.699999999999964, -286.6, -400.0, -387.40000000000003, -400.0], "policy_predator_policy_reward": [1.0, 200.0, 133.0, 26.0, 173.0, 170.0, 168.0, 142.0, 177.0, 146.0, 452.0, 2.0, 178.0, 200.0, 3.0, 200.0, 162.0, 172.0, 10.0, 491.0, 0.0, 2.0, 2.0, 190.0, 2.0, 199.0, 170.0, 200.0, 192.0, 200.0, 2.0, 6.0, 143.0, 21.0, 0.0, 180.0, 189.0, 2.0, 145.0, 1.0, 195.0, 200.0, 6.0, 4.0, 3.0, 4.0, 0.0, 0.0, 200.0, 121.0, 200.0, 200.0, 37.0, 161.0, 2.0, 0.0, 200.0, 37.0, 1.0, 10.0, 7.0, 9.0, 200.0, 200.0, 71.0, 200.0, 2.0, 6.0, 178.0, 200.0, 0.0, 193.0, 5.0, 5.0, 198.0, 15.0, 2.0, 6.0, 2.0, 3.0, 3.0, 170.0, 4.0, 7.0, 2.0, 6.0, 200.0, 131.0, 6.0, 5.0, 200.0, 200.0, 200.0, 200.0, 0.0, 12.0, 200.0, 199.0, 194.0, 168.0, 124.0, 194.0, 200.0, 15.0, 12.0, 200.0, 8.0, 9.0, 166.0, 2.0, 3.0, 191.0, 200.0, 200.0, 200.0, 6.0, 4.0, 11.0, 196.0, 2.0, 47.0, 2.0, 186.0, 200.0, 7.0, 6.0, 200.0, 126.0, 130.0, 195.0, 189.0, 2.0, 6.0, 172.0, 200.0, 200.0, 200.0, 85.0, 2.0, 28.0, 200.0, 4.0, 78.0, 200.0, 200.0, 200.0, 184.0, 200.0, 111.0, 200.0, 4.0, 164.0, 6.0, 107.0, 200.0, 151.0, 200.0, 890.0, 143.0, 186.0, 81.0, 162.0, 100.0, 162.0, 73.0, 132.0, 5.0, 4.0, 0.0, 173.0, 167.0, 10.0, 180.0, 182.0, 85.0, 9.0, 2.0, 200.0, 5.0, 2.0, 130.0, 58.0, 196.0, 149.0, 197.0, 9.0, 0.0, 200.0, 123.0, 97.0, 151.0, 189.0, 85.0, 195.0, 3.0, 200.0, 161.0, 200.0, 200.0, 194.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6003599521611773, "mean_inference_ms": 1.8842742086757827, "mean_action_processing_ms": 0.2641984227574975, "mean_env_wait_ms": 0.2023358822188391, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004102230072021484, "StateBufferConnector_ms": 0.0031366348266601562, "ViewRequirementAgentConnector_ms": 0.0931711196899414}, "num_episodes": 23, "episode_return_max": 94.09999999999991, "episode_return_min": -564.3, "episode_return_mean": -177.73900000000006, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 407.5886455627367, "num_env_steps_trained_throughput_per_sec": 407.5886455627367, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 9759.419, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9759.376, "sample_time_ms": 1350.543, "learn_time_ms": 8392.328, "learn_throughput": 476.626, "synch_weights_time_ms": 15.018}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-14-16", "timestamp": 1723644856, "time_this_iter_s": 9.864911794662476, "time_total_s": 722.1141276359558, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318743b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 722.1141276359558, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 29.757142857142856, "ram_util_percent": 83.49285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1386485341837798, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.009999999999999998, "total_loss": 8.990031065259661, "policy_loss": 0.003377940056158141, "vf_loss": 8.964664150167394, "vf_explained_var": 0.12525257354690916, "kl": 0.01286963156369309, "entropy": 0.49757964122232307, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.128808652321813, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.680122648218951, "policy_loss": 0.0042569518981195945, "vf_loss": 8.652580839237839, "vf_explained_var": 0.004471810942604428, "kl": 0.009085390653325634, "entropy": 0.4022999739047711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 94.09999999999991, "episode_reward_min": -564.3, "episode_reward_mean": -199.1510000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1024.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 890.0}, "policy_reward_mean": {"prey_policy": -217.0005, "predator_policy": 117.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-159.30000000000052, -120.60000000000085, -388.20000000000005, 46.40000000000041, 48.50000000000045, 53.500000000000526, -319.40000000000043, -377.49999999999994, -254.90000000000052, 47.70000000000043, -563.0, 39.90000000000029, 42.500000000000334, 30.800000000000196, -109.00000000000017, 57.900000000000524, 1.5999999999999872, -165.10000000000056, 47.60000000000043, -194.30000000000078, 50.10000000000048, 47.10000000000042, -243.30000000000007, 25.800000000000068, 55.20000000000051, -397.3, 50.10000000000047, -400.0, 21.80000000000004, 40.3000000000003, -354.80000000000007, -358.20000000000016, -49.39999999999985, -221.70000000000073, -188.10000000000073, 39.30000000000029, -126.80000000000057, -549.3, -400.0, -186.6000000000007, 31.900000000000183, -165.20000000000059, -11.799999999999775, -304.7999999999991, 58.10000000000052, -474.0, -64.90000000000063, -169.20000000000059, -155.80000000000052, -400.0, -273.4999999999999, 11.200000000000049, -184.4000000000007, -454.80000000000007, -376.89999999999975, -400.7, -489.0, -389.6000000000005, -81.60000000000056, -225.5000000000005, 94.09999999999991, -308.4, -461.59999999999997, -160.89999999999998, -184.60000000000102, 52.000000000000504, -334.4999999999999, -154.70000000000093, -92.70000000000073, -136.90000000000015, -557.8, 55.400000000000496, -44.99999999999965, -410.9, -186.6000000000007, -564.3, -48.69999999999975, -22.599999999999767, -263.50000000000017, -183.3000000000007, -325.5999999999999, -393.40000000000003, -395.8, -182.20000000000067, -355.4999999999999, -400.0, -424.30000000000007, -419.9, -379.6, -231.19999999999993, -312.00000000000006, -384.3, -360.40000000000003, -176.2000000000006, -212.90000000000018, -297.6999999999998, -541.7, -271.8999999999986, 17.800000000000338, -51.60000000000042], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.600000000000122, -376.9, 17.899999999999988, -284.5000000000002, -400.0, -383.20000000000005, 16.399999999999963, 20.000000000000014, 13.699999999999964, 27.800000000000146, 33.50000000000024, 20.000000000000014, -240.40000000000043, -400.0, -377.49999999999994, -400.0, -231.40000000000035, -221.50000000000028, 25.700000000000106, 20.000000000000014, -400.0, -400.0, 8.89999999999997, 20.000000000000014, 1.0999999999999865, 25.400000000000098, -400.0, 30.800000000000196, -400.0, 20.000000000000014, 31.700000000000212, 18.19999999999999, -400.0, 23.600000000000065, -385.3, 27.20000000000013, 17.59999999999998, 20.000000000000014, -395.8, -11.499999999999819, 7.399999999999965, 34.70000000000025, 13.699999999999964, 28.400000000000155, -137.49999999999997, -278.79999999999995, 9.499999999999964, 5.299999999999965, 19.1, 28.100000000000147, -328.3, -400.0, 7.399999999999965, 31.700000000000212, -400.0, -400.0, 21.80000000000004, -400.0, 20.000000000000014, 8.299999999999972, -353.80000000000007, -400.0, -387.4, -332.8000000000002, 20.000000000000014, -387.39999999999986, -36.699999999999754, -400.0, -0.10000000000003478, -400.0, 21.20000000000003, 1.0999999999999865, -332.80000000000007, 38.000000000000256, -381.1, -362.2, -400.0, -400.0, -400.0, 7.399999999999965, -3.099999999999958, 20.000000000000014, -391.6, 28.400000000000155, -5.199999999999934, -55.599999999999866, -290.7999999999991, -400.0, 16.099999999999962, 29.000000000000163, -400.0, -400.0, -386.8, -3.099999999999979, 15.799999999999963, -376.0, 20.000000000000014, -353.8, -400.0, -400.0, -400.0, -158.50000000000009, 20.000000000000014, -38.799999999999756, 11.599999999999964, -400.0, -400.0, -332.80000000000007, -376.89999999999975, -400.0, -400.0, -384.7, -400.0, -400.0, -253.90000000000015, -303.7000000000002, 7.399999999999965, -202.0000000000005, -204.70000000000016, -371.8, 28.100000000000147, -1024.0, -277.6, -359.8, -304.6, -400.0, -96.09999999999984, -326.7999999999996, -257.1999999999988, -132.40000000000072, 23.00000000000006, 20.000000000000014, -325.89999999999986, -181.60000000000002, -0.9999999999999846, -330.70000000000016, -371.8, -82.90000000000072, -156.39999999999992, -74.50000000000013, -359.8, -400.0, 20.000000000000014, 28.40000000000016, -253.0, 20.000000000000014, -391.6, -364.3, 1.0999999999999865, -393.7, -400.0, -364.3, 32.60000000000023, -301.3000000000003, -376.9, 14.299999999999965, -158.5, -385.0, -400.0, 13.699999999999964, -286.6, -400.0, -387.40000000000003, -400.0, -395.8, -400.0, 15.799999999999963, -400.0, -353.19999999999993, -364.3, -400.0, -400.0, -301.3000000000001, -400.0, -397.9, -400.0, -400.0, -379.6, -365.2, -186.99999999999991, -232.00000000000003, -400.0, -340.3, -397.0, -325.9, -332.5, -360.09999999999997, -108.10000000000065, -680.0, -121.89999999999989, -400.0, -204.70000000000013, -348.7, -400.0, -400.0, -271.8999999999986, -108.10000000000004, 29.90000000000018, -55.60000000000005, -127.00000000000054], "policy_predator_policy_reward": [189.0, 2.0, 145.0, 1.0, 195.0, 200.0, 6.0, 4.0, 3.0, 4.0, 0.0, 0.0, 200.0, 121.0, 200.0, 200.0, 37.0, 161.0, 2.0, 0.0, 200.0, 37.0, 1.0, 10.0, 7.0, 9.0, 200.0, 200.0, 71.0, 200.0, 2.0, 6.0, 178.0, 200.0, 0.0, 193.0, 5.0, 5.0, 198.0, 15.0, 2.0, 6.0, 2.0, 3.0, 3.0, 170.0, 4.0, 7.0, 2.0, 6.0, 200.0, 131.0, 6.0, 5.0, 200.0, 200.0, 200.0, 200.0, 0.0, 12.0, 200.0, 199.0, 194.0, 168.0, 124.0, 194.0, 200.0, 15.0, 12.0, 200.0, 8.0, 9.0, 166.0, 2.0, 3.0, 191.0, 200.0, 200.0, 200.0, 6.0, 4.0, 11.0, 196.0, 2.0, 47.0, 2.0, 186.0, 200.0, 7.0, 6.0, 200.0, 126.0, 130.0, 195.0, 189.0, 2.0, 6.0, 172.0, 200.0, 200.0, 200.0, 85.0, 2.0, 28.0, 200.0, 4.0, 78.0, 200.0, 200.0, 200.0, 184.0, 200.0, 111.0, 200.0, 4.0, 164.0, 6.0, 107.0, 200.0, 151.0, 200.0, 890.0, 143.0, 186.0, 81.0, 162.0, 100.0, 162.0, 73.0, 132.0, 5.0, 4.0, 0.0, 173.0, 167.0, 10.0, 180.0, 182.0, 85.0, 9.0, 2.0, 200.0, 5.0, 2.0, 130.0, 58.0, 196.0, 149.0, 197.0, 9.0, 0.0, 200.0, 123.0, 97.0, 151.0, 189.0, 85.0, 195.0, 3.0, 200.0, 161.0, 200.0, 200.0, 194.0, 200.0, 200.0, 2.0, 200.0, 183.0, 179.0, 200.0, 200.0, 77.0, 200.0, 178.0, 200.0, 200.0, 200.0, 135.0, 186.0, 200.0, 120.0, 154.0, 199.0, 171.0, 127.0, 195.0, 97.0, 74.0, 515.0, 107.0, 200.0, 200.0, 7.0, 200.0, 200.0, 61.0, 35.0, 57.0, 74.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5987572105180028, "mean_inference_ms": 1.8795745556312058, "mean_action_processing_ms": 0.263172219925844, "mean_env_wait_ms": 0.20181126336042407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004176735877990723, "StateBufferConnector_ms": 0.003393888473510742, "ViewRequirementAgentConnector_ms": 0.0942997932434082}, "num_episodes": 18, "episode_return_max": 94.09999999999991, "episode_return_min": -564.3, "episode_return_mean": -199.1510000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 407.261557035777, "num_env_steps_trained_throughput_per_sec": 407.261557035777, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 9700.322, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9700.281, "sample_time_ms": 1304.914, "learn_time_ms": 8379.849, "learn_throughput": 477.336, "synch_weights_time_ms": 14.168}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-14-26", "timestamp": 1723644866, "time_this_iter_s": 9.826916933059692, "time_total_s": 731.9410445690155, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31877c3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 731.9410445690155, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 29.99285714285714, "ram_util_percent": 83.44285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1636387923722546, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.009999999999999998, "total_loss": 7.906669766057736, "policy_loss": 0.006974385554961387, "vf_loss": 7.868969129885315, "vf_explained_var": 0.02773299980415869, "kl": 0.017983349237463832, "entropy": 0.49152349263587325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.888213067072094, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 6.246619258608137, "policy_loss": 0.0044260595607319994, "vf_loss": 6.219626613647219, "vf_explained_var": 0.0010426130244340847, "kl": 0.00880513073635894, "entropy": 0.46107250649935355, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 94.09999999999991, "episode_reward_min": -564.3, "episode_reward_mean": -212.97400000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1024.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 890.0}, "policy_reward_mean": {"prey_policy": -230.15700000000004, "predator_policy": 123.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.60000000000043, -194.30000000000078, 50.10000000000048, 47.10000000000042, -243.30000000000007, 25.800000000000068, 55.20000000000051, -397.3, 50.10000000000047, -400.0, 21.80000000000004, 40.3000000000003, -354.80000000000007, -358.20000000000016, -49.39999999999985, -221.70000000000073, -188.10000000000073, 39.30000000000029, -126.80000000000057, -549.3, -400.0, -186.6000000000007, 31.900000000000183, -165.20000000000059, -11.799999999999775, -304.7999999999991, 58.10000000000052, -474.0, -64.90000000000063, -169.20000000000059, -155.80000000000052, -400.0, -273.4999999999999, 11.200000000000049, -184.4000000000007, -454.80000000000007, -376.89999999999975, -400.7, -489.0, -389.6000000000005, -81.60000000000056, -225.5000000000005, 94.09999999999991, -308.4, -461.59999999999997, -160.89999999999998, -184.60000000000102, 52.000000000000504, -334.4999999999999, -154.70000000000093, -92.70000000000073, -136.90000000000015, -557.8, 55.400000000000496, -44.99999999999965, -410.9, -186.6000000000007, -564.3, -48.69999999999975, -22.599999999999767, -263.50000000000017, -183.3000000000007, -325.5999999999999, -393.40000000000003, -395.8, -182.20000000000067, -355.4999999999999, -400.0, -424.30000000000007, -419.9, -379.6, -231.19999999999993, -312.00000000000006, -384.3, -360.40000000000003, -176.2000000000006, -212.90000000000018, -297.6999999999998, -541.7, -271.8999999999986, 17.800000000000338, -51.60000000000042, -29.799999999999883, -273.20000000000005, -259.2999999999987, -169.1000000000006, -24.00000000000003, -306.49999999999886, -332.8, -123.9000000000002, -469.0, -140.3000000000005, -139.60000000000142, 35.50000000000023, -386.29999999999876, -121.8000000000007, -237.20000000000059, -308.99999999999926, -166.40000000000046, -17.799999999999606], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.59999999999998, 20.000000000000014, -395.8, -11.499999999999819, 7.399999999999965, 34.70000000000025, 13.699999999999964, 28.400000000000155, -137.49999999999997, -278.79999999999995, 9.499999999999964, 5.299999999999965, 19.1, 28.100000000000147, -328.3, -400.0, 7.399999999999965, 31.700000000000212, -400.0, -400.0, 21.80000000000004, -400.0, 20.000000000000014, 8.299999999999972, -353.80000000000007, -400.0, -387.4, -332.8000000000002, 20.000000000000014, -387.39999999999986, -36.699999999999754, -400.0, -0.10000000000003478, -400.0, 21.20000000000003, 1.0999999999999865, -332.80000000000007, 38.000000000000256, -381.1, -362.2, -400.0, -400.0, -400.0, 7.399999999999965, -3.099999999999958, 20.000000000000014, -391.6, 28.400000000000155, -5.199999999999934, -55.599999999999866, -290.7999999999991, -400.0, 16.099999999999962, 29.000000000000163, -400.0, -400.0, -386.8, -3.099999999999979, 15.799999999999963, -376.0, 20.000000000000014, -353.8, -400.0, -400.0, -400.0, -158.50000000000009, 20.000000000000014, -38.799999999999756, 11.599999999999964, -400.0, -400.0, -332.80000000000007, -376.89999999999975, -400.0, -400.0, -384.7, -400.0, -400.0, -253.90000000000015, -303.7000000000002, 7.399999999999965, -202.0000000000005, -204.70000000000016, -371.8, 28.100000000000147, -1024.0, -277.6, -359.8, -304.6, -400.0, -96.09999999999984, -326.7999999999996, -257.1999999999988, -132.40000000000072, 23.00000000000006, 20.000000000000014, -325.89999999999986, -181.60000000000002, -0.9999999999999846, -330.70000000000016, -371.8, -82.90000000000072, -156.39999999999992, -74.50000000000013, -359.8, -400.0, 20.000000000000014, 28.40000000000016, -253.0, 20.000000000000014, -391.6, -364.3, 1.0999999999999865, -393.7, -400.0, -364.3, 32.60000000000023, -301.3000000000003, -376.9, 14.299999999999965, -158.5, -385.0, -400.0, 13.699999999999964, -286.6, -400.0, -387.40000000000003, -400.0, -395.8, -400.0, 15.799999999999963, -400.0, -353.19999999999993, -364.3, -400.0, -400.0, -301.3000000000001, -400.0, -397.9, -400.0, -400.0, -379.6, -365.2, -186.99999999999991, -232.00000000000003, -400.0, -340.3, -397.0, -325.9, -332.5, -360.09999999999997, -108.10000000000065, -680.0, -121.89999999999989, -400.0, -204.70000000000013, -348.7, -400.0, -400.0, -271.8999999999986, -108.10000000000004, 29.90000000000018, -55.60000000000005, -127.00000000000054, 20.30000000000002, -144.09999999999994, -400.0, -131.2000000000006, -379.0, -280.2999999999987, -400.0, 26.90000000000013, -400.0, 20.000000000000014, -400.0, -221.50000000000048, -332.8, -400.0, 15.799999999999963, -288.69999999999993, -400.0, -400.0, -318.1, -5.1999999999999265, -114.40000000000077, -131.20000000000064, 26.900000000000134, -72.40000000000089, -276.3999999999988, -397.9, -101.8000000000007, -400.0, -378.9999999999999, -194.20000000000056, -186.40000000000055, -391.6, -400.0, 14.600000000000229, -84.10000000000046, 2.2999999999999607], "policy_predator_policy_reward": [5.0, 5.0, 198.0, 15.0, 2.0, 6.0, 2.0, 3.0, 3.0, 170.0, 4.0, 7.0, 2.0, 6.0, 200.0, 131.0, 6.0, 5.0, 200.0, 200.0, 200.0, 200.0, 0.0, 12.0, 200.0, 199.0, 194.0, 168.0, 124.0, 194.0, 200.0, 15.0, 12.0, 200.0, 8.0, 9.0, 166.0, 2.0, 3.0, 191.0, 200.0, 200.0, 200.0, 6.0, 4.0, 11.0, 196.0, 2.0, 47.0, 2.0, 186.0, 200.0, 7.0, 6.0, 200.0, 126.0, 130.0, 195.0, 189.0, 2.0, 6.0, 172.0, 200.0, 200.0, 200.0, 85.0, 2.0, 28.0, 200.0, 4.0, 78.0, 200.0, 200.0, 200.0, 184.0, 200.0, 111.0, 200.0, 4.0, 164.0, 6.0, 107.0, 200.0, 151.0, 200.0, 890.0, 143.0, 186.0, 81.0, 162.0, 100.0, 162.0, 73.0, 132.0, 5.0, 4.0, 0.0, 173.0, 167.0, 10.0, 180.0, 182.0, 85.0, 9.0, 2.0, 200.0, 5.0, 2.0, 130.0, 58.0, 196.0, 149.0, 197.0, 9.0, 0.0, 200.0, 123.0, 97.0, 151.0, 189.0, 85.0, 195.0, 3.0, 200.0, 161.0, 200.0, 200.0, 194.0, 200.0, 200.0, 2.0, 200.0, 183.0, 179.0, 200.0, 200.0, 77.0, 200.0, 178.0, 200.0, 200.0, 200.0, 135.0, 186.0, 200.0, 120.0, 154.0, 199.0, 171.0, 127.0, 195.0, 97.0, 74.0, 515.0, 107.0, 200.0, 200.0, 7.0, 200.0, 200.0, 61.0, 35.0, 57.0, 74.0, 52.0, 42.0, 80.0, 178.0, 200.0, 200.0, 200.0, 4.0, 156.0, 200.0, 200.0, 115.0, 200.0, 200.0, 147.0, 2.0, 131.0, 200.0, 22.0, 161.0, 27.0, 79.0, 37.0, 44.0, 196.0, 92.0, 200.0, 180.0, 141.0, 195.0, 184.0, 85.0, 197.0, 22.0, 8.0, 56.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5972901808671505, "mean_inference_ms": 1.8751862285639425, "mean_action_processing_ms": 0.26220495593780335, "mean_env_wait_ms": 0.20132342357154015, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004242420196533203, "StateBufferConnector_ms": 0.0034259557723999023, "ViewRequirementAgentConnector_ms": 0.09390783309936523}, "num_episodes": 18, "episode_return_max": 94.09999999999991, "episode_return_min": -564.3, "episode_return_mean": -212.97400000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 407.98663001959414, "num_env_steps_trained_throughput_per_sec": 407.98663001959414, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 9720.273, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9720.234, "sample_time_ms": 1299.68, "learn_time_ms": 8404.999, "learn_throughput": 475.907, "synch_weights_time_ms": 14.221}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-14-36", "timestamp": 1723644876, "time_this_iter_s": 9.809879779815674, "time_total_s": 741.7509243488312, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 741.7509243488312, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 28.014285714285712, "ram_util_percent": 83.72142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.741672167292348, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.009999999999999998, "total_loss": 7.794101225888288, "policy_loss": 0.005306766955576167, "vf_loss": 7.768388061674814, "vf_explained_var": 0.007492253862360798, "kl": 0.011943402295996549, "entropy": 0.34056725132244603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.476164738636799, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 6.1101850756892455, "policy_loss": 0.003839185082466987, "vf_loss": 6.084887931460426, "vf_explained_var": 0.0034878184871068077, "kl": 0.008372563417697888, "entropy": 0.42448309432104153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 94.09999999999991, "episode_reward_min": -564.3, "episode_reward_mean": -213.12800000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1024.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 890.0}, "policy_reward_mean": {"prey_policy": -238.22400000000002, "predator_policy": 131.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.900000000000183, -165.20000000000059, -11.799999999999775, -304.7999999999991, 58.10000000000052, -474.0, -64.90000000000063, -169.20000000000059, -155.80000000000052, -400.0, -273.4999999999999, 11.200000000000049, -184.4000000000007, -454.80000000000007, -376.89999999999975, -400.7, -489.0, -389.6000000000005, -81.60000000000056, -225.5000000000005, 94.09999999999991, -308.4, -461.59999999999997, -160.89999999999998, -184.60000000000102, 52.000000000000504, -334.4999999999999, -154.70000000000093, -92.70000000000073, -136.90000000000015, -557.8, 55.400000000000496, -44.99999999999965, -410.9, -186.6000000000007, -564.3, -48.69999999999975, -22.599999999999767, -263.50000000000017, -183.3000000000007, -325.5999999999999, -393.40000000000003, -395.8, -182.20000000000067, -355.4999999999999, -400.0, -424.30000000000007, -419.9, -379.6, -231.19999999999993, -312.00000000000006, -384.3, -360.40000000000003, -176.2000000000006, -212.90000000000018, -297.6999999999998, -541.7, -271.8999999999986, 17.800000000000338, -51.60000000000042, -29.799999999999883, -273.20000000000005, -259.2999999999987, -169.1000000000006, -24.00000000000003, -306.49999999999886, -332.8, -123.9000000000002, -469.0, -140.3000000000005, -139.60000000000142, 35.50000000000023, -386.29999999999876, -121.8000000000007, -237.20000000000059, -308.99999999999926, -166.40000000000046, -17.799999999999606, -354.19999999999897, -12.79999999999958, 20.000000000000014, -121.0000000000003, -231.70000000000087, -365.0, -96.4, -0.8999999999997725, -90.70000000000027, 6.6999999999999975, -279.2999999999963, -132.50000000000063, 49.200000000000465, -408.0, 16.499999999999964, 18.199999999999992, -290.2999999999991, -205.5000000000009, -237.70000000000107, -189.10000000000096, -20.399999999999665, -383.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.099999999999958, 20.000000000000014, -391.6, 28.400000000000155, -5.199999999999934, -55.599999999999866, -290.7999999999991, -400.0, 16.099999999999962, 29.000000000000163, -400.0, -400.0, -386.8, -3.099999999999979, 15.799999999999963, -376.0, 20.000000000000014, -353.8, -400.0, -400.0, -400.0, -158.50000000000009, 20.000000000000014, -38.799999999999756, 11.599999999999964, -400.0, -400.0, -332.80000000000007, -376.89999999999975, -400.0, -400.0, -384.7, -400.0, -400.0, -253.90000000000015, -303.7000000000002, 7.399999999999965, -202.0000000000005, -204.70000000000016, -371.8, 28.100000000000147, -1024.0, -277.6, -359.8, -304.6, -400.0, -96.09999999999984, -326.7999999999996, -257.1999999999988, -132.40000000000072, 23.00000000000006, 20.000000000000014, -325.89999999999986, -181.60000000000002, -0.9999999999999846, -330.70000000000016, -371.8, -82.90000000000072, -156.39999999999992, -74.50000000000013, -359.8, -400.0, 20.000000000000014, 28.40000000000016, -253.0, 20.000000000000014, -391.6, -364.3, 1.0999999999999865, -393.7, -400.0, -364.3, 32.60000000000023, -301.3000000000003, -376.9, 14.299999999999965, -158.5, -385.0, -400.0, 13.699999999999964, -286.6, -400.0, -387.40000000000003, -400.0, -395.8, -400.0, 15.799999999999963, -400.0, -353.19999999999993, -364.3, -400.0, -400.0, -301.3000000000001, -400.0, -397.9, -400.0, -400.0, -379.6, -365.2, -186.99999999999991, -232.00000000000003, -400.0, -340.3, -397.0, -325.9, -332.5, -360.09999999999997, -108.10000000000065, -680.0, -121.89999999999989, -400.0, -204.70000000000013, -348.7, -400.0, -400.0, -271.8999999999986, -108.10000000000004, 29.90000000000018, -55.60000000000005, -127.00000000000054, 20.30000000000002, -144.09999999999994, -400.0, -131.2000000000006, -379.0, -280.2999999999987, -400.0, 26.90000000000013, -400.0, 20.000000000000014, -400.0, -221.50000000000048, -332.8, -400.0, 15.799999999999963, -288.69999999999993, -400.0, -400.0, -318.1, -5.1999999999999265, -114.40000000000077, -131.20000000000064, 26.900000000000134, -72.40000000000089, -276.3999999999988, -397.9, -101.8000000000007, -400.0, -378.9999999999999, -194.20000000000056, -186.40000000000055, -391.6, -400.0, 14.600000000000229, -84.10000000000046, 2.2999999999999607, -400.0, -278.19999999999897, 15.799999999999963, -76.60000000000088, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -183.70000000000059, -295.0000000000003, -400.0, -358.0, -9.399999999999855, -400.0, 37.10000000000026, -400.0, -19.900000000000013, -332.7999999999993, -72.4000000000006, 25.100000000000094, -161.20000000000053, -249.1000000000004, -400.0, 24.50000000000008, 20.000000000000014, 9.199999999999973, -400.0, -400.0, -400.0, 33.50000000000024, 36.20000000000026, -400.0, -400.0, -268.2999999999991, -243.40000000000038, -156.10000000000056, -299.1999999999989, -95.50000000000081, -150.10000000000068, -294.99999999999886, 38.00000000000025, -177.4000000000006, -362.2, -374.8], "policy_predator_policy_reward": [4.0, 11.0, 196.0, 2.0, 47.0, 2.0, 186.0, 200.0, 7.0, 6.0, 200.0, 126.0, 130.0, 195.0, 189.0, 2.0, 6.0, 172.0, 200.0, 200.0, 200.0, 85.0, 2.0, 28.0, 200.0, 4.0, 78.0, 200.0, 200.0, 200.0, 184.0, 200.0, 111.0, 200.0, 4.0, 164.0, 6.0, 107.0, 200.0, 151.0, 200.0, 890.0, 143.0, 186.0, 81.0, 162.0, 100.0, 162.0, 73.0, 132.0, 5.0, 4.0, 0.0, 173.0, 167.0, 10.0, 180.0, 182.0, 85.0, 9.0, 2.0, 200.0, 5.0, 2.0, 130.0, 58.0, 196.0, 149.0, 197.0, 9.0, 0.0, 200.0, 123.0, 97.0, 151.0, 189.0, 85.0, 195.0, 3.0, 200.0, 161.0, 200.0, 200.0, 194.0, 200.0, 200.0, 2.0, 200.0, 183.0, 179.0, 200.0, 200.0, 77.0, 200.0, 178.0, 200.0, 200.0, 200.0, 135.0, 186.0, 200.0, 120.0, 154.0, 199.0, 171.0, 127.0, 195.0, 97.0, 74.0, 515.0, 107.0, 200.0, 200.0, 7.0, 200.0, 200.0, 61.0, 35.0, 57.0, 74.0, 52.0, 42.0, 80.0, 178.0, 200.0, 200.0, 200.0, 4.0, 156.0, 200.0, 200.0, 115.0, 200.0, 200.0, 147.0, 2.0, 131.0, 200.0, 22.0, 161.0, 27.0, 79.0, 37.0, 44.0, 196.0, 92.0, 200.0, 180.0, 141.0, 195.0, 184.0, 85.0, 197.0, 22.0, 8.0, 56.0, 184.0, 140.0, 46.0, 2.0, 200.0, 200.0, 59.0, 200.0, 130.0, 117.0, 193.0, 200.0, 200.0, 113.0, 162.0, 200.0, 94.0, 168.0, 41.0, 13.0, 2.0, 129.0, 44.0, 199.0, 8.0, 12.0, 200.0, 192.0, 200.0, 183.0, 182.0, 200.0, 178.0, 200.0, 66.0, 128.0, 152.0, 5.0, 150.0, 106.0, 25.0, 94.0, 166.0, 188.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5960818244247567, "mean_inference_ms": 1.8722289479020362, "mean_action_processing_ms": 0.2605101122064355, "mean_env_wait_ms": 0.20081507736654744, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004296422004699707, "StateBufferConnector_ms": 0.003458857536315918, "ViewRequirementAgentConnector_ms": 0.09423887729644775}, "num_episodes": 22, "episode_return_max": 94.09999999999991, "episode_return_min": -564.3, "episode_return_mean": -213.12800000000004, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 405.40469485310604, "num_env_steps_trained_throughput_per_sec": 405.40469485310604, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 9762.874, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9762.833, "sample_time_ms": 1307.549, "learn_time_ms": 8439.696, "learn_throughput": 473.951, "synch_weights_time_ms": 14.25}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-14-46", "timestamp": 1723644886, "time_this_iter_s": 9.870978116989136, "time_total_s": 751.6219024658203, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 751.6219024658203, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 28.507142857142856, "ram_util_percent": 83.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.265793205900167, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.009999999999999998, "total_loss": 8.688971391556755, "policy_loss": 0.0015373084769293509, "vf_loss": 8.674775589584673, "vf_explained_var": -0.0006545506772540864, "kl": 0.007408738125600799, "entropy": 0.29157608461285395, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2354747934158516, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 6.916424950090035, "policy_loss": 0.0059293664967217455, "vf_loss": 6.876665445862624, "vf_explained_var": 0.004667278036238655, "kl": 0.013199986133497472, "entropy": 0.5723676270199201, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 55.400000000000496, "episode_reward_min": -564.3, "episode_reward_mean": -202.687, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -857.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 785.0}, "policy_reward_mean": {"prey_policy": -239.20850000000002, "predator_policy": 137.865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-160.89999999999998, -184.60000000000102, 52.000000000000504, -334.4999999999999, -154.70000000000093, -92.70000000000073, -136.90000000000015, -557.8, 55.400000000000496, -44.99999999999965, -410.9, -186.6000000000007, -564.3, -48.69999999999975, -22.599999999999767, -263.50000000000017, -183.3000000000007, -325.5999999999999, -393.40000000000003, -395.8, -182.20000000000067, -355.4999999999999, -400.0, -424.30000000000007, -419.9, -379.6, -231.19999999999993, -312.00000000000006, -384.3, -360.40000000000003, -176.2000000000006, -212.90000000000018, -297.6999999999998, -541.7, -271.8999999999986, 17.800000000000338, -51.60000000000042, -29.799999999999883, -273.20000000000005, -259.2999999999987, -169.1000000000006, -24.00000000000003, -306.49999999999886, -332.8, -123.9000000000002, -469.0, -140.3000000000005, -139.60000000000142, 35.50000000000023, -386.29999999999876, -121.8000000000007, -237.20000000000059, -308.99999999999926, -166.40000000000046, -17.799999999999606, -354.19999999999897, -12.79999999999958, 20.000000000000014, -121.0000000000003, -231.70000000000087, -365.0, -96.4, -0.8999999999997725, -90.70000000000027, 6.6999999999999975, -279.2999999999963, -132.50000000000063, 49.200000000000465, -408.0, 16.499999999999964, 18.199999999999992, -290.2999999999991, -205.5000000000009, -237.70000000000107, -189.10000000000096, -20.399999999999665, -383.0, -272.0, -366.8, 27.800000000000107, -310.89999999999867, -15.399999999999736, -82.80000000000086, -227.7999999999999, -400.0, -233.3000000000005, -352.7, -20.799999999999578, -167.90000000000114, -121.00000000000031, -400.0, 49.700000000000465, -173.2000000000006, -147.69999999999993, -142.6000000000006, 7.999999999999957, -382.1, -231.3000000000007, -52.2999999999998, -137.20000000000076], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-96.09999999999984, -326.7999999999996, -257.1999999999988, -132.40000000000072, 23.00000000000006, 20.000000000000014, -325.89999999999986, -181.60000000000002, -0.9999999999999846, -330.70000000000016, -371.8, -82.90000000000072, -156.39999999999992, -74.50000000000013, -359.8, -400.0, 20.000000000000014, 28.40000000000016, -253.0, 20.000000000000014, -391.6, -364.3, 1.0999999999999865, -393.7, -400.0, -364.3, 32.60000000000023, -301.3000000000003, -376.9, 14.299999999999965, -158.5, -385.0, -400.0, 13.699999999999964, -286.6, -400.0, -387.40000000000003, -400.0, -395.8, -400.0, 15.799999999999963, -400.0, -353.19999999999993, -364.3, -400.0, -400.0, -301.3000000000001, -400.0, -397.9, -400.0, -400.0, -379.6, -365.2, -186.99999999999991, -232.00000000000003, -400.0, -340.3, -397.0, -325.9, -332.5, -360.09999999999997, -108.10000000000065, -680.0, -121.89999999999989, -400.0, -204.70000000000013, -348.7, -400.0, -400.0, -271.8999999999986, -108.10000000000004, 29.90000000000018, -55.60000000000005, -127.00000000000054, 20.30000000000002, -144.09999999999994, -400.0, -131.2000000000006, -379.0, -280.2999999999987, -400.0, 26.90000000000013, -400.0, 20.000000000000014, -400.0, -221.50000000000048, -332.8, -400.0, 15.799999999999963, -288.69999999999993, -400.0, -400.0, -318.1, -5.1999999999999265, -114.40000000000077, -131.20000000000064, 26.900000000000134, -72.40000000000089, -276.3999999999988, -397.9, -101.8000000000007, -400.0, -378.9999999999999, -194.20000000000056, -186.40000000000055, -391.6, -400.0, 14.600000000000229, -84.10000000000046, 2.2999999999999607, -400.0, -278.19999999999897, 15.799999999999963, -76.60000000000088, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -183.70000000000059, -295.0000000000003, -400.0, -358.0, -9.399999999999855, -400.0, 37.10000000000026, -400.0, -19.900000000000013, -332.7999999999993, -72.4000000000006, 25.100000000000094, -161.20000000000053, -249.1000000000004, -400.0, 24.50000000000008, 20.000000000000014, 9.199999999999973, -400.0, -400.0, -400.0, 33.50000000000024, 36.20000000000026, -400.0, -400.0, -268.2999999999991, -243.40000000000038, -156.10000000000056, -299.1999999999989, -95.50000000000081, -150.10000000000068, -294.99999999999886, 38.00000000000025, -177.4000000000006, -362.2, -374.8, -857.0, -400.0, -360.1, -393.7, 20.000000000000014, -5.1999999999999265, -400.0, -229.90000000000046, -395.8, -13.599999999999783, -80.80000000000086, -400.0, -397.9, -187.90000000000003, -400.0, -400.0, -339.09999999999997, -215.2000000000005, -355.9, -383.8, -122.80000000000075, 32.00000000000022, -42.99999999999976, -313.9000000000002, -400.0, 20.000000000000014, -400.0, -400.0, 10.39999999999997, 29.30000000000017, -173.2000000000006, -400.0, -400.0, -147.69999999999993, -356.8, -185.80000000000058, 20.000000000000014, -400.0, -400.0, -381.1, -299.1999999999989, -186.10000000000042, -157.90000000000038, -3.3999999999999724, -5.1999999999999265, -400.0], "policy_predator_policy_reward": [100.0, 162.0, 73.0, 132.0, 5.0, 4.0, 0.0, 173.0, 167.0, 10.0, 180.0, 182.0, 85.0, 9.0, 2.0, 200.0, 5.0, 2.0, 130.0, 58.0, 196.0, 149.0, 197.0, 9.0, 0.0, 200.0, 123.0, 97.0, 151.0, 189.0, 85.0, 195.0, 3.0, 200.0, 161.0, 200.0, 200.0, 194.0, 200.0, 200.0, 2.0, 200.0, 183.0, 179.0, 200.0, 200.0, 77.0, 200.0, 178.0, 200.0, 200.0, 200.0, 135.0, 186.0, 200.0, 120.0, 154.0, 199.0, 171.0, 127.0, 195.0, 97.0, 74.0, 515.0, 107.0, 200.0, 200.0, 7.0, 200.0, 200.0, 61.0, 35.0, 57.0, 74.0, 52.0, 42.0, 80.0, 178.0, 200.0, 200.0, 200.0, 4.0, 156.0, 200.0, 200.0, 115.0, 200.0, 200.0, 147.0, 2.0, 131.0, 200.0, 22.0, 161.0, 27.0, 79.0, 37.0, 44.0, 196.0, 92.0, 200.0, 180.0, 141.0, 195.0, 184.0, 85.0, 197.0, 22.0, 8.0, 56.0, 184.0, 140.0, 46.0, 2.0, 200.0, 200.0, 59.0, 200.0, 130.0, 117.0, 193.0, 200.0, 200.0, 113.0, 162.0, 200.0, 94.0, 168.0, 41.0, 13.0, 2.0, 129.0, 44.0, 199.0, 8.0, 12.0, 200.0, 192.0, 200.0, 183.0, 182.0, 200.0, 178.0, 200.0, 66.0, 128.0, 152.0, 5.0, 150.0, 106.0, 25.0, 94.0, 166.0, 188.0, 785.0, 200.0, 187.0, 200.0, 1.0, 12.0, 200.0, 119.0, 198.0, 196.0, 200.0, 198.0, 199.0, 159.0, 200.0, 200.0, 121.0, 200.0, 194.0, 193.0, 2.0, 68.0, 57.0, 132.0, 193.0, 66.0, 200.0, 200.0, 2.0, 8.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 199.0, 149.0, 105.0, 8.0, 101.0, 200.0, 68.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5950159540669432, "mean_inference_ms": 1.870398343898715, "mean_action_processing_ms": 0.26072213542117867, "mean_env_wait_ms": 0.20023568529734193, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003799915313720703, "StateBufferConnector_ms": 0.0033911466598510742, "ViewRequirementAgentConnector_ms": 0.09346282482147217}, "num_episodes": 23, "episode_return_max": 55.400000000000496, "episode_return_min": -564.3, "episode_return_mean": -202.687, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 433.06015643603075, "num_env_steps_trained_throughput_per_sec": 433.06015643603075, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 9735.596, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9735.556, "sample_time_ms": 1292.732, "learn_time_ms": 8427.522, "learn_throughput": 474.635, "synch_weights_time_ms": 14.003}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-14-55", "timestamp": 1723644895, "time_this_iter_s": 9.242295026779175, "time_total_s": 760.8641974925995, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31877e5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 760.8641974925995, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 29.115384615384617, "ram_util_percent": 83.58461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3171574783861324, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.009999999999999998, "total_loss": 8.762930619275128, "policy_loss": 0.00339852489319152, "vf_loss": 8.739802882532594, "vf_explained_var": 0.03046157757441203, "kl": 0.011547044015329718, "entropy": 0.2890107307326857, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1111674672317884, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.036645220196436, "policy_loss": 0.0046629935884897515, "vf_loss": 7.007465983950903, "vf_explained_var": 0.003458444939719306, "kl": 0.009565852580949802, "entropy": 0.5351902914425684, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 49.700000000000465, "episode_reward_min": -541.7, "episode_reward_mean": -199.549, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -857.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 785.0}, "policy_reward_mean": {"prey_policy": -246.06950000000003, "predator_policy": 146.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-393.40000000000003, -395.8, -182.20000000000067, -355.4999999999999, -400.0, -424.30000000000007, -419.9, -379.6, -231.19999999999993, -312.00000000000006, -384.3, -360.40000000000003, -176.2000000000006, -212.90000000000018, -297.6999999999998, -541.7, -271.8999999999986, 17.800000000000338, -51.60000000000042, -29.799999999999883, -273.20000000000005, -259.2999999999987, -169.1000000000006, -24.00000000000003, -306.49999999999886, -332.8, -123.9000000000002, -469.0, -140.3000000000005, -139.60000000000142, 35.50000000000023, -386.29999999999876, -121.8000000000007, -237.20000000000059, -308.99999999999926, -166.40000000000046, -17.799999999999606, -354.19999999999897, -12.79999999999958, 20.000000000000014, -121.0000000000003, -231.70000000000087, -365.0, -96.4, -0.8999999999997725, -90.70000000000027, 6.6999999999999975, -279.2999999999963, -132.50000000000063, 49.200000000000465, -408.0, 16.499999999999964, 18.199999999999992, -290.2999999999991, -205.5000000000009, -237.70000000000107, -189.10000000000096, -20.399999999999665, -383.0, -272.0, -366.8, 27.800000000000107, -310.89999999999867, -15.399999999999736, -82.80000000000086, -227.7999999999999, -400.0, -233.3000000000005, -352.7, -20.799999999999578, -167.90000000000114, -121.00000000000031, -400.0, 49.700000000000465, -173.2000000000006, -147.69999999999993, -142.6000000000006, 7.999999999999957, -382.1, -231.3000000000007, -52.2999999999998, -137.20000000000076, 21.80000000000004, -341.2, -100.40000000000006, -447.5, -10.799999999999882, -38.09999999999958, -169.0000000000007, 11.000000000000004, -154.80000000000052, 9.699999999999974, -395.8, 7.000000000000128, -400.0, -114.10000000000068, -366.1, -109.80000000000072, -396.0, -257.3000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-387.40000000000003, -400.0, -395.8, -400.0, 15.799999999999963, -400.0, -353.19999999999993, -364.3, -400.0, -400.0, -301.3000000000001, -400.0, -397.9, -400.0, -400.0, -379.6, -365.2, -186.99999999999991, -232.00000000000003, -400.0, -340.3, -397.0, -325.9, -332.5, -360.09999999999997, -108.10000000000065, -680.0, -121.89999999999989, -400.0, -204.70000000000013, -348.7, -400.0, -400.0, -271.8999999999986, -108.10000000000004, 29.90000000000018, -55.60000000000005, -127.00000000000054, 20.30000000000002, -144.09999999999994, -400.0, -131.2000000000006, -379.0, -280.2999999999987, -400.0, 26.90000000000013, -400.0, 20.000000000000014, -400.0, -221.50000000000048, -332.8, -400.0, 15.799999999999963, -288.69999999999993, -400.0, -400.0, -318.1, -5.1999999999999265, -114.40000000000077, -131.20000000000064, 26.900000000000134, -72.40000000000089, -276.3999999999988, -397.9, -101.8000000000007, -400.0, -378.9999999999999, -194.20000000000056, -186.40000000000055, -391.6, -400.0, 14.600000000000229, -84.10000000000046, 2.2999999999999607, -400.0, -278.19999999999897, 15.799999999999963, -76.60000000000088, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -183.70000000000059, -295.0000000000003, -400.0, -358.0, -9.399999999999855, -400.0, 37.10000000000026, -400.0, -19.900000000000013, -332.7999999999993, -72.4000000000006, 25.100000000000094, -161.20000000000053, -249.1000000000004, -400.0, 24.50000000000008, 20.000000000000014, 9.199999999999973, -400.0, -400.0, -400.0, 33.50000000000024, 36.20000000000026, -400.0, -400.0, -268.2999999999991, -243.40000000000038, -156.10000000000056, -299.1999999999989, -95.50000000000081, -150.10000000000068, -294.99999999999886, 38.00000000000025, -177.4000000000006, -362.2, -374.8, -857.0, -400.0, -360.1, -393.7, 20.000000000000014, -5.1999999999999265, -400.0, -229.90000000000046, -395.8, -13.599999999999783, -80.80000000000086, -400.0, -397.9, -187.90000000000003, -400.0, -400.0, -339.09999999999997, -215.2000000000005, -355.9, -383.8, -122.80000000000075, 32.00000000000022, -42.99999999999976, -313.9000000000002, -400.0, 20.000000000000014, -400.0, -400.0, 10.39999999999997, 29.30000000000017, -173.2000000000006, -400.0, -400.0, -147.69999999999993, -356.8, -185.80000000000058, 20.000000000000014, -400.0, -400.0, -381.1, -299.1999999999989, -186.10000000000042, -157.90000000000038, -3.3999999999999724, -5.1999999999999265, -400.0, -400.0, 21.80000000000004, -400.0, -338.2, 5.299999999999965, -393.69999999999993, -397.9, -352.6, -360.09999999999997, 35.30000000000026, -122.8000000000007, 13.699999999999964, -252.9999999999999, -106.00000000000074, -400.0, 20.000000000000014, -353.8, 20.000000000000014, 20.000000000000014, -322.3, -389.8, -400.0, 13.699999999999964, -36.699999999999754, -400.0, -400.0, 17.899999999999988, -400.0, -381.1, -544.0, 3.1999999999999615, -400.0, -394.0, -400.0, -269.7999999999995, -326.5], "policy_predator_policy_reward": [200.0, 194.0, 200.0, 200.0, 2.0, 200.0, 183.0, 179.0, 200.0, 200.0, 77.0, 200.0, 178.0, 200.0, 200.0, 200.0, 135.0, 186.0, 200.0, 120.0, 154.0, 199.0, 171.0, 127.0, 195.0, 97.0, 74.0, 515.0, 107.0, 200.0, 200.0, 7.0, 200.0, 200.0, 61.0, 35.0, 57.0, 74.0, 52.0, 42.0, 80.0, 178.0, 200.0, 200.0, 200.0, 4.0, 156.0, 200.0, 200.0, 115.0, 200.0, 200.0, 147.0, 2.0, 131.0, 200.0, 22.0, 161.0, 27.0, 79.0, 37.0, 44.0, 196.0, 92.0, 200.0, 180.0, 141.0, 195.0, 184.0, 85.0, 197.0, 22.0, 8.0, 56.0, 184.0, 140.0, 46.0, 2.0, 200.0, 200.0, 59.0, 200.0, 130.0, 117.0, 193.0, 200.0, 200.0, 113.0, 162.0, 200.0, 94.0, 168.0, 41.0, 13.0, 2.0, 129.0, 44.0, 199.0, 8.0, 12.0, 200.0, 192.0, 200.0, 183.0, 182.0, 200.0, 178.0, 200.0, 66.0, 128.0, 152.0, 5.0, 150.0, 106.0, 25.0, 94.0, 166.0, 188.0, 785.0, 200.0, 187.0, 200.0, 1.0, 12.0, 200.0, 119.0, 198.0, 196.0, 200.0, 198.0, 199.0, 159.0, 200.0, 200.0, 121.0, 200.0, 194.0, 193.0, 2.0, 68.0, 57.0, 132.0, 193.0, 66.0, 200.0, 200.0, 2.0, 8.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 199.0, 149.0, 105.0, 8.0, 101.0, 200.0, 68.0, 200.0, 200.0, 200.0, 197.0, 142.0, 146.0, 152.0, 151.0, 181.0, 133.0, 68.0, 3.0, 130.0, 60.0, 200.0, 191.0, 178.0, 1.0, 151.0, 161.0, 200.0, 194.0, 3.0, 27.0, 200.0, 200.0, 200.0, 68.0, 362.0, 197.0, 200.0, 87.0, 198.0, 200.0, 157.0, 182.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5936139626317917, "mean_inference_ms": 1.861285113662246, "mean_action_processing_ms": 0.25913443349232995, "mean_env_wait_ms": 0.19988335582005162, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003755807876586914, "StateBufferConnector_ms": 0.003342270851135254, "ViewRequirementAgentConnector_ms": 0.09123027324676514}, "num_episodes": 18, "episode_return_max": 49.700000000000465, "episode_return_min": -541.7, "episode_return_mean": -199.549, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 432.82600786186833, "num_env_steps_trained_throughput_per_sec": 432.82600786186833, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 9682.202, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9682.162, "sample_time_ms": 1282.978, "learn_time_ms": 8384.396, "learn_throughput": 477.077, "synch_weights_time_ms": 13.525}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-15-04", "timestamp": 1723644904, "time_this_iter_s": 9.245779275894165, "time_total_s": 770.1099767684937, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d3160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 770.1099767684937, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 27.761538461538464, "ram_util_percent": 83.46923076923076}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4974815847973029, "cur_kl_coeff": 1.7085937499999995, "cur_lr": 0.009999999999999998, "total_loss": 9.209163761643506, "policy_loss": 0.00016238761058067362, "vf_loss": 9.20444338409989, "vf_explained_var": 0.054599048599364264, "kl": 0.002667677331117824, "entropy": 0.12558165726266682, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7631633377422102, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.632889778651888, "policy_loss": 0.003709596837747586, "vf_loss": 7.590152279788224, "vf_explained_var": 0.008436342048897314, "kl": 0.015228082019497097, "entropy": 0.6449637727131919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 49.700000000000465, "episode_reward_min": -469.0, "episode_reward_mean": -183.97099999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -857.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 40.700000000000244, "predator_policy": 785.0}, "policy_reward_mean": {"prey_policy": -242.5805, "predator_policy": 150.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-51.60000000000042, -29.799999999999883, -273.20000000000005, -259.2999999999987, -169.1000000000006, -24.00000000000003, -306.49999999999886, -332.8, -123.9000000000002, -469.0, -140.3000000000005, -139.60000000000142, 35.50000000000023, -386.29999999999876, -121.8000000000007, -237.20000000000059, -308.99999999999926, -166.40000000000046, -17.799999999999606, -354.19999999999897, -12.79999999999958, 20.000000000000014, -121.0000000000003, -231.70000000000087, -365.0, -96.4, -0.8999999999997725, -90.70000000000027, 6.6999999999999975, -279.2999999999963, -132.50000000000063, 49.200000000000465, -408.0, 16.499999999999964, 18.199999999999992, -290.2999999999991, -205.5000000000009, -237.70000000000107, -189.10000000000096, -20.399999999999665, -383.0, -272.0, -366.8, 27.800000000000107, -310.89999999999867, -15.399999999999736, -82.80000000000086, -227.7999999999999, -400.0, -233.3000000000005, -352.7, -20.799999999999578, -167.90000000000114, -121.00000000000031, -400.0, 49.700000000000465, -173.2000000000006, -147.69999999999993, -142.6000000000006, 7.999999999999957, -382.1, -231.3000000000007, -52.2999999999998, -137.20000000000076, 21.80000000000004, -341.2, -100.40000000000006, -447.5, -10.799999999999882, -38.09999999999958, -169.0000000000007, 11.000000000000004, -154.80000000000052, 9.699999999999974, -395.8, 7.000000000000128, -400.0, -114.10000000000068, -366.1, -109.80000000000072, -396.0, -257.3000000000002, -109.80000000000044, -446.4999999999991, 37.10000000000024, 26.400000000000276, -427.0, 20.000000000000018, -395.6, -296.59999999999945, -374.8, -379.1, 29.700000000000188, -367.0, -338.3999999999987, -385.6, -364.6, -7.999999999999853, -409.0, 25.400000000000098], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-55.60000000000005, -127.00000000000054, 20.30000000000002, -144.09999999999994, -400.0, -131.2000000000006, -379.0, -280.2999999999987, -400.0, 26.90000000000013, -400.0, 20.000000000000014, -400.0, -221.50000000000048, -332.8, -400.0, 15.799999999999963, -288.69999999999993, -400.0, -400.0, -318.1, -5.1999999999999265, -114.40000000000077, -131.20000000000064, 26.900000000000134, -72.40000000000089, -276.3999999999988, -397.9, -101.8000000000007, -400.0, -378.9999999999999, -194.20000000000056, -186.40000000000055, -391.6, -400.0, 14.600000000000229, -84.10000000000046, 2.2999999999999607, -400.0, -278.19999999999897, 15.799999999999963, -76.60000000000088, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -183.70000000000059, -295.0000000000003, -400.0, -358.0, -9.399999999999855, -400.0, 37.10000000000026, -400.0, -19.900000000000013, -332.7999999999993, -72.4000000000006, 25.100000000000094, -161.20000000000053, -249.1000000000004, -400.0, 24.50000000000008, 20.000000000000014, 9.199999999999973, -400.0, -400.0, -400.0, 33.50000000000024, 36.20000000000026, -400.0, -400.0, -268.2999999999991, -243.40000000000038, -156.10000000000056, -299.1999999999989, -95.50000000000081, -150.10000000000068, -294.99999999999886, 38.00000000000025, -177.4000000000006, -362.2, -374.8, -857.0, -400.0, -360.1, -393.7, 20.000000000000014, -5.1999999999999265, -400.0, -229.90000000000046, -395.8, -13.599999999999783, -80.80000000000086, -400.0, -397.9, -187.90000000000003, -400.0, -400.0, -339.09999999999997, -215.2000000000005, -355.9, -383.8, -122.80000000000075, 32.00000000000022, -42.99999999999976, -313.9000000000002, -400.0, 20.000000000000014, -400.0, -400.0, 10.39999999999997, 29.30000000000017, -173.2000000000006, -400.0, -400.0, -147.69999999999993, -356.8, -185.80000000000058, 20.000000000000014, -400.0, -400.0, -381.1, -299.1999999999989, -186.10000000000042, -157.90000000000038, -3.3999999999999724, -5.1999999999999265, -400.0, -400.0, 21.80000000000004, -400.0, -338.2, 5.299999999999965, -393.69999999999993, -397.9, -352.6, -360.09999999999997, 35.30000000000026, -122.8000000000007, 13.699999999999964, -252.9999999999999, -106.00000000000074, -400.0, 20.000000000000014, -353.8, 20.000000000000014, 20.000000000000014, -322.3, -389.8, -400.0, 13.699999999999964, -36.699999999999754, -400.0, -400.0, 17.899999999999988, -400.0, -381.1, -544.0, 3.1999999999999615, -400.0, -394.0, -400.0, -269.7999999999995, -326.5, -103.90000000000046, -800.9, -254.79999999999947, -393.7, 37.10000000000024, -400.0, -343.2999999999995, 40.700000000000244, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -391.6, -322.29999999999916, -280.3000000000003, -400.0, -374.8, -400.0, -360.1, -211.0, 13.69999999999997, -379.0, -358.0, -397.9, -284.49999999999875, -400.0, -385.6, -400.0, -334.6, -400.0, 20.000000000000014, -400.0, -400.0, 25.400000000000098, -400.0], "policy_predator_policy_reward": [57.0, 74.0, 52.0, 42.0, 80.0, 178.0, 200.0, 200.0, 200.0, 4.0, 156.0, 200.0, 200.0, 115.0, 200.0, 200.0, 147.0, 2.0, 131.0, 200.0, 22.0, 161.0, 27.0, 79.0, 37.0, 44.0, 196.0, 92.0, 200.0, 180.0, 141.0, 195.0, 184.0, 85.0, 197.0, 22.0, 8.0, 56.0, 184.0, 140.0, 46.0, 2.0, 200.0, 200.0, 59.0, 200.0, 130.0, 117.0, 193.0, 200.0, 200.0, 113.0, 162.0, 200.0, 94.0, 168.0, 41.0, 13.0, 2.0, 129.0, 44.0, 199.0, 8.0, 12.0, 200.0, 192.0, 200.0, 183.0, 182.0, 200.0, 178.0, 200.0, 66.0, 128.0, 152.0, 5.0, 150.0, 106.0, 25.0, 94.0, 166.0, 188.0, 785.0, 200.0, 187.0, 200.0, 1.0, 12.0, 200.0, 119.0, 198.0, 196.0, 200.0, 198.0, 199.0, 159.0, 200.0, 200.0, 121.0, 200.0, 194.0, 193.0, 2.0, 68.0, 57.0, 132.0, 193.0, 66.0, 200.0, 200.0, 2.0, 8.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 199.0, 149.0, 105.0, 8.0, 101.0, 200.0, 68.0, 200.0, 200.0, 200.0, 197.0, 142.0, 146.0, 152.0, 151.0, 181.0, 133.0, 68.0, 3.0, 130.0, 60.0, 200.0, 191.0, 178.0, 1.0, 151.0, 161.0, 200.0, 194.0, 3.0, 27.0, 200.0, 200.0, 200.0, 68.0, 362.0, 197.0, 200.0, 87.0, 198.0, 200.0, 157.0, 182.0, 189.0, 606.0, 197.0, 5.0, 200.0, 200.0, 173.0, 156.0, 173.0, 200.0, 200.0, 200.0, 200.0, 196.0, 163.0, 143.0, 200.0, 200.0, 200.0, 181.0, 119.0, 108.0, 180.0, 190.0, 145.0, 199.0, 200.0, 200.0, 194.0, 176.0, 200.0, 172.0, 200.0, 191.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.592391819702502, "mean_inference_ms": 1.8567626942631101, "mean_action_processing_ms": 0.2582170890885094, "mean_env_wait_ms": 0.19934394703599723, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037169456481933594, "StateBufferConnector_ms": 0.003125786781311035, "ViewRequirementAgentConnector_ms": 0.09097766876220703}, "num_episodes": 18, "episode_return_max": 49.700000000000465, "episode_return_min": -469.0, "episode_return_mean": -183.97099999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 410.0420164842736, "num_env_steps_trained_throughput_per_sec": 410.0420164842736, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 9688.446, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9688.405, "sample_time_ms": 1271.277, "learn_time_ms": 8402.249, "learn_throughput": 476.063, "synch_weights_time_ms": 13.564}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-15-14", "timestamp": 1723644914, "time_this_iter_s": 9.79827094078064, "time_total_s": 779.9082477092743, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31877cca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 779.9082477092743, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 29.285714285714285, "ram_util_percent": 83.58571428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6648302828469288, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.009999999999999998, "total_loss": 9.102593000099143, "policy_loss": 0.0034751788952028153, "vf_loss": 9.08407373226509, "vf_explained_var": 0.047329510393596834, "kl": 0.01760989824504424, "entropy": 0.15987888015116805, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.533529372962694, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.8283764632290636, "policy_loss": 0.0029112306332324074, "vf_loss": 7.801426369803292, "vf_explained_var": 0.002439205072544239, "kl": 0.009379591857806274, "entropy": 0.5690861132094469, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 72.00000000000017, "episode_reward_min": -464.0, "episode_reward_mean": -182.80700000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1488.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 40.700000000000244, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -256.9935, "predator_policy": 165.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-17.799999999999606, -354.19999999999897, -12.79999999999958, 20.000000000000014, -121.0000000000003, -231.70000000000087, -365.0, -96.4, -0.8999999999997725, -90.70000000000027, 6.6999999999999975, -279.2999999999963, -132.50000000000063, 49.200000000000465, -408.0, 16.499999999999964, 18.199999999999992, -290.2999999999991, -205.5000000000009, -237.70000000000107, -189.10000000000096, -20.399999999999665, -383.0, -272.0, -366.8, 27.800000000000107, -310.89999999999867, -15.399999999999736, -82.80000000000086, -227.7999999999999, -400.0, -233.3000000000005, -352.7, -20.799999999999578, -167.90000000000114, -121.00000000000031, -400.0, 49.700000000000465, -173.2000000000006, -147.69999999999993, -142.6000000000006, 7.999999999999957, -382.1, -231.3000000000007, -52.2999999999998, -137.20000000000076, 21.80000000000004, -341.2, -100.40000000000006, -447.5, -10.799999999999882, -38.09999999999958, -169.0000000000007, 11.000000000000004, -154.80000000000052, 9.699999999999974, -395.8, 7.000000000000128, -400.0, -114.10000000000068, -366.1, -109.80000000000072, -396.0, -257.3000000000002, -109.80000000000044, -446.4999999999991, 37.10000000000024, 26.400000000000276, -427.0, 20.000000000000018, -395.6, -296.59999999999945, -374.8, -379.1, 29.700000000000188, -367.0, -338.3999999999987, -385.6, -364.6, -7.999999999999853, -409.0, 25.400000000000098, -158.50000000000068, -84.69999999999985, 20.000000000000014, 20.000000000000014, -400.0, -10.299999999999816, 72.00000000000017, -192.10000000000076, -464.0, -376.6, 25.300000000000097, -379.7, -70.00000000000068, -42.499999999999844, -400.0, -400.0, -168.7, -378.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-84.10000000000046, 2.2999999999999607, -400.0, -278.19999999999897, 15.799999999999963, -76.60000000000088, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -183.70000000000059, -295.0000000000003, -400.0, -358.0, -9.399999999999855, -400.0, 37.10000000000026, -400.0, -19.900000000000013, -332.7999999999993, -72.4000000000006, 25.100000000000094, -161.20000000000053, -249.1000000000004, -400.0, 24.50000000000008, 20.000000000000014, 9.199999999999973, -400.0, -400.0, -400.0, 33.50000000000024, 36.20000000000026, -400.0, -400.0, -268.2999999999991, -243.40000000000038, -156.10000000000056, -299.1999999999989, -95.50000000000081, -150.10000000000068, -294.99999999999886, 38.00000000000025, -177.4000000000006, -362.2, -374.8, -857.0, -400.0, -360.1, -393.7, 20.000000000000014, -5.1999999999999265, -400.0, -229.90000000000046, -395.8, -13.599999999999783, -80.80000000000086, -400.0, -397.9, -187.90000000000003, -400.0, -400.0, -339.09999999999997, -215.2000000000005, -355.9, -383.8, -122.80000000000075, 32.00000000000022, -42.99999999999976, -313.9000000000002, -400.0, 20.000000000000014, -400.0, -400.0, 10.39999999999997, 29.30000000000017, -173.2000000000006, -400.0, -400.0, -147.69999999999993, -356.8, -185.80000000000058, 20.000000000000014, -400.0, -400.0, -381.1, -299.1999999999989, -186.10000000000042, -157.90000000000038, -3.3999999999999724, -5.1999999999999265, -400.0, -400.0, 21.80000000000004, -400.0, -338.2, 5.299999999999965, -393.69999999999993, -397.9, -352.6, -360.09999999999997, 35.30000000000026, -122.8000000000007, 13.699999999999964, -252.9999999999999, -106.00000000000074, -400.0, 20.000000000000014, -353.8, 20.000000000000014, 20.000000000000014, -322.3, -389.8, -400.0, 13.699999999999964, -36.699999999999754, -400.0, -400.0, 17.899999999999988, -400.0, -381.1, -544.0, 3.1999999999999615, -400.0, -394.0, -400.0, -269.7999999999995, -326.5, -103.90000000000046, -800.9, -254.79999999999947, -393.7, 37.10000000000024, -400.0, -343.2999999999995, 40.700000000000244, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -391.6, -322.29999999999916, -280.3000000000003, -400.0, -374.8, -400.0, -360.1, -211.0, 13.69999999999997, -379.0, -358.0, -397.9, -284.49999999999875, -400.0, -385.6, -400.0, -334.6, -400.0, 20.000000000000014, -400.0, -400.0, 25.400000000000098, -400.0, -297.399999999999, -45.10000000000003, -368.8, 1.099999999999966, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -5.1999999999999265, -372.1, -1488.0, 20.000000000000014, -374.79999999999995, -28.29999999999975, -400.0, -400.0, -400.0, -370.6, 20.000000000000014, -363.7, -372.7, -400.0, -400.0, 20.000000000000014, 24.50000000000009, -400.0, -400.0, -400.0, -400.0, -400.0, -162.70000000000002, -400.0, -389.5, -373.6], "policy_predator_policy_reward": [8.0, 56.0, 184.0, 140.0, 46.0, 2.0, 200.0, 200.0, 59.0, 200.0, 130.0, 117.0, 193.0, 200.0, 200.0, 113.0, 162.0, 200.0, 94.0, 168.0, 41.0, 13.0, 2.0, 129.0, 44.0, 199.0, 8.0, 12.0, 200.0, 192.0, 200.0, 183.0, 182.0, 200.0, 178.0, 200.0, 66.0, 128.0, 152.0, 5.0, 150.0, 106.0, 25.0, 94.0, 166.0, 188.0, 785.0, 200.0, 187.0, 200.0, 1.0, 12.0, 200.0, 119.0, 198.0, 196.0, 200.0, 198.0, 199.0, 159.0, 200.0, 200.0, 121.0, 200.0, 194.0, 193.0, 2.0, 68.0, 57.0, 132.0, 193.0, 66.0, 200.0, 200.0, 2.0, 8.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 199.0, 149.0, 105.0, 8.0, 101.0, 200.0, 68.0, 200.0, 200.0, 200.0, 197.0, 142.0, 146.0, 152.0, 151.0, 181.0, 133.0, 68.0, 3.0, 130.0, 60.0, 200.0, 191.0, 178.0, 1.0, 151.0, 161.0, 200.0, 194.0, 3.0, 27.0, 200.0, 200.0, 200.0, 68.0, 362.0, 197.0, 200.0, 87.0, 198.0, 200.0, 157.0, 182.0, 189.0, 606.0, 197.0, 5.0, 200.0, 200.0, 173.0, 156.0, 173.0, 200.0, 200.0, 200.0, 200.0, 196.0, 163.0, 143.0, 200.0, 200.0, 200.0, 181.0, 119.0, 108.0, 180.0, 190.0, 145.0, 199.0, 200.0, 200.0, 194.0, 176.0, 200.0, 172.0, 200.0, 191.0, 200.0, 200.0, 33.0, 151.0, 192.0, 91.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 179.0, 116.0, 1424.0, 188.0, 23.0, 200.0, 136.0, 194.0, 200.0, 187.0, 182.0, 193.0, 200.0, 200.0, 110.0, 164.0, 169.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 195.0, 190.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5913906945211717, "mean_inference_ms": 1.852724856315282, "mean_action_processing_ms": 0.25737039461457845, "mean_env_wait_ms": 0.19887938603432853, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003752470016479492, "StateBufferConnector_ms": 0.0031630992889404297, "ViewRequirementAgentConnector_ms": 0.09186172485351562}, "num_episodes": 18, "episode_return_max": 72.00000000000017, "episode_return_min": -464.0, "episode_return_mean": -182.80700000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 421.12608523851713, "num_env_steps_trained_throughput_per_sec": 421.12608523851713, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 9649.445, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9649.404, "sample_time_ms": 1270.639, "learn_time_ms": 8363.945, "learn_throughput": 478.243, "synch_weights_time_ms": 13.517}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-15-24", "timestamp": 1723644924, "time_this_iter_s": 9.502623081207275, "time_total_s": 789.4108707904816, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318762280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 789.4108707904816, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 28.57857142857143, "ram_util_percent": 83.57857142857144}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7671717988120186, "cur_kl_coeff": 0.8542968749999997, "cur_lr": 0.009999999999999998, "total_loss": 8.868879593490924, "policy_loss": 0.00505378681910101, "vf_loss": 8.844463647862591, "vf_explained_var": 0.016521070148579026, "kl": 0.02266443524957563, "entropy": 0.1486201653581004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9573274577736224, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.837856551579066, "policy_loss": 0.0034873177334370595, "vf_loss": 7.815804309441299, "vf_explained_var": -0.0014460281720237126, "kl": 0.007243744168649333, "entropy": 0.43539323898219556, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 72.00000000000017, "episode_reward_min": -464.0, "episode_reward_mean": -203.832, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1488.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 40.700000000000244, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -277.32599999999996, "predator_policy": 175.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-383.0, -272.0, -366.8, 27.800000000000107, -310.89999999999867, -15.399999999999736, -82.80000000000086, -227.7999999999999, -400.0, -233.3000000000005, -352.7, -20.799999999999578, -167.90000000000114, -121.00000000000031, -400.0, 49.700000000000465, -173.2000000000006, -147.69999999999993, -142.6000000000006, 7.999999999999957, -382.1, -231.3000000000007, -52.2999999999998, -137.20000000000076, 21.80000000000004, -341.2, -100.40000000000006, -447.5, -10.799999999999882, -38.09999999999958, -169.0000000000007, 11.000000000000004, -154.80000000000052, 9.699999999999974, -395.8, 7.000000000000128, -400.0, -114.10000000000068, -366.1, -109.80000000000072, -396.0, -257.3000000000002, -109.80000000000044, -446.4999999999991, 37.10000000000024, 26.400000000000276, -427.0, 20.000000000000018, -395.6, -296.59999999999945, -374.8, -379.1, 29.700000000000188, -367.0, -338.3999999999987, -385.6, -364.6, -7.999999999999853, -409.0, 25.400000000000098, -158.50000000000068, -84.69999999999985, 20.000000000000014, 20.000000000000014, -400.0, -10.299999999999816, 72.00000000000017, -192.10000000000076, -464.0, -376.6, 25.300000000000097, -379.7, -70.00000000000068, -42.499999999999844, -400.0, -400.0, -168.7, -378.1, -423.79999999999995, 15.699999999999966, -168.20000000000059, -305.5, -395.6, -320.79999999999836, -353.4, 20.000000000000014, -400.0, -6.899999999999842, -392.8, 15.699999999999966, -350.499999999999, -441.0, -142.40000000000038, -149.80000000000047, -357.0999999999993, -121.0000000000003, 20.000000000000018, -400.0, -21.99999999999998, -365.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-362.2, -374.8, -857.0, -400.0, -360.1, -393.7, 20.000000000000014, -5.1999999999999265, -400.0, -229.90000000000046, -395.8, -13.599999999999783, -80.80000000000086, -400.0, -397.9, -187.90000000000003, -400.0, -400.0, -339.09999999999997, -215.2000000000005, -355.9, -383.8, -122.80000000000075, 32.00000000000022, -42.99999999999976, -313.9000000000002, -400.0, 20.000000000000014, -400.0, -400.0, 10.39999999999997, 29.30000000000017, -173.2000000000006, -400.0, -400.0, -147.69999999999993, -356.8, -185.80000000000058, 20.000000000000014, -400.0, -400.0, -381.1, -299.1999999999989, -186.10000000000042, -157.90000000000038, -3.3999999999999724, -5.1999999999999265, -400.0, -400.0, 21.80000000000004, -400.0, -338.2, 5.299999999999965, -393.69999999999993, -397.9, -352.6, -360.09999999999997, 35.30000000000026, -122.8000000000007, 13.699999999999964, -252.9999999999999, -106.00000000000074, -400.0, 20.000000000000014, -353.8, 20.000000000000014, 20.000000000000014, -322.3, -389.8, -400.0, 13.699999999999964, -36.699999999999754, -400.0, -400.0, 17.899999999999988, -400.0, -381.1, -544.0, 3.1999999999999615, -400.0, -394.0, -400.0, -269.7999999999995, -326.5, -103.90000000000046, -800.9, -254.79999999999947, -393.7, 37.10000000000024, -400.0, -343.2999999999995, 40.700000000000244, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -391.6, -322.29999999999916, -280.3000000000003, -400.0, -374.8, -400.0, -360.1, -211.0, 13.69999999999997, -379.0, -358.0, -397.9, -284.49999999999875, -400.0, -385.6, -400.0, -334.6, -400.0, 20.000000000000014, -400.0, -400.0, 25.400000000000098, -400.0, -297.399999999999, -45.10000000000003, -368.8, 1.099999999999966, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -5.1999999999999265, -372.1, -1488.0, 20.000000000000014, -374.79999999999995, -28.29999999999975, -400.0, -400.0, -400.0, -370.6, 20.000000000000014, -363.7, -372.7, -400.0, -400.0, 20.000000000000014, 24.50000000000009, -400.0, -400.0, -400.0, -400.0, -400.0, -162.70000000000002, -400.0, -389.5, -373.6, -338.8, -400.0, -400.0, 22.700000000000053, -400.0, 18.799999999999997, -305.50000000000006, -400.0, -400.0, -391.6, -248.8000000000004, -400.0, -345.4, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -150.10000000000028, 36.200000000000244, -392.8, -400.0, 20.000000000000014, -364.3, -400.0, -305.499999999999, -400.0, -400.0, -319.60000000000014, 3.1999999999999615, 20.000000000000014, -353.8, -334.8999999999993, -383.2, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, 13.699999999999964, -384.7, -400.0, -365.8], "policy_predator_policy_reward": [166.0, 188.0, 785.0, 200.0, 187.0, 200.0, 1.0, 12.0, 200.0, 119.0, 198.0, 196.0, 200.0, 198.0, 199.0, 159.0, 200.0, 200.0, 121.0, 200.0, 194.0, 193.0, 2.0, 68.0, 57.0, 132.0, 193.0, 66.0, 200.0, 200.0, 2.0, 8.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 199.0, 149.0, 105.0, 8.0, 101.0, 200.0, 68.0, 200.0, 200.0, 200.0, 197.0, 142.0, 146.0, 152.0, 151.0, 181.0, 133.0, 68.0, 3.0, 130.0, 60.0, 200.0, 191.0, 178.0, 1.0, 151.0, 161.0, 200.0, 194.0, 3.0, 27.0, 200.0, 200.0, 200.0, 68.0, 362.0, 197.0, 200.0, 87.0, 198.0, 200.0, 157.0, 182.0, 189.0, 606.0, 197.0, 5.0, 200.0, 200.0, 173.0, 156.0, 173.0, 200.0, 200.0, 200.0, 200.0, 196.0, 163.0, 143.0, 200.0, 200.0, 200.0, 181.0, 119.0, 108.0, 180.0, 190.0, 145.0, 199.0, 200.0, 200.0, 194.0, 176.0, 200.0, 172.0, 200.0, 191.0, 200.0, 200.0, 33.0, 151.0, 192.0, 91.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 179.0, 116.0, 1424.0, 188.0, 23.0, 200.0, 136.0, 194.0, 200.0, 187.0, 182.0, 193.0, 200.0, 200.0, 110.0, 164.0, 169.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 195.0, 190.0, 115.0, 200.0, 193.0, 200.0, 13.0, 200.0, 200.0, 200.0, 196.0, 200.0, 200.0, 128.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 81.0, 26.0, 200.0, 200.0, 181.0, 179.0, 155.0, 200.0, 159.0, 200.0, 47.0, 127.0, 12.0, 172.0, 169.0, 192.0, 200.0, 59.0, 200.0, 200.0, 200.0, 200.0, 155.0, 194.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.589970108395741, "mean_inference_ms": 1.8478071941201548, "mean_action_processing_ms": 0.25642135510677144, "mean_env_wait_ms": 0.19831364176737448, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037387609481811523, "StateBufferConnector_ms": 0.003152012825012207, "ViewRequirementAgentConnector_ms": 0.09216451644897461}, "num_episodes": 22, "episode_return_max": 72.00000000000017, "episode_return_min": -464.0, "episode_return_mean": -203.832, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 423.1041605379308, "num_env_steps_trained_throughput_per_sec": 423.1041605379308, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 9618.119, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9618.079, "sample_time_ms": 1275.682, "learn_time_ms": 8327.639, "learn_throughput": 480.328, "synch_weights_time_ms": 13.741}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-15-33", "timestamp": 1723644933, "time_this_iter_s": 9.459410905838013, "time_total_s": 798.8702816963196, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d30d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 798.8702816963196, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 27.94615384615385, "ram_util_percent": 83.66923076923078}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2865232542689358, "cur_kl_coeff": 1.2814453125000003, "cur_lr": 0.009999999999999998, "total_loss": 9.377131197187635, "policy_loss": 0.0006765302800371375, "vf_loss": 9.372530481045839, "vf_explained_var": 0.017769380915101874, "kl": 0.0030623176405671295, "entropy": 0.03837467335311144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3555700982649808, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.065533903666905, "policy_loss": 0.00219425476949524, "vf_loss": 8.04462784661187, "vf_explained_var": -0.0001475240187670188, "kl": 0.0073010538899600675, "entropy": 0.3436869292978256, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 72.00000000000017, "episode_reward_min": -464.0, "episode_reward_mean": -216.94099999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1488.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.700000000000244, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -288.81549999999993, "predator_policy": 180.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-137.20000000000076, 21.80000000000004, -341.2, -100.40000000000006, -447.5, -10.799999999999882, -38.09999999999958, -169.0000000000007, 11.000000000000004, -154.80000000000052, 9.699999999999974, -395.8, 7.000000000000128, -400.0, -114.10000000000068, -366.1, -109.80000000000072, -396.0, -257.3000000000002, -109.80000000000044, -446.4999999999991, 37.10000000000024, 26.400000000000276, -427.0, 20.000000000000018, -395.6, -296.59999999999945, -374.8, -379.1, 29.700000000000188, -367.0, -338.3999999999987, -385.6, -364.6, -7.999999999999853, -409.0, 25.400000000000098, -158.50000000000068, -84.69999999999985, 20.000000000000014, 20.000000000000014, -400.0, -10.299999999999816, 72.00000000000017, -192.10000000000076, -464.0, -376.6, 25.300000000000097, -379.7, -70.00000000000068, -42.499999999999844, -400.0, -400.0, -168.7, -378.1, -423.79999999999995, 15.699999999999966, -168.20000000000059, -305.5, -395.6, -320.79999999999836, -353.4, 20.000000000000014, -400.0, -6.899999999999842, -392.8, 15.699999999999966, -350.499999999999, -441.0, -142.40000000000038, -149.80000000000047, -357.0999999999993, -121.0000000000003, 20.000000000000018, -400.0, -21.99999999999998, -365.8, -391.8, -435.0, -165.6000000000006, -400.0, -172.20000000000053, 36.90000000000026, 52.60000000000026, -400.0, -356.8, -342.7999999999988, -400.0, -400.0, -392.3, -371.6, -400.0, 20.000000000000014, -355.8, -400.0, -137.7000000000004, -363.8, 20.000000000000014, 16.999999999999975, 29.900000000000176], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.1999999999999265, -400.0, -400.0, 21.80000000000004, -400.0, -338.2, 5.299999999999965, -393.69999999999993, -397.9, -352.6, -360.09999999999997, 35.30000000000026, -122.8000000000007, 13.699999999999964, -252.9999999999999, -106.00000000000074, -400.0, 20.000000000000014, -353.8, 20.000000000000014, 20.000000000000014, -322.3, -389.8, -400.0, 13.699999999999964, -36.699999999999754, -400.0, -400.0, 17.899999999999988, -400.0, -381.1, -544.0, 3.1999999999999615, -400.0, -394.0, -400.0, -269.7999999999995, -326.5, -103.90000000000046, -800.9, -254.79999999999947, -393.7, 37.10000000000024, -400.0, -343.2999999999995, 40.700000000000244, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -391.6, -322.29999999999916, -280.3000000000003, -400.0, -374.8, -400.0, -360.1, -211.0, 13.69999999999997, -379.0, -358.0, -397.9, -284.49999999999875, -400.0, -385.6, -400.0, -334.6, -400.0, 20.000000000000014, -400.0, -400.0, 25.400000000000098, -400.0, -297.399999999999, -45.10000000000003, -368.8, 1.099999999999966, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -5.1999999999999265, -372.1, -1488.0, 20.000000000000014, -374.79999999999995, -28.29999999999975, -400.0, -400.0, -400.0, -370.6, 20.000000000000014, -363.7, -372.7, -400.0, -400.0, 20.000000000000014, 24.50000000000009, -400.0, -400.0, -400.0, -400.0, -400.0, -162.70000000000002, -400.0, -389.5, -373.6, -338.8, -400.0, -400.0, 22.700000000000053, -400.0, 18.799999999999997, -305.50000000000006, -400.0, -400.0, -391.6, -248.8000000000004, -400.0, -345.4, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -150.10000000000028, 36.200000000000244, -392.8, -400.0, 20.000000000000014, -364.3, -400.0, -305.499999999999, -400.0, -400.0, -319.60000000000014, 3.1999999999999615, 20.000000000000014, -353.8, -334.8999999999993, -383.2, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, 13.699999999999964, -384.7, -400.0, -365.8, -374.8, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -368.8, -183.40000000000052, -385.29999999999995, 36.20000000000025, 35.30000000000025, -342.7, -400.0, -400.0, -400.0, -356.8, -290.7999999999988, -400.0, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, -355.6, -400.0, -400.0, -400.0, 20.000000000000014, -332.8, -400.0, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -344.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 29.90000000000018], "policy_predator_policy_reward": [200.0, 68.0, 200.0, 200.0, 200.0, 197.0, 142.0, 146.0, 152.0, 151.0, 181.0, 133.0, 68.0, 3.0, 130.0, 60.0, 200.0, 191.0, 178.0, 1.0, 151.0, 161.0, 200.0, 194.0, 3.0, 27.0, 200.0, 200.0, 200.0, 68.0, 362.0, 197.0, 200.0, 87.0, 198.0, 200.0, 157.0, 182.0, 189.0, 606.0, 197.0, 5.0, 200.0, 200.0, 173.0, 156.0, 173.0, 200.0, 200.0, 200.0, 200.0, 196.0, 163.0, 143.0, 200.0, 200.0, 200.0, 181.0, 119.0, 108.0, 180.0, 190.0, 145.0, 199.0, 200.0, 200.0, 194.0, 176.0, 200.0, 172.0, 200.0, 191.0, 200.0, 200.0, 33.0, 151.0, 192.0, 91.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 179.0, 116.0, 1424.0, 188.0, 23.0, 200.0, 136.0, 194.0, 200.0, 187.0, 182.0, 193.0, 200.0, 200.0, 110.0, 164.0, 169.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 195.0, 190.0, 115.0, 200.0, 193.0, 200.0, 13.0, 200.0, 200.0, 200.0, 196.0, 200.0, 200.0, 128.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 81.0, 26.0, 200.0, 200.0, 181.0, 179.0, 155.0, 200.0, 159.0, 200.0, 47.0, 127.0, 12.0, 172.0, 169.0, 192.0, 200.0, 59.0, 200.0, 200.0, 200.0, 200.0, 155.0, 194.0, 200.0, 200.0, 183.0, 200.0, 200.0, 165.0, 200.0, 0.0, 200.0, 200.0, 187.0, 193.0, 193.0, 193.0, 180.0, 180.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 184.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 27.0, 200.0, 181.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5885797394278653, "mean_inference_ms": 1.8433284782840855, "mean_action_processing_ms": 0.25541347352715643, "mean_env_wait_ms": 0.1977381777838158, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004356861114501953, "StateBufferConnector_ms": 0.0031479597091674805, "ViewRequirementAgentConnector_ms": 0.09609496593475342}, "num_episodes": 23, "episode_return_max": 72.00000000000017, "episode_return_min": -464.0, "episode_return_mean": -216.94099999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 421.5862127176979, "num_env_steps_trained_throughput_per_sec": 421.5862127176979, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 9598.005, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9597.965, "sample_time_ms": 1272.885, "learn_time_ms": 8310.362, "learn_throughput": 481.327, "synch_weights_time_ms": 13.776}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-15-43", "timestamp": 1723644943, "time_this_iter_s": 9.493112802505493, "time_total_s": 808.3633944988251, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d3550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 808.3633944988251, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 28.55, "ram_util_percent": 83.59285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3270790648720567, "cur_kl_coeff": 0.6407226562500001, "cur_lr": 0.009999999999999998, "total_loss": 9.407547905836156, "policy_loss": 0.002132713187870289, "vf_loss": 9.391807712575115, "vf_explained_var": 0.03300898661689153, "kl": 0.02123770275969396, "entropy": 0.024220219163660482, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5936148188259236, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.296606464234609, "policy_loss": 0.0026422526697238917, "vf_loss": 8.275910064656898, "vf_explained_var": 0.0005180436782735997, "kl": 0.007044449091927228, "entropy": 0.39390467465239226, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 72.00000000000017, "episode_reward_min": -464.0, "episode_reward_mean": -231.90599999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1488.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.700000000000244, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -304.513, "predator_policy": 188.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-257.3000000000002, -109.80000000000044, -446.4999999999991, 37.10000000000024, 26.400000000000276, -427.0, 20.000000000000018, -395.6, -296.59999999999945, -374.8, -379.1, 29.700000000000188, -367.0, -338.3999999999987, -385.6, -364.6, -7.999999999999853, -409.0, 25.400000000000098, -158.50000000000068, -84.69999999999985, 20.000000000000014, 20.000000000000014, -400.0, -10.299999999999816, 72.00000000000017, -192.10000000000076, -464.0, -376.6, 25.300000000000097, -379.7, -70.00000000000068, -42.499999999999844, -400.0, -400.0, -168.7, -378.1, -423.79999999999995, 15.699999999999966, -168.20000000000059, -305.5, -395.6, -320.79999999999836, -353.4, 20.000000000000014, -400.0, -6.899999999999842, -392.8, 15.699999999999966, -350.499999999999, -441.0, -142.40000000000038, -149.80000000000047, -357.0999999999993, -121.0000000000003, 20.000000000000018, -400.0, -21.99999999999998, -365.8, -391.8, -435.0, -165.6000000000006, -400.0, -172.20000000000053, 36.90000000000026, 52.60000000000026, -400.0, -356.8, -342.7999999999988, -400.0, -400.0, -392.3, -371.6, -400.0, 20.000000000000014, -355.8, -400.0, -137.7000000000004, -363.8, 20.000000000000014, 16.999999999999975, 29.900000000000176, -346.7, -371.6, -380.4, -400.0, 13.599999999999959, -400.0, -381.7, -400.0, 34.400000000000254, 20.000000000000018, -393.6, -400.0, -360.5, -344.8, -106.0000000000008, -379.8, -49.700000000000024, 19.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-269.7999999999995, -326.5, -103.90000000000046, -800.9, -254.79999999999947, -393.7, 37.10000000000024, -400.0, -343.2999999999995, 40.700000000000244, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -391.6, -322.29999999999916, -280.3000000000003, -400.0, -374.8, -400.0, -360.1, -211.0, 13.69999999999997, -379.0, -358.0, -397.9, -284.49999999999875, -400.0, -385.6, -400.0, -334.6, -400.0, 20.000000000000014, -400.0, -400.0, 25.400000000000098, -400.0, -297.399999999999, -45.10000000000003, -368.8, 1.099999999999966, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -5.1999999999999265, -372.1, -1488.0, 20.000000000000014, -374.79999999999995, -28.29999999999975, -400.0, -400.0, -400.0, -370.6, 20.000000000000014, -363.7, -372.7, -400.0, -400.0, 20.000000000000014, 24.50000000000009, -400.0, -400.0, -400.0, -400.0, -400.0, -162.70000000000002, -400.0, -389.5, -373.6, -338.8, -400.0, -400.0, 22.700000000000053, -400.0, 18.799999999999997, -305.50000000000006, -400.0, -400.0, -391.6, -248.8000000000004, -400.0, -345.4, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -150.10000000000028, 36.200000000000244, -392.8, -400.0, 20.000000000000014, -364.3, -400.0, -305.499999999999, -400.0, -400.0, -319.60000000000014, 3.1999999999999615, 20.000000000000014, -353.8, -334.8999999999993, -383.2, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, 13.699999999999964, -384.7, -400.0, -365.8, -374.8, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -368.8, -183.40000000000052, -385.29999999999995, 36.20000000000025, 35.30000000000025, -342.7, -400.0, -400.0, -400.0, -356.8, -290.7999999999988, -400.0, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, -355.6, -400.0, -400.0, -400.0, 20.000000000000014, -332.8, -400.0, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -344.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 29.90000000000018, -342.7, -400.0, -353.8, -392.8, -400.0, -363.4, -400.0, -400.0, 23.600000000000065, -400.0, -400.0, -400.0, -381.7, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, 20.000000000000014, -400.0, -390.7, -397.9, -400.0, -400.0, -400.0, -338.5, -400.0, -344.8, -106.0000000000008, -400.0, -400.0, -368.8, -36.699999999999775, -400.0, -400.0, 20.000000000000014], "policy_predator_policy_reward": [157.0, 182.0, 189.0, 606.0, 197.0, 5.0, 200.0, 200.0, 173.0, 156.0, 173.0, 200.0, 200.0, 200.0, 200.0, 196.0, 163.0, 143.0, 200.0, 200.0, 200.0, 181.0, 119.0, 108.0, 180.0, 190.0, 145.0, 199.0, 200.0, 200.0, 194.0, 176.0, 200.0, 172.0, 200.0, 191.0, 200.0, 200.0, 33.0, 151.0, 192.0, 91.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 179.0, 116.0, 1424.0, 188.0, 23.0, 200.0, 136.0, 194.0, 200.0, 187.0, 182.0, 193.0, 200.0, 200.0, 110.0, 164.0, 169.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 195.0, 190.0, 115.0, 200.0, 193.0, 200.0, 13.0, 200.0, 200.0, 200.0, 196.0, 200.0, 200.0, 128.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 81.0, 26.0, 200.0, 200.0, 181.0, 179.0, 155.0, 200.0, 159.0, 200.0, 47.0, 127.0, 12.0, 172.0, 169.0, 192.0, 200.0, 59.0, 200.0, 200.0, 200.0, 200.0, 155.0, 194.0, 200.0, 200.0, 183.0, 200.0, 200.0, 165.0, 200.0, 0.0, 200.0, 200.0, 187.0, 193.0, 193.0, 193.0, 180.0, 180.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 184.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 27.0, 200.0, 181.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 196.0, 200.0, 197.0, 178.0, 183.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 187.0, 200.0, 199.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5876537690480934, "mean_inference_ms": 1.8404551906325446, "mean_action_processing_ms": 0.25471383777203693, "mean_env_wait_ms": 0.19732639157876136, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004874825477600098, "StateBufferConnector_ms": 0.003185272216796875, "ViewRequirementAgentConnector_ms": 0.09776163101196289}, "num_episodes": 18, "episode_return_max": 72.00000000000017, "episode_return_min": -464.0, "episode_return_mean": -231.90599999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 427.3571485993656, "num_env_steps_trained_throughput_per_sec": 427.3571485993656, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 9552.608, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9552.569, "sample_time_ms": 1268.763, "learn_time_ms": 8269.016, "learn_throughput": 483.734, "synch_weights_time_ms": 13.988}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-15-52", "timestamp": 1723644952, "time_this_iter_s": 9.364678144454956, "time_total_s": 817.72807264328, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187484c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 817.72807264328, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 29.66153846153846, "ram_util_percent": 83.65384615384617}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1720748143221336, "cur_kl_coeff": 0.9610839843749998, "cur_lr": 0.009999999999999998, "total_loss": 8.361623449678774, "policy_loss": 0.00018891471181872976, "vf_loss": 8.360139018517954, "vf_explained_var": 0.06339240193997742, "kl": 0.001347979739390559, "entropy": 0.010438341801166465, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5964709772082863, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.377638248917918, "policy_loss": 0.0032223754139893033, "vf_loss": 8.34939403660083, "vf_explained_var": 0.001170994585784024, "kl": 0.009763132114508466, "entropy": 0.3928084295932893, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 72.00000000000017, "episode_reward_min": -464.0, "episode_reward_mean": -234.958, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1488.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 1424.0}, "policy_reward_mean": {"prey_policy": -305.189, "predator_policy": 187.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.400000000000098, -158.50000000000068, -84.69999999999985, 20.000000000000014, 20.000000000000014, -400.0, -10.299999999999816, 72.00000000000017, -192.10000000000076, -464.0, -376.6, 25.300000000000097, -379.7, -70.00000000000068, -42.499999999999844, -400.0, -400.0, -168.7, -378.1, -423.79999999999995, 15.699999999999966, -168.20000000000059, -305.5, -395.6, -320.79999999999836, -353.4, 20.000000000000014, -400.0, -6.899999999999842, -392.8, 15.699999999999966, -350.499999999999, -441.0, -142.40000000000038, -149.80000000000047, -357.0999999999993, -121.0000000000003, 20.000000000000018, -400.0, -21.99999999999998, -365.8, -391.8, -435.0, -165.6000000000006, -400.0, -172.20000000000053, 36.90000000000026, 52.60000000000026, -400.0, -356.8, -342.7999999999988, -400.0, -400.0, -392.3, -371.6, -400.0, 20.000000000000014, -355.8, -400.0, -137.7000000000004, -363.8, 20.000000000000014, 16.999999999999975, 29.900000000000176, -346.7, -371.6, -380.4, -400.0, 13.599999999999959, -400.0, -381.7, -400.0, 34.400000000000254, 20.000000000000018, -393.6, -400.0, -360.5, -344.8, -106.0000000000008, -379.8, -49.700000000000024, 19.0, -381.8, -400.0, -153.8000000000005, -327.4, -400.0, -416.0, -4.999999999999906, 34.400000000000254, 29.000000000000163, -400.0, -398.0, -354.4, -354.8, 20.000000000000014, -339.4, -372.5, -159.80000000000055, -371.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [25.400000000000098, -400.0, -297.399999999999, -45.10000000000003, -368.8, 1.099999999999966, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -5.1999999999999265, -372.1, -1488.0, 20.000000000000014, -374.79999999999995, -28.29999999999975, -400.0, -400.0, -400.0, -370.6, 20.000000000000014, -363.7, -372.7, -400.0, -400.0, 20.000000000000014, 24.50000000000009, -400.0, -400.0, -400.0, -400.0, -400.0, -162.70000000000002, -400.0, -389.5, -373.6, -338.8, -400.0, -400.0, 22.700000000000053, -400.0, 18.799999999999997, -305.50000000000006, -400.0, -400.0, -391.6, -248.8000000000004, -400.0, -345.4, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -150.10000000000028, 36.200000000000244, -392.8, -400.0, 20.000000000000014, -364.3, -400.0, -305.499999999999, -400.0, -400.0, -319.60000000000014, 3.1999999999999615, 20.000000000000014, -353.8, -334.8999999999993, -383.2, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, 13.699999999999964, -384.7, -400.0, -365.8, -374.8, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -368.8, -183.40000000000052, -385.29999999999995, 36.20000000000025, 35.30000000000025, -342.7, -400.0, -400.0, -400.0, -356.8, -290.7999999999988, -400.0, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, -355.6, -400.0, -400.0, -400.0, 20.000000000000014, -332.8, -400.0, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -344.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 29.90000000000018, -342.7, -400.0, -353.8, -392.8, -400.0, -363.4, -400.0, -400.0, 23.600000000000065, -400.0, -400.0, -400.0, -381.7, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, 20.000000000000014, -400.0, -390.7, -397.9, -400.0, -400.0, -400.0, -338.5, -400.0, -344.8, -106.0000000000008, -400.0, -400.0, -368.8, -36.699999999999775, -400.0, -400.0, 20.000000000000014, -400.0, -371.8, -400.0, -400.0, 20.000000000000014, -359.8, -368.5, -310.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, 29.000000000000163, -400.0, -400.0, -400.0, -397.0, -400.0, -400.0, -339.4, -400.0, -353.8, -400.0, 20.000000000000014, -400.0, -339.4, -400.0, -350.5, 20.000000000000014, -368.8, -359.8, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 33.0, 151.0, 192.0, 91.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 179.0, 116.0, 1424.0, 188.0, 23.0, 200.0, 136.0, 194.0, 200.0, 187.0, 182.0, 193.0, 200.0, 200.0, 110.0, 164.0, 169.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 195.0, 190.0, 115.0, 200.0, 193.0, 200.0, 13.0, 200.0, 200.0, 200.0, 196.0, 200.0, 200.0, 128.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 81.0, 26.0, 200.0, 200.0, 181.0, 179.0, 155.0, 200.0, 159.0, 200.0, 47.0, 127.0, 12.0, 172.0, 169.0, 192.0, 200.0, 59.0, 200.0, 200.0, 200.0, 200.0, 155.0, 194.0, 200.0, 200.0, 183.0, 200.0, 200.0, 165.0, 200.0, 0.0, 200.0, 200.0, 187.0, 193.0, 193.0, 193.0, 180.0, 180.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 184.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 27.0, 200.0, 181.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 196.0, 200.0, 197.0, 178.0, 183.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 187.0, 200.0, 199.0, 200.0, 190.0, 200.0, 200.0, 186.0, 0.0, 167.0, 185.0, 200.0, 200.0, 200.0, 184.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 185.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 0.0, 189.0, 200.0, 188.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.586897956631013, "mean_inference_ms": 1.8380562630641817, "mean_action_processing_ms": 0.25409672907141023, "mean_env_wait_ms": 0.19699087421682976, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005574584007263184, "StateBufferConnector_ms": 0.0036094188690185547, "ViewRequirementAgentConnector_ms": 0.0987696647644043}, "num_episodes": 18, "episode_return_max": 72.00000000000017, "episode_return_min": -464.0, "episode_return_mean": -234.958, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 418.8293484727405, "num_env_steps_trained_throughput_per_sec": 418.8293484727405, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 9525.481, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9525.442, "sample_time_ms": 1267.154, "learn_time_ms": 8243.201, "learn_throughput": 485.248, "synch_weights_time_ms": 14.198}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-16-02", "timestamp": 1723644962, "time_this_iter_s": 9.555665731430054, "time_total_s": 827.2837383747101, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187433a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 827.2837383747101, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 27.692857142857143, "ram_util_percent": 83.35714285714288}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.262664620743857, "cur_kl_coeff": 0.4805419921874999, "cur_lr": 0.009999999999999998, "total_loss": 5.956095964441855, "policy_loss": -1.5653375777657384e-05, "vf_loss": 5.955516331788724, "vf_explained_var": 0.064076950373473, "kl": 0.0012387496419086882, "entropy": 0.0013410143597508352, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.280695648852085, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.424591227687856, "policy_loss": 0.0021643428370928166, "vf_loss": 8.408697682335264, "vf_explained_var": 0.0005324774949008195, "kl": 0.005356913738709786, "entropy": 0.3352151926784288, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 52.60000000000026, "episode_reward_min": -441.59999999999997, "episode_reward_mean": -248.354, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -310.147, "predator_policy": 185.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-305.5, -395.6, -320.79999999999836, -353.4, 20.000000000000014, -400.0, -6.899999999999842, -392.8, 15.699999999999966, -350.499999999999, -441.0, -142.40000000000038, -149.80000000000047, -357.0999999999993, -121.0000000000003, 20.000000000000018, -400.0, -21.99999999999998, -365.8, -391.8, -435.0, -165.6000000000006, -400.0, -172.20000000000053, 36.90000000000026, 52.60000000000026, -400.0, -356.8, -342.7999999999988, -400.0, -400.0, -392.3, -371.6, -400.0, 20.000000000000014, -355.8, -400.0, -137.7000000000004, -363.8, 20.000000000000014, 16.999999999999975, 29.900000000000176, -346.7, -371.6, -380.4, -400.0, 13.599999999999959, -400.0, -381.7, -400.0, 34.400000000000254, 20.000000000000018, -393.6, -400.0, -360.5, -344.8, -106.0000000000008, -379.8, -49.700000000000024, 19.0, -381.8, -400.0, -153.8000000000005, -327.4, -400.0, -416.0, -4.999999999999906, 34.400000000000254, 29.000000000000163, -400.0, -398.0, -354.4, -354.8, 20.000000000000014, -339.4, -372.5, -159.80000000000055, -371.8, -395.8, -383.2, -357.4, -377.8, -400.0, -335.09999999999997, -441.59999999999997, -400.0, -378.7, 20.000000000000014, -400.0, -400.0, 19.0, 20.000000000000018, 27.20000000000013, 11.899999999999961, -378.5, 23.600000000000065, -400.0, 28.000000000000146, 20.000000000000018, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-305.50000000000006, -400.0, -400.0, -391.6, -248.8000000000004, -400.0, -345.4, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -150.10000000000028, 36.200000000000244, -392.8, -400.0, 20.000000000000014, -364.3, -400.0, -305.499999999999, -400.0, -400.0, -319.60000000000014, 3.1999999999999615, 20.000000000000014, -353.8, -334.8999999999993, -383.2, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, 13.699999999999964, -384.7, -400.0, -365.8, -374.8, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -368.8, -183.40000000000052, -385.29999999999995, 36.20000000000025, 35.30000000000025, -342.7, -400.0, -400.0, -400.0, -356.8, -290.7999999999988, -400.0, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, -355.6, -400.0, -400.0, -400.0, 20.000000000000014, -332.8, -400.0, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -344.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 29.90000000000018, -342.7, -400.0, -353.8, -392.8, -400.0, -363.4, -400.0, -400.0, 23.600000000000065, -400.0, -400.0, -400.0, -381.7, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, 20.000000000000014, -400.0, -390.7, -397.9, -400.0, -400.0, -400.0, -338.5, -400.0, -344.8, -106.0000000000008, -400.0, -400.0, -368.8, -36.699999999999775, -400.0, -400.0, 20.000000000000014, -400.0, -371.8, -400.0, -400.0, 20.000000000000014, -359.8, -368.5, -310.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, 29.000000000000163, -400.0, -400.0, -400.0, -397.0, -400.0, -400.0, -339.4, -400.0, -353.8, -400.0, 20.000000000000014, -400.0, -339.4, -400.0, -350.5, 20.000000000000014, -368.8, -359.8, -400.0, -395.8, -400.0, -383.2, -400.0, -357.4, -400.0, -400.0, -374.8, -400.0, -400.0, -381.1, -295.0, -337.9, -279.69999999999993, -400.0, -400.0, -400.0, -366.7, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 27.20000000000013, 29.90000000000018, -400.0, -379.0, -389.5, 23.600000000000065, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, 20.000000000000014, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 196.0, 200.0, 200.0, 128.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 81.0, 26.0, 200.0, 200.0, 181.0, 179.0, 155.0, 200.0, 159.0, 200.0, 47.0, 127.0, 12.0, 172.0, 169.0, 192.0, 200.0, 59.0, 200.0, 200.0, 200.0, 200.0, 155.0, 194.0, 200.0, 200.0, 183.0, 200.0, 200.0, 165.0, 200.0, 0.0, 200.0, 200.0, 187.0, 193.0, 193.0, 193.0, 180.0, 180.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 184.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 27.0, 200.0, 181.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 196.0, 200.0, 197.0, 178.0, 183.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 187.0, 200.0, 199.0, 200.0, 190.0, 200.0, 200.0, 186.0, 0.0, 167.0, 185.0, 200.0, 200.0, 200.0, 184.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 185.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 0.0, 189.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 150.0, 191.0, 0.0, 176.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.585981017229334, "mean_inference_ms": 1.8365488907485834, "mean_action_processing_ms": 0.25291184963282903, "mean_env_wait_ms": 0.19659356515060622, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006667375564575195, "StateBufferConnector_ms": 0.003543853759765625, "ViewRequirementAgentConnector_ms": 0.09609091281890869}, "num_episodes": 22, "episode_return_max": 52.60000000000026, "episode_return_min": -441.59999999999997, "episode_return_mean": -248.354, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 425.0023400539853, "num_env_steps_trained_throughput_per_sec": 425.0023400539853, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 9486.229, "restore_workers_time_ms": 0.016, "training_step_time_ms": 9486.19, "sample_time_ms": 1269.536, "learn_time_ms": 8201.477, "learn_throughput": 487.717, "synch_weights_time_ms": 14.287}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-16-11", "timestamp": 1723644971, "time_this_iter_s": 9.41573977470398, "time_total_s": 836.6994781494141, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d30d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 836.6994781494141, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 28.88461538461539, "ram_util_percent": 83.3153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.247827975854041, "cur_kl_coeff": 0.24027099609374994, "cur_lr": 0.009999999999999998, "total_loss": 2.838381153944308, "policy_loss": 0.000279148665340568, "vf_loss": 2.83810009294086, "vf_explained_var": 0.017889048908122634, "kl": 7.967121132225583e-06, "entropy": 1.4083129532616387e-06, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.622304868093007, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.129274147780484, "policy_loss": 0.0029217680119761518, "vf_loss": 8.108604481359007, "vf_explained_var": -4.415158872251157e-09, "kl": 0.006924966428449976, "entropy": 0.34533527222259963, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 52.60000000000026, "episode_reward_min": -583.1, "episode_reward_mean": -250.975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -314.7175, "predator_policy": 189.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-172.20000000000053, 36.90000000000026, 52.60000000000026, -400.0, -356.8, -342.7999999999988, -400.0, -400.0, -392.3, -371.6, -400.0, 20.000000000000014, -355.8, -400.0, -137.7000000000004, -363.8, 20.000000000000014, 16.999999999999975, 29.900000000000176, -346.7, -371.6, -380.4, -400.0, 13.599999999999959, -400.0, -381.7, -400.0, 34.400000000000254, 20.000000000000018, -393.6, -400.0, -360.5, -344.8, -106.0000000000008, -379.8, -49.700000000000024, 19.0, -381.8, -400.0, -153.8000000000005, -327.4, -400.0, -416.0, -4.999999999999906, 34.400000000000254, 29.000000000000163, -400.0, -398.0, -354.4, -354.8, 20.000000000000014, -339.4, -372.5, -159.80000000000055, -371.8, -395.8, -383.2, -357.4, -377.8, -400.0, -335.09999999999997, -441.59999999999997, -400.0, -378.7, 20.000000000000014, -400.0, -400.0, 19.0, 20.000000000000018, 27.20000000000013, 11.899999999999961, -378.5, 23.600000000000065, -400.0, 28.000000000000146, 20.000000000000018, -400.0, -435.4, -400.0, 33.50000000000024, -398.9, -394.5, 20.000000000000018, -355.9, -365.8, -400.0, -583.1, 23.600000000000065, 20.000000000000014, -521.8, -175.80000000000064, -350.5, -368.6, -343.6, -391.8, 20.000000000000014, 20.000000000000014, -400.0, -397.9, 23.10000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-368.8, -183.40000000000052, -385.29999999999995, 36.20000000000025, 35.30000000000025, -342.7, -400.0, -400.0, -400.0, -356.8, -290.7999999999988, -400.0, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, -355.6, -400.0, -400.0, -400.0, 20.000000000000014, -332.8, -400.0, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -344.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 29.90000000000018, -342.7, -400.0, -353.8, -392.8, -400.0, -363.4, -400.0, -400.0, 23.600000000000065, -400.0, -400.0, -400.0, -381.7, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, 20.000000000000014, -400.0, -390.7, -397.9, -400.0, -400.0, -400.0, -338.5, -400.0, -344.8, -106.0000000000008, -400.0, -400.0, -368.8, -36.699999999999775, -400.0, -400.0, 20.000000000000014, -400.0, -371.8, -400.0, -400.0, 20.000000000000014, -359.8, -368.5, -310.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, 29.000000000000163, -400.0, -400.0, -400.0, -397.0, -400.0, -400.0, -339.4, -400.0, -353.8, -400.0, 20.000000000000014, -400.0, -339.4, -400.0, -350.5, 20.000000000000014, -368.8, -359.8, -400.0, -395.8, -400.0, -383.2, -400.0, -357.4, -400.0, -400.0, -374.8, -400.0, -400.0, -381.1, -295.0, -337.9, -279.69999999999993, -400.0, -400.0, -400.0, -366.7, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 27.20000000000013, 29.90000000000018, -400.0, -379.0, -389.5, 23.600000000000065, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -397.9, -400.0, -400.0, -389.5, 20.000000000000014, -400.0, -381.1, -362.8, -400.0, -347.8, -400.0, -400.0, -395.8, -385.3, -400.0, 23.600000000000065, -400.0, 20.000000000000014, -400.0, -356.8, -392.8, 20.000000000000014, -355.9, -349.6, -400.0, -352.6, -400.0, -343.6, -400.0, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, 28.100000000000147], "policy_predator_policy_reward": [187.0, 193.0, 193.0, 193.0, 180.0, 180.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 184.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 27.0, 200.0, 181.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 196.0, 200.0, 197.0, 178.0, 183.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 187.0, 200.0, 199.0, 200.0, 190.0, 200.0, 200.0, 186.0, 0.0, 167.0, 185.0, 200.0, 200.0, 200.0, 184.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 185.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 0.0, 189.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 150.0, 191.0, 0.0, 176.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 101.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 195.0, 200.0, 200.0, 194.0, 194.0, 182.0, 200.0, 200.0, 200.0, 198.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 35.0, 0.0, 197.0, 176.0, 179.0, 184.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5855003689390932, "mean_inference_ms": 1.8382882827654192, "mean_action_processing_ms": 0.253478442965823, "mean_env_wait_ms": 0.19629875244357833, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007189631462097168, "StateBufferConnector_ms": 0.003586888313293457, "ViewRequirementAgentConnector_ms": 0.10077571868896484}, "num_episodes": 23, "episode_return_max": 52.60000000000026, "episode_return_min": -583.1, "episode_return_mean": -250.975, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 395.6797618621978, "num_env_steps_trained_throughput_per_sec": 395.6797618621978, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 9510.479, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9510.441, "sample_time_ms": 1282.78, "learn_time_ms": 8212.152, "learn_throughput": 487.083, "synch_weights_time_ms": 14.59}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-16-21", "timestamp": 1723644981, "time_this_iter_s": 10.119279146194458, "time_total_s": 846.8187572956085, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8b6a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 846.8187572956085, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 32.413333333333334, "ram_util_percent": 83.60666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.463606776742551, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 0.009999999999999998, "total_loss": 1.895747951477293, "policy_loss": -0.00012953786029130536, "vf_loss": 1.8958774917970889, "vf_explained_var": -0.0048440428007216685, "kl": -1.4499949188073941e-08, "entropy": 4.928976043403348e-06, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.037602431307394, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.523227825618926, "policy_loss": 0.003504625985044099, "vf_loss": 7.497145257425056, "vf_explained_var": -4.018381159141581e-05, "kl": 0.00880956707978695, "entropy": 0.4357320140515055, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 38.00000000000025, "episode_reward_min": -583.1, "episode_reward_mean": -245.82700000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -309.5935, "predator_policy": 186.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.900000000000176, -346.7, -371.6, -380.4, -400.0, 13.599999999999959, -400.0, -381.7, -400.0, 34.400000000000254, 20.000000000000018, -393.6, -400.0, -360.5, -344.8, -106.0000000000008, -379.8, -49.700000000000024, 19.0, -381.8, -400.0, -153.8000000000005, -327.4, -400.0, -416.0, -4.999999999999906, 34.400000000000254, 29.000000000000163, -400.0, -398.0, -354.4, -354.8, 20.000000000000014, -339.4, -372.5, -159.80000000000055, -371.8, -395.8, -383.2, -357.4, -377.8, -400.0, -335.09999999999997, -441.59999999999997, -400.0, -378.7, 20.000000000000014, -400.0, -400.0, 19.0, 20.000000000000018, 27.20000000000013, 11.899999999999961, -378.5, 23.600000000000065, -400.0, 28.000000000000146, 20.000000000000018, -400.0, -435.4, -400.0, 33.50000000000024, -398.9, -394.5, 20.000000000000018, -355.9, -365.8, -400.0, -583.1, 23.600000000000065, 20.000000000000014, -521.8, -175.80000000000064, -350.5, -368.6, -343.6, -391.8, 20.000000000000014, 20.000000000000014, -400.0, -397.9, 23.10000000000006, 1.0000000000000009, 20.000000000000014, -159.20000000000053, 31.70000000000021, -400.0, 37.10000000000026, -372.7, 38.00000000000025, -370.6, -390.7, -169.8000000000006, -553.8, -331.4, -180.00000000000068, -372.7, -273.1999999999991, -55.9000000000004, -329.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 29.90000000000018, -342.7, -400.0, -353.8, -392.8, -400.0, -363.4, -400.0, -400.0, 23.600000000000065, -400.0, -400.0, -400.0, -381.7, -400.0, -400.0, -400.0, -400.0, 34.400000000000254, 20.000000000000014, -400.0, -390.7, -397.9, -400.0, -400.0, -400.0, -338.5, -400.0, -344.8, -106.0000000000008, -400.0, -400.0, -368.8, -36.699999999999775, -400.0, -400.0, 20.000000000000014, -400.0, -371.8, -400.0, -400.0, 20.000000000000014, -359.8, -368.5, -310.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, 29.000000000000163, -400.0, -400.0, -400.0, -397.0, -400.0, -400.0, -339.4, -400.0, -353.8, -400.0, 20.000000000000014, -400.0, -339.4, -400.0, -350.5, 20.000000000000014, -368.8, -359.8, -400.0, -395.8, -400.0, -383.2, -400.0, -357.4, -400.0, -400.0, -374.8, -400.0, -400.0, -381.1, -295.0, -337.9, -279.69999999999993, -400.0, -400.0, -400.0, -366.7, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 27.20000000000013, 29.90000000000018, -400.0, -379.0, -389.5, 23.600000000000065, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -397.9, -400.0, -400.0, -389.5, 20.000000000000014, -400.0, -381.1, -362.8, -400.0, -347.8, -400.0, -400.0, -395.8, -385.3, -400.0, 23.600000000000065, -400.0, 20.000000000000014, -400.0, -356.8, -392.8, 20.000000000000014, -355.9, -349.6, -400.0, -352.6, -400.0, -343.6, -400.0, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, 28.100000000000147, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 35.30000000000026, -389.5, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -372.7, 38.00000000000025, -400.0, -370.6, -400.0, -397.9, -386.8, -383.8, 20.000000000000014, -400.0, -353.8, -400.0, -327.4, -400.0, 20.000000000000014, -400.0, -372.7, -286.59999999999906, -349.6, -400.0, -55.900000000000254, -329.5, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 196.0, 200.0, 197.0, 178.0, 183.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 187.0, 200.0, 199.0, 200.0, 190.0, 200.0, 200.0, 186.0, 0.0, 167.0, 185.0, 200.0, 200.0, 200.0, 184.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 185.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 0.0, 189.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 150.0, 191.0, 0.0, 176.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 101.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 195.0, 200.0, 200.0, 194.0, 194.0, 182.0, 200.0, 200.0, 200.0, 198.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 35.0, 0.0, 197.0, 176.0, 179.0, 184.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 181.0, 200.0, 200.0, 0.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 195.0, 0.0, 194.0, 0.0, 200.0, 200.0, 196.0, 0.0, 200.0, 200.0, 200.0, 176.0, 187.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5848318522058681, "mean_inference_ms": 1.8317496121986216, "mean_action_processing_ms": 0.25245402375074744, "mean_env_wait_ms": 0.19620900334978272, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006693601608276367, "StateBufferConnector_ms": 0.003570079803466797, "ViewRequirementAgentConnector_ms": 0.09585511684417725}, "num_episodes": 18, "episode_return_max": 38.00000000000025, "episode_return_min": -583.1, "episode_return_mean": -245.82700000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 424.0112372019541, "num_env_steps_trained_throughput_per_sec": 424.0112372019541, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 9530.191, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9530.153, "sample_time_ms": 1284.3, "learn_time_ms": 8230.135, "learn_throughput": 486.019, "synch_weights_time_ms": 14.81}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-16-31", "timestamp": 1723644991, "time_this_iter_s": 9.437827825546265, "time_total_s": 856.2565851211548, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187621f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 856.2565851211548, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 28.66923076923077, "ram_util_percent": 82.99999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3714399080467286, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": 2.4699175572663387e-05, "vf_loss": 0.6272247442177363, "vf_explained_var": 0.002601047987660403, "kl": Infinity, "entropy": 0.0003487869879939615, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.826059769038801, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.783059253137578, "policy_loss": 0.002581786417781755, "vf_loss": 7.759573207582746, "vf_explained_var": 2.0304369548010446e-06, "kl": 0.008156522625911683, "entropy": 0.48451563703320016, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 38.00000000000025, "episode_reward_min": -583.1, "episode_reward_mean": -238.467, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -304.88349999999997, "predator_policy": 185.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.0, -381.8, -400.0, -153.8000000000005, -327.4, -400.0, -416.0, -4.999999999999906, 34.400000000000254, 29.000000000000163, -400.0, -398.0, -354.4, -354.8, 20.000000000000014, -339.4, -372.5, -159.80000000000055, -371.8, -395.8, -383.2, -357.4, -377.8, -400.0, -335.09999999999997, -441.59999999999997, -400.0, -378.7, 20.000000000000014, -400.0, -400.0, 19.0, 20.000000000000018, 27.20000000000013, 11.899999999999961, -378.5, 23.600000000000065, -400.0, 28.000000000000146, 20.000000000000018, -400.0, -435.4, -400.0, 33.50000000000024, -398.9, -394.5, 20.000000000000018, -355.9, -365.8, -400.0, -583.1, 23.600000000000065, 20.000000000000014, -521.8, -175.80000000000064, -350.5, -368.6, -343.6, -391.8, 20.000000000000014, 20.000000000000014, -400.0, -397.9, 23.10000000000006, 1.0000000000000009, 20.000000000000014, -159.20000000000053, 31.70000000000021, -400.0, 37.10000000000026, -372.7, 38.00000000000025, -370.6, -390.7, -169.8000000000006, -553.8, -331.4, -180.00000000000068, -372.7, -273.1999999999991, -55.9000000000004, -329.5, 17.99999999999999, -400.0, -400.0, -381.1, 20.000000000000014, 4.699999999999958, 35.30000000000025, 33.000000000000234, -362.2, -365.9, 20.000000000000018, -400.0, -380.8, -393.7, -171.2000000000006, -325.0, -400.0, -31.999999999999744], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 20.000000000000014, -400.0, -371.8, -400.0, -400.0, 20.000000000000014, -359.8, -368.5, -310.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, 29.000000000000163, -400.0, -400.0, -400.0, -397.0, -400.0, -400.0, -339.4, -400.0, -353.8, -400.0, 20.000000000000014, -400.0, -339.4, -400.0, -350.5, 20.000000000000014, -368.8, -359.8, -400.0, -395.8, -400.0, -383.2, -400.0, -357.4, -400.0, -400.0, -374.8, -400.0, -400.0, -381.1, -295.0, -337.9, -279.69999999999993, -400.0, -400.0, -400.0, -366.7, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 27.20000000000013, 29.90000000000018, -400.0, -379.0, -389.5, 23.600000000000065, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -397.9, -400.0, -400.0, -389.5, 20.000000000000014, -400.0, -381.1, -362.8, -400.0, -347.8, -400.0, -400.0, -395.8, -385.3, -400.0, 23.600000000000065, -400.0, 20.000000000000014, -400.0, -356.8, -392.8, 20.000000000000014, -355.9, -349.6, -400.0, -352.6, -400.0, -343.6, -400.0, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, 28.100000000000147, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 35.30000000000026, -389.5, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -372.7, 38.00000000000025, -400.0, -370.6, -400.0, -397.9, -386.8, -383.8, 20.000000000000014, -400.0, -353.8, -400.0, -327.4, -400.0, 20.000000000000014, -400.0, -372.7, -286.59999999999906, -349.6, -400.0, -55.900000000000254, -329.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -381.1, -400.0, -400.0, 20.000000000000014, 22.700000000000053, -400.0, -400.0, 35.30000000000025, 31.700000000000212, -375.7, -400.0, -362.2, -400.0, -355.9, 20.000000000000014, -400.0, -400.0, -400.0, -380.8, -400.0, -400.0, -393.7, 20.000000000000014, -383.2, -325.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014], "policy_predator_policy_reward": [200.0, 199.0, 200.0, 190.0, 200.0, 200.0, 186.0, 0.0, 167.0, 185.0, 200.0, 200.0, 200.0, 184.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 185.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 0.0, 189.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 150.0, 191.0, 0.0, 176.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 101.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 195.0, 200.0, 200.0, 194.0, 194.0, 182.0, 200.0, 200.0, 200.0, 198.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 35.0, 0.0, 197.0, 176.0, 179.0, 184.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 181.0, 200.0, 200.0, 0.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 195.0, 0.0, 194.0, 0.0, 200.0, 200.0, 196.0, 0.0, 200.0, 200.0, 200.0, 176.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 191.0, 186.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 192.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5842363282179676, "mean_inference_ms": 1.8298793211230002, "mean_action_processing_ms": 0.25204991657717885, "mean_env_wait_ms": 0.19604227137755076, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006202101707458496, "StateBufferConnector_ms": 0.003558635711669922, "ViewRequirementAgentConnector_ms": 0.09518766403198242}, "num_episodes": 18, "episode_return_max": 38.00000000000025, "episode_return_min": -583.1, "episode_return_mean": -238.467, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.3978680167543, "num_env_steps_trained_throughput_per_sec": 416.3978680167543, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 9566.652, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9566.614, "sample_time_ms": 1292.803, "learn_time_ms": 8257.339, "learn_throughput": 484.418, "synch_weights_time_ms": 15.536}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-16-40", "timestamp": 1723645000, "time_this_iter_s": 9.618510007858276, "time_total_s": 865.8750951290131, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187433a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 865.8750951290131, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 27.428571428571423, "ram_util_percent": 83.25714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6373559537043096, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": 0.0001813837748375677, "vf_loss": 0.8195335831296034, "vf_explained_var": -0.0015548252239429132, "kl": Infinity, "entropy": 1.1190037011071456e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0640707073979594, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.140452340292553, "policy_loss": 0.0025861463999799477, "vf_loss": 8.116938169166525, "vf_explained_var": -1.2898571276790881e-08, "kl": 0.008165787873567462, "entropy": 0.4740461000847438, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 38.00000000000025, "episode_reward_min": -583.1, "episode_reward_mean": -229.66100000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -301.6405, "predator_policy": 186.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-371.8, -395.8, -383.2, -357.4, -377.8, -400.0, -335.09999999999997, -441.59999999999997, -400.0, -378.7, 20.000000000000014, -400.0, -400.0, 19.0, 20.000000000000018, 27.20000000000013, 11.899999999999961, -378.5, 23.600000000000065, -400.0, 28.000000000000146, 20.000000000000018, -400.0, -435.4, -400.0, 33.50000000000024, -398.9, -394.5, 20.000000000000018, -355.9, -365.8, -400.0, -583.1, 23.600000000000065, 20.000000000000014, -521.8, -175.80000000000064, -350.5, -368.6, -343.6, -391.8, 20.000000000000014, 20.000000000000014, -400.0, -397.9, 23.10000000000006, 1.0000000000000009, 20.000000000000014, -159.20000000000053, 31.70000000000021, -400.0, 37.10000000000026, -372.7, 38.00000000000025, -370.6, -390.7, -169.8000000000006, -553.8, -331.4, -180.00000000000068, -372.7, -273.1999999999991, -55.9000000000004, -329.5, 17.99999999999999, -400.0, -400.0, -381.1, 20.000000000000014, 4.699999999999958, 35.30000000000025, 33.000000000000234, -362.2, -365.9, 20.000000000000018, -400.0, -380.8, -393.7, -171.2000000000006, -325.0, -400.0, -31.999999999999744, -386.79999999999995, 22.000000000000046, 27.20000000000013, 20.000000000000014, 10.999999999999963, -400.0, 33.50000000000024, -367.9, -395.8, -358.0, 20.600000000000023, -162.00000000000054, -400.0, -400.0, 20.000000000000014, 34.200000000000244, -400.0, -397.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-359.8, -400.0, -395.8, -400.0, -383.2, -400.0, -357.4, -400.0, -400.0, -374.8, -400.0, -400.0, -381.1, -295.0, -337.9, -279.69999999999993, -400.0, -400.0, -400.0, -366.7, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 27.20000000000013, 29.90000000000018, -400.0, -379.0, -389.5, 23.600000000000065, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -397.9, -400.0, -400.0, -389.5, 20.000000000000014, -400.0, -381.1, -362.8, -400.0, -347.8, -400.0, -400.0, -395.8, -385.3, -400.0, 23.600000000000065, -400.0, 20.000000000000014, -400.0, -356.8, -392.8, 20.000000000000014, -355.9, -349.6, -400.0, -352.6, -400.0, -343.6, -400.0, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, 28.100000000000147, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 35.30000000000026, -389.5, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -372.7, 38.00000000000025, -400.0, -370.6, -400.0, -397.9, -386.8, -383.8, 20.000000000000014, -400.0, -353.8, -400.0, -327.4, -400.0, 20.000000000000014, -400.0, -372.7, -286.59999999999906, -349.6, -400.0, -55.900000000000254, -329.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -381.1, -400.0, -400.0, 20.000000000000014, 22.700000000000053, -400.0, -400.0, 35.30000000000025, 31.700000000000212, -375.7, -400.0, -362.2, -400.0, -355.9, 20.000000000000014, -400.0, -400.0, -400.0, -380.8, -400.0, -400.0, -393.7, 20.000000000000014, -383.2, -325.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -376.9, -397.9, 30.800000000000196, -374.8, 27.20000000000013, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 33.50000000000024, -400.0, -362.2, -393.7, -400.0, -395.8, -400.0, -358.0, -397.9, 33.50000000000024, 38.00000000000025, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -335.8, 20.000000000000014, -400.0, -400.0, -400.0, -397.9], "policy_predator_policy_reward": [200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 150.0, 191.0, 0.0, 176.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 101.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 195.0, 200.0, 200.0, 194.0, 194.0, 182.0, 200.0, 200.0, 200.0, 198.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 35.0, 0.0, 197.0, 176.0, 179.0, 184.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 181.0, 200.0, 200.0, 0.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 195.0, 0.0, 194.0, 0.0, 200.0, 200.0, 196.0, 0.0, 200.0, 200.0, 200.0, 176.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 191.0, 186.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 192.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 189.0, 199.0, 175.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 199.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 172.0, 178.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5836740307502818, "mean_inference_ms": 1.8285506223831862, "mean_action_processing_ms": 0.251709187216092, "mean_env_wait_ms": 0.19592317589201044, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005635857582092285, "StateBufferConnector_ms": 0.003476262092590332, "ViewRequirementAgentConnector_ms": 0.0958331823348999}, "num_episodes": 18, "episode_return_max": 38.00000000000025, "episode_return_min": -583.1, "episode_return_mean": -229.66100000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 406.1978156198954, "num_env_steps_trained_throughput_per_sec": 406.1978156198954, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 9575.884, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9575.844, "sample_time_ms": 1303.526, "learn_time_ms": 8256.409, "learn_throughput": 484.472, "synch_weights_time_ms": 15.02}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-16-50", "timestamp": 1723645010, "time_this_iter_s": 9.854076862335205, "time_total_s": 875.7291719913483, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x318743b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 875.7291719913483, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 30.357142857142854, "ram_util_percent": 83.62142857142855}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.527805749031286, "cur_kl_coeff": 0.1351524353027344, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": 4.2968354232254484e-05, "vf_loss": 1.0008535972978703, "vf_explained_var": -0.0006051656114992011, "kl": Infinity, "entropy": 4.177776767666142e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.307346297307778, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.40591175064208, "policy_loss": 0.0028199528148102147, "vf_loss": 8.385384657774022, "vf_explained_var": -1.6731339156943025e-05, "kl": 0.006909049114436016, "entropy": 0.3427686633768851, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 38.00000000000025, "episode_reward_min": -583.1, "episode_reward_mean": -234.209, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -301.94949999999994, "predator_policy": 184.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -435.4, -400.0, 33.50000000000024, -398.9, -394.5, 20.000000000000018, -355.9, -365.8, -400.0, -583.1, 23.600000000000065, 20.000000000000014, -521.8, -175.80000000000064, -350.5, -368.6, -343.6, -391.8, 20.000000000000014, 20.000000000000014, -400.0, -397.9, 23.10000000000006, 1.0000000000000009, 20.000000000000014, -159.20000000000053, 31.70000000000021, -400.0, 37.10000000000026, -372.7, 38.00000000000025, -370.6, -390.7, -169.8000000000006, -553.8, -331.4, -180.00000000000068, -372.7, -273.1999999999991, -55.9000000000004, -329.5, 17.99999999999999, -400.0, -400.0, -381.1, 20.000000000000014, 4.699999999999958, 35.30000000000025, 33.000000000000234, -362.2, -365.9, 20.000000000000018, -400.0, -380.8, -393.7, -171.2000000000006, -325.0, -400.0, -31.999999999999744, -386.79999999999995, 22.000000000000046, 27.20000000000013, 20.000000000000014, 10.999999999999963, -400.0, 33.50000000000024, -367.9, -395.8, -358.0, 20.600000000000023, -162.00000000000054, -400.0, -400.0, 20.000000000000014, 34.200000000000244, -400.0, -397.9, -395.8, 36.200000000000266, -400.0, -319.9, -180.00000000000065, -382.4, -381.0, -370.29999999999995, 24.50000000000008, 20.000000000000018, 18.39999999999999, 32.60000000000023, -569.7, -400.0, -359.4, -378.1, -180.00000000000068, -394.7, -391.6, 32.60000000000023, -400.0, -366.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -336.4, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -397.9, -400.0, -400.0, -389.5, 20.000000000000014, -400.0, -381.1, -362.8, -400.0, -347.8, -400.0, -400.0, -395.8, -385.3, -400.0, 23.600000000000065, -400.0, 20.000000000000014, -400.0, -356.8, -392.8, 20.000000000000014, -355.9, -349.6, -400.0, -352.6, -400.0, -343.6, -400.0, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, 28.100000000000147, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 35.30000000000026, -389.5, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -372.7, 38.00000000000025, -400.0, -370.6, -400.0, -397.9, -386.8, -383.8, 20.000000000000014, -400.0, -353.8, -400.0, -327.4, -400.0, 20.000000000000014, -400.0, -372.7, -286.59999999999906, -349.6, -400.0, -55.900000000000254, -329.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -381.1, -400.0, -400.0, 20.000000000000014, 22.700000000000053, -400.0, -400.0, 35.30000000000025, 31.700000000000212, -375.7, -400.0, -362.2, -400.0, -355.9, 20.000000000000014, -400.0, -400.0, -400.0, -380.8, -400.0, -400.0, -393.7, 20.000000000000014, -383.2, -325.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -376.9, -397.9, 30.800000000000196, -374.8, 27.20000000000013, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 33.50000000000024, -400.0, -362.2, -393.7, -400.0, -395.8, -400.0, -358.0, -397.9, 33.50000000000024, 38.00000000000025, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -335.8, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, -395.8, -347.8, 20.000000000000014, -400.0, -400.0, -319.9, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -376.0, -343.3, -400.0, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 34.40000000000025, -400.0, 32.60000000000023, -400.0, -369.7, -400.0, -400.0, -400.0, -351.70000000000005, -393.7, -363.1, -400.0, -400.0, 20.000000000000014, -390.7, -400.0, -391.6, -400.0, -400.0, 32.60000000000023, -400.0, -400.0, -366.4, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 101.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 200.0, 195.0, 200.0, 200.0, 194.0, 194.0, 182.0, 200.0, 200.0, 200.0, 198.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 35.0, 0.0, 197.0, 176.0, 179.0, 184.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 181.0, 200.0, 200.0, 0.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 195.0, 0.0, 194.0, 0.0, 200.0, 200.0, 196.0, 0.0, 200.0, 200.0, 200.0, 176.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 191.0, 186.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 192.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 189.0, 199.0, 175.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 199.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 172.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 184.0, 200.0, 195.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 185.0, 0.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5830223438500619, "mean_inference_ms": 1.827296518376758, "mean_action_processing_ms": 0.2513430841125877, "mean_env_wait_ms": 0.19580598400747995, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004435181617736816, "StateBufferConnector_ms": 0.0034818649291992188, "ViewRequirementAgentConnector_ms": 0.09774816036224365}, "num_episodes": 22, "episode_return_max": 38.00000000000025, "episode_return_min": -583.1, "episode_return_mean": -234.209, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 410.23108082602363, "num_env_steps_trained_throughput_per_sec": 410.23108082602363, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 9601.109, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9601.07, "sample_time_ms": 1303.815, "learn_time_ms": 8281.108, "learn_throughput": 483.027, "synch_weights_time_ms": 15.173}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-17-00", "timestamp": 1723645020, "time_this_iter_s": 9.784080266952515, "time_total_s": 885.5132522583008, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31874ca60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 885.5132522583008, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 30.728571428571424, "ram_util_percent": 83.67142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7066776758089426, "cur_kl_coeff": 0.2027286529541015, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": -0.0003316784942788737, "vf_loss": 0.4298827725832188, "vf_explained_var": 0.0016930857663432126, "kl": Infinity, "entropy": 1.162926938343599e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7507638224494206, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.527997069888645, "policy_loss": 0.004146314020608626, "vf_loss": 8.499510865741305, "vf_explained_var": -1.4382285415810883e-05, "kl": 0.009497040482027366, "entropy": 0.4351710936379811, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 38.00000000000025, "episode_reward_min": -600.0, "episode_reward_mean": -234.02, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -303.13, "predator_policy": 186.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.10000000000006, 1.0000000000000009, 20.000000000000014, -159.20000000000053, 31.70000000000021, -400.0, 37.10000000000026, -372.7, 38.00000000000025, -370.6, -390.7, -169.8000000000006, -553.8, -331.4, -180.00000000000068, -372.7, -273.1999999999991, -55.9000000000004, -329.5, 17.99999999999999, -400.0, -400.0, -381.1, 20.000000000000014, 4.699999999999958, 35.30000000000025, 33.000000000000234, -362.2, -365.9, 20.000000000000018, -400.0, -380.8, -393.7, -171.2000000000006, -325.0, -400.0, -31.999999999999744, -386.79999999999995, 22.000000000000046, 27.20000000000013, 20.000000000000014, 10.999999999999963, -400.0, 33.50000000000024, -367.9, -395.8, -358.0, 20.600000000000023, -162.00000000000054, -400.0, -400.0, 20.000000000000014, 34.200000000000244, -400.0, -397.9, -395.8, 36.200000000000266, -400.0, -319.9, -180.00000000000065, -382.4, -381.0, -370.29999999999995, 24.50000000000008, 20.000000000000018, 18.39999999999999, 32.60000000000023, -569.7, -400.0, -359.4, -378.1, -180.00000000000068, -394.7, -391.6, 32.60000000000023, -400.0, -366.4, -365.8, -311.79999999999995, -380.2, -400.0, -53.000000000000014, 20.000000000000014, -400.0, -370.5, -330.1, -380.5, 20.000000000000018, -379.0, -400.0, 23.10000000000006, -600.0, -1.6999999999999869, -370.7, -400.0, 20.000000000000014, -400.0, -317.79999999999995, -349.6, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 28.100000000000147, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 35.30000000000026, -389.5, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -372.7, 38.00000000000025, -400.0, -370.6, -400.0, -397.9, -386.8, -383.8, 20.000000000000014, -400.0, -353.8, -400.0, -327.4, -400.0, 20.000000000000014, -400.0, -372.7, -286.59999999999906, -349.6, -400.0, -55.900000000000254, -329.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -381.1, -400.0, -400.0, 20.000000000000014, 22.700000000000053, -400.0, -400.0, 35.30000000000025, 31.700000000000212, -375.7, -400.0, -362.2, -400.0, -355.9, 20.000000000000014, -400.0, -400.0, -400.0, -380.8, -400.0, -400.0, -393.7, 20.000000000000014, -383.2, -325.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -376.9, -397.9, 30.800000000000196, -374.8, 27.20000000000013, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 33.50000000000024, -400.0, -362.2, -393.7, -400.0, -395.8, -400.0, -358.0, -397.9, 33.50000000000024, 38.00000000000025, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -335.8, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, -395.8, -347.8, 20.000000000000014, -400.0, -400.0, -319.9, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -376.0, -343.3, -400.0, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 34.40000000000025, -400.0, 32.60000000000023, -400.0, -369.7, -400.0, -400.0, -400.0, -351.70000000000005, -393.7, -363.1, -400.0, -400.0, 20.000000000000014, -390.7, -400.0, -391.6, -400.0, -400.0, 32.60000000000023, -400.0, -400.0, -366.4, -400.0, -400.0, -347.8, -365.8, -274.0, -400.0, -362.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -368.5, -330.1, -400.0, -387.7, -380.8, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -369.7, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -253.00000000000003, -395.8, -400.0, -349.6, -400.0, -400.0], "policy_predator_policy_reward": [195.0, 200.0, 200.0, 181.0, 200.0, 200.0, 0.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 195.0, 0.0, 194.0, 0.0, 200.0, 200.0, 196.0, 0.0, 200.0, 200.0, 200.0, 176.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 191.0, 186.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 192.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 189.0, 199.0, 175.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 199.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 172.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 184.0, 200.0, 195.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 185.0, 0.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 140.0, 188.0, 182.0, 200.0, 200.0, 200.0, 127.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 195.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 0.0, 163.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 133.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.582075515503207, "mean_inference_ms": 1.8250544588741748, "mean_action_processing_ms": 0.25072669809179754, "mean_env_wait_ms": 0.19544660565577587, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003789663314819336, "StateBufferConnector_ms": 0.0034650564193725586, "ViewRequirementAgentConnector_ms": 0.09199357032775879}, "num_episodes": 23, "episode_return_max": 38.00000000000025, "episode_return_min": -600.0, "episode_return_mean": -234.02, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.8766141312016, "num_env_steps_trained_throughput_per_sec": 404.8766141312016, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 9643.671, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9643.63, "sample_time_ms": 1301.233, "learn_time_ms": 8326.684, "learn_throughput": 480.383, "synch_weights_time_ms": 14.687}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-17-10", "timestamp": 1723645030, "time_this_iter_s": 9.88444709777832, "time_total_s": 895.3976993560791, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d3ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 895.3976993560791, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 29.478571428571428, "ram_util_percent": 83.62142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4962455710445446, "cur_kl_coeff": 0.3040929794311523, "cur_lr": 0.009999999999999998, "total_loss": 0.9095039553112454, "policy_loss": -0.00031776005025243475, "vf_loss": 0.9098217141612497, "vf_explained_var": -0.0006105854082359838, "kl": -9.31350371767743e-39, "entropy": 5.284939178360496e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.223259035426946, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.522147599477616, "policy_loss": 0.000863081245638785, "vf_loss": 8.508009026290248, "vf_explained_var": -7.316548988301918e-09, "kl": 0.0051798941534381806, "entropy": 0.35587726769939304, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 210.9999999999993, "episode_reward_min": -600.0, "episode_reward_mean": -248.02000000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1928.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 1919.0}, "policy_reward_mean": {"prey_policy": -320.16, "predator_policy": 196.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-329.5, 17.99999999999999, -400.0, -400.0, -381.1, 20.000000000000014, 4.699999999999958, 35.30000000000025, 33.000000000000234, -362.2, -365.9, 20.000000000000018, -400.0, -380.8, -393.7, -171.2000000000006, -325.0, -400.0, -31.999999999999744, -386.79999999999995, 22.000000000000046, 27.20000000000013, 20.000000000000014, 10.999999999999963, -400.0, 33.50000000000024, -367.9, -395.8, -358.0, 20.600000000000023, -162.00000000000054, -400.0, -400.0, 20.000000000000014, 34.200000000000244, -400.0, -397.9, -395.8, 36.200000000000266, -400.0, -319.9, -180.00000000000065, -382.4, -381.0, -370.29999999999995, 24.50000000000008, 20.000000000000018, 18.39999999999999, 32.60000000000023, -569.7, -400.0, -359.4, -378.1, -180.00000000000068, -394.7, -391.6, 32.60000000000023, -400.0, -366.4, -365.8, -311.79999999999995, -380.2, -400.0, -53.000000000000014, 20.000000000000014, -400.0, -370.5, -330.1, -380.5, 20.000000000000018, -379.0, -400.0, 23.10000000000006, -600.0, -1.6999999999999869, -370.7, -400.0, 20.000000000000014, -400.0, -317.79999999999995, -349.6, -400.0, -377.8, 1.9999999999999876, -400.0, -600.0, -330.5, -401.0, -397.8, -400.0, -356.7, -365.9, -400.0, -361.6, -376.9, -400.0, 210.9999999999993, 39.1000000000003, 16.99999999999998, 20.000000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-329.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -381.1, -400.0, -400.0, 20.000000000000014, 22.700000000000053, -400.0, -400.0, 35.30000000000025, 31.700000000000212, -375.7, -400.0, -362.2, -400.0, -355.9, 20.000000000000014, -400.0, -400.0, -400.0, -380.8, -400.0, -400.0, -393.7, 20.000000000000014, -383.2, -325.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -376.9, -397.9, 30.800000000000196, -374.8, 27.20000000000013, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 33.50000000000024, -400.0, -362.2, -393.7, -400.0, -395.8, -400.0, -358.0, -397.9, 33.50000000000024, 38.00000000000025, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -335.8, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, -395.8, -347.8, 20.000000000000014, -400.0, -400.0, -319.9, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -376.0, -343.3, -400.0, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 34.40000000000025, -400.0, 32.60000000000023, -400.0, -369.7, -400.0, -400.0, -400.0, -351.70000000000005, -393.7, -363.1, -400.0, -400.0, 20.000000000000014, -390.7, -400.0, -391.6, -400.0, -400.0, 32.60000000000023, -400.0, -400.0, -366.4, -400.0, -400.0, -347.8, -365.8, -274.0, -400.0, -362.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -368.5, -330.1, -400.0, -387.7, -380.8, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -369.7, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -253.00000000000003, -395.8, -400.0, -349.6, -400.0, -400.0, -365.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -364.3, -320.2, -400.0, -400.0, -400.0, -395.8, -400.0, -400.0, -333.7, -400.0, -400.0, -334.9, -400.0, -400.0, -395.8, -344.8, -376.9, -400.0, -400.0, -400.0, 20.000000000000014, -1928.0, -150.10000000000002, 27.20000000000013, 20.000000000000014, -400.0, -400.0, 20.000000000000014], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 191.0, 186.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 192.0, 200.0, 200.0, 200.0, 200.0, 148.0, 200.0, 189.0, 199.0, 175.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 199.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 172.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 184.0, 200.0, 195.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 185.0, 0.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 140.0, 188.0, 182.0, 200.0, 200.0, 200.0, 127.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 195.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 0.0, 163.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 133.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 183.0, 171.0, 199.0, 200.0, 198.0, 200.0, 200.0, 200.0, 177.0, 200.0, 169.0, 200.0, 200.0, 200.0, 181.0, 198.0, 200.0, 200.0, 200.0, 200.0, 1919.0, 200.0, 81.0, 81.0, 200.0, 197.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5814103790900069, "mean_inference_ms": 1.8236220561767007, "mean_action_processing_ms": 0.2503391279555855, "mean_env_wait_ms": 0.1952050933985972, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038652420043945312, "StateBufferConnector_ms": 0.003427743911743164, "ViewRequirementAgentConnector_ms": 0.09297239780426025}, "num_episodes": 18, "episode_return_max": 210.9999999999993, "episode_return_min": -600.0, "episode_return_mean": -248.02000000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 425.0169072320394, "num_env_steps_trained_throughput_per_sec": 425.0169072320394, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 9636.012, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9635.972, "sample_time_ms": 1303.414, "learn_time_ms": 8316.636, "learn_throughput": 480.964, "synch_weights_time_ms": 14.89}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-17-19", "timestamp": 1723645039, "time_this_iter_s": 9.414924144744873, "time_total_s": 904.812623500824, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8b6dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 904.812623500824, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 29.48461538461538, "ram_util_percent": 83.74615384615383}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5274782932190982, "cur_kl_coeff": 0.15204648971557616, "cur_lr": 0.009999999999999998, "total_loss": 0.39305637934979387, "policy_loss": 0.0002518206534207498, "vf_loss": 0.39280455867552305, "vf_explained_var": 0.0002478545620327904, "kl": -5.1805411083881365e-43, "entropy": 7.192139020772456e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.475362254832945, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.996210673498728, "policy_loss": 0.0035842058643028533, "vf_loss": 8.971678455796821, "vf_explained_var": -1.1164044576977927e-08, "kl": 0.008173580930515834, "entropy": 0.39898041258097955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 210.9999999999993, "episode_reward_min": -600.0, "episode_reward_mean": -258.055, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1928.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 1919.0}, "policy_reward_mean": {"prey_policy": -325.65749999999997, "predator_policy": 196.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-31.999999999999744, -386.79999999999995, 22.000000000000046, 27.20000000000013, 20.000000000000014, 10.999999999999963, -400.0, 33.50000000000024, -367.9, -395.8, -358.0, 20.600000000000023, -162.00000000000054, -400.0, -400.0, 20.000000000000014, 34.200000000000244, -400.0, -397.9, -395.8, 36.200000000000266, -400.0, -319.9, -180.00000000000065, -382.4, -381.0, -370.29999999999995, 24.50000000000008, 20.000000000000018, 18.39999999999999, 32.60000000000023, -569.7, -400.0, -359.4, -378.1, -180.00000000000068, -394.7, -391.6, 32.60000000000023, -400.0, -366.4, -365.8, -311.79999999999995, -380.2, -400.0, -53.000000000000014, 20.000000000000014, -400.0, -370.5, -330.1, -380.5, 20.000000000000018, -379.0, -400.0, 23.10000000000006, -600.0, -1.6999999999999869, -370.7, -400.0, 20.000000000000014, -400.0, -317.79999999999995, -349.6, -400.0, -377.8, 1.9999999999999876, -400.0, -600.0, -330.5, -401.0, -397.8, -400.0, -356.7, -365.9, -400.0, -361.6, -376.9, -400.0, 210.9999999999993, 39.1000000000003, 16.99999999999998, 20.000000000000014, -400.0, -359.4, -400.0, -394.1, -400.0, -379.9, 20.000000000000018, 32.60000000000023, -377.8, -404.0, -403.0, -394.7, 35.30000000000025, -400.0, 20.000000000000014, -197.49999999999991, -385.7, -393.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 20.000000000000014, -376.9, -397.9, 30.800000000000196, -374.8, 27.20000000000013, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 33.50000000000024, -400.0, -362.2, -393.7, -400.0, -395.8, -400.0, -358.0, -397.9, 33.50000000000024, 38.00000000000025, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -335.8, 20.000000000000014, -400.0, -400.0, -400.0, -397.9, -400.0, -395.8, -347.8, 20.000000000000014, -400.0, -400.0, -319.9, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -376.0, -343.3, -400.0, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 34.40000000000025, -400.0, 32.60000000000023, -400.0, -369.7, -400.0, -400.0, -400.0, -351.70000000000005, -393.7, -363.1, -400.0, -400.0, 20.000000000000014, -390.7, -400.0, -391.6, -400.0, -400.0, 32.60000000000023, -400.0, -400.0, -366.4, -400.0, -400.0, -347.8, -365.8, -274.0, -400.0, -362.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -368.5, -330.1, -400.0, -387.7, -380.8, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -369.7, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -253.00000000000003, -395.8, -400.0, -349.6, -400.0, -400.0, -365.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -364.3, -320.2, -400.0, -400.0, -400.0, -395.8, -400.0, -400.0, -333.7, -400.0, -400.0, -334.9, -400.0, -400.0, -395.8, -344.8, -376.9, -400.0, -400.0, -400.0, 20.000000000000014, -1928.0, -150.10000000000002, 27.20000000000013, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -357.7, -336.4, -400.0, -400.0, -376.9, -400.0, 20.000000000000014, -400.0, -400.0, 32.60000000000023, -400.0, -365.8, -400.0, -400.0, -400.0, -400.0, -390.7, -400.0, 35.30000000000025, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -197.49999999999991, -372.7, -400.0, -397.9, -392.8], "policy_predator_policy_reward": [148.0, 200.0, 189.0, 199.0, 175.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 199.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 172.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 184.0, 200.0, 195.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 185.0, 0.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 140.0, 188.0, 182.0, 200.0, 200.0, 200.0, 127.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 195.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 0.0, 163.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 133.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 183.0, 171.0, 199.0, 200.0, 198.0, 200.0, 200.0, 200.0, 177.0, 200.0, 169.0, 200.0, 200.0, 200.0, 181.0, 198.0, 200.0, 200.0, 200.0, 200.0, 1919.0, 200.0, 81.0, 81.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 123.0, 177.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 196.0, 200.0, 197.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 197.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5807245261522525, "mean_inference_ms": 1.8222350615899108, "mean_action_processing_ms": 0.24993114394736074, "mean_env_wait_ms": 0.19495714161347266, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003854990005493164, "StateBufferConnector_ms": 0.0035867691040039062, "ViewRequirementAgentConnector_ms": 0.09179878234863281}, "num_episodes": 18, "episode_return_max": 210.9999999999993, "episode_return_min": -600.0, "episode_return_mean": -258.055, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 417.0517972061096, "num_env_steps_trained_throughput_per_sec": 417.0517972061096, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 9659.14, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9659.101, "sample_time_ms": 1296.765, "learn_time_ms": 8346.731, "learn_throughput": 479.23, "synch_weights_time_ms": 14.572}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-17-29", "timestamp": 1723645049, "time_this_iter_s": 9.59571623802185, "time_total_s": 914.4083397388458, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d1af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 914.4083397388458, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 26.721428571428568, "ram_util_percent": 83.62857142857145}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.356038492257219, "cur_kl_coeff": 0.07602324485778808, "cur_lr": 0.009999999999999998, "total_loss": 1.4782768417130072, "policy_loss": 7.881354491310145e-05, "vf_loss": 1.4781980310482954, "vf_explained_var": 0.00011272824630535469, "kl": 8.818838115280137e-39, "entropy": 7.8306042676214e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8612594464705103, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.263220782759328, "policy_loss": 0.0035097684344109247, "vf_loss": 8.236232594585923, "vf_explained_var": 1.0128374452944156e-06, "kl": 0.009160910704865098, "entropy": 0.42807977562228205, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 210.9999999999993, "episode_reward_min": -600.0, "episode_reward_mean": -279.94899999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1928.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000026, "predator_policy": 1919.0}, "policy_reward_mean": {"prey_policy": -337.14450000000005, "predator_policy": 197.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-319.9, -180.00000000000065, -382.4, -381.0, -370.29999999999995, 24.50000000000008, 20.000000000000018, 18.39999999999999, 32.60000000000023, -569.7, -400.0, -359.4, -378.1, -180.00000000000068, -394.7, -391.6, 32.60000000000023, -400.0, -366.4, -365.8, -311.79999999999995, -380.2, -400.0, -53.000000000000014, 20.000000000000014, -400.0, -370.5, -330.1, -380.5, 20.000000000000018, -379.0, -400.0, 23.10000000000006, -600.0, -1.6999999999999869, -370.7, -400.0, 20.000000000000014, -400.0, -317.79999999999995, -349.6, -400.0, -377.8, 1.9999999999999876, -400.0, -600.0, -330.5, -401.0, -397.8, -400.0, -356.7, -365.9, -400.0, -361.6, -376.9, -400.0, 210.9999999999993, 39.1000000000003, 16.99999999999998, 20.000000000000014, -400.0, -359.4, -400.0, -394.1, -400.0, -379.9, 20.000000000000018, 32.60000000000023, -377.8, -404.0, -403.0, -394.7, 35.30000000000025, -400.0, 20.000000000000014, -197.49999999999991, -385.7, -393.7, -380.2, -383.29999999999995, -400.0, 20.000000000000018, -407.0, -24.000000000000036, -379.0, -404.0, -271.3000000000002, -396.7, -400.0, 28.500000000000156, -368.8, -400.0, 20.000000000000014, -360.5, -400.0, 27.200000000000134, -351.8, -400.0, -430.0, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-319.9, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -376.0, -343.3, -400.0, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 34.40000000000025, -400.0, 32.60000000000023, -400.0, -369.7, -400.0, -400.0, -400.0, -351.70000000000005, -393.7, -363.1, -400.0, -400.0, 20.000000000000014, -390.7, -400.0, -391.6, -400.0, -400.0, 32.60000000000023, -400.0, -400.0, -366.4, -400.0, -400.0, -347.8, -365.8, -274.0, -400.0, -362.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -368.5, -330.1, -400.0, -387.7, -380.8, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -369.7, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -253.00000000000003, -395.8, -400.0, -349.6, -400.0, -400.0, -365.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -364.3, -320.2, -400.0, -400.0, -400.0, -395.8, -400.0, -400.0, -333.7, -400.0, -400.0, -334.9, -400.0, -400.0, -395.8, -344.8, -376.9, -400.0, -400.0, -400.0, 20.000000000000014, -1928.0, -150.10000000000002, 27.20000000000013, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -357.7, -336.4, -400.0, -400.0, -376.9, -400.0, 20.000000000000014, -400.0, -400.0, 32.60000000000023, -400.0, -365.8, -400.0, -400.0, -400.0, -400.0, -390.7, -400.0, 35.30000000000025, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -197.49999999999991, -372.7, -400.0, -397.9, -392.8, -400.0, -362.2, -343.3, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -154.30000000000067, -400.0, -393.7, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -397.9, -400.0, -400.0, 36.20000000000025, -400.0, -340.3, -389.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 0.0, 200.0, 184.0, 200.0, 195.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 185.0, 0.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 140.0, 188.0, 182.0, 200.0, 200.0, 200.0, 127.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 195.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 0.0, 163.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 133.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 183.0, 171.0, 199.0, 200.0, 198.0, 200.0, 200.0, 200.0, 177.0, 200.0, 169.0, 200.0, 200.0, 200.0, 181.0, 198.0, 200.0, 200.0, 200.0, 200.0, 1919.0, 200.0, 81.0, 81.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 123.0, 177.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 196.0, 200.0, 197.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 197.0, 200.0, 182.0, 200.0, 160.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 156.0, 200.0, 200.0, 200.0, 196.0, 200.0, 83.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 199.0, 200.0, 200.0, 191.0, 200.0, 195.0, 183.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5798680536784022, "mean_inference_ms": 1.8214246522365278, "mean_action_processing_ms": 0.24900459669740418, "mean_env_wait_ms": 0.19460627348264484, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037816762924194336, "StateBufferConnector_ms": 0.003267526626586914, "ViewRequirementAgentConnector_ms": 0.09144306182861328}, "num_episodes": 22, "episode_return_max": 210.9999999999993, "episode_return_min": -600.0, "episode_return_mean": -279.94899999999996, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 423.7839216323309, "num_env_steps_trained_throughput_per_sec": 423.7839216323309, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 9647.975, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9647.935, "sample_time_ms": 1295.822, "learn_time_ms": 8336.741, "learn_throughput": 479.804, "synch_weights_time_ms": 14.42}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-17-39", "timestamp": 1723645059, "time_this_iter_s": 9.44456672668457, "time_total_s": 923.8529064655304, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d1b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 923.8529064655304, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 27.646153846153847, "ram_util_percent": 83.47692307692309}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8696065348035917, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": -0.00026481670066320077, "vf_loss": 1.3123681540053989, "vf_explained_var": 2.9672043664114814e-05, "kl": Infinity, "entropy": 5.648314576809341e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.924796785130387, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.987098952197524, "policy_loss": 0.0041701819672539985, "vf_loss": 7.955124185198829, "vf_explained_var": -7.151926636065125e-06, "kl": 0.010848919202329143, "entropy": 0.5122122776334879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 210.9999999999993, "episode_reward_min": -600.0, "episode_reward_mean": -275.079, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1928.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000026, "predator_policy": 1919.0}, "policy_reward_mean": {"prey_policy": -333.6045, "predator_policy": 196.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-366.4, -365.8, -311.79999999999995, -380.2, -400.0, -53.000000000000014, 20.000000000000014, -400.0, -370.5, -330.1, -380.5, 20.000000000000018, -379.0, -400.0, 23.10000000000006, -600.0, -1.6999999999999869, -370.7, -400.0, 20.000000000000014, -400.0, -317.79999999999995, -349.6, -400.0, -377.8, 1.9999999999999876, -400.0, -600.0, -330.5, -401.0, -397.8, -400.0, -356.7, -365.9, -400.0, -361.6, -376.9, -400.0, 210.9999999999993, 39.1000000000003, 16.99999999999998, 20.000000000000014, -400.0, -359.4, -400.0, -394.1, -400.0, -379.9, 20.000000000000018, 32.60000000000023, -377.8, -404.0, -403.0, -394.7, 35.30000000000025, -400.0, 20.000000000000014, -197.49999999999991, -385.7, -393.7, -380.2, -383.29999999999995, -400.0, 20.000000000000018, -407.0, -24.000000000000036, -379.0, -404.0, -271.3000000000002, -396.7, -400.0, 28.500000000000156, -368.8, -400.0, 20.000000000000014, -360.5, -400.0, 27.200000000000134, -351.8, -400.0, -430.0, -400.0, -400.0, -400.0, -251.50000000000077, 21.300000000000033, -278.099999999999, -353.20000000000005, -400.0, -31.80000000000002, -483.69999999999993, -400.0, 29.000000000000163, -114.40000000000077, 20.000000000000014, -386.5, 34.400000000000254, -383.49999999999966, -134.0000000000004, -180.00000000000065], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-366.4, -400.0, -400.0, -347.8, -365.8, -274.0, -400.0, -362.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -368.5, -330.1, -400.0, -387.7, -380.8, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -400.0, 35.30000000000025, -400.0, -369.7, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -253.00000000000003, -395.8, -400.0, -349.6, -400.0, -400.0, -365.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -364.3, -320.2, -400.0, -400.0, -400.0, -395.8, -400.0, -400.0, -333.7, -400.0, -400.0, -334.9, -400.0, -400.0, -395.8, -344.8, -376.9, -400.0, -400.0, -400.0, 20.000000000000014, -1928.0, -150.10000000000002, 27.20000000000013, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -357.7, -336.4, -400.0, -400.0, -376.9, -400.0, 20.000000000000014, -400.0, -400.0, 32.60000000000023, -400.0, -365.8, -400.0, -400.0, -400.0, -400.0, -390.7, -400.0, 35.30000000000025, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -197.49999999999991, -372.7, -400.0, -397.9, -392.8, -400.0, -362.2, -343.3, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -154.30000000000067, -400.0, -393.7, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -397.9, -400.0, -400.0, 36.20000000000025, -400.0, -340.3, -389.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -116.50000000000077, 20.000000000000014, -372.7, -276.099999999999, -400.0, -350.8, -366.4, -400.0, -400.0, 20.000000000000014, -389.8, -309.7, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, -114.40000000000077, -400.0, -400.0, 20.000000000000014, -400.0, -341.5, -400.0, 34.400000000000254, -400.0, -368.49999999999966, 20.000000000000014, -331.0, 20.000000000000014, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 182.0, 200.0, 140.0, 188.0, 182.0, 200.0, 200.0, 200.0, 127.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 195.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 0.0, 163.0, 200.0, 200.0, 199.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 133.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 183.0, 171.0, 199.0, 200.0, 198.0, 200.0, 200.0, 200.0, 177.0, 200.0, 169.0, 200.0, 200.0, 200.0, 181.0, 198.0, 200.0, 200.0, 200.0, 200.0, 1919.0, 200.0, 81.0, 81.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 123.0, 177.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 196.0, 200.0, 197.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 197.0, 200.0, 182.0, 200.0, 160.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 156.0, 200.0, 200.0, 200.0, 196.0, 200.0, 83.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 199.0, 200.0, 200.0, 191.0, 200.0, 195.0, 183.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 187.0, 187.0, 198.0, 200.0, 184.0, 180.0, 200.0, 200.0, 196.0, 142.0, 200.0, 26.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 200.0, 185.0, 200.0, 174.0, 3.0, 200.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5790231222837118, "mean_inference_ms": 1.817714015634063, "mean_action_processing_ms": 0.24896256942030032, "mean_env_wait_ms": 0.194289255044001, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037894248962402344, "StateBufferConnector_ms": 0.0032706260681152344, "ViewRequirementAgentConnector_ms": 0.0912022590637207}, "num_episodes": 18, "episode_return_max": 210.9999999999993, "episode_return_min": -600.0, "episode_return_mean": -275.079, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 422.7138509731263, "num_env_steps_trained_throughput_per_sec": 422.7138509731263, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 9653.071, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9653.029, "sample_time_ms": 1292.136, "learn_time_ms": 8345.526, "learn_throughput": 479.299, "synch_weights_time_ms": 14.419}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-17-48", "timestamp": 1723645068, "time_this_iter_s": 9.466915130615234, "time_total_s": 933.3198215961456, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 933.3198215961456, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 30.33076923076923, "ram_util_percent": 83.56153846153848}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2290828990814076, "cur_kl_coeff": 0.05701743364334108, "cur_lr": 0.009999999999999998, "total_loss": 1.0198882574442203, "policy_loss": -0.00010280298495975633, "vf_loss": 1.0199910597038018, "vf_explained_var": 0.0006771650894609078, "kl": -3.053627531472309e-39, "entropy": 4.9102489704249284e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.171641545249987, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.565874955767677, "policy_loss": 0.0036922167236399317, "vf_loss": 8.534454415336487, "vf_explained_var": -1.679239449677644e-05, "kl": 0.010819165444873428, "entropy": 0.5838422271625074, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 210.9999999999993, "episode_reward_min": -600.0, "episode_reward_mean": -263.503, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1928.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 1919.0}, "policy_reward_mean": {"prey_policy": -329.2715, "predator_policy": 197.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -377.8, 1.9999999999999876, -400.0, -600.0, -330.5, -401.0, -397.8, -400.0, -356.7, -365.9, -400.0, -361.6, -376.9, -400.0, 210.9999999999993, 39.1000000000003, 16.99999999999998, 20.000000000000014, -400.0, -359.4, -400.0, -394.1, -400.0, -379.9, 20.000000000000018, 32.60000000000023, -377.8, -404.0, -403.0, -394.7, 35.30000000000025, -400.0, 20.000000000000014, -197.49999999999991, -385.7, -393.7, -380.2, -383.29999999999995, -400.0, 20.000000000000018, -407.0, -24.000000000000036, -379.0, -404.0, -271.3000000000002, -396.7, -400.0, 28.500000000000156, -368.8, -400.0, 20.000000000000014, -360.5, -400.0, 27.200000000000134, -351.8, -400.0, -430.0, -400.0, -400.0, -400.0, -251.50000000000077, 21.300000000000033, -278.099999999999, -353.20000000000005, -400.0, -31.80000000000002, -483.69999999999993, -400.0, 29.000000000000163, -114.40000000000077, 20.000000000000014, -386.5, 34.400000000000254, -383.49999999999966, -134.0000000000004, -180.00000000000065, -396.7, -371.8, 20.000000000000014, 7.549516567451064e-15, 20.000000000000014, -400.0, -393.7, 38.000000000000256, -397.8, -221.1000000000004, -401.0, 20.000000000000018, -93.10000000000004, -57.299999999999976, -364.7, -356.1, 24.50000000000008, -400.0, -400.0, -360.6, -44.999999999999744, -400.0, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -365.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -364.3, -320.2, -400.0, -400.0, -400.0, -395.8, -400.0, -400.0, -333.7, -400.0, -400.0, -334.9, -400.0, -400.0, -395.8, -344.8, -376.9, -400.0, -400.0, -400.0, 20.000000000000014, -1928.0, -150.10000000000002, 27.20000000000013, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -357.7, -336.4, -400.0, -400.0, -376.9, -400.0, 20.000000000000014, -400.0, -400.0, 32.60000000000023, -400.0, -365.8, -400.0, -400.0, -400.0, -400.0, -390.7, -400.0, 35.30000000000025, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -197.49999999999991, -372.7, -400.0, -397.9, -392.8, -400.0, -362.2, -343.3, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -154.30000000000067, -400.0, -393.7, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -397.9, -400.0, -400.0, 36.20000000000025, -400.0, -340.3, -389.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -116.50000000000077, 20.000000000000014, -372.7, -276.099999999999, -400.0, -350.8, -366.4, -400.0, -400.0, 20.000000000000014, -389.8, -309.7, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, -114.40000000000077, -400.0, -400.0, 20.000000000000014, -400.0, -341.5, -400.0, 34.400000000000254, -400.0, -368.49999999999966, 20.000000000000014, -331.0, 20.000000000000014, -400.0, -400.0, -393.7, -356.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -393.7, -400.0, 38.000000000000256, -395.8, -400.0, -66.10000000000004, -400.0, -395.8, -341.2, 20.000000000000014, -400.0, -93.40000000000003, -393.7, -400.0, 22.700000000000053, -400.0, -363.7, -584.0, -360.1, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -358.6, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 188.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 183.0, 171.0, 199.0, 200.0, 198.0, 200.0, 200.0, 200.0, 177.0, 200.0, 169.0, 200.0, 200.0, 200.0, 181.0, 198.0, 200.0, 200.0, 200.0, 200.0, 1919.0, 200.0, 81.0, 81.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 123.0, 177.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 196.0, 200.0, 197.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 197.0, 200.0, 182.0, 200.0, 160.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 156.0, 200.0, 200.0, 200.0, 196.0, 200.0, 83.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 199.0, 200.0, 200.0, 191.0, 200.0, 195.0, 183.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 187.0, 187.0, 198.0, 200.0, 184.0, 180.0, 200.0, 200.0, 196.0, 142.0, 200.0, 26.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 200.0, 185.0, 200.0, 174.0, 3.0, 200.0, 0.0, 197.0, 200.0, 200.0, 185.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 195.0, 50.0, 138.0, 198.0, 200.0, 200.0, 197.0, 197.0, 200.0, 120.0, 200.0, 199.0, 181.0, 407.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 135.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5780048504975986, "mean_inference_ms": 1.8149847687191636, "mean_action_processing_ms": 0.24842429293925933, "mean_env_wait_ms": 0.19390625166173273, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003758549690246582, "StateBufferConnector_ms": 0.0032755136489868164, "ViewRequirementAgentConnector_ms": 0.09023582935333252}, "num_episodes": 23, "episode_return_max": 210.9999999999993, "episode_return_min": -600.0, "episode_return_mean": -263.503, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 427.0905248169061, "num_env_steps_trained_throughput_per_sec": 427.0905248169061, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 9578.722, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9578.68, "sample_time_ms": 1274.002, "learn_time_ms": 8289.632, "learn_throughput": 482.53, "synch_weights_time_ms": 14.078}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-17-57", "timestamp": 1723645077, "time_this_iter_s": 9.378648042678833, "time_total_s": 942.6984696388245, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ad280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 942.6984696388245, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 27.64285714285715, "ram_util_percent": 83.68571428571431}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8689691550083576, "cur_kl_coeff": 0.02850871682167054, "cur_lr": 0.009999999999999998, "total_loss": 1.0564437644349205, "policy_loss": 0.0001404545904339227, "vf_loss": 1.0563033118607505, "vf_explained_var": 0.00023715988038078186, "kl": -9.520728839902288e-38, "entropy": 1.8686921381972327e-34, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9243625219457994, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.761858879826056, "policy_loss": 0.002560996910971072, "vf_loss": 8.733708406630017, "vf_explained_var": -7.336953329661536e-06, "kl": 0.009984623765335777, "entropy": 0.5772206474233557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 38.000000000000256, "episode_reward_min": -483.69999999999993, "episode_reward_mean": -262.85900000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 1709.0}, "policy_reward_mean": {"prey_policy": -328.66949999999997, "predator_policy": 197.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.000000000000014, -400.0, -359.4, -400.0, -394.1, -400.0, -379.9, 20.000000000000018, 32.60000000000023, -377.8, -404.0, -403.0, -394.7, 35.30000000000025, -400.0, 20.000000000000014, -197.49999999999991, -385.7, -393.7, -380.2, -383.29999999999995, -400.0, 20.000000000000018, -407.0, -24.000000000000036, -379.0, -404.0, -271.3000000000002, -396.7, -400.0, 28.500000000000156, -368.8, -400.0, 20.000000000000014, -360.5, -400.0, 27.200000000000134, -351.8, -400.0, -430.0, -400.0, -400.0, -400.0, -251.50000000000077, 21.300000000000033, -278.099999999999, -353.20000000000005, -400.0, -31.80000000000002, -483.69999999999993, -400.0, 29.000000000000163, -114.40000000000077, 20.000000000000014, -386.5, 34.400000000000254, -383.49999999999966, -134.0000000000004, -180.00000000000065, -396.7, -371.8, 20.000000000000014, 7.549516567451064e-15, 20.000000000000014, -400.0, -393.7, 38.000000000000256, -397.8, -221.1000000000004, -401.0, 20.000000000000018, -93.10000000000004, -57.299999999999976, -364.7, -356.1, 24.50000000000008, -400.0, -400.0, -360.6, -44.999999999999744, -400.0, -400.0, -365.09999999999997, -400.0, -383.7, -388.7, -336.8, 20.000000000000018, -374.7, -400.0, -3.9999999999999236, -380.7, 5.999999999999957, -83.20000000000118, -400.0, -199.29999999999998, -400.0, -379.8, -400.0, -364.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 20.000000000000014, -400.0, -400.0, -400.0, -336.4, -400.0, -400.0, -357.7, -336.4, -400.0, -400.0, -376.9, -400.0, 20.000000000000014, -400.0, -400.0, 32.60000000000023, -400.0, -365.8, -400.0, -400.0, -400.0, -400.0, -390.7, -400.0, 35.30000000000025, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -197.49999999999991, -372.7, -400.0, -397.9, -392.8, -400.0, -362.2, -343.3, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -154.30000000000067, -400.0, -393.7, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -397.9, -400.0, -400.0, 36.20000000000025, -400.0, -340.3, -389.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -116.50000000000077, 20.000000000000014, -372.7, -276.099999999999, -400.0, -350.8, -366.4, -400.0, -400.0, 20.000000000000014, -389.8, -309.7, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, -114.40000000000077, -400.0, -400.0, 20.000000000000014, -400.0, -341.5, -400.0, 34.400000000000254, -400.0, -368.49999999999966, 20.000000000000014, -331.0, 20.000000000000014, -400.0, -400.0, -393.7, -356.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -393.7, -400.0, 38.000000000000256, -395.8, -400.0, -66.10000000000004, -400.0, -395.8, -341.2, 20.000000000000014, -400.0, -93.40000000000003, -393.7, -400.0, 22.700000000000053, -400.0, -363.7, -584.0, -360.1, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -358.6, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -362.2, -397.9, -400.0, -400.0, -400.0, -372.7, -381.7, -400.0, -346.0, -353.8, 20.000000000000014, -400.0, -400.0, -360.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -369.7, -400.0, 20.000000000000014, -183.70000000000059, -11.500000000000007, -400.0, -400.0, -1744.0, -364.29999999999995, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, -400.0, -345.7], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 123.0, 177.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 196.0, 200.0, 197.0, 200.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 197.0, 200.0, 182.0, 200.0, 160.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 156.0, 200.0, 200.0, 200.0, 196.0, 200.0, 83.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 199.0, 200.0, 200.0, 191.0, 200.0, 195.0, 183.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 187.0, 187.0, 198.0, 200.0, 184.0, 180.0, 200.0, 200.0, 196.0, 142.0, 200.0, 26.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 200.0, 185.0, 200.0, 174.0, 3.0, 200.0, 0.0, 197.0, 200.0, 200.0, 185.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 195.0, 50.0, 138.0, 198.0, 200.0, 200.0, 197.0, 197.0, 200.0, 120.0, 200.0, 199.0, 181.0, 407.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 135.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 189.0, 200.0, 193.0, 191.0, 172.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 176.0, 200.0, 200.0, 189.0, 186.0, 200.0, 15.0, 97.0, 200.0, 200.0, 200.0, 1709.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 181.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5771759913678998, "mean_inference_ms": 1.8125463856790316, "mean_action_processing_ms": 0.2479908135529294, "mean_env_wait_ms": 0.1936204633320753, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003703594207763672, "StateBufferConnector_ms": 0.0032777786254882812, "ViewRequirementAgentConnector_ms": 0.08972322940826416}, "num_episodes": 18, "episode_return_max": 38.000000000000256, "episode_return_min": -483.69999999999993, "episode_return_mean": -262.85900000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.404813038582, "num_env_steps_trained_throughput_per_sec": 416.404813038582, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 9595.954, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9595.913, "sample_time_ms": 1273.356, "learn_time_ms": 8307.819, "learn_throughput": 481.474, "synch_weights_time_ms": 13.773}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-18-07", "timestamp": 1723645087, "time_this_iter_s": 9.61048698425293, "time_total_s": 952.3089566230774, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187433a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 952.3089566230774, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 28.02307692307693, "ram_util_percent": 83.45384615384614}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2243654334838823, "cur_kl_coeff": 0.01425435841083527, "cur_lr": 0.009999999999999998, "total_loss": 0.3675125859162854, "policy_loss": -6.176749239404681e-05, "vf_loss": 0.367574352990847, "vf_explained_var": 0.012492038995500596, "kl": 6.301894843698252e-38, "entropy": 2.8397165211076907e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2413600378724, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.095660186696936, "policy_loss": 0.002907174723419957, "vf_loss": 8.067153667520595, "vf_explained_var": -1.4696171674778853e-08, "kl": 0.009988464310631778, "entropy": 0.578076462550138, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 65.40000000000013, "episode_reward_min": -483.69999999999993, "episode_reward_mean": -251.27, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.600000000000236, "predator_policy": 1709.0}, "policy_reward_mean": {"prey_policy": -322.2, "predator_policy": 196.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-393.7, -380.2, -383.29999999999995, -400.0, 20.000000000000018, -407.0, -24.000000000000036, -379.0, -404.0, -271.3000000000002, -396.7, -400.0, 28.500000000000156, -368.8, -400.0, 20.000000000000014, -360.5, -400.0, 27.200000000000134, -351.8, -400.0, -430.0, -400.0, -400.0, -400.0, -251.50000000000077, 21.300000000000033, -278.099999999999, -353.20000000000005, -400.0, -31.80000000000002, -483.69999999999993, -400.0, 29.000000000000163, -114.40000000000077, 20.000000000000014, -386.5, 34.400000000000254, -383.49999999999966, -134.0000000000004, -180.00000000000065, -396.7, -371.8, 20.000000000000014, 7.549516567451064e-15, 20.000000000000014, -400.0, -393.7, 38.000000000000256, -397.8, -221.1000000000004, -401.0, 20.000000000000018, -93.10000000000004, -57.299999999999976, -364.7, -356.1, 24.50000000000008, -400.0, -400.0, -360.6, -44.999999999999744, -400.0, -400.0, -365.09999999999997, -400.0, -383.7, -388.7, -336.8, 20.000000000000018, -374.7, -400.0, -3.9999999999999236, -380.7, 5.999999999999957, -83.20000000000118, -400.0, -199.29999999999998, -400.0, -379.8, -400.0, -364.7, -386.8, 65.40000000000013, -388.7, -376.9, 17.99999999999999, -348.1, -2.9999999999999414, -369.0, -374.7, -391.6, 13.199999999999958, 29.000000000000163, -409.00000000000006, 25.300000000000097, -365.9, 20.000000000000018, -402.0, 35.50000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-397.9, -392.8, -400.0, -362.2, -343.3, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -379.0, -400.0, -400.0, -154.30000000000067, -400.0, -393.7, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -397.9, -400.0, -400.0, 36.20000000000025, -400.0, -340.3, -389.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -116.50000000000077, 20.000000000000014, -372.7, -276.099999999999, -400.0, -350.8, -366.4, -400.0, -400.0, 20.000000000000014, -389.8, -309.7, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, -114.40000000000077, -400.0, -400.0, 20.000000000000014, -400.0, -341.5, -400.0, 34.400000000000254, -400.0, -368.49999999999966, 20.000000000000014, -331.0, 20.000000000000014, -400.0, -400.0, -393.7, -356.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -393.7, -400.0, 38.000000000000256, -395.8, -400.0, -66.10000000000004, -400.0, -395.8, -341.2, 20.000000000000014, -400.0, -93.40000000000003, -393.7, -400.0, 22.700000000000053, -400.0, -363.7, -584.0, -360.1, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -358.6, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -362.2, -397.9, -400.0, -400.0, -400.0, -372.7, -381.7, -400.0, -346.0, -353.8, 20.000000000000014, -400.0, -400.0, -360.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -369.7, -400.0, 20.000000000000014, -183.70000000000059, -11.500000000000007, -400.0, -400.0, -1744.0, -364.29999999999995, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, -400.0, -345.7, -379.0, -395.8, 41.600000000000236, -314.2, -383.8, -397.9, -376.9, -400.0, 20.000000000000014, -400.0, -318.1, -400.0, 20.000000000000014, -400.0, -358.0, -400.0, -400.0, -351.7, -391.6, -400.0, -389.8, 20.000000000000014, 29.000000000000163, -400.0, -395.8, -383.2, -400.0, 26.300000000000114, -334.9, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 35.30000000000026, -353.8], "policy_predator_policy_reward": [197.0, 200.0, 182.0, 200.0, 160.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 156.0, 200.0, 200.0, 200.0, 196.0, 200.0, 83.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 199.0, 200.0, 200.0, 191.0, 200.0, 195.0, 183.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 187.0, 187.0, 198.0, 200.0, 184.0, 180.0, 200.0, 200.0, 196.0, 142.0, 200.0, 26.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 200.0, 185.0, 200.0, 174.0, 3.0, 200.0, 0.0, 197.0, 200.0, 200.0, 185.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 195.0, 50.0, 138.0, 198.0, 200.0, 200.0, 197.0, 197.0, 200.0, 120.0, 200.0, 199.0, 181.0, 407.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 135.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 189.0, 200.0, 193.0, 191.0, 172.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 176.0, 200.0, 200.0, 189.0, 186.0, 200.0, 15.0, 97.0, 200.0, 200.0, 200.0, 1709.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 181.0, 190.0, 198.0, 169.0, 169.0, 199.0, 194.0, 200.0, 200.0, 198.0, 200.0, 200.0, 170.0, 200.0, 177.0, 200.0, 189.0, 200.0, 177.0, 200.0, 200.0, 196.0, 187.0, 200.0, 200.0, 200.0, 170.0, 199.0, 200.0, 200.0, 169.0, 200.0, 200.0, 200.0, 198.0, 170.0, 184.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5763977765629074, "mean_inference_ms": 1.8103432607865804, "mean_action_processing_ms": 0.24759401515948887, "mean_env_wait_ms": 0.19335736637861076, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003695249557495117, "StateBufferConnector_ms": 0.0030976533889770508, "ViewRequirementAgentConnector_ms": 0.0894172191619873}, "num_episodes": 18, "episode_return_max": 65.40000000000013, "episode_return_min": -483.69999999999993, "episode_return_mean": -251.27, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 431.04669904489583, "num_env_steps_trained_throughput_per_sec": 431.04669904489583, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 9563.308, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9563.267, "sample_time_ms": 1266.786, "learn_time_ms": 8282.144, "learn_throughput": 482.967, "synch_weights_time_ms": 13.266}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-18-16", "timestamp": 1723645096, "time_this_iter_s": 9.318341970443726, "time_total_s": 961.6272985935211, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae493a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 961.6272985935211, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 28.96923076923077, "ram_util_percent": 83.28461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3047150560521654, "cur_kl_coeff": 0.007127179205417635, "cur_lr": 0.009999999999999998, "total_loss": 1.0829591005528099, "policy_loss": -0.00028024854522848885, "vf_loss": 1.083239349383841, "vf_explained_var": 0.0002037901411611567, "kl": -1.4185209740736218e-39, "entropy": 3.3783134736207315e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.371929762721377, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.471596380516335, "policy_loss": 0.003083149078376, "vf_loss": 8.451409897223982, "vf_explained_var": -6.216859060620505e-07, "kl": 0.006673459363014309, "entropy": 0.42092863367821176, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 65.40000000000013, "episode_reward_min": -483.69999999999993, "episode_reward_mean": -247.002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.600000000000236, "predator_policy": 1709.0}, "policy_reward_mean": {"prey_policy": -318.39599999999996, "predator_policy": 194.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -251.50000000000077, 21.300000000000033, -278.099999999999, -353.20000000000005, -400.0, -31.80000000000002, -483.69999999999993, -400.0, 29.000000000000163, -114.40000000000077, 20.000000000000014, -386.5, 34.400000000000254, -383.49999999999966, -134.0000000000004, -180.00000000000065, -396.7, -371.8, 20.000000000000014, 7.549516567451064e-15, 20.000000000000014, -400.0, -393.7, 38.000000000000256, -397.8, -221.1000000000004, -401.0, 20.000000000000018, -93.10000000000004, -57.299999999999976, -364.7, -356.1, 24.50000000000008, -400.0, -400.0, -360.6, -44.999999999999744, -400.0, -400.0, -365.09999999999997, -400.0, -383.7, -388.7, -336.8, 20.000000000000018, -374.7, -400.0, -3.9999999999999236, -380.7, 5.999999999999957, -83.20000000000118, -400.0, -199.29999999999998, -400.0, -379.8, -400.0, -364.7, -386.8, 65.40000000000013, -388.7, -376.9, 17.99999999999999, -348.1, -2.9999999999999414, -369.0, -374.7, -391.6, 13.199999999999958, 29.000000000000163, -409.00000000000006, 25.300000000000097, -365.9, 20.000000000000018, -402.0, 35.50000000000024, 25.300000000000097, -356.1, -164.70000000000056, -338.8, -376.9, -400.0, 30.700000000000195, -352.6, -73.80000000000061, -400.0, 20.000000000000018, -390.1, -333.6, -180.00000000000065, -400.0, 20.000000000000018, -377.6, -400.0, -400.0, -400.0, -379.6, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -116.50000000000077, 20.000000000000014, -372.7, -276.099999999999, -400.0, -350.8, -366.4, -400.0, -400.0, 20.000000000000014, -389.8, -309.7, -400.0, -400.0, -400.0, 29.000000000000163, -400.0, -114.40000000000077, -400.0, -400.0, 20.000000000000014, -400.0, -341.5, -400.0, 34.400000000000254, -400.0, -368.49999999999966, 20.000000000000014, -331.0, 20.000000000000014, -400.0, -400.0, -393.7, -356.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -393.7, -400.0, 38.000000000000256, -395.8, -400.0, -66.10000000000004, -400.0, -395.8, -341.2, 20.000000000000014, -400.0, -93.40000000000003, -393.7, -400.0, 22.700000000000053, -400.0, -363.7, -584.0, -360.1, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -358.6, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -362.2, -397.9, -400.0, -400.0, -400.0, -372.7, -381.7, -400.0, -346.0, -353.8, 20.000000000000014, -400.0, -400.0, -360.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -369.7, -400.0, 20.000000000000014, -183.70000000000059, -11.500000000000007, -400.0, -400.0, -1744.0, -364.29999999999995, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, -400.0, -345.7, -379.0, -395.8, 41.600000000000236, -314.2, -383.8, -397.9, -376.9, -400.0, 20.000000000000014, -400.0, -318.1, -400.0, 20.000000000000014, -400.0, -358.0, -400.0, -400.0, -351.7, -391.6, -400.0, -389.8, 20.000000000000014, 29.000000000000163, -400.0, -395.8, -383.2, -400.0, 26.300000000000114, -334.9, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 35.30000000000026, -353.8, -351.7, 20.000000000000014, -400.0, -330.1, 35.30000000000025, -400.0, -338.8, -400.0, -400.0, -376.9, -400.0, -400.0, 31.700000000000212, -400.0, -345.7, -376.9, 20.000000000000014, -386.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -381.1, -385.0, -340.6, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -364.6, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 187.0, 187.0, 198.0, 200.0, 184.0, 180.0, 200.0, 200.0, 196.0, 142.0, 200.0, 26.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 200.0, 185.0, 200.0, 174.0, 3.0, 200.0, 0.0, 197.0, 200.0, 200.0, 185.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 195.0, 50.0, 138.0, 198.0, 200.0, 200.0, 197.0, 197.0, 200.0, 120.0, 200.0, 199.0, 181.0, 407.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 135.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 189.0, 200.0, 193.0, 191.0, 172.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 176.0, 200.0, 200.0, 189.0, 186.0, 200.0, 15.0, 97.0, 200.0, 200.0, 200.0, 1709.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 181.0, 190.0, 198.0, 169.0, 169.0, 199.0, 194.0, 200.0, 200.0, 198.0, 200.0, 200.0, 170.0, 200.0, 177.0, 200.0, 189.0, 200.0, 177.0, 200.0, 200.0, 196.0, 187.0, 200.0, 200.0, 200.0, 170.0, 199.0, 200.0, 200.0, 169.0, 200.0, 200.0, 200.0, 198.0, 170.0, 184.0, 174.0, 183.0, 200.0, 174.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 181.0, 189.0, 98.0, 195.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 195.0, 197.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5756098840628971, "mean_inference_ms": 1.8079442530773242, "mean_action_processing_ms": 0.24717610753223163, "mean_env_wait_ms": 0.1930766295690961, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038111209869384766, "StateBufferConnector_ms": 0.0031815767288208008, "ViewRequirementAgentConnector_ms": 0.09242010116577148}, "num_episodes": 22, "episode_return_max": 65.40000000000013, "episode_return_min": -483.69999999999993, "episode_return_mean": -247.002, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.71412178748716, "num_env_steps_trained_throughput_per_sec": 409.71412178748716, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 9554.856, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9554.818, "sample_time_ms": 1267.905, "learn_time_ms": 8272.134, "learn_throughput": 483.551, "synch_weights_time_ms": 13.72}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-18-26", "timestamp": 1723645106, "time_this_iter_s": 9.767362117767334, "time_total_s": 971.3946607112885, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d6040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 971.3946607112885, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 29.95, "ram_util_percent": 83.47142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4130904967931133, "cur_kl_coeff": 0.0035635896027088176, "cur_lr": 0.009999999999999998, "total_loss": 1.1652533992178857, "policy_loss": -6.362015662330484e-05, "vf_loss": 1.1653170198990555, "vf_explained_var": 0.0008812694637863724, "kl": -3.5201067646948863e-38, "entropy": 3.5422855720965576e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5467034086900413, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.018542148953392, "policy_loss": 0.003865332171325843, "vf_loss": 7.993231871266844, "vf_explained_var": -3.1526126558818515e-06, "kl": 0.008367488230420345, "entropy": 0.4180863071607534, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 65.40000000000013, "episode_reward_min": -552.0, "episode_reward_mean": -250.82800000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.600000000000236, "predator_policy": 1709.0}, "policy_reward_mean": {"prey_policy": -320.634, "predator_policy": 195.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.000000000000014, -400.0, -393.7, 38.000000000000256, -397.8, -221.1000000000004, -401.0, 20.000000000000018, -93.10000000000004, -57.299999999999976, -364.7, -356.1, 24.50000000000008, -400.0, -400.0, -360.6, -44.999999999999744, -400.0, -400.0, -365.09999999999997, -400.0, -383.7, -388.7, -336.8, 20.000000000000018, -374.7, -400.0, -3.9999999999999236, -380.7, 5.999999999999957, -83.20000000000118, -400.0, -199.29999999999998, -400.0, -379.8, -400.0, -364.7, -386.8, 65.40000000000013, -388.7, -376.9, 17.99999999999999, -348.1, -2.9999999999999414, -369.0, -374.7, -391.6, 13.199999999999958, 29.000000000000163, -409.00000000000006, 25.300000000000097, -365.9, 20.000000000000018, -402.0, 35.50000000000024, 25.300000000000097, -356.1, -164.70000000000056, -338.8, -376.9, -400.0, 30.700000000000195, -352.6, -73.80000000000061, -400.0, 20.000000000000018, -390.1, -333.6, -180.00000000000065, -400.0, 20.000000000000018, -377.6, -400.0, -400.0, -400.0, -379.6, -400.0, -337.8, -397.8, 7.999999999999961, -265.6, -357.0, 20.000000000000018, -400.0, -271.3, -393.4, 2.90000000000013, 23.10000000000006, -0.999999999999972, 10.999999999999963, -407.0, -400.0, -158.90000000000055, -72.69999999999987, -400.0, -521.0, -380.7, -552.0, 28.100000000000144, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 20.000000000000014, -400.0, -400.0, -400.0, -393.7, -400.0, 38.000000000000256, -395.8, -400.0, -66.10000000000004, -400.0, -395.8, -341.2, 20.000000000000014, -400.0, -93.40000000000003, -393.7, -400.0, 22.700000000000053, -400.0, -363.7, -584.0, -360.1, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -358.6, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -362.2, -397.9, -400.0, -400.0, -400.0, -372.7, -381.7, -400.0, -346.0, -353.8, 20.000000000000014, -400.0, -400.0, -360.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -369.7, -400.0, 20.000000000000014, -183.70000000000059, -11.500000000000007, -400.0, -400.0, -1744.0, -364.29999999999995, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, -400.0, -345.7, -379.0, -395.8, 41.600000000000236, -314.2, -383.8, -397.9, -376.9, -400.0, 20.000000000000014, -400.0, -318.1, -400.0, 20.000000000000014, -400.0, -358.0, -400.0, -400.0, -351.7, -391.6, -400.0, -389.8, 20.000000000000014, 29.000000000000163, -400.0, -395.8, -383.2, -400.0, 26.300000000000114, -334.9, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 35.30000000000026, -353.8, -351.7, 20.000000000000014, -400.0, -330.1, 35.30000000000025, -400.0, -338.8, -400.0, -400.0, -376.9, -400.0, -400.0, 31.700000000000212, -400.0, -345.7, -376.9, 20.000000000000014, -386.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -381.1, -385.0, -340.6, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -364.6, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -400.0, -362.2, -340.6, -400.0, -395.8, -400.0, 20.000000000000014, -400.0, -265.6, -331.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -154.30000000000055, -400.0, -387.4, 2.90000000000013, -400.0, 28.100000000000147, -379.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.90000000000003, -368.8, -400.0, 35.30000000000026, -400.0, -400.0, -400.0, -400.0, -369.7, -400.0, -400.0, -373.0, -400.0, 28.100000000000147, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 195.0, 50.0, 138.0, 198.0, 200.0, 200.0, 197.0, 197.0, 200.0, 120.0, 200.0, 199.0, 181.0, 407.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 135.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 189.0, 200.0, 193.0, 191.0, 172.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 176.0, 200.0, 200.0, 189.0, 186.0, 200.0, 15.0, 97.0, 200.0, 200.0, 200.0, 1709.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 181.0, 190.0, 198.0, 169.0, 169.0, 199.0, 194.0, 200.0, 200.0, 198.0, 200.0, 200.0, 170.0, 200.0, 177.0, 200.0, 189.0, 200.0, 177.0, 200.0, 200.0, 196.0, 187.0, 200.0, 200.0, 200.0, 170.0, 199.0, 200.0, 200.0, 169.0, 200.0, 200.0, 200.0, 198.0, 170.0, 184.0, 174.0, 183.0, 200.0, 174.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 181.0, 189.0, 98.0, 195.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 195.0, 197.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 178.0, 187.0, 200.0, 198.0, 200.0, 188.0, 200.0, 200.0, 200.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 83.0, 194.0, 200.0, 200.0, 200.0, 190.0, 184.0, 200.0, 179.0, 200.0, 191.0, 200.0, 193.0, 200.0, 200.0, 189.0, 0.0, 92.0, 200.0, 200.0, 200.0, 200.0, 79.0, 189.0, 200.0, 200.0, 21.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5749324124117076, "mean_inference_ms": 1.8110899131517737, "mean_action_processing_ms": 0.2472404280001728, "mean_env_wait_ms": 0.1927616041410781, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039061307907104492, "StateBufferConnector_ms": 0.0032030344009399414, "ViewRequirementAgentConnector_ms": 0.09379279613494873}, "num_episodes": 23, "episode_return_max": 65.40000000000013, "episode_return_min": -552.0, "episode_return_mean": -250.82800000000006, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 436.30492945146483, "num_env_steps_trained_throughput_per_sec": 436.30492945146483, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 9496.587, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9496.548, "sample_time_ms": 1264.988, "learn_time_ms": 8217.082, "learn_throughput": 486.791, "synch_weights_time_ms": 13.487}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-18-35", "timestamp": 1723645115, "time_this_iter_s": 9.17310881614685, "time_total_s": 980.5677695274353, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d14c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 980.5677695274353, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 28.876923076923074, "ram_util_percent": 83.42307692307692}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6934671073797203, "cur_kl_coeff": 0.0017817948013544088, "cur_lr": 0.009999999999999998, "total_loss": 1.1157464217335458, "policy_loss": 0.00014506905664882016, "vf_loss": 1.1156013585508815, "vf_explained_var": 0.0002467364230483928, "kl": 7.642977621258105e-38, "entropy": 2.764797742245561e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.22669845036571, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.060109640555407, "policy_loss": 0.0036111328073299277, "vf_loss": 8.037099414653879, "vf_explained_var": -1.5169224411091477e-08, "kl": 0.007569225767635289, "entropy": 0.37830909003341007, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 65.40000000000013, "episode_reward_min": -553.8, "episode_reward_mean": -248.74200000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.600000000000236, "predator_policy": 1709.0}, "policy_reward_mean": {"prey_policy": -317.49100000000004, "predator_policy": 193.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -365.09999999999997, -400.0, -383.7, -388.7, -336.8, 20.000000000000018, -374.7, -400.0, -3.9999999999999236, -380.7, 5.999999999999957, -83.20000000000118, -400.0, -199.29999999999998, -400.0, -379.8, -400.0, -364.7, -386.8, 65.40000000000013, -388.7, -376.9, 17.99999999999999, -348.1, -2.9999999999999414, -369.0, -374.7, -391.6, 13.199999999999958, 29.000000000000163, -409.00000000000006, 25.300000000000097, -365.9, 20.000000000000018, -402.0, 35.50000000000024, 25.300000000000097, -356.1, -164.70000000000056, -338.8, -376.9, -400.0, 30.700000000000195, -352.6, -73.80000000000061, -400.0, 20.000000000000018, -390.1, -333.6, -180.00000000000065, -400.0, 20.000000000000018, -377.6, -400.0, -400.0, -400.0, -379.6, -400.0, -337.8, -397.8, 7.999999999999961, -265.6, -357.0, 20.000000000000018, -400.0, -271.3, -393.4, 2.90000000000013, 23.10000000000006, -0.999999999999972, 10.999999999999963, -407.0, -400.0, -158.90000000000055, -72.69999999999987, -400.0, -521.0, -380.7, -552.0, 28.100000000000144, -400.0, -383.5, 20.40000000000002, -400.0, -392.3, -374.7, 20.000000000000018, -296.6, -553.8, -29.00000000000002, 25.500000000000103, -400.0, -400.0, -365.8, 15.999999999999957, 20.000000000000018, -395.6, 28.70000000000014, -118.60000000000076], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -362.2, -397.9, -400.0, -400.0, -400.0, -372.7, -381.7, -400.0, -346.0, -353.8, 20.000000000000014, -400.0, -400.0, -360.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -369.7, -400.0, 20.000000000000014, -183.70000000000059, -11.500000000000007, -400.0, -400.0, -1744.0, -364.29999999999995, -400.0, -400.0, -368.8, -400.0, -400.0, -400.0, -400.0, -345.7, -379.0, -395.8, 41.600000000000236, -314.2, -383.8, -397.9, -376.9, -400.0, 20.000000000000014, -400.0, -318.1, -400.0, 20.000000000000014, -400.0, -358.0, -400.0, -400.0, -351.7, -391.6, -400.0, -389.8, 20.000000000000014, 29.000000000000163, -400.0, -395.8, -383.2, -400.0, 26.300000000000114, -334.9, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 35.30000000000026, -353.8, -351.7, 20.000000000000014, -400.0, -330.1, 35.30000000000025, -400.0, -338.8, -400.0, -400.0, -376.9, -400.0, -400.0, 31.700000000000212, -400.0, -345.7, -376.9, 20.000000000000014, -386.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -381.1, -385.0, -340.6, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -364.6, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -400.0, -362.2, -340.6, -400.0, -395.8, -400.0, 20.000000000000014, -400.0, -265.6, -331.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -154.30000000000055, -400.0, -387.4, 2.90000000000013, -400.0, 28.100000000000147, -379.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.90000000000003, -368.8, -400.0, 35.30000000000026, -400.0, -400.0, -400.0, -400.0, -369.7, -400.0, -400.0, -373.0, -400.0, 28.100000000000147, -400.0, -400.0, -368.5, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, -400.0, -385.3, -351.7, -400.0, 20.000000000000014, -400.0, -395.8, -206.8, -356.8, -400.0, -400.0, 20.000000000000014, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -347.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -393.7, -397.9, -190.00000000000057, -7.300000000000004, -400.0, -118.60000000000076], "policy_predator_policy_reward": [200.0, 200.0, 199.0, 196.0, 200.0, 200.0, 200.0, 189.0, 200.0, 193.0, 191.0, 172.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 176.0, 200.0, 200.0, 189.0, 186.0, 200.0, 15.0, 97.0, 200.0, 200.0, 200.0, 1709.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 181.0, 190.0, 198.0, 169.0, 169.0, 199.0, 194.0, 200.0, 200.0, 198.0, 200.0, 200.0, 170.0, 200.0, 177.0, 200.0, 189.0, 200.0, 177.0, 200.0, 200.0, 196.0, 187.0, 200.0, 200.0, 200.0, 170.0, 199.0, 200.0, 200.0, 169.0, 200.0, 200.0, 200.0, 198.0, 170.0, 184.0, 174.0, 183.0, 200.0, 174.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 181.0, 189.0, 98.0, 195.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 195.0, 197.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 178.0, 187.0, 200.0, 198.0, 200.0, 188.0, 200.0, 200.0, 200.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 83.0, 194.0, 200.0, 200.0, 200.0, 190.0, 184.0, 200.0, 179.0, 200.0, 191.0, 200.0, 193.0, 200.0, 200.0, 189.0, 0.0, 92.0, 200.0, 200.0, 200.0, 200.0, 79.0, 189.0, 200.0, 200.0, 21.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 186.0, 200.0, 200.0, 200.0, 193.0, 177.0, 200.0, 200.0, 200.0, 198.0, 108.0, 200.0, 3.0, 200.0, 151.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 196.0, 200.0, 200.0, 199.0, 197.0, 113.0, 113.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5743280109190162, "mean_inference_ms": 1.8044276766256655, "mean_action_processing_ms": 0.24645461652953193, "mean_env_wait_ms": 0.19265818863394707, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003833770751953125, "StateBufferConnector_ms": 0.003135085105895996, "ViewRequirementAgentConnector_ms": 0.09177649021148682}, "num_episodes": 18, "episode_return_max": 65.40000000000013, "episode_return_min": -553.8, "episode_return_mean": -248.74200000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 420.3176064035967, "num_env_steps_trained_throughput_per_sec": 420.3176064035967, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 9460.292, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9460.253, "sample_time_ms": 1264.038, "learn_time_ms": 8181.831, "learn_throughput": 488.888, "synch_weights_time_ms": 13.501}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-18-45", "timestamp": 1723645125, "time_this_iter_s": 9.522148132324219, "time_total_s": 990.0899176597595, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d1160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 990.0899176597595, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 27.83571428571429, "ram_util_percent": 83.42142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8884492587771207, "cur_kl_coeff": 0.0008908974006772044, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": -0.00015278391209899117, "vf_loss": 1.7854182910036158, "vf_explained_var": 0.0008776142168297338, "kl": Infinity, "entropy": 1.857789683418774e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6787187003032873, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.63441256492857, "policy_loss": 0.003022417142893626, "vf_loss": 7.608703010296695, "vf_explained_var": 1.130942945127134e-06, "kl": 0.008852169527152134, "entropy": 0.4629016016053144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 65.40000000000013, "episode_reward_min": -553.8, "episode_reward_mean": -236.96499999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.600000000000236, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -303.2725, "predator_policy": 184.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-364.7, -386.8, 65.40000000000013, -388.7, -376.9, 17.99999999999999, -348.1, -2.9999999999999414, -369.0, -374.7, -391.6, 13.199999999999958, 29.000000000000163, -409.00000000000006, 25.300000000000097, -365.9, 20.000000000000018, -402.0, 35.50000000000024, 25.300000000000097, -356.1, -164.70000000000056, -338.8, -376.9, -400.0, 30.700000000000195, -352.6, -73.80000000000061, -400.0, 20.000000000000018, -390.1, -333.6, -180.00000000000065, -400.0, 20.000000000000018, -377.6, -400.0, -400.0, -400.0, -379.6, -400.0, -337.8, -397.8, 7.999999999999961, -265.6, -357.0, 20.000000000000018, -400.0, -271.3, -393.4, 2.90000000000013, 23.10000000000006, -0.999999999999972, 10.999999999999963, -407.0, -400.0, -158.90000000000055, -72.69999999999987, -400.0, -521.0, -380.7, -552.0, 28.100000000000144, -400.0, -383.5, 20.40000000000002, -400.0, -392.3, -374.7, 20.000000000000018, -296.6, -553.8, -29.00000000000002, 25.500000000000103, -400.0, -400.0, -365.8, 15.999999999999957, 20.000000000000018, -395.6, 28.70000000000014, -118.60000000000076, -400.0, -31.00000000000002, -409.0, -391.5999999999999, 20.000000000000018, -325.29999999999944, -397.9, 18.000000000000018, -313.4999999999974, 32.60000000000023, -345.7999999999986, 14.999999999999957, -378.0, -367.6, -400.0, -355.9, -57.09999999999998, -5.199999999999905], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -345.7, -379.0, -395.8, 41.600000000000236, -314.2, -383.8, -397.9, -376.9, -400.0, 20.000000000000014, -400.0, -318.1, -400.0, 20.000000000000014, -400.0, -358.0, -400.0, -400.0, -351.7, -391.6, -400.0, -389.8, 20.000000000000014, 29.000000000000163, -400.0, -395.8, -383.2, -400.0, 26.300000000000114, -334.9, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 35.30000000000026, -353.8, -351.7, 20.000000000000014, -400.0, -330.1, 35.30000000000025, -400.0, -338.8, -400.0, -400.0, -376.9, -400.0, -400.0, 31.700000000000212, -400.0, -345.7, -376.9, 20.000000000000014, -386.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -381.1, -385.0, -340.6, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -364.6, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -400.0, -362.2, -340.6, -400.0, -395.8, -400.0, 20.000000000000014, -400.0, -265.6, -331.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -154.30000000000055, -400.0, -387.4, 2.90000000000013, -400.0, 28.100000000000147, -379.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.90000000000003, -368.8, -400.0, 35.30000000000026, -400.0, -400.0, -400.0, -400.0, -369.7, -400.0, -400.0, -373.0, -400.0, 28.100000000000147, -400.0, -400.0, -368.5, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, -400.0, -385.3, -351.7, -400.0, 20.000000000000014, -400.0, -395.8, -206.8, -356.8, -400.0, -400.0, 20.000000000000014, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -347.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -393.7, -397.9, -190.00000000000057, -7.300000000000004, -400.0, -118.60000000000076, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -391.5999999999999, 20.000000000000014, -400.0, -325.29999999999944, -400.0, -397.9, -400.0, 20.000000000000014, -400.0, -334.8999999999993, -223.60000000000048, -400.0, 32.60000000000023, -224.50000000000037, -385.3, 20.000000000000014, -400.0, -400.0, -358.0, -353.8, -395.8, -400.0, -400.0, -355.9, -400.0, 20.90000000000003, -337.0, 20.000000000000014, -383.2], "policy_predator_policy_reward": [200.0, 181.0, 190.0, 198.0, 169.0, 169.0, 199.0, 194.0, 200.0, 200.0, 198.0, 200.0, 200.0, 170.0, 200.0, 177.0, 200.0, 189.0, 200.0, 177.0, 200.0, 200.0, 196.0, 187.0, 200.0, 200.0, 200.0, 170.0, 199.0, 200.0, 200.0, 169.0, 200.0, 200.0, 200.0, 198.0, 170.0, 184.0, 174.0, 183.0, 200.0, 174.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 181.0, 189.0, 98.0, 195.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 195.0, 197.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 178.0, 187.0, 200.0, 198.0, 200.0, 188.0, 200.0, 200.0, 200.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 83.0, 194.0, 200.0, 200.0, 200.0, 190.0, 184.0, 200.0, 179.0, 200.0, 191.0, 200.0, 193.0, 200.0, 200.0, 189.0, 0.0, 92.0, 200.0, 200.0, 200.0, 200.0, 79.0, 189.0, 200.0, 200.0, 21.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 186.0, 200.0, 200.0, 200.0, 193.0, 177.0, 200.0, 200.0, 200.0, 198.0, 108.0, 200.0, 3.0, 200.0, 151.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 196.0, 200.0, 200.0, 199.0, 197.0, 113.0, 113.0, 200.0, 200.0, 200.0, 200.0, 149.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 169.0, 76.0, 200.0, 200.0, 79.0, 185.0, 195.0, 200.0, 200.0, 180.0, 184.0, 198.0, 200.0, 200.0, 200.0, 200.0, 170.0, 89.0, 166.0, 192.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5737474031371075, "mean_inference_ms": 1.803010601271022, "mean_action_processing_ms": 0.2461322282001559, "mean_env_wait_ms": 0.19244238550701426, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003899812698364258, "StateBufferConnector_ms": 0.003176093101501465, "ViewRequirementAgentConnector_ms": 0.09296762943267822}, "num_episodes": 18, "episode_return_max": 65.40000000000013, "episode_return_min": -553.8, "episode_return_mean": -236.96499999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 405.60200794222186, "num_env_steps_trained_throughput_per_sec": 405.60200794222186, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 9505.342, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9505.301, "sample_time_ms": 1260.857, "learn_time_ms": 8230.298, "learn_throughput": 486.009, "synch_weights_time_ms": 13.234}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-18-55", "timestamp": 1723645135, "time_this_iter_s": 9.896575927734375, "time_total_s": 999.9864935874939, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae49280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 999.9864935874939, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 31.87857142857143, "ram_util_percent": 83.62857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1245851317745825, "cur_kl_coeff": 0.001336346101015806, "cur_lr": 0.009999999999999998, "total_loss": 2.8468384778688822, "policy_loss": 4.742081577658022e-05, "vf_loss": 2.846791057485752, "vf_explained_var": 4.329101118461165e-05, "kl": 8.937435563022283e-38, "entropy": 2.0935348292106572e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.983762324045575, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.438614449425349, "policy_loss": 0.004236858245539701, "vf_loss": 7.403297397320864, "vf_explained_var": 1.5181523782235606e-06, "kl": 0.012127014183504916, "entropy": 0.5213080261592512, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 36.90000000000028, "episode_reward_min": -553.8, "episode_reward_mean": -235.19299999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1576.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 1523.0}, "policy_reward_mean": {"prey_policy": -312.80649999999997, "predator_policy": 195.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-338.8, -376.9, -400.0, 30.700000000000195, -352.6, -73.80000000000061, -400.0, 20.000000000000018, -390.1, -333.6, -180.00000000000065, -400.0, 20.000000000000018, -377.6, -400.0, -400.0, -400.0, -379.6, -400.0, -337.8, -397.8, 7.999999999999961, -265.6, -357.0, 20.000000000000018, -400.0, -271.3, -393.4, 2.90000000000013, 23.10000000000006, -0.999999999999972, 10.999999999999963, -407.0, -400.0, -158.90000000000055, -72.69999999999987, -400.0, -521.0, -380.7, -552.0, 28.100000000000144, -400.0, -383.5, 20.40000000000002, -400.0, -392.3, -374.7, 20.000000000000018, -296.6, -553.8, -29.00000000000002, 25.500000000000103, -400.0, -400.0, -365.8, 15.999999999999957, 20.000000000000018, -395.6, 28.70000000000014, -118.60000000000076, -400.0, -31.00000000000002, -409.0, -391.5999999999999, 20.000000000000018, -325.29999999999944, -397.9, 18.000000000000018, -313.4999999999974, 32.60000000000023, -345.7999999999986, 14.999999999999957, -378.0, -367.6, -400.0, -355.9, -57.09999999999998, -5.199999999999905, -344.99999999999886, -395.79999999999995, -400.0, -400.0, -288.8999999999994, -301.09999999999917, -1.9999999999999587, -339.6, -87.60000000000008, -265.19999999999845, -270.6, -11.600000000000048, 27.000000000000114, -253.0, 22.700000000000053, 9.599999999999964, -287.79999999999944, 36.90000000000028, -200.00000000000085, -162.70000000000064, -392.3, 14.699999999999964], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-338.8, -400.0, -400.0, -376.9, -400.0, -400.0, 31.700000000000212, -400.0, -345.7, -376.9, 20.000000000000014, -386.8, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -381.1, -385.0, -340.6, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -364.6, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -400.0, -362.2, -340.6, -400.0, -395.8, -400.0, 20.000000000000014, -400.0, -265.6, -331.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -154.30000000000055, -400.0, -387.4, 2.90000000000013, -400.0, 28.100000000000147, -379.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.90000000000003, -368.8, -400.0, 35.30000000000026, -400.0, -400.0, -400.0, -400.0, -369.7, -400.0, -400.0, -373.0, -400.0, 28.100000000000147, -400.0, -400.0, -368.5, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, -400.0, -385.3, -351.7, -400.0, 20.000000000000014, -400.0, -395.8, -206.8, -356.8, -400.0, -400.0, 20.000000000000014, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -347.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -393.7, -397.9, -190.00000000000057, -7.300000000000004, -400.0, -118.60000000000076, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -391.5999999999999, 20.000000000000014, -400.0, -325.29999999999944, -400.0, -397.9, -400.0, 20.000000000000014, -400.0, -334.8999999999993, -223.60000000000048, -400.0, 32.60000000000023, -224.50000000000037, -385.3, 20.000000000000014, -400.0, -400.0, -358.0, -353.8, -395.8, -400.0, -400.0, -355.9, -400.0, 20.90000000000003, -337.0, 20.000000000000014, -383.2, -294.99999999999886, -400.0, -400.0, -395.79999999999995, -400.0, -400.0, -400.0, -400.0, -366.4, -221.50000000000048, -400.0, -273.09999999999917, 20.000000000000014, -400.0, -400.0, -328.6, 20.000000000000014, -349.6, -257.19999999999845, -400.0, -370.6, -1312.0, -349.59999999999945, 20.000000000000014, -253.0, 20.000000000000014, -1576.0, -400.0, -400.0, 22.700000000000053, 32.60000000000023, -400.0, -303.3999999999994, -342.4, 35.30000000000026, -366.4, -400.0, -85.00000000000085, -400.0, -162.70000000000064, -400.0, -385.3, 31.700000000000212, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 181.0, 189.0, 98.0, 195.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 195.0, 197.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 178.0, 187.0, 200.0, 198.0, 200.0, 188.0, 200.0, 200.0, 200.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 83.0, 194.0, 200.0, 200.0, 200.0, 190.0, 184.0, 200.0, 179.0, 200.0, 191.0, 200.0, 193.0, 200.0, 200.0, 189.0, 0.0, 92.0, 200.0, 200.0, 200.0, 200.0, 79.0, 189.0, 200.0, 200.0, 21.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 186.0, 200.0, 200.0, 200.0, 193.0, 177.0, 200.0, 200.0, 200.0, 198.0, 108.0, 200.0, 3.0, 200.0, 151.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 196.0, 200.0, 200.0, 199.0, 197.0, 113.0, 113.0, 200.0, 200.0, 200.0, 200.0, 149.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 169.0, 76.0, 200.0, 200.0, 79.0, 185.0, 195.0, 200.0, 200.0, 180.0, 184.0, 198.0, 200.0, 200.0, 200.0, 200.0, 170.0, 89.0, 166.0, 192.0, 150.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 115.0, 184.0, 172.0, 200.0, 200.0, 178.0, 189.0, 200.0, 74.0, 168.0, 192.0, 200.0, 1226.0, 186.0, 176.0, 142.0, 130.0, 130.0, 1523.0, 200.0, 200.0, 200.0, 200.0, 177.0, 179.0, 179.0, 184.0, 184.0, 197.0, 88.0, 200.0, 200.0, 194.0, 199.0, 200.0, 183.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5733112566786305, "mean_inference_ms": 1.8030168239086763, "mean_action_processing_ms": 0.24545637820033492, "mean_env_wait_ms": 0.19224769009733633, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038957595825195312, "StateBufferConnector_ms": 0.003172636032104492, "ViewRequirementAgentConnector_ms": 0.09492170810699463}, "num_episodes": 22, "episode_return_max": 36.90000000000028, "episode_return_min": -553.8, "episode_return_mean": -235.19299999999993, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.5715979752014, "num_env_steps_trained_throughput_per_sec": 388.5715979752014, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 9575.64, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9575.599, "sample_time_ms": 1262.244, "learn_time_ms": 8298.987, "learn_throughput": 481.987, "synch_weights_time_ms": 13.456}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-19-05", "timestamp": 1723645145, "time_this_iter_s": 10.299201011657715, "time_total_s": 1010.2856945991516, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8b6ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1010.2856945991516, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 34.52142857142857, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0388488824607403, "cur_kl_coeff": 0.000668173050507903, "cur_lr": 0.009999999999999998, "total_loss": 4.003826263468102, "policy_loss": -3.525385283249081e-05, "vf_loss": 4.003861531000289, "vf_explained_var": 1.952569320719078e-05, "kl": 2.0588835675778218e-38, "entropy": 1.2293775640218852e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9446868413970586, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.936018128874441, "policy_loss": 0.0036659635544296293, "vf_loss": 7.906578568302135, "vf_explained_var": -1.7566024941742104e-08, "kl": 0.010056458597206231, "entropy": 0.5668101924594748, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 36.90000000000028, "episode_reward_min": -654.0, "episode_reward_mean": -224.68799999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1576.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 1523.0}, "policy_reward_mean": {"prey_policy": -312.9789999999999, "predator_policy": 200.635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -337.8, -397.8, 7.999999999999961, -265.6, -357.0, 20.000000000000018, -400.0, -271.3, -393.4, 2.90000000000013, 23.10000000000006, -0.999999999999972, 10.999999999999963, -407.0, -400.0, -158.90000000000055, -72.69999999999987, -400.0, -521.0, -380.7, -552.0, 28.100000000000144, -400.0, -383.5, 20.40000000000002, -400.0, -392.3, -374.7, 20.000000000000018, -296.6, -553.8, -29.00000000000002, 25.500000000000103, -400.0, -400.0, -365.8, 15.999999999999957, 20.000000000000018, -395.6, 28.70000000000014, -118.60000000000076, -400.0, -31.00000000000002, -409.0, -391.5999999999999, 20.000000000000018, -325.29999999999944, -397.9, 18.000000000000018, -313.4999999999974, 32.60000000000023, -345.7999999999986, 14.999999999999957, -378.0, -367.6, -400.0, -355.9, -57.09999999999998, -5.199999999999905, -344.99999999999886, -395.79999999999995, -400.0, -400.0, -288.8999999999994, -301.09999999999917, -1.9999999999999587, -339.6, -87.60000000000008, -265.19999999999845, -270.6, -11.600000000000048, 27.000000000000114, -253.0, 22.700000000000053, 9.599999999999964, -287.79999999999944, 36.90000000000028, -200.00000000000085, -162.70000000000064, -392.3, 14.699999999999964, -392.29999999999995, -312.2999999999997, -46.499999999999794, -225.1000000000009, -118.60000000000002, -381.1, -393.0999999999996, -76.00000000000003, -18.999999999999872, -654.0, -192.1000000000005, -93.00000000000013, 20.000000000000014, -281.5999999999981, -220.70000000000027, -148.30000000000092, -189.60000000000073, -358.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -362.2, -340.6, -400.0, -395.8, -400.0, 20.000000000000014, -400.0, -265.6, -331.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -154.30000000000055, -400.0, -387.4, 2.90000000000013, -400.0, 28.100000000000147, -379.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.90000000000003, -368.8, -400.0, 35.30000000000026, -400.0, -400.0, -400.0, -400.0, -369.7, -400.0, -400.0, -373.0, -400.0, 28.100000000000147, -400.0, -400.0, -368.5, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, -400.0, -385.3, -351.7, -400.0, 20.000000000000014, -400.0, -395.8, -206.8, -356.8, -400.0, -400.0, 20.000000000000014, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -347.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -393.7, -397.9, -190.00000000000057, -7.300000000000004, -400.0, -118.60000000000076, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -391.5999999999999, 20.000000000000014, -400.0, -325.29999999999944, -400.0, -397.9, -400.0, 20.000000000000014, -400.0, -334.8999999999993, -223.60000000000048, -400.0, 32.60000000000023, -224.50000000000037, -385.3, 20.000000000000014, -400.0, -400.0, -358.0, -353.8, -395.8, -400.0, -400.0, -355.9, -400.0, 20.90000000000003, -337.0, 20.000000000000014, -383.2, -294.99999999999886, -400.0, -400.0, -395.79999999999995, -400.0, -400.0, -400.0, -400.0, -366.4, -221.50000000000048, -400.0, -273.09999999999917, 20.000000000000014, -400.0, -400.0, -328.6, 20.000000000000014, -349.6, -257.19999999999845, -400.0, -370.6, -1312.0, -349.59999999999945, 20.000000000000014, -253.0, 20.000000000000014, -1576.0, -400.0, -400.0, 22.700000000000053, 32.60000000000023, -400.0, -303.3999999999994, -342.4, 35.30000000000026, -366.4, -400.0, -85.00000000000085, -400.0, -162.70000000000064, -400.0, -385.3, 31.700000000000212, -400.0, -385.29999999999995, -400.0, -348.69999999999976, -355.6, -292.89999999999884, 13.399999999999972, -400.0, -66.1000000000009, -118.60000000000002, -400.0, -400.0, -381.1, -327.0999999999999, -400.0, -400.0, 20.000000000000014, -1088.0, 20.000000000000014, -1504.0, -792.0, -192.1000000000005, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -188.20000000000041, -345.3999999999994, -259.3, -279.3999999999988, -292.5999999999993, -36.69999999999978, -91.60000000000075, -400.0, -335.5, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 178.0, 187.0, 200.0, 198.0, 200.0, 188.0, 200.0, 200.0, 200.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 83.0, 194.0, 200.0, 200.0, 200.0, 190.0, 184.0, 200.0, 179.0, 200.0, 191.0, 200.0, 193.0, 200.0, 200.0, 189.0, 0.0, 92.0, 200.0, 200.0, 200.0, 200.0, 79.0, 189.0, 200.0, 200.0, 21.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 186.0, 200.0, 200.0, 200.0, 193.0, 177.0, 200.0, 200.0, 200.0, 198.0, 108.0, 200.0, 3.0, 200.0, 151.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 196.0, 200.0, 200.0, 199.0, 197.0, 113.0, 113.0, 200.0, 200.0, 200.0, 200.0, 149.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 169.0, 76.0, 200.0, 200.0, 79.0, 185.0, 195.0, 200.0, 200.0, 180.0, 184.0, 198.0, 200.0, 200.0, 200.0, 200.0, 170.0, 89.0, 166.0, 192.0, 150.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 115.0, 184.0, 172.0, 200.0, 200.0, 178.0, 189.0, 200.0, 74.0, 168.0, 192.0, 200.0, 1226.0, 186.0, 176.0, 142.0, 130.0, 130.0, 1523.0, 200.0, 200.0, 200.0, 200.0, 177.0, 179.0, 179.0, 184.0, 184.0, 197.0, 88.0, 200.0, 200.0, 194.0, 199.0, 200.0, 183.0, 193.0, 200.0, 196.0, 196.0, 84.0, 149.0, 41.0, 200.0, 200.0, 200.0, 200.0, 200.0, 134.0, 200.0, 200.0, 104.0, 75.0, 974.0, 200.0, 1442.0, 200.0, 200.0, 93.0, 194.0, 200.0, 200.0, 78.0, 174.0, 180.0, 138.0, 154.0, 27.0, 106.0, 196.0, 200.0, 177.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5728040093136089, "mean_inference_ms": 1.800089597975482, "mean_action_processing_ms": 0.24553943577091972, "mean_env_wait_ms": 0.1920441411358003, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003889799118041992, "StateBufferConnector_ms": 0.0031282901763916016, "ViewRequirementAgentConnector_ms": 0.09243965148925781}, "num_episodes": 18, "episode_return_max": 36.90000000000028, "episode_return_min": -654.0, "episode_return_mean": -224.68799999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.7386354599009, "num_env_steps_trained_throughput_per_sec": 359.7386354599009, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 9743.681, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9743.638, "sample_time_ms": 1260.234, "learn_time_ms": 8468.543, "learn_throughput": 472.336, "synch_weights_time_ms": 13.642}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-19-16", "timestamp": 1723645156, "time_this_iter_s": 11.153829097747803, "time_total_s": 1021.4395236968994, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d3940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1021.4395236968994, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 45.150000000000006, "ram_util_percent": 83.76249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.401078390598632, "cur_kl_coeff": 0.0003340865252539515, "cur_lr": 0.009999999999999998, "total_loss": 5.211423738923653, "policy_loss": -0.00013681177774237262, "vf_loss": 5.21156055132548, "vf_explained_var": -4.12489686693464e-05, "kl": -4.073349241753537e-42, "entropy": 1.5145942554024787e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3266994927768354, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.464616364019888, "policy_loss": 0.0034049840579942737, "vf_loss": 7.43252332778204, "vf_explained_var": -8.19958076275215e-10, "kl": 0.011193635563736284, "entropy": 0.6522569389097275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 36.90000000000028, "episode_reward_min": -1336.9, "episode_reward_mean": -235.41699999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1723.9, "predator_policy": 3.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 1739.0}, "policy_reward_mean": {"prey_policy": -332.4785, "predator_policy": 214.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -383.5, 20.40000000000002, -400.0, -392.3, -374.7, 20.000000000000018, -296.6, -553.8, -29.00000000000002, 25.500000000000103, -400.0, -400.0, -365.8, 15.999999999999957, 20.000000000000018, -395.6, 28.70000000000014, -118.60000000000076, -400.0, -31.00000000000002, -409.0, -391.5999999999999, 20.000000000000018, -325.29999999999944, -397.9, 18.000000000000018, -313.4999999999974, 32.60000000000023, -345.7999999999986, 14.999999999999957, -378.0, -367.6, -400.0, -355.9, -57.09999999999998, -5.199999999999905, -344.99999999999886, -395.79999999999995, -400.0, -400.0, -288.8999999999994, -301.09999999999917, -1.9999999999999587, -339.6, -87.60000000000008, -265.19999999999845, -270.6, -11.600000000000048, 27.000000000000114, -253.0, 22.700000000000053, 9.599999999999964, -287.79999999999944, 36.90000000000028, -200.00000000000085, -162.70000000000064, -392.3, 14.699999999999964, -392.29999999999995, -312.2999999999997, -46.499999999999794, -225.1000000000009, -118.60000000000002, -381.1, -393.0999999999996, -76.00000000000003, -18.999999999999872, -654.0, -192.1000000000005, -93.00000000000013, 20.000000000000014, -281.5999999999981, -220.70000000000027, -148.30000000000092, -189.60000000000073, -358.5, -100.80000000000155, -1336.9, -123.60000000000102, -166.30000000000112, -89.80000000000061, -479.8, -299.4999999999992, -82.0000000000012, -393.4, -173.40000000000117, -252.99999999999872, -376.8, -185.80000000000112, -400.0, -64.50000000000038, -261.09999999999957, -334.29999999999967, -33.999999999999886, -221.50000000000048, -368.1, -292.7, -517.7, -141.00000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -368.5, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, -400.0, -385.3, -351.7, -400.0, 20.000000000000014, -400.0, -395.8, -206.8, -356.8, -400.0, -400.0, 20.000000000000014, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -347.8, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -393.7, -397.9, -190.00000000000057, -7.300000000000004, -400.0, -118.60000000000076, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -391.5999999999999, 20.000000000000014, -400.0, -325.29999999999944, -400.0, -397.9, -400.0, 20.000000000000014, -400.0, -334.8999999999993, -223.60000000000048, -400.0, 32.60000000000023, -224.50000000000037, -385.3, 20.000000000000014, -400.0, -400.0, -358.0, -353.8, -395.8, -400.0, -400.0, -355.9, -400.0, 20.90000000000003, -337.0, 20.000000000000014, -383.2, -294.99999999999886, -400.0, -400.0, -395.79999999999995, -400.0, -400.0, -400.0, -400.0, -366.4, -221.50000000000048, -400.0, -273.09999999999917, 20.000000000000014, -400.0, -400.0, -328.6, 20.000000000000014, -349.6, -257.19999999999845, -400.0, -370.6, -1312.0, -349.59999999999945, 20.000000000000014, -253.0, 20.000000000000014, -1576.0, -400.0, -400.0, 22.700000000000053, 32.60000000000023, -400.0, -303.3999999999994, -342.4, 35.30000000000026, -366.4, -400.0, -85.00000000000085, -400.0, -162.70000000000064, -400.0, -385.3, 31.700000000000212, -400.0, -385.29999999999995, -400.0, -348.69999999999976, -355.6, -292.89999999999884, 13.399999999999972, -400.0, -66.1000000000009, -118.60000000000002, -400.0, -400.0, -381.1, -327.0999999999999, -400.0, -400.0, 20.000000000000014, -1088.0, 20.000000000000014, -1504.0, -792.0, -192.1000000000005, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -188.20000000000041, -345.3999999999994, -259.3, -279.3999999999988, -292.5999999999993, -36.69999999999978, -91.60000000000075, -400.0, -335.5, -400.0, -181.6000000000006, -47.19999999999976, -1552.0, -1723.9, -80.80000000000084, -332.7999999999993, -211.0000000000005, -175.3000000000006, -400.0, 24.20000000000008, -400.0, -377.8, -164.50000000000054, -400.0, -76.60000000000088, -282.3999999999987, -397.9, -389.5, -145.9000000000007, -221.50000000000048, -400.0, -252.9999999999993, -374.8, -400.0, -140.8000000000007, -217.00000000000045, -400.0, -400.0, -215.8000000000004, -162.70000000000002, -1344.0, -360.09999999999957, -400.0, -238.30000000000038, 20.000000000000014, -912.0, -400.0, -221.50000000000048, -375.4, -372.7, -1225.7, -400.0, -361.59999999999997, -360.1, -400.0, 20.000000000000014], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 185.0, 200.0, 186.0, 200.0, 200.0, 200.0, 193.0, 177.0, 200.0, 200.0, 200.0, 198.0, 108.0, 200.0, 3.0, 200.0, 151.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 196.0, 200.0, 200.0, 199.0, 197.0, 113.0, 113.0, 200.0, 200.0, 200.0, 200.0, 149.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 169.0, 76.0, 200.0, 200.0, 79.0, 185.0, 195.0, 200.0, 200.0, 180.0, 184.0, 198.0, 200.0, 200.0, 200.0, 200.0, 170.0, 89.0, 166.0, 192.0, 150.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 115.0, 184.0, 172.0, 200.0, 200.0, 178.0, 189.0, 200.0, 74.0, 168.0, 192.0, 200.0, 1226.0, 186.0, 176.0, 142.0, 130.0, 130.0, 1523.0, 200.0, 200.0, 200.0, 200.0, 177.0, 179.0, 179.0, 184.0, 184.0, 197.0, 88.0, 200.0, 200.0, 194.0, 199.0, 200.0, 183.0, 193.0, 200.0, 196.0, 196.0, 84.0, 149.0, 41.0, 200.0, 200.0, 200.0, 200.0, 200.0, 134.0, 200.0, 200.0, 104.0, 75.0, 974.0, 200.0, 1442.0, 200.0, 200.0, 93.0, 194.0, 200.0, 200.0, 78.0, 174.0, 180.0, 138.0, 154.0, 27.0, 106.0, 196.0, 200.0, 177.0, 96.0, 32.0, 200.0, 1739.0, 168.0, 122.0, 110.0, 110.0, 200.0, 86.0, 98.0, 200.0, 70.0, 195.0, 133.0, 144.0, 195.0, 199.0, 115.0, 79.0, 200.0, 200.0, 200.0, 198.0, 53.0, 119.0, 200.0, 200.0, 186.0, 128.0, 181.0, 1262.0, 200.0, 104.0, 776.0, 82.0, 200.0, 200.0, 190.0, 190.0, 1133.0, 200.0, 23.0, 181.0, 53.0, 186.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5723486994252187, "mean_inference_ms": 1.798268223512133, "mean_action_processing_ms": 0.2451615878273744, "mean_env_wait_ms": 0.1918373162546936, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006969928741455078, "StateBufferConnector_ms": 0.006761312484741211, "ViewRequirementAgentConnector_ms": 0.11325931549072266}, "num_episodes": 23, "episode_return_max": 36.90000000000028, "episode_return_min": -1336.9, "episode_return_mean": -235.41699999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.3663390106485, "num_env_steps_trained_throughput_per_sec": 365.3663390106485, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 9892.205, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9892.162, "sample_time_ms": 1273.25, "learn_time_ms": 8603.874, "learn_throughput": 464.907, "synch_weights_time_ms": 13.645}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-19-27", "timestamp": 1723645167, "time_this_iter_s": 10.96875524520874, "time_total_s": 1032.4082789421082, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d68b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1032.4082789421082, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 37.15625, "ram_util_percent": 82.38750000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2692774827418223, "cur_kl_coeff": 0.00016704326262697574, "cur_lr": 0.009999999999999998, "total_loss": 6.104865123859789, "policy_loss": -2.8206426748838375e-05, "vf_loss": 6.1048933225964745, "vf_explained_var": -1.1855679214316071e-05, "kl": 7.602652139724433e-43, "entropy": 1.0826861504263003e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3867389887255968, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 6.773121139233705, "policy_loss": 0.0029850071586826174, "vf_loss": 6.74252441648453, "vf_explained_var": 3.7213481923259754e-09, "kl": 0.010773663553325733, "entropy": 0.6666991156245035, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 36.90000000000028, "episode_reward_min": -1336.9, "episode_reward_mean": -234.65999999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1723.9, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 1739.0}, "policy_reward_mean": {"prey_policy": -336.755, "predator_policy": 219.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-118.60000000000076, -400.0, -31.00000000000002, -409.0, -391.5999999999999, 20.000000000000018, -325.29999999999944, -397.9, 18.000000000000018, -313.4999999999974, 32.60000000000023, -345.7999999999986, 14.999999999999957, -378.0, -367.6, -400.0, -355.9, -57.09999999999998, -5.199999999999905, -344.99999999999886, -395.79999999999995, -400.0, -400.0, -288.8999999999994, -301.09999999999917, -1.9999999999999587, -339.6, -87.60000000000008, -265.19999999999845, -270.6, -11.600000000000048, 27.000000000000114, -253.0, 22.700000000000053, 9.599999999999964, -287.79999999999944, 36.90000000000028, -200.00000000000085, -162.70000000000064, -392.3, 14.699999999999964, -392.29999999999995, -312.2999999999997, -46.499999999999794, -225.1000000000009, -118.60000000000002, -381.1, -393.0999999999996, -76.00000000000003, -18.999999999999872, -654.0, -192.1000000000005, -93.00000000000013, 20.000000000000014, -281.5999999999981, -220.70000000000027, -148.30000000000092, -189.60000000000073, -358.5, -100.80000000000155, -1336.9, -123.60000000000102, -166.30000000000112, -89.80000000000061, -479.8, -299.4999999999992, -82.0000000000012, -393.4, -173.40000000000117, -252.99999999999872, -376.8, -185.80000000000112, -400.0, -64.50000000000038, -261.09999999999957, -334.29999999999967, -33.999999999999886, -221.50000000000048, -368.1, -292.7, -517.7, -141.00000000000045, -287.4, -254.6999999999981, -126.30000000000064, -319.50000000000045, -338.19999999999845, 10.099999999999941, -359.90000000000043, -109.60000000000105, -233.20000000000067, -392.70000000000005, -40.0, -363.9999999999987, -156.60000000000056, 36.70000000000025, 27.200000000000117, -514.9, -556.7, -205.30000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -118.60000000000076, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -391.5999999999999, 20.000000000000014, -400.0, -325.29999999999944, -400.0, -397.9, -400.0, 20.000000000000014, -400.0, -334.8999999999993, -223.60000000000048, -400.0, 32.60000000000023, -224.50000000000037, -385.3, 20.000000000000014, -400.0, -400.0, -358.0, -353.8, -395.8, -400.0, -400.0, -355.9, -400.0, 20.90000000000003, -337.0, 20.000000000000014, -383.2, -294.99999999999886, -400.0, -400.0, -395.79999999999995, -400.0, -400.0, -400.0, -400.0, -366.4, -221.50000000000048, -400.0, -273.09999999999917, 20.000000000000014, -400.0, -400.0, -328.6, 20.000000000000014, -349.6, -257.19999999999845, -400.0, -370.6, -1312.0, -349.59999999999945, 20.000000000000014, -253.0, 20.000000000000014, -1576.0, -400.0, -400.0, 22.700000000000053, 32.60000000000023, -400.0, -303.3999999999994, -342.4, 35.30000000000026, -366.4, -400.0, -85.00000000000085, -400.0, -162.70000000000064, -400.0, -385.3, 31.700000000000212, -400.0, -385.29999999999995, -400.0, -348.69999999999976, -355.6, -292.89999999999884, 13.399999999999972, -400.0, -66.1000000000009, -118.60000000000002, -400.0, -400.0, -381.1, -327.0999999999999, -400.0, -400.0, 20.000000000000014, -1088.0, 20.000000000000014, -1504.0, -792.0, -192.1000000000005, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -188.20000000000041, -345.3999999999994, -259.3, -279.3999999999988, -292.5999999999993, -36.69999999999978, -91.60000000000075, -400.0, -335.5, -400.0, -181.6000000000006, -47.19999999999976, -1552.0, -1723.9, -80.80000000000084, -332.7999999999993, -211.0000000000005, -175.3000000000006, -400.0, 24.20000000000008, -400.0, -377.8, -164.50000000000054, -400.0, -76.60000000000088, -282.3999999999987, -397.9, -389.5, -145.9000000000007, -221.50000000000048, -400.0, -252.9999999999993, -374.8, -400.0, -140.8000000000007, -217.00000000000045, -400.0, -400.0, -215.8000000000004, -162.70000000000002, -1344.0, -360.09999999999957, -400.0, -238.30000000000038, 20.000000000000014, -912.0, -400.0, -221.50000000000048, -375.4, -372.7, -1225.7, -400.0, -361.59999999999997, -360.1, -400.0, 20.000000000000014, -281.5, -376.9, -301.29999999999893, -240.40000000000043, -351.6999999999995, 7.399999999999965, -346.3, -236.20000000000044, -378.9999999999998, -278.1999999999987, -124.90000000000074, 20.000000000000014, -250.9000000000004, -400.0, 17.899999999999988, -263.4999999999985, -156.40000000000066, -356.8, -400.0, -330.7, -1704.0, -1688.0, -280.2999999999987, -372.7, -391.5999999999999, 20.000000000000014, 23.600000000000065, -124.90000000000074, 20.000000000000014, -101.80000000000081, -362.2, -351.70000000000005, -360.7, -400.0, -320.19999999999914, -285.1], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 149.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 169.0, 76.0, 200.0, 200.0, 79.0, 185.0, 195.0, 200.0, 200.0, 180.0, 184.0, 198.0, 200.0, 200.0, 200.0, 200.0, 170.0, 89.0, 166.0, 192.0, 150.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 115.0, 184.0, 172.0, 200.0, 200.0, 178.0, 189.0, 200.0, 74.0, 168.0, 192.0, 200.0, 1226.0, 186.0, 176.0, 142.0, 130.0, 130.0, 1523.0, 200.0, 200.0, 200.0, 200.0, 177.0, 179.0, 179.0, 184.0, 184.0, 197.0, 88.0, 200.0, 200.0, 194.0, 199.0, 200.0, 183.0, 193.0, 200.0, 196.0, 196.0, 84.0, 149.0, 41.0, 200.0, 200.0, 200.0, 200.0, 200.0, 134.0, 200.0, 200.0, 104.0, 75.0, 974.0, 200.0, 1442.0, 200.0, 200.0, 93.0, 194.0, 200.0, 200.0, 78.0, 174.0, 180.0, 138.0, 154.0, 27.0, 106.0, 196.0, 200.0, 177.0, 96.0, 32.0, 200.0, 1739.0, 168.0, 122.0, 110.0, 110.0, 200.0, 86.0, 98.0, 200.0, 70.0, 195.0, 133.0, 144.0, 195.0, 199.0, 115.0, 79.0, 200.0, 200.0, 200.0, 198.0, 53.0, 119.0, 200.0, 200.0, 186.0, 128.0, 181.0, 1262.0, 200.0, 104.0, 776.0, 82.0, 200.0, 200.0, 190.0, 190.0, 1133.0, 200.0, 23.0, 181.0, 53.0, 186.0, 182.0, 189.0, 153.0, 134.0, 41.0, 177.0, 86.0, 177.0, 190.0, 129.0, 46.0, 69.0, 91.0, 200.0, 135.0, 1.0, 80.0, 200.0, 190.0, 148.0, 1676.0, 1676.0, 200.0, 89.0, 193.0, 22.0, 69.0, 69.0, 51.0, 58.0, 186.0, 13.0, 4.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5720518475578225, "mean_inference_ms": 1.796940512444678, "mean_action_processing_ms": 0.24491612450505904, "mean_env_wait_ms": 0.19168212605723053, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007515668869018555, "StateBufferConnector_ms": 0.006801486015319824, "ViewRequirementAgentConnector_ms": 0.11637604236602783}, "num_episodes": 18, "episode_return_max": 36.90000000000028, "episode_return_min": -1336.9, "episode_return_mean": -234.65999999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 414.95644336673075, "num_env_steps_trained_throughput_per_sec": 414.95644336673075, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 9919.592, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9919.549, "sample_time_ms": 1272.703, "learn_time_ms": 8631.712, "learn_throughput": 463.407, "synch_weights_time_ms": 13.789}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-19-37", "timestamp": 1723645177, "time_this_iter_s": 9.644260168075562, "time_total_s": 1042.0525391101837, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d35e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1042.0525391101837, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 29.846153846153847, "ram_util_percent": 81.43846153846152}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.563806977918342, "cur_kl_coeff": 8.352163131348787e-05, "cur_lr": 0.009999999999999998, "total_loss": 5.051591757113341, "policy_loss": 0.00010370967944187146, "vf_loss": 5.051488038093325, "vf_explained_var": 5.650652779473199e-05, "kl": 2.953242519129399e-41, "entropy": 1.323175307839755e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5149009878830935, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.999469329692699, "policy_loss": 0.0034442085234100916, "vf_loss": 7.964428455615169, "vf_explained_var": -7.379622686476935e-09, "kl": 0.012328522975145109, "entropy": 0.7052621113402503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 36.90000000000028, "episode_reward_min": -1336.9, "episode_reward_mean": -234.68600000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1723.9, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 35.60000000000025, "predator_policy": 1739.0}, "policy_reward_mean": {"prey_policy": -347.848, "predator_policy": 230.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.199999999999905, -344.99999999999886, -395.79999999999995, -400.0, -400.0, -288.8999999999994, -301.09999999999917, -1.9999999999999587, -339.6, -87.60000000000008, -265.19999999999845, -270.6, -11.600000000000048, 27.000000000000114, -253.0, 22.700000000000053, 9.599999999999964, -287.79999999999944, 36.90000000000028, -200.00000000000085, -162.70000000000064, -392.3, 14.699999999999964, -392.29999999999995, -312.2999999999997, -46.499999999999794, -225.1000000000009, -118.60000000000002, -381.1, -393.0999999999996, -76.00000000000003, -18.999999999999872, -654.0, -192.1000000000005, -93.00000000000013, 20.000000000000014, -281.5999999999981, -220.70000000000027, -148.30000000000092, -189.60000000000073, -358.5, -100.80000000000155, -1336.9, -123.60000000000102, -166.30000000000112, -89.80000000000061, -479.8, -299.4999999999992, -82.0000000000012, -393.4, -173.40000000000117, -252.99999999999872, -376.8, -185.80000000000112, -400.0, -64.50000000000038, -261.09999999999957, -334.29999999999967, -33.999999999999886, -221.50000000000048, -368.1, -292.7, -517.7, -141.00000000000045, -287.4, -254.6999999999981, -126.30000000000064, -319.50000000000045, -338.19999999999845, 10.099999999999941, -359.90000000000043, -109.60000000000105, -233.20000000000067, -392.70000000000005, -40.0, -363.9999999999987, -156.60000000000056, 36.70000000000025, 27.200000000000117, -514.9, -556.7, -205.30000000000024, -156.50000000000114, -896.4, 25.70000000000013, -264.3000000000004, -6.2000000000000615, -351.59999999999997, -82.30000000000038, -287.9999999999973, -4.000000000000023, -252.7000000000007, -139.30000000000112, 26.30000000000011, -126.1000000000014, -292.2, -303.0, -454.0, -192.00000000000054, -451.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -383.2, -294.99999999999886, -400.0, -400.0, -395.79999999999995, -400.0, -400.0, -400.0, -400.0, -366.4, -221.50000000000048, -400.0, -273.09999999999917, 20.000000000000014, -400.0, -400.0, -328.6, 20.000000000000014, -349.6, -257.19999999999845, -400.0, -370.6, -1312.0, -349.59999999999945, 20.000000000000014, -253.0, 20.000000000000014, -1576.0, -400.0, -400.0, 22.700000000000053, 32.60000000000023, -400.0, -303.3999999999994, -342.4, 35.30000000000026, -366.4, -400.0, -85.00000000000085, -400.0, -162.70000000000064, -400.0, -385.3, 31.700000000000212, -400.0, -385.29999999999995, -400.0, -348.69999999999976, -355.6, -292.89999999999884, 13.399999999999972, -400.0, -66.1000000000009, -118.60000000000002, -400.0, -400.0, -381.1, -327.0999999999999, -400.0, -400.0, 20.000000000000014, -1088.0, 20.000000000000014, -1504.0, -792.0, -192.1000000000005, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -188.20000000000041, -345.3999999999994, -259.3, -279.3999999999988, -292.5999999999993, -36.69999999999978, -91.60000000000075, -400.0, -335.5, -400.0, -181.6000000000006, -47.19999999999976, -1552.0, -1723.9, -80.80000000000084, -332.7999999999993, -211.0000000000005, -175.3000000000006, -400.0, 24.20000000000008, -400.0, -377.8, -164.50000000000054, -400.0, -76.60000000000088, -282.3999999999987, -397.9, -389.5, -145.9000000000007, -221.50000000000048, -400.0, -252.9999999999993, -374.8, -400.0, -140.8000000000007, -217.00000000000045, -400.0, -400.0, -215.8000000000004, -162.70000000000002, -1344.0, -360.09999999999957, -400.0, -238.30000000000038, 20.000000000000014, -912.0, -400.0, -221.50000000000048, -375.4, -372.7, -1225.7, -400.0, -361.59999999999997, -360.1, -400.0, 20.000000000000014, -281.5, -376.9, -301.29999999999893, -240.40000000000043, -351.6999999999995, 7.399999999999965, -346.3, -236.20000000000044, -378.9999999999998, -278.1999999999987, -124.90000000000074, 20.000000000000014, -250.9000000000004, -400.0, 17.899999999999988, -263.4999999999985, -156.40000000000066, -356.8, -400.0, -330.7, -1704.0, -1688.0, -280.2999999999987, -372.7, -391.5999999999999, 20.000000000000014, 23.600000000000065, -124.90000000000074, 20.000000000000014, -101.80000000000081, -362.2, -351.70000000000005, -360.7, -400.0, -320.19999999999914, -285.1, -121.00000000000068, -221.50000000000048, -1048.0, -1499.4, 35.60000000000025, -124.90000000000074, -214.00000000000037, -943.3, -328.5999999999992, 25.400000000000098, -313.9, -393.7, -129.10000000000073, -326.2, -244.60000000000036, -243.40000000000032, -400.0, 20.000000000000014, -123.7000000000007, -400.0, -15.699999999999754, -286.5999999999988, -400.0, 26.300000000000114, -217.3000000000005, -59.80000000000061, -1181.5, -378.7, -1176.0, -400.0, -360.1, -355.9, -187.90000000000057, -360.1, -339.7, -400.0], "policy_predator_policy_reward": [166.0, 192.0, 150.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 115.0, 184.0, 172.0, 200.0, 200.0, 178.0, 189.0, 200.0, 74.0, 168.0, 192.0, 200.0, 1226.0, 186.0, 176.0, 142.0, 130.0, 130.0, 1523.0, 200.0, 200.0, 200.0, 200.0, 177.0, 179.0, 179.0, 184.0, 184.0, 197.0, 88.0, 200.0, 200.0, 194.0, 199.0, 200.0, 183.0, 193.0, 200.0, 196.0, 196.0, 84.0, 149.0, 41.0, 200.0, 200.0, 200.0, 200.0, 200.0, 134.0, 200.0, 200.0, 104.0, 75.0, 974.0, 200.0, 1442.0, 200.0, 200.0, 93.0, 194.0, 200.0, 200.0, 78.0, 174.0, 180.0, 138.0, 154.0, 27.0, 106.0, 196.0, 200.0, 177.0, 96.0, 32.0, 200.0, 1739.0, 168.0, 122.0, 110.0, 110.0, 200.0, 86.0, 98.0, 200.0, 70.0, 195.0, 133.0, 144.0, 195.0, 199.0, 115.0, 79.0, 200.0, 200.0, 200.0, 198.0, 53.0, 119.0, 200.0, 200.0, 186.0, 128.0, 181.0, 1262.0, 200.0, 104.0, 776.0, 82.0, 200.0, 200.0, 190.0, 190.0, 1133.0, 200.0, 23.0, 181.0, 53.0, 186.0, 182.0, 189.0, 153.0, 134.0, 41.0, 177.0, 86.0, 177.0, 190.0, 129.0, 46.0, 69.0, 91.0, 200.0, 135.0, 1.0, 80.0, 200.0, 190.0, 148.0, 1676.0, 1676.0, 200.0, 89.0, 193.0, 22.0, 69.0, 69.0, 51.0, 58.0, 186.0, 13.0, 4.0, 200.0, 200.0, 200.0, 42.0, 144.0, 1451.0, 200.0, 46.0, 69.0, 45.0, 848.0, 131.0, 166.0, 197.0, 159.0, 200.0, 173.0, 139.0, 61.0, 176.0, 200.0, 71.0, 200.0, 146.0, 17.0, 200.0, 200.0, 80.0, 71.0, 195.0, 1073.0, 1073.0, 200.0, 165.0, 97.0, 175.0, 181.0, 88.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5722358091992522, "mean_inference_ms": 1.796967252633043, "mean_action_processing_ms": 0.24486784227005728, "mean_env_wait_ms": 0.19169311007085935, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010115385055541992, "StateBufferConnector_ms": 0.007093548774719238, "ViewRequirementAgentConnector_ms": 0.13820016384124756}, "num_episodes": 18, "episode_return_max": 36.90000000000028, "episode_return_min": -1336.9, "episode_return_mean": -234.68600000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.41064792397617, "num_env_steps_trained_throughput_per_sec": 378.41064792397617, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 10016.041, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10015.998, "sample_time_ms": 1309.855, "learn_time_ms": 8690.91, "learn_throughput": 460.251, "synch_weights_time_ms": 13.886}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-19-48", "timestamp": 1723645188, "time_this_iter_s": 10.575138092041016, "time_total_s": 1052.6276772022247, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x31877c0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1052.6276772022247, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 33.61333333333333, "ram_util_percent": 80.78666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4573121630542336, "cur_kl_coeff": 4.1760815656743936e-05, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": -0.00022888992858863383, "vf_loss": 1.6987979782006097, "vf_explained_var": 0.0012937167334178138, "kl": Infinity, "entropy": 1.2692102308657252e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.568281024584064, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.112033299541977, "policy_loss": 0.0030634881679717668, "vf_loss": 8.091108978614605, "vf_explained_var": 3.7497313565047327e-08, "kl": 0.006969022455143719, "entropy": 0.5158106006169445, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 38.900000000000254, "episode_reward_min": -1336.9, "episode_reward_mean": -241.34800000000018, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1749.5, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 38.900000000000254, "predator_policy": 1739.0}, "policy_reward_mean": {"prey_policy": -353.00900000000007, "predator_policy": 232.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.699999999999964, -392.29999999999995, -312.2999999999997, -46.499999999999794, -225.1000000000009, -118.60000000000002, -381.1, -393.0999999999996, -76.00000000000003, -18.999999999999872, -654.0, -192.1000000000005, -93.00000000000013, 20.000000000000014, -281.5999999999981, -220.70000000000027, -148.30000000000092, -189.60000000000073, -358.5, -100.80000000000155, -1336.9, -123.60000000000102, -166.30000000000112, -89.80000000000061, -479.8, -299.4999999999992, -82.0000000000012, -393.4, -173.40000000000117, -252.99999999999872, -376.8, -185.80000000000112, -400.0, -64.50000000000038, -261.09999999999957, -334.29999999999967, -33.999999999999886, -221.50000000000048, -368.1, -292.7, -517.7, -141.00000000000045, -287.4, -254.6999999999981, -126.30000000000064, -319.50000000000045, -338.19999999999845, 10.099999999999941, -359.90000000000043, -109.60000000000105, -233.20000000000067, -392.70000000000005, -40.0, -363.9999999999987, -156.60000000000056, 36.70000000000025, 27.200000000000117, -514.9, -556.7, -205.30000000000024, -156.50000000000114, -896.4, 25.70000000000013, -264.3000000000004, -6.2000000000000615, -351.59999999999997, -82.30000000000038, -287.9999999999973, -4.000000000000023, -252.7000000000007, -139.30000000000112, 26.30000000000011, -126.1000000000014, -292.2, -303.0, -454.0, -192.00000000000054, -451.7, -224.90000000000006, -269.9, 10.699999999999964, -812.0, -38.00000000000001, -357.7, -25.799999999999876, -378.0, 17.099999999999973, -224.5, -241.10000000000053, 38.900000000000254, -162.70000000000064, -345.2, -139.5000000000007, -344.8, -200.20000000000076, -263.1, -235.60000000000068, -401.0, -401.10000000000036, 20.000000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.700000000000212, -400.0, -385.29999999999995, -400.0, -348.69999999999976, -355.6, -292.89999999999884, 13.399999999999972, -400.0, -66.1000000000009, -118.60000000000002, -400.0, -400.0, -381.1, -327.0999999999999, -400.0, -400.0, 20.000000000000014, -1088.0, 20.000000000000014, -1504.0, -792.0, -192.1000000000005, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -188.20000000000041, -345.3999999999994, -259.3, -279.3999999999988, -292.5999999999993, -36.69999999999978, -91.60000000000075, -400.0, -335.5, -400.0, -181.6000000000006, -47.19999999999976, -1552.0, -1723.9, -80.80000000000084, -332.7999999999993, -211.0000000000005, -175.3000000000006, -400.0, 24.20000000000008, -400.0, -377.8, -164.50000000000054, -400.0, -76.60000000000088, -282.3999999999987, -397.9, -389.5, -145.9000000000007, -221.50000000000048, -400.0, -252.9999999999993, -374.8, -400.0, -140.8000000000007, -217.00000000000045, -400.0, -400.0, -215.8000000000004, -162.70000000000002, -1344.0, -360.09999999999957, -400.0, -238.30000000000038, 20.000000000000014, -912.0, -400.0, -221.50000000000048, -375.4, -372.7, -1225.7, -400.0, -361.59999999999997, -360.1, -400.0, 20.000000000000014, -281.5, -376.9, -301.29999999999893, -240.40000000000043, -351.6999999999995, 7.399999999999965, -346.3, -236.20000000000044, -378.9999999999998, -278.1999999999987, -124.90000000000074, 20.000000000000014, -250.9000000000004, -400.0, 17.899999999999988, -263.4999999999985, -156.40000000000066, -356.8, -400.0, -330.7, -1704.0, -1688.0, -280.2999999999987, -372.7, -391.5999999999999, 20.000000000000014, 23.600000000000065, -124.90000000000074, 20.000000000000014, -101.80000000000081, -362.2, -351.70000000000005, -360.7, -400.0, -320.19999999999914, -285.1, -121.00000000000068, -221.50000000000048, -1048.0, -1499.4, 35.60000000000025, -124.90000000000074, -214.00000000000037, -943.3, -328.5999999999992, 25.400000000000098, -313.9, -393.7, -129.10000000000073, -326.2, -244.60000000000036, -243.40000000000032, -400.0, 20.000000000000014, -123.7000000000007, -400.0, -15.699999999999754, -286.5999999999988, -400.0, 26.300000000000114, -217.3000000000005, -59.80000000000061, -1181.5, -378.7, -1176.0, -400.0, -360.1, -355.9, -187.90000000000057, -360.1, -339.7, -400.0, -109.89999999999986, -400.0, -192.10000000000045, -380.8, 31.700000000000212, -400.0, -1648.0, -968.0, 20.000000000000014, -400.0, -345.7, -400.0, -24.099999999999795, -207.6999999999999, -358.0, -400.0, -400.0, 37.10000000000025, -400.0, -1749.5, -164.80000000000052, -343.3, -400.0, 38.900000000000254, -395.8, -166.90000000000063, -329.2, -400.0, -137.5000000000007, -400.0, -338.8, -400.0, -116.50000000000077, -366.7, -261.1, -400.0, -358.6, -148.00000000000068, -400.0, -400.0, -400.0, -255.1000000000004, -400.0, 20.000000000000014], "policy_predator_policy_reward": [200.0, 183.0, 193.0, 200.0, 196.0, 196.0, 84.0, 149.0, 41.0, 200.0, 200.0, 200.0, 200.0, 200.0, 134.0, 200.0, 200.0, 104.0, 75.0, 974.0, 200.0, 1442.0, 200.0, 200.0, 93.0, 194.0, 200.0, 200.0, 78.0, 174.0, 180.0, 138.0, 154.0, 27.0, 106.0, 196.0, 200.0, 177.0, 96.0, 32.0, 200.0, 1739.0, 168.0, 122.0, 110.0, 110.0, 200.0, 86.0, 98.0, 200.0, 70.0, 195.0, 133.0, 144.0, 195.0, 199.0, 115.0, 79.0, 200.0, 200.0, 200.0, 198.0, 53.0, 119.0, 200.0, 200.0, 186.0, 128.0, 181.0, 1262.0, 200.0, 104.0, 776.0, 82.0, 200.0, 200.0, 190.0, 190.0, 1133.0, 200.0, 23.0, 181.0, 53.0, 186.0, 182.0, 189.0, 153.0, 134.0, 41.0, 177.0, 86.0, 177.0, 190.0, 129.0, 46.0, 69.0, 91.0, 200.0, 135.0, 1.0, 80.0, 200.0, 190.0, 148.0, 1676.0, 1676.0, 200.0, 89.0, 193.0, 22.0, 69.0, 69.0, 51.0, 58.0, 186.0, 13.0, 4.0, 200.0, 200.0, 200.0, 42.0, 144.0, 1451.0, 200.0, 46.0, 69.0, 45.0, 848.0, 131.0, 166.0, 197.0, 159.0, 200.0, 173.0, 139.0, 61.0, 176.0, 200.0, 71.0, 200.0, 146.0, 17.0, 200.0, 200.0, 80.0, 71.0, 195.0, 1073.0, 1073.0, 200.0, 165.0, 97.0, 175.0, 181.0, 88.0, 200.0, 200.0, 85.0, 122.0, 181.0, 179.0, 200.0, 1604.0, 200.0, 200.0, 142.0, 200.0, 188.0, 113.0, 93.0, 200.0, 180.0, 180.0, 200.0, 1725.0, 200.0, 173.0, 94.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 198.0, 200.0, 200.0, 194.0, 200.0, 83.0, 200.0, 198.0, 200.0, 71.0, 199.0, 200.0, 54.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5723104791356383, "mean_inference_ms": 1.7966468410147263, "mean_action_processing_ms": 0.2447770646594409, "mean_env_wait_ms": 0.1916778757799927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010768532752990723, "StateBufferConnector_ms": 0.007125258445739746, "ViewRequirementAgentConnector_ms": 0.13677668571472168}, "num_episodes": 22, "episode_return_max": 38.900000000000254, "episode_return_min": -1336.9, "episode_return_mean": -241.34800000000018, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 421.015227621335, "num_env_steps_trained_throughput_per_sec": 421.015227621335, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 10038.152, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10038.11, "sample_time_ms": 1306.53, "learn_time_ms": 8716.641, "learn_throughput": 458.892, "synch_weights_time_ms": 13.73}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-19-57", "timestamp": 1723645197, "time_this_iter_s": 9.504731178283691, "time_total_s": 1062.1324083805084, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae49790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1062.1324083805084, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 30.050000000000008, "ram_util_percent": 80.29285714285716}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0398132300112772, "cur_kl_coeff": 6.264122348511592e-05, "cur_lr": 0.009999999999999998, "total_loss": 2.3941507079298536, "policy_loss": -0.000321584326220016, "vf_loss": 2.3944722839133448, "vf_explained_var": 0.0008839802451865383, "kl": 6.42788209857695e-44, "entropy": 1.6516447054437473e-35, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.66063059124524, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.247738834663673, "policy_loss": 0.0032943531363295816, "vf_loss": 8.224176708857218, "vf_explained_var": 1.0962208742817874e-07, "kl": 0.007908171840715532, "entropy": 0.4809334688874149, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 38.900000000000254, "episode_reward_min": -896.4, "episode_reward_mean": -249.98200000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1749.5, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 38.900000000000254, "predator_policy": 1725.0}, "policy_reward_mean": {"prey_policy": -344.036, "predator_policy": 219.045}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-89.80000000000061, -479.8, -299.4999999999992, -82.0000000000012, -393.4, -173.40000000000117, -252.99999999999872, -376.8, -185.80000000000112, -400.0, -64.50000000000038, -261.09999999999957, -334.29999999999967, -33.999999999999886, -221.50000000000048, -368.1, -292.7, -517.7, -141.00000000000045, -287.4, -254.6999999999981, -126.30000000000064, -319.50000000000045, -338.19999999999845, 10.099999999999941, -359.90000000000043, -109.60000000000105, -233.20000000000067, -392.70000000000005, -40.0, -363.9999999999987, -156.60000000000056, 36.70000000000025, 27.200000000000117, -514.9, -556.7, -205.30000000000024, -156.50000000000114, -896.4, 25.70000000000013, -264.3000000000004, -6.2000000000000615, -351.59999999999997, -82.30000000000038, -287.9999999999973, -4.000000000000023, -252.7000000000007, -139.30000000000112, 26.30000000000011, -126.1000000000014, -292.2, -303.0, -454.0, -192.00000000000054, -451.7, -224.90000000000006, -269.9, 10.699999999999964, -812.0, -38.00000000000001, -357.7, -25.799999999999876, -378.0, 17.099999999999973, -224.5, -241.10000000000053, 38.900000000000254, -162.70000000000064, -345.2, -139.5000000000007, -344.8, -200.20000000000076, -263.1, -235.60000000000068, -401.0, -401.10000000000036, 20.000000000000014, -391.8, -115.00000000000065, -24.00000000000002, -47.0, -7.200000000000003, -526.0, -336.3, -100.30000000000018, -404.0, -400.0, -298.099999999998, -400.0, -343.0999999999998, -261.49999999999903, -364.9999999999994, -366.7, -320.9, -427.0, -355.9, -400.0, -427.9999999999993, -373.8, 33.500000000000234], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 24.20000000000008, -400.0, -377.8, -164.50000000000054, -400.0, -76.60000000000088, -282.3999999999987, -397.9, -389.5, -145.9000000000007, -221.50000000000048, -400.0, -252.9999999999993, -374.8, -400.0, -140.8000000000007, -217.00000000000045, -400.0, -400.0, -215.8000000000004, -162.70000000000002, -1344.0, -360.09999999999957, -400.0, -238.30000000000038, 20.000000000000014, -912.0, -400.0, -221.50000000000048, -375.4, -372.7, -1225.7, -400.0, -361.59999999999997, -360.1, -400.0, 20.000000000000014, -281.5, -376.9, -301.29999999999893, -240.40000000000043, -351.6999999999995, 7.399999999999965, -346.3, -236.20000000000044, -378.9999999999998, -278.1999999999987, -124.90000000000074, 20.000000000000014, -250.9000000000004, -400.0, 17.899999999999988, -263.4999999999985, -156.40000000000066, -356.8, -400.0, -330.7, -1704.0, -1688.0, -280.2999999999987, -372.7, -391.5999999999999, 20.000000000000014, 23.600000000000065, -124.90000000000074, 20.000000000000014, -101.80000000000081, -362.2, -351.70000000000005, -360.7, -400.0, -320.19999999999914, -285.1, -121.00000000000068, -221.50000000000048, -1048.0, -1499.4, 35.60000000000025, -124.90000000000074, -214.00000000000037, -943.3, -328.5999999999992, 25.400000000000098, -313.9, -393.7, -129.10000000000073, -326.2, -244.60000000000036, -243.40000000000032, -400.0, 20.000000000000014, -123.7000000000007, -400.0, -15.699999999999754, -286.5999999999988, -400.0, 26.300000000000114, -217.3000000000005, -59.80000000000061, -1181.5, -378.7, -1176.0, -400.0, -360.1, -355.9, -187.90000000000057, -360.1, -339.7, -400.0, -109.89999999999986, -400.0, -192.10000000000045, -380.8, 31.700000000000212, -400.0, -1648.0, -968.0, 20.000000000000014, -400.0, -345.7, -400.0, -24.099999999999795, -207.6999999999999, -358.0, -400.0, -400.0, 37.10000000000025, -400.0, -1749.5, -164.80000000000052, -343.3, -400.0, 38.900000000000254, -395.8, -166.90000000000063, -329.2, -400.0, -137.5000000000007, -400.0, -338.8, -400.0, -116.50000000000077, -366.7, -261.1, -400.0, -358.6, -148.00000000000068, -400.0, -400.0, -400.0, -255.1000000000004, -400.0, 20.000000000000014, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -347.5, -353.8, -400.0, 22.700000000000053, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -276.09999999999866, -400.0, -400.0, -381.0999999999998, -325.0, -330.7, -311.79999999999905, -333.9999999999994, -400.0, -348.7, -400.0, -262.9, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -368.8, -400.0, 30.800000000000196, -343.3], "policy_predator_policy_reward": [200.0, 86.0, 98.0, 200.0, 70.0, 195.0, 133.0, 144.0, 195.0, 199.0, 115.0, 79.0, 200.0, 200.0, 200.0, 198.0, 53.0, 119.0, 200.0, 200.0, 186.0, 128.0, 181.0, 1262.0, 200.0, 104.0, 776.0, 82.0, 200.0, 200.0, 190.0, 190.0, 1133.0, 200.0, 23.0, 181.0, 53.0, 186.0, 182.0, 189.0, 153.0, 134.0, 41.0, 177.0, 86.0, 177.0, 190.0, 129.0, 46.0, 69.0, 91.0, 200.0, 135.0, 1.0, 80.0, 200.0, 190.0, 148.0, 1676.0, 1676.0, 200.0, 89.0, 193.0, 22.0, 69.0, 69.0, 51.0, 58.0, 186.0, 13.0, 4.0, 200.0, 200.0, 200.0, 42.0, 144.0, 1451.0, 200.0, 46.0, 69.0, 45.0, 848.0, 131.0, 166.0, 197.0, 159.0, 200.0, 173.0, 139.0, 61.0, 176.0, 200.0, 71.0, 200.0, 146.0, 17.0, 200.0, 200.0, 80.0, 71.0, 195.0, 1073.0, 1073.0, 200.0, 165.0, 97.0, 175.0, 181.0, 88.0, 200.0, 200.0, 85.0, 122.0, 181.0, 179.0, 200.0, 1604.0, 200.0, 200.0, 142.0, 200.0, 188.0, 113.0, 93.0, 200.0, 180.0, 180.0, 200.0, 1725.0, 200.0, 173.0, 94.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 198.0, 200.0, 200.0, 194.0, 200.0, 83.0, 200.0, 198.0, 200.0, 71.0, 199.0, 200.0, 54.0, 200.0, 200.0, 200.0, 200.0, 195.0, 65.0, 200.0, 170.0, 186.0, 200.0, 133.0, 200.0, 171.0, 74.0, 200.0, 184.0, 181.0, 200.0, 77.0, 196.0, 200.0, 200.0, 200.0, 170.0, 145.0, 200.0, 200.0, 172.0, 191.0, 200.0, 181.0, 200.0, 169.0, 182.0, 200.0, 142.0, 200.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 110.0, 199.0, 197.0, 198.0, 173.0, 173.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5723196311027688, "mean_inference_ms": 1.8012053820292777, "mean_action_processing_ms": 0.24502978003461287, "mean_env_wait_ms": 0.1915267008755017, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010669231414794922, "StateBufferConnector_ms": 0.00705564022064209, "ViewRequirementAgentConnector_ms": 0.13292181491851807}, "num_episodes": 23, "episode_return_max": 38.900000000000254, "episode_return_min": -896.4, "episode_return_mean": -249.98200000000006, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 410.0792099947852, "num_env_steps_trained_throughput_per_sec": 410.0792099947852, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 10037.283, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10037.24, "sample_time_ms": 1298.889, "learn_time_ms": 8723.566, "learn_throughput": 458.528, "synch_weights_time_ms": 13.578}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-20-07", "timestamp": 1723645207, "time_this_iter_s": 9.7586829662323, "time_total_s": 1071.8910913467407, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d1040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1071.8910913467407, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 27.449999999999996, "ram_util_percent": 80.47857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3058132632024506, "cur_kl_coeff": 3.132061174255796e-05, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": -0.000143854217800908, "vf_loss": 1.6264490466584605, "vf_explained_var": 0.000303280511230388, "kl": Infinity, "entropy": 8.22330643785554e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.574490595904608, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.530522624525444, "policy_loss": 0.002776545811341041, "vf_loss": 8.506506620639216, "vf_explained_var": -1.3907750447591146e-08, "kl": 0.008287316136228242, "entropy": 0.4843821515324255, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 38.900000000000254, "episode_reward_min": -896.4, "episode_reward_mean": -256.656, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1749.5, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 38.900000000000254, "predator_policy": 1725.0}, "policy_reward_mean": {"prey_policy": -338.69800000000004, "predator_policy": 210.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-141.00000000000045, -287.4, -254.6999999999981, -126.30000000000064, -319.50000000000045, -338.19999999999845, 10.099999999999941, -359.90000000000043, -109.60000000000105, -233.20000000000067, -392.70000000000005, -40.0, -363.9999999999987, -156.60000000000056, 36.70000000000025, 27.200000000000117, -514.9, -556.7, -205.30000000000024, -156.50000000000114, -896.4, 25.70000000000013, -264.3000000000004, -6.2000000000000615, -351.59999999999997, -82.30000000000038, -287.9999999999973, -4.000000000000023, -252.7000000000007, -139.30000000000112, 26.30000000000011, -126.1000000000014, -292.2, -303.0, -454.0, -192.00000000000054, -451.7, -224.90000000000006, -269.9, 10.699999999999964, -812.0, -38.00000000000001, -357.7, -25.799999999999876, -378.0, 17.099999999999973, -224.5, -241.10000000000053, 38.900000000000254, -162.70000000000064, -345.2, -139.5000000000007, -344.8, -200.20000000000076, -263.1, -235.60000000000068, -401.0, -401.10000000000036, 20.000000000000014, -391.8, -115.00000000000065, -24.00000000000002, -47.0, -7.200000000000003, -526.0, -336.3, -100.30000000000018, -404.0, -400.0, -298.099999999998, -400.0, -343.0999999999998, -261.49999999999903, -364.9999999999994, -366.7, -320.9, -427.0, -355.9, -400.0, -427.9999999999993, -373.8, 33.500000000000234, -315.2999999999985, -400.0, -11.80000000000004, -410.0, -400.0, -49.89999999999977, -375.8, 10.199999999999957, -400.0, -298.5999999999993, 20.000000000000018, -537.0, -391.89999999999975, -468.8, -371.4, -391.59999999999997, -378.7999999999999, -324.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 20.000000000000014, -281.5, -376.9, -301.29999999999893, -240.40000000000043, -351.6999999999995, 7.399999999999965, -346.3, -236.20000000000044, -378.9999999999998, -278.1999999999987, -124.90000000000074, 20.000000000000014, -250.9000000000004, -400.0, 17.899999999999988, -263.4999999999985, -156.40000000000066, -356.8, -400.0, -330.7, -1704.0, -1688.0, -280.2999999999987, -372.7, -391.5999999999999, 20.000000000000014, 23.600000000000065, -124.90000000000074, 20.000000000000014, -101.80000000000081, -362.2, -351.70000000000005, -360.7, -400.0, -320.19999999999914, -285.1, -121.00000000000068, -221.50000000000048, -1048.0, -1499.4, 35.60000000000025, -124.90000000000074, -214.00000000000037, -943.3, -328.5999999999992, 25.400000000000098, -313.9, -393.7, -129.10000000000073, -326.2, -244.60000000000036, -243.40000000000032, -400.0, 20.000000000000014, -123.7000000000007, -400.0, -15.699999999999754, -286.5999999999988, -400.0, 26.300000000000114, -217.3000000000005, -59.80000000000061, -1181.5, -378.7, -1176.0, -400.0, -360.1, -355.9, -187.90000000000057, -360.1, -339.7, -400.0, -109.89999999999986, -400.0, -192.10000000000045, -380.8, 31.700000000000212, -400.0, -1648.0, -968.0, 20.000000000000014, -400.0, -345.7, -400.0, -24.099999999999795, -207.6999999999999, -358.0, -400.0, -400.0, 37.10000000000025, -400.0, -1749.5, -164.80000000000052, -343.3, -400.0, 38.900000000000254, -395.8, -166.90000000000063, -329.2, -400.0, -137.5000000000007, -400.0, -338.8, -400.0, -116.50000000000077, -366.7, -261.1, -400.0, -358.6, -148.00000000000068, -400.0, -400.0, -400.0, -255.1000000000004, -400.0, 20.000000000000014, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -347.5, -353.8, -400.0, 22.700000000000053, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -276.09999999999866, -400.0, -400.0, -381.0999999999998, -325.0, -330.7, -311.79999999999905, -333.9999999999994, -400.0, -348.7, -400.0, -262.9, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -368.8, -400.0, 30.800000000000196, -343.3, -400.0, -238.30000000000044, -400.0, -400.0, 20.000000000000014, -386.8, -400.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -353.8, -374.8, 20.000000000000014, -400.0, -400.0, -332.7999999999993, -347.8, 20.000000000000014, -400.0, -400.0, -400.0, -376.89999999999975, -400.0, -374.8, -400.0, -365.8, -388.6, -397.9, -393.7, -400.0, -320.7999999999999, -400.0, -324.1], "policy_predator_policy_reward": [53.0, 186.0, 182.0, 189.0, 153.0, 134.0, 41.0, 177.0, 86.0, 177.0, 190.0, 129.0, 46.0, 69.0, 91.0, 200.0, 135.0, 1.0, 80.0, 200.0, 190.0, 148.0, 1676.0, 1676.0, 200.0, 89.0, 193.0, 22.0, 69.0, 69.0, 51.0, 58.0, 186.0, 13.0, 4.0, 200.0, 200.0, 200.0, 42.0, 144.0, 1451.0, 200.0, 46.0, 69.0, 45.0, 848.0, 131.0, 166.0, 197.0, 159.0, 200.0, 173.0, 139.0, 61.0, 176.0, 200.0, 71.0, 200.0, 146.0, 17.0, 200.0, 200.0, 80.0, 71.0, 195.0, 1073.0, 1073.0, 200.0, 165.0, 97.0, 175.0, 181.0, 88.0, 200.0, 200.0, 85.0, 122.0, 181.0, 179.0, 200.0, 1604.0, 200.0, 200.0, 142.0, 200.0, 188.0, 113.0, 93.0, 200.0, 180.0, 180.0, 200.0, 1725.0, 200.0, 173.0, 94.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 198.0, 200.0, 200.0, 194.0, 200.0, 83.0, 200.0, 198.0, 200.0, 71.0, 199.0, 200.0, 54.0, 200.0, 200.0, 200.0, 200.0, 195.0, 65.0, 200.0, 170.0, 186.0, 200.0, 133.0, 200.0, 171.0, 74.0, 200.0, 184.0, 181.0, 200.0, 77.0, 196.0, 200.0, 200.0, 200.0, 170.0, 145.0, 200.0, 200.0, 172.0, 191.0, 200.0, 181.0, 200.0, 169.0, 182.0, 200.0, 142.0, 200.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 110.0, 199.0, 197.0, 198.0, 173.0, 173.0, 200.0, 123.0, 200.0, 200.0, 160.0, 195.0, 200.0, 190.0, 200.0, 200.0, 200.0, 113.0, 178.0, 200.0, 191.0, 174.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 63.0, 200.0, 200.0, 185.0, 200.0, 106.0, 195.0, 188.0, 200.0, 200.0, 167.0, 175.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5722284295053665, "mean_inference_ms": 1.7956674572934945, "mean_action_processing_ms": 0.2445297323382799, "mean_env_wait_ms": 0.19154142658699436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007645368576049805, "StateBufferConnector_ms": 0.003378152847290039, "ViewRequirementAgentConnector_ms": 0.11233484745025635}, "num_episodes": 18, "episode_return_max": 38.900000000000254, "episode_return_min": -896.4, "episode_return_mean": -256.656, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 414.73408599872835, "num_env_steps_trained_throughput_per_sec": 414.73408599872835, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 10084.966, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10084.924, "sample_time_ms": 1291.837, "learn_time_ms": 8778.018, "learn_throughput": 455.684, "synch_weights_time_ms": 13.865}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-20-17", "timestamp": 1723645217, "time_this_iter_s": 9.650697231292725, "time_total_s": 1081.5417885780334, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8cc310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1081.5417885780334, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 28.678571428571438, "ram_util_percent": 80.29285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1374790163513606, "cur_kl_coeff": 4.698091761383694e-05, "cur_lr": 0.009999999999999998, "total_loss": 2.9299723776559983, "policy_loss": -0.000165205009567438, "vf_loss": 2.930137592207187, "vf_explained_var": 1.207135972522554e-06, "kl": 6.767381869378184e-44, "entropy": 5.228787776636779e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.748020777051096, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.961536397631206, "policy_loss": 0.003140982898031041, "vf_loss": 7.935083950133551, "vf_explained_var": 1.4018129419397423e-07, "kl": 0.009095775287843777, "entropy": 0.4383543926808569, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 440.0, "episode_reward_min": -896.4, "episode_reward_mean": -255.98699999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1749.5, "predator_policy": 17.0}, "policy_reward_max": {"prey_policy": 38.900000000000254, "predator_policy": 1725.0}, "policy_reward_mean": {"prey_policy": -342.7835, "predator_policy": 214.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-205.30000000000024, -156.50000000000114, -896.4, 25.70000000000013, -264.3000000000004, -6.2000000000000615, -351.59999999999997, -82.30000000000038, -287.9999999999973, -4.000000000000023, -252.7000000000007, -139.30000000000112, 26.30000000000011, -126.1000000000014, -292.2, -303.0, -454.0, -192.00000000000054, -451.7, -224.90000000000006, -269.9, 10.699999999999964, -812.0, -38.00000000000001, -357.7, -25.799999999999876, -378.0, 17.099999999999973, -224.5, -241.10000000000053, 38.900000000000254, -162.70000000000064, -345.2, -139.5000000000007, -344.8, -200.20000000000076, -263.1, -235.60000000000068, -401.0, -401.10000000000036, 20.000000000000014, -391.8, -115.00000000000065, -24.00000000000002, -47.0, -7.200000000000003, -526.0, -336.3, -100.30000000000018, -404.0, -400.0, -298.099999999998, -400.0, -343.0999999999998, -261.49999999999903, -364.9999999999994, -366.7, -320.9, -427.0, -355.9, -400.0, -427.9999999999993, -373.8, 33.500000000000234, -315.2999999999985, -400.0, -11.80000000000004, -410.0, -400.0, -49.89999999999977, -375.8, 10.199999999999957, -400.0, -298.5999999999993, 20.000000000000018, -537.0, -391.89999999999975, -468.8, -371.4, -391.59999999999997, -378.7999999999999, -324.1, 15.300000000000114, -264.7000000000005, 17.899999999999974, -363.99999999999983, -395.8, -38.6999999999998, -400.0, -400.0, -400.0, 440.0, -363.7, -461.3000000000002, -358.5, -389.7999999999993, 44.10000000000038, -354.8, 34.20000000000026, -414.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-320.19999999999914, -285.1, -121.00000000000068, -221.50000000000048, -1048.0, -1499.4, 35.60000000000025, -124.90000000000074, -214.00000000000037, -943.3, -328.5999999999992, 25.400000000000098, -313.9, -393.7, -129.10000000000073, -326.2, -244.60000000000036, -243.40000000000032, -400.0, 20.000000000000014, -123.7000000000007, -400.0, -15.699999999999754, -286.5999999999988, -400.0, 26.300000000000114, -217.3000000000005, -59.80000000000061, -1181.5, -378.7, -1176.0, -400.0, -360.1, -355.9, -187.90000000000057, -360.1, -339.7, -400.0, -109.89999999999986, -400.0, -192.10000000000045, -380.8, 31.700000000000212, -400.0, -1648.0, -968.0, 20.000000000000014, -400.0, -345.7, -400.0, -24.099999999999795, -207.6999999999999, -358.0, -400.0, -400.0, 37.10000000000025, -400.0, -1749.5, -164.80000000000052, -343.3, -400.0, 38.900000000000254, -395.8, -166.90000000000063, -329.2, -400.0, -137.5000000000007, -400.0, -338.8, -400.0, -116.50000000000077, -366.7, -261.1, -400.0, -358.6, -148.00000000000068, -400.0, -400.0, -400.0, -255.1000000000004, -400.0, 20.000000000000014, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -347.5, -353.8, -400.0, 22.700000000000053, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -276.09999999999866, -400.0, -400.0, -381.0999999999998, -325.0, -330.7, -311.79999999999905, -333.9999999999994, -400.0, -348.7, -400.0, -262.9, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -368.8, -400.0, 30.800000000000196, -343.3, -400.0, -238.30000000000044, -400.0, -400.0, 20.000000000000014, -386.8, -400.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -353.8, -374.8, 20.000000000000014, -400.0, -400.0, -332.7999999999993, -347.8, 20.000000000000014, -400.0, -400.0, -400.0, -376.89999999999975, -400.0, -374.8, -400.0, -365.8, -388.6, -397.9, -393.7, -400.0, -320.7999999999999, -400.0, -324.1, 26.300000000000114, -400.0, -99.70000000000081, -400.0, -213.1000000000005, 20.000000000000014, -380.8, -383.1999999999998, -395.8, -400.0, 35.30000000000026, -936.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -1072.0, -400.0, -400.0, -363.7, -322.3000000000002, -400.0, -366.7, -377.8, -400.0, -326.7999999999993, -82.90000000000086, 29.000000000000163, -326.8, -400.0, 36.20000000000026, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 42.0, 144.0, 1451.0, 200.0, 46.0, 69.0, 45.0, 848.0, 131.0, 166.0, 197.0, 159.0, 200.0, 173.0, 139.0, 61.0, 176.0, 200.0, 71.0, 200.0, 146.0, 17.0, 200.0, 200.0, 80.0, 71.0, 195.0, 1073.0, 1073.0, 200.0, 165.0, 97.0, 175.0, 181.0, 88.0, 200.0, 200.0, 85.0, 122.0, 181.0, 179.0, 200.0, 1604.0, 200.0, 200.0, 142.0, 200.0, 188.0, 113.0, 93.0, 200.0, 180.0, 180.0, 200.0, 1725.0, 200.0, 173.0, 94.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 198.0, 200.0, 200.0, 194.0, 200.0, 83.0, 200.0, 198.0, 200.0, 71.0, 199.0, 200.0, 54.0, 200.0, 200.0, 200.0, 200.0, 195.0, 65.0, 200.0, 170.0, 186.0, 200.0, 133.0, 200.0, 171.0, 74.0, 200.0, 184.0, 181.0, 200.0, 77.0, 196.0, 200.0, 200.0, 200.0, 170.0, 145.0, 200.0, 200.0, 172.0, 191.0, 200.0, 181.0, 200.0, 169.0, 182.0, 200.0, 142.0, 200.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 110.0, 199.0, 197.0, 198.0, 173.0, 173.0, 200.0, 123.0, 200.0, 200.0, 160.0, 195.0, 200.0, 190.0, 200.0, 200.0, 200.0, 113.0, 178.0, 200.0, 191.0, 174.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 63.0, 200.0, 200.0, 185.0, 200.0, 106.0, 195.0, 188.0, 200.0, 200.0, 167.0, 175.0, 200.0, 200.0, 189.0, 200.0, 35.0, 200.0, 102.0, 109.0, 200.0, 200.0, 200.0, 200.0, 803.0, 59.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 956.0, 956.0, 200.0, 200.0, 61.0, 200.0, 194.0, 192.0, 200.0, 137.0, 49.0, 49.0, 172.0, 200.0, 200.0, 198.0, 200.0, 186.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5721099486695636, "mean_inference_ms": 1.7950507844572792, "mean_action_processing_ms": 0.24438497127360434, "mean_env_wait_ms": 0.1914647235082853, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007207393646240234, "StateBufferConnector_ms": 0.0034084320068359375, "ViewRequirementAgentConnector_ms": 0.11490797996520996}, "num_episodes": 18, "episode_return_max": 440.0, "episode_return_min": -896.4, "episode_return_mean": -255.98699999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 414.0655187004063, "num_env_steps_trained_throughput_per_sec": 414.0655187004063, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 10099.336, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10099.295, "sample_time_ms": 1292.864, "learn_time_ms": 8791.17, "learn_throughput": 455.002, "synch_weights_time_ms": 14.071}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-20-26", "timestamp": 1723645226, "time_this_iter_s": 9.665884017944336, "time_total_s": 1091.2076725959778, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8ccd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1091.2076725959778, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 28.661538461538466, "ram_util_percent": 80.58461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4839846228323283, "cur_kl_coeff": 2.349045880691847e-05, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": 0.00012292587863547462, "vf_loss": 2.089141801393852, "vf_explained_var": 2.6296023969297057e-05, "kl": Infinity, "entropy": 7.205644128243118e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.850272343295907, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.720720134462629, "policy_loss": 0.002258992765749258, "vf_loss": 7.696717968441191, "vf_explained_var": 1.3686992503978588e-08, "kl": 0.008483840846924445, "entropy": 0.48936210843148054, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 440.0, "episode_reward_min": -812.0, "episode_reward_mean": -252.76499999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1749.5, "predator_policy": 7.0}, "policy_reward_max": {"prey_policy": 38.900000000000254, "predator_policy": 1725.0}, "policy_reward_mean": {"prey_policy": -333.6025, "predator_policy": 207.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-812.0, -38.00000000000001, -357.7, -25.799999999999876, -378.0, 17.099999999999973, -224.5, -241.10000000000053, 38.900000000000254, -162.70000000000064, -345.2, -139.5000000000007, -344.8, -200.20000000000076, -263.1, -235.60000000000068, -401.0, -401.10000000000036, 20.000000000000014, -391.8, -115.00000000000065, -24.00000000000002, -47.0, -7.200000000000003, -526.0, -336.3, -100.30000000000018, -404.0, -400.0, -298.099999999998, -400.0, -343.0999999999998, -261.49999999999903, -364.9999999999994, -366.7, -320.9, -427.0, -355.9, -400.0, -427.9999999999993, -373.8, 33.500000000000234, -315.2999999999985, -400.0, -11.80000000000004, -410.0, -400.0, -49.89999999999977, -375.8, 10.199999999999957, -400.0, -298.5999999999993, 20.000000000000018, -537.0, -391.89999999999975, -468.8, -371.4, -391.59999999999997, -378.7999999999999, -324.1, 15.300000000000114, -264.7000000000005, 17.899999999999974, -363.99999999999983, -395.8, -38.6999999999998, -400.0, -400.0, -400.0, 440.0, -363.7, -461.3000000000002, -358.5, -389.7999999999993, 44.10000000000038, -354.8, 34.20000000000026, -414.0, -409.0, -97.80000000000015, -198.3, -220.30000000000067, 35.30000000000025, -99.70000000000081, 37.40000000000026, -169.4000000000006, -411.8, 30.800000000000193, -395.6, -374.69999999999976, -400.0, 23.700000000000067, -6.499999999999893, -343.5, -348.1, -293.2999999999992, -267.10000000000014, -307.8999999999987, 20.000000000000018, -379.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1648.0, -968.0, 20.000000000000014, -400.0, -345.7, -400.0, -24.099999999999795, -207.6999999999999, -358.0, -400.0, -400.0, 37.10000000000025, -400.0, -1749.5, -164.80000000000052, -343.3, -400.0, 38.900000000000254, -395.8, -166.90000000000063, -329.2, -400.0, -137.5000000000007, -400.0, -338.8, -400.0, -116.50000000000077, -366.7, -261.1, -400.0, -358.6, -148.00000000000068, -400.0, -400.0, -400.0, -255.1000000000004, -400.0, 20.000000000000014, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -347.5, -353.8, -400.0, 22.700000000000053, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -276.09999999999866, -400.0, -400.0, -381.0999999999998, -325.0, -330.7, -311.79999999999905, -333.9999999999994, -400.0, -348.7, -400.0, -262.9, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -368.8, -400.0, 30.800000000000196, -343.3, -400.0, -238.30000000000044, -400.0, -400.0, 20.000000000000014, -386.8, -400.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -353.8, -374.8, 20.000000000000014, -400.0, -400.0, -332.7999999999993, -347.8, 20.000000000000014, -400.0, -400.0, -400.0, -376.89999999999975, -400.0, -374.8, -400.0, -365.8, -388.6, -397.9, -393.7, -400.0, -320.7999999999999, -400.0, -324.1, 26.300000000000114, -400.0, -99.70000000000081, -400.0, -213.1000000000005, 20.000000000000014, -380.8, -383.1999999999998, -395.8, -400.0, 35.30000000000026, -936.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -1072.0, -400.0, -400.0, -363.7, -322.3000000000002, -400.0, -366.7, -377.8, -400.0, -326.7999999999993, -82.90000000000086, 29.000000000000163, -326.8, -400.0, 36.20000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -347.8, -319.3, -1368.0, -154.30000000000067, -400.0, -400.0, 35.300000000000246, -99.70000000000081, -400.0, -340.6, 20.000000000000014, 23.600000000000065, -400.0, -392.8, -358.0, 29.90000000000018, -381.1, -391.6, -400.0, -372.69999999999976, -400.0, -400.0, -400.0, -400.0, 31.700000000000212, -200.50000000000054, 20.000000000000014, -323.8, -393.7, -355.9, -362.2, -400.0, -196.30000000000047, -196.30000000000052, -359.8, -238.30000000000035, -391.6, 20.000000000000014, -400.0, -400.0, -363.7], "policy_predator_policy_reward": [1604.0, 200.0, 200.0, 142.0, 200.0, 188.0, 113.0, 93.0, 200.0, 180.0, 180.0, 200.0, 1725.0, 200.0, 173.0, 94.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 198.0, 200.0, 200.0, 194.0, 200.0, 83.0, 200.0, 198.0, 200.0, 71.0, 199.0, 200.0, 54.0, 200.0, 200.0, 200.0, 200.0, 195.0, 65.0, 200.0, 170.0, 186.0, 200.0, 133.0, 200.0, 171.0, 74.0, 200.0, 184.0, 181.0, 200.0, 77.0, 196.0, 200.0, 200.0, 200.0, 170.0, 145.0, 200.0, 200.0, 172.0, 191.0, 200.0, 181.0, 200.0, 169.0, 182.0, 200.0, 142.0, 200.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 110.0, 199.0, 197.0, 198.0, 173.0, 173.0, 200.0, 123.0, 200.0, 200.0, 160.0, 195.0, 200.0, 190.0, 200.0, 200.0, 200.0, 113.0, 178.0, 200.0, 191.0, 174.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 63.0, 200.0, 200.0, 185.0, 200.0, 106.0, 195.0, 188.0, 200.0, 200.0, 167.0, 175.0, 200.0, 200.0, 189.0, 200.0, 35.0, 200.0, 102.0, 109.0, 200.0, 200.0, 200.0, 200.0, 803.0, 59.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 956.0, 956.0, 200.0, 200.0, 61.0, 200.0, 194.0, 192.0, 200.0, 137.0, 49.0, 49.0, 172.0, 200.0, 200.0, 198.0, 200.0, 186.0, 191.0, 200.0, 152.0, 78.0, 1289.0, 200.0, 134.0, 200.0, 200.0, 200.0, 200.0, 200.0, 179.0, 179.0, 200.0, 7.0, 139.0, 200.0, 191.0, 191.0, 196.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 192.0, 105.0, 69.0, 177.0, 197.0, 185.0, 185.0, 103.0, 200.0, 103.0, 186.0, 126.0, 196.0, 200.0, 200.0, 184.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5715739597253223, "mean_inference_ms": 1.7943270953775632, "mean_action_processing_ms": 0.2437144599431509, "mean_env_wait_ms": 0.1912263554562512, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004279613494873047, "StateBufferConnector_ms": 0.0030355453491210938, "ViewRequirementAgentConnector_ms": 0.08976459503173828}, "num_episodes": 22, "episode_return_max": 440.0, "episode_return_min": -812.0, "episode_return_mean": -252.76499999999993, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 414.25513135671713, "num_env_steps_trained_throughput_per_sec": 414.25513135671713, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 10078.736, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10078.695, "sample_time_ms": 1289.917, "learn_time_ms": 8773.368, "learn_throughput": 455.925, "synch_weights_time_ms": 14.256}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-20-36", "timestamp": 1723645236, "time_this_iter_s": 9.660469055175781, "time_total_s": 1100.8681416511536, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8cc0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1100.8681416511536, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 27.064285714285713, "ram_util_percent": 80.37857142857145}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9507565869728016, "cur_kl_coeff": 3.5235688210377694e-05, "cur_lr": 0.009999999999999998, "total_loss": 3.8644027899182034, "policy_loss": 0.00020942574172285656, "vf_loss": 3.8641933496666963, "vf_explained_var": -3.253716640371494e-05, "kl": 6.847085353460151e-44, "entropy": 5.513656616329781e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6394963996356755, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.73850540685906, "policy_loss": 0.002589450904079491, "vf_loss": 7.715091978052937, "vf_explained_var": -7.947285970052083e-09, "kl": 0.008125190928659543, "entropy": 0.4940767341820651, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 440.0, "episode_reward_min": -537.0, "episode_reward_mean": -247.60699999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1752.0, "predator_policy": 7.0}, "policy_reward_max": {"prey_policy": 37.10000000000026, "predator_policy": 1697.0}, "policy_reward_mean": {"prey_policy": -324.3085, "predator_policy": 200.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.000000000000014, -391.8, -115.00000000000065, -24.00000000000002, -47.0, -7.200000000000003, -526.0, -336.3, -100.30000000000018, -404.0, -400.0, -298.099999999998, -400.0, -343.0999999999998, -261.49999999999903, -364.9999999999994, -366.7, -320.9, -427.0, -355.9, -400.0, -427.9999999999993, -373.8, 33.500000000000234, -315.2999999999985, -400.0, -11.80000000000004, -410.0, -400.0, -49.89999999999977, -375.8, 10.199999999999957, -400.0, -298.5999999999993, 20.000000000000018, -537.0, -391.89999999999975, -468.8, -371.4, -391.59999999999997, -378.7999999999999, -324.1, 15.300000000000114, -264.7000000000005, 17.899999999999974, -363.99999999999983, -395.8, -38.6999999999998, -400.0, -400.0, -400.0, 440.0, -363.7, -461.3000000000002, -358.5, -389.7999999999993, 44.10000000000038, -354.8, 34.20000000000026, -414.0, -409.0, -97.80000000000015, -198.3, -220.30000000000067, 35.30000000000025, -99.70000000000081, 37.40000000000026, -169.4000000000006, -411.8, 30.800000000000193, -395.6, -374.69999999999976, -400.0, 23.700000000000067, -6.499999999999893, -343.5, -348.1, -293.2999999999992, -267.10000000000014, -307.8999999999987, 20.000000000000018, -379.7, -496.0, 164.99999999999957, -453.0, -361.8, -192.2000000000001, -102.20000000000059, -314.7999999999973, -365.7, -396.6, -214.80000000000058, -384.7, -141.90000000000072, 2.499999999999963, -393.4, -400.0, 11.000000000000009, 14.99999999999996, 25.100000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 20.000000000000014, -386.8, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -347.5, -353.8, -400.0, 22.700000000000053, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -276.09999999999866, -400.0, -400.0, -381.0999999999998, -325.0, -330.7, -311.79999999999905, -333.9999999999994, -400.0, -348.7, -400.0, -262.9, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, -336.9999999999993, -368.8, -400.0, 30.800000000000196, -343.3, -400.0, -238.30000000000044, -400.0, -400.0, 20.000000000000014, -386.8, -400.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -353.8, -374.8, 20.000000000000014, -400.0, -400.0, -332.7999999999993, -347.8, 20.000000000000014, -400.0, -400.0, -400.0, -376.89999999999975, -400.0, -374.8, -400.0, -365.8, -388.6, -397.9, -393.7, -400.0, -320.7999999999999, -400.0, -324.1, 26.300000000000114, -400.0, -99.70000000000081, -400.0, -213.1000000000005, 20.000000000000014, -380.8, -383.1999999999998, -395.8, -400.0, 35.30000000000026, -936.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -1072.0, -400.0, -400.0, -363.7, -322.3000000000002, -400.0, -366.7, -377.8, -400.0, -326.7999999999993, -82.90000000000086, 29.000000000000163, -326.8, -400.0, 36.20000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -347.8, -319.3, -1368.0, -154.30000000000067, -400.0, -400.0, 35.300000000000246, -99.70000000000081, -400.0, -340.6, 20.000000000000014, 23.600000000000065, -400.0, -392.8, -358.0, 29.90000000000018, -381.1, -391.6, -400.0, -372.69999999999976, -400.0, -400.0, -400.0, -400.0, 31.700000000000212, -200.50000000000054, 20.000000000000014, -323.8, -393.7, -355.9, -362.2, -400.0, -196.30000000000047, -196.30000000000052, -359.8, -238.30000000000035, -391.6, 20.000000000000014, -400.0, -400.0, -363.7, -656.0, -528.0, -1752.0, 20.000000000000014, -400.0, -400.0, -400.0, -341.8, -78.70000000000005, -389.5, -311.8, -51.40000000000005, -255.09999999999872, -240.70000000000027, -343.0, -393.7, -386.8, -308.8, -397.9, -187.90000000000057, -366.7, -400.0, -118.90000000000072, -400.0, 33.50000000000024, -400.0, -387.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -145.9000000000007, 20.000000000000014], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 195.0, 65.0, 200.0, 170.0, 186.0, 200.0, 133.0, 200.0, 171.0, 74.0, 200.0, 184.0, 181.0, 200.0, 77.0, 196.0, 200.0, 200.0, 200.0, 170.0, 145.0, 200.0, 200.0, 172.0, 191.0, 200.0, 181.0, 200.0, 169.0, 182.0, 200.0, 142.0, 200.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 110.0, 199.0, 197.0, 198.0, 173.0, 173.0, 200.0, 123.0, 200.0, 200.0, 160.0, 195.0, 200.0, 190.0, 200.0, 200.0, 200.0, 113.0, 178.0, 200.0, 191.0, 174.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 63.0, 200.0, 200.0, 185.0, 200.0, 106.0, 195.0, 188.0, 200.0, 200.0, 167.0, 175.0, 200.0, 200.0, 189.0, 200.0, 35.0, 200.0, 102.0, 109.0, 200.0, 200.0, 200.0, 200.0, 803.0, 59.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 956.0, 956.0, 200.0, 200.0, 61.0, 200.0, 194.0, 192.0, 200.0, 137.0, 49.0, 49.0, 172.0, 200.0, 200.0, 198.0, 200.0, 186.0, 191.0, 200.0, 152.0, 78.0, 1289.0, 200.0, 134.0, 200.0, 200.0, 200.0, 200.0, 200.0, 179.0, 179.0, 200.0, 7.0, 139.0, 200.0, 191.0, 191.0, 196.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 192.0, 105.0, 69.0, 177.0, 197.0, 185.0, 185.0, 103.0, 200.0, 103.0, 186.0, 126.0, 196.0, 200.0, 200.0, 184.0, 200.0, 200.0, 488.0, 200.0, 1697.0, 189.0, 158.0, 200.0, 180.0, 110.0, 166.0, 158.0, 103.0, 148.0, 33.0, 200.0, 171.0, 195.0, 104.0, 171.0, 200.0, 200.0, 182.0, 195.0, 182.0, 188.0, 181.0, 194.0, 200.0, 200.0, 200.0, 200.0, 191.0, 195.0, 200.0, 72.0, 79.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.570953044734943, "mean_inference_ms": 1.7910364264927938, "mean_action_processing_ms": 0.24368748628598777, "mean_env_wait_ms": 0.19098867152572727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003862142562866211, "StateBufferConnector_ms": 0.003033876419067383, "ViewRequirementAgentConnector_ms": 0.09154200553894043}, "num_episodes": 18, "episode_return_max": 440.0, "episode_return_min": -537.0, "episode_return_mean": -247.60699999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 411.89639278221074, "num_env_steps_trained_throughput_per_sec": 411.89639278221074, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 10020.443, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10020.402, "sample_time_ms": 1289.01, "learn_time_ms": 8716.037, "learn_throughput": 458.924, "synch_weights_time_ms": 14.19}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-20-46", "timestamp": 1723645246, "time_this_iter_s": 9.715543031692505, "time_total_s": 1110.583684682846, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8cc160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1110.583684682846, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 26.85714285714286, "ram_util_percent": 80.34285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.245475458296228, "cur_kl_coeff": 1.7617844105188847e-05, "cur_lr": 0.009999999999999998, "total_loss": 3.7238879141984165, "policy_loss": 0.0002581404828806482, "vf_loss": 3.7236297804211813, "vf_explained_var": 8.769681844761763e-05, "kl": -3.8809294611967316e-44, "entropy": 5.72767545275877e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5761552326617734, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.788902762327245, "policy_loss": 0.003259222848444349, "vf_loss": 7.767475094114031, "vf_explained_var": 5.98884764171782e-07, "kl": 0.0070890522850560805, "entropy": 0.4237266606833569, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 440.0, "episode_reward_min": -537.0, "episode_reward_mean": -234.0989999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1752.0, "predator_policy": 7.0}, "policy_reward_max": {"prey_policy": 37.10000000000026, "predator_policy": 1697.0}, "policy_reward_mean": {"prey_policy": -314.1945, "predator_policy": 197.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.500000000000234, -315.2999999999985, -400.0, -11.80000000000004, -410.0, -400.0, -49.89999999999977, -375.8, 10.199999999999957, -400.0, -298.5999999999993, 20.000000000000018, -537.0, -391.89999999999975, -468.8, -371.4, -391.59999999999997, -378.7999999999999, -324.1, 15.300000000000114, -264.7000000000005, 17.899999999999974, -363.99999999999983, -395.8, -38.6999999999998, -400.0, -400.0, -400.0, 440.0, -363.7, -461.3000000000002, -358.5, -389.7999999999993, 44.10000000000038, -354.8, 34.20000000000026, -414.0, -409.0, -97.80000000000015, -198.3, -220.30000000000067, 35.30000000000025, -99.70000000000081, 37.40000000000026, -169.4000000000006, -411.8, 30.800000000000193, -395.6, -374.69999999999976, -400.0, 23.700000000000067, -6.499999999999893, -343.5, -348.1, -293.2999999999992, -267.10000000000014, -307.8999999999987, 20.000000000000018, -379.7, -496.0, 164.99999999999957, -453.0, -361.8, -192.2000000000001, -102.20000000000059, -314.7999999999973, -365.7, -396.6, -214.80000000000058, -384.7, -141.90000000000072, 2.499999999999963, -393.4, -400.0, 11.000000000000009, 14.99999999999996, 25.100000000000083, 9.999999999999957, -279.40000000000055, -254.49999999999693, -183.30000000000112, -178.1000000000002, 20.000000000000018, -238.30000000000072, -129.50000000000003, -535.0, -425.0, -314.19999999999857, -127.00000000000034, -321.09999999999843, -213.8, -528.3, -435.1, 11.999999999999957, -45.69999999999977, -356.5, -326.9000000000003, -412.0, 26.20000000000011, -85.3000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [30.800000000000196, -343.3, -400.0, -238.30000000000044, -400.0, -400.0, 20.000000000000014, -386.8, -400.0, -400.0, -400.0, -400.0, 37.10000000000026, -400.0, -400.0, -353.8, -374.8, 20.000000000000014, -400.0, -400.0, -332.7999999999993, -347.8, 20.000000000000014, -400.0, -400.0, -400.0, -376.89999999999975, -400.0, -374.8, -400.0, -365.8, -388.6, -397.9, -393.7, -400.0, -320.7999999999999, -400.0, -324.1, 26.300000000000114, -400.0, -99.70000000000081, -400.0, -213.1000000000005, 20.000000000000014, -380.8, -383.1999999999998, -395.8, -400.0, 35.30000000000026, -936.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -1072.0, -400.0, -400.0, -363.7, -322.3000000000002, -400.0, -366.7, -377.8, -400.0, -326.7999999999993, -82.90000000000086, 29.000000000000163, -326.8, -400.0, 36.20000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -347.8, -319.3, -1368.0, -154.30000000000067, -400.0, -400.0, 35.300000000000246, -99.70000000000081, -400.0, -340.6, 20.000000000000014, 23.600000000000065, -400.0, -392.8, -358.0, 29.90000000000018, -381.1, -391.6, -400.0, -372.69999999999976, -400.0, -400.0, -400.0, -400.0, 31.700000000000212, -200.50000000000054, 20.000000000000014, -323.8, -393.7, -355.9, -362.2, -400.0, -196.30000000000047, -196.30000000000052, -359.8, -238.30000000000035, -391.6, 20.000000000000014, -400.0, -400.0, -363.7, -656.0, -528.0, -1752.0, 20.000000000000014, -400.0, -400.0, -400.0, -341.8, -78.70000000000005, -389.5, -311.8, -51.40000000000005, -255.09999999999872, -240.70000000000027, -343.0, -393.7, -386.8, -308.8, -397.9, -187.90000000000057, -366.7, -400.0, -118.90000000000072, -400.0, 33.50000000000024, -400.0, -387.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -145.9000000000007, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -93.39999999999984, -175.6000000000005, -250.89999999999986, -313.9000000000002, -72.40000000000089, -234.69999999999993, -324.3999999999992, 20.000000000000014, -400.0, -91.30000000000072, -400.0, -400.0, -116.50000000000003, -400.0, -400.0, -400.0, -400.0, -248.8000000000004, -387.4, 20.000000000000014, -400.0, -397.9, -257.19999999999845, -185.8, -400.0, -400.0, -331.3, -400.0, -360.1, -400.0, 20.000000000000014, 35.30000000000025, -400.0, -345.7, -395.8, -292.9000000000003, -665.0, -400.0, -400.0, 25.400000000000098, -383.2, 31.700000000000212, -357.99999999999955], "policy_predator_policy_reward": [173.0, 173.0, 200.0, 123.0, 200.0, 200.0, 160.0, 195.0, 200.0, 190.0, 200.0, 200.0, 200.0, 113.0, 178.0, 200.0, 191.0, 174.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 63.0, 200.0, 200.0, 185.0, 200.0, 106.0, 195.0, 188.0, 200.0, 200.0, 167.0, 175.0, 200.0, 200.0, 189.0, 200.0, 35.0, 200.0, 102.0, 109.0, 200.0, 200.0, 200.0, 200.0, 803.0, 59.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 956.0, 956.0, 200.0, 200.0, 61.0, 200.0, 194.0, 192.0, 200.0, 137.0, 49.0, 49.0, 172.0, 200.0, 200.0, 198.0, 200.0, 186.0, 191.0, 200.0, 152.0, 78.0, 1289.0, 200.0, 134.0, 200.0, 200.0, 200.0, 200.0, 200.0, 179.0, 179.0, 200.0, 7.0, 139.0, 200.0, 191.0, 191.0, 196.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 192.0, 105.0, 69.0, 177.0, 197.0, 185.0, 185.0, 103.0, 200.0, 103.0, 186.0, 126.0, 196.0, 200.0, 200.0, 184.0, 200.0, 200.0, 488.0, 200.0, 1697.0, 189.0, 158.0, 200.0, 180.0, 110.0, 166.0, 158.0, 103.0, 148.0, 33.0, 200.0, 171.0, 195.0, 104.0, 171.0, 200.0, 200.0, 182.0, 195.0, 182.0, 188.0, 181.0, 194.0, 200.0, 200.0, 200.0, 200.0, 191.0, 195.0, 200.0, 72.0, 79.0, 200.0, 190.0, 14.0, 200.0, 129.0, 43.0, 94.0, 109.0, 200.0, 181.0, 200.0, 200.0, 200.0, 53.0, 187.0, 200.0, 200.0, 65.0, 175.0, 200.0, 128.0, 194.0, 58.0, 195.0, 158.0, 176.0, 191.0, 181.0, 184.0, 19.0, 125.0, 200.0, 200.0, 192.0, 200.0, 119.0, 198.0, 187.0, 92.0, 539.0, 200.0, 188.0, 192.0, 192.0, 180.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.570194418002999, "mean_inference_ms": 1.7887062560982543, "mean_action_processing_ms": 0.2432625151237455, "mean_env_wait_ms": 0.1906854276163328, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036543607711791992, "StateBufferConnector_ms": 0.003023505210876465, "ViewRequirementAgentConnector_ms": 0.09108352661132812}, "num_episodes": 23, "episode_return_max": 440.0, "episode_return_min": -537.0, "episode_return_mean": -234.0989999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 423.5793919122347, "num_env_steps_trained_throughput_per_sec": 423.5793919122347, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 9852.857, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9852.819, "sample_time_ms": 1288.195, "learn_time_ms": 8549.845, "learn_throughput": 467.845, "synch_weights_time_ms": 13.882}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-20-55", "timestamp": 1723645255, "time_this_iter_s": 9.447325944900513, "time_total_s": 1120.0310106277466, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae49550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1120.0310106277466, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 29.292307692307695, "ram_util_percent": 80.8076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3663451709203107, "cur_kl_coeff": 8.808922052594424e-06, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": -0.0001454037182998878, "vf_loss": 2.926808302806168, "vf_explained_var": 6.357986460287104e-05, "kl": Infinity, "entropy": 6.21369899588599e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5846667768818046, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 8.221568847585607, "policy_loss": 0.002735309726336882, "vf_loss": 8.198337833717387, "vf_explained_var": -1.7205243388181011e-06, "kl": 0.007997102111327814, "entropy": 0.4408326669739037, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 440.0, "episode_reward_min": -535.0, "episode_reward_mean": -229.19499999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1752.0, "predator_policy": 7.0}, "policy_reward_max": {"prey_policy": 36.20000000000026, "predator_policy": 1697.0}, "policy_reward_mean": {"prey_policy": -309.5625, "predator_policy": 194.965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-324.1, 15.300000000000114, -264.7000000000005, 17.899999999999974, -363.99999999999983, -395.8, -38.6999999999998, -400.0, -400.0, -400.0, 440.0, -363.7, -461.3000000000002, -358.5, -389.7999999999993, 44.10000000000038, -354.8, 34.20000000000026, -414.0, -409.0, -97.80000000000015, -198.3, -220.30000000000067, 35.30000000000025, -99.70000000000081, 37.40000000000026, -169.4000000000006, -411.8, 30.800000000000193, -395.6, -374.69999999999976, -400.0, 23.700000000000067, -6.499999999999893, -343.5, -348.1, -293.2999999999992, -267.10000000000014, -307.8999999999987, 20.000000000000018, -379.7, -496.0, 164.99999999999957, -453.0, -361.8, -192.2000000000001, -102.20000000000059, -314.7999999999973, -365.7, -396.6, -214.80000000000058, -384.7, -141.90000000000072, 2.499999999999963, -393.4, -400.0, 11.000000000000009, 14.99999999999996, 25.100000000000083, 9.999999999999957, -279.40000000000055, -254.49999999999693, -183.30000000000112, -178.1000000000002, 20.000000000000018, -238.30000000000072, -129.50000000000003, -535.0, -425.0, -314.19999999999857, -127.00000000000034, -321.09999999999843, -213.8, -528.3, -435.1, 11.999999999999957, -45.69999999999977, -356.5, -326.9000000000003, -412.0, 26.20000000000011, -85.3000000000003, -428.0, -376.7, -383.8, -400.0, -5.699999999999768, 8.899999999999949, -403.2, -300.399999999999, -420.7999999999986, -266.0, -373.8, -95.60000000000016, -307.69999999999925, -83.50000000000057, -13.99999999999981, -394.5, 20.000000000000018, -422.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -324.1, 26.300000000000114, -400.0, -99.70000000000081, -400.0, -213.1000000000005, 20.000000000000014, -380.8, -383.1999999999998, -395.8, -400.0, 35.30000000000026, -936.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -1072.0, -400.0, -400.0, -363.7, -322.3000000000002, -400.0, -366.7, -377.8, -400.0, -326.7999999999993, -82.90000000000086, 29.000000000000163, -326.8, -400.0, 36.20000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -347.8, -319.3, -1368.0, -154.30000000000067, -400.0, -400.0, 35.300000000000246, -99.70000000000081, -400.0, -340.6, 20.000000000000014, 23.600000000000065, -400.0, -392.8, -358.0, 29.90000000000018, -381.1, -391.6, -400.0, -372.69999999999976, -400.0, -400.0, -400.0, -400.0, 31.700000000000212, -200.50000000000054, 20.000000000000014, -323.8, -393.7, -355.9, -362.2, -400.0, -196.30000000000047, -196.30000000000052, -359.8, -238.30000000000035, -391.6, 20.000000000000014, -400.0, -400.0, -363.7, -656.0, -528.0, -1752.0, 20.000000000000014, -400.0, -400.0, -400.0, -341.8, -78.70000000000005, -389.5, -311.8, -51.40000000000005, -255.09999999999872, -240.70000000000027, -343.0, -393.7, -386.8, -308.8, -397.9, -187.90000000000057, -366.7, -400.0, -118.90000000000072, -400.0, 33.50000000000024, -400.0, -387.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -145.9000000000007, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -93.39999999999984, -175.6000000000005, -250.89999999999986, -313.9000000000002, -72.40000000000089, -234.69999999999993, -324.3999999999992, 20.000000000000014, -400.0, -91.30000000000072, -400.0, -400.0, -116.50000000000003, -400.0, -400.0, -400.0, -400.0, -248.8000000000004, -387.4, 20.000000000000014, -400.0, -397.9, -257.19999999999845, -185.8, -400.0, -400.0, -331.3, -400.0, -360.1, -400.0, 20.000000000000014, 35.30000000000025, -400.0, -345.7, -395.8, -292.9000000000003, -665.0, -400.0, -400.0, 25.400000000000098, -383.2, 31.700000000000212, -357.99999999999955, -400.0, -400.0, -400.0, -363.7, -383.8, -400.0, -400.0, -400.0, -162.7000000000006, 20.000000000000014, -236.20000000000044, -73.9, -385.0, -383.2, -309.699999999999, -390.7, -400.0, -269.7999999999986, -400.0, -253.0, -359.8, -400.0, -400.0, 25.400000000000098, -260.7999999999993, -376.9, 27.20000000000013, -309.6999999999991, 36.20000000000026, -362.1999999999996, -389.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 189.0, 200.0, 35.0, 200.0, 102.0, 109.0, 200.0, 200.0, 200.0, 200.0, 803.0, 59.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 956.0, 956.0, 200.0, 200.0, 61.0, 200.0, 194.0, 192.0, 200.0, 137.0, 49.0, 49.0, 172.0, 200.0, 200.0, 198.0, 200.0, 186.0, 191.0, 200.0, 152.0, 78.0, 1289.0, 200.0, 134.0, 200.0, 200.0, 200.0, 200.0, 200.0, 179.0, 179.0, 200.0, 7.0, 139.0, 200.0, 191.0, 191.0, 196.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 192.0, 105.0, 69.0, 177.0, 197.0, 185.0, 185.0, 103.0, 200.0, 103.0, 186.0, 126.0, 196.0, 200.0, 200.0, 184.0, 200.0, 200.0, 488.0, 200.0, 1697.0, 189.0, 158.0, 200.0, 180.0, 110.0, 166.0, 158.0, 103.0, 148.0, 33.0, 200.0, 171.0, 195.0, 104.0, 171.0, 200.0, 200.0, 182.0, 195.0, 182.0, 188.0, 181.0, 194.0, 200.0, 200.0, 200.0, 200.0, 191.0, 195.0, 200.0, 72.0, 79.0, 200.0, 190.0, 14.0, 200.0, 129.0, 43.0, 94.0, 109.0, 200.0, 181.0, 200.0, 200.0, 200.0, 53.0, 187.0, 200.0, 200.0, 65.0, 175.0, 200.0, 128.0, 194.0, 58.0, 195.0, 158.0, 176.0, 191.0, 181.0, 184.0, 19.0, 125.0, 200.0, 200.0, 192.0, 200.0, 119.0, 198.0, 187.0, 92.0, 539.0, 200.0, 188.0, 192.0, 192.0, 180.0, 61.0, 189.0, 183.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 50.0, 87.0, 151.0, 168.0, 170.0, 195.0, 200.0, 200.0, 200.0, 49.0, 200.0, 187.0, 200.0, 186.0, 79.0, 200.0, 189.0, 141.0, 42.0, 157.0, 130.0, 182.0, 200.0, 195.0, 200.0, 200.0, 178.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5696742718103158, "mean_inference_ms": 1.7870399737019225, "mean_action_processing_ms": 0.2429629395118612, "mean_env_wait_ms": 0.1904733781805745, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003667473793029785, "StateBufferConnector_ms": 0.0030727386474609375, "ViewRequirementAgentConnector_ms": 0.09444940090179443}, "num_episodes": 18, "episode_return_max": 440.0, "episode_return_min": -535.0, "episode_return_mean": -229.19499999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 414.0463891828991, "num_env_steps_trained_throughput_per_sec": 414.0463891828991, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 9724.141, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9724.104, "sample_time_ms": 1277.58, "learn_time_ms": 8431.947, "learn_throughput": 474.386, "synch_weights_time_ms": 13.858}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-21-05", "timestamp": 1723645265, "time_this_iter_s": 9.666248798370361, "time_total_s": 1129.697259426117, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d60d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1129.697259426117, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 28.192857142857143, "ram_util_percent": 80.82142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.951793894283572, "cur_kl_coeff": 1.3213383078891642e-05, "cur_lr": 0.009999999999999998, "total_loss": 1.7284395053312576, "policy_loss": 5.025894543717778e-05, "vf_loss": 1.7283892431902508, "vf_explained_var": 1.7905235290527342e-05, "kl": -9.830765113233547e-41, "entropy": 5.645096556377071e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9535231271275768, "cur_kl_coeff": 2.5628906250000005, "cur_lr": 0.009999999999999998, "total_loss": 7.586884038410489, "policy_loss": 0.0019666723983372174, "vf_loss": 7.574197625609302, "vf_explained_var": -1.236244484230324e-08, "kl": 0.004182674638063415, "entropy": 0.26639368101639094, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 164.99999999999957, "episode_reward_min": -535.0, "episode_reward_mean": -226.2109999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1752.0, "predator_policy": 7.0}, "policy_reward_max": {"prey_policy": 36.20000000000026, "predator_policy": 1697.0}, "policy_reward_mean": {"prey_policy": -293.1205, "predator_policy": 180.015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-220.30000000000067, 35.30000000000025, -99.70000000000081, 37.40000000000026, -169.4000000000006, -411.8, 30.800000000000193, -395.6, -374.69999999999976, -400.0, 23.700000000000067, -6.499999999999893, -343.5, -348.1, -293.2999999999992, -267.10000000000014, -307.8999999999987, 20.000000000000018, -379.7, -496.0, 164.99999999999957, -453.0, -361.8, -192.2000000000001, -102.20000000000059, -314.7999999999973, -365.7, -396.6, -214.80000000000058, -384.7, -141.90000000000072, 2.499999999999963, -393.4, -400.0, 11.000000000000009, 14.99999999999996, 25.100000000000083, 9.999999999999957, -279.40000000000055, -254.49999999999693, -183.30000000000112, -178.1000000000002, 20.000000000000018, -238.30000000000072, -129.50000000000003, -535.0, -425.0, -314.19999999999857, -127.00000000000034, -321.09999999999843, -213.8, -528.3, -435.1, 11.999999999999957, -45.69999999999977, -356.5, -326.9000000000003, -412.0, 26.20000000000011, -85.3000000000003, -428.0, -376.7, -383.8, -400.0, -5.699999999999768, 8.899999999999949, -403.2, -300.399999999999, -420.7999999999986, -266.0, -373.8, -95.60000000000016, -307.69999999999925, -83.50000000000057, -13.99999999999981, -394.5, 20.000000000000018, -422.0, -479.1, -400.0, 20.000000000000014, -6.0999999999999, -188.10000000000056, 20.900000000000027, -329.39999999999884, -382.4, -278.9999999999999, -361.2, -66.10000000000089, -373.6, 33.50000000000024, -171.00000000000063, -214.1000000000009, -370.29999999999995, -156.10000000000056, 20.000000000000018, -400.0, -351.5, -370.9999999999999, 20.000000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-154.30000000000067, -400.0, -400.0, 35.300000000000246, -99.70000000000081, -400.0, -340.6, 20.000000000000014, 23.600000000000065, -400.0, -392.8, -358.0, 29.90000000000018, -381.1, -391.6, -400.0, -372.69999999999976, -400.0, -400.0, -400.0, -400.0, 31.700000000000212, -200.50000000000054, 20.000000000000014, -323.8, -393.7, -355.9, -362.2, -400.0, -196.30000000000047, -196.30000000000052, -359.8, -238.30000000000035, -391.6, 20.000000000000014, -400.0, -400.0, -363.7, -656.0, -528.0, -1752.0, 20.000000000000014, -400.0, -400.0, -400.0, -341.8, -78.70000000000005, -389.5, -311.8, -51.40000000000005, -255.09999999999872, -240.70000000000027, -343.0, -393.7, -386.8, -308.8, -397.9, -187.90000000000057, -366.7, -400.0, -118.90000000000072, -400.0, 33.50000000000024, -400.0, -387.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -145.9000000000007, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -93.39999999999984, -175.6000000000005, -250.89999999999986, -313.9000000000002, -72.40000000000089, -234.69999999999993, -324.3999999999992, 20.000000000000014, -400.0, -91.30000000000072, -400.0, -400.0, -116.50000000000003, -400.0, -400.0, -400.0, -400.0, -248.8000000000004, -387.4, 20.000000000000014, -400.0, -397.9, -257.19999999999845, -185.8, -400.0, -400.0, -331.3, -400.0, -360.1, -400.0, 20.000000000000014, 35.30000000000025, -400.0, -345.7, -395.8, -292.9000000000003, -665.0, -400.0, -400.0, 25.400000000000098, -383.2, 31.700000000000212, -357.99999999999955, -400.0, -400.0, -400.0, -363.7, -383.8, -400.0, -400.0, -400.0, -162.7000000000006, 20.000000000000014, -236.20000000000044, -73.9, -385.0, -383.2, -309.699999999999, -390.7, -400.0, -269.7999999999986, -400.0, -253.0, -359.8, -400.0, -400.0, 25.400000000000098, -260.7999999999993, -376.9, 27.20000000000013, -309.6999999999991, 36.20000000000026, -362.1999999999996, -389.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -360.1, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -381.0999999999998, 29.000000000000163, -143.80000000000055, -262.29999999999995, -400.0, 20.90000000000003, -262.59999999999883, -374.8, -400.0, -366.4, -169.00000000000063, -400.0, -383.2, -358.0, -66.10000000000089, -400.0, -387.4, -362.2, 33.50000000000024, -400.0, -400.0, 20.000000000000014, -383.2, -61.900000000000766, -343.3, -400.0, -400.0, -156.10000000000056, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -341.5, -387.39999999999986, -364.6, 20.000000000000014, -400.0], "policy_predator_policy_reward": [134.0, 200.0, 200.0, 200.0, 200.0, 200.0, 179.0, 179.0, 200.0, 7.0, 139.0, 200.0, 191.0, 191.0, 196.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 192.0, 105.0, 69.0, 177.0, 197.0, 185.0, 185.0, 103.0, 200.0, 103.0, 186.0, 126.0, 196.0, 200.0, 200.0, 184.0, 200.0, 200.0, 488.0, 200.0, 1697.0, 189.0, 158.0, 200.0, 180.0, 110.0, 166.0, 158.0, 103.0, 148.0, 33.0, 200.0, 171.0, 195.0, 104.0, 171.0, 200.0, 200.0, 182.0, 195.0, 182.0, 188.0, 181.0, 194.0, 200.0, 200.0, 200.0, 200.0, 191.0, 195.0, 200.0, 72.0, 79.0, 200.0, 190.0, 14.0, 200.0, 129.0, 43.0, 94.0, 109.0, 200.0, 181.0, 200.0, 200.0, 200.0, 53.0, 187.0, 200.0, 200.0, 65.0, 175.0, 200.0, 128.0, 194.0, 58.0, 195.0, 158.0, 176.0, 191.0, 181.0, 184.0, 19.0, 125.0, 200.0, 200.0, 192.0, 200.0, 119.0, 198.0, 187.0, 92.0, 539.0, 200.0, 188.0, 192.0, 192.0, 180.0, 61.0, 189.0, 183.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 50.0, 87.0, 151.0, 168.0, 170.0, 195.0, 200.0, 200.0, 200.0, 49.0, 200.0, 187.0, 200.0, 186.0, 79.0, 200.0, 189.0, 141.0, 42.0, 157.0, 130.0, 182.0, 200.0, 195.0, 200.0, 200.0, 178.0, 200.0, 200.0, 81.0, 200.0, 200.0, 200.0, 200.0, 155.0, 191.0, 78.0, 140.0, 200.0, 200.0, 117.0, 191.0, 184.0, 200.0, 90.0, 200.0, 188.0, 192.0, 200.0, 200.0, 176.0, 200.0, 200.0, 200.0, 9.0, 200.0, 192.0, 39.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 194.0, 187.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5690900580548989, "mean_inference_ms": 1.7864832538499218, "mean_action_processing_ms": 0.24234124114047398, "mean_env_wait_ms": 0.19021752699072075, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003632187843322754, "StateBufferConnector_ms": 0.0030072927474975586, "ViewRequirementAgentConnector_ms": 0.09188699722290039}, "num_episodes": 22, "episode_return_max": 164.99999999999957, "episode_return_min": -535.0, "episode_return_mean": -226.2109999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 425.2621905235253, "num_env_steps_trained_throughput_per_sec": 425.2621905235253, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 9700.78, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9700.744, "sample_time_ms": 1276.878, "learn_time_ms": 8409.371, "learn_throughput": 475.66, "synch_weights_time_ms": 13.782}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-21-14", "timestamp": 1723645274, "time_this_iter_s": 9.410936832427979, "time_total_s": 1139.108196258545, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ada7c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1139.108196258545, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 27.94285714285714, "ram_util_percent": 80.71428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9398350070733281, "cur_kl_coeff": 6.606691539445821e-06, "cur_lr": 0.009999999999999998, "total_loss": 1.55565566371673, "policy_loss": -8.579186760086231e-05, "vf_loss": 1.5557414573651773, "vf_explained_var": 1.1104029953164399e-05, "kl": 6.63377658722404e-44, "entropy": 7.637952569410636e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7975316470814129, "cur_kl_coeff": 1.2814453125000003, "cur_lr": 0.009999999999999998, "total_loss": 7.456709421753253, "policy_loss": 0.002954635891703662, "vf_loss": 7.44486615922716, "vf_explained_var": -6.212759270239129e-09, "kl": 0.0069364021051129265, "entropy": 0.18261843823763743, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 164.99999999999957, "episode_reward_min": -535.0, "episode_reward_mean": -230.45999999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1752.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000026, "predator_policy": 1697.0}, "policy_reward_mean": {"prey_policy": -294.85, "predator_policy": 179.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-379.7, -496.0, 164.99999999999957, -453.0, -361.8, -192.2000000000001, -102.20000000000059, -314.7999999999973, -365.7, -396.6, -214.80000000000058, -384.7, -141.90000000000072, 2.499999999999963, -393.4, -400.0, 11.000000000000009, 14.99999999999996, 25.100000000000083, 9.999999999999957, -279.40000000000055, -254.49999999999693, -183.30000000000112, -178.1000000000002, 20.000000000000018, -238.30000000000072, -129.50000000000003, -535.0, -425.0, -314.19999999999857, -127.00000000000034, -321.09999999999843, -213.8, -528.3, -435.1, 11.999999999999957, -45.69999999999977, -356.5, -326.9000000000003, -412.0, 26.20000000000011, -85.3000000000003, -428.0, -376.7, -383.8, -400.0, -5.699999999999768, 8.899999999999949, -403.2, -300.399999999999, -420.7999999999986, -266.0, -373.8, -95.60000000000016, -307.69999999999925, -83.50000000000057, -13.99999999999981, -394.5, 20.000000000000018, -422.0, -479.1, -400.0, 20.000000000000014, -6.0999999999999, -188.10000000000056, 20.900000000000027, -329.39999999999884, -382.4, -278.9999999999999, -361.2, -66.10000000000089, -373.6, 33.50000000000024, -171.00000000000063, -214.1000000000009, -370.29999999999995, -156.10000000000056, 20.000000000000018, -400.0, -351.5, -370.9999999999999, 20.000000000000018, -400.0, -352.9, -135.5000000000004, 20.000000000000018, -400.0, 17.29999999999998, -400.0, 40.0000000000003, -377.9, 20.000000000000014, -400.0, -251.50000000000077, -400.0, 20.000000000000014, -62.799999999999926, -348.29999999999995, -524.0, 20.000000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -363.7, -656.0, -528.0, -1752.0, 20.000000000000014, -400.0, -400.0, -400.0, -341.8, -78.70000000000005, -389.5, -311.8, -51.40000000000005, -255.09999999999872, -240.70000000000027, -343.0, -393.7, -386.8, -308.8, -397.9, -187.90000000000057, -366.7, -400.0, -118.90000000000072, -400.0, 33.50000000000024, -400.0, -387.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -145.9000000000007, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -93.39999999999984, -175.6000000000005, -250.89999999999986, -313.9000000000002, -72.40000000000089, -234.69999999999993, -324.3999999999992, 20.000000000000014, -400.0, -91.30000000000072, -400.0, -400.0, -116.50000000000003, -400.0, -400.0, -400.0, -400.0, -248.8000000000004, -387.4, 20.000000000000014, -400.0, -397.9, -257.19999999999845, -185.8, -400.0, -400.0, -331.3, -400.0, -360.1, -400.0, 20.000000000000014, 35.30000000000025, -400.0, -345.7, -395.8, -292.9000000000003, -665.0, -400.0, -400.0, 25.400000000000098, -383.2, 31.700000000000212, -357.99999999999955, -400.0, -400.0, -400.0, -363.7, -383.8, -400.0, -400.0, -400.0, -162.7000000000006, 20.000000000000014, -236.20000000000044, -73.9, -385.0, -383.2, -309.699999999999, -390.7, -400.0, -269.7999999999986, -400.0, -253.0, -359.8, -400.0, -400.0, 25.400000000000098, -260.7999999999993, -376.9, 27.20000000000013, -309.6999999999991, 36.20000000000026, -362.1999999999996, -389.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -360.1, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -381.0999999999998, 29.000000000000163, -143.80000000000055, -262.29999999999995, -400.0, 20.90000000000003, -262.59999999999883, -374.8, -400.0, -366.4, -169.00000000000063, -400.0, -383.2, -358.0, -66.10000000000089, -400.0, -387.4, -362.2, 33.50000000000024, -400.0, -400.0, 20.000000000000014, -383.2, -61.900000000000766, -343.3, -400.0, -400.0, -156.10000000000056, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -341.5, -387.39999999999986, -364.6, 20.000000000000014, -400.0, -400.0, -400.0, -387.7, -338.2, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -383.2, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -361.9, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -116.50000000000077, -400.0, -400.0, -400.0, 20.000000000000014, 27.20000000000013, -400.0, -400.0, -301.3, -400.0, -400.0, 20.000000000000014, -400.0], "policy_predator_policy_reward": [184.0, 200.0, 200.0, 488.0, 200.0, 1697.0, 189.0, 158.0, 200.0, 180.0, 110.0, 166.0, 158.0, 103.0, 148.0, 33.0, 200.0, 171.0, 195.0, 104.0, 171.0, 200.0, 200.0, 182.0, 195.0, 182.0, 188.0, 181.0, 194.0, 200.0, 200.0, 200.0, 200.0, 191.0, 195.0, 200.0, 72.0, 79.0, 200.0, 190.0, 14.0, 200.0, 129.0, 43.0, 94.0, 109.0, 200.0, 181.0, 200.0, 200.0, 200.0, 53.0, 187.0, 200.0, 200.0, 65.0, 175.0, 200.0, 128.0, 194.0, 58.0, 195.0, 158.0, 176.0, 191.0, 181.0, 184.0, 19.0, 125.0, 200.0, 200.0, 192.0, 200.0, 119.0, 198.0, 187.0, 92.0, 539.0, 200.0, 188.0, 192.0, 192.0, 180.0, 61.0, 189.0, 183.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 50.0, 87.0, 151.0, 168.0, 170.0, 195.0, 200.0, 200.0, 200.0, 49.0, 200.0, 187.0, 200.0, 186.0, 79.0, 200.0, 189.0, 141.0, 42.0, 157.0, 130.0, 182.0, 200.0, 195.0, 200.0, 200.0, 178.0, 200.0, 200.0, 81.0, 200.0, 200.0, 200.0, 200.0, 155.0, 191.0, 78.0, 140.0, 200.0, 200.0, 117.0, 191.0, 184.0, 200.0, 90.0, 200.0, 188.0, 192.0, 200.0, 200.0, 176.0, 200.0, 200.0, 200.0, 9.0, 200.0, 192.0, 39.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 194.0, 187.0, 200.0, 200.0, 200.0, 200.0, 178.0, 195.0, 200.0, 31.0, 200.0, 200.0, 200.0, 200.0, 181.0, 186.0, 200.0, 200.0, 0.0, 0.0, 184.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 200.0, 200.0, 200.0, 200.0, 110.0, 200.0, 153.0, 200.0, 76.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.568444077895384, "mean_inference_ms": 1.7832224158502155, "mean_action_processing_ms": 0.2423369181694205, "mean_env_wait_ms": 0.1899592190121539, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003640413284301758, "StateBufferConnector_ms": 0.0030045509338378906, "ViewRequirementAgentConnector_ms": 0.09240007400512695}, "num_episodes": 18, "episode_return_max": 164.99999999999957, "episode_return_min": -535.0, "episode_return_mean": -230.45999999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 421.53779389300934, "num_env_steps_trained_throughput_per_sec": 421.53779389300934, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 9592.634, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9592.598, "sample_time_ms": 1236.627, "learn_time_ms": 8341.448, "learn_throughput": 479.533, "synch_weights_time_ms": 13.811}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-21-24", "timestamp": 1723645284, "time_this_iter_s": 9.493713140487671, "time_total_s": 1148.6019093990326, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae94700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1148.6019093990326, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 28.838461538461537, "ram_util_percent": 80.49999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.389225918206352, "cur_kl_coeff": 3.3033457697229105e-06, "cur_lr": 0.009999999999999998, "total_loss": 1.497421248174376, "policy_loss": -0.00021276489200770224, "vf_loss": 1.4976340154018353, "vf_explained_var": 0.00015024047680002042, "kl": 2.3286985479922303e-43, "entropy": 5.483673751668544e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0651922242390732, "cur_kl_coeff": 1.2814453125000003, "cur_lr": 0.009999999999999998, "total_loss": 8.311492123427215, "policy_loss": 0.006393927724775735, "vf_loss": 8.285295504110831, "vf_explained_var": -1.1570869930206783e-07, "kl": 0.015453410284952689, "entropy": 0.3687197080522618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 40.0000000000003, "episode_reward_min": -535.0, "episode_reward_mean": -242.72199999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -665.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000026, "predator_policy": 539.0}, "policy_reward_mean": {"prey_policy": -295.64099999999996, "predator_policy": 174.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-178.1000000000002, 20.000000000000018, -238.30000000000072, -129.50000000000003, -535.0, -425.0, -314.19999999999857, -127.00000000000034, -321.09999999999843, -213.8, -528.3, -435.1, 11.999999999999957, -45.69999999999977, -356.5, -326.9000000000003, -412.0, 26.20000000000011, -85.3000000000003, -428.0, -376.7, -383.8, -400.0, -5.699999999999768, 8.899999999999949, -403.2, -300.399999999999, -420.7999999999986, -266.0, -373.8, -95.60000000000016, -307.69999999999925, -83.50000000000057, -13.99999999999981, -394.5, 20.000000000000018, -422.0, -479.1, -400.0, 20.000000000000014, -6.0999999999999, -188.10000000000056, 20.900000000000027, -329.39999999999884, -382.4, -278.9999999999999, -361.2, -66.10000000000089, -373.6, 33.50000000000024, -171.00000000000063, -214.1000000000009, -370.29999999999995, -156.10000000000056, 20.000000000000018, -400.0, -351.5, -370.9999999999999, 20.000000000000018, -400.0, -352.9, -135.5000000000004, 20.000000000000018, -400.0, 17.29999999999998, -400.0, 40.0000000000003, -377.9, 20.000000000000014, -400.0, -251.50000000000077, -400.0, 20.000000000000014, -62.799999999999926, -348.29999999999995, -524.0, 20.000000000000018, -350.499999999999, -391.2, -360.3, -400.0, 31.800000000000185, 20.000000000000018, 20.000000000000014, -387.9, -152.00000000000065, -321.59999999999997, -400.0, -354.7, -312.99999999999955, -248.90000000000072, -395.8, -298.79999999999905, -385.7, -400.0, 34.40000000000026, -532.0, -400.0, -106.00000000000074, -219.40000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-234.69999999999993, -324.3999999999992, 20.000000000000014, -400.0, -91.30000000000072, -400.0, -400.0, -116.50000000000003, -400.0, -400.0, -400.0, -400.0, -248.8000000000004, -387.4, 20.000000000000014, -400.0, -397.9, -257.19999999999845, -185.8, -400.0, -400.0, -331.3, -400.0, -360.1, -400.0, 20.000000000000014, 35.30000000000025, -400.0, -345.7, -395.8, -292.9000000000003, -665.0, -400.0, -400.0, 25.400000000000098, -383.2, 31.700000000000212, -357.99999999999955, -400.0, -400.0, -400.0, -363.7, -383.8, -400.0, -400.0, -400.0, -162.7000000000006, 20.000000000000014, -236.20000000000044, -73.9, -385.0, -383.2, -309.699999999999, -390.7, -400.0, -269.7999999999986, -400.0, -253.0, -359.8, -400.0, -400.0, 25.400000000000098, -260.7999999999993, -376.9, 27.20000000000013, -309.6999999999991, 36.20000000000026, -362.1999999999996, -389.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -360.1, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -381.0999999999998, 29.000000000000163, -143.80000000000055, -262.29999999999995, -400.0, 20.90000000000003, -262.59999999999883, -374.8, -400.0, -366.4, -169.00000000000063, -400.0, -383.2, -358.0, -66.10000000000089, -400.0, -387.4, -362.2, 33.50000000000024, -400.0, -400.0, 20.000000000000014, -383.2, -61.900000000000766, -343.3, -400.0, -400.0, -156.10000000000056, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -341.5, -387.39999999999986, -364.6, 20.000000000000014, -400.0, -400.0, -400.0, -387.7, -338.2, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -383.2, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -361.9, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -116.50000000000077, -400.0, -400.0, -400.0, 20.000000000000014, 27.20000000000013, -400.0, -400.0, -301.3, -400.0, -400.0, 20.000000000000014, -400.0, -305.499999999999, -400.0, -383.2, -400.0, -337.3, -400.0, -400.0, -400.0, -152.20000000000067, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -376.9, -400.0, 20.000000000000014, -400.0, -330.1, -341.5, -400.0, -400.0, -400.0, -354.7, -357.99999999999955, -328.0, -400.0, -82.90000000000072, -395.8, -400.0, -400.0, -206.8000000000004, -387.4, -385.3, -400.0, -400.0, 34.40000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, -106.00000000000074, -400.0, -400.0, -219.40000000000043], "policy_predator_policy_reward": [200.0, 181.0, 200.0, 200.0, 200.0, 53.0, 187.0, 200.0, 200.0, 65.0, 175.0, 200.0, 128.0, 194.0, 58.0, 195.0, 158.0, 176.0, 191.0, 181.0, 184.0, 19.0, 125.0, 200.0, 200.0, 192.0, 200.0, 119.0, 198.0, 187.0, 92.0, 539.0, 200.0, 188.0, 192.0, 192.0, 180.0, 61.0, 189.0, 183.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 50.0, 87.0, 151.0, 168.0, 170.0, 195.0, 200.0, 200.0, 200.0, 49.0, 200.0, 187.0, 200.0, 186.0, 79.0, 200.0, 189.0, 141.0, 42.0, 157.0, 130.0, 182.0, 200.0, 195.0, 200.0, 200.0, 178.0, 200.0, 200.0, 81.0, 200.0, 200.0, 200.0, 200.0, 155.0, 191.0, 78.0, 140.0, 200.0, 200.0, 117.0, 191.0, 184.0, 200.0, 90.0, 200.0, 188.0, 192.0, 200.0, 200.0, 176.0, 200.0, 200.0, 200.0, 9.0, 200.0, 192.0, 39.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 194.0, 187.0, 200.0, 200.0, 200.0, 200.0, 178.0, 195.0, 200.0, 31.0, 200.0, 200.0, 200.0, 200.0, 181.0, 186.0, 200.0, 200.0, 0.0, 0.0, 184.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 200.0, 200.0, 200.0, 200.0, 110.0, 200.0, 153.0, 200.0, 76.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 192.0, 200.0, 177.0, 200.0, 200.0, 82.0, 82.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 28.0, 200.0, 176.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 173.0, 200.0, 34.0, 200.0, 200.0, 200.0, 108.0, 194.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 68.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5678376992465989, "mean_inference_ms": 1.7863773779890286, "mean_action_processing_ms": 0.24238905200237187, "mean_env_wait_ms": 0.1895844135673614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037118196487426758, "StateBufferConnector_ms": 0.0031813383102416992, "ViewRequirementAgentConnector_ms": 0.09273147583007812}, "num_episodes": 23, "episode_return_max": 40.0000000000003, "episode_return_min": -535.0, "episode_return_mean": -242.72199999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 427.9589914602912, "num_env_steps_trained_throughput_per_sec": 427.9589914602912, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 9577.219, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9577.183, "sample_time_ms": 1242.965, "learn_time_ms": 8319.463, "learn_throughput": 480.8, "synch_weights_time_ms": 14.051}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-21-33", "timestamp": 1723645293, "time_this_iter_s": 9.35128378868103, "time_total_s": 1157.9531931877136, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ada7a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1157.9531931877136, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 28.615384615384617, "ram_util_percent": 80.56153846153848}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4487254085659824, "cur_kl_coeff": 1.6516728848614553e-06, "cur_lr": 0.009999999999999998, "total_loss": 2.0584029141872646, "policy_loss": -0.00025014041506601545, "vf_loss": 2.058653047097423, "vf_explained_var": 0.006143874466103851, "kl": -6.364429487614312e-40, "entropy": 6.895624173131826e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.509298635242635, "cur_kl_coeff": 1.2814453125000003, "cur_lr": 0.009999999999999998, "total_loss": 7.584303177979888, "policy_loss": 0.008180331478447274, "vf_loss": 7.55307577703365, "vf_explained_var": -5.993704316477296e-06, "kl": 0.01798521249055733, "entropy": 0.46210385937066306, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 40.0000000000003, "episode_reward_min": -532.0, "episode_reward_mean": -243.16299999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000026, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -296.0815, "predator_policy": 174.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-85.3000000000003, -428.0, -376.7, -383.8, -400.0, -5.699999999999768, 8.899999999999949, -403.2, -300.399999999999, -420.7999999999986, -266.0, -373.8, -95.60000000000016, -307.69999999999925, -83.50000000000057, -13.99999999999981, -394.5, 20.000000000000018, -422.0, -479.1, -400.0, 20.000000000000014, -6.0999999999999, -188.10000000000056, 20.900000000000027, -329.39999999999884, -382.4, -278.9999999999999, -361.2, -66.10000000000089, -373.6, 33.50000000000024, -171.00000000000063, -214.1000000000009, -370.29999999999995, -156.10000000000056, 20.000000000000018, -400.0, -351.5, -370.9999999999999, 20.000000000000018, -400.0, -352.9, -135.5000000000004, 20.000000000000018, -400.0, 17.29999999999998, -400.0, 40.0000000000003, -377.9, 20.000000000000014, -400.0, -251.50000000000077, -400.0, 20.000000000000014, -62.799999999999926, -348.29999999999995, -524.0, 20.000000000000018, -350.499999999999, -391.2, -360.3, -400.0, 31.800000000000185, 20.000000000000018, 20.000000000000014, -387.9, -152.00000000000065, -321.59999999999997, -400.0, -354.7, -312.99999999999955, -248.90000000000072, -395.8, -298.79999999999905, -385.7, -400.0, 34.40000000000026, -532.0, -400.0, -106.00000000000074, -219.40000000000043, -374.8, -400.0, -400.0, -348.79999999999933, -400.0, -278.49999999999983, -434.7, -146.00000000000045, -415.0, -400.0, -3.999999999999959, -522.0, -2.9999999999999414, -52.29999999999999, 33.20000000000024, -400.0, 20.000000000000018, -46.49999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.700000000000212, -357.99999999999955, -400.0, -400.0, -400.0, -363.7, -383.8, -400.0, -400.0, -400.0, -162.7000000000006, 20.000000000000014, -236.20000000000044, -73.9, -385.0, -383.2, -309.699999999999, -390.7, -400.0, -269.7999999999986, -400.0, -253.0, -359.8, -400.0, -400.0, 25.400000000000098, -260.7999999999993, -376.9, 27.20000000000013, -309.6999999999991, 36.20000000000026, -362.1999999999996, -389.5, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -360.1, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -381.0999999999998, 29.000000000000163, -143.80000000000055, -262.29999999999995, -400.0, 20.90000000000003, -262.59999999999883, -374.8, -400.0, -366.4, -169.00000000000063, -400.0, -383.2, -358.0, -66.10000000000089, -400.0, -387.4, -362.2, 33.50000000000024, -400.0, -400.0, 20.000000000000014, -383.2, -61.900000000000766, -343.3, -400.0, -400.0, -156.10000000000056, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -341.5, -387.39999999999986, -364.6, 20.000000000000014, -400.0, -400.0, -400.0, -387.7, -338.2, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -383.2, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -361.9, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -116.50000000000077, -400.0, -400.0, -400.0, 20.000000000000014, 27.20000000000013, -400.0, -400.0, -301.3, -400.0, -400.0, 20.000000000000014, -400.0, -305.499999999999, -400.0, -383.2, -400.0, -337.3, -400.0, -400.0, -400.0, -152.20000000000067, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -376.9, -400.0, 20.000000000000014, -400.0, -330.1, -341.5, -400.0, -400.0, -400.0, -354.7, -357.99999999999955, -328.0, -400.0, -82.90000000000072, -395.8, -400.0, -400.0, -206.8000000000004, -387.4, -385.3, -400.0, -400.0, 34.40000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, -106.00000000000074, -400.0, -400.0, -219.40000000000043, -374.8, -400.0, -400.0, -400.0, -400.0, -400.0, -371.8, -336.9999999999993, -400.0, -400.0, -386.8, -183.70000000000059, -351.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -379.0, -400.0, 20.000000000000014, -400.0, 22.700000000000053, -400.0, -347.8, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, 24.50000000000008, -400.0], "policy_predator_policy_reward": [180.0, 61.0, 189.0, 183.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 50.0, 87.0, 151.0, 168.0, 170.0, 195.0, 200.0, 200.0, 200.0, 49.0, 200.0, 187.0, 200.0, 186.0, 79.0, 200.0, 189.0, 141.0, 42.0, 157.0, 130.0, 182.0, 200.0, 195.0, 200.0, 200.0, 178.0, 200.0, 200.0, 81.0, 200.0, 200.0, 200.0, 200.0, 155.0, 191.0, 78.0, 140.0, 200.0, 200.0, 117.0, 191.0, 184.0, 200.0, 90.0, 200.0, 188.0, 192.0, 200.0, 200.0, 176.0, 200.0, 200.0, 200.0, 9.0, 200.0, 192.0, 39.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 194.0, 187.0, 200.0, 200.0, 200.0, 200.0, 178.0, 195.0, 200.0, 31.0, 200.0, 200.0, 200.0, 200.0, 181.0, 186.0, 200.0, 200.0, 0.0, 0.0, 184.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 200.0, 200.0, 200.0, 200.0, 110.0, 200.0, 153.0, 200.0, 76.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 192.0, 200.0, 177.0, 200.0, 200.0, 82.0, 82.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 28.0, 200.0, 176.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 173.0, 200.0, 34.0, 200.0, 200.0, 200.0, 108.0, 194.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 68.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 170.0, 200.0, 200.0, 97.0, 195.0, 117.0, 200.0, 34.0, 200.0, 185.0, 200.0, 200.0, 200.0, 176.0, 200.0, 197.0, 60.0, 200.0, 177.0, 200.0, 125.0, 179.0, 182.0, 200.0, 200.0, 200.0, 200.0, 193.0, 136.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5674683537605313, "mean_inference_ms": 1.7801719725213632, "mean_action_processing_ms": 0.24178635023595865, "mean_env_wait_ms": 0.18954663841638578, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037360191345214844, "StateBufferConnector_ms": 0.0031954050064086914, "ViewRequirementAgentConnector_ms": 0.09366321563720703}, "num_episodes": 18, "episode_return_max": 40.0000000000003, "episode_return_min": -532.0, "episode_return_mean": -243.16299999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 420.09455899540774, "num_env_steps_trained_throughput_per_sec": 420.09455899540774, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 9553.965, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9553.927, "sample_time_ms": 1245.914, "learn_time_ms": 8293.534, "learn_throughput": 482.303, "synch_weights_time_ms": 13.69}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-21-43", "timestamp": 1723645303, "time_this_iter_s": 9.527249813079834, "time_total_s": 1167.4804430007935, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae94a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1167.4804430007935, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 27.599999999999998, "ram_util_percent": 80.58571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.900951744150863, "cur_kl_coeff": 8.258364424307276e-07, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": -9.791254812467193e-05, "vf_loss": 1.095461706777729, "vf_explained_var": -0.0016458350514608716, "kl": Infinity, "entropy": 6.55536437519797e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8747880241779424, "cur_kl_coeff": 1.2814453125000003, "cur_lr": 0.009999999999999998, "total_loss": 7.818577114741007, "policy_loss": 0.005765159126302159, "vf_loss": 7.792214124417179, "vf_explained_var": -5.529986487494575e-07, "kl": 0.016073907989097434, "entropy": 0.47752225625294226, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 40.0000000000003, "episode_reward_min": -532.0, "episode_reward_mean": -239.02800000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 34.40000000000026, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -298.144, "predator_policy": 178.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-422.0, -479.1, -400.0, 20.000000000000014, -6.0999999999999, -188.10000000000056, 20.900000000000027, -329.39999999999884, -382.4, -278.9999999999999, -361.2, -66.10000000000089, -373.6, 33.50000000000024, -171.00000000000063, -214.1000000000009, -370.29999999999995, -156.10000000000056, 20.000000000000018, -400.0, -351.5, -370.9999999999999, 20.000000000000018, -400.0, -352.9, -135.5000000000004, 20.000000000000018, -400.0, 17.29999999999998, -400.0, 40.0000000000003, -377.9, 20.000000000000014, -400.0, -251.50000000000077, -400.0, 20.000000000000014, -62.799999999999926, -348.29999999999995, -524.0, 20.000000000000018, -350.499999999999, -391.2, -360.3, -400.0, 31.800000000000185, 20.000000000000018, 20.000000000000014, -387.9, -152.00000000000065, -321.59999999999997, -400.0, -354.7, -312.99999999999955, -248.90000000000072, -395.8, -298.79999999999905, -385.7, -400.0, 34.40000000000026, -532.0, -400.0, -106.00000000000074, -219.40000000000043, -374.8, -400.0, -400.0, -348.79999999999933, -400.0, -278.49999999999983, -434.7, -146.00000000000045, -415.0, -400.0, -3.999999999999959, -522.0, -2.9999999999999414, -52.29999999999999, 33.20000000000024, -400.0, 20.000000000000018, -46.49999999999998, -42.2, -384.59999999999997, 19.200000000000003, -400.0, -69.7000000000008, -123.30000000000027, -350.9, -400.0, 19.000000000000004, -388.9999999999998, -38.00000000000001, -234.10000000000045, -396.7, -203.50000000000054, -376.9, -159.10000000000068, -332.7999999999994, -34.000000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -360.1, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -381.0999999999998, 29.000000000000163, -143.80000000000055, -262.29999999999995, -400.0, 20.90000000000003, -262.59999999999883, -374.8, -400.0, -366.4, -169.00000000000063, -400.0, -383.2, -358.0, -66.10000000000089, -400.0, -387.4, -362.2, 33.50000000000024, -400.0, -400.0, 20.000000000000014, -383.2, -61.900000000000766, -343.3, -400.0, -400.0, -156.10000000000056, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -341.5, -387.39999999999986, -364.6, 20.000000000000014, -400.0, -400.0, -400.0, -387.7, -338.2, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -383.2, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -361.9, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -116.50000000000077, -400.0, -400.0, -400.0, 20.000000000000014, 27.20000000000013, -400.0, -400.0, -301.3, -400.0, -400.0, 20.000000000000014, -400.0, -305.499999999999, -400.0, -383.2, -400.0, -337.3, -400.0, -400.0, -400.0, -152.20000000000067, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -376.9, -400.0, 20.000000000000014, -400.0, -330.1, -341.5, -400.0, -400.0, -400.0, -354.7, -357.99999999999955, -328.0, -400.0, -82.90000000000072, -395.8, -400.0, -400.0, -206.8000000000004, -387.4, -385.3, -400.0, -400.0, 34.40000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, -106.00000000000074, -400.0, -400.0, -219.40000000000043, -374.8, -400.0, -400.0, -400.0, -400.0, -400.0, -371.8, -336.9999999999993, -400.0, -400.0, -386.8, -183.70000000000059, -351.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -379.0, -400.0, 20.000000000000014, -400.0, 22.700000000000053, -400.0, -347.8, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, 24.50000000000008, -400.0, -400.0, 21.80000000000004, -400.0, -370.6, -400.0, 27.20000000000013, -400.0, -400.0, -69.7000000000008, -400.0, 13.70000000000001, -400.0, -370.6, -352.3, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -378.9999999999998, 20.000000000000014, -400.0, -234.10000000000045, -400.0, -400.0, -393.7, -204.70000000000053, -389.8, -385.3, -370.59999999999997, -400.0, -150.10000000000068, -341.19999999999936, -391.6, -400.0, 20.000000000000014], "policy_predator_policy_reward": [178.0, 200.0, 200.0, 81.0, 200.0, 200.0, 200.0, 200.0, 155.0, 191.0, 78.0, 140.0, 200.0, 200.0, 117.0, 191.0, 184.0, 200.0, 90.0, 200.0, 188.0, 192.0, 200.0, 200.0, 176.0, 200.0, 200.0, 200.0, 9.0, 200.0, 192.0, 39.0, 200.0, 173.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 194.0, 187.0, 200.0, 200.0, 200.0, 200.0, 178.0, 195.0, 200.0, 31.0, 200.0, 200.0, 200.0, 200.0, 181.0, 186.0, 200.0, 200.0, 0.0, 0.0, 184.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 200.0, 200.0, 200.0, 200.0, 110.0, 200.0, 153.0, 200.0, 76.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 192.0, 200.0, 177.0, 200.0, 200.0, 82.0, 82.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 28.0, 200.0, 176.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 173.0, 200.0, 34.0, 200.0, 200.0, 200.0, 108.0, 194.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 68.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 170.0, 200.0, 200.0, 97.0, 195.0, 117.0, 200.0, 34.0, 200.0, 185.0, 200.0, 200.0, 200.0, 176.0, 200.0, 197.0, 60.0, 200.0, 177.0, 200.0, 125.0, 179.0, 182.0, 200.0, 200.0, 200.0, 200.0, 193.0, 136.0, 200.0, 136.0, 186.0, 200.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 63.0, 182.0, 190.0, 200.0, 200.0, 200.0, 199.0, 190.0, 200.0, 142.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 191.0, 193.0, 186.0, 191.0, 200.0, 200.0, 200.0, 146.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5670551628513715, "mean_inference_ms": 1.7788013717550755, "mean_action_processing_ms": 0.24154863106750746, "mean_env_wait_ms": 0.18936661779956857, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003700852394104004, "StateBufferConnector_ms": 0.0031703710556030273, "ViewRequirementAgentConnector_ms": 0.09122145175933838}, "num_episodes": 18, "episode_return_max": 40.0000000000003, "episode_return_min": -532.0, "episode_return_mean": -239.02800000000008, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 414.81026401986, "num_env_steps_trained_throughput_per_sec": 414.81026401986, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 9553.787, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9553.75, "sample_time_ms": 1251.089, "learn_time_ms": 8288.468, "learn_throughput": 482.598, "synch_weights_time_ms": 13.407}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-21-52", "timestamp": 1723645312, "time_this_iter_s": 9.647395133972168, "time_total_s": 1177.1278381347656, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae948b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1177.1278381347656, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 27.099999999999998, "ram_util_percent": 80.66428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0725581574135474, "cur_kl_coeff": 1.2387546636460912e-06, "cur_lr": 0.009999999999999998, "total_loss": 0.7250776138836665, "policy_loss": 2.5979567457128453e-05, "vf_loss": 0.7250516351174425, "vf_explained_var": 0.003802087698033247, "kl": 2.839776594333931e-38, "entropy": 4.369296895936734e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8602864163499029, "cur_kl_coeff": 1.2814453125000003, "cur_lr": 0.009999999999999998, "total_loss": 8.440820935415843, "policy_loss": 0.004614750105670836, "vf_loss": 8.422111095196355, "vf_explained_var": -1.5863035091016657e-08, "kl": 0.010999391788123846, "entropy": 0.3730462759220726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 40.0000000000003, "episode_reward_min": -532.0, "episode_reward_mean": -235.54900000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 34.40000000000026, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -299.9245, "predator_policy": 182.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.000000000000018, -400.0, -352.9, -135.5000000000004, 20.000000000000018, -400.0, 17.29999999999998, -400.0, 40.0000000000003, -377.9, 20.000000000000014, -400.0, -251.50000000000077, -400.0, 20.000000000000014, -62.799999999999926, -348.29999999999995, -524.0, 20.000000000000018, -350.499999999999, -391.2, -360.3, -400.0, 31.800000000000185, 20.000000000000018, 20.000000000000014, -387.9, -152.00000000000065, -321.59999999999997, -400.0, -354.7, -312.99999999999955, -248.90000000000072, -395.8, -298.79999999999905, -385.7, -400.0, 34.40000000000026, -532.0, -400.0, -106.00000000000074, -219.40000000000043, -374.8, -400.0, -400.0, -348.79999999999933, -400.0, -278.49999999999983, -434.7, -146.00000000000045, -415.0, -400.0, -3.999999999999959, -522.0, -2.9999999999999414, -52.29999999999999, 33.20000000000024, -400.0, 20.000000000000018, -46.49999999999998, -42.2, -384.59999999999997, 19.200000000000003, -400.0, -69.7000000000008, -123.30000000000027, -350.9, -400.0, 19.000000000000004, -388.9999999999998, -38.00000000000001, -234.10000000000045, -396.7, -203.50000000000054, -376.9, -159.10000000000068, -332.7999999999994, -34.000000000000014, -355.4, -295.49999999999994, -372.3, -379.8, -365.8, 20.000000000000014, 20.000000000000018, 36.20000000000026, -392.8, 20.000000000000014, -188.70000000000076, -420.0, -376.9, -400.0, 20.000000000000014, -362.2, -364.3, -400.0, 13.99999999999996, -386.0, 20.000000000000014, 30.800000000000196], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -400.0, -400.0, -400.0, -387.7, -338.2, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -383.2, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -361.9, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -116.50000000000077, -400.0, -400.0, -400.0, 20.000000000000014, 27.20000000000013, -400.0, -400.0, -301.3, -400.0, -400.0, 20.000000000000014, -400.0, -305.499999999999, -400.0, -383.2, -400.0, -337.3, -400.0, -400.0, -400.0, -152.20000000000067, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -376.9, -400.0, 20.000000000000014, -400.0, -330.1, -341.5, -400.0, -400.0, -400.0, -354.7, -357.99999999999955, -328.0, -400.0, -82.90000000000072, -395.8, -400.0, -400.0, -206.8000000000004, -387.4, -385.3, -400.0, -400.0, 34.40000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, -106.00000000000074, -400.0, -400.0, -219.40000000000043, -374.8, -400.0, -400.0, -400.0, -400.0, -400.0, -371.8, -336.9999999999993, -400.0, -400.0, -386.8, -183.70000000000059, -351.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -379.0, -400.0, 20.000000000000014, -400.0, 22.700000000000053, -400.0, -347.8, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, 24.50000000000008, -400.0, -400.0, 21.80000000000004, -400.0, -370.6, -400.0, 27.20000000000013, -400.0, -400.0, -69.7000000000008, -400.0, 13.70000000000001, -400.0, -370.6, -352.3, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -378.9999999999998, 20.000000000000014, -400.0, -234.10000000000045, -400.0, -400.0, -393.7, -204.70000000000053, -389.8, -385.3, -370.59999999999997, -400.0, -150.10000000000068, -341.19999999999936, -391.6, -400.0, 20.000000000000014, -354.4, -400.0, -393.7, -269.8, -400.0, -364.3, -400.0, -365.8, -400.0, -347.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -347.8, -400.0, -389.8, -400.0, 20.000000000000014, -9.699999999999886, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -362.2, -400.0, -364.3, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.0, -400.0, -400.0, 20.000000000000014, -400.0, 30.800000000000196], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 178.0, 195.0, 200.0, 31.0, 200.0, 200.0, 200.0, 200.0, 181.0, 186.0, 200.0, 200.0, 0.0, 0.0, 184.0, 200.0, 200.0, 200.0, 200.0, 200.0, 65.0, 200.0, 200.0, 200.0, 200.0, 200.0, 110.0, 200.0, 153.0, 200.0, 76.0, 200.0, 200.0, 200.0, 200.0, 155.0, 200.0, 192.0, 200.0, 177.0, 200.0, 200.0, 82.0, 82.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 28.0, 200.0, 176.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 173.0, 200.0, 34.0, 200.0, 200.0, 200.0, 108.0, 194.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 68.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 170.0, 200.0, 200.0, 97.0, 195.0, 117.0, 200.0, 34.0, 200.0, 185.0, 200.0, 200.0, 200.0, 176.0, 200.0, 197.0, 60.0, 200.0, 177.0, 200.0, 125.0, 179.0, 182.0, 200.0, 200.0, 200.0, 200.0, 193.0, 136.0, 200.0, 136.0, 186.0, 200.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 63.0, 182.0, 190.0, 200.0, 200.0, 200.0, 199.0, 190.0, 200.0, 142.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 191.0, 193.0, 186.0, 191.0, 200.0, 200.0, 200.0, 146.0, 200.0, 200.0, 199.0, 197.0, 171.0, 192.0, 200.0, 200.0, 186.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 197.0, 200.0, 200.0, 21.0, 200.0, 180.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5665644742589852, "mean_inference_ms": 1.7770337111244794, "mean_action_processing_ms": 0.2412782551229232, "mean_env_wait_ms": 0.18915796673444907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003679037094116211, "StateBufferConnector_ms": 0.003186464309692383, "ViewRequirementAgentConnector_ms": 0.08962535858154297}, "num_episodes": 22, "episode_return_max": 40.0000000000003, "episode_return_min": -532.0, "episode_return_mean": -235.54900000000006, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 415.2042847085228, "num_env_steps_trained_throughput_per_sec": 415.2042847085228, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 9551.137, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9551.101, "sample_time_ms": 1245.501, "learn_time_ms": 8291.472, "learn_throughput": 482.423, "synch_weights_time_ms": 13.35}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-22-02", "timestamp": 1723645322, "time_this_iter_s": 9.637929916381836, "time_total_s": 1186.7657680511475, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ada7af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1186.7657680511475, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 28.242857142857137, "ram_util_percent": 80.47142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1729357772718663, "cur_kl_coeff": 6.193773318230456e-07, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": 2.6046734170189924e-05, "vf_loss": 0.8984690630956301, "vf_explained_var": 0.00019293868983233416, "kl": Infinity, "entropy": 2.5094941777612495e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5825943584598248, "cur_kl_coeff": 1.2814453125000003, "cur_lr": 0.009999999999999998, "total_loss": 8.307047843933105, "policy_loss": 0.00510954481978265, "vf_loss": 8.275115402413423, "vf_explained_var": -9.02490010337224e-07, "kl": 0.02093174249843374, "entropy": 0.4098160627914011, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 36.20000000000026, "episode_reward_min": -532.0, "episode_reward_mean": -240.778, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 21.0}, "policy_reward_max": {"prey_policy": 34.40000000000026, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -306.73900000000003, "predator_policy": 186.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.000000000000018, -350.499999999999, -391.2, -360.3, -400.0, 31.800000000000185, 20.000000000000018, 20.000000000000014, -387.9, -152.00000000000065, -321.59999999999997, -400.0, -354.7, -312.99999999999955, -248.90000000000072, -395.8, -298.79999999999905, -385.7, -400.0, 34.40000000000026, -532.0, -400.0, -106.00000000000074, -219.40000000000043, -374.8, -400.0, -400.0, -348.79999999999933, -400.0, -278.49999999999983, -434.7, -146.00000000000045, -415.0, -400.0, -3.999999999999959, -522.0, -2.9999999999999414, -52.29999999999999, 33.20000000000024, -400.0, 20.000000000000018, -46.49999999999998, -42.2, -384.59999999999997, 19.200000000000003, -400.0, -69.7000000000008, -123.30000000000027, -350.9, -400.0, 19.000000000000004, -388.9999999999998, -38.00000000000001, -234.10000000000045, -396.7, -203.50000000000054, -376.9, -159.10000000000068, -332.7999999999994, -34.000000000000014, -355.4, -295.49999999999994, -372.3, -379.8, -365.8, 20.000000000000014, 20.000000000000018, 36.20000000000026, -392.8, 20.000000000000014, -188.70000000000076, -420.0, -376.9, -400.0, 20.000000000000014, -362.2, -364.3, -400.0, 13.99999999999996, -386.0, 20.000000000000014, 30.800000000000196, -400.0, -41.49999999999978, -400.0, 12.999999999999961, -382.6, -219.60000000000045, -400.0, 32.60000000000023, 17.099999999999977, 9.99999999999996, -365.8, 31.700000000000212, -400.0, -400.0, -400.0, -367.6, -365.8, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -400.0, -305.499999999999, -400.0, -383.2, -400.0, -337.3, -400.0, -400.0, -400.0, -152.20000000000067, 20.000000000000014, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -376.9, -400.0, 20.000000000000014, -400.0, -330.1, -341.5, -400.0, -400.0, -400.0, -354.7, -357.99999999999955, -328.0, -400.0, -82.90000000000072, -395.8, -400.0, -400.0, -206.8000000000004, -387.4, -385.3, -400.0, -400.0, 34.40000000000026, -400.0, -400.0, -400.0, -400.0, -400.0, -106.00000000000074, -400.0, -400.0, -219.40000000000043, -374.8, -400.0, -400.0, -400.0, -400.0, -400.0, -371.8, -336.9999999999993, -400.0, -400.0, -386.8, -183.70000000000059, -351.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -379.0, -400.0, 20.000000000000014, -400.0, 22.700000000000053, -400.0, -347.8, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, 24.50000000000008, -400.0, -400.0, 21.80000000000004, -400.0, -370.6, -400.0, 27.20000000000013, -400.0, -400.0, -69.7000000000008, -400.0, 13.70000000000001, -400.0, -370.6, -352.3, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -378.9999999999998, 20.000000000000014, -400.0, -234.10000000000045, -400.0, -400.0, -393.7, -204.70000000000053, -389.8, -385.3, -370.59999999999997, -400.0, -150.10000000000068, -341.19999999999936, -391.6, -400.0, 20.000000000000014, -354.4, -400.0, -393.7, -269.8, -400.0, -364.3, -400.0, -365.8, -400.0, -347.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -347.8, -400.0, -389.8, -400.0, 20.000000000000014, -9.699999999999886, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -362.2, -400.0, -364.3, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.0, -400.0, -400.0, 20.000000000000014, -400.0, 30.800000000000196, -400.0, -400.0, -400.0, -41.49999999999978, -400.0, -400.0, -400.0, 20.000000000000014, -383.8, -392.8, -55.60000000000004, -400.0, -400.0, -400.0, 32.60000000000023, -400.0, 20.000000000000014, -397.9, 20.000000000000014, -400.0, -365.8, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -356.8, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 155.0, 200.0, 192.0, 200.0, 177.0, 200.0, 200.0, 82.0, 82.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 28.0, 200.0, 176.0, 174.0, 200.0, 200.0, 200.0, 200.0, 200.0, 173.0, 200.0, 34.0, 200.0, 200.0, 200.0, 108.0, 194.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 68.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 170.0, 200.0, 200.0, 97.0, 195.0, 117.0, 200.0, 34.0, 200.0, 185.0, 200.0, 200.0, 200.0, 176.0, 200.0, 197.0, 60.0, 200.0, 177.0, 200.0, 125.0, 179.0, 182.0, 200.0, 200.0, 200.0, 200.0, 193.0, 136.0, 200.0, 136.0, 186.0, 200.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 63.0, 182.0, 190.0, 200.0, 200.0, 200.0, 199.0, 190.0, 200.0, 142.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 191.0, 193.0, 186.0, 191.0, 200.0, 200.0, 200.0, 146.0, 200.0, 200.0, 199.0, 197.0, 171.0, 192.0, 200.0, 200.0, 186.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 197.0, 200.0, 200.0, 21.0, 200.0, 180.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 197.0, 197.0, 36.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5662967491573064, "mean_inference_ms": 1.7763275953081854, "mean_action_processing_ms": 0.24115421996690145, "mean_env_wait_ms": 0.18906224072236008, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037000179290771484, "StateBufferConnector_ms": 0.0032072067260742188, "ViewRequirementAgentConnector_ms": 0.08951830863952637}, "num_episodes": 18, "episode_return_max": 36.20000000000026, "episode_return_min": -532.0, "episode_return_mean": -240.778, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.4916040052685, "num_env_steps_trained_throughput_per_sec": 416.4916040052685, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 9545.952, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9545.916, "sample_time_ms": 1266.959, "learn_time_ms": 8265.253, "learn_throughput": 483.954, "synch_weights_time_ms": 12.898}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-22-12", "timestamp": 1723645332, "time_this_iter_s": 9.610473871231079, "time_total_s": 1196.3762419223785, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae49310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1196.3762419223785, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 30.5, "ram_util_percent": 80.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9316987202980767, "cur_kl_coeff": 9.290659977345681e-07, "cur_lr": 0.009999999999999998, "total_loss": 1.8169723281469294, "policy_loss": -9.260962855208803e-05, "vf_loss": 1.8170649394156442, "vf_explained_var": -4.590850658517666e-05, "kl": 4.1787313348373164e-43, "entropy": 4.145350972670235e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8080964093150758, "cur_kl_coeff": 1.9221679687499995, "cur_lr": 0.009999999999999998, "total_loss": 8.747270853052694, "policy_loss": 0.0030268993980137916, "vf_loss": 8.728070533086383, "vf_explained_var": -9.366444178989955e-09, "kl": 0.00841415340799953, "entropy": 0.3148572561602113, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 193.7999999999994, "episode_reward_min": -522.0, "episode_reward_mean": -248.42, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1704.0, "predator_policy": 21.0}, "policy_reward_max": {"prey_policy": 32.60000000000023, "predator_policy": 1667.0}, "policy_reward_mean": {"prey_policy": -320.03, "predator_policy": 195.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-219.40000000000043, -374.8, -400.0, -400.0, -348.79999999999933, -400.0, -278.49999999999983, -434.7, -146.00000000000045, -415.0, -400.0, -3.999999999999959, -522.0, -2.9999999999999414, -52.29999999999999, 33.20000000000024, -400.0, 20.000000000000018, -46.49999999999998, -42.2, -384.59999999999997, 19.200000000000003, -400.0, -69.7000000000008, -123.30000000000027, -350.9, -400.0, 19.000000000000004, -388.9999999999998, -38.00000000000001, -234.10000000000045, -396.7, -203.50000000000054, -376.9, -159.10000000000068, -332.7999999999994, -34.000000000000014, -355.4, -295.49999999999994, -372.3, -379.8, -365.8, 20.000000000000014, 20.000000000000018, 36.20000000000026, -392.8, 20.000000000000014, -188.70000000000076, -420.0, -376.9, -400.0, 20.000000000000014, -362.2, -364.3, -400.0, 13.99999999999996, -386.0, 20.000000000000014, 30.800000000000196, -400.0, -41.49999999999978, -400.0, 12.999999999999961, -382.6, -219.60000000000045, -400.0, 32.60000000000023, 17.099999999999977, 9.99999999999996, -365.8, 31.700000000000212, -400.0, -400.0, -400.0, -367.6, -365.8, -400.0, -411.0, -400.0, -324.0999999999999, -315.199999999999, -388.7, -376.8999999999995, -345.7, -400.0, -83.09999999999991, -400.0, -296.9999999999991, 193.7999999999994, -107.10000000000085, 21.80000000000004, -400.0, -400.0, -123.00000000000028, -400.0, -329.7, -400.0, -396.7, -400.0, -353.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -219.40000000000043, -374.8, -400.0, -400.0, -400.0, -400.0, -400.0, -371.8, -336.9999999999993, -400.0, -400.0, -386.8, -183.70000000000059, -351.7, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -379.0, -400.0, 20.000000000000014, -400.0, 22.700000000000053, -400.0, -347.8, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, 24.50000000000008, -400.0, -400.0, 21.80000000000004, -400.0, -370.6, -400.0, 27.20000000000013, -400.0, -400.0, -69.7000000000008, -400.0, 13.70000000000001, -400.0, -370.6, -352.3, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -378.9999999999998, 20.000000000000014, -400.0, -234.10000000000045, -400.0, -400.0, -393.7, -204.70000000000053, -389.8, -385.3, -370.59999999999997, -400.0, -150.10000000000068, -341.19999999999936, -391.6, -400.0, 20.000000000000014, -354.4, -400.0, -393.7, -269.8, -400.0, -364.3, -400.0, -365.8, -400.0, -347.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -347.8, -400.0, -389.8, -400.0, 20.000000000000014, -9.699999999999886, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -362.2, -400.0, -364.3, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.0, -400.0, -400.0, 20.000000000000014, -400.0, 30.800000000000196, -400.0, -400.0, -400.0, -41.49999999999978, -400.0, -400.0, -400.0, 20.000000000000014, -383.8, -392.8, -55.60000000000004, -400.0, -400.0, -400.0, 32.60000000000023, -400.0, 20.000000000000014, -397.9, 20.000000000000014, -400.0, -365.8, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -356.8, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -255.10000000000002, -290.49999999999903, -351.7, -381.7, -400.0, -355.8999999999995, -400.0, -381.1, -331.6, -400.0, -400.0, -45.09999999999976, -400.0, -400.0, -400.0, -279.9999999999991, -400.0, -1704.0, 30.800000000000196, -24.099999999999746, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -330.1, -349.6, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -353.8, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 190.0, 170.0, 200.0, 200.0, 97.0, 195.0, 117.0, 200.0, 34.0, 200.0, 185.0, 200.0, 200.0, 200.0, 176.0, 200.0, 197.0, 60.0, 200.0, 177.0, 200.0, 125.0, 179.0, 182.0, 200.0, 200.0, 200.0, 200.0, 193.0, 136.0, 200.0, 136.0, 186.0, 200.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 63.0, 182.0, 190.0, 200.0, 200.0, 200.0, 199.0, 190.0, 200.0, 142.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 191.0, 193.0, 186.0, 191.0, 200.0, 200.0, 200.0, 146.0, 200.0, 200.0, 199.0, 197.0, 171.0, 192.0, 200.0, 200.0, 186.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 197.0, 200.0, 200.0, 21.0, 200.0, 180.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 197.0, 197.0, 36.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 131.0, 150.0, 177.0, 193.0, 200.0, 200.0, 179.0, 176.0, 191.0, 200.0, 200.0, 200.0, 162.0, 200.0, 200.0, 183.0, 200.0, 200.0, 1667.0, 160.0, 157.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 61.0, 196.0, 200.0, 200.0, 174.0, 176.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5658714642929142, "mean_inference_ms": 1.7751456179162879, "mean_action_processing_ms": 0.2409725593521153, "mean_env_wait_ms": 0.18891830772085216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003644108772277832, "StateBufferConnector_ms": 0.0032094717025756836, "ViewRequirementAgentConnector_ms": 0.08806264400482178}, "num_episodes": 23, "episode_return_max": 193.7999999999994, "episode_return_min": -522.0, "episode_return_mean": -248.42, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 427.50845004407535, "num_env_steps_trained_throughput_per_sec": 427.50845004407535, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 9510.488, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9510.452, "sample_time_ms": 1266.142, "learn_time_ms": 8230.976, "learn_throughput": 485.969, "synch_weights_time_ms": 12.53}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-22-21", "timestamp": 1723645341, "time_this_iter_s": 9.36111307144165, "time_total_s": 1205.7373549938202, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8cc430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1205.7373549938202, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 28.985714285714288, "ram_util_percent": 80.95714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0564746485554943, "cur_kl_coeff": 4.6453299886728404e-07, "cur_lr": 0.009999999999999998, "total_loss": 0.4789225287183567, "policy_loss": 0.00022766584969032062, "vf_loss": 0.47869486313525134, "vf_explained_var": 0.0014885533423650832, "kl": 4.310557190370096e-43, "entropy": 2.7784592511189405e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7822843832983857, "cur_kl_coeff": 1.9221679687499995, "cur_lr": 0.009999999999999998, "total_loss": 8.174491588400786, "policy_loss": 0.0020148656269407305, "vf_loss": 8.162911378769648, "vf_explained_var": -2.005207475531038e-06, "kl": 0.004976337341474425, "entropy": 0.2350722591673571, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 1812.9999999999945, "episode_reward_min": -423.7, "episode_reward_mean": -223.87300000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1840.0, "predator_policy": 21.0}, "policy_reward_max": {"prey_policy": 32.60000000000023, "predator_policy": 1820.0}, "policy_reward_mean": {"prey_policy": -326.87149999999997, "predator_policy": 214.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.49999999999998, -42.2, -384.59999999999997, 19.200000000000003, -400.0, -69.7000000000008, -123.30000000000027, -350.9, -400.0, 19.000000000000004, -388.9999999999998, -38.00000000000001, -234.10000000000045, -396.7, -203.50000000000054, -376.9, -159.10000000000068, -332.7999999999994, -34.000000000000014, -355.4, -295.49999999999994, -372.3, -379.8, -365.8, 20.000000000000014, 20.000000000000018, 36.20000000000026, -392.8, 20.000000000000014, -188.70000000000076, -420.0, -376.9, -400.0, 20.000000000000014, -362.2, -364.3, -400.0, 13.99999999999996, -386.0, 20.000000000000014, 30.800000000000196, -400.0, -41.49999999999978, -400.0, 12.999999999999961, -382.6, -219.60000000000045, -400.0, 32.60000000000023, 17.099999999999977, 9.99999999999996, -365.8, 31.700000000000212, -400.0, -400.0, -400.0, -367.6, -365.8, -400.0, -411.0, -400.0, -324.0999999999999, -315.199999999999, -388.7, -376.8999999999995, -345.7, -400.0, -83.09999999999991, -400.0, -296.9999999999991, 193.7999999999994, -107.10000000000085, 21.80000000000004, -400.0, -400.0, -123.00000000000028, -400.0, -329.7, -400.0, -396.7, -400.0, -353.8, -362.3, 20.000000000000018, 3.9999999999999627, -400.0, 1812.9999999999945, -340.3, -423.7, -369.6, 20.000000000000014, -400.0, 13.999999999999957, 20.000000000000018, -400.0, 20.000000000000014, -400.0, -341.4, -400.0, -364.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [24.50000000000008, -400.0, -400.0, 21.80000000000004, -400.0, -370.6, -400.0, 27.20000000000013, -400.0, -400.0, -69.7000000000008, -400.0, 13.70000000000001, -400.0, -370.6, -352.3, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -378.9999999999998, 20.000000000000014, -400.0, -234.10000000000045, -400.0, -400.0, -393.7, -204.70000000000053, -389.8, -385.3, -370.59999999999997, -400.0, -150.10000000000068, -341.19999999999936, -391.6, -400.0, 20.000000000000014, -354.4, -400.0, -393.7, -269.8, -400.0, -364.3, -400.0, -365.8, -400.0, -347.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -347.8, -400.0, -389.8, -400.0, 20.000000000000014, -9.699999999999886, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -362.2, -400.0, -364.3, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.0, -400.0, -400.0, 20.000000000000014, -400.0, 30.800000000000196, -400.0, -400.0, -400.0, -41.49999999999978, -400.0, -400.0, -400.0, 20.000000000000014, -383.8, -392.8, -55.60000000000004, -400.0, -400.0, -400.0, 32.60000000000023, -400.0, 20.000000000000014, -397.9, 20.000000000000014, -400.0, -365.8, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -356.8, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -255.10000000000002, -290.49999999999903, -351.7, -381.7, -400.0, -355.8999999999995, -400.0, -381.1, -331.6, -400.0, -400.0, -45.09999999999976, -400.0, -400.0, -400.0, -279.9999999999991, -400.0, -1704.0, 30.800000000000196, -24.099999999999746, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -330.1, -349.6, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -353.8, -400.0, -400.0, -340.3, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -1840.0, 20.000000000000014, -347.5, -350.8, -400.0, -393.7, -371.8, -389.8, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -339.4, -400.0, -400.0, -364.3, -400.0], "policy_predator_policy_reward": [193.0, 136.0, 200.0, 136.0, 186.0, 200.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 63.0, 182.0, 190.0, 200.0, 200.0, 200.0, 199.0, 190.0, 200.0, 142.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 191.0, 193.0, 186.0, 191.0, 200.0, 200.0, 200.0, 146.0, 200.0, 200.0, 199.0, 197.0, 171.0, 192.0, 200.0, 200.0, 186.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 197.0, 200.0, 200.0, 21.0, 200.0, 180.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 197.0, 197.0, 36.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 131.0, 150.0, 177.0, 193.0, 200.0, 200.0, 179.0, 176.0, 191.0, 200.0, 200.0, 200.0, 162.0, 200.0, 200.0, 183.0, 200.0, 200.0, 1667.0, 160.0, 157.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 61.0, 196.0, 200.0, 200.0, 174.0, 176.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 1820.0, 1813.0, 175.0, 183.0, 200.0, 170.0, 196.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5654846389263793, "mean_inference_ms": 1.7742008566913077, "mean_action_processing_ms": 0.24083965436214638, "mean_env_wait_ms": 0.1887976701674839, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036020278930664062, "StateBufferConnector_ms": 0.002999424934387207, "ViewRequirementAgentConnector_ms": 0.08672690391540527}, "num_episodes": 18, "episode_return_max": 1812.9999999999945, "episode_return_min": -423.7, "episode_return_mean": -223.87300000000008, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 412.91707699624203, "num_env_steps_trained_throughput_per_sec": 412.91707699624203, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 9534.872, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9534.837, "sample_time_ms": 1271.296, "learn_time_ms": 8250.078, "learn_throughput": 484.844, "synch_weights_time_ms": 12.664}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-22-31", "timestamp": 1723645351, "time_this_iter_s": 9.69166111946106, "time_total_s": 1215.4290161132812, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ad44820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1215.4290161132812, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 28.030769230769234, "ram_util_percent": 80.96153846153847}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.228240749800686, "cur_kl_coeff": 2.3226649943364202e-07, "cur_lr": 0.009999999999999998, "total_loss": 0.5820834964701028, "policy_loss": 0.0003347010181714145, "vf_loss": 0.5817487982333337, "vf_explained_var": 0.00026979613556432977, "kl": -2.2720713356211054e-41, "entropy": 3.113975879323039e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6680318299542976, "cur_kl_coeff": 0.9610839843749998, "cur_lr": 0.009999999999999998, "total_loss": 8.183627604933642, "policy_loss": 0.004146398850544184, "vf_loss": 8.169773186577691, "vf_explained_var": 1.8270905055697002e-05, "kl": 0.010101108158774966, "entropy": 0.21644267555247382, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 1812.9999999999945, "episode_reward_min": -544.1, "episode_reward_mean": -231.35000000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1840.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 1820.0}, "policy_reward_mean": {"prey_policy": -330.89, "predator_policy": 215.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-379.8, -365.8, 20.000000000000014, 20.000000000000018, 36.20000000000026, -392.8, 20.000000000000014, -188.70000000000076, -420.0, -376.9, -400.0, 20.000000000000014, -362.2, -364.3, -400.0, 13.99999999999996, -386.0, 20.000000000000014, 30.800000000000196, -400.0, -41.49999999999978, -400.0, 12.999999999999961, -382.6, -219.60000000000045, -400.0, 32.60000000000023, 17.099999999999977, 9.99999999999996, -365.8, 31.700000000000212, -400.0, -400.0, -400.0, -367.6, -365.8, -400.0, -411.0, -400.0, -324.0999999999999, -315.199999999999, -388.7, -376.8999999999995, -345.7, -400.0, -83.09999999999991, -400.0, -296.9999999999991, 193.7999999999994, -107.10000000000085, 21.80000000000004, -400.0, -400.0, -123.00000000000028, -400.0, -329.7, -400.0, -396.7, -400.0, -353.8, -362.3, 20.000000000000018, 3.9999999999999627, -400.0, 1812.9999999999945, -340.3, -423.7, -369.6, 20.000000000000014, -400.0, 13.999999999999957, 20.000000000000018, -400.0, 20.000000000000014, -400.0, -341.4, -400.0, -364.3, -400.0, -544.1, 30.200000000000184, 18.499999999999996, -180.00000000000065, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000018, -384.59999999999997, -389.0, -400.0, 35.30000000000026, -391.2, 5.999999999999963, -400.0, -388.6, -400.0, 33.50000000000024, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -365.8, -400.0, -347.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -347.8, -400.0, -389.8, -400.0, 20.000000000000014, -9.699999999999886, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -362.2, -400.0, -364.3, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.0, -400.0, -400.0, 20.000000000000014, -400.0, 30.800000000000196, -400.0, -400.0, -400.0, -41.49999999999978, -400.0, -400.0, -400.0, 20.000000000000014, -383.8, -392.8, -55.60000000000004, -400.0, -400.0, -400.0, 32.60000000000023, -400.0, 20.000000000000014, -397.9, 20.000000000000014, -400.0, -365.8, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -356.8, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -255.10000000000002, -290.49999999999903, -351.7, -381.7, -400.0, -355.8999999999995, -400.0, -381.1, -331.6, -400.0, -400.0, -45.09999999999976, -400.0, -400.0, -400.0, -279.9999999999991, -400.0, -1704.0, 30.800000000000196, -24.099999999999746, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -330.1, -349.6, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -353.8, -400.0, -400.0, -340.3, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -1840.0, 20.000000000000014, -347.5, -350.8, -400.0, -393.7, -371.8, -389.8, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -339.4, -400.0, -400.0, -364.3, -400.0, -400.0, -400.0, -381.1, -400.0, 20.000000000000014, -350.8, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -370.59999999999997, -400.0, -397.9, -381.1, -400.0, -400.0, -400.0, 35.30000000000026, -383.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -370.6, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 186.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 197.0, 200.0, 200.0, 21.0, 200.0, 180.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 197.0, 197.0, 36.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 131.0, 150.0, 177.0, 193.0, 200.0, 200.0, 179.0, 176.0, 191.0, 200.0, 200.0, 200.0, 162.0, 200.0, 200.0, 183.0, 200.0, 200.0, 1667.0, 160.0, 157.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 61.0, 196.0, 200.0, 200.0, 174.0, 176.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 1820.0, 1813.0, 175.0, 183.0, 200.0, 170.0, 196.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 37.0, 178.0, 183.0, 194.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 191.0, 199.0, 200.0, 200.0, 200.0, 200.0, 192.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5651473544053707, "mean_inference_ms": 1.7747784484224958, "mean_action_processing_ms": 0.24044576867022666, "mean_env_wait_ms": 0.1886981430905093, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036045312881469727, "StateBufferConnector_ms": 0.003007173538208008, "ViewRequirementAgentConnector_ms": 0.0862734317779541}, "num_episodes": 22, "episode_return_max": 1812.9999999999945, "episode_return_min": -544.1, "episode_return_mean": -231.35000000000002, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 429.7647818020819, "num_env_steps_trained_throughput_per_sec": 429.7647818020819, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 9499.539, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9499.503, "sample_time_ms": 1268.786, "learn_time_ms": 8217.611, "learn_throughput": 486.759, "synch_weights_time_ms": 12.293}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-22-40", "timestamp": 1723645360, "time_this_iter_s": 9.31358289718628, "time_total_s": 1224.7425990104675, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8cc280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1224.7425990104675, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 26.78571428571429, "ram_util_percent": 80.79285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.101688812562713, "cur_kl_coeff": 1.1613324971682101e-07, "cur_lr": 0.009999999999999998, "total_loss": 0.37749954975904926, "policy_loss": 0.00030858395941476657, "vf_loss": 0.37719096405278874, "vf_explained_var": 0.0003262294347954806, "kl": 1.0038857712757455e-43, "entropy": 2.997799477960522e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3682478822284827, "cur_kl_coeff": 0.9610839843749998, "cur_lr": 0.009999999999999998, "total_loss": 8.222212824998078, "policy_loss": 0.0017375984322772456, "vf_loss": 8.214944005390954, "vf_explained_var": 2.47006063108091e-06, "kl": 0.005755199052701375, "entropy": 0.10800646783010394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 1812.9999999999945, "episode_reward_min": -544.1, "episode_reward_mean": -240.16, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1840.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 1820.0}, "policy_reward_mean": {"prey_policy": -335.57, "predator_policy": 215.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.800000000000196, -400.0, -41.49999999999978, -400.0, 12.999999999999961, -382.6, -219.60000000000045, -400.0, 32.60000000000023, 17.099999999999977, 9.99999999999996, -365.8, 31.700000000000212, -400.0, -400.0, -400.0, -367.6, -365.8, -400.0, -411.0, -400.0, -324.0999999999999, -315.199999999999, -388.7, -376.8999999999995, -345.7, -400.0, -83.09999999999991, -400.0, -296.9999999999991, 193.7999999999994, -107.10000000000085, 21.80000000000004, -400.0, -400.0, -123.00000000000028, -400.0, -329.7, -400.0, -396.7, -400.0, -353.8, -362.3, 20.000000000000018, 3.9999999999999627, -400.0, 1812.9999999999945, -340.3, -423.7, -369.6, 20.000000000000014, -400.0, 13.999999999999957, 20.000000000000018, -400.0, 20.000000000000014, -400.0, -341.4, -400.0, -364.3, -400.0, -544.1, 30.200000000000184, 18.499999999999996, -180.00000000000065, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000018, -384.59999999999997, -389.0, -400.0, 35.30000000000026, -391.2, 5.999999999999963, -400.0, -388.6, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -396.7, -400.0, -377.8, 25.400000000000098, -175.50000000000063, -400.0, -400.0, -393.7, -400.0, 20.000000000000014, 20.000000000000018, -355.9, 34.40000000000026, 4.999999999999957, -372.5, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 30.800000000000196, -400.0, -400.0, -400.0, -41.49999999999978, -400.0, -400.0, -400.0, 20.000000000000014, -383.8, -392.8, -55.60000000000004, -400.0, -400.0, -400.0, 32.60000000000023, -400.0, 20.000000000000014, -397.9, 20.000000000000014, -400.0, -365.8, -400.0, 31.700000000000212, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -367.6, -400.0, -356.8, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -255.10000000000002, -290.49999999999903, -351.7, -381.7, -400.0, -355.8999999999995, -400.0, -381.1, -331.6, -400.0, -400.0, -45.09999999999976, -400.0, -400.0, -400.0, -279.9999999999991, -400.0, -1704.0, 30.800000000000196, -24.099999999999746, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -330.1, -349.6, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -353.8, -400.0, -400.0, -340.3, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -1840.0, 20.000000000000014, -347.5, -350.8, -400.0, -393.7, -371.8, -389.8, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -339.4, -400.0, -400.0, -364.3, -400.0, -400.0, -400.0, -381.1, -400.0, 20.000000000000014, -350.8, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -370.59999999999997, -400.0, -397.9, -381.1, -400.0, -400.0, -400.0, 35.30000000000026, -383.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -370.6, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -400.0, -365.8, 25.400000000000098, -400.0, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, 34.40000000000026, 20.000000000000014, -400.0, -347.5, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 197.0, 197.0, 36.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 196.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 131.0, 150.0, 177.0, 193.0, 200.0, 200.0, 179.0, 176.0, 191.0, 200.0, 200.0, 200.0, 162.0, 200.0, 200.0, 183.0, 200.0, 200.0, 1667.0, 160.0, 157.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 61.0, 196.0, 200.0, 200.0, 174.0, 176.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 1820.0, 1813.0, 175.0, 183.0, 200.0, 170.0, 196.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 37.0, 178.0, 183.0, 194.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 191.0, 199.0, 200.0, 200.0, 200.0, 200.0, 192.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 175.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5646477896697752, "mean_inference_ms": 1.7723317705263613, "mean_action_processing_ms": 0.24056301979389147, "mean_env_wait_ms": 0.18854043483865682, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036047697067260742, "StateBufferConnector_ms": 0.0031305551528930664, "ViewRequirementAgentConnector_ms": 0.08611571788787842}, "num_episodes": 18, "episode_return_max": 1812.9999999999945, "episode_return_min": -544.1, "episode_return_mean": -240.16, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 412.22923955434214, "num_env_steps_trained_throughput_per_sec": 412.22923955434214, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 9529.277, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9529.24, "sample_time_ms": 1259.552, "learn_time_ms": 8256.552, "learn_throughput": 484.464, "synch_weights_time_ms": 12.31}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-22-50", "timestamp": 1723645370, "time_this_iter_s": 9.709239959716797, "time_total_s": 1234.4518389701843, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8d61f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1234.4518389701843, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 30.361538461538462, "ram_util_percent": 81.09230769230768}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0522348678794016, "cur_kl_coeff": 5.8066624858410505e-08, "cur_lr": 0.009999999999999998, "total_loss": 0.09576470556190957, "policy_loss": -0.00023969483559350014, "vf_loss": 0.09600440080538786, "vf_explained_var": -0.008911008494240896, "kl": 3.3625231721724392e-43, "entropy": 3.231940394681218e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4233785413580125, "cur_kl_coeff": 0.9610839843749998, "cur_lr": 0.009999999999999998, "total_loss": 8.01382393357615, "policy_loss": 0.0018316727426647154, "vf_loss": 8.001228049444775, "vf_explained_var": 7.090114411853609e-07, "kl": 0.011200079273547514, "entropy": 0.051165449426103064, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 1812.9999999999945, "episode_reward_min": -544.1, "episode_reward_mean": -231.19200000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1840.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 1820.0}, "policy_reward_mean": {"prey_policy": -332.306, "predator_policy": 216.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-388.7, -376.8999999999995, -345.7, -400.0, -83.09999999999991, -400.0, -296.9999999999991, 193.7999999999994, -107.10000000000085, 21.80000000000004, -400.0, -400.0, -123.00000000000028, -400.0, -329.7, -400.0, -396.7, -400.0, -353.8, -362.3, 20.000000000000018, 3.9999999999999627, -400.0, 1812.9999999999945, -340.3, -423.7, -369.6, 20.000000000000014, -400.0, 13.999999999999957, 20.000000000000018, -400.0, 20.000000000000014, -400.0, -341.4, -400.0, -364.3, -400.0, -544.1, 30.200000000000184, 18.499999999999996, -180.00000000000065, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000018, -384.59999999999997, -389.0, -400.0, 35.30000000000026, -391.2, 5.999999999999963, -400.0, -388.6, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -396.7, -400.0, -377.8, 25.400000000000098, -175.50000000000063, -400.0, -400.0, -393.7, -400.0, 20.000000000000014, 20.000000000000018, -355.9, 34.40000000000026, 4.999999999999957, -372.5, -400.0, -400.0, -400.0, -400.0, -400.0, -382.8, 1.0000000000000009, -400.0, -400.0, -381.8, 20.000000000000014, 20.000000000000018, 20.000000000000018, 20.000000000000014, -400.0, 34.400000000000254, -400.0, 33.50000000000024, 10.999999999999957, 20.000000000000018, 23.500000000000068, -400.0, -400.0, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-381.7, -400.0, -355.8999999999995, -400.0, -381.1, -331.6, -400.0, -400.0, -45.09999999999976, -400.0, -400.0, -400.0, -279.9999999999991, -400.0, -1704.0, 30.800000000000196, -24.099999999999746, -400.0, -400.0, 21.80000000000004, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -330.1, -349.6, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -353.8, -400.0, -400.0, -340.3, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -1840.0, 20.000000000000014, -347.5, -350.8, -400.0, -393.7, -371.8, -389.8, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -339.4, -400.0, -400.0, -364.3, -400.0, -400.0, -400.0, -381.1, -400.0, 20.000000000000014, -350.8, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -370.59999999999997, -400.0, -397.9, -381.1, -400.0, -400.0, -400.0, 35.30000000000026, -383.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -370.6, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -400.0, -365.8, 25.400000000000098, -400.0, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, 34.40000000000026, 20.000000000000014, -400.0, -347.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -359.8, -358.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [193.0, 200.0, 200.0, 179.0, 176.0, 191.0, 200.0, 200.0, 200.0, 162.0, 200.0, 200.0, 183.0, 200.0, 200.0, 1667.0, 160.0, 157.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 61.0, 196.0, 200.0, 200.0, 174.0, 176.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 1820.0, 1813.0, 175.0, 183.0, 200.0, 170.0, 196.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 37.0, 178.0, 183.0, 194.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 191.0, 199.0, 200.0, 200.0, 200.0, 200.0, 192.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 192.0, 143.0, 200.0, 181.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5640445226315848, "mean_inference_ms": 1.7756056594598673, "mean_action_processing_ms": 0.24061537020967166, "mean_env_wait_ms": 0.18820371734473704, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004021048545837402, "StateBufferConnector_ms": 0.0031462907791137695, "ViewRequirementAgentConnector_ms": 0.08619832992553711}, "num_episodes": 23, "episode_return_max": 1812.9999999999945, "episode_return_min": -544.1, "episode_return_mean": -231.19200000000004, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 411.9166186610876, "num_env_steps_trained_throughput_per_sec": 411.9166186610876, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 9551.44, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9551.404, "sample_time_ms": 1265.868, "learn_time_ms": 8272.414, "learn_throughput": 483.535, "synch_weights_time_ms": 12.282}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-23-00", "timestamp": 1723645380, "time_this_iter_s": 9.715651988983154, "time_total_s": 1244.1674909591675, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3187621f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1244.1674909591675, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 27.64285714285714, "ram_util_percent": 81.22857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.119821571427146, "cur_kl_coeff": 2.9033312429205252e-08, "cur_lr": 0.009999999999999998, "total_loss": 0.3516331034850467, "policy_loss": -5.742177988092105e-06, "vf_loss": 0.35163884630495135, "vf_explained_var": 2.411991830856081e-05, "kl": 3.318408220517769e-43, "entropy": 3.182607994273052e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1030707343841197, "cur_kl_coeff": 0.9610839843749998, "cur_lr": 0.009999999999999998, "total_loss": 8.447064438572637, "policy_loss": 0.0020258155045291735, "vf_loss": 8.435856652385974, "vf_explained_var": 1.1399498692265263e-05, "kl": 0.009553771511000666, "entropy": 0.026974532130455413, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 1812.9999999999945, "episode_reward_min": -544.1, "episode_reward_mean": -230.87300000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1840.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 1820.0}, "policy_reward_mean": {"prey_policy": -326.5315, "predator_policy": 211.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-353.8, -362.3, 20.000000000000018, 3.9999999999999627, -400.0, 1812.9999999999945, -340.3, -423.7, -369.6, 20.000000000000014, -400.0, 13.999999999999957, 20.000000000000018, -400.0, 20.000000000000014, -400.0, -341.4, -400.0, -364.3, -400.0, -544.1, 30.200000000000184, 18.499999999999996, -180.00000000000065, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000018, -384.59999999999997, -389.0, -400.0, 35.30000000000026, -391.2, 5.999999999999963, -400.0, -388.6, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -396.7, -400.0, -377.8, 25.400000000000098, -175.50000000000063, -400.0, -400.0, -393.7, -400.0, 20.000000000000014, 20.000000000000018, -355.9, 34.40000000000026, 4.999999999999957, -372.5, -400.0, -400.0, -400.0, -400.0, -400.0, -382.8, 1.0000000000000009, -400.0, -400.0, -381.8, 20.000000000000014, 20.000000000000018, 20.000000000000018, 20.000000000000014, -400.0, 34.400000000000254, -400.0, 33.50000000000024, 10.999999999999957, 20.000000000000018, 23.500000000000068, -400.0, -400.0, -400.0, -400.0, -400.0, -9.999999999999817, -400.0, -400.0, -400.0, -379.8, -344.5, 23.500000000000068, -400.0, 20.000000000000018, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-353.8, -400.0, -400.0, -340.3, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -1840.0, 20.000000000000014, -347.5, -350.8, -400.0, -393.7, -371.8, -389.8, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -339.4, -400.0, -400.0, -364.3, -400.0, -400.0, -400.0, -381.1, -400.0, 20.000000000000014, -350.8, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -370.59999999999997, -400.0, -397.9, -381.1, -400.0, -400.0, -400.0, 35.30000000000026, -383.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -370.6, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -400.0, -365.8, 25.400000000000098, -400.0, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, 34.40000000000026, 20.000000000000014, -400.0, -347.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -359.8, -358.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -368.8, -344.5, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 1820.0, 1813.0, 175.0, 183.0, 200.0, 170.0, 196.0, 196.0, 200.0, 200.0, 200.0, 200.0, 200.0, 194.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 198.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 37.0, 178.0, 183.0, 194.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 191.0, 199.0, 200.0, 200.0, 200.0, 200.0, 192.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 192.0, 143.0, 200.0, 181.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5635583649847269, "mean_inference_ms": 1.7690752572928343, "mean_action_processing_ms": 0.24003598309375213, "mean_env_wait_ms": 0.18812388579244352, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004381418228149414, "StateBufferConnector_ms": 0.0031311511993408203, "ViewRequirementAgentConnector_ms": 0.0856856107711792}, "num_episodes": 18, "episode_return_max": 1812.9999999999945, "episode_return_min": -544.1, "episode_return_mean": -230.87300000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.28487263114823, "num_env_steps_trained_throughput_per_sec": 409.28487263114823, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 9594.086, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9594.049, "sample_time_ms": 1259.779, "learn_time_ms": 8321.041, "learn_throughput": 480.709, "synch_weights_time_ms": 12.379}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-23-09", "timestamp": 1723645389, "time_this_iter_s": 9.779398202896118, "time_total_s": 1253.9468891620636, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae944c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1253.9468891620636, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 27.635714285714283, "ram_util_percent": 81.2642857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.40237133472606, "cur_kl_coeff": 1.4516656214602626e-08, "cur_lr": 0.009999999999999998, "total_loss": 0.5876819680725771, "policy_loss": 0.00011681929210979472, "vf_loss": 0.5875651464506826, "vf_explained_var": -0.0002997960678484074, "kl": 2.944165144934386e-43, "entropy": 2.766165599084148e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1065850229795884, "cur_kl_coeff": 0.9610839843749998, "cur_lr": 0.009999999999999998, "total_loss": 8.32629645842093, "policy_loss": 0.0005080818118547243, "vf_loss": 8.319835907567747, "vf_explained_var": -5.129153135592345e-07, "kl": 0.006193479182953747, "entropy": 0.007373336100775817, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 35.30000000000026, "episode_reward_min": -544.1, "episode_reward_mean": -255.31099999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -319.5505, "predator_policy": 191.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-364.3, -400.0, -544.1, 30.200000000000184, 18.499999999999996, -180.00000000000065, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000018, -384.59999999999997, -389.0, -400.0, 35.30000000000026, -391.2, 5.999999999999963, -400.0, -388.6, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -396.7, -400.0, -377.8, 25.400000000000098, -175.50000000000063, -400.0, -400.0, -393.7, -400.0, 20.000000000000014, 20.000000000000018, -355.9, 34.40000000000026, 4.999999999999957, -372.5, -400.0, -400.0, -400.0, -400.0, -400.0, -382.8, 1.0000000000000009, -400.0, -400.0, -381.8, 20.000000000000014, 20.000000000000018, 20.000000000000018, 20.000000000000014, -400.0, 34.400000000000254, -400.0, 33.50000000000024, 10.999999999999957, 20.000000000000018, 23.500000000000068, -400.0, -400.0, -400.0, -400.0, -400.0, -9.999999999999817, -400.0, -400.0, -400.0, -379.8, -344.5, 23.500000000000068, -400.0, 20.000000000000018, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, 33.50000000000025, 29.000000000000156, 20.000000000000014, -397.8, -392.3, -400.0, -531.2, 1.9999999999999876, -195.40000000000057, -373.2, -359.2, -400.0, -400.0, -386.8, -180.00000000000068, 7.499999999999959, -400.0, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-364.3, -400.0, -400.0, -400.0, -381.1, -400.0, 20.000000000000014, -350.8, 24.50000000000008, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -370.59999999999997, -400.0, -397.9, -381.1, -400.0, -400.0, -400.0, 35.30000000000026, -383.2, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -370.6, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -400.0, -365.8, 25.400000000000098, -400.0, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, 34.40000000000026, 20.000000000000014, -400.0, -347.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -359.8, -358.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -368.8, -344.5, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -400.0, 33.50000000000024, -400.0, -362.2, 27.20000000000013, -400.0, 20.000000000000014, -395.8, -400.0, -400.0, -385.3, -400.0, -400.0, -370.6, -346.6, -400.0, 20.000000000000014, -9.400000000000006, -400.0, -356.2, -400.0, -335.2, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, -400.0, 20.000000000000014, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 37.0, 178.0, 183.0, 194.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 191.0, 199.0, 200.0, 200.0, 200.0, 200.0, 192.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 192.0, 143.0, 200.0, 181.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 198.0, 200.0, 193.0, 200.0, 200.0, 200.0, 0.0, 186.0, 182.0, 200.0, 14.0, 200.0, 200.0, 183.0, 200.0, 176.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 0.0, 200.0, 183.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5630367904898506, "mean_inference_ms": 1.7674716758881726, "mean_action_processing_ms": 0.23978305150681392, "mean_env_wait_ms": 0.18792129978032698, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047914981842041016, "StateBufferConnector_ms": 0.003136754035949707, "ViewRequirementAgentConnector_ms": 0.08739066123962402}, "num_episodes": 18, "episode_return_max": 35.30000000000026, "episode_return_min": -544.1, "episode_return_mean": -255.31099999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 425.89828297955484, "num_env_steps_trained_throughput_per_sec": 425.89828297955484, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 9581.11, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9581.075, "sample_time_ms": 1256.347, "learn_time_ms": 8311.199, "learn_throughput": 481.278, "synch_weights_time_ms": 12.69}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-23-19", "timestamp": 1723645399, "time_this_iter_s": 9.397741079330444, "time_total_s": 1263.344630241394, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39adae040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1263.344630241394, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 27.371428571428567, "ram_util_percent": 81.25714285714287}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.873090567104469, "cur_kl_coeff": 7.258328107301313e-09, "cur_lr": 0.009999999999999998, "total_loss": 1.0071803619345976, "policy_loss": -6.274714272607255e-05, "vf_loss": 1.0072431097474508, "vf_explained_var": -0.00013970155564565508, "kl": 3.248921610953472e-43, "entropy": 3.105566154300353e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2108342434250055, "cur_kl_coeff": 0.9610839843749998, "cur_lr": 0.009999999999999998, "total_loss": 8.279014347217702, "policy_loss": 0.0001440562330008972, "vf_loss": 8.278812187437028, "vf_explained_var": -1.3838684748089503e-06, "kl": 6.050120241517773e-05, "entropy": 0.0001844225330969686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 34.40000000000026, "episode_reward_min": -600.0, "episode_reward_mean": -262.35200000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 34.40000000000026, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -322.111, "predator_policy": 190.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -396.7, -400.0, -377.8, 25.400000000000098, -175.50000000000063, -400.0, -400.0, -393.7, -400.0, 20.000000000000014, 20.000000000000018, -355.9, 34.40000000000026, 4.999999999999957, -372.5, -400.0, -400.0, -400.0, -400.0, -400.0, -382.8, 1.0000000000000009, -400.0, -400.0, -381.8, 20.000000000000014, 20.000000000000018, 20.000000000000018, 20.000000000000014, -400.0, 34.400000000000254, -400.0, 33.50000000000024, 10.999999999999957, 20.000000000000018, 23.500000000000068, -400.0, -400.0, -400.0, -400.0, -400.0, -9.999999999999817, -400.0, -400.0, -400.0, -379.8, -344.5, 23.500000000000068, -400.0, 20.000000000000018, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, 33.50000000000025, 29.000000000000156, 20.000000000000014, -397.8, -392.3, -400.0, -531.2, 1.9999999999999876, -195.40000000000057, -373.2, -359.2, -400.0, -400.0, -386.8, -180.00000000000068, 7.499999999999959, -400.0, -400.0, -400.0, -600.0, -169.2000000000006, -381.8, -400.0, -400.0, 20.000000000000018, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000018, -382.4, -400.0, -180.00000000000068, -400.0, 27.20000000000013, -364.5, -400.0, -400.0, 8.29999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, -400.0, -365.8, 25.400000000000098, -400.0, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -393.7, -400.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, 34.40000000000026, 20.000000000000014, -400.0, -347.5, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -359.8, -358.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -368.8, -344.5, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -400.0, 33.50000000000024, -400.0, -362.2, 27.20000000000013, -400.0, 20.000000000000014, -395.8, -400.0, -400.0, -385.3, -400.0, -400.0, -370.6, -346.6, -400.0, 20.000000000000014, -9.400000000000006, -400.0, -356.2, -400.0, -335.2, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, -400.0, 20.000000000000014, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 30.800000000000196, -371.8, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 27.20000000000013, -400.0, -400.0, -344.5, -400.0, -400.0, -400.0, -400.0, 26.300000000000114, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 197.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 185.0, 200.0, 175.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 192.0, 143.0, 200.0, 181.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 198.0, 200.0, 193.0, 200.0, 200.0, 200.0, 0.0, 186.0, 182.0, 200.0, 14.0, 200.0, 200.0, 183.0, 200.0, 176.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 0.0, 200.0, 183.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 0.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.562430408801871, "mean_inference_ms": 1.7657381339945863, "mean_action_processing_ms": 0.23950643696657173, "mean_env_wait_ms": 0.18768274147923975, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005403995513916016, "StateBufferConnector_ms": 0.0032303333282470703, "ViewRequirementAgentConnector_ms": 0.09047293663024902}, "num_episodes": 22, "episode_return_max": 34.40000000000026, "episode_return_min": -600.0, "episode_return_mean": -262.35200000000003, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 420.75142272313826, "num_env_steps_trained_throughput_per_sec": 420.75142272313826, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 9567.494, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9567.458, "sample_time_ms": 1258.527, "learn_time_ms": 8295.497, "learn_throughput": 482.189, "synch_weights_time_ms": 12.583}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-23-28", "timestamp": 1723645408, "time_this_iter_s": 9.514173030853271, "time_total_s": 1272.8588032722473, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ae02820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1272.8588032722473, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 28.338461538461537, "ram_util_percent": 81.29230769230769}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.183827644936425, "cur_kl_coeff": 3.6291640536506565e-09, "cur_lr": 0.009999999999999998, "total_loss": 0.39454350803619026, "policy_loss": 3.059985185111011e-05, "vf_loss": 0.39451290767272384, "vf_explained_var": -0.0075270048524967575, "kl": -1.6122887859588414e-41, "entropy": 2.416204346142199e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2112809685774015, "cur_kl_coeff": 0.4805419921874999, "cur_lr": 0.009999999999999998, "total_loss": 8.481853767929884, "policy_loss": 3.66218498952332e-05, "vf_loss": 8.48181716550595, "vf_explained_var": -1.605225618554171e-08, "kl": -9.433497531813399e-08, "entropy": 0.00018772662859182146, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 34.400000000000254, "episode_reward_min": -600.0, "episode_reward_mean": -260.20300000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 34.400000000000254, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -320.0215, "predator_policy": 189.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -382.8, 1.0000000000000009, -400.0, -400.0, -381.8, 20.000000000000014, 20.000000000000018, 20.000000000000018, 20.000000000000014, -400.0, 34.400000000000254, -400.0, 33.50000000000024, 10.999999999999957, 20.000000000000018, 23.500000000000068, -400.0, -400.0, -400.0, -400.0, -400.0, -9.999999999999817, -400.0, -400.0, -400.0, -379.8, -344.5, 23.500000000000068, -400.0, 20.000000000000018, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, 33.50000000000025, 29.000000000000156, 20.000000000000014, -397.8, -392.3, -400.0, -531.2, 1.9999999999999876, -195.40000000000057, -373.2, -359.2, -400.0, -400.0, -386.8, -180.00000000000068, 7.499999999999959, -400.0, -400.0, -400.0, -600.0, -169.2000000000006, -381.8, -400.0, -400.0, 20.000000000000018, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000018, -382.4, -400.0, -180.00000000000068, -400.0, 27.20000000000013, -364.5, -400.0, -400.0, 8.29999999999996, -400.0, 33.50000000000025, -180.00000000000065, -373.8, 33.50000000000024, -400.0, -379.0, -400.0, 5.999999999999957, -400.0, -400.0, -392.3, 20.900000000000027, 20.000000000000018, -166.50000000000057, -374.7, -400.0, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -359.8, -358.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, 20.000000000000014, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 34.400000000000254, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -368.8, -344.5, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -400.0, 33.50000000000024, -400.0, -362.2, 27.20000000000013, -400.0, 20.000000000000014, -395.8, -400.0, -400.0, -385.3, -400.0, -400.0, -370.6, -346.6, -400.0, 20.000000000000014, -9.400000000000006, -400.0, -356.2, -400.0, -335.2, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, -400.0, 20.000000000000014, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 30.800000000000196, -371.8, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 27.20000000000013, -400.0, -400.0, -344.5, -400.0, -400.0, -400.0, -400.0, 26.300000000000114, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -359.8, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, 20.90000000000003, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -351.7, -400.0, -400.0, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 192.0, 143.0, 200.0, 181.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 198.0, 200.0, 193.0, 200.0, 200.0, 200.0, 0.0, 186.0, 182.0, 200.0, 14.0, 200.0, 200.0, 183.0, 200.0, 176.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 0.0, 200.0, 183.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 0.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5619543585184844, "mean_inference_ms": 1.764392706504163, "mean_action_processing_ms": 0.23927565074396034, "mean_env_wait_ms": 0.18750043433135294, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005855441093444824, "StateBufferConnector_ms": 0.003277301788330078, "ViewRequirementAgentConnector_ms": 0.09214746952056885}, "num_episodes": 18, "episode_return_max": 34.400000000000254, "episode_return_min": -600.0, "episode_return_mean": -260.20300000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 420.7292965206835, "num_env_steps_trained_throughput_per_sec": 420.7292965206835, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 9554.844, "restore_workers_time_ms": 0.013, "training_step_time_ms": 9554.806, "sample_time_ms": 1263.71, "learn_time_ms": 8277.492, "learn_throughput": 483.238, "synch_weights_time_ms": 12.747}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-23-38", "timestamp": 1723645418, "time_this_iter_s": 9.512475967407227, "time_total_s": 1282.3712792396545, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39adae1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1282.3712792396545, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 27.192857142857143, "ram_util_percent": 81.32142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8874155847271954, "cur_kl_coeff": 1.8145820268253283e-09, "cur_lr": 0.009999999999999998, "total_loss": 0.9242655694267895, "policy_loss": 0.00016311785802442246, "vf_loss": 0.9241024533220784, "vf_explained_var": 0.00016968102051467492, "kl": 4.083354067932161e-43, "entropy": 4.034392860021756e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4516845096859259, "cur_kl_coeff": 0.24027099609374994, "cur_lr": 0.009999999999999998, "total_loss": 7.59737094848875, "policy_loss": 0.0002423469728676888, "vf_loss": 7.5971285792254895, "vf_explained_var": -4.478232570426174e-09, "kl": 4.770057462793109e-08, "entropy": 0.00018633012361110005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 33.50000000000025, "episode_reward_min": -600.0, "episode_reward_mean": -266.27000000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -320.275, "predator_policy": 187.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -9.999999999999817, -400.0, -400.0, -400.0, -379.8, -344.5, 23.500000000000068, -400.0, 20.000000000000018, 20.000000000000018, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, 33.50000000000025, 29.000000000000156, 20.000000000000014, -397.8, -392.3, -400.0, -531.2, 1.9999999999999876, -195.40000000000057, -373.2, -359.2, -400.0, -400.0, -386.8, -180.00000000000068, 7.499999999999959, -400.0, -400.0, -400.0, -600.0, -169.2000000000006, -381.8, -400.0, -400.0, 20.000000000000018, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000018, -382.4, -400.0, -180.00000000000068, -400.0, 27.20000000000013, -364.5, -400.0, -400.0, 8.29999999999996, -400.0, 33.50000000000025, -180.00000000000065, -373.8, 33.50000000000024, -400.0, -379.0, -400.0, 5.999999999999957, -400.0, -400.0, -392.3, 20.900000000000027, 20.000000000000018, -166.50000000000057, -374.7, -400.0, -400.0, -400.0, 20.000000000000018, 33.50000000000024, 14.999999999999957, -400.0, -166.5000000000006, 6.099999999999961, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.9, -400.0, 25.400000000000098, -180.00000000000068, -400.0, -180.00000000000065, -400.0, 12.499999999999963, -400.0, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -368.8, -344.5, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -349.6, -400.0, 33.50000000000024, -400.0, -362.2, 27.20000000000013, -400.0, 20.000000000000014, -395.8, -400.0, -400.0, -385.3, -400.0, -400.0, -370.6, -346.6, -400.0, 20.000000000000014, -9.400000000000006, -400.0, -356.2, -400.0, -335.2, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, -400.0, 20.000000000000014, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 30.800000000000196, -371.8, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 27.20000000000013, -400.0, -400.0, -344.5, -400.0, -400.0, -400.0, -400.0, 26.300000000000114, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -359.8, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, 20.90000000000003, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -351.7, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 28.100000000000147, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, -400.0, 25.400000000000098, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 170.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 198.0, 200.0, 193.0, 200.0, 200.0, 200.0, 0.0, 186.0, 182.0, 200.0, 14.0, 200.0, 200.0, 183.0, 200.0, 176.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 0.0, 200.0, 183.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 0.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 0.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5613327944028984, "mean_inference_ms": 1.762684728807489, "mean_action_processing_ms": 0.23898509145816202, "mean_env_wait_ms": 0.1872730690044032, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005415916442871094, "StateBufferConnector_ms": 0.0030961036682128906, "ViewRequirementAgentConnector_ms": 0.09199070930480957}, "num_episodes": 23, "episode_return_max": 33.50000000000025, "episode_return_min": -600.0, "episode_return_mean": -266.27000000000004, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 409.9642636575086, "num_env_steps_trained_throughput_per_sec": 409.9642636575086, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 9570.135, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9570.097, "sample_time_ms": 1242.494, "learn_time_ms": 8313.698, "learn_throughput": 481.134, "synch_weights_time_ms": 13.07}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-23-48", "timestamp": 1723645428, "time_this_iter_s": 9.762306928634644, "time_total_s": 1292.1335861682892, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ada7af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1292.1335861682892, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 27.564285714285717, "ram_util_percent": 81.42142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9938056586665056, "cur_kl_coeff": 9.072910134126641e-10, "cur_lr": 0.009999999999999998, "total_loss": 0.7150987336165691, "policy_loss": 0.0004906841322148918, "vf_loss": 0.7146080484860158, "vf_explained_var": 0.00012380237932558413, "kl": 3.2244619091872943e-43, "entropy": 3.078337231076927e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3263466056543631, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 0.009999999999999998, "total_loss": 7.9042229881993045, "policy_loss": -9.601759950990084e-05, "vf_loss": 7.904319037079181, "vf_explained_var": -1.2173223747778191e-08, "kl": 8.331571029668011e-07, "entropy": 0.00019168119666458565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 33.50000000000025, "episode_reward_min": -600.0, "episode_reward_mean": -263.684, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -316.11699999999996, "predator_policy": 184.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-349.6, 33.50000000000025, 29.000000000000156, 20.000000000000014, -397.8, -392.3, -400.0, -531.2, 1.9999999999999876, -195.40000000000057, -373.2, -359.2, -400.0, -400.0, -386.8, -180.00000000000068, 7.499999999999959, -400.0, -400.0, -400.0, -600.0, -169.2000000000006, -381.8, -400.0, -400.0, 20.000000000000018, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000018, -382.4, -400.0, -180.00000000000068, -400.0, 27.20000000000013, -364.5, -400.0, -400.0, 8.29999999999996, -400.0, 33.50000000000025, -180.00000000000065, -373.8, 33.50000000000024, -400.0, -379.0, -400.0, 5.999999999999957, -400.0, -400.0, -392.3, 20.900000000000027, 20.000000000000018, -166.50000000000057, -374.7, -400.0, -400.0, -400.0, 20.000000000000018, 33.50000000000024, 14.999999999999957, -400.0, -166.5000000000006, 6.099999999999961, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.9, -400.0, 25.400000000000098, -180.00000000000068, -400.0, -180.00000000000065, -400.0, 12.499999999999963, -400.0, -400.0, 20.000000000000018, 20.000000000000014, -400.0, -400.0, -400.0, -373.6, -180.00000000000065, 33.50000000000024, -400.0, -381.1, 20.90000000000003, -400.0, -400.0, -180.00000000000065, -400.0, -400.0, -400.0, -171.90000000000063], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-349.6, -400.0, 33.50000000000024, -400.0, -362.2, 27.20000000000013, -400.0, 20.000000000000014, -395.8, -400.0, -400.0, -385.3, -400.0, -400.0, -370.6, -346.6, -400.0, 20.000000000000014, -9.400000000000006, -400.0, -356.2, -400.0, -335.2, -400.0, -400.0, -400.0, -400.0, -400.0, -374.8, -400.0, -400.0, 20.000000000000014, 24.50000000000008, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 30.800000000000196, -371.8, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 27.20000000000013, -400.0, -400.0, -344.5, -400.0, -400.0, -400.0, -400.0, 26.300000000000114, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -359.8, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, 20.90000000000003, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -351.7, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 28.100000000000147, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, -400.0, 25.400000000000098, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -349.6, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -381.1, 20.90000000000003, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 28.100000000000147], "policy_predator_policy_reward": [200.0, 200.0, 200.0, 200.0, 182.0, 182.0, 200.0, 200.0, 198.0, 200.0, 193.0, 200.0, 200.0, 200.0, 0.0, 186.0, 182.0, 200.0, 14.0, 200.0, 200.0, 183.0, 200.0, 176.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 0.0, 200.0, 183.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 0.0, 200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 0.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 176.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.56089205312987, "mean_inference_ms": 1.7614716007568676, "mean_action_processing_ms": 0.23876489084831842, "mean_env_wait_ms": 0.18710384477393394, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005038142204284668, "StateBufferConnector_ms": 0.00311434268951416, "ViewRequirementAgentConnector_ms": 0.09203124046325684}, "num_episodes": 18, "episode_return_max": 33.50000000000025, "episode_return_min": -600.0, "episode_return_mean": -263.684, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 413.35414572708015, "num_env_steps_trained_throughput_per_sec": 413.35414572708015, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 9602.174, "restore_workers_time_ms": 0.014, "training_step_time_ms": 9602.136, "sample_time_ms": 1243.499, "learn_time_ms": 8344.748, "learn_throughput": 479.343, "synch_weights_time_ms": 13.049}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-23-57", "timestamp": 1723645437, "time_this_iter_s": 9.681482076644897, "time_total_s": 1301.815068244934, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ada7a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1301.815068244934, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 27.55384615384615, "ram_util_percent": 81.5153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1236152563515125, "cur_kl_coeff": 4.5364550670633207e-10, "cur_lr": 0.009999999999999998, "total_loss": 0.7282735522915289, "policy_loss": 3.261456546920633e-05, "vf_loss": 0.728240933444686, "vf_explained_var": -6.982466531178308e-05, "kl": 3.5432832597927518e-43, "entropy": 3.433274275747099e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2384447362239765, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 0.009999999999999998, "total_loss": 8.158150971881927, "policy_loss": 2.808375629010024e-05, "vf_loss": 8.158122878604464, "vf_explained_var": -1.5358445505616526e-08, "kl": 5.428053772555066e-07, "entropy": 0.00018507462521450145, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 33.50000000000025, "episode_reward_min": -560.1, "episode_reward_mean": -251.05100000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -312.36549999999994, "predator_policy": 186.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-381.8, -400.0, -400.0, 20.000000000000018, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000018, -382.4, -400.0, -180.00000000000068, -400.0, 27.20000000000013, -364.5, -400.0, -400.0, 8.29999999999996, -400.0, 33.50000000000025, -180.00000000000065, -373.8, 33.50000000000024, -400.0, -379.0, -400.0, 5.999999999999957, -400.0, -400.0, -392.3, 20.900000000000027, 20.000000000000018, -166.50000000000057, -374.7, -400.0, -400.0, -400.0, 20.000000000000018, 33.50000000000024, 14.999999999999957, -400.0, -166.5000000000006, 6.099999999999961, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.9, -400.0, 25.400000000000098, -180.00000000000068, -400.0, -180.00000000000065, -400.0, 12.499999999999963, -400.0, -400.0, 20.000000000000018, 20.000000000000014, -400.0, -400.0, -400.0, -373.6, -180.00000000000065, 33.50000000000024, -400.0, -381.1, 20.90000000000003, -400.0, -400.0, -180.00000000000065, -400.0, -400.0, -400.0, -171.90000000000063, 20.900000000000027, 20.000000000000018, 29.90000000000018, 29.90000000000018, -180.00000000000068, 20.000000000000014, -400.0, -400.0, -377.8, 20.000000000000018, -400.0, 20.000000000000018, -400.0, -355.9, -400.0, -560.1, 20.000000000000018, -348.3, -400.0, -400.0, -558.0, 20.000000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-371.8, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -366.4, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 27.20000000000013, -400.0, -400.0, -344.5, -400.0, -400.0, -400.0, -400.0, 26.300000000000114, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -359.8, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, 20.90000000000003, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -351.7, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 28.100000000000147, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, -400.0, 25.400000000000098, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -349.6, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -381.1, 20.90000000000003, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 28.100000000000147, -400.0, 20.90000000000003, 20.000000000000014, -400.0, 29.90000000000018, -400.0, 29.90000000000018, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -365.8, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -360.1, 20.000000000000014, -400.0, -340.3, -400.0, -400.0, -400.0, -400.0, -400.0, -358.0, -400.0, -400.0, 20.000000000000014], "policy_predator_policy_reward": [200.0, 190.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 180.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 0.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 176.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5605076764228637, "mean_inference_ms": 1.761502425029277, "mean_action_processing_ms": 0.23830449233716025, "mean_env_wait_ms": 0.18695154921587306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045239925384521484, "StateBufferConnector_ms": 0.0031197071075439453, "ViewRequirementAgentConnector_ms": 0.09130465984344482}, "num_episodes": 22, "episode_return_max": 33.50000000000025, "episode_return_min": -560.1, "episode_return_mean": -251.05100000000004, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 431.9036366580012, "num_env_steps_trained_throughput_per_sec": 431.9036366580012, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 9559.589, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9559.55, "sample_time_ms": 1242.199, "learn_time_ms": 8303.545, "learn_throughput": 481.722, "synch_weights_time_ms": 13.014}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-24-07", "timestamp": 1723645447, "time_this_iter_s": 9.265948057174683, "time_total_s": 1311.0810163021088, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39a8cc5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1311.0810163021088, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 27.457142857142856, "ram_util_percent": 81.38571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6888371600977652, "cur_kl_coeff": 2.2682275335316603e-10, "cur_lr": 0.009999999999999998, "total_loss": 0.55555099599635, "policy_loss": -1.3890025752877433e-06, "vf_loss": 0.55555238682449, "vf_explained_var": 0.00010344956917737527, "kl": 3.0044283931779418e-43, "entropy": 2.833437072787132e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2422414668518946, "cur_kl_coeff": 0.030033874511718742, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": 0.0004750853187586895, "vf_loss": 8.019304743014946, "vf_explained_var": -1.1416339369677992e-08, "kl": Infinity, "entropy": 6.666965484169544e-05, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 33.50000000000025, "episode_reward_min": -560.1, "episode_reward_mean": -248.74300000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -310.3015, "predator_policy": 185.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.29999999999996, -400.0, 33.50000000000025, -180.00000000000065, -373.8, 33.50000000000024, -400.0, -379.0, -400.0, 5.999999999999957, -400.0, -400.0, -392.3, 20.900000000000027, 20.000000000000018, -166.50000000000057, -374.7, -400.0, -400.0, -400.0, 20.000000000000018, 33.50000000000024, 14.999999999999957, -400.0, -166.5000000000006, 6.099999999999961, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.9, -400.0, 25.400000000000098, -180.00000000000068, -400.0, -180.00000000000065, -400.0, 12.499999999999963, -400.0, -400.0, 20.000000000000018, 20.000000000000014, -400.0, -400.0, -400.0, -373.6, -180.00000000000065, 33.50000000000024, -400.0, -381.1, 20.90000000000003, -400.0, -400.0, -180.00000000000065, -400.0, -400.0, -400.0, -171.90000000000063, 20.900000000000027, 20.000000000000018, 29.90000000000018, 29.90000000000018, -180.00000000000068, 20.000000000000014, -400.0, -400.0, -377.8, 20.000000000000018, -400.0, 20.000000000000018, -400.0, -355.9, -400.0, -560.1, 20.000000000000018, -348.3, -400.0, -400.0, -558.0, 20.000000000000014, 13.999999999999957, -341.2, 20.000000000000018, 21.80000000000004, -180.00000000000065, -400.0, -400.0, -400.0, -375.8, -389.5, -400.0, -180.00000000000068, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.300000000000114, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -359.8, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -379.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -385.3, -400.0, -400.0, 20.90000000000003, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -351.7, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, 33.50000000000024, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, 28.100000000000147, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, -400.0, 25.400000000000098, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -349.6, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -381.1, 20.90000000000003, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 28.100000000000147, -400.0, 20.90000000000003, 20.000000000000014, -400.0, 29.90000000000018, -400.0, 29.90000000000018, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -365.8, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -360.1, 20.000000000000014, -400.0, -340.3, -400.0, -400.0, -400.0, -400.0, -400.0, -358.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -341.2, 20.000000000000014, -400.0, 21.80000000000004, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -353.8, -400.0, -389.5, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0], "policy_predator_policy_reward": [200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 186.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 193.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 177.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 0.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 176.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 194.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5600042667793018, "mean_inference_ms": 1.7589515967267653, "mean_action_processing_ms": 0.23834566408582858, "mean_env_wait_ms": 0.18676403816063833, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004005074501037598, "StateBufferConnector_ms": 0.0030927658081054688, "ViewRequirementAgentConnector_ms": 0.08941149711608887}, "num_episodes": 18, "episode_return_max": 33.50000000000025, "episode_return_min": -560.1, "episode_return_mean": -248.74300000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 415.4814256290022, "num_env_steps_trained_throughput_per_sec": 415.4814256290022, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 9591.586, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9591.547, "sample_time_ms": 1239.04, "learn_time_ms": 8338.112, "learn_throughput": 479.725, "synch_weights_time_ms": 13.543}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-24-16", "timestamp": 1723645456, "time_this_iter_s": 9.641249656677246, "time_total_s": 1320.722265958786, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ad36280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1320.722265958786, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 29.707692307692316, "ram_util_percent": 81.1076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.47440076997139, "cur_kl_coeff": 1.1341137667658302e-10, "cur_lr": 0.009999999999999998, "total_loss": 0.701069804327316, "policy_loss": -0.00024012380659028335, "vf_loss": 0.7013099292598705, "vf_explained_var": 0.0005539251698387994, "kl": 3.0949122368743442e-43, "entropy": 2.934184092986805e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1574210435352548, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 0.009999999999999998, "total_loss": Infinity, "policy_loss": 0.00025872112986035446, "vf_loss": 8.029570325720247, "vf_explained_var": -8.262654460927166e-09, "kl": Infinity, "entropy": 4.548119634839719e-36, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 33.50000000000024, "episode_reward_min": -560.1, "episode_reward_mean": -256.37300000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -314.0515, "predator_policy": 185.865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -166.5000000000006, 6.099999999999961, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -373.9, -400.0, 25.400000000000098, -180.00000000000068, -400.0, -180.00000000000065, -400.0, 12.499999999999963, -400.0, -400.0, 20.000000000000018, 20.000000000000014, -400.0, -400.0, -400.0, -373.6, -180.00000000000065, 33.50000000000024, -400.0, -381.1, 20.90000000000003, -400.0, -400.0, -180.00000000000065, -400.0, -400.0, -400.0, -171.90000000000063, 20.900000000000027, 20.000000000000018, 29.90000000000018, 29.90000000000018, -180.00000000000068, 20.000000000000014, -400.0, -400.0, -377.8, 20.000000000000018, -400.0, 20.000000000000018, -400.0, -355.9, -400.0, -560.1, 20.000000000000018, -348.3, -400.0, -400.0, -558.0, 20.000000000000014, 13.999999999999957, -341.2, 20.000000000000018, 21.80000000000004, -180.00000000000065, -400.0, -400.0, -400.0, -375.8, -389.5, -400.0, -180.00000000000068, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000018, -400.0, -366.4, 20.000000000000014, 20.000000000000014, -180.00000000000068, -179.10000000000068, -400.0, -400.0, -400.0, -354.3, -372.8, -379.0, -400.0, -391.8, -400.0, 25.700000000000102, 20.000000000000014, 25.400000000000098, -379.8, -400.0, 33.50000000000024, 20.000000000000018, -400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -400.0, -400.0, 33.50000000000024, -400.0, 28.100000000000147, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -355.9, -400.0, -400.0, -400.0, 25.400000000000098, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -349.6, 20.000000000000014, -400.0, 33.50000000000024, -400.0, -400.0, -400.0, -400.0, -381.1, 20.90000000000003, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 28.100000000000147, -400.0, 20.90000000000003, 20.000000000000014, -400.0, 29.90000000000018, -400.0, 29.90000000000018, -400.0, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -365.8, 20.000000000000014, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -355.9, -400.0, -400.0, -400.0, -360.1, 20.000000000000014, -400.0, -340.3, -400.0, -400.0, -400.0, -400.0, -400.0, -358.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, -400.0, -400.0, -341.2, 20.000000000000014, -400.0, 21.80000000000004, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -353.8, -400.0, -389.5, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, 20.000000000000014, -400.0, -400.0, -400.0, -400.0, -366.4, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.90000000000003, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -366.4, -355.9, -400.0, -359.8, -400.0, -379.0, -400.0, -400.0, -386.8, -400.0, -400.0, -400.0, -374.8, 33.50000000000024, -400.0, 20.000000000000014, -400.0, 25.400000000000098, -400.0, -368.8, -400.0, -400.0, -400.0, 33.50000000000024, 20.000000000000014, -400.0, -400.0, -400.0], "policy_predator_policy_reward": [200.0, 200.0, 0.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 182.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 176.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 188.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 192.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 194.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 0.0, 200.0, 200.0, 0.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 184.0, 184.0, 187.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 195.0, 200.0, 200.0, 176.0, 191.0, 200.0, 200.0, 200.0, 200.0, 200.0, 189.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5595320155173062, "mean_inference_ms": 1.762620503143657, "mean_action_processing_ms": 0.2384304217369414, "mean_env_wait_ms": 0.1864929779055018, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003673553466796875, "StateBufferConnector_ms": 0.0031038522720336914, "ViewRequirementAgentConnector_ms": 0.09279096126556396}, "num_episodes": 23, "episode_return_max": 33.50000000000024, "episode_return_min": -560.1, "episode_return_mean": -256.37300000000005, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 416.650600936934, "num_env_steps_trained_throughput_per_sec": 416.650600936934, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 9581.289, "restore_workers_time_ms": 0.015, "training_step_time_ms": 9581.25, "sample_time_ms": 1249.801, "learn_time_ms": 8317.267, "learn_throughput": 480.927, "synch_weights_time_ms": 13.339}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "c7e6b_00000", "date": "2024-08-14_10-24-26", "timestamp": 1723645466, "time_this_iter_s": 9.605434894561768, "time_total_s": 1330.3277008533478, "pid": 21815, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 0.01, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x39ad36c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1330.3277008533478, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 28.835714285714285, "ram_util_percent": 81.4}}
